Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,209,890

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7227 |     50.840 |   1.3133 |     44.669 |     0.2
    2 |   1.3084 |     43.200 |   1.2194 |     40.349 |     0.5
    3 |   1.2293 |     40.643 |   1.1670 |     38.051 |     0.7
    4 |   1.1685 |     39.001 |   1.1206 |     36.060 |     0.9
    5 |   1.1233 |     37.240 |   1.1066 |     36.979 |     1.1
    6 |   1.0826 |     36.579 |   1.1196 |     37.500 |     1.3
    7 |   1.0532 |     35.685 |   1.0930 |     36.489 |     1.6
    8 |   1.0228 |     34.276 |   1.0366 |     34.651 |     1.8
    9 |   0.9822 |     33.480 |   1.0081 |     33.364 |     2.0
   10 |   0.9498 |     31.757 |   1.0189 |     33.578 |     2.2
   11 |   0.9244 |     31.329 |   1.0115 |     32.782 |     2.5
   12 |   0.8960 |     30.407 |   1.0004 |     33.977 |     2.7
   13 |   0.8657 |     29.302 |   0.9949 |     32.812 |     2.9
   14 |   0.8450 |     28.842 |   0.9745 |     32.996 |     3.1
   15 |   0.8338 |     28.538 |   0.9690 |     31.464 |     3.4
   16 |   0.7973 |     27.173 |   0.9468 |     31.495 |     3.6
   17 |   0.7835 |     26.631 |   0.9525 |     32.138 |     3.8
   18 |   0.7643 |     26.327 |   0.9527 |     32.077 |     4.0
   19 |   0.7396 |     25.233 |   0.9315 |     30.790 |     4.3
   20 |   0.7380 |     25.385 |   0.9561 |     31.832 |     4.5
   21 |   0.6956 |     24.036 |   0.9854 |     32.904 |     4.7
   22 |   0.6912 |     23.673 |   0.9513 |     32.292 |     4.9
   23 |   0.6882 |     23.629 |   0.9216 |     30.882 |     5.2
   24 |   0.6554 |     22.784 |   1.0153 |     31.985 |     5.4
   25 |   0.6420 |     22.215 |   0.9450 |     31.342 |     5.6
   26 |   0.6214 |     21.337 |   0.9487 |     30.178 |     5.9
   27 |   0.6121 |     20.985 |   0.9610 |     32.659 |     6.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 419,170

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7453 |     48.781 |   1.3252 |     43.781 |     0.1
    2 |   1.3035 |     42.615 |   1.1932 |     39.062 |     0.3
    3 |   1.2041 |     39.911 |   1.1203 |     36.979 |     0.4
    4 |   1.1426 |     38.118 |   1.0706 |     35.815 |     0.6
    5 |   1.0894 |     36.552 |   1.0359 |     34.498 |     0.7
    6 |   1.0506 |     35.273 |   0.9947 |     33.150 |     0.9
    7 |   1.0035 |     33.528 |   0.9873 |     33.670 |     1.0
    8 |   0.9739 |     33.008 |   0.9541 |     31.740 |     1.2
    9 |   0.9392 |     31.735 |   0.9258 |     30.607 |     1.3
   10 |   0.9042 |     30.532 |   0.9017 |     29.933 |     1.5
   11 |   0.8755 |     29.373 |   0.8987 |     29.657 |     1.6
   12 |   0.8406 |     28.273 |   0.8816 |     29.473 |     1.7
   13 |   0.8262 |     28.088 |   0.8659 |     28.707 |     1.9
   14 |   0.7939 |     26.918 |   0.8503 |     28.554 |     2.0
   15 |   0.7763 |     26.344 |   0.8229 |     26.777 |     2.2
   16 |   0.7471 |     25.070 |   0.8276 |     27.390 |     2.3
   17 |   0.7236 |     24.881 |   0.8198 |     26.348 |     2.5
   18 |   0.7012 |     23.580 |   0.8218 |     26.777 |     2.6
   19 |   0.6811 |     23.402 |   0.8471 |     27.267 |     2.7
   20 |   0.6645 |     23.017 |   0.8223 |     27.114 |     2.9
   21 |   0.6408 |     21.760 |   0.8210 |     26.256 |     3.0
   22 |   0.6157 |     20.898 |   0.7989 |     24.571 |     3.2
   23 |   0.5971 |     20.340 |   0.7898 |     25.276 |     3.3
   24 |   0.5885 |     20.216 |   0.8144 |     25.613 |     3.5
   25 |   0.5622 |     19.425 |   0.7988 |     24.847 |     3.6
   26 |   0.5652 |     19.311 |   0.7954 |     24.510 |     3.8
   27 |   0.5366 |     18.531 |   0.7888 |     25.092 |     3.9
   28 |   0.5176 |     17.658 |   0.8360 |     25.306 |     4.0
   29 |   0.5204 |     17.907 |   0.7996 |     25.705 |     4.2
   30 |   0.4962 |     17.111 |   0.7909 |     24.326 |     4.3
   31 |   0.4889 |     17.171 |   0.8276 |     24.418 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 151,650

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9570 |     75.899 |   2.5507 |     50.674 |     0.2
    2 |   2.3798 |     50.130 |   2.0168 |     45.558 |     0.3
    3 |   2.0059 |     46.261 |   1.7755 |     44.945 |     0.5
    4 |   1.8115 |     45.172 |   1.6428 |     43.597 |     0.6
    5 |   1.6849 |     44.116 |   1.5556 |     42.647 |     0.8
    6 |   1.5908 |     43.265 |   1.4859 |     41.973 |     1.0
    7 |   1.5238 |     42.555 |   1.4389 |     41.850 |     1.1
    8 |   1.4675 |     42.019 |   1.3924 |     40.441 |     1.3
    9 |   1.4245 |     41.217 |   1.3583 |     40.165 |     1.4
   10 |   1.3840 |     40.713 |   1.3296 |     39.920 |     1.6
   11 |   1.3474 |     40.036 |   1.3064 |     39.154 |     1.7
   12 |   1.3142 |     39.879 |   1.2810 |     38.879 |     1.9
   13 |   1.2850 |     38.979 |   1.2596 |     37.929 |     2.1
   14 |   1.2616 |     38.399 |   1.2457 |     37.960 |     2.2
   15 |   1.2377 |     37.803 |   1.2285 |     37.898 |     2.4
   16 |   1.2156 |     37.305 |   1.2152 |     37.623 |     2.5
   17 |   1.1962 |     36.834 |   1.1997 |     36.949 |     2.7
   18 |   1.1736 |     36.563 |   1.1912 |     36.366 |     2.8
   19 |   1.1574 |     35.566 |   1.1721 |     35.692 |     2.9
   20 |   1.1381 |     35.392 |   1.1632 |     35.754 |     3.1
   21 |   1.1244 |     34.775 |   1.1621 |     35.938 |     3.2
   22 |   1.1106 |     34.303 |   1.1439 |     34.957 |     3.4
   23 |   1.0935 |     34.038 |   1.1403 |     35.325 |     3.5
   24 |   1.0742 |     33.393 |   1.1246 |     34.344 |     3.7
   25 |   1.0609 |     33.176 |   1.1287 |     35.080 |     3.8
   26 |   1.0497 |     32.949 |   1.1148 |     34.375 |     4.0
   27 |   1.0353 |     32.493 |   1.1164 |     34.344 |     4.1
   28 |   1.0243 |     32.152 |   1.1079 |     34.375 |     4.3
   29 |   1.0126 |     32.011 |   1.1031 |     33.517 |     4.5
   30 |   1.0013 |     31.448 |   1.0994 |     33.762 |     4.6
   31 |   0.9875 |     30.998 |   1.0842 |     33.333 |     4.8
   32 |   0.9746 |     30.673 |   1.0849 |     33.395 |     4.9
   33 |   0.9681 |     30.451 |   1.0810 |     33.150 |     5.1
   34 |   0.9523 |     30.245 |   1.0874 |     33.272 |     5.3
   35 |   0.9485 |     30.153 |   1.0733 |     33.088 |     5.4
   36 |   0.9343 |     29.578 |   1.0642 |     32.874 |     5.6
   37 |   0.9239 |     29.020 |   1.0686 |     33.027 |     5.7
   38 |   0.9083 |     28.950 |   1.0672 |     33.088 |     5.9
   39 |   0.9081 |     28.879 |   1.0653 |     32.812 |     6.0
   40 |   0.8977 |     28.706 |   1.0549 |     32.292 |     6.2
   41 |   0.8869 |     28.316 |   1.0551 |     32.353 |     6.4
   42 |   0.8773 |     27.958 |   1.0655 |     32.751 |     6.5
   43 |   0.8636 |     27.476 |   1.0596 |     32.629 |     6.7
   44 |   0.8611 |     27.601 |   1.0653 |     32.721 |     6.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 602,658

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5955 |     46.419 |   1.2861 |     40.564 |     0.2
    2 |   1.2062 |     39.624 |   1.1567 |     38.664 |     0.4
    3 |   1.0843 |     35.945 |   1.0232 |     34.773 |     0.5
    4 |   1.0027 |     33.707 |   1.0157 |     34.344 |     0.7
    5 |   0.9322 |     31.464 |   0.9472 |     31.127 |     0.9
    6 |   0.8643 |     29.237 |   0.8879 |     30.086 |     1.1
    7 |   0.8215 |     27.953 |   0.8815 |     28.983 |     1.3
    8 |   0.7832 |     26.718 |   0.8808 |     29.197 |     1.5
    9 |   0.7474 |     25.704 |   0.8049 |     26.379 |     1.6
   10 |   0.7008 |     24.160 |   0.8157 |     27.267 |     1.8
   11 |   0.6701 |     23.163 |   0.8002 |     25.735 |     2.0
   12 |   0.6435 |     21.874 |   0.7699 |     25.153 |     2.2
   13 |   0.6335 |     21.928 |   0.7624 |     24.755 |     2.4
   14 |   0.5824 |     19.755 |   0.7872 |     25.276 |     2.6
   15 |   0.5623 |     19.695 |   0.7512 |     24.877 |     2.7
   16 |   0.5346 |     18.563 |   0.7547 |     24.632 |     2.9
   17 |   0.5076 |     17.534 |   0.7536 |     23.621 |     3.1
   18 |   0.5024 |     17.566 |   0.7652 |     24.632 |     3.3
   19 |   0.4800 |     16.959 |   0.7640 |     22.825 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 437,090

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7754 |     50.515 |   1.3168 |     43.444 |     0.2
    2 |   1.2775 |     42.046 |   1.2075 |     39.583 |     0.3
    3 |   1.1823 |     39.407 |   1.1395 |     37.377 |     0.5
    4 |   1.1120 |     37.289 |   1.0581 |     35.386 |     0.6
    5 |   1.0454 |     34.737 |   1.0204 |     33.364 |     0.8
    6 |   0.9952 |     33.149 |   0.9966 |     33.517 |     1.0
    7 |   0.9463 |     31.773 |   0.9361 |     30.974 |     1.1
    8 |   0.9041 |     30.424 |   0.9390 |     31.189 |     1.3
    9 |   0.8656 |     29.318 |   0.9054 |     29.902 |     1.4
   10 |   0.8361 |     27.855 |   0.9018 |     29.871 |     1.6
   11 |   0.8045 |     27.297 |   0.8912 |     29.320 |     1.7
   12 |   0.7681 |     26.279 |   0.8681 |     29.136 |     1.9
   13 |   0.7358 |     25.238 |   0.8425 |     27.604 |     2.0
   14 |   0.7192 |     24.382 |   0.8440 |     27.114 |     2.2
   15 |   0.6906 |     23.353 |   0.8553 |     27.267 |     2.3
   16 |   0.6806 |     23.315 |   0.8247 |     26.716 |     2.5
   17 |   0.6524 |     22.415 |   0.8241 |     26.256 |     2.6
   18 |   0.6351 |     21.744 |   0.8019 |     25.153 |     2.8
   19 |   0.6042 |     20.817 |   0.8067 |     25.735 |     2.9
   20 |   0.5987 |     20.530 |   0.8128 |     25.858 |     3.0
   21 |   0.5704 |     19.641 |   0.8190 |     25.613 |     3.2
   22 |   0.5470 |     19.067 |   0.8197 |     25.521 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 138,946

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.0965 |     76.701 |   2.7379 |     66.054 |     0.1
    2 |   2.6202 |     61.741 |   2.2904 |     53.615 |     0.2
    3 |   2.2746 |     51.799 |   1.9758 |     48.529 |     0.2
    4 |   2.0183 |     48.277 |   1.7739 |     45.833 |     0.3
    5 |   1.8393 |     46.749 |   1.6545 |     44.608 |     0.4
    6 |   1.7257 |     45.936 |   1.5744 |     44.271 |     0.5
    7 |   1.6349 |     45.021 |   1.5105 |     42.586 |     0.6
    8 |   1.5746 |     44.457 |   1.4686 |     42.341 |     0.6
    9 |   1.5212 |     43.818 |   1.4272 |     41.850 |     0.7
   10 |   1.4778 |     43.314 |   1.3965 |     41.085 |     0.8
   11 |   1.4377 |     42.355 |   1.3940 |     40.870 |     0.9
   12 |   1.4038 |     41.553 |   1.3565 |     39.706 |     1.0
   13 |   1.3732 |     41.239 |   1.3394 |     40.257 |     1.0
   14 |   1.3472 |     40.643 |   1.3153 |     39.308 |     1.1
   15 |   1.3219 |     40.323 |   1.3156 |     39.767 |     1.2
   16 |   1.2980 |     39.315 |   1.3081 |     39.062 |     1.3
   17 |   1.2754 |     38.968 |   1.2925 |     38.971 |     1.4
   18 |   1.2518 |     38.481 |   1.2733 |     38.572 |     1.4
   19 |   1.2338 |     37.955 |   1.2603 |     38.174 |     1.5
   20 |   1.2172 |     37.971 |   1.2610 |     38.113 |     1.6
   21 |   1.2020 |     37.435 |   1.2515 |     37.868 |     1.7
   22 |   1.1824 |     36.449 |   1.2452 |     37.531 |     1.8
   23 |   1.1693 |     36.785 |   1.2625 |     38.021 |     1.8
   24 |   1.1534 |     36.254 |   1.2337 |     37.163 |     1.9
   25 |   1.1406 |     35.994 |   1.2277 |     37.408 |     2.0
   26 |   1.1366 |     35.804 |   1.2154 |     36.397 |     2.1
   27 |   1.1206 |     35.105 |   1.2074 |     36.703 |     2.1
   28 |   1.1111 |     34.964 |   1.2205 |     37.132 |     2.2
   29 |   1.0915 |     34.547 |   1.2155 |     37.286 |     2.3
   30 |   1.0848 |     34.027 |   1.2162 |     36.887 |     2.4
   31 |   1.0809 |     34.011 |   1.2110 |     36.887 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 295,330

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6618 |     64.169 |   2.1104 |     48.100 |     0.1
    2 |   1.8472 |     46.099 |   1.6397 |     44.148 |     0.2
    3 |   1.5527 |     43.444 |   1.4765 |     42.065 |     0.2
    4 |   1.4243 |     41.515 |   1.3799 |     40.656 |     0.3
    5 |   1.3375 |     39.868 |   1.3195 |     39.461 |     0.4
    6 |   1.2720 |     38.665 |   1.2648 |     38.358 |     0.5
    7 |   1.2165 |     37.478 |   1.2311 |     37.071 |     0.6
    8 |   1.1747 |     36.021 |   1.1996 |     35.846 |     0.6
    9 |   1.1298 |     34.785 |   1.1760 |     35.815 |     0.7
   10 |   1.0941 |     33.751 |   1.1507 |     34.835 |     0.8
   11 |   1.0571 |     32.667 |   1.1330 |     34.375 |     0.9
   12 |   1.0261 |     31.778 |   1.1043 |     33.609 |     1.0
   13 |   0.9883 |     30.689 |   1.0856 |     33.425 |     1.1
   14 |   0.9614 |     29.801 |   1.0620 |     32.721 |     1.1
   15 |   0.9315 |     28.717 |   1.0656 |     34.406 |     1.2
   16 |   0.9054 |     28.078 |   1.0358 |     32.169 |     1.3
   17 |   0.8806 |     27.324 |   1.0188 |     31.710 |     1.4
   18 |   0.8606 |     26.766 |   1.0028 |     30.576 |     1.5
   19 |   0.8346 |     26.154 |   0.9910 |     31.281 |     1.6
   20 |   0.8104 |     25.401 |   0.9796 |     30.607 |     1.6
   21 |   0.7890 |     24.870 |   0.9582 |     29.565 |     1.7
   22 |   0.7696 |     24.214 |   0.9687 |     30.208 |     1.8
   23 |   0.7501 |     23.624 |   0.9680 |     30.270 |     1.9
   24 |   0.7345 |     23.293 |   0.9501 |     29.197 |     2.0
   25 |   0.7164 |     22.583 |   0.9445 |     29.933 |     2.0
   26 |   0.6944 |     21.895 |   0.9203 |     28.094 |     2.1
   27 |   0.6785 |     21.164 |   0.9368 |     29.779 |     2.2
   28 |   0.6663 |     20.844 |   0.9340 |     28.523 |     2.3
   29 |   0.6452 |     20.172 |   0.9252 |     28.186 |     2.4
   30 |   0.6365 |     19.934 |   0.9240 |     28.615 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,472,162

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4993 |     46.045 |   1.2251 |     39.645 |     0.2
    2 |   1.1497 |     38.161 |   1.1036 |     36.121 |     0.3
    3 |   1.0433 |     34.943 |   1.0089 |     32.935 |     0.5
    4 |   0.9653 |     32.564 |   0.9922 |     33.333 |     0.7
    5 |   0.9069 |     31.090 |   0.9300 |     30.423 |     0.8
    6 |   0.8604 |     29.286 |   0.8933 |     29.626 |     1.0
    7 |   0.8174 |     28.023 |   0.9180 |     30.852 |     1.2
    8 |   0.7842 |     26.864 |   0.8418 |     27.237 |     1.3
    9 |   0.7383 |     25.450 |   0.8573 |     28.707 |     1.5
   10 |   0.7104 |     24.393 |   0.8332 |     28.094 |     1.7
   11 |   0.6648 |     22.632 |   0.8260 |     26.654 |     1.8
   12 |   0.6445 |     22.123 |   0.8643 |     28.523 |     2.0
   13 |   0.6435 |     22.248 |   0.8013 |     26.348 |     2.2
   14 |   0.5979 |     20.725 |   0.7987 |     25.521 |     2.3
   15 |   0.5710 |     20.048 |   0.7954 |     25.337 |     2.5
   16 |   0.5433 |     18.894 |   0.7780 |     25.368 |     2.7
   17 |   0.5287 |     18.211 |   0.7972 |     25.797 |     2.8
   18 |   0.5110 |     17.940 |   0.8271 |     25.980 |     3.0
   19 |   0.5074 |     17.458 |   0.8104 |     24.816 |     3.1
   20 |   0.4907 |     17.008 |   0.7967 |     24.877 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 910,114

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5482 |     46.614 |   1.2405 |     39.614 |     0.1
    2 |   1.2534 |     41.591 |   1.1670 |     38.572 |     0.2
    3 |   1.1728 |     39.055 |   1.1145 |     36.305 |     0.4
    4 |   1.1278 |     37.803 |   1.0573 |     35.325 |     0.5
    5 |   1.0820 |     36.064 |   1.0361 |     34.712 |     0.6
    6 |   1.0492 |     35.463 |   1.0013 |     34.161 |     0.7
    7 |   0.9960 |     33.512 |   0.9900 |     32.629 |     0.8
    8 |   0.9677 |     32.954 |   0.9633 |     32.475 |     1.0
    9 |   0.9453 |     32.006 |   0.9498 |     31.250 |     1.1
   10 |   0.9058 |     30.456 |   0.9558 |     32.598 |     1.2
   11 |   0.8736 |     29.833 |   0.9079 |     30.699 |     1.3
   12 |   0.8415 |     28.798 |   0.8775 |     29.596 |     1.4
   13 |   0.8351 |     28.408 |   0.8824 |     30.025 |     1.6
   14 |   0.8146 |     28.099 |   0.8701 |     29.105 |     1.7
   15 |   0.7745 |     26.793 |   0.8895 |     30.116 |     1.8
   16 |   0.7577 |     26.143 |   0.8443 |     28.462 |     1.9
   17 |   0.7492 |     25.981 |   0.8409 |     28.094 |     2.0
   18 |   0.7313 |     25.141 |   0.8329 |     27.635 |     2.2
   19 |   0.7090 |     24.274 |   0.8440 |     27.941 |     2.3
   20 |   0.6862 |     23.607 |   0.8322 |     26.838 |     2.4
   21 |   0.6695 |     22.952 |   0.7871 |     25.674 |     2.5
   22 |   0.6436 |     22.340 |   0.8234 |     26.930 |     2.7
   23 |   0.6372 |     21.987 |   0.8299 |     26.379 |     2.8
   24 |   0.6271 |     21.836 |   0.8161 |     26.930 |     2.9
   25 |   0.6090 |     21.012 |   0.8157 |     25.888 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 337,314

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6513 |     47.237 |   1.2748 |     40.839 |     0.1
    2 |   1.1932 |     38.779 |   1.1210 |     36.029 |     0.3
    3 |   1.0586 |     34.769 |   1.0397 |     34.161 |     0.4
    4 |   0.9704 |     32.060 |   0.9569 |     31.648 |     0.5
    5 |   0.9003 |     29.974 |   0.9335 |     30.699 |     0.6
    6 |   0.8429 |     28.067 |   0.8779 |     29.657 |     0.8
    7 |   0.7922 |     26.555 |   0.8757 |     28.922 |     0.9
    8 |   0.7454 |     25.114 |   0.8595 |     27.543 |     1.0
    9 |   0.7040 |     23.759 |   0.8347 |     26.930 |     1.1
   10 |   0.6651 |     22.361 |   0.8105 |     26.409 |     1.2
   11 |   0.6347 |     21.565 |   0.8003 |     24.755 |     1.4
   12 |   0.5976 |     20.627 |   0.7938 |     26.072 |     1.5
   13 |   0.5725 |     19.175 |   0.8148 |     24.602 |     1.6
   14 |   0.5617 |     19.154 |   0.7943 |     25.000 |     1.8
   15 |   0.5492 |     18.921 |   0.7945 |     24.418 |     1.9
   16 |   0.5207 |     17.821 |   0.7840 |     24.479 |     2.0
   17 |   0.5095 |     17.604 |   0.7556 |     23.284 |     2.1
   18 |   0.4733 |     16.499 |   0.7704 |     23.438 |     2.3
   19 |   0.4593 |     15.876 |   0.7583 |     23.162 |     2.4
   20 |   0.4432 |     15.280 |   0.7794 |     23.744 |     2.5
   21 |   0.4396 |     15.122 |   0.7972 |     23.744 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 226,882

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8732 |     49.816 |   1.4050 |     43.444 |     0.1
    2 |   1.3657 |     43.173 |   1.2774 |     41.636 |     0.2
    3 |   1.2633 |     41.206 |   1.2008 |     39.062 |     0.3
    4 |   1.1873 |     39.185 |   1.1364 |     36.642 |     0.4
    5 |   1.1344 |     37.554 |   1.1051 |     36.397 |     0.5
    6 |   1.0866 |     36.292 |   1.0387 |     34.283 |     0.7
    7 |   1.0448 |     34.850 |   0.9967 |     33.150 |     0.8
    8 |   1.0060 |     33.561 |   0.9847 |     32.077 |     0.9
    9 |   0.9733 |     32.493 |   0.9534 |     31.648 |     1.0
   10 |   0.9426 |     31.724 |   0.9313 |     31.219 |     1.1
   11 |   0.9152 |     30.705 |   0.9231 |     31.373 |     1.2
   12 |   0.8882 |     30.321 |   0.9048 |     30.484 |     1.3
   13 |   0.8597 |     28.999 |   0.8913 |     29.596 |     1.4
   14 |   0.8448 |     28.885 |   0.8618 |     28.554 |     1.6
   15 |   0.8129 |     27.520 |   0.8430 |     27.727 |     1.7
   16 |   0.7907 |     26.934 |   0.8554 |     28.278 |     1.8
   17 |   0.7720 |     26.452 |   0.8619 |     28.646 |     1.9
   18 |   0.7603 |     25.899 |   0.8373 |     27.941 |     2.0
   19 |   0.7515 |     25.634 |   0.8235 |     27.022 |     2.1
   20 |   0.7235 |     24.453 |   0.8366 |     26.930 |     2.2
   21 |   0.6980 |     24.231 |   0.8279 |     26.991 |     2.3
   22 |   0.6814 |     23.423 |   0.8533 |     26.961 |     2.4
   23 |   0.6675 |     22.914 |   0.8033 |     26.532 |     2.5
   24 |   0.6553 |     22.546 |   0.8135 |     26.287 |     2.7
   25 |   0.6376 |     21.798 |   0.8022 |     25.674 |     2.8
   26 |   0.6308 |     21.641 |   0.8274 |     27.022 |     2.9
   27 |   0.6060 |     21.066 |   0.8053 |     25.306 |     3.0
   28 |   0.5993 |     20.275 |   0.8163 |     26.164 |     3.1
   29 |   0.5909 |     20.633 |   0.8148 |     25.245 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 139,522

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1199 |     54.692 |   1.4739 |     45.711 |     0.1
    2 |   1.4508 |     45.519 |   1.3387 |     42.739 |     0.2
    3 |   1.3484 |     44.099 |   1.2625 |     40.043 |     0.3
    4 |   1.2772 |     41.482 |   1.2320 |     39.614 |     0.4
    5 |   1.2287 |     40.502 |   1.1733 |     37.745 |     0.5
    6 |   1.1886 |     39.261 |   1.1529 |     36.550 |     0.6
    7 |   1.1547 |     38.356 |   1.1565 |     37.286 |     0.7
    8 |   1.1282 |     37.673 |   1.1262 |     36.765 |     0.8
    9 |   1.0867 |     36.156 |   1.1139 |     35.386 |     0.9
   10 |   1.0657 |     35.446 |   1.1025 |     35.325 |     1.0
   11 |   1.0442 |     34.471 |   1.0927 |     35.141 |     1.1
   12 |   1.0178 |     33.561 |   1.0515 |     33.854 |     1.2
   13 |   0.9924 |     33.247 |   1.0666 |     34.069 |     1.3
   14 |   0.9767 |     32.613 |   1.0445 |     32.782 |     1.4
   15 |   0.9559 |     32.044 |   1.0275 |     33.272 |     1.5
   16 |   0.9371 |     30.998 |   1.0337 |     31.985 |     1.6
   17 |   0.9189 |     30.944 |   1.0520 |     33.670 |     1.7
   18 |   0.9052 |     30.272 |   1.0214 |     32.629 |     1.8
   19 |   0.8864 |     29.931 |   1.0413 |     32.966 |     1.9
   20 |   0.8711 |     29.221 |   1.0156 |     32.996 |     2.0
   21 |   0.8629 |     29.015 |   1.0161 |     31.648 |     2.1
   22 |   0.8460 |     28.479 |   1.0279 |     32.445 |     2.2
   23 |   0.8395 |     28.435 |   1.0397 |     33.027 |     2.3
   24 |   0.8162 |     27.438 |   1.0448 |     32.537 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 155,938

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9726 |     77.324 |   2.5942 |     58.762 |     0.1
    2 |   2.3851 |     53.814 |   2.0078 |     45.466 |     0.2
    3 |   1.9891 |     47.085 |   1.7669 |     45.588 |     0.4
    4 |   1.7886 |     45.866 |   1.6378 |     44.853 |     0.5
    5 |   1.6721 |     44.809 |   1.5526 |     42.831 |     0.6
    6 |   1.5882 |     43.953 |   1.4865 |     42.218 |     0.7
    7 |   1.5196 |     42.891 |   1.4361 |     41.268 |     0.9
    8 |   1.4668 |     42.208 |   1.3898 |     40.901 |     1.0
    9 |   1.4219 |     41.450 |   1.3560 |     39.737 |     1.1
   10 |   1.3862 |     40.843 |   1.3236 |     38.572 |     1.2
   11 |   1.3461 |     40.122 |   1.2951 |     38.174 |     1.4
   12 |   1.3152 |     39.548 |   1.2755 |     37.868 |     1.5
   13 |   1.2888 |     38.822 |   1.2470 |     37.255 |     1.6
   14 |   1.2633 |     38.475 |   1.2338 |     36.979 |     1.7
   15 |   1.2342 |     37.733 |   1.2142 |     36.734 |     1.8
   16 |   1.2207 |     37.354 |   1.2030 |     37.316 |     1.9
   17 |   1.1941 |     36.606 |   1.1893 |     36.550 |     2.1
   18 |   1.1737 |     35.967 |   1.1874 |     36.612 |     2.2
   19 |   1.1566 |     35.652 |   1.1697 |     36.183 |     2.3
   20 |   1.1389 |     35.089 |   1.1447 |     35.202 |     2.4
   21 |   1.1236 |     34.704 |   1.1341 |     35.631 |     2.6
   22 |   1.0979 |     33.967 |   1.1378 |     35.141 |     2.7
   23 |   1.0839 |     33.512 |   1.1243 |     35.233 |     2.8
   24 |   1.0785 |     33.268 |   1.1123 |     34.988 |     2.9
   25 |   1.0522 |     32.651 |   1.0984 |     34.712 |     3.0
   26 |   1.0434 |     32.033 |   1.1090 |     34.589 |     3.2
   27 |   1.0313 |     31.973 |   1.0941 |     34.498 |     3.3
   28 |   1.0167 |     31.659 |   1.0849 |     33.425 |     3.4
   29 |   1.0013 |     31.166 |   1.0822 |     33.977 |     3.5
   30 |   0.9944 |     30.684 |   1.0832 |     33.885 |     3.7
   31 |   0.9855 |     30.657 |   1.0754 |     33.578 |     3.8
   32 |   0.9683 |     30.337 |   1.0736 |     33.670 |     3.9
   33 |   0.9586 |     29.860 |   1.0729 |     33.487 |     4.0
   34 |   0.9485 |     29.643 |   1.0688 |     33.670 |     4.1
   35 |   0.9329 |     29.080 |   1.0665 |     33.425 |     4.3
   36 |   0.9265 |     28.966 |   1.0641 |     32.782 |     4.4
   37 |   0.9230 |     28.977 |   1.0453 |     32.629 |     4.5
   38 |   0.9114 |     28.581 |   1.0625 |     33.241 |     4.6
   39 |   0.9010 |     28.164 |   1.0623 |     33.058 |     4.8
   40 |   0.8915 |     28.056 |   1.0518 |     32.567 |     4.9
   41 |   0.8800 |     27.509 |   1.0522 |     32.812 |     5.0
   42 |   0.8770 |     27.590 |   1.0405 |     32.475 |     5.1
   43 |   0.8629 |     27.227 |   1.0554 |     32.690 |     5.2
   44 |   0.8600 |     27.173 |   1.0372 |     32.169 |     5.4
   45 |   0.8496 |     26.490 |   1.0314 |     32.077 |     5.5
   46 |   0.8470 |     26.588 |   1.0405 |     31.648 |     5.6
   47 |   0.8448 |     26.452 |   1.0526 |     32.016 |     5.7
   48 |   0.8345 |     26.387 |   1.0370 |     31.618 |     5.9
   49 |   0.8242 |     26.029 |   1.0376 |     31.679 |     6.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 126,690

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1095 |     53.132 |   1.4501 |     45.098 |     0.1
    2 |   1.4353 |     44.820 |   1.3135 |     42.065 |     0.3
    3 |   1.3245 |     42.945 |   1.2450 |     40.257 |     0.4
    4 |   1.2559 |     41.336 |   1.1890 |     38.787 |     0.6
    5 |   1.2071 |     39.873 |   1.1454 |     38.143 |     0.7
    6 |   1.1505 |     37.868 |   1.1272 |     36.979 |     0.8
    7 |   1.1334 |     37.473 |   1.1129 |     36.826 |     1.0
    8 |   1.0884 |     36.275 |   1.0812 |     35.080 |     1.1
    9 |   1.0675 |     35.604 |   1.0632 |     34.620 |     1.3
   10 |   1.0365 |     34.536 |   1.0848 |     35.570 |     1.4
   11 |   1.0160 |     33.555 |   1.0510 |     34.314 |     1.6
   12 |   0.9911 |     33.052 |   1.0479 |     34.007 |     1.7
   13 |   0.9720 |     32.461 |   1.0350 |     33.609 |     1.8
   14 |   0.9422 |     31.491 |   1.0394 |     33.395 |     2.0
   15 |   0.9188 |     30.944 |   1.0416 |     33.058 |     2.1
   16 |   0.9057 |     30.245 |   1.0375 |     33.241 |     2.3
   17 |   0.8859 |     30.012 |   1.0242 |     32.812 |     2.4
   18 |   0.8651 |     29.243 |   1.0524 |     33.088 |     2.5
   19 |   0.8660 |     29.096 |   1.0219 |     32.200 |     2.7
   20 |   0.8423 |     28.863 |   1.0367 |     32.353 |     2.8
   21 |   0.8232 |     27.687 |   1.0444 |     32.751 |     3.0
   22 |   0.8091 |     27.698 |   1.0271 |     31.893 |     3.1
   23 |   0.7894 |     27.221 |   1.0373 |     31.955 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 502,690

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6367 |     47.757 |   1.2954 |     43.168 |     0.1
    2 |   1.1867 |     39.028 |   1.1381 |     38.235 |     0.2
    3 |   1.0609 |     34.590 |   0.9955 |     31.985 |     0.2
    4 |   0.9611 |     31.908 |   0.9611 |     32.598 |     0.3
    5 |   0.8975 |     29.817 |   0.9112 |     29.933 |     0.4
    6 |   0.8166 |     27.249 |   0.9185 |     29.779 |     0.5
    7 |   0.7692 |     25.694 |   0.8163 |     27.267 |     0.6
    8 |   0.7170 |     24.420 |   0.8352 |     27.145 |     0.6
    9 |   0.6581 |     22.123 |   0.8020 |     25.827 |     0.7
   10 |   0.6384 |     21.630 |   0.7786 |     25.245 |     0.8
   11 |   0.5892 |     20.048 |   0.7699 |     24.755 |     0.9
   12 |   0.5746 |     19.717 |   0.7493 |     24.540 |     1.0
   13 |   0.5278 |     17.929 |   0.7588 |     23.989 |     1.0
   14 |   0.5118 |     17.620 |   0.7677 |     23.254 |     1.1
   15 |   0.4761 |     16.547 |   0.7416 |     24.020 |     1.2
   16 |   0.4522 |     15.778 |   0.7778 |     24.142 |     1.3
   17 |   0.4365 |     15.626 |   0.7522 |     22.059 |     1.4
   18 |   0.3987 |     13.876 |   0.7489 |     22.151 |     1.4
   19 |   0.3876 |     13.779 |   0.7593 |     22.426 |     1.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3420 |     59.948 |   1.5395 |     43.566 |     0.1
    2 |   1.5161 |     44.370 |   1.3445 |     41.728 |     0.3
    3 |   1.3679 |     41.873 |   1.2546 |     39.062 |     0.4
    4 |   1.2810 |     39.868 |   1.1867 |     36.183 |     0.5
    5 |   1.2089 |     37.831 |   1.1360 |     35.570 |     0.7
    6 |   1.1486 |     35.988 |   1.0965 |     34.559 |     0.8
    7 |   1.0948 |     34.227 |   1.0757 |     34.314 |     0.9
    8 |   1.0497 |     33.133 |   1.0393 |     33.027 |     1.1
    9 |   1.0102 |     31.946 |   1.0001 |     31.893 |     1.2
   10 |   0.9681 |     30.472 |   0.9859 |     31.036 |     1.3
   11 |   0.9354 |     29.833 |   0.9640 |     30.607 |     1.5
   12 |   0.8946 |     28.560 |   0.9395 |     30.362 |     1.6
   13 |   0.8610 |     27.205 |   0.9375 |     30.729 |     1.7
   14 |   0.8326 |     26.376 |   0.9277 |     29.136 |     1.9
   15 |   0.8029 |     25.731 |   0.9121 |     29.412 |     2.0
   16 |   0.7733 |     24.837 |   0.9071 |     28.370 |     2.1
   17 |   0.7475 |     23.922 |   0.9050 |     27.574 |     2.3
   18 |   0.7322 |     23.196 |   0.9000 |     28.033 |     2.4
   19 |   0.7100 |     22.518 |   0.8743 |     27.328 |     2.5
   20 |   0.6812 |     21.928 |   0.8853 |     27.359 |     2.7
   21 |   0.6640 |     21.408 |   0.8881 |     27.206 |     2.8
   22 |   0.6414 |     20.660 |   0.8701 |     26.042 |     2.9
   23 |   0.6252 |     20.270 |   0.8597 |     25.980 |     3.1
   24 |   0.6070 |     19.658 |   0.8805 |     25.521 |     3.2
   25 |   0.5874 |     18.877 |   0.8709 |     25.919 |     3.3
   26 |   0.5737 |     18.395 |   0.8789 |     26.317 |     3.5
   27 |   0.5623 |     18.639 |   0.8614 |     24.877 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,009,698

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1327 |     51.918 |   1.5249 |     45.037 |     0.1
    2 |   1.4816 |     44.132 |   1.3287 |     41.360 |     0.3
    3 |   1.3376 |     41.266 |   1.2299 |     38.205 |     0.4
    4 |   1.2488 |     38.985 |   1.1738 |     36.244 |     0.6
    5 |   1.1812 |     37.397 |   1.1323 |     35.417 |     0.7
    6 |   1.1239 |     35.604 |   1.0865 |     34.436 |     0.9
    7 |   1.0714 |     33.864 |   1.0535 |     33.548 |     1.0
    8 |   1.0200 |     32.412 |   1.0330 |     32.996 |     1.1
    9 |   0.9775 |     31.204 |   1.0121 |     31.893 |     1.3
   10 |   0.9464 |     30.023 |   0.9881 |     31.434 |     1.4
   11 |   0.9014 |     28.722 |   0.9826 |     31.219 |     1.6
   12 |   0.8679 |     27.769 |   0.9574 |     29.933 |     1.7
   13 |   0.8379 |     26.864 |   0.9414 |     30.086 |     1.9
   14 |   0.8076 |     25.531 |   0.9390 |     29.688 |     2.0
   15 |   0.7806 |     25.331 |   0.9309 |     29.534 |     2.2
   16 |   0.7535 |     23.662 |   0.9361 |     28.799 |     2.3
   17 |   0.7266 |     23.364 |   0.9146 |     27.788 |     2.4
   18 |   0.7185 |     23.066 |   0.9276 |     28.278 |     2.6
   19 |   0.6864 |     21.884 |   0.9111 |     28.523 |     2.7
   20 |   0.6762 |     21.776 |   0.9168 |     27.849 |     2.9
   21 |   0.6430 |     20.622 |   0.8975 |     27.512 |     3.0
   22 |   0.6333 |     20.606 |   0.9078 |     27.696 |     3.2
   23 |   0.6011 |     19.468 |   0.9291 |     27.788 |     3.3
   24 |   0.5922 |     19.197 |   0.9083 |     27.114 |     3.4
   25 |   0.5806 |     18.655 |   0.9140 |     26.930 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 379,298

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6358 |     64.602 |   1.9179 |     46.415 |     0.1
    2 |   1.6943 |     44.625 |   1.5448 |     42.831 |     0.2
    3 |   1.4772 |     41.743 |   1.4098 |     41.759 |     0.3
    4 |   1.3616 |     39.835 |   1.3251 |     38.695 |     0.4
    5 |   1.2811 |     38.161 |   1.2659 |     37.316 |     0.5
    6 |   1.2187 |     36.893 |   1.2116 |     36.275 |     0.6
    7 |   1.1603 |     35.609 |   1.1656 |     34.222 |     0.7
    8 |   1.1133 |     34.184 |   1.1290 |     34.007 |     0.7
    9 |   1.0663 |     32.932 |   1.0997 |     33.364 |     0.8
   10 |   1.0304 |     31.654 |   1.0759 |     33.303 |     0.9
   11 |   0.9940 |     30.570 |   1.0545 |     32.629 |     1.0
   12 |   0.9579 |     29.210 |   1.0432 |     32.384 |     1.1
   13 |   0.9271 |     28.571 |   1.0120 |     31.373 |     1.2
   14 |   0.8948 |     27.097 |   0.9993 |     31.924 |     1.3
   15 |   0.8685 |     26.647 |   0.9931 |     31.250 |     1.4
   16 |   0.8448 |     26.051 |   0.9729 |     29.871 |     1.5
   17 |   0.8204 |     25.309 |   0.9449 |     29.718 |     1.6
   18 |   0.7928 |     24.323 |   0.9468 |     29.718 |     1.7
   19 |   0.7644 |     23.743 |   0.9510 |     30.086 |     1.8
   20 |   0.7446 |     22.887 |   0.9280 |     28.615 |     1.9
   21 |   0.7266 |     22.470 |   0.9247 |     28.830 |     2.0
   22 |   0.7041 |     22.009 |   0.9206 |     29.626 |     2.1
   23 |   0.6881 |     21.272 |   0.9061 |     28.125 |     2.2
   24 |   0.6730 |     20.888 |   0.8922 |     28.094 |     2.2
   25 |   0.6478 |     20.064 |   0.9051 |     27.880 |     2.3
   26 |   0.6316 |     19.685 |   0.8984 |     28.401 |     2.4
   27 |   0.6190 |     19.381 |   0.8903 |     26.869 |     2.5
   28 |   0.6020 |     18.693 |   0.8810 |     27.298 |     2.6
   29 |   0.5897 |     18.081 |   0.8910 |     27.482 |     2.7
   30 |   0.5724 |     17.815 |   0.8974 |     27.328 |     2.8
   31 |   0.5583 |     17.322 |   0.8857 |     26.011 |     2.9
   32 |   0.5547 |     17.176 |   0.8855 |     27.083 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 135,266

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9495 |     51.858 |   1.4461 |     43.260 |     0.1
    2 |   1.3196 |     40.794 |   1.2630 |     39.706 |     0.1
    3 |   1.1824 |     37.852 |   1.1307 |     36.887 |     0.2
    4 |   1.0653 |     34.525 |   1.0519 |     34.406 |     0.3
    5 |   0.9934 |     32.596 |   1.0032 |     32.629 |     0.4
    6 |   0.9236 |     30.299 |   0.9652 |     31.893 |     0.4
    7 |   0.8685 |     28.587 |   0.9433 |     31.066 |     0.5
    8 |   0.8304 |     27.590 |   0.9102 |     30.453 |     0.6
    9 |   0.7835 |     25.699 |   0.8879 |     28.309 |     0.6
   10 |   0.7510 |     24.978 |   0.8540 |     27.482 |     0.7
   11 |   0.7072 |     23.369 |   0.8688 |     27.451 |     0.8
   12 |   0.6828 |     22.529 |   0.8481 |     27.788 |     0.8
   13 |   0.6568 |     21.619 |   0.8379 |     27.175 |     0.9
   14 |   0.6402 |     21.283 |   0.8385 |     27.206 |     1.0
   15 |   0.6091 |     20.362 |   0.8207 |     26.685 |     1.1
   16 |   0.5837 |     19.506 |   0.8172 |     25.766 |     1.1
   17 |   0.5763 |     19.425 |   0.8000 |     25.888 |     1.2
   18 |   0.5489 |     18.617 |   0.8091 |     25.735 |     1.3
   19 |   0.5217 |     17.848 |   0.7919 |     25.000 |     1.3
   20 |   0.5164 |     17.674 |   0.8067 |     25.123 |     1.4
   21 |   0.5047 |     17.317 |   0.7981 |     24.602 |     1.5
   22 |   0.4872 |     16.775 |   0.8318 |     26.532 |     1.5
   23 |   0.4845 |     16.992 |   0.8090 |     25.521 |     1.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 152,354

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1067 |     53.874 |   1.4834 |     45.282 |     0.1
    2 |   1.4248 |     44.365 |   1.3124 |     42.616 |     0.3
    3 |   1.3049 |     42.371 |   1.2294 |     39.491 |     0.5
    4 |   1.2389 |     40.426 |   1.1727 |     38.266 |     0.6
    5 |   1.1833 |     38.790 |   1.1345 |     37.224 |     0.8
    6 |   1.1337 |     37.598 |   1.0783 |     34.926 |     0.9
    7 |   1.0960 |     36.248 |   1.0445 |     34.191 |     1.1
    8 |   1.0535 |     34.850 |   1.0146 |     33.272 |     1.2
    9 |   1.0236 |     34.049 |   1.0007 |     33.241 |     1.4
   10 |   0.9968 |     32.932 |   0.9627 |     31.801 |     1.5
   11 |   0.9640 |     32.369 |   0.9436 |     32.047 |     1.7
   12 |   0.9408 |     31.410 |   0.9348 |     30.760 |     1.8
   13 |   0.9100 |     30.250 |   0.9097 |     30.453 |     2.0
   14 |   0.8853 |     29.627 |   0.9045 |     30.423 |     2.1
   15 |   0.8646 |     28.945 |   0.8846 |     30.086 |     2.3
   16 |   0.8431 |     28.094 |   0.8863 |     29.442 |     2.4
   17 |   0.8265 |     27.525 |   0.8744 |     28.891 |     2.6
   18 |   0.8170 |     27.693 |   0.8448 |     28.094 |     2.7
   19 |   0.7836 |     26.127 |   0.8557 |     28.094 |     2.9
   20 |   0.7711 |     26.246 |   0.8494 |     27.727 |     3.0
   21 |   0.7484 |     25.352 |   0.8337 |     26.746 |     3.2
   22 |   0.7374 |     24.740 |   0.8305 |     27.482 |     3.3
   23 |   0.7240 |     24.350 |   0.8186 |     27.175 |     3.5
   24 |   0.7133 |     24.008 |   0.8243 |     27.175 |     3.6
   25 |   0.6963 |     23.656 |   0.8161 |     26.287 |     3.8
   26 |   0.6772 |     23.077 |   0.8176 |     26.409 |     3.9
   27 |   0.6734 |     22.925 |   0.8191 |     26.409 |     4.1
   28 |   0.6493 |     22.166 |   0.8042 |     25.705 |     4.2
   29 |   0.6468 |     21.971 |   0.7955 |     25.276 |     4.4
   30 |   0.6317 |     21.391 |   0.8081 |     25.613 |     4.6
   31 |   0.6264 |     21.413 |   0.8339 |     26.593 |     4.7
   32 |   0.6151 |     21.028 |   0.8149 |     26.440 |     4.9
   33 |   0.6112 |     20.779 |   0.8217 |     26.103 |     5.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 143,234

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.1501 |     81.681 |   2.7627 |     64.890 |     0.1
    2 |   2.6230 |     59.699 |   2.2905 |     49.265 |     0.1
    3 |   2.2308 |     49.399 |   1.9544 |     46.446 |     0.2
    4 |   1.9608 |     46.630 |   1.7715 |     45.251 |     0.3
    5 |   1.8024 |     45.790 |   1.6621 |     44.547 |     0.3
    6 |   1.6963 |     45.118 |   1.5818 |     44.210 |     0.4
    7 |   1.6128 |     44.701 |   1.5166 |     44.056 |     0.5
    8 |   1.5459 |     43.991 |   1.4645 |     43.168 |     0.5
    9 |   1.4943 |     43.216 |   1.4216 |     42.616 |     0.6
   10 |   1.4464 |     42.398 |   1.3804 |     41.299 |     0.7
   11 |   1.4065 |     41.575 |   1.3474 |     40.380 |     0.7
   12 |   1.3715 |     40.854 |   1.3190 |     39.062 |     0.8
   13 |   1.3369 |     40.177 |   1.2940 |     39.400 |     0.9
   14 |   1.3057 |     39.472 |   1.2682 |     38.480 |     0.9
   15 |   1.2834 |     38.990 |   1.2461 |     37.531 |     1.0
   16 |   1.2525 |     37.901 |   1.2282 |     36.979 |     1.1
   17 |   1.2322 |     37.440 |   1.2194 |     37.377 |     1.1
   18 |   1.2083 |     37.305 |   1.1935 |     36.857 |     1.2
   19 |   1.1866 |     36.557 |   1.1781 |     36.275 |     1.3
   20 |   1.1670 |     35.864 |   1.1665 |     35.539 |     1.3
   21 |   1.1512 |     35.430 |   1.1569 |     35.478 |     1.4
   22 |   1.1341 |     34.980 |   1.1415 |     35.294 |     1.5
   23 |   1.1179 |     34.742 |   1.1343 |     34.773 |     1.6
   24 |   1.1015 |     34.054 |   1.1326 |     35.172 |     1.6
   25 |   1.0864 |     33.458 |   1.1244 |     34.712 |     1.7
   26 |   1.0682 |     33.068 |   1.1200 |     34.283 |     1.8
   27 |   1.0597 |     32.786 |   1.1078 |     34.038 |     1.8
   28 |   1.0443 |     32.483 |   1.0999 |     33.946 |     1.9
   29 |   1.0308 |     32.185 |   1.0920 |     33.824 |     2.0
   30 |   1.0224 |     32.136 |   1.0802 |     33.425 |     2.0
   31 |   1.0122 |     31.556 |   1.0760 |     33.027 |     2.1
   32 |   0.9949 |     31.329 |   1.0858 |     34.069 |     2.2
   33 |   0.9851 |     30.879 |   1.0785 |     33.977 |     2.2
   34 |   0.9737 |     30.527 |   1.0589 |     33.241 |     2.3
   35 |   0.9630 |     30.407 |   1.0657 |     33.548 |     2.4
   36 |   0.9510 |     29.795 |   1.0553 |     32.966 |     2.4
   37 |   0.9373 |     29.394 |   1.0583 |     33.333 |     2.5
   38 |   0.9301 |     29.454 |   1.0477 |     32.935 |     2.6
   39 |   0.9226 |     29.161 |   1.0502 |     32.874 |     2.6
   40 |   0.9115 |     28.950 |   1.0364 |     32.261 |     2.7
   41 |   0.9021 |     28.479 |   1.0495 |     32.935 |     2.8
   42 |   0.8953 |     28.148 |   1.0312 |     32.016 |     2.8
   43 |   0.8872 |     28.164 |   1.0338 |     32.016 |     2.9
   44 |   0.8820 |     28.040 |   1.0410 |     32.138 |     3.0
   45 |   0.8696 |     27.633 |   1.0364 |     32.721 |     3.0
   46 |   0.8666 |     27.330 |   1.0245 |     31.985 |     3.1
   47 |   0.8523 |     27.108 |   1.0279 |     31.924 |     3.2
   48 |   0.8501 |     27.081 |   1.0310 |     32.567 |     3.2
   49 |   0.8437 |     26.750 |   1.0258 |     31.679 |     3.3
   50 |   0.8368 |     27.129 |   1.0152 |     32.016 |     3.4
   51 |   0.8263 |     26.398 |   1.0270 |     31.679 |     3.4
   52 |   0.8258 |     26.295 |   1.0192 |     31.373 |     3.5
   53 |   0.8181 |     25.916 |   1.0112 |     30.913 |     3.6
   54 |   0.8070 |     26.067 |   1.0160 |     31.036 |     3.6
   55 |   0.8008 |     25.488 |   1.0204 |     31.526 |     3.7
   56 |   0.8038 |     25.997 |   1.0142 |     31.679 |     3.8
   57 |   0.7887 |     25.255 |   1.0096 |     31.342 |     3.8
   58 |   0.7817 |     25.157 |   1.0213 |     30.882 |     3.9
   59 |   0.7741 |     25.000 |   1.0149 |     31.066 |     4.0
   60 |   0.7704 |     24.745 |   1.0070 |     31.158 |     4.0
   61 |   0.7688 |     24.691 |   1.0029 |     30.423 |     4.1
   62 |   0.7642 |     24.854 |   1.0112 |     30.453 |     4.2
   63 |   0.7623 |     24.615 |   1.0127 |     30.208 |     4.2
   64 |   0.7517 |     24.117 |   1.0032 |     30.086 |     4.3
   65 |   0.7514 |     24.263 |   1.0250 |     31.066 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 226,882

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8989 |     49.550 |   1.4246 |     42.616 |     0.1
    2 |   1.3275 |     41.797 |   1.2497 |     39.032 |     0.2
    3 |   1.1794 |     38.448 |   1.1264 |     37.163 |     0.3
    4 |   1.0781 |     35.663 |   1.0426 |     34.191 |     0.4
    5 |   1.0003 |     32.987 |   1.0127 |     33.241 |     0.5
    6 |   0.9354 |     31.144 |   0.9827 |     33.701 |     0.6
    7 |   0.8855 |     29.454 |   0.9277 |     31.005 |     0.7
    8 |   0.8366 |     28.018 |   0.8881 |     30.178 |     0.8
    9 |   0.7960 |     26.837 |   0.8803 |     29.596 |     0.9
   10 |   0.7646 |     26.225 |   0.8595 |     28.983 |     1.0
   11 |   0.7224 |     24.545 |   0.8623 |     28.339 |     1.1
   12 |   0.6941 |     23.456 |   0.8048 |     26.440 |     1.1
   13 |   0.6600 |     22.052 |   0.7949 |     26.348 |     1.2
   14 |   0.6300 |     21.283 |   0.8111 |     25.735 |     1.3
   15 |   0.6221 |     21.180 |   0.7976 |     24.724 |     1.4
   16 |   0.5887 |     19.853 |   0.7966 |     25.613 |     1.5
   17 |   0.5616 |     19.045 |   0.7918 |     25.735 |     1.6
   18 |   0.5493 |     18.845 |   0.7770 |     25.368 |     1.7
   19 |   0.5185 |     17.761 |   0.7837 |     24.969 |     1.8
   20 |   0.4972 |     17.376 |   0.8056 |     24.847 |     1.9
   21 |   0.4975 |     16.878 |   0.7907 |     24.387 |     2.0
   22 |   0.4674 |     16.016 |   0.7847 |     24.449 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,074,594

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3412 |     57.959 |   1.5655 |     43.995 |     0.1
    2 |   1.5749 |     44.630 |   1.3683 |     41.912 |     0.2
    3 |   1.4070 |     42.366 |   1.2717 |     38.971 |     0.4
    4 |   1.3172 |     40.735 |   1.2173 |     37.653 |     0.5
    5 |   1.2482 |     38.979 |   1.1695 |     36.734 |     0.6
    6 |   1.1952 |     37.505 |   1.1504 |     35.968 |     0.7
    7 |   1.1468 |     36.005 |   1.1176 |     35.049 |     0.8
    8 |   1.1074 |     34.899 |   1.0905 |     34.773 |     1.0
    9 |   1.0685 |     33.680 |   1.0825 |     34.252 |     1.1
   10 |   1.0356 |     32.943 |   1.0586 |     34.038 |     1.2
   11 |   1.0030 |     31.778 |   1.0480 |     33.854 |     1.3
   12 |   0.9671 |     30.841 |   1.0438 |     32.996 |     1.4
   13 |   0.9437 |     30.066 |   1.0306 |     32.384 |     1.6
   14 |   0.9194 |     29.400 |   1.0226 |     32.047 |     1.7
   15 |   0.8889 |     28.224 |   0.9871 |     30.729 |     1.8
   16 |   0.8668 |     27.314 |   1.0008 |     30.913 |     1.9
   17 |   0.8363 |     26.853 |   0.9948 |     30.944 |     2.0
   18 |   0.8143 |     26.268 |   0.9971 |     31.219 |     2.2
   19 |   0.7899 |     25.309 |   0.9784 |     30.699 |     2.3
   20 |   0.7702 |     24.675 |   0.9668 |     30.208 |     2.4
   21 |   0.7467 |     24.025 |   0.9777 |     30.055 |     2.5
   22 |   0.7292 |     23.488 |   0.9774 |     30.116 |     2.6
   23 |   0.7115 |     23.201 |   0.9808 |     29.994 |     2.8
   24 |   0.6976 |     22.578 |   0.9704 |     29.289 |     2.9
   25 |   0.6791 |     21.901 |   0.9637 |     28.707 |     3.0
   26 |   0.6592 |     21.440 |   0.9625 |     28.094 |     3.1
   27 |   0.6411 |     20.687 |   1.0038 |     29.320 |     3.3
   28 |   0.6315 |     20.519 |   0.9885 |     29.320 |     3.4
   29 |   0.6189 |     20.015 |   0.9794 |     28.554 |     3.5
   30 |   0.5980 |     19.479 |   0.9931 |     28.707 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1077 |     53.977 |   1.4568 |     43.229 |     0.2
    2 |   1.4488 |     43.563 |   1.3078 |     39.154 |     0.3
    3 |   1.3191 |     40.431 |   1.2174 |     37.408 |     0.5
    4 |   1.2309 |     38.313 |   1.1571 |     35.386 |     0.6
    5 |   1.1593 |     36.476 |   1.1113 |     34.007 |     0.8
    6 |   1.0958 |     34.477 |   1.0837 |     34.314 |     1.0
    7 |   1.0434 |     32.927 |   1.0501 |     32.904 |     1.1
    8 |   0.9940 |     31.264 |   1.0380 |     32.506 |     1.3
    9 |   0.9500 |     30.077 |   0.9874 |     31.342 |     1.4
   10 |   0.9021 |     28.581 |   0.9786 |     30.882 |     1.6
   11 |   0.8626 |     27.319 |   0.9454 |     29.933 |     1.8
   12 |   0.8255 |     25.921 |   0.9419 |     28.952 |     1.9
   13 |   0.7921 |     25.070 |   0.9225 |     28.891 |     2.1
   14 |   0.7574 |     24.041 |   0.9143 |     28.248 |     2.2
   15 |   0.7262 |     23.217 |   0.9352 |     29.197 |     2.4
   16 |   0.6913 |     22.318 |   0.9074 |     27.849 |     2.6
   17 |   0.6729 |     21.581 |   0.8933 |     26.930 |     2.7
   18 |   0.6541 |     20.801 |   0.9033 |     27.267 |     2.9
   19 |   0.6176 |     19.880 |   0.9025 |     26.348 |     3.0
   20 |   0.5987 |     19.354 |   0.9130 |     27.267 |     3.2
   21 |   0.5848 |     18.915 |   0.8918 |     26.195 |     3.4
   22 |   0.5627 |     17.972 |   0.8752 |     25.643 |     3.5
   23 |   0.5412 |     17.479 |   0.9197 |     26.716 |     3.7
   24 |   0.5283 |     17.106 |   0.8860 |     25.674 |     3.8
   25 |   0.5008 |     16.320 |   0.8987 |     25.582 |     4.0
   26 |   0.4940 |     16.206 |   0.9096 |     25.551 |     4.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 379,298

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6105 |     65.160 |   1.9642 |     44.608 |     0.1
    2 |   1.7119 |     43.812 |   1.5513 |     41.789 |     0.2
    3 |   1.4693 |     41.309 |   1.4131 |     40.074 |     0.3
    4 |   1.3632 |     39.803 |   1.3262 |     39.001 |     0.4
    5 |   1.2757 |     38.280 |   1.2693 |     39.216 |     0.5
    6 |   1.2127 |     36.763 |   1.2095 |     36.397 |     0.6
    7 |   1.1587 |     35.143 |   1.1724 |     36.060 |     0.7
    8 |   1.1069 |     33.512 |   1.1496 |     34.406 |     0.8
    9 |   1.0622 |     32.190 |   1.1098 |     33.640 |     0.8
   10 |   1.0139 |     30.846 |   1.0684 |     31.679 |     0.9
   11 |   0.9776 |     29.524 |   1.0434 |     31.403 |     1.0
   12 |   0.9447 |     28.565 |   1.0357 |     31.587 |     1.1
   13 |   0.9073 |     27.536 |   0.9991 |     30.668 |     1.2
   14 |   0.8716 |     26.550 |   0.9827 |     30.699 |     1.3
   15 |   0.8449 |     25.894 |   0.9736 |     30.086 |     1.4
   16 |   0.8212 |     24.924 |   0.9716 |     29.963 |     1.5
   17 |   0.7951 |     24.436 |   0.9362 |     28.983 |     1.6
   18 |   0.7658 |     23.440 |   0.9295 |     29.320 |     1.7
   19 |   0.7382 |     22.849 |   0.9359 |     29.534 |     1.8
   20 |   0.7180 |     22.285 |   0.9108 |     28.186 |     1.9
   21 |   0.6990 |     21.668 |   0.9085 |     28.186 |     2.0
   22 |   0.6801 |     21.240 |   0.9205 |     29.136 |     2.1
   23 |   0.6577 |     20.048 |   0.8708 |     27.083 |     2.2
   24 |   0.6387 |     19.717 |   0.8898 |     26.930 |     2.3
   25 |   0.6196 |     19.202 |   0.8787 |     27.237 |     2.4
   26 |   0.6075 |     18.877 |   0.9037 |     27.267 |     2.5
   27 |   0.5916 |     18.173 |   0.8795 |     26.685 |     2.6
   28 |   0.5741 |     17.615 |   0.8673 |     26.103 |     2.6
   29 |   0.5598 |     17.284 |   0.8873 |     26.961 |     2.7
   30 |   0.5514 |     17.268 |   0.8667 |     25.827 |     2.8
   31 |   0.5365 |     16.650 |   0.8888 |     26.287 |     2.9
   32 |   0.5233 |     16.423 |   0.8735 |     26.317 |     3.0
   33 |   0.5049 |     15.892 |   0.8806 |     26.042 |     3.1
   34 |   0.5005 |     15.670 |   0.8750 |     25.735 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,586

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2255 |     56.394 |   1.5138 |     44.271 |     0.2
    2 |   1.4908 |     44.213 |   1.3264 |     41.054 |     0.4
    3 |   1.3372 |     41.249 |   1.2300 |     36.949 |     0.6
    4 |   1.2375 |     38.324 |   1.1682 |     36.581 |     0.8
    5 |   1.1735 |     36.682 |   1.1092 |     34.957 |     1.0
    6 |   1.1132 |     34.953 |   1.0889 |     35.263 |     1.1
    7 |   1.0659 |     33.577 |   1.0507 |     33.364 |     1.3
    8 |   1.0185 |     32.076 |   1.0235 |     32.414 |     1.5
    9 |   0.9674 |     30.825 |   1.0152 |     31.863 |     1.7
   10 |   0.9303 |     29.584 |   0.9843 |     31.066 |     1.9
   11 |   0.8967 |     28.311 |   0.9870 |     31.127 |     2.1
   12 |   0.8719 |     27.845 |   0.9636 |     30.178 |     2.3
   13 |   0.8289 |     26.425 |   0.9492 |     30.055 |     2.5
   14 |   0.8032 |     25.721 |   0.9231 |     29.412 |     2.7
   15 |   0.7697 |     24.583 |   0.9126 |     28.615 |     2.9
   16 |   0.7398 |     23.564 |   0.9010 |     28.186 |     3.1
   17 |   0.7153 |     22.984 |   0.9114 |     27.849 |     3.3
   18 |   0.6916 |     21.782 |   0.8991 |     27.145 |     3.5
   19 |   0.6693 |     21.326 |   0.9100 |     28.309 |     3.7
   20 |   0.6493 |     20.920 |   0.8958 |     26.624 |     3.9
   21 |   0.6291 |     20.308 |   0.8720 |     26.471 |     4.1
   22 |   0.6065 |     19.387 |   0.9062 |     25.643 |     4.3
   23 |   0.5867 |     18.866 |   0.8962 |     26.685 |     4.4
   24 |   0.5784 |     18.330 |   0.8836 |     25.797 |     4.6
   25 |   0.5541 |     18.146 |   0.9098 |     26.379 |     4.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,586

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1130 |     54.069 |   1.4721 |     42.862 |     0.2
    2 |   1.3575 |     41.130 |   1.2802 |     38.082 |     0.4
    3 |   1.2137 |     37.267 |   1.1778 |     35.876 |     0.5
    4 |   1.1191 |     34.742 |   1.1273 |     35.110 |     0.7
    5 |   1.0349 |     31.941 |   1.0509 |     32.843 |     0.9
    6 |   0.9649 |     30.115 |   1.0116 |     31.495 |     1.1
    7 |   0.9021 |     28.181 |   0.9649 |     30.116 |     1.2
    8 |   0.8486 |     26.360 |   0.9505 |     29.412 |     1.4
    9 |   0.8002 |     24.653 |   0.9166 |     28.156 |     1.6
   10 |   0.7544 |     23.358 |   0.8846 |     27.420 |     1.8
   11 |   0.7127 |     22.334 |   0.8745 |     27.849 |     2.0
   12 |   0.6792 |     21.294 |   0.8699 |     26.348 |     2.1
   13 |   0.6330 |     19.593 |   0.8423 |     25.980 |     2.3
   14 |   0.5986 |     18.525 |   0.8607 |     26.808 |     2.5
   15 |   0.5818 |     18.498 |   0.8447 |     25.919 |     2.7
   16 |   0.5508 |     17.295 |   0.8017 |     24.755 |     2.9
   17 |   0.5140 |     16.130 |   0.8136 |     25.000 |     3.0
   18 |   0.4874 |     15.415 |   0.8126 |     24.632 |     3.2
   19 |   0.4713 |     14.765 |   0.8206 |     24.724 |     3.4
   20 |   0.4504 |     14.364 |   0.8105 |     24.540 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 139,522

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.0235 |     72.621 |   2.6968 |     55.729 |     0.1
    2 |   2.3902 |     48.938 |   2.1342 |     45.037 |     0.2
    3 |   2.0001 |     45.091 |   1.8714 |     43.474 |     0.3
    4 |   1.7946 |     44.029 |   1.7160 |     43.781 |     0.4
    5 |   1.6658 |     43.525 |   1.6100 |     43.229 |     0.5
    6 |   1.5668 |     42.691 |   1.5282 |     42.249 |     0.6
    7 |   1.4847 |     41.748 |   1.4744 |     42.034 |     0.7
    8 |   1.4181 |     40.285 |   1.4170 |     40.778 |     0.7
    9 |   1.3590 |     39.071 |   1.3659 |     39.583 |     0.8
   10 |   1.3109 |     37.998 |   1.3345 |     38.542 |     0.9
   11 |   1.2704 |     36.947 |   1.3093 |     37.990 |     1.0
   12 |   1.2261 |     36.070 |   1.2766 |     38.021 |     1.1
   13 |   1.1926 |     35.338 |   1.2463 |     37.531 |     1.2
   14 |   1.1621 |     34.027 |   1.2232 |     36.949 |     1.3
   15 |   1.1331 |     33.463 |   1.2014 |     36.244 |     1.4
   16 |   1.1029 |     32.591 |   1.1810 |     35.509 |     1.5
   17 |   1.0720 |     32.028 |   1.1711 |     35.110 |     1.6
   18 |   1.0523 |     31.377 |   1.1644 |     35.600 |     1.7
   19 |   1.0297 |     30.749 |   1.1346 |     34.773 |     1.8
   20 |   1.0034 |     30.120 |   1.1214 |     33.915 |     1.9
   21 |   0.9816 |     29.362 |   1.1185 |     33.885 |     2.0
   22 |   0.9631 |     29.080 |   1.1001 |     33.333 |     2.0
   23 |   0.9485 |     28.712 |   1.0858 |     32.751 |     2.1
   24 |   0.9272 |     28.078 |   1.0883 |     33.854 |     2.2
   25 |   0.9086 |     27.482 |   1.0675 |     32.629 |     2.3
   26 |   0.8915 |     26.886 |   1.0705 |     32.782 |     2.4
   27 |   0.8744 |     26.766 |   1.0508 |     32.721 |     2.5
   28 |   0.8627 |     26.355 |   1.0553 |     32.751 |     2.6
   29 |   0.8407 |     25.748 |   1.0423 |     31.955 |     2.7
   30 |   0.8277 |     25.466 |   1.0585 |     31.801 |     2.8
   31 |   0.8144 |     24.930 |   1.0359 |     31.158 |     2.9
   32 |   0.8062 |     24.778 |   1.0171 |     30.913 |     3.0
   33 |   0.7945 |     24.556 |   1.0219 |     31.219 |     3.1
   34 |   0.7798 |     24.079 |   1.0039 |     30.147 |     3.2
   35 |   0.7630 |     23.662 |   1.0162 |     29.933 |     3.3
   36 |   0.7554 |     23.331 |   1.0125 |     30.637 |     3.3
   37 |   0.7415 |     22.822 |   1.0058 |     30.545 |     3.4
   38 |   0.7294 |     22.394 |   1.0024 |     30.453 |     3.5
   39 |   0.7196 |     22.405 |   0.9979 |     30.208 |     3.6
   40 |   0.7089 |     22.009 |   0.9965 |     30.668 |     3.7
   41 |   0.7077 |     21.944 |   0.9870 |     30.515 |     3.8
   42 |   0.6905 |     21.278 |   1.0029 |     29.534 |     3.9
   43 |   0.6831 |     21.348 |   0.9988 |     30.147 |     4.0
   44 |   0.6768 |     21.251 |   0.9849 |     29.626 |     4.1
   45 |   0.6627 |     20.633 |   0.9947 |     29.626 |     4.2
   46 |   0.6570 |     20.470 |   1.0007 |     29.381 |     4.3
   47 |   0.6497 |     20.151 |   1.0030 |     29.871 |     4.4
   48 |   0.6396 |     19.966 |   0.9889 |     29.136 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 602,658

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7759 |     50.493 |   1.3405 |     43.964 |     0.2
    2 |   1.3376 |     43.731 |   1.2389 |     40.349 |     0.3
    3 |   1.2490 |     41.022 |   1.1854 |     39.124 |     0.5
    4 |   1.1871 |     39.532 |   1.1211 |     36.550 |     0.7
    5 |   1.1447 |     37.885 |   1.0974 |     36.642 |     0.9
    6 |   1.0891 |     36.573 |   1.0305 |     33.701 |     1.1
    7 |   1.0559 |     35.165 |   1.0299 |     34.252 |     1.2
    8 |   1.0212 |     34.487 |   0.9663 |     32.047 |     1.4
    9 |   0.9813 |     33.155 |   0.9865 |     33.241 |     1.6
   10 |   0.9512 |     31.719 |   0.9214 |     30.852 |     1.8
   11 |   0.9198 |     31.231 |   0.9254 |     31.648 |     1.9
   12 |   0.8911 |     30.072 |   0.9071 |     30.699 |     2.1
   13 |   0.8628 |     29.015 |   0.8845 |     30.270 |     2.3
   14 |   0.8416 |     28.581 |   0.8910 |     30.208 |     2.5
   15 |   0.8160 |     27.725 |   0.8904 |     30.576 |     2.6
   16 |   0.8044 |     27.417 |   0.8574 |     28.830 |     2.8
   17 |   0.7714 |     26.203 |   0.8651 |     29.075 |     3.0
   18 |   0.7587 |     26.187 |   0.8248 |     27.114 |     3.2
   19 |   0.7308 |     25.070 |   0.8360 |     28.125 |     3.3
   20 |   0.7169 |     24.431 |   0.8218 |     27.267 |     3.5
   21 |   0.6832 |     23.261 |   0.8421 |     27.604 |     3.7
   22 |   0.6950 |     23.797 |   0.7995 |     26.562 |     3.9
   23 |   0.6639 |     22.827 |   0.8053 |     26.011 |     4.0
   24 |   0.6275 |     21.619 |   0.7913 |     26.164 |     4.2
   25 |   0.6103 |     21.196 |   0.7986 |     25.827 |     4.4
   26 |   0.5957 |     20.530 |   0.8491 |     27.145 |     4.6
   27 |   0.5874 |     19.945 |   0.8184 |     26.501 |     4.7
   28 |   0.5737 |     20.075 |   0.7928 |     25.398 |     4.9
   29 |   0.5537 |     19.397 |   0.7832 |     25.061 |     5.1
   30 |   0.5310 |     18.628 |   0.8157 |     25.490 |     5.3
   31 |   0.5189 |     18.119 |   0.8458 |     26.317 |     5.4
   32 |   0.4894 |     17.078 |   0.8302 |     25.643 |     5.6
   33 |   0.5023 |     17.544 |   0.8247 |     25.061 |     5.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,074,594

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5565 |     47.015 |   1.2326 |     39.982 |     0.1
    2 |   1.2314 |     40.832 |   1.1367 |     37.102 |     0.2
    3 |   1.1660 |     38.936 |   1.1042 |     36.979 |     0.4
    4 |   1.1193 |     37.560 |   1.0635 |     35.692 |     0.5
    5 |   1.0718 |     36.021 |   1.0231 |     35.294 |     0.6
    6 |   1.0221 |     34.639 |   0.9906 |     33.027 |     0.7
    7 |   1.0050 |     33.940 |   0.9859 |     33.088 |     0.8
    8 |   0.9617 |     32.168 |   0.9323 |     31.771 |     1.0
    9 |   0.9279 |     31.079 |   0.9282 |     31.342 |     1.1
   10 |   0.8930 |     30.684 |   0.9260 |     32.077 |     1.2
   11 |   0.8627 |     29.427 |   0.8968 |     30.637 |     1.3
   12 |   0.8537 |     28.972 |   0.8968 |     29.841 |     1.5
   13 |   0.8276 |     28.164 |   0.9053 |     30.852 |     1.6
   14 |   0.8054 |     27.628 |   0.8852 |     29.044 |     1.7
   15 |   0.7637 |     25.959 |   0.9049 |     29.412 |     1.8
   16 |   0.7578 |     26.089 |   0.8613 |     28.830 |     1.9
   17 |   0.7440 |     25.699 |   0.8823 |     30.453 |     2.1
   18 |   0.7147 |     24.621 |   0.8816 |     29.442 |     2.2
   19 |   0.7060 |     24.355 |   0.8492 |     29.044 |     2.3
   20 |   0.6784 |     23.440 |   0.8632 |     28.278 |     2.4
   21 |   0.6676 |     23.104 |   0.8642 |     28.431 |     2.5
   22 |   0.6399 |     22.464 |   0.8607 |     28.707 |     2.7
   23 |   0.6290 |     21.928 |   0.8586 |     28.860 |     2.8
   24 |   0.6072 |     21.348 |   0.8359 |     27.145 |     2.9
   25 |   0.6105 |     20.898 |   0.8548 |     27.727 |     3.0
   26 |   0.5809 |     20.216 |   0.9018 |     28.646 |     3.1
   27 |   0.5768 |     19.733 |   0.9004 |     29.320 |     3.3
   28 |   0.5474 |     19.170 |   0.8767 |     27.298 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 977,314

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5887 |     47.275 |   1.2577 |     40.533 |     0.1
    2 |   1.2278 |     40.225 |   1.1301 |     36.918 |     0.3
    3 |   1.1370 |     37.868 |   1.0611 |     34.988 |     0.5
    4 |   1.0564 |     35.387 |   1.0278 |     34.375 |     0.6
    5 |   1.0064 |     33.962 |   0.9863 |     33.425 |     0.8
    6 |   0.9542 |     32.380 |   0.9371 |     31.710 |     0.9
    7 |   0.9081 |     30.678 |   0.9594 |     31.740 |     1.1
    8 |   0.8756 |     29.725 |   0.9192 |     31.036 |     1.2
    9 |   0.8357 |     28.479 |   0.9256 |     31.097 |     1.4
   10 |   0.8118 |     27.585 |   0.8683 |     28.922 |     1.5
   11 |   0.7918 |     27.135 |   0.8791 |     29.473 |     1.7
   12 |   0.7636 |     26.100 |   0.8869 |     28.952 |     1.8
   13 |   0.7428 |     25.303 |   0.8582 |     27.972 |     2.0
   14 |   0.7100 |     24.296 |   0.8868 |     29.259 |     2.1
   15 |   0.6976 |     24.160 |   0.8486 |     27.451 |     2.3
   16 |   0.6848 |     23.602 |   0.8486 |     27.206 |     2.5
   17 |   0.6594 |     22.871 |   0.8549 |     27.145 |     2.6
   18 |   0.6393 |     22.090 |   0.8801 |     27.941 |     2.8
   19 |   0.6255 |     21.928 |   0.8641 |     27.727 |     2.9
   20 |   0.6102 |     21.072 |   0.8441 |     27.114 |     3.1
   21 |   0.5950 |     20.644 |   0.8630 |     27.390 |     3.2
   22 |   0.5735 |     19.950 |   0.8496 |     27.022 |     3.4
   23 |   0.5749 |     20.243 |   0.8884 |     28.401 |     3.5
   24 |   0.5491 |     18.926 |   0.8929 |     28.064 |     3.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 152,354

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.2316 |     79.790 |   2.8147 |     64.522 |     0.2
    2 |   2.7686 |     63.324 |   2.3666 |     54.044 |     0.3
    3 |   2.3962 |     54.681 |   1.9915 |     46.998 |     0.5
    4 |   2.0908 |     49.556 |   1.7999 |     46.354 |     0.6
    5 |   1.8978 |     47.448 |   1.6952 |     46.201 |     0.8
    6 |   1.7726 |     46.895 |   1.6162 |     45.374 |     0.9
    7 |   1.6849 |     46.023 |   1.5609 |     44.301 |     1.1
    8 |   1.6212 |     45.546 |   1.5196 |     43.444 |     1.2
    9 |   1.5723 |     45.167 |   1.4889 |     43.474 |     1.4
   10 |   1.5340 |     44.977 |   1.4682 |     43.260 |     1.5
   11 |   1.4993 |     44.614 |   1.4488 |     43.199 |     1.7
   12 |   1.4648 |     43.926 |   1.4258 |     42.433 |     1.8
   13 |   1.4404 |     43.536 |   1.4166 |     41.820 |     2.0
   14 |   1.4139 |     43.200 |   1.3917 |     41.667 |     2.1
   15 |   1.3909 |     42.604 |   1.4033 |     41.360 |     2.3
   16 |   1.3708 |     42.171 |   1.3757 |     40.349 |     2.5
   17 |   1.3533 |     41.845 |   1.3676 |     40.043 |     2.6
   18 |   1.3318 |     41.358 |   1.3730 |     40.441 |     2.8
   19 |   1.3111 |     40.892 |   1.3822 |     40.012 |     2.9
   20 |   1.2963 |     40.702 |   1.3539 |     40.043 |     3.1
   21 |   1.2791 |     39.998 |   1.3641 |     40.196 |     3.2
   22 |   1.2679 |     39.759 |   1.3296 |     38.113 |     3.4
   23 |   1.2479 |     39.169 |   1.3582 |     39.859 |     3.5
   24 |   1.2342 |     38.622 |   1.3343 |     39.522 |     3.7
   25 |   1.2208 |     38.275 |   1.3476 |     40.288 |     3.8
   26 |   1.2094 |     37.917 |   1.3482 |     40.411 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 911,010

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4502 |     61.384 |   1.6442 |     44.822 |     0.2
    2 |   1.5738 |     45.026 |   1.3881 |     43.290 |     0.4
    3 |   1.3909 |     42.452 |   1.2853 |     39.032 |     0.5
    4 |   1.2903 |     39.629 |   1.2174 |     36.857 |     0.7
    5 |   1.2254 |     38.129 |   1.1748 |     36.121 |     0.9
    6 |   1.1635 |     36.335 |   1.1305 |     35.784 |     1.1
    7 |   1.1063 |     34.661 |   1.1080 |     35.202 |     1.3
    8 |   1.0663 |     33.518 |   1.0841 |     34.773 |     1.4
    9 |   1.0284 |     32.103 |   1.0607 |     33.578 |     1.6
   10 |   0.9833 |     30.987 |   1.0482 |     33.333 |     1.8
   11 |   0.9455 |     29.573 |   1.0295 |     32.200 |     2.0
   12 |   0.9166 |     28.999 |   1.0111 |     31.526 |     2.1
   13 |   0.8854 |     27.937 |   0.9939 |     31.403 |     2.3
   14 |   0.8506 |     26.880 |   0.9957 |     30.576 |     2.5
   15 |   0.8259 |     26.468 |   0.9774 |     30.668 |     2.7
   16 |   0.7956 |     25.531 |   1.0044 |     30.515 |     2.9
   17 |   0.7748 |     24.745 |   0.9652 |     29.871 |     3.0
   18 |   0.7554 |     24.328 |   0.9663 |     30.362 |     3.2
   19 |   0.7289 |     23.683 |   0.9613 |     29.259 |     3.4
   20 |   0.7107 |     22.616 |   0.9647 |     30.147 |     3.6
   21 |   0.6943 |     22.285 |   0.9564 |     29.075 |     3.8
   22 |   0.6712 |     21.451 |   0.9806 |     30.300 |     3.9
   23 |   0.6662 |     21.240 |   0.9660 |     28.248 |     4.1
   24 |   0.6366 |     20.600 |   0.9610 |     28.922 |     4.3
   25 |   0.6207 |     20.151 |   0.9679 |     28.891 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 130,978

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0980 |     53.782 |   1.4680 |     43.964 |     0.1
    2 |   1.4243 |     44.262 |   1.3092 |     42.371 |     0.2
    3 |   1.3099 |     42.035 |   1.2152 |     38.572 |     0.2
    4 |   1.2270 |     40.177 |   1.1628 |     38.327 |     0.3
    5 |   1.1579 |     38.053 |   1.1014 |     35.478 |     0.4
    6 |   1.0994 |     36.438 |   1.0485 |     34.314 |     0.5
    7 |   1.0596 |     35.300 |   1.0212 |     33.027 |     0.6
    8 |   1.0160 |     33.826 |   0.9983 |     32.874 |     0.7
    9 |   0.9774 |     32.651 |   0.9726 |     32.047 |     0.8
   10 |   0.9543 |     32.011 |   0.9542 |     31.434 |     0.8
   11 |   0.9242 |     30.613 |   0.9420 |     30.668 |     0.9
   12 |   0.8961 |     30.229 |   0.9416 |     31.342 |     1.0
   13 |   0.8872 |     29.947 |   0.9226 |     30.362 |     1.1
   14 |   0.8602 |     28.571 |   0.9064 |     30.116 |     1.2
   15 |   0.8351 |     28.202 |   0.9102 |     31.097 |     1.3
   16 |   0.8220 |     27.888 |   0.9284 |     30.637 |     1.3
   17 |   0.8037 |     27.146 |   0.9086 |     29.504 |     1.4
   18 |   0.7812 |     26.582 |   0.9130 |     29.902 |     1.5
   19 |   0.7699 |     26.197 |   0.9014 |     29.167 |     1.6
   20 |   0.7532 |     25.417 |   0.9096 |     30.025 |     1.7
   21 |   0.7340 |     24.626 |   0.9040 |     28.952 |     1.8
   22 |   0.7278 |     24.675 |   0.9096 |     28.676 |     1.8
   23 |   0.7070 |     24.052 |   0.8957 |     29.320 |     1.9
   24 |   0.6982 |     23.732 |   0.8858 |     27.849 |     2.0
   25 |   0.6914 |     22.990 |   0.8989 |     28.125 |     2.1
   26 |   0.6800 |     23.309 |   0.9188 |     28.799 |     2.2
   27 |   0.6580 |     22.378 |   0.9134 |     28.922 |     2.3
   28 |   0.6506 |     22.502 |   0.9140 |     28.156 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 435,938

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5715 |     62.549 |   1.8353 |     44.577 |     0.1
    2 |   1.7542 |     45.210 |   1.5396 |     44.026 |     0.2
    3 |   1.5510 |     43.791 |   1.4270 |     41.513 |     0.2
    4 |   1.4464 |     41.916 |   1.3446 |     40.104 |     0.3
    5 |   1.3710 |     40.410 |   1.2821 |     38.205 |     0.4
    6 |   1.3049 |     39.115 |   1.2304 |     37.040 |     0.5
    7 |   1.2506 |     37.950 |   1.1939 |     35.815 |     0.5
    8 |   1.2032 |     37.180 |   1.1563 |     35.662 |     0.6
    9 |   1.1630 |     35.652 |   1.1275 |     34.743 |     0.7
   10 |   1.1288 |     35.040 |   1.1044 |     33.732 |     0.8
   11 |   1.0908 |     33.707 |   1.0835 |     33.180 |     0.8
   12 |   1.0620 |     32.922 |   1.0572 |     33.487 |     0.9
   13 |   1.0259 |     31.849 |   1.0348 |     32.445 |     1.0
   14 |   1.0056 |     31.323 |   1.0185 |     32.138 |     1.1
   15 |   0.9732 |     30.137 |   0.9973 |     31.127 |     1.2
   16 |   0.9536 |     29.611 |   0.9918 |     31.679 |     1.2
   17 |   0.9249 |     28.885 |   0.9736 |     30.055 |     1.3
   18 |   0.9099 |     28.419 |   0.9607 |     30.086 |     1.4
   19 |   0.8813 |     27.758 |   0.9464 |     29.504 |     1.5
   20 |   0.8629 |     27.238 |   0.9259 |     29.167 |     1.5
   21 |   0.8416 |     26.826 |   0.9199 |     28.768 |     1.6
   22 |   0.8245 |     26.300 |   0.9161 |     29.044 |     1.7
   23 |   0.8083 |     25.759 |   0.9078 |     28.615 |     1.8
   24 |   0.7885 |     24.729 |   0.9123 |     28.278 |     1.9
   25 |   0.7742 |     24.447 |   0.8945 |     27.849 |     1.9
   26 |   0.7578 |     24.122 |   0.8959 |     28.033 |     2.0
   27 |   0.7470 |     23.629 |   0.8894 |     27.420 |     2.1
   28 |   0.7258 |     23.044 |   0.8777 |     27.390 |     2.2
   29 |   0.7135 |     22.453 |   0.8783 |     27.298 |     2.3
   30 |   0.7008 |     22.248 |   0.8771 |     26.532 |     2.3
   31 |   0.6962 |     22.112 |   0.8818 |     26.685 |     2.4
   32 |   0.6727 |     21.597 |   0.8733 |     25.919 |     2.5
   33 |   0.6606 |     21.207 |   0.8973 |     27.420 |     2.6
   34 |   0.6570 |     21.066 |   0.8668 |     25.919 |     2.6
   35 |   0.6462 |     20.768 |   0.8691 |     26.225 |     2.7
   36 |   0.6312 |     20.102 |   0.8737 |     25.858 |     2.8
   37 |   0.6275 |     20.199 |   0.8626 |     26.011 |     2.9
   38 |   0.6094 |     19.636 |   0.8701 |     26.103 |     3.0
   39 |   0.5992 |     19.614 |   0.8909 |     26.379 |     3.0
   40 |   0.5912 |     19.148 |   0.8794 |     26.134 |     3.1
   41 |   0.5825 |     18.991 |   0.8803 |     25.888 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 976,418

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5379 |     64.689 |   1.7096 |     43.627 |     0.1
    2 |   1.6803 |     45.568 |   1.3998 |     42.249 |     0.2
    3 |   1.4586 |     43.753 |   1.2918 |     40.135 |     0.3
    4 |   1.3576 |     41.894 |   1.2375 |     38.664 |     0.4
    5 |   1.2942 |     40.686 |   1.1853 |     36.918 |     0.5
    6 |   1.2388 |     38.968 |   1.1574 |     35.754 |     0.6
    7 |   1.1963 |     37.885 |   1.1429 |     35.570 |     0.7
    8 |   1.1541 |     36.747 |   1.1198 |     35.263 |     0.8
    9 |   1.1232 |     35.940 |   1.1016 |     34.406 |     0.9
   10 |   1.0892 |     34.888 |   1.0757 |     34.130 |     1.0
   11 |   1.0627 |     33.929 |   1.0560 |     33.640 |     1.1
   12 |   1.0265 |     32.624 |   1.0358 |     32.261 |     1.2
   13 |   1.0017 |     32.136 |   1.0226 |     32.414 |     1.3
   14 |   0.9789 |     31.264 |   1.0115 |     31.618 |     1.4
   15 |   0.9527 |     30.705 |   1.0203 |     32.414 |     1.5
   16 |   0.9295 |     29.763 |   1.0019 |     31.985 |     1.6
   17 |   0.9026 |     29.080 |   0.9884 |     31.464 |     1.7
   18 |   0.8781 |     28.202 |   0.9826 |     30.515 |     1.8
   19 |   0.8636 |     27.872 |   0.9826 |     31.189 |     1.9
   20 |   0.8411 |     27.427 |   0.9637 |     30.147 |     2.0
   21 |   0.8192 |     26.609 |   0.9553 |     29.626 |     2.1
   22 |   0.7984 |     25.601 |   0.9546 |     29.534 |     2.2
   23 |   0.7845 |     25.396 |   0.9535 |     29.013 |     2.2
   24 |   0.7637 |     25.022 |   0.9574 |     28.554 |     2.3
   25 |   0.7494 |     24.371 |   0.9353 |     28.830 |     2.4
   26 |   0.7333 |     24.241 |   0.9497 |     28.891 |     2.5
   27 |   0.7135 |     23.244 |   0.9552 |     28.462 |     2.6
   28 |   0.7153 |     22.849 |   0.9416 |     27.849 |     2.7
   29 |   0.6918 |     22.827 |   0.9495 |     28.676 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,009,698

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4676 |     45.156 |   1.2216 |     39.675 |     0.1
    2 |   1.1741 |     39.342 |   1.1468 |     38.971 |     0.3
    3 |   1.0899 |     36.785 |   1.0672 |     36.520 |     0.4
    4 |   1.0197 |     34.298 |   0.9919 |     33.517 |     0.5
    5 |   0.9565 |     32.905 |   0.9675 |     33.027 |     0.7
    6 |   0.9065 |     30.803 |   0.9409 |     32.353 |     0.8
    7 |   0.8625 |     29.280 |   0.9074 |     30.515 |     1.0
    8 |   0.8275 |     28.609 |   0.8485 |     28.646 |     1.1
    9 |   0.7902 |     26.848 |   0.8554 |     28.799 |     1.2
   10 |   0.7544 |     25.894 |   0.8522 |     28.707 |     1.4
   11 |   0.7364 |     25.076 |   0.8509 |     28.983 |     1.5
   12 |   0.7211 |     24.653 |   0.8172 |     27.941 |     1.6
   13 |   0.7084 |     24.274 |   0.8795 |     29.565 |     1.8
   14 |   0.6830 |     23.369 |   0.8275 |     27.849 |     1.9
   15 |   0.6426 |     22.177 |   0.7915 |     26.348 |     2.0
   16 |   0.6348 |     22.096 |   0.7797 |     26.072 |     2.2
   17 |   0.5979 |     20.649 |   0.7857 |     26.256 |     2.3
   18 |   0.5922 |     20.617 |   0.7932 |     25.705 |     2.5
   19 |   0.5735 |     19.798 |   0.7944 |     25.368 |     2.6
   20 |   0.5696 |     19.863 |   0.7666 |     25.031 |     2.7
   21 |   0.5658 |     19.647 |   0.7862 |     25.674 |     2.9
   22 |   0.5429 |     18.606 |   0.7660 |     23.009 |     3.0
   23 |   0.5368 |     18.845 |   0.7473 |     24.112 |     3.1
   24 |   0.5266 |     18.601 |   0.8300 |     26.195 |     3.3
   25 |   0.5448 |     18.964 |   0.7941 |     23.897 |     3.4
   26 |   0.4945 |     17.127 |   0.7498 |     23.254 |     3.6
   27 |   0.4962 |     17.263 |   0.8113 |     24.663 |     3.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 977,314

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6066 |     65.177 |   1.8013 |     46.324 |     0.2
    2 |   1.7467 |     46.072 |   1.4509 |     43.260 |     0.3
    3 |   1.5050 |     44.798 |   1.3405 |     41.605 |     0.5
    4 |   1.3901 |     42.859 |   1.2739 |     40.012 |     0.6
    5 |   1.3149 |     41.168 |   1.2524 |     39.614 |     0.8
    6 |   1.2609 |     39.494 |   1.1883 |     36.887 |     0.9
    7 |   1.2165 |     38.372 |   1.1625 |     35.723 |     1.1
    8 |   1.1667 |     36.947 |   1.1460 |     35.509 |     1.2
    9 |   1.1304 |     35.950 |   1.1433 |     35.294 |     1.4
   10 |   1.0971 |     35.008 |   1.1177 |     35.080 |     1.5
   11 |   1.0704 |     34.000 |   1.0963 |     34.038 |     1.7
   12 |   1.0329 |     32.862 |   1.0757 |     33.425 |     1.9
   13 |   1.0120 |     32.483 |   1.0845 |     33.609 |     2.0
   14 |   0.9816 |     31.301 |   1.0893 |     33.885 |     2.2
   15 |   0.9631 |     30.716 |   1.0552 |     32.414 |     2.3
   16 |   0.9366 |     30.001 |   1.0559 |     32.138 |     2.5
   17 |   0.9176 |     29.486 |   1.0490 |     32.598 |     2.6
   18 |   0.8924 |     28.766 |   1.0467 |     32.475 |     2.8
   19 |   0.8733 |     28.197 |   1.0731 |     32.996 |     2.9
   20 |   0.8510 |     27.460 |   1.0794 |     33.364 |     3.1
   21 |   0.8301 |     27.167 |   1.0785 |     33.364 |     3.2
   22 |   0.8225 |     26.739 |   1.0474 |     32.016 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 403,618

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9229 |     53.305 |   1.3576 |     43.290 |     0.1
    2 |   1.3454 |     43.146 |   1.2409 |     40.686 |     0.2
    3 |   1.2509 |     40.951 |   1.1853 |     38.971 |     0.3
    4 |   1.1924 |     39.055 |   1.1333 |     37.224 |     0.4
    5 |   1.1426 |     37.847 |   1.1030 |     35.968 |     0.5
    6 |   1.0936 |     36.308 |   1.0482 |     34.467 |     0.7
    7 |   1.0547 |     35.035 |   1.0309 |     34.099 |     0.8
    8 |   1.0082 |     33.637 |   1.0257 |     34.099 |     0.9
    9 |   0.9742 |     32.699 |   1.0058 |     33.027 |     1.0
   10 |   0.9404 |     31.984 |   0.9660 |     32.353 |     1.1
   11 |   0.9127 |     30.787 |   0.9609 |     30.852 |     1.2
   12 |   0.8825 |     29.746 |   0.9517 |     30.116 |     1.3
   13 |   0.8502 |     28.804 |   0.9500 |     30.453 |     1.4
   14 |   0.8356 |     28.126 |   0.9345 |     30.545 |     1.5
   15 |   0.8002 |     27.135 |   0.9388 |     30.116 |     1.6
   16 |   0.7693 |     25.975 |   0.9266 |     29.504 |     1.7
   17 |   0.7454 |     25.157 |   0.9086 |     28.676 |     1.9
   18 |   0.7390 |     24.995 |   0.9142 |     28.952 |     2.0
   19 |   0.7256 |     24.762 |   0.9068 |     28.033 |     2.1
   20 |   0.6986 |     23.613 |   0.9069 |     28.309 |     2.2
   21 |   0.6779 |     23.288 |   0.9349 |     28.309 |     2.3
   22 |   0.6655 |     22.800 |   0.8883 |     27.267 |     2.4
   23 |   0.6485 |     22.134 |   0.8902 |     27.114 |     2.5
   24 |   0.6265 |     21.538 |   0.8872 |     27.175 |     2.6
   25 |   0.5990 |     20.676 |   0.9305 |     27.727 |     2.7
   26 |   0.5981 |     20.844 |   0.9144 |     27.390 |     2.8
   27 |   0.5721 |     19.755 |   0.9414 |     27.512 |     3.0
   28 |   0.5735 |     19.842 |   0.9444 |     27.359 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 469,154

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5385 |     59.861 |   1.8950 |     46.661 |     0.1
    2 |   1.7863 |     45.389 |   1.5518 |     42.862 |     0.2
    3 |   1.5561 |     42.924 |   1.4168 |     40.472 |     0.3
    4 |   1.4334 |     41.477 |   1.3435 |     39.645 |     0.4
    5 |   1.3518 |     39.922 |   1.2764 |     38.051 |     0.6
    6 |   1.2873 |     38.719 |   1.2314 |     37.500 |     0.7
    7 |   1.2368 |     37.722 |   1.1964 |     36.734 |     0.8
    8 |   1.1870 |     36.563 |   1.1777 |     35.815 |     0.9
    9 |   1.1493 |     35.479 |   1.1477 |     34.681 |     1.0
   10 |   1.1117 |     33.648 |   1.1222 |     33.854 |     1.1
   11 |   1.0776 |     33.306 |   1.1090 |     33.946 |     1.2
   12 |   1.0464 |     32.190 |   1.0962 |     33.333 |     1.4
   13 |   1.0194 |     31.264 |   1.0848 |     33.303 |     1.5
   14 |   0.9828 |     30.364 |   1.0761 |     32.874 |     1.6
   15 |   0.9625 |     29.811 |   1.0575 |     32.353 |     1.7
   16 |   0.9401 |     29.010 |   1.0554 |     32.659 |     1.8
   17 |   0.9156 |     28.235 |   1.0411 |     31.556 |     1.9
   18 |   0.8956 |     27.742 |   1.0439 |     32.506 |     2.0
   19 |   0.8681 |     27.227 |   1.0178 |     30.699 |     2.1
   20 |   0.8462 |     26.441 |   1.0160 |     31.403 |     2.3
   21 |   0.8237 |     25.937 |   1.0293 |     30.423 |     2.4
   22 |   0.8086 |     25.731 |   1.0094 |     31.097 |     2.5
   23 |   0.7913 |     24.827 |   0.9984 |     29.841 |     2.6
   24 |   0.7645 |     24.220 |   1.0046 |     30.331 |     2.7
   25 |   0.7575 |     23.851 |   0.9894 |     29.779 |     2.8
   26 |   0.7353 |     23.131 |   0.9997 |     30.300 |     2.9
   27 |   0.7147 |     22.811 |   0.9960 |     29.504 |     3.1
   28 |   0.6996 |     22.421 |   0.9938 |     29.596 |     3.2
   29 |   0.6898 |     22.188 |   0.9840 |     27.972 |     3.3
   30 |   0.6794 |     21.651 |   0.9875 |     28.646 |     3.4
   31 |   0.6631 |     20.990 |   0.9862 |     28.493 |     3.5
   32 |   0.6492 |     20.671 |   0.9821 |     28.952 |     3.6
   33 |   0.6370 |     20.378 |   0.9925 |     28.554 |     3.7
   34 |   0.6194 |     19.636 |   0.9802 |     27.237 |     3.8
   35 |   0.6081 |     19.972 |   0.9813 |     27.298 |     4.0
   36 |   0.5961 |     19.278 |   1.0027 |     28.186 |     4.1
   37 |   0.5856 |     18.915 |   0.9882 |     27.451 |     4.2
   38 |   0.5827 |     18.520 |   1.0008 |     28.401 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8618 |     73.938 |   2.1745 |     50.429 |     0.2
    2 |   2.1144 |     49.875 |   1.6795 |     44.577 |     0.3
    3 |   1.7475 |     46.023 |   1.5103 |     44.087 |     0.5
    4 |   1.5847 |     45.140 |   1.4294 |     43.321 |     0.7
    5 |   1.4988 |     44.154 |   1.3811 |     42.525 |     0.9
    6 |   1.4313 |     43.460 |   1.3328 |     40.809 |     1.0
    7 |   1.3852 |     42.149 |   1.2985 |     38.787 |     1.2
    8 |   1.3413 |     41.239 |   1.2716 |     38.542 |     1.4
    9 |   1.3022 |     40.372 |   1.2567 |     37.898 |     1.5
   10 |   1.2716 |     39.353 |   1.2304 |     37.071 |     1.7
   11 |   1.2384 |     38.557 |   1.2438 |     37.255 |     1.9
   12 |   1.2138 |     37.863 |   1.2175 |     37.010 |     2.1
   13 |   1.1845 |     37.164 |   1.2016 |     36.520 |     2.2
   14 |   1.1548 |     36.167 |   1.2037 |     36.581 |     2.4
   15 |   1.1342 |     35.479 |   1.1790 |     35.754 |     2.6
   16 |   1.1071 |     34.970 |   1.1891 |     35.325 |     2.7
   17 |   1.0945 |     34.195 |   1.1648 |     35.080 |     2.9
   18 |   1.0718 |     33.322 |   1.1744 |     35.784 |     3.1
   19 |   1.0517 |     33.220 |   1.1603 |     35.080 |     3.3
   20 |   1.0289 |     32.185 |   1.1638 |     35.172 |     3.4
   21 |   1.0123 |     31.583 |   1.1483 |     35.141 |     3.6
   22 |   0.9989 |     31.708 |   1.1598 |     35.141 |     3.8
   23 |   0.9787 |     31.031 |   1.1386 |     34.589 |     3.9
   24 |   0.9711 |     30.597 |   1.1480 |     34.467 |     4.1
   25 |   0.9494 |     30.310 |   1.1397 |     33.303 |     4.3
   26 |   0.9326 |     29.660 |   1.1574 |     34.559 |     4.5
   27 |   0.9222 |     29.172 |   1.1581 |     34.375 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 159,522

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8906 |     49.388 |   1.4102 |     42.923 |     0.1
    2 |   1.2992 |     40.670 |   1.2001 |     38.327 |     0.2
    3 |   1.1453 |     36.752 |   1.1123 |     35.417 |     0.3
    4 |   1.0525 |     34.016 |   1.0402 |     33.670 |     0.3
    5 |   0.9736 |     31.757 |   1.0014 |     33.425 |     0.4
    6 |   0.9123 |     29.985 |   0.9401 |     30.607 |     0.5
    7 |   0.8580 |     28.218 |   0.9219 |     30.300 |     0.6
    8 |   0.8048 |     26.252 |   0.8812 |     28.646 |     0.7
    9 |   0.7618 |     25.060 |   0.8929 |     29.136 |     0.7
   10 |   0.7319 |     24.312 |   0.8574 |     28.125 |     0.8
   11 |   0.6846 |     22.589 |   0.8406 |     27.237 |     0.9
   12 |   0.6504 |     21.765 |   0.8278 |     26.011 |     1.0
   13 |   0.6200 |     20.909 |   0.8080 |     26.072 |     1.1
   14 |   0.5918 |     19.630 |   0.8043 |     26.317 |     1.1
   15 |   0.5679 |     19.110 |   0.8274 |     25.888 |     1.2
   16 |   0.5427 |     18.498 |   0.8069 |     24.387 |     1.3
   17 |   0.5203 |     17.658 |   0.8140 |     25.061 |     1.4
   18 |   0.4926 |     16.688 |   0.8430 |     25.490 |     1.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2658 |     57.163 |   1.5182 |     43.658 |     0.1
    2 |   1.5059 |     44.018 |   1.3348 |     41.513 |     0.2
    3 |   1.3580 |     41.515 |   1.2453 |     39.062 |     0.4
    4 |   1.2626 |     39.364 |   1.1823 |     36.765 |     0.5
    5 |   1.1927 |     37.110 |   1.1366 |     35.784 |     0.6
    6 |   1.1295 |     35.268 |   1.1009 |     34.406 |     0.8
    7 |   1.0757 |     33.956 |   1.0578 |     33.548 |     0.9
    8 |   1.0315 |     32.559 |   1.0398 |     32.812 |     1.0
    9 |   0.9879 |     31.264 |   1.0018 |     31.464 |     1.1
   10 |   0.9466 |     29.893 |   0.9960 |     31.771 |     1.3
   11 |   0.9131 |     29.069 |   0.9593 |     30.852 |     1.4
   12 |   0.8805 |     27.985 |   0.9441 |     30.178 |     1.5
   13 |   0.8429 |     26.951 |   0.9313 |     29.657 |     1.6
   14 |   0.8160 |     26.252 |   0.9114 |     29.871 |     1.8
   15 |   0.7835 |     25.103 |   0.9101 |     28.830 |     1.9
   16 |   0.7582 |     24.361 |   0.8824 |     27.512 |     2.0
   17 |   0.7345 |     23.797 |   0.9039 |     28.523 |     2.1
   18 |   0.7182 |     23.001 |   0.8896 |     27.911 |     2.3
   19 |   0.6948 |     22.302 |   0.8817 |     28.156 |     2.4
   20 |   0.6639 |     21.267 |   0.8744 |     27.328 |     2.5
   21 |   0.6549 |     21.093 |   0.9094 |     27.512 |     2.6
   22 |   0.6356 |     20.627 |   0.8787 |     26.164 |     2.8
   23 |   0.6151 |     19.701 |   0.8656 |     25.919 |     2.9
   24 |   0.5945 |     19.240 |   0.8869 |     26.348 |     3.0
   25 |   0.5860 |     19.164 |   0.8738 |     26.746 |     3.1
   26 |   0.5721 |     18.639 |   0.8692 |     25.429 |     3.3
   27 |   0.5574 |     18.476 |   0.8673 |     25.214 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,273,378

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4749 |     44.869 |   1.1915 |     39.461 |     0.1
    2 |   1.1361 |     38.139 |   1.0648 |     35.846 |     0.3
    3 |   1.0422 |     35.284 |   0.9999 |     34.651 |     0.4
    4 |   0.9471 |     32.358 |   0.9452 |     32.353 |     0.6
    5 |   0.8891 |     30.798 |   0.9070 |     30.270 |     0.7
    6 |   0.8388 |     29.107 |   0.8733 |     29.718 |     0.9
    7 |   0.8009 |     27.834 |   0.8837 |     30.147 |     1.0
    8 |   0.7666 |     26.593 |   0.8457 |     27.757 |     1.2
    9 |   0.7171 |     24.951 |   0.8097 |     26.746 |     1.3
   10 |   0.6870 |     23.873 |   0.7969 |     26.624 |     1.5
   11 |   0.6488 |     22.860 |   0.8101 |     26.440 |     1.6
   12 |   0.6172 |     21.570 |   0.7794 |     25.797 |     1.8
   13 |   0.5871 |     20.557 |   0.7919 |     26.225 |     1.9
   14 |   0.5633 |     19.934 |   0.7748 |     24.142 |     2.1
   15 |   0.5474 |     19.143 |   0.7723 |     25.031 |     2.2
   16 |   0.5307 |     18.796 |   0.7573 |     23.836 |     2.4
   17 |   0.4909 |     16.970 |   0.7698 |     23.866 |     2.5
   18 |   0.4803 |     16.797 |   0.7548 |     23.713 |     2.7
   19 |   0.4638 |     16.564 |   0.7576 |     23.621 |     2.8
   20 |   0.4390 |     15.399 |   0.7404 |     22.426 |     3.0
   21 |   0.4149 |     14.613 |   0.7631 |     23.009 |     3.1
   22 |   0.4254 |     15.155 |   0.8358 |     24.295 |     3.3
   23 |   0.4395 |     15.670 |   0.8219 |     23.775 |     3.4
   24 |   0.4101 |     14.369 |   0.7690 |     22.426 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,060,450

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4870 |     63.952 |   1.7067 |     48.192 |     0.1
    2 |   1.6931 |     46.684 |   1.3936 |     41.452 |     0.3
    3 |   1.4596 |     43.801 |   1.3039 |     39.430 |     0.4
    4 |   1.3562 |     41.726 |   1.2585 |     38.113 |     0.6
    5 |   1.2892 |     40.020 |   1.2175 |     37.132 |     0.7
    6 |   1.2340 |     38.697 |   1.1956 |     36.489 |     0.9
    7 |   1.1934 |     37.619 |   1.1530 |     35.202 |     1.0
    8 |   1.1564 |     36.319 |   1.1414 |     35.049 |     1.2
    9 |   1.1156 |     35.192 |   1.1206 |     34.130 |     1.3
   10 |   1.0772 |     34.254 |   1.1030 |     34.712 |     1.5
   11 |   1.0397 |     32.976 |   1.1162 |     34.559 |     1.6
   12 |   1.0159 |     32.163 |   1.0861 |     33.854 |     1.8
   13 |   0.9813 |     31.296 |   1.0968 |     34.375 |     1.9
   14 |   0.9585 |     30.359 |   1.0934 |     33.762 |     2.1
   15 |   0.9348 |     29.952 |   1.0613 |     32.169 |     2.2
   16 |   0.9129 |     28.977 |   1.0597 |     32.138 |     2.4
   17 |   0.8881 |     28.386 |   1.0394 |     30.790 |     2.5
   18 |   0.8706 |     28.029 |   1.0361 |     31.955 |     2.7
   19 |   0.8488 |     26.956 |   1.0327 |     31.342 |     2.8
   20 |   0.8313 |     26.685 |   1.0457 |     31.801 |     3.0
   21 |   0.8155 |     26.436 |   1.0855 |     32.629 |     3.1
   22 |   0.8004 |     25.553 |   1.0531 |     32.261 |     3.3
   23 |   0.7761 |     25.287 |   1.0641 |     31.373 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 942,114

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2192 |     56.199 |   1.5343 |     43.811 |     0.1
    2 |   1.4797 |     43.379 |   1.3306 |     41.330 |     0.2
    3 |   1.3208 |     40.041 |   1.2252 |     37.071 |     0.3
    4 |   1.2253 |     38.058 |   1.1587 |     35.417 |     0.4
    5 |   1.1492 |     35.587 |   1.1059 |     34.528 |     0.6
    6 |   1.0928 |     34.043 |   1.0603 |     33.303 |     0.7
    7 |   1.0443 |     32.889 |   1.0397 |     33.180 |     0.8
    8 |   0.9979 |     31.236 |   1.0039 |     31.955 |     0.9
    9 |   0.9514 |     29.952 |   0.9791 |     31.373 |     1.0
   10 |   0.9110 |     28.869 |   0.9562 |     30.729 |     1.1
   11 |   0.8859 |     28.262 |   0.9285 |     30.055 |     1.2
   12 |   0.8417 |     27.140 |   0.9124 |     29.350 |     1.3
   13 |   0.8173 |     26.181 |   0.8940 |     28.860 |     1.4
   14 |   0.7909 |     25.439 |   0.8868 |     28.156 |     1.6
   15 |   0.7569 |     24.209 |   0.8792 |     28.339 |     1.7
   16 |   0.7399 |     23.900 |   0.8746 |     27.665 |     1.8
   17 |   0.7086 |     22.719 |   0.8658 |     26.991 |     1.9
   18 |   0.6920 |     22.329 |   0.8689 |     27.696 |     2.0
   19 |   0.6687 |     21.830 |   0.8412 |     26.562 |     2.1
   20 |   0.6463 |     20.795 |   0.8561 |     26.379 |     2.2
   21 |   0.6264 |     20.357 |   0.8609 |     27.145 |     2.3
   22 |   0.6026 |     19.593 |   0.8615 |     26.195 |     2.5
   23 |   0.5967 |     19.435 |   0.8385 |     26.011 |     2.6
   24 |   0.5839 |     19.110 |   0.8411 |     25.613 |     2.7
   25 |   0.5653 |     18.298 |   0.8560 |     25.429 |     2.8
   26 |   0.5431 |     17.734 |   0.8436 |     24.877 |     2.9
   27 |   0.5280 |     17.572 |   0.8412 |     25.368 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 911,010

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5538 |     46.782 |   1.2757 |     41.973 |     0.1
    2 |   1.2350 |     40.984 |   1.1874 |     40.074 |     0.3
    3 |   1.1697 |     39.191 |   1.1026 |     36.673 |     0.4
    4 |   1.0991 |     37.121 |   1.0743 |     35.386 |     0.6
    5 |   1.0574 |     35.631 |   1.0326 |     35.172 |     0.7
    6 |   1.0110 |     34.195 |   1.0367 |     34.651 |     0.8
    7 |   0.9695 |     32.954 |   0.9791 |     33.517 |     1.0
    8 |   0.9345 |     32.179 |   0.9716 |     32.292 |     1.1
    9 |   0.9071 |     31.096 |   0.9956 |     33.854 |     1.3
   10 |   0.8821 |     30.153 |   0.9855 |     33.395 |     1.4
   11 |   0.8548 |     29.145 |   0.9434 |     32.138 |     1.5
   12 |   0.8257 |     28.061 |   0.9822 |     33.824 |     1.7
   13 |   0.8026 |     27.552 |   0.9530 |     31.158 |     1.8
   14 |   0.7902 |     26.934 |   0.9454 |     32.721 |     2.0
   15 |   0.7676 |     26.555 |   0.9487 |     31.495 |     2.1
   16 |   0.7654 |     25.986 |   0.9005 |     31.587 |     2.2
   17 |   0.7454 |     25.358 |   0.9404 |     30.086 |     2.4
   18 |   0.7175 |     24.816 |   0.8719 |     28.493 |     2.5
   19 |   0.6964 |     24.263 |   0.9400 |     30.453 |     2.7
   20 |   0.6806 |     23.580 |   0.9436 |     30.974 |     2.8
   21 |   0.6697 |     23.326 |   0.8613 |     28.064 |     3.0
   22 |   0.6446 |     22.383 |   0.9272 |     29.534 |     3.1
   23 |   0.6334 |     21.939 |   0.8789 |     28.431 |     3.2
   24 |   0.6138 |     21.435 |   0.8684 |     28.676 |     3.4
   25 |   0.6041 |     21.072 |   0.9011 |     28.431 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 252,194

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9283 |     72.654 |   2.3706 |     50.551 |     0.1
    2 |   2.2000 |     48.158 |   1.9026 |     45.680 |     0.2
    3 |   1.9004 |     46.229 |   1.7473 |     45.680 |     0.3
    4 |   1.7578 |     45.335 |   1.6430 |     44.516 |     0.5
    5 |   1.6556 |     44.668 |   1.5594 |     42.647 |     0.6
    6 |   1.5746 |     43.466 |   1.4971 |     41.636 |     0.7
    7 |   1.5048 |     42.198 |   1.4403 |     40.931 |     0.8
    8 |   1.4508 |     41.607 |   1.3883 |     40.656 |     0.9
    9 |   1.3957 |     40.702 |   1.3479 |     39.062 |     1.0
   10 |   1.3541 |     39.467 |   1.3074 |     38.572 |     1.1
   11 |   1.3103 |     38.502 |   1.2782 |     38.450 |     1.2
   12 |   1.2778 |     37.755 |   1.2514 |     37.347 |     1.4
   13 |   1.2406 |     37.039 |   1.2228 |     36.795 |     1.5
   14 |   1.2152 |     36.676 |   1.2018 |     35.754 |     1.6
   15 |   1.1820 |     35.365 |   1.1857 |     35.662 |     1.7
   16 |   1.1534 |     34.921 |   1.1768 |     35.478 |     1.8
   17 |   1.1311 |     34.238 |   1.1541 |     34.743 |     1.9
   18 |   1.1090 |     33.610 |   1.1420 |     35.080 |     2.0
   19 |   1.0900 |     33.160 |   1.1226 |     34.161 |     2.1
   20 |   1.0699 |     32.564 |   1.1229 |     34.773 |     2.3
   21 |   1.0494 |     32.564 |   1.1127 |     34.498 |     2.4
   22 |   1.0369 |     32.038 |   1.0989 |     34.498 |     2.5
   23 |   1.0150 |     31.448 |   1.0916 |     33.272 |     2.6
   24 |   1.0003 |     30.906 |   1.0779 |     33.088 |     2.7
   25 |   0.9836 |     30.543 |   1.0695 |     33.487 |     2.8
   26 |   0.9660 |     29.849 |   1.0694 |     33.303 |     2.9
   27 |   0.9519 |     29.427 |   1.0537 |     32.414 |     3.0
   28 |   0.9382 |     29.400 |   1.0598 |     32.659 |     3.2
   29 |   0.9248 |     29.015 |   1.0443 |     33.119 |     3.3
   30 |   0.9119 |     28.549 |   1.0457 |     32.996 |     3.4
   31 |   0.8964 |     28.451 |   1.0498 |     32.782 |     3.5
   32 |   0.8878 |     27.985 |   1.0326 |     32.384 |     3.6
   33 |   0.8720 |     27.492 |   1.0300 |     31.985 |     3.7
   34 |   0.8678 |     27.308 |   1.0248 |     31.771 |     3.8
   35 |   0.8475 |     26.858 |   1.0237 |     31.281 |     3.9
   36 |   0.8356 |     26.539 |   1.0357 |     31.863 |     4.1
   37 |   0.8301 |     26.631 |   1.0174 |     31.526 |     4.2
   38 |   0.8174 |     25.742 |   1.0137 |     30.974 |     4.3
   39 |   0.8124 |     25.856 |   1.0049 |     31.219 |     4.4
   40 |   0.8030 |     25.574 |   1.0071 |     30.821 |     4.5
   41 |   0.7971 |     25.498 |   0.9888 |     30.637 |     4.6
   42 |   0.7838 |     24.837 |   1.0095 |     30.821 |     4.7
   43 |   0.7700 |     24.691 |   0.9990 |     30.882 |     4.8
   44 |   0.7674 |     24.599 |   0.9945 |     30.637 |     5.0
   45 |   0.7553 |     24.155 |   1.0104 |     31.158 |     5.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 354,082

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7624 |     68.742 |   2.0605 |     48.131 |     0.1
    2 |   1.9382 |     47.811 |   1.6191 |     45.159 |     0.2
    3 |   1.6477 |     45.481 |   1.4836 |     43.658 |     0.2
    4 |   1.5189 |     44.457 |   1.4017 |     42.249 |     0.3
    5 |   1.4438 |     43.168 |   1.3532 |     41.513 |     0.4
    6 |   1.3770 |     41.612 |   1.2975 |     39.583 |     0.5
    7 |   1.3281 |     40.616 |   1.2636 |     39.001 |     0.6
    8 |   1.2856 |     39.749 |   1.2215 |     37.929 |     0.6
    9 |   1.2425 |     38.432 |   1.1960 |     36.642 |     0.7
   10 |   1.2106 |     37.663 |   1.1779 |     37.010 |     0.8
   11 |   1.1756 |     36.741 |   1.1451 |     35.999 |     0.9
   12 |   1.1461 |     35.809 |   1.1257 |     35.018 |     1.0
   13 |   1.1250 |     35.311 |   1.1153 |     35.325 |     1.0
   14 |   1.0996 |     34.596 |   1.0957 |     34.191 |     1.1
   15 |   1.0714 |     33.848 |   1.0846 |     33.793 |     1.2
   16 |   1.0506 |     33.480 |   1.0652 |     33.027 |     1.3
   17 |   1.0317 |     32.380 |   1.0576 |     33.211 |     1.4
   18 |   1.0098 |     32.109 |   1.0421 |     32.537 |     1.4
   19 |   0.9909 |     31.605 |   1.0409 |     32.904 |     1.5
   20 |   0.9794 |     31.377 |   1.0156 |     31.985 |     1.6
   21 |   0.9582 |     30.705 |   1.0048 |     32.230 |     1.7
   22 |   0.9395 |     30.034 |   0.9981 |     31.924 |     1.8
   23 |   0.9247 |     29.752 |   1.0002 |     32.261 |     1.8
   24 |   0.9139 |     29.595 |   0.9953 |     32.384 |     1.9
   25 |   0.8924 |     28.511 |   0.9704 |     31.832 |     2.0
   26 |   0.8799 |     28.376 |   0.9721 |     31.342 |     2.1
   27 |   0.8704 |     28.056 |   0.9699 |     31.219 |     2.2
   28 |   0.8620 |     27.438 |   0.9622 |     30.668 |     2.3
   29 |   0.8442 |     27.427 |   0.9746 |     31.342 |     2.3
   30 |   0.8261 |     26.978 |   0.9597 |     30.576 |     2.4
   31 |   0.8203 |     26.436 |   0.9570 |     30.239 |     2.5
   32 |   0.8035 |     25.964 |   0.9488 |     30.300 |     2.6
   33 |   0.7913 |     25.683 |   0.9405 |     30.576 |     2.7
   34 |   0.7848 |     25.558 |   0.9417 |     29.534 |     2.7
   35 |   0.7743 |     25.184 |   0.9349 |     29.412 |     2.8
   36 |   0.7739 |     25.222 |   0.9341 |     29.167 |     2.9
   37 |   0.7535 |     24.534 |   0.9500 |     29.963 |     3.0
   38 |   0.7491 |     24.539 |   0.9332 |     29.779 |     3.1
   39 |   0.7297 |     23.906 |   0.9321 |     28.799 |     3.1
   40 |   0.7285 |     23.878 |   0.9213 |     29.473 |     3.2
   41 |   0.7215 |     23.412 |   0.9099 |     28.983 |     3.3
   42 |   0.7005 |     22.898 |   0.9167 |     28.615 |     3.4
   43 |   0.7015 |     22.751 |   0.9442 |     29.504 |     3.5
   44 |   0.6980 |     22.779 |   0.9252 |     28.922 |     3.6
   45 |   0.6825 |     22.383 |   0.9135 |     28.830 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 180,546

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9794 |     70.405 |   2.4154 |     47.212 |     0.1
    2 |   2.0961 |     46.738 |   1.9039 |     46.661 |     0.2
    3 |   1.8032 |     45.535 |   1.7332 |     45.833 |     0.3
    4 |   1.6698 |     44.934 |   1.6288 |     44.761 |     0.4
    5 |   1.5741 |     43.682 |   1.5470 |     43.444 |     0.5
    6 |   1.4960 |     41.986 |   1.4772 |     41.636 |     0.6
    7 |   1.4264 |     40.783 |   1.4236 |     40.901 |     0.7
    8 |   1.3634 |     39.456 |   1.3696 |     39.185 |     0.8
    9 |   1.3113 |     38.172 |   1.3260 |     38.082 |     0.9
   10 |   1.2615 |     36.893 |   1.2877 |     37.132 |     1.0
   11 |   1.2216 |     35.744 |   1.2543 |     36.152 |     1.1
   12 |   1.1829 |     34.742 |   1.2311 |     35.938 |     1.2
   13 |   1.1475 |     33.723 |   1.1985 |     33.946 |     1.3
   14 |   1.1144 |     32.689 |   1.1772 |     33.824 |     1.4
   15 |   1.0833 |     31.919 |   1.1600 |     33.058 |     1.5
   16 |   1.0569 |     31.242 |   1.1440 |     32.629 |     1.6
   17 |   1.0317 |     30.223 |   1.1170 |     32.445 |     1.7
   18 |   1.0048 |     29.763 |   1.1067 |     32.690 |     1.8
   19 |   0.9799 |     29.329 |   1.0918 |     32.230 |     2.0
   20 |   0.9589 |     28.820 |   1.0755 |     32.506 |     2.1
   21 |   0.9329 |     27.996 |   1.0594 |     31.250 |     2.2
   22 |   0.9105 |     27.395 |   1.0443 |     31.250 |     2.3
   23 |   0.8935 |     27.108 |   1.0319 |     30.729 |     2.4
   24 |   0.8761 |     26.777 |   1.0111 |     30.484 |     2.5
   25 |   0.8529 |     25.975 |   1.0123 |     30.300 |     2.6
   26 |   0.8358 |     25.249 |   1.0092 |     31.403 |     2.7
   27 |   0.8190 |     25.076 |   1.0023 |     30.239 |     2.8
   28 |   0.8006 |     24.274 |   0.9895 |     30.086 |     2.9
   29 |   0.7858 |     24.090 |   0.9854 |     29.442 |     3.0
   30 |   0.7683 |     23.483 |   0.9871 |     29.963 |     3.1
   31 |   0.7596 |     23.467 |   0.9697 |     29.442 |     3.2
   32 |   0.7449 |     22.838 |   0.9821 |     29.933 |     3.3
   33 |   0.7350 |     22.567 |   0.9778 |     29.810 |     3.4
   34 |   0.7249 |     22.421 |   0.9669 |     29.167 |     3.5
   35 |   0.7038 |     21.933 |   0.9679 |     29.473 |     3.6
   36 |   0.6956 |     21.343 |   0.9590 |     28.768 |     3.7
   37 |   0.6856 |     21.229 |   0.9473 |     28.615 |     3.8
   38 |   0.6712 |     20.443 |   0.9512 |     28.554 |     3.9
   39 |   0.6571 |     20.449 |   0.9568 |     28.493 |     4.0
   40 |   0.6444 |     19.636 |   0.9468 |     28.462 |     4.1
   41 |   0.6367 |     19.880 |   0.9433 |     28.891 |     4.2
   42 |   0.6285 |     19.490 |   0.9554 |     28.431 |     4.3
   43 |   0.6196 |     19.202 |   0.9677 |     28.401 |     4.4
   44 |   0.6057 |     18.861 |   0.9491 |     28.493 |     4.5
   45 |   0.6011 |     18.872 |   0.9508 |     27.911 |     4.6
   46 |   0.5889 |     18.417 |   0.9407 |     27.604 |     4.7
   47 |   0.5834 |     18.363 |   0.9795 |     29.075 |     4.8
   48 |   0.5843 |     18.270 |   0.9481 |     27.665 |     4.9
   49 |   0.5559 |     17.290 |   0.9471 |     27.604 |     5.0
   50 |   0.5575 |     17.615 |   0.9575 |     27.849 |     5.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 942,114

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4680 |     44.652 |   1.2113 |     39.583 |     0.1
    2 |   1.1733 |     38.464 |   1.0752 |     35.662 |     0.2
    3 |   1.0531 |     34.975 |   1.0177 |     34.896 |     0.3
    4 |   0.9771 |     32.970 |   0.9587 |     32.629 |     0.4
    5 |   0.9239 |     31.177 |   0.9100 |     31.158 |     0.6
    6 |   0.8694 |     29.974 |   0.8899 |     29.933 |     0.7
    7 |   0.8314 |     28.354 |   0.8756 |     29.504 |     0.8
    8 |   0.7878 |     26.907 |   0.8754 |     29.902 |     0.9
    9 |   0.7498 |     25.531 |   0.7962 |     26.256 |     1.0
   10 |   0.7150 |     24.502 |   0.8524 |     28.554 |     1.1
   11 |   0.6849 |     23.651 |   0.8268 |     27.175 |     1.2
   12 |   0.6454 |     22.052 |   0.8066 |     26.409 |     1.3
   13 |   0.6317 |     21.684 |   0.7982 |     25.276 |     1.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5765 |     65.025 |   1.8532 |     45.159 |     0.1
    2 |   1.7571 |     45.476 |   1.5232 |     43.260 |     0.2
    3 |   1.5375 |     43.937 |   1.4106 |     41.881 |     0.3
    4 |   1.4364 |     42.447 |   1.3344 |     40.074 |     0.5
    5 |   1.3556 |     40.751 |   1.2647 |     38.174 |     0.6
    6 |   1.2913 |     39.071 |   1.2144 |     36.305 |     0.7
    7 |   1.2270 |     36.909 |   1.1725 |     35.938 |     0.8
    8 |   1.1826 |     35.712 |   1.1364 |     34.069 |     0.9
    9 |   1.1309 |     34.168 |   1.1035 |     33.854 |     1.1
   10 |   1.0905 |     33.469 |   1.0864 |     33.701 |     1.2
   11 |   1.0513 |     32.168 |   1.0579 |     32.414 |     1.3
   12 |   1.0142 |     31.014 |   1.0358 |     31.955 |     1.4
   13 |   0.9798 |     30.017 |   1.0382 |     32.659 |     1.5
   14 |   0.9485 |     29.058 |   1.0054 |     31.618 |     1.7
   15 |   0.9266 |     28.652 |   0.9938 |     31.127 |     1.8
   16 |   0.9008 |     27.850 |   0.9985 |     31.036 |     1.9
   17 |   0.8794 |     27.184 |   0.9785 |     30.331 |     2.0
   18 |   0.8478 |     26.631 |   0.9738 |     29.994 |     2.1
   19 |   0.8239 |     25.634 |   0.9648 |     30.300 |     2.2
   20 |   0.8044 |     25.119 |   0.9673 |     29.902 |     2.4
   21 |   0.7869 |     24.225 |   0.9468 |     28.860 |     2.5
   22 |   0.7651 |     23.813 |   0.9523 |     29.902 |     2.6
   23 |   0.7463 |     23.412 |   0.9534 |     29.963 |     2.7
   24 |   0.7334 |     23.147 |   0.9536 |     29.197 |     2.8
   25 |   0.7183 |     22.806 |   0.9320 |     28.676 |     2.9
   26 |   0.7023 |     22.085 |   0.9430 |     29.228 |     3.1
   27 |   0.6915 |     21.559 |   0.9337 |     28.523 |     3.2
   28 |   0.6657 |     21.316 |   0.9459 |     28.125 |     3.3
   29 |   0.6526 |     20.519 |   0.9458 |     28.615 |     3.4
   30 |   0.6346 |     19.869 |   0.9258 |     27.175 |     3.5
   31 |   0.6340 |     20.064 |   0.9210 |     26.900 |     3.7
   32 |   0.6194 |     19.636 |   0.9275 |     27.482 |     3.8
   33 |   0.6060 |     19.143 |   0.9311 |     26.440 |     3.9
   34 |   0.5914 |     18.904 |   0.9108 |     26.317 |     4.0
   35 |   0.5863 |     18.623 |   0.9491 |     26.930 |     4.1
   36 |   0.5700 |     18.514 |   0.9365 |     27.053 |     4.2
   37 |   0.5603 |     17.832 |   0.9323 |     26.716 |     4.4
   38 |   0.5487 |     17.479 |   0.9210 |     26.164 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 139,522

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9371 |     69.273 |   2.5321 |     53.431 |     0.1
    2 |   2.2614 |     49.924 |   2.0638 |     47.886 |     0.3
    3 |   1.9231 |     46.695 |   1.8226 |     46.661 |     0.4
    4 |   1.7424 |     45.980 |   1.6822 |     44.822 |     0.5
    5 |   1.6254 |     44.143 |   1.5887 |     43.444 |     0.7
    6 |   1.5419 |     42.956 |   1.5207 |     42.586 |     0.8
    7 |   1.4772 |     41.840 |   1.4631 |     40.809 |     0.9
    8 |   1.4216 |     40.740 |   1.4149 |     40.043 |     1.1
    9 |   1.3700 |     39.581 |   1.3670 |     39.461 |     1.2
   10 |   1.3222 |     38.746 |   1.3345 |     38.542 |     1.3
   11 |   1.2831 |     37.728 |   1.3019 |     38.542 |     1.5
   12 |   1.2478 |     37.256 |   1.2738 |     37.531 |     1.6
   13 |   1.2118 |     36.118 |   1.2449 |     37.347 |     1.7
   14 |   1.1810 |     35.403 |   1.2151 |     36.489 |     1.8
   15 |   1.1503 |     34.590 |   1.1954 |     35.876 |     2.0
   16 |   1.1208 |     33.713 |   1.1833 |     35.417 |     2.1
   17 |   1.0952 |     32.976 |   1.1755 |     35.723 |     2.2
   18 |   1.0759 |     32.461 |   1.1444 |     34.988 |     2.4
   19 |   1.0450 |     31.860 |   1.1201 |     34.099 |     2.5
   20 |   1.0252 |     31.155 |   1.1308 |     34.926 |     2.6
   21 |   1.0054 |     30.716 |   1.1071 |     32.904 |     2.8
   22 |   0.9832 |     29.719 |   1.0975 |     33.946 |     2.9
   23 |   0.9667 |     29.557 |   1.0864 |     33.609 |     3.0
   24 |   0.9463 |     28.771 |   1.0704 |     32.751 |     3.2
   25 |   0.9300 |     28.370 |   1.0638 |     32.445 |     3.3
   26 |   0.9121 |     28.083 |   1.0796 |     33.395 |     3.4
   27 |   0.8991 |     27.601 |   1.0478 |     32.966 |     3.6
   28 |   0.8860 |     27.184 |   1.0409 |     32.016 |     3.7
   29 |   0.8718 |     26.956 |   1.0393 |     32.138 |     3.8
   30 |   0.8527 |     26.089 |   1.0307 |     32.292 |     4.0
   31 |   0.8505 |     26.235 |   1.0183 |     31.311 |     4.1
   32 |   0.8260 |     25.390 |   1.0212 |     31.863 |     4.2
   33 |   0.8177 |     25.303 |   1.0205 |     30.882 |     4.4
   34 |   0.8004 |     24.707 |   1.0124 |     31.587 |     4.5
   35 |   0.7925 |     24.442 |   1.0076 |     30.453 |     4.6
   36 |   0.7785 |     23.998 |   0.9959 |     30.178 |     4.7
   37 |   0.7703 |     23.461 |   1.0182 |     31.250 |     4.9
   38 |   0.7674 |     23.364 |   1.0048 |     30.607 |     5.0
   39 |   0.7504 |     23.196 |   0.9884 |     30.116 |     5.1
   40 |   0.7456 |     22.627 |   1.0044 |     30.331 |     5.3
   41 |   0.7350 |     22.556 |   0.9998 |     30.668 |     5.4
   42 |   0.7226 |     22.220 |   0.9992 |     30.607 |     5.5
   43 |   0.7121 |     21.998 |   0.9939 |     30.025 |     5.7
   44 |   0.7005 |     21.538 |   0.9821 |     29.197 |     5.8
   45 |   0.6953 |     21.462 |   0.9821 |     29.197 |     5.9
   46 |   0.6955 |     21.614 |   1.0014 |     30.545 |     6.1
   47 |   0.6784 |     20.947 |   0.9866 |     29.534 |     6.2
   48 |   0.6696 |     20.600 |   0.9856 |     29.473 |     6.3
   49 |   0.6654 |     20.725 |   1.0030 |     30.392 |     6.5
   50 |   0.6575 |     20.557 |   0.9751 |     29.136 |     6.6
   51 |   0.6463 |     20.102 |   0.9851 |     29.412 |     6.7
   52 |   0.6418 |     19.733 |   0.9828 |     28.891 |     6.9
   53 |   0.6358 |     19.663 |   0.9951 |     29.259 |     7.0
   54 |   0.6229 |     19.164 |   0.9863 |     28.830 |     7.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5756 |     46.597 |   1.2601 |     40.196 |     0.1
    2 |   1.1903 |     39.353 |   1.1473 |     38.266 |     0.2
    3 |   1.0885 |     36.319 |   1.0545 |     36.244 |     0.3
    4 |   1.0031 |     34.146 |   1.0079 |     33.211 |     0.4
    5 |   0.9348 |     31.296 |   0.9269 |     30.913 |     0.5
    6 |   0.8883 |     30.370 |   0.8768 |     29.779 |     0.6
    7 |   0.8331 |     27.975 |   0.8997 |     29.657 |     0.8
    8 |   0.7919 |     27.059 |   0.8507 |     28.370 |     0.9
    9 |   0.7451 |     25.477 |   0.8574 |     28.707 |     1.0
   10 |   0.7144 |     24.464 |   0.8065 |     26.654 |     1.1
   11 |   0.6819 |     23.385 |   0.8057 |     26.838 |     1.2
   12 |   0.6590 |     22.621 |   0.8118 |     26.685 |     1.3
   13 |   0.6417 |     22.204 |   0.7808 |     25.184 |     1.4
   14 |   0.6198 |     21.402 |   0.7436 |     24.602 |     1.5
   15 |   0.5862 |     19.934 |   0.7654 |     24.663 |     1.6
   16 |   0.5529 |     19.045 |   0.7650 |     24.724 |     1.7
   17 |   0.5353 |     18.509 |   0.7541 |     24.265 |     1.8
   18 |   0.5172 |     17.913 |   0.7675 |     23.836 |     1.9
   19 |   0.4890 |     17.241 |   0.7433 |     24.050 |     2.1
   20 |   0.4857 |     17.051 |   0.7944 |     23.560 |     2.2
   21 |   0.4689 |     16.379 |   0.7797 |     23.866 |     2.3
   22 |   0.4530 |     15.740 |   0.7615 |     23.100 |     2.4
   23 |   0.4264 |     15.150 |   0.7595 |     23.070 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 420,322

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6601 |     65.052 |   1.9701 |     46.140 |     0.2
    2 |   1.8537 |     46.077 |   1.5810 |     44.577 |     0.3
    3 |   1.5965 |     44.923 |   1.4578 |     43.689 |     0.5
    4 |   1.4741 |     43.341 |   1.3752 |     41.973 |     0.6
    5 |   1.3945 |     41.618 |   1.3128 |     39.522 |     0.8
    6 |   1.3321 |     40.231 |   1.2659 |     38.021 |     1.0
    7 |   1.2782 |     38.979 |   1.2299 |     37.439 |     1.1
    8 |   1.2347 |     37.711 |   1.2017 |     35.999 |     1.3
    9 |   1.1965 |     36.785 |   1.1606 |     34.620 |     1.4
   10 |   1.1529 |     35.620 |   1.1408 |     34.528 |     1.6
   11 |   1.1257 |     34.672 |   1.1193 |     34.498 |     1.8
   12 |   1.0949 |     34.021 |   1.0975 |     32.996 |     1.9
   13 |   1.0565 |     32.282 |   1.0823 |     32.445 |     2.1
   14 |   1.0272 |     31.437 |   1.0682 |     32.629 |     2.2
   15 |   1.0031 |     31.052 |   1.0554 |     32.537 |     2.4
   16 |   0.9798 |     30.180 |   1.0338 |     31.403 |     2.6
   17 |   0.9508 |     29.389 |   1.0355 |     31.740 |     2.7
   18 |   0.9357 |     28.923 |   1.0135 |     31.189 |     2.9
   19 |   0.9081 |     28.451 |   1.0051 |     31.740 |     3.1
   20 |   0.8842 |     27.682 |   0.9916 |     30.974 |     3.2
   21 |   0.8639 |     26.896 |   0.9937 |     30.790 |     3.4
   22 |   0.8434 |     26.355 |   0.9922 |     31.434 |     3.5
   23 |   0.8315 |     26.355 |   0.9825 |     30.208 |     3.7
   24 |   0.8091 |     25.374 |   0.9736 |     30.208 |     3.9
   25 |   0.7961 |     25.228 |   0.9741 |     29.994 |     4.0
   26 |   0.7816 |     24.837 |   0.9768 |     30.055 |     4.2
   27 |   0.7652 |     24.339 |   0.9679 |     29.841 |     4.3
   28 |   0.7495 |     23.705 |   0.9632 |     29.718 |     4.5
   29 |   0.7387 |     23.196 |   0.9531 |     28.983 |     4.7
   30 |   0.7255 |     22.719 |   0.9528 |     29.197 |     4.8
   31 |   0.7142 |     22.535 |   0.9586 |     29.167 |     5.0
   32 |   0.7017 |     22.426 |   0.9646 |     29.105 |     5.2
   33 |   0.6856 |     21.814 |   0.9676 |     29.044 |     5.3
   34 |   0.6722 |     21.440 |   0.9559 |     29.228 |     5.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,642

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1393 |     55.781 |   1.4460 |     43.995 |     0.2
    2 |   1.4365 |     43.612 |   1.2982 |     40.533 |     0.4
    3 |   1.3086 |     40.480 |   1.2066 |     37.898 |     0.6
    4 |   1.2231 |     37.993 |   1.1413 |     35.723 |     0.8
    5 |   1.1470 |     35.950 |   1.1021 |     35.784 |     1.0
    6 |   1.0805 |     34.244 |   1.0519 |     33.609 |     1.2
    7 |   1.0268 |     32.531 |   1.0198 |     32.966 |     1.4
    8 |   0.9751 |     30.971 |   0.9864 |     31.403 |     1.7
    9 |   0.9222 |     29.042 |   0.9475 |     30.208 |     1.9
   10 |   0.8796 |     27.687 |   0.9470 |     30.699 |     2.1
   11 |   0.8448 |     26.880 |   0.9168 |     28.983 |     2.3
   12 |   0.8086 |     25.645 |   0.8968 |     28.860 |     2.5
   13 |   0.7697 |     24.306 |   0.8822 |     26.961 |     2.7
   14 |   0.7361 |     23.364 |   0.8785 |     27.390 |     2.9
   15 |   0.7062 |     22.334 |   0.8743 |     26.593 |     3.1
   16 |   0.6836 |     21.446 |   0.8665 |     26.471 |     3.3
   17 |   0.6523 |     20.611 |   0.8550 |     25.582 |     3.5
   18 |   0.6271 |     20.031 |   0.8470 |     25.368 |     3.7
   19 |   0.6042 |     19.511 |   0.8535 |     26.011 |     3.9
   20 |   0.5758 |     18.493 |   0.8619 |     25.490 |     4.1
   21 |   0.5550 |     17.935 |   0.8567 |     25.858 |     4.4
   22 |   0.5382 |     17.490 |   0.8542 |     24.755 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9512 |     51.566 |   1.4224 |     43.474 |     0.2
    2 |   1.3273 |     40.632 |   1.2503 |     38.113 |     0.4
    3 |   1.1938 |     36.996 |   1.1475 |     35.202 |     0.5
    4 |   1.0813 |     33.718 |   1.0839 |     33.640 |     0.7
    5 |   0.9968 |     31.074 |   1.0272 |     31.158 |     0.9
    6 |   0.9254 |     29.080 |   0.9846 |     31.556 |     1.1
    7 |   0.8607 |     27.075 |   0.9416 |     29.289 |     1.3
    8 |   0.7960 |     25.098 |   0.9191 |     29.259 |     1.5
    9 |   0.7431 |     23.234 |   0.8901 |     28.094 |     1.6
   10 |   0.7038 |     22.117 |   0.8526 |     26.716 |     1.8
   11 |   0.6492 |     20.221 |   0.8418 |     26.225 |     2.0
   12 |   0.6174 |     19.528 |   0.8607 |     26.930 |     2.2
   13 |   0.5716 |     18.130 |   0.8027 |     24.847 |     2.4
   14 |   0.5318 |     16.802 |   0.8129 |     24.724 |     2.6
   15 |   0.5014 |     15.849 |   0.8236 |     24.724 |     2.7
   16 |   0.4757 |     15.014 |   0.8385 |     24.602 |     2.9
   17 |   0.4475 |     14.326 |   0.8294 |     24.112 |     3.1
   18 |   0.4306 |     14.147 |   0.7882 |     23.162 |     3.3
   19 |   0.4023 |     12.863 |   0.7983 |     24.081 |     3.5
   20 |   0.3811 |     12.121 |   0.8126 |     24.020 |     3.7
   21 |   0.3609 |     11.498 |   0.7986 |     22.488 |     3.8
   22 |   0.3451 |     11.200 |   0.8272 |     23.989 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,126,754

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5438 |     46.494 |   1.2557 |     41.268 |     0.1
    2 |   1.1811 |     39.326 |   1.1099 |     36.029 |     0.2
    3 |   1.0707 |     35.918 |   1.0289 |     33.364 |     0.4
    4 |   0.9927 |     33.512 |   0.9791 |     33.211 |     0.5
    5 |   0.9417 |     31.843 |   0.9508 |     31.955 |     0.6
    6 |   0.8756 |     29.914 |   0.9176 |     31.158 |     0.7
    7 |   0.8291 |     28.305 |   0.8731 |     28.830 |     0.9
    8 |   0.7976 |     26.869 |   0.8819 |     29.228 |     1.0
    9 |   0.7628 |     26.290 |   0.8712 |     29.228 |     1.1
   10 |   0.7220 |     24.567 |   0.8919 |     29.565 |     1.2
   11 |   0.7190 |     24.599 |   0.8116 |     27.298 |     1.4
   12 |   0.6794 |     23.375 |   0.8252 |     26.808 |     1.5
   13 |   0.6414 |     21.966 |   0.8186 |     26.532 |     1.6
   14 |   0.6207 |     21.456 |   0.8102 |     25.276 |     1.7
   15 |   0.6073 |     20.741 |   0.7772 |     25.031 |     1.9
   16 |   0.5973 |     20.709 |   0.8162 |     26.348 |     2.0
   17 |   0.5740 |     20.151 |   0.7743 |     25.184 |     2.1
   18 |   0.5568 |     19.278 |   0.7968 |     25.613 |     2.2
   19 |   0.5354 |     18.617 |   0.7828 |     25.490 |     2.4
   20 |   0.5234 |     18.476 |   0.7876 |     24.847 |     2.5
   21 |   0.5126 |     18.070 |   0.7766 |     23.254 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 118,146

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.1853 |     81.735 |   2.7799 |     67.678 |     0.1
    2 |   2.6374 |     58.046 |   2.3602 |     48.499 |     0.2
    3 |   2.3017 |     49.344 |   2.0774 |     48.162 |     0.3
    4 |   2.0660 |     48.450 |   1.8819 |     48.100 |     0.4
    5 |   1.8884 |     47.540 |   1.7350 |     46.324 |     0.5
    6 |   1.7532 |     46.218 |   1.6231 |     44.087 |     0.7
    7 |   1.6540 |     45.199 |   1.5515 |     44.853 |     0.8
    8 |   1.5752 |     44.365 |   1.4823 |     42.402 |     0.9
    9 |   1.5161 |     43.590 |   1.4388 |     42.034 |     1.0
   10 |   1.4645 |     42.696 |   1.3978 |     40.748 |     1.1
   11 |   1.4182 |     41.938 |   1.3671 |     40.043 |     1.2
   12 |   1.3877 |     41.147 |   1.3428 |     40.441 |     1.3
   13 |   1.3556 |     40.480 |   1.3160 |     39.032 |     1.4
   14 |   1.3215 |     39.982 |   1.2904 |     38.480 |     1.5
   15 |   1.2963 |     39.050 |   1.2700 |     38.327 |     1.6
   16 |   1.2735 |     38.486 |   1.2563 |     37.653 |     1.7
   17 |   1.2503 |     37.961 |   1.2467 |     37.132 |     1.9
   18 |   1.2273 |     37.283 |   1.2377 |     37.286 |     2.0
   19 |   1.2099 |     36.866 |   1.2153 |     36.581 |     2.1
   20 |   1.1930 |     36.362 |   1.2112 |     36.703 |     2.2
   21 |   1.1726 |     36.010 |   1.2053 |     36.642 |     2.3
   22 |   1.1568 |     35.533 |   1.1900 |     36.305 |     2.4
   23 |   1.1406 |     35.132 |   1.1845 |     36.060 |     2.5
   24 |   1.1270 |     34.737 |   1.1786 |     35.723 |     2.6
   25 |   1.1143 |     34.173 |   1.1710 |     35.509 |     2.7
   26 |   1.1003 |     33.908 |   1.1696 |     36.152 |     2.8
   27 |   1.0847 |     33.718 |   1.1601 |     34.988 |     2.9
   28 |   1.0786 |     33.501 |   1.1581 |     35.723 |     3.1
   29 |   1.0650 |     33.106 |   1.1555 |     36.060 |     3.2
   30 |   1.0525 |     32.819 |   1.1509 |     35.018 |     3.3
   31 |   1.0355 |     32.179 |   1.1465 |     35.600 |     3.4
   32 |   1.0313 |     32.109 |   1.1535 |     35.754 |     3.5
   33 |   1.0184 |     32.082 |   1.1599 |     35.386 |     3.6
   34 |   1.0113 |     31.697 |   1.1487 |     35.539 |     3.7
   35 |   0.9987 |     31.307 |   1.1338 |     34.620 |     3.8
   36 |   0.9863 |     31.345 |   1.1423 |     35.049 |     3.9
   37 |   0.9767 |     30.884 |   1.1447 |     35.202 |     4.0
   38 |   0.9744 |     30.922 |   1.1342 |     34.651 |     4.1
   39 |   0.9632 |     30.527 |   1.1426 |     34.865 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 353,378

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7524 |     70.302 |   2.0558 |     49.939 |     0.1
    2 |   1.8817 |     46.662 |   1.5814 |     44.210 |     0.2
    3 |   1.5963 |     44.392 |   1.4488 |     42.494 |     0.3
    4 |   1.4814 |     43.059 |   1.3683 |     41.299 |     0.4
    5 |   1.4019 |     42.019 |   1.3100 |     39.553 |     0.5
    6 |   1.3405 |     40.832 |   1.2571 |     38.542 |     0.6
    7 |   1.2871 |     39.391 |   1.2199 |     37.531 |     0.7
    8 |   1.2397 |     38.204 |   1.1873 |     36.244 |     0.8
    9 |   1.1995 |     37.164 |   1.1540 |     35.938 |     0.9
   10 |   1.1645 |     36.232 |   1.1274 |     35.386 |     1.0
   11 |   1.1330 |     35.197 |   1.1000 |     34.467 |     1.1
   12 |   1.0998 |     34.460 |   1.0887 |     33.762 |     1.2
   13 |   1.0752 |     33.230 |   1.0661 |     33.701 |     1.3
   14 |   1.0474 |     32.559 |   1.0548 |     33.272 |     1.4
   15 |   1.0197 |     32.017 |   1.0372 |     32.904 |     1.5
   16 |   1.0017 |     31.285 |   1.0273 |     32.537 |     1.6
   17 |   0.9697 |     30.483 |   1.0075 |     32.169 |     1.7
   18 |   0.9565 |     30.077 |   0.9970 |     31.464 |     1.8
   19 |   0.9282 |     29.232 |   0.9844 |     30.913 |     1.9
   20 |   0.9155 |     29.134 |   0.9814 |     31.495 |     2.0
   21 |   0.8939 |     28.386 |   0.9717 |     30.576 |     2.1
   22 |   0.8820 |     27.769 |   0.9639 |     29.963 |     2.2
   23 |   0.8515 |     27.129 |   0.9497 |     29.963 |     2.3
   24 |   0.8360 |     26.523 |   0.9462 |     30.178 |     2.4
   25 |   0.8319 |     26.197 |   0.9492 |     30.239 |     2.5
   26 |   0.8067 |     25.905 |   0.9391 |     29.688 |     2.6
   27 |   0.7972 |     25.412 |   0.9274 |     29.381 |     2.7
   28 |   0.7727 |     24.740 |   0.9340 |     29.167 |     2.8
   29 |   0.7672 |     24.859 |   0.9337 |     29.197 |     2.9
   30 |   0.7533 |     24.263 |   0.9233 |     29.473 |     3.0
   31 |   0.7362 |     24.155 |   0.9179 |     29.197 |     3.1
   32 |   0.7259 |     23.028 |   0.9058 |     28.493 |     3.2
   33 |   0.7165 |     23.098 |   0.9091 |     28.248 |     3.3
   34 |   0.7058 |     22.833 |   0.9199 |     27.972 |     3.4
   35 |   0.6814 |     22.139 |   0.8995 |     27.819 |     3.5
   36 |   0.6749 |     21.695 |   0.9149 |     28.156 |     3.6
   37 |   0.6761 |     21.760 |   0.8975 |     27.941 |     3.7
   38 |   0.6630 |     21.489 |   0.9034 |     27.328 |     3.8
   39 |   0.6499 |     20.757 |   0.8996 |     27.696 |     3.9
   40 |   0.6498 |     21.126 |   0.9034 |     26.930 |     4.0
   41 |   0.6284 |     20.557 |   0.9055 |     26.685 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 362,530

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6573 |     47.616 |   1.3050 |     41.850 |     0.1
    2 |   1.2178 |     40.009 |   1.1575 |     38.174 |     0.2
    3 |   1.1017 |     36.817 |   1.0647 |     34.896 |     0.3
    4 |   1.0218 |     34.650 |   1.0029 |     33.211 |     0.4
    5 |   0.9512 |     31.740 |   0.9423 |     31.526 |     0.5
    6 |   0.8879 |     29.963 |   0.9260 |     29.871 |     0.6
    7 |   0.8527 |     28.609 |   0.8876 |     29.933 |     0.7
    8 |   0.7972 |     26.983 |   0.8731 |     28.922 |     0.8
    9 |   0.7608 |     25.829 |   0.8498 |     28.585 |     0.9
   10 |   0.7339 |     25.000 |   0.8254 |     27.267 |     1.0
   11 |   0.6942 |     23.748 |   0.8478 |     28.125 |     1.1
   12 |   0.6738 |     23.001 |   0.8104 |     27.543 |     1.2
   13 |   0.6369 |     21.955 |   0.8085 |     26.103 |     1.3
   14 |   0.6159 |     21.083 |   0.8237 |     26.379 |     1.4
   15 |   0.6056 |     20.682 |   0.8260 |     26.164 |     1.5
   16 |   0.5920 |     20.346 |   0.7784 |     25.582 |     1.6
   17 |   0.5588 |     19.029 |   0.7937 |     25.735 |     1.8
   18 |   0.5359 |     18.585 |   0.8056 |     25.276 |     1.9
   19 |   0.5258 |     18.336 |   0.8082 |     24.694 |     2.0
   20 |   0.4966 |     17.387 |   0.7853 |     24.602 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 744,738

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5666 |     63.286 |   1.8039 |     48.009 |     0.1
    2 |   1.7258 |     45.915 |   1.4268 |     42.157 |     0.2
    3 |   1.4716 |     43.791 |   1.3162 |     39.890 |     0.3
    4 |   1.3573 |     41.547 |   1.2532 |     38.848 |     0.3
    5 |   1.2895 |     40.009 |   1.2103 |     37.408 |     0.4
    6 |   1.2359 |     38.389 |   1.1844 |     35.846 |     0.5
    7 |   1.1916 |     37.348 |   1.1623 |     36.060 |     0.6
    8 |   1.1506 |     35.999 |   1.1327 |     35.355 |     0.7
    9 |   1.1145 |     35.235 |   1.1123 |     35.294 |     0.8
   10 |   1.0799 |     34.016 |   1.1052 |     34.559 |     0.9
   11 |   1.0509 |     33.149 |   1.0801 |     33.364 |     0.9
   12 |   1.0274 |     32.261 |   1.0643 |     32.904 |     1.0
   13 |   1.0064 |     32.017 |   1.0504 |     32.966 |     1.1
   14 |   0.9796 |     31.469 |   1.0614 |     33.670 |     1.2
   15 |   0.9589 |     30.760 |   1.0327 |     32.629 |     1.3
   16 |   0.9351 |     30.028 |   1.0209 |     31.740 |     1.4
   17 |   0.9134 |     29.210 |   1.0087 |     31.801 |     1.5
   18 |   0.8913 |     28.820 |   1.0122 |     32.138 |     1.6
   19 |   0.8787 |     28.153 |   1.0110 |     31.250 |     1.6
   20 |   0.8558 |     27.449 |   1.0083 |     31.189 |     1.7
   21 |   0.8381 |     26.853 |   0.9971 |     32.322 |     1.8
   22 |   0.8285 |     26.923 |   0.9943 |     31.066 |     1.9
   23 |   0.8126 |     26.149 |   0.9810 |     29.841 |     2.0
   24 |   0.7918 |     25.677 |   1.0027 |     30.668 |     2.1
   25 |   0.7811 |     25.471 |   0.9754 |     29.994 |     2.2
   26 |   0.7731 |     25.368 |   0.9728 |     29.105 |     2.2
   27 |   0.7586 |     25.146 |   0.9641 |     29.013 |     2.3
   28 |   0.7416 |     24.371 |   0.9764 |     29.688 |     2.4
   29 |   0.7293 |     23.998 |   0.9766 |     29.350 |     2.5
   30 |   0.7192 |     23.412 |   0.9851 |     29.381 |     2.6
   31 |   0.7123 |     23.277 |   0.9799 |     29.841 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 977,314

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6336 |     48.499 |   1.2875 |     41.605 |     0.1
    2 |   1.2749 |     42.051 |   1.1842 |     38.174 |     0.2
    3 |   1.1848 |     39.846 |   1.1456 |     36.428 |     0.4
    4 |   1.1361 |     38.004 |   1.1425 |     36.275 |     0.5
    5 |   1.0939 |     36.546 |   1.1209 |     36.152 |     0.6
    6 |   1.0592 |     35.593 |   1.0826 |     35.876 |     0.7
    7 |   1.0114 |     33.935 |   1.0371 |     33.915 |     0.9
    8 |   0.9808 |     32.987 |   1.0445 |     33.425 |     1.0
    9 |   0.9606 |     32.418 |   1.0593 |     34.252 |     1.1
   10 |   0.9307 |     31.702 |   1.0669 |     33.793 |     1.2
   11 |   0.8936 |     30.212 |   1.0916 |     34.804 |     1.3
   12 |   0.8851 |     29.909 |   1.0001 |     32.016 |     1.5
   13 |   0.8437 |     28.522 |   0.9848 |     31.127 |     1.6
   14 |   0.8171 |     27.915 |   1.0285 |     32.292 |     1.7
   15 |   0.8018 |     27.454 |   1.0348 |     32.445 |     1.8
   16 |   0.7756 |     26.528 |   1.0303 |     32.169 |     1.9
   17 |   0.7676 |     26.241 |   1.0291 |     32.108 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 744,738

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6090 |     47.844 |   1.2592 |     39.890 |     0.1
    2 |   1.2424 |     40.653 |   1.1535 |     36.857 |     0.2
    3 |   1.1544 |     38.123 |   1.1094 |     36.673 |     0.3
    4 |   1.0890 |     36.400 |   1.0675 |     35.692 |     0.3
    5 |   1.0304 |     34.639 |   1.0234 |     33.487 |     0.4
    6 |   0.9873 |     33.155 |   1.0176 |     33.517 |     0.5
    7 |   0.9590 |     32.076 |   1.0008 |     33.395 |     0.6
    8 |   0.9181 |     30.928 |   1.0202 |     33.180 |     0.7
    9 |   0.8873 |     30.017 |   0.9973 |     32.966 |     0.8
   10 |   0.8609 |     28.934 |   0.9738 |     32.506 |     0.9
   11 |   0.8343 |     28.479 |   0.9888 |     32.659 |     0.9
   12 |   0.7961 |     27.292 |   0.9833 |     32.230 |     1.0
   13 |   0.7757 |     26.187 |   1.0092 |     32.537 |     1.1
   14 |   0.7586 |     25.932 |   0.9976 |     32.169 |     1.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,126,754

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6394 |     48.981 |   1.2672 |     41.115 |     0.2
    2 |   1.2270 |     40.334 |   1.1291 |     37.684 |     0.3
    3 |   1.1264 |     37.533 |   1.0814 |     35.662 |     0.5
    4 |   1.0650 |     35.354 |   1.0246 |     33.670 |     0.6
    5 |   1.0070 |     33.751 |   1.0035 |     33.395 |     0.8
    6 |   0.9730 |     32.683 |   0.9548 |     31.097 |     1.0
    7 |   0.9289 |     31.020 |   0.9329 |     31.189 |     1.1
    8 |   0.8926 |     30.326 |   0.9442 |     31.189 |     1.3
    9 |   0.8656 |     29.221 |   0.9538 |     32.016 |     1.4
   10 |   0.8338 |     28.636 |   0.9204 |     30.821 |     1.6
   11 |   0.8003 |     27.221 |   0.9080 |     30.882 |     1.8
   12 |   0.7822 |     26.566 |   0.9163 |     30.300 |     1.9
   13 |   0.7611 |     26.029 |   0.9049 |     30.055 |     2.1
   14 |   0.7327 |     25.282 |   0.9304 |     30.515 |     2.2
   15 |   0.7220 |     24.464 |   0.8956 |     29.963 |     2.4
   16 |   0.7031 |     23.949 |   0.8738 |     29.228 |     2.6
   17 |   0.6760 |     23.445 |   0.8693 |     28.125 |     2.7
   18 |   0.6747 |     23.011 |   0.8879 |     29.902 |     2.9
   19 |   0.6425 |     22.285 |   0.8798 |     29.013 |     3.0
   20 |   0.6199 |     21.608 |   0.9016 |     28.830 |     3.2
   21 |   0.6056 |     20.736 |   0.9238 |     29.442 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 126,690

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.0561 |     74.491 |   2.6651 |     60.938 |     0.1
    2 |   2.3928 |     55.527 |   2.1562 |     48.254 |     0.2
    3 |   2.0028 |     46.890 |   1.8744 |     45.864 |     0.2
    4 |   1.7859 |     44.609 |   1.7095 |     43.413 |     0.3
    5 |   1.6480 |     43.455 |   1.6010 |     43.076 |     0.4
    6 |   1.5510 |     42.837 |   1.5213 |     42.678 |     0.5
    7 |   1.4753 |     42.078 |   1.4637 |     42.279 |     0.6
    8 |   1.4177 |     41.417 |   1.4121 |     41.238 |     0.7
    9 |   1.3673 |     40.285 |   1.3805 |     41.115 |     0.7
   10 |   1.3231 |     39.380 |   1.3405 |     39.767 |     0.8
   11 |   1.2855 |     38.687 |   1.3144 |     39.767 |     0.9
   12 |   1.2486 |     37.663 |   1.2810 |     38.419 |     1.0
   13 |   1.2190 |     36.904 |   1.2652 |     38.143 |     1.1
   14 |   1.1903 |     36.015 |   1.2313 |     37.500 |     1.2
   15 |   1.1659 |     35.181 |   1.2211 |     36.979 |     1.2
   16 |   1.1376 |     34.206 |   1.2014 |     36.642 |     1.3
   17 |   1.1163 |     33.604 |   1.1878 |     36.826 |     1.4
   18 |   1.0939 |     33.106 |   1.1674 |     35.539 |     1.5
   19 |   1.0704 |     32.309 |   1.1512 |     34.896 |     1.6
   20 |   1.0518 |     32.082 |   1.1451 |     35.570 |     1.6
   21 |   1.0352 |     31.329 |   1.1319 |     35.049 |     1.7
   22 |   1.0162 |     31.009 |   1.1176 |     34.743 |     1.8
   23 |   0.9983 |     30.603 |   1.1113 |     34.344 |     1.9
   24 |   0.9847 |     29.925 |   1.0991 |     33.762 |     2.0
   25 |   0.9652 |     29.438 |   1.0941 |     33.793 |     2.1
   26 |   0.9514 |     29.058 |   1.0964 |     33.762 |     2.1
   27 |   0.9320 |     28.674 |   1.0781 |     33.762 |     2.2
   28 |   0.9205 |     28.305 |   1.0622 |     32.598 |     2.3
   29 |   0.9065 |     27.758 |   1.0639 |     33.058 |     2.4
   30 |   0.8911 |     27.406 |   1.0641 |     33.578 |     2.5
   31 |   0.8780 |     27.129 |   1.0560 |     33.364 |     2.6
   32 |   0.8689 |     26.756 |   1.0429 |     33.364 |     2.6
   33 |   0.8561 |     26.550 |   1.0357 |     32.414 |     2.7
   34 |   0.8423 |     26.019 |   1.0410 |     32.016 |     2.8
   35 |   0.8337 |     25.959 |   1.0358 |     31.832 |     2.9
   36 |   0.8184 |     25.331 |   1.0249 |     31.373 |     3.0
   37 |   0.8069 |     24.897 |   1.0329 |     32.108 |     3.0
   38 |   0.7987 |     24.594 |   1.0242 |     31.832 |     3.1
   39 |   0.7908 |     24.637 |   1.0216 |     32.016 |     3.2
   40 |   0.7772 |     24.079 |   1.0156 |     32.200 |     3.3
   41 |   0.7719 |     23.884 |   1.0086 |     31.434 |     3.4
   42 |   0.7607 |     23.700 |   1.0175 |     31.648 |     3.5
   43 |   0.7530 |     23.418 |   1.0087 |     31.219 |     3.5
   44 |   0.7449 |     23.044 |   1.0032 |     31.158 |     3.6
   45 |   0.7368 |     23.022 |   1.0082 |     30.668 |     3.7
   46 |   0.7285 |     22.518 |   1.0214 |     31.495 |     3.8
   47 |   0.7148 |     22.085 |   1.0066 |     30.974 |     3.9
   48 |   0.7141 |     22.340 |   1.0054 |     30.852 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,586

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0446 |     52.660 |   1.4986 |     43.934 |     0.1
    2 |   1.3838 |     42.339 |   1.2940 |     37.469 |     0.3
    3 |   1.2268 |     37.928 |   1.1917 |     36.520 |     0.4
    4 |   1.1188 |     34.932 |   1.0986 |     33.609 |     0.6
    5 |   1.0348 |     32.472 |   1.0480 |     33.272 |     0.7
    6 |   0.9679 |     30.651 |   1.0003 |     30.790 |     0.8
    7 |   0.8969 |     28.609 |   0.9944 |     31.434 |     1.0
    8 |   0.8457 |     26.582 |   0.9471 |     30.576 |     1.1
    9 |   0.7959 |     25.217 |   0.9308 |     29.412 |     1.3
   10 |   0.7512 |     23.759 |   0.9128 |     28.401 |     1.4
   11 |   0.7178 |     22.573 |   0.9006 |     28.125 |     1.6
   12 |   0.6716 |     21.164 |   0.8737 |     26.532 |     1.7
   13 |   0.6386 |     20.069 |   0.8506 |     26.991 |     1.8
   14 |   0.6014 |     19.045 |   0.8589 |     26.746 |     2.0
   15 |   0.5750 |     18.433 |   0.8460 |     26.593 |     2.1
   16 |   0.5443 |     17.030 |   0.8502 |     26.440 |     2.3
   17 |   0.5156 |     16.379 |   0.8292 |     24.908 |     2.4
   18 |   0.4905 |     15.659 |   0.8286 |     25.490 |     2.5
   19 |   0.4666 |     14.949 |   0.8256 |     24.969 |     2.7
   20 |   0.4426 |     13.855 |   0.8556 |     25.705 |     2.8
   21 |   0.4294 |     13.486 |   0.8223 |     24.020 |     3.0
   22 |   0.4129 |     13.242 |   0.8081 |     24.449 |     3.1
   23 |   0.3837 |     12.289 |   0.8279 |     23.989 |     3.2
   24 |   0.3744 |     11.980 |   0.8227 |     23.591 |     3.4
   25 |   0.3551 |     11.357 |   0.8394 |     24.602 |     3.5
   26 |   0.3448 |     11.118 |   0.8178 |     23.989 |     3.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 152,354

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9138 |     49.664 |   1.4135 |     42.402 |     0.1
    2 |   1.3209 |     41.699 |   1.2393 |     38.113 |     0.2
    3 |   1.1882 |     38.172 |   1.1581 |     36.918 |     0.3
    4 |   1.0927 |     35.755 |   1.0824 |     34.804 |     0.4
    5 |   1.0320 |     33.631 |   1.0246 |     33.150 |     0.5
    6 |   0.9623 |     31.925 |   0.9827 |     32.322 |     0.6
    7 |   0.9168 |     30.321 |   0.9627 |     32.108 |     0.7
    8 |   0.8728 |     28.614 |   0.9756 |     32.230 |     0.8
    9 |   0.8347 |     27.926 |   0.8854 |     28.707 |     0.9
   10 |   0.7801 |     26.002 |   0.8748 |     29.259 |     1.0
   11 |   0.7600 |     25.536 |   0.8651 |     29.228 |     1.1
   12 |   0.7328 |     24.507 |   0.8357 |     26.654 |     1.2
   13 |   0.6996 |     23.499 |   0.8389 |     26.777 |     1.3
   14 |   0.6833 |     23.114 |   0.8413 |     27.390 |     1.3
   15 |   0.6523 |     21.852 |   0.8295 |     27.911 |     1.4
   16 |   0.6327 |     21.456 |   0.8173 |     26.654 |     1.5
   17 |   0.6089 |     20.665 |   0.8090 |     25.858 |     1.6
   18 |   0.5904 |     20.134 |   0.8389 |     27.114 |     1.7
   19 |   0.5812 |     19.425 |   0.8017 |     25.398 |     1.8
   20 |   0.5500 |     18.812 |   0.7916 |     25.643 |     1.9
   21 |   0.5357 |     18.070 |   0.8241 |     27.175 |     2.0
   22 |   0.5557 |     18.910 |   0.7965 |     25.460 |     2.1
   23 |   0.5172 |     17.750 |   0.7836 |     25.092 |     2.2
   24 |   0.4974 |     17.127 |   0.7817 |     24.510 |     2.3
   25 |   0.4838 |     16.542 |   0.8000 |     24.602 |     2.4
   26 |   0.4747 |     16.141 |   0.7845 |     23.897 |     2.5
   27 |   0.4636 |     16.081 |   0.7984 |     24.939 |     2.6
   28 |   0.4634 |     16.136 |   0.7821 |     24.571 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1252 |     55.337 |   1.4623 |     43.229 |     0.2
    2 |   1.4372 |     43.357 |   1.2969 |     39.216 |     0.3
    3 |   1.3047 |     40.160 |   1.2141 |     37.255 |     0.5
    4 |   1.2092 |     37.560 |   1.1380 |     34.681 |     0.6
    5 |   1.1410 |     35.414 |   1.0936 |     34.589 |     0.8
    6 |   1.0796 |     34.168 |   1.0606 |     33.364 |     0.9
    7 |   1.0295 |     32.195 |   1.0236 |     32.261 |     1.1
    8 |   0.9677 |     30.700 |   0.9934 |     31.373 |     1.2
    9 |   0.9327 |     29.681 |   0.9725 |     30.270 |     1.4
   10 |   0.8807 |     27.422 |   0.9510 |     29.749 |     1.6
   11 |   0.8494 |     26.479 |   0.9340 |     28.646 |     1.7
   12 |   0.8129 |     25.905 |   0.9189 |     29.197 |     1.9
   13 |   0.7738 |     24.724 |   0.9070 |     28.554 |     2.0
   14 |   0.7448 |     23.705 |   0.8930 |     27.083 |     2.2
   15 |   0.7125 |     22.833 |   0.9002 |     27.849 |     2.3
   16 |   0.6859 |     21.635 |   0.8731 |     26.348 |     2.5
   17 |   0.6548 |     20.893 |   0.8949 |     27.022 |     2.7
   18 |   0.6249 |     20.232 |   0.8905 |     26.225 |     2.8
   19 |   0.6128 |     19.945 |   0.8757 |     26.287 |     3.0
   20 |   0.5966 |     19.159 |   0.8771 |     26.072 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 138,946

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9447 |     50.363 |   1.4333 |     42.494 |     0.1
    2 |   1.3268 |     41.304 |   1.2568 |     39.675 |     0.2
    3 |   1.1910 |     37.988 |   1.1873 |     37.623 |     0.3
    4 |   1.1006 |     35.707 |   1.0732 |     34.191 |     0.4
    5 |   1.0172 |     33.566 |   1.0338 |     34.007 |     0.5
    6 |   0.9530 |     31.372 |   0.9809 |     33.027 |     0.6
    7 |   0.8912 |     29.410 |   0.9584 |     31.955 |     0.7
    8 |   0.8391 |     27.975 |   0.9147 |     29.810 |     0.8
    9 |   0.8013 |     26.625 |   0.8980 |     30.331 |     0.9
   10 |   0.7646 |     25.618 |   0.8858 |     29.473 |     1.0
   11 |   0.7340 |     24.366 |   0.8452 |     27.941 |     1.1
   12 |   0.6943 |     23.022 |   0.8559 |     27.911 |     1.2
   13 |   0.6676 |     22.470 |   0.8495 |     26.716 |     1.3
   14 |   0.6408 |     21.424 |   0.8067 |     26.716 |     1.4
   15 |   0.6137 |     20.454 |   0.8520 |     27.267 |     1.5
   16 |   0.6013 |     20.427 |   0.8217 |     25.705 |     1.6
   17 |   0.5748 |     19.360 |   0.8575 |     27.022 |     1.7
   18 |   0.5532 |     18.541 |   0.8041 |     25.061 |     1.8
   19 |   0.5289 |     18.016 |   0.8230 |     25.123 |     1.9
   20 |   0.5110 |     17.490 |   0.8382 |     26.409 |     2.0
   21 |   0.5095 |     17.490 |   0.8303 |     25.153 |     2.1
   22 |   0.4961 |     16.873 |   0.8189 |     24.571 |     2.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 270,114

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.0673 |     78.164 |   2.4954 |     59.957 |     0.1
    2 |   2.3740 |     56.025 |   1.9377 |     47.886 |     0.2
    3 |   1.9519 |     47.822 |   1.6541 |     45.527 |     0.3
    4 |   1.7153 |     45.855 |   1.5051 |     43.750 |     0.3
    5 |   1.5788 |     44.609 |   1.4283 |     42.831 |     0.4
    6 |   1.4947 |     43.796 |   1.3679 |     41.146 |     0.5
    7 |   1.4282 |     42.474 |   1.3271 |     40.472 |     0.6
    8 |   1.3812 |     41.829 |   1.3007 |     39.522 |     0.7
    9 |   1.3396 |     41.103 |   1.2663 |     38.450 |     0.8
   10 |   1.2998 |     40.047 |   1.2450 |     38.082 |     0.9
   11 |   1.2697 |     39.662 |   1.2180 |     37.837 |     1.0
   12 |   1.2442 |     38.762 |   1.1997 |     37.439 |     1.0
   13 |   1.2194 |     38.259 |   1.1947 |     37.010 |     1.1
   14 |   1.1938 |     37.695 |   1.1761 |     36.366 |     1.2
   15 |   1.1758 |     37.251 |   1.1698 |     36.520 |     1.3
   16 |   1.1541 |     36.395 |   1.1611 |     36.520 |     1.4
   17 |   1.1385 |     36.292 |   1.1459 |     36.091 |     1.5
   18 |   1.1183 |     35.322 |   1.1365 |     35.784 |     1.6
   19 |   1.1028 |     34.926 |   1.1295 |     35.692 |     1.7
   20 |   1.0873 |     34.520 |   1.1268 |     34.926 |     1.8
   21 |   1.0627 |     34.043 |   1.1257 |     35.172 |     1.8
   22 |   1.0549 |     33.745 |   1.1109 |     34.896 |     1.9
   23 |   1.0372 |     33.474 |   1.1009 |     34.436 |     2.0
   24 |   1.0215 |     32.634 |   1.1119 |     34.161 |     2.1
   25 |   1.0155 |     32.531 |   1.0971 |     34.559 |     2.2
   26 |   1.0006 |     32.163 |   1.1003 |     34.436 |     2.3
   27 |   0.9888 |     31.789 |   1.0844 |     34.038 |     2.4
   28 |   0.9686 |     31.144 |   1.0853 |     33.701 |     2.5
   29 |   0.9583 |     31.139 |   1.0757 |     33.578 |     2.5
   30 |   0.9465 |     30.229 |   1.0784 |     33.793 |     2.6
   31 |   0.9370 |     30.066 |   1.0733 |     33.548 |     2.7
   32 |   0.9266 |     29.763 |   1.0803 |     33.395 |     2.8
   33 |   0.9068 |     29.243 |   1.0705 |     33.241 |     2.9
   34 |   0.8975 |     29.042 |   1.0731 |     33.303 |     3.0
   35 |   0.8971 |     28.554 |   1.0715 |     33.456 |     3.1
   36 |   0.8788 |     28.495 |   1.0689 |     33.180 |     3.2
   37 |   0.8770 |     28.376 |   1.0671 |     32.782 |     3.2
   38 |   0.8615 |     27.910 |   1.0806 |     33.548 |     3.3
   39 |   0.8576 |     27.828 |   1.0698 |     32.904 |     3.4
   40 |   0.8436 |     27.449 |   1.0636 |     32.292 |     3.5
   41 |   0.8388 |     27.146 |   1.0672 |     32.353 |     3.6
   42 |   0.8288 |     26.810 |   1.0669 |     32.537 |     3.7
   43 |   0.8137 |     26.430 |   1.0568 |     32.047 |     3.8
   44 |   0.8161 |     26.474 |   1.0574 |     32.200 |     3.9
   45 |   0.8046 |     25.937 |   1.0641 |     32.230 |     3.9
   46 |   0.7918 |     25.867 |   1.0725 |     32.322 |     4.0
   47 |   0.7875 |     25.856 |   1.0654 |     32.138 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 435,938

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6236 |     62.500 |   1.8660 |     45.190 |     0.1
    2 |   1.7562 |     45.557 |   1.5388 |     43.597 |     0.2
    3 |   1.5366 |     43.839 |   1.4148 |     41.544 |     0.3
    4 |   1.4238 |     41.873 |   1.3320 |     39.706 |     0.4
    5 |   1.3484 |     40.404 |   1.2731 |     37.990 |     0.5
    6 |   1.2836 |     38.790 |   1.2213 |     36.428 |     0.6
    7 |   1.2305 |     37.365 |   1.1796 |     36.060 |     0.7
    8 |   1.1877 |     36.682 |   1.1504 |     35.417 |     0.8
    9 |   1.1465 |     35.230 |   1.1153 |     34.161 |     0.9
   10 |   1.1126 |     34.146 |   1.0815 |     33.241 |     1.0
   11 |   1.0732 |     32.900 |   1.0531 |     32.904 |     1.1
   12 |   1.0454 |     32.212 |   1.0266 |     31.464 |     1.2
   13 |   1.0118 |     31.551 |   1.0127 |     31.924 |     1.3
   14 |   0.9846 |     30.722 |   0.9957 |     31.679 |     1.4
   15 |   0.9596 |     29.936 |   0.9883 |     31.679 |     1.5
   16 |   0.9313 |     29.302 |   0.9625 |     30.607 |     1.6
   17 |   0.9100 |     28.289 |   0.9489 |     30.331 |     1.7
   18 |   0.8892 |     28.240 |   0.9437 |     29.933 |     1.8
   19 |   0.8645 |     27.259 |   0.9269 |     29.810 |     1.9
   20 |   0.8441 |     26.777 |   0.9242 |     29.013 |     2.0
   21 |   0.8248 |     26.127 |   0.9095 |     28.646 |     2.1
   22 |   0.8106 |     25.580 |   0.9005 |     28.615 |     2.2
   23 |   0.7910 |     25.087 |   0.8933 |     28.002 |     2.3
   24 |   0.7751 |     24.751 |   0.8892 |     27.420 |     2.4
   25 |   0.7571 |     23.775 |   0.8895 |     27.543 |     2.5
   26 |   0.7509 |     23.754 |   0.8763 |     27.727 |     2.6
   27 |   0.7319 |     23.201 |   0.8734 |     26.746 |     2.7
   28 |   0.7121 |     22.513 |   0.8797 |     27.328 |     2.8
   29 |   0.7044 |     22.269 |   0.8624 |     26.624 |     2.9
   30 |   0.6905 |     22.215 |   0.8527 |     25.490 |     3.0
   31 |   0.6777 |     21.798 |   0.8694 |     26.348 |     3.1
   32 |   0.6628 |     21.001 |   0.8570 |     26.685 |     3.2
   33 |   0.6513 |     20.622 |   0.8708 |     26.195 |     3.3
   34 |   0.6419 |     20.367 |   0.8553 |     26.042 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 976,418

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2732 |     56.908 |   1.5109 |     44.853 |     0.1
    2 |   1.4911 |     44.192 |   1.3299 |     41.789 |     0.2
    3 |   1.3478 |     41.347 |   1.2347 |     38.266 |     0.3
    4 |   1.2581 |     39.299 |   1.1732 |     36.550 |     0.4
    5 |   1.1909 |     37.034 |   1.1087 |     35.049 |     0.5
    6 |   1.1265 |     35.474 |   1.0773 |     33.977 |     0.6
    7 |   1.0721 |     33.805 |   1.0312 |     32.537 |     0.7
    8 |   1.0346 |     32.792 |   1.0119 |     32.659 |     0.8
    9 |   0.9916 |     31.540 |   0.9907 |     31.005 |     0.8
   10 |   0.9561 |     30.364 |   0.9646 |     31.281 |     0.9
   11 |   0.9228 |     29.438 |   0.9411 |     29.902 |     1.0
   12 |   0.8898 |     28.533 |   0.9267 |     30.331 |     1.1
   13 |   0.8599 |     27.454 |   0.9276 |     29.442 |     1.2
   14 |   0.8268 |     26.284 |   0.9076 |     28.676 |     1.3
   15 |   0.8089 |     25.910 |   0.8965 |     28.094 |     1.4
   16 |   0.7839 |     25.211 |   0.8981 |     29.044 |     1.5
   17 |   0.7588 |     24.583 |   0.8909 |     27.819 |     1.6
   18 |   0.7411 |     23.781 |   0.8712 |     28.248 |     1.7
   19 |   0.7182 |     22.898 |   0.8781 |     28.309 |     1.8
   20 |   0.7008 |     22.735 |   0.8606 |     27.145 |     1.9
   21 |   0.6735 |     21.782 |   0.8508 |     26.287 |     2.0
   22 |   0.6671 |     21.722 |   0.8600 |     26.685 |     2.1
   23 |   0.6422 |     20.942 |   0.8536 |     26.256 |     2.2
   24 |   0.6279 |     20.427 |   0.8550 |     26.409 |     2.3
   25 |   0.6132 |     20.275 |   0.8537 |     26.164 |     2.4
   26 |   0.5921 |     19.338 |   0.8447 |     25.521 |     2.5
   27 |   0.5765 |     18.742 |   0.8389 |     25.613 |     2.6
   28 |   0.5701 |     18.677 |   0.8469 |     25.214 |     2.6
   29 |   0.5578 |     18.352 |   0.8548 |     25.551 |     2.7
   30 |   0.5461 |     17.891 |   0.8664 |     25.888 |     2.8
   31 |   0.5325 |     17.469 |   0.8615 |     25.582 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,126,754

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6969 |     49.464 |   1.3249 |     42.892 |     0.1
    2 |   1.2918 |     42.192 |   1.2066 |     38.542 |     0.3
    3 |   1.2144 |     39.992 |   1.1574 |     37.837 |     0.4
    4 |   1.1702 |     39.071 |   1.1291 |     36.826 |     0.5
    5 |   1.1147 |     37.321 |   1.1050 |     36.581 |     0.6
    6 |   1.0740 |     36.243 |   1.0800 |     35.846 |     0.8
    7 |   1.0358 |     34.850 |   1.0815 |     36.091 |     0.9
    8 |   1.0121 |     33.897 |   1.0782 |     36.673 |     1.0
    9 |   0.9950 |     33.507 |   1.0766 |     34.957 |     1.2
   10 |   0.9665 |     32.596 |   1.1317 |     37.592 |     1.3
   11 |   0.9289 |     31.594 |   1.1228 |     37.194 |     1.4
   12 |   0.9051 |     30.684 |   1.1176 |     35.478 |     1.5
   13 |   0.8864 |     30.272 |   1.0833 |     35.600 |     1.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,142,306

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5150 |     46.229 |   1.2363 |     40.227 |     0.1
    2 |   1.1625 |     38.567 |   1.1159 |     35.938 |     0.2
    3 |   1.0576 |     35.224 |   1.0271 |     33.456 |     0.3
    4 |   0.9799 |     33.106 |   0.9902 |     32.874 |     0.4
    5 |   0.9065 |     30.613 |   0.9280 |     30.300 |     0.5
    6 |   0.8457 |     28.842 |   0.8741 |     29.626 |     0.6
    7 |   0.7860 |     26.463 |   0.8646 |     28.615 |     0.7
    8 |   0.7622 |     25.997 |   0.8646 |     29.136 |     0.8
    9 |   0.7228 |     24.724 |   0.8528 |     27.298 |     0.9
   10 |   0.6907 |     23.570 |   0.8175 |     27.482 |     1.0
   11 |   0.6434 |     22.253 |   0.8153 |     26.593 |     1.1
   12 |   0.6220 |     21.532 |   0.8176 |     26.501 |     1.2
   13 |   0.5938 |     20.812 |   0.8000 |     25.858 |     1.3
   14 |   0.5573 |     19.284 |   0.8169 |     24.877 |     1.4
   15 |   0.5408 |     18.764 |   0.7750 |     24.112 |     1.5
   16 |   0.5070 |     17.566 |   0.8125 |     24.877 |     1.6
   17 |   0.4835 |     16.629 |   0.8376 |     26.011 |     1.7
   18 |   0.4932 |     17.078 |   0.8518 |     25.858 |     1.8
   19 |   0.4952 |     17.376 |   0.7842 |     23.591 |     1.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,009,698

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1459 |     55.055 |   1.5222 |     43.934 |     0.1
    2 |   1.4094 |     42.452 |   1.3162 |     39.185 |     0.3
    3 |   1.2543 |     38.692 |   1.2111 |     37.316 |     0.4
    4 |   1.1557 |     35.761 |   1.1389 |     35.018 |     0.5
    5 |   1.0771 |     33.555 |   1.0946 |     33.609 |     0.7
    6 |   1.0034 |     31.166 |   1.0583 |     33.303 |     0.8
    7 |   0.9474 |     29.871 |   1.0192 |     32.169 |     0.9
    8 |   0.8863 |     28.034 |   0.9877 |     30.453 |     1.1
    9 |   0.8382 |     26.078 |   0.9626 |     29.534 |     1.2
   10 |   0.7964 |     24.892 |   0.9531 |     29.963 |     1.3
   11 |   0.7556 |     23.797 |   0.9310 |     29.504 |     1.5
   12 |   0.7129 |     22.275 |   0.9148 |     28.064 |     1.6
   13 |   0.6836 |     21.332 |   0.8990 |     27.114 |     1.7
   14 |   0.6531 |     20.384 |   0.8892 |     27.237 |     1.9
   15 |   0.6188 |     19.148 |   0.8843 |     26.685 |     2.0
   16 |   0.5919 |     18.590 |   0.8607 |     26.072 |     2.1
   17 |   0.5667 |     17.664 |   0.8737 |     26.471 |     2.3
   18 |   0.5412 |     17.003 |   0.8717 |     25.858 |     2.4
   19 |   0.5132 |     16.119 |   0.8704 |     25.306 |     2.5
   20 |   0.4956 |     15.567 |   0.8833 |     25.337 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 386,850

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5339 |     61.487 |   1.8790 |     44.608 |     0.1
    2 |   1.6825 |     44.208 |   1.5430 |     41.789 |     0.2
    3 |   1.4729 |     41.938 |   1.4096 |     40.717 |     0.4
    4 |   1.3518 |     39.716 |   1.3131 |     38.909 |     0.5
    5 |   1.2594 |     37.581 |   1.2380 |     35.999 |     0.6
    6 |   1.1845 |     35.208 |   1.1818 |     35.570 |     0.7
    7 |   1.1231 |     33.648 |   1.1513 |     34.835 |     0.8
    8 |   1.0702 |     32.315 |   1.0955 |     33.548 |     0.9
    9 |   1.0197 |     30.781 |   1.0670 |     32.445 |     1.1
   10 |   0.9762 |     29.876 |   1.0431 |     31.893 |     1.2
   11 |   0.9354 |     28.538 |   1.0151 |     31.464 |     1.3
   12 |   0.9070 |     27.639 |   0.9984 |     30.852 |     1.4
   13 |   0.8663 |     26.577 |   0.9730 |     29.994 |     1.5
   14 |   0.8413 |     25.829 |   0.9550 |     29.779 |     1.6
   15 |   0.8159 |     25.190 |   0.9441 |     29.289 |     1.8
   16 |   0.7773 |     24.014 |   0.9331 |     29.136 |     1.9
   17 |   0.7535 |     23.006 |   0.9142 |     28.033 |     2.0
   18 |   0.7290 |     22.318 |   0.9076 |     28.891 |     2.1
   19 |   0.7095 |     21.906 |   0.8901 |     28.033 |     2.2
   20 |   0.6847 |     20.963 |   0.8966 |     27.849 |     2.4
   21 |   0.6630 |     20.530 |   0.8714 |     27.145 |     2.5
   22 |   0.6391 |     19.961 |   0.8638 |     27.665 |     2.6
   23 |   0.6198 |     19.202 |   0.8675 |     26.808 |     2.7
   24 |   0.6041 |     19.034 |   0.8612 |     25.950 |     2.8
   25 |   0.5838 |     18.184 |   0.8650 |     27.083 |     2.9
   26 |   0.5621 |     17.284 |   0.8611 |     26.532 |     3.1
   27 |   0.5469 |     17.198 |   0.8564 |     25.827 |     3.2
   28 |   0.5351 |     16.829 |   0.8579 |     26.440 |     3.3
   29 |   0.5233 |     16.450 |   0.8512 |     25.276 |     3.4
   30 |   0.5047 |     15.897 |   0.8364 |     24.326 |     3.5
   31 |   0.4912 |     15.469 |   0.8553 |     25.643 |     3.7
   32 |   0.4770 |     15.166 |   0.8406 |     24.632 |     3.8
   33 |   0.4653 |     14.646 |   0.8482 |     24.632 |     3.9
   34 |   0.4502 |     14.060 |   0.8465 |     24.173 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 337,314

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7694 |     49.697 |   1.3068 |     42.341 |     0.1
    2 |   1.2769 |     41.547 |   1.1840 |     38.787 |     0.2
    3 |   1.1744 |     38.687 |   1.0958 |     35.049 |     0.4
    4 |   1.0975 |     36.032 |   1.0545 |     34.498 |     0.5
    5 |   1.0400 |     34.552 |   0.9889 |     32.935 |     0.6
    6 |   0.9923 |     32.981 |   0.9746 |     32.567 |     0.8
    7 |   0.9401 |     31.486 |   0.9407 |     31.250 |     0.9
    8 |   0.9032 |     30.147 |   0.9120 |     30.944 |     1.0
    9 |   0.8651 |     29.064 |   0.9024 |     29.504 |     1.1
   10 |   0.8364 |     28.078 |   0.9026 |     29.013 |     1.3
   11 |   0.7952 |     26.625 |   0.8822 |     29.749 |     1.4
   12 |   0.7775 |     26.154 |   0.8675 |     29.013 |     1.5
   13 |   0.7526 |     25.840 |   0.8647 |     27.757 |     1.6
   14 |   0.7231 |     24.496 |   0.8479 |     27.849 |     1.8
   15 |   0.6994 |     23.835 |   0.8306 |     26.317 |     1.9
   16 |   0.6772 |     23.066 |   0.8271 |     27.359 |     2.0
   17 |   0.6568 |     22.399 |   0.8243 |     26.379 |     2.1
   18 |   0.6435 |     22.117 |   0.8401 |     25.950 |     2.3
   19 |   0.6222 |     21.256 |   0.8374 |     26.348 |     2.4
   20 |   0.6059 |     21.028 |   0.8549 |     27.053 |     2.5
   21 |   0.5855 |     20.378 |   0.8779 |     27.574 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 602,658

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6112 |     65.420 |   1.8091 |     46.109 |     0.2
    2 |   1.7257 |     45.812 |   1.5315 |     44.516 |     0.3
    3 |   1.5377 |     44.490 |   1.4225 |     42.494 |     0.5
    4 |   1.4317 |     42.745 |   1.3447 |     41.207 |     0.7
    5 |   1.3526 |     41.011 |   1.2779 |     38.848 |     0.9
    6 |   1.2867 |     39.554 |   1.2261 |     37.316 |     1.0
    7 |   1.2285 |     38.015 |   1.1829 |     36.121 |     1.2
    8 |   1.1853 |     36.758 |   1.1463 |     35.080 |     1.4
    9 |   1.1426 |     35.452 |   1.1276 |     34.498 |     1.5
   10 |   1.1019 |     33.967 |   1.0927 |     33.180 |     1.7
   11 |   1.0620 |     33.111 |   1.0770 |     33.395 |     1.9
   12 |   1.0280 |     31.730 |   1.0563 |     32.384 |     2.1
   13 |   1.0006 |     30.760 |   1.0395 |     31.893 |     2.2
   14 |   0.9693 |     30.034 |   1.0244 |     31.679 |     2.4
   15 |   0.9395 |     29.335 |   1.0034 |     30.637 |     2.6
   16 |   0.9132 |     28.506 |   0.9990 |     30.362 |     2.8
   17 |   0.8859 |     28.023 |   0.9760 |     29.596 |     2.9
   18 |   0.8624 |     27.151 |   0.9801 |     29.320 |     3.1
   19 |   0.8332 |     25.737 |   0.9525 |     29.197 |     3.3
   20 |   0.8165 |     25.688 |   0.9545 |     29.289 |     3.4
   21 |   0.7913 |     24.940 |   0.9497 |     28.768 |     3.6
   22 |   0.7792 |     24.366 |   0.9415 |     28.370 |     3.8
   23 |   0.7619 |     23.981 |   0.9370 |     28.922 |     4.0
   24 |   0.7414 |     23.423 |   0.9316 |     28.339 |     4.1
   25 |   0.7093 |     22.491 |   0.9410 |     28.033 |     4.3
   26 |   0.7034 |     22.237 |   0.9269 |     27.451 |     4.5
   27 |   0.6970 |     21.857 |   0.9286 |     27.727 |     4.6
   28 |   0.6869 |     21.738 |   0.9214 |     26.991 |     4.8
   29 |   0.6570 |     21.055 |   0.9320 |     27.114 |     5.0
   30 |   0.6470 |     20.627 |   0.9164 |     26.562 |     5.2
   31 |   0.6322 |     20.151 |   0.9204 |     26.900 |     5.3
   32 |   0.6146 |     19.473 |   0.9101 |     26.501 |     5.5
   33 |   0.6037 |     19.235 |   0.9335 |     26.746 |     5.7
   34 |   0.5977 |     19.132 |   0.9373 |     27.727 |     5.8
   35 |   0.5857 |     18.904 |   0.9328 |     26.195 |     6.0
   36 |   0.5686 |     18.243 |   0.9251 |     26.501 |     6.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 911,010

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2972 |     55.716 |   1.5964 |     45.251 |     0.2
    2 |   1.5476 |     44.457 |   1.3719 |     41.513 |     0.4
    3 |   1.3764 |     41.472 |   1.2697 |     38.634 |     0.5
    4 |   1.2783 |     39.353 |   1.2018 |     36.520 |     0.7
    5 |   1.2008 |     37.565 |   1.1431 |     35.263 |     0.9
    6 |   1.1400 |     35.669 |   1.1049 |     34.099 |     1.1
    7 |   1.0837 |     33.772 |   1.0866 |     33.915 |     1.2
    8 |   1.0424 |     32.683 |   1.0445 |     32.414 |     1.4
    9 |   0.9924 |     31.123 |   1.0237 |     32.537 |     1.6
   10 |   0.9598 |     30.261 |   0.9935 |     31.679 |     1.8
   11 |   0.9219 |     29.042 |   0.9849 |     30.821 |     1.9
   12 |   0.8894 |     28.229 |   0.9715 |     30.607 |     2.1
   13 |   0.8626 |     27.389 |   0.9518 |     29.044 |     2.3
   14 |   0.8318 |     26.555 |   0.9502 |     28.983 |     2.5
   15 |   0.8042 |     25.737 |   0.9598 |     29.841 |     2.7
   16 |   0.7763 |     24.686 |   0.9497 |     28.891 |     2.8
   17 |   0.7505 |     23.933 |   0.9273 |     28.002 |     3.0
   18 |   0.7332 |     23.559 |   0.9296 |     28.248 |     3.2
   19 |   0.7172 |     22.876 |   0.9339 |     28.217 |     3.4
   20 |   0.6942 |     22.340 |   0.9327 |     28.156 |     3.5
   21 |   0.6773 |     21.646 |   0.9297 |     28.064 |     3.7
   22 |   0.6621 |     21.581 |   0.9084 |     26.838 |     3.9
   23 |   0.6474 |     20.757 |   0.9117 |     28.002 |     4.1
   24 |   0.6249 |     19.999 |   0.9225 |     26.991 |     4.2
   25 |   0.6173 |     19.723 |   0.9242 |     28.094 |     4.4
   26 |   0.5950 |     18.915 |   0.9247 |     26.624 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 379,298

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8373 |     51.490 |   1.3274 |     42.586 |     0.1
    2 |   1.3074 |     42.420 |   1.2202 |     40.319 |     0.3
    3 |   1.2060 |     39.684 |   1.1254 |     36.612 |     0.4
    4 |   1.1425 |     37.484 |   1.0721 |     35.202 |     0.5
    5 |   1.0769 |     35.918 |   1.0194 |     33.548 |     0.7
    6 |   1.0228 |     33.870 |   1.0027 |     32.843 |     0.8
    7 |   0.9903 |     33.138 |   0.9683 |     31.924 |     0.9
    8 |   0.9309 |     31.394 |   0.9431 |     31.740 |     1.1
    9 |   0.8980 |     30.272 |   0.9249 |     31.189 |     1.2
   10 |   0.8624 |     28.999 |   0.9034 |     30.760 |     1.3
   11 |   0.8339 |     28.246 |   0.8884 |     29.228 |     1.5
   12 |   0.7973 |     27.097 |   0.9085 |     30.423 |     1.6
   13 |   0.7787 |     26.409 |   0.8570 |     28.339 |     1.7
   14 |   0.7440 |     25.461 |   0.8625 |     29.289 |     1.9
   15 |   0.7186 |     24.252 |   0.8407 |     28.339 |     2.0
   16 |   0.7038 |     24.057 |   0.8396 |     28.125 |     2.1
   17 |   0.6758 |     22.936 |   0.8429 |     28.370 |     2.3
   18 |   0.6516 |     22.291 |   0.8575 |     28.554 |     2.4
   19 |   0.6400 |     21.711 |   0.8250 |     27.849 |     2.6
   20 |   0.6274 |     21.733 |   0.8356 |     27.298 |     2.7
   21 |   0.6089 |     20.990 |   0.8211 |     26.900 |     2.8
   22 |   0.5824 |     19.961 |   0.8211 |     26.777 |     3.0
   23 |   0.5825 |     20.151 |   0.8650 |     28.370 |     3.1
   24 |   0.5573 |     19.495 |   0.8545 |     27.880 |     3.2
   25 |   0.5377 |     18.661 |   0.8309 |     25.582 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,472,162

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0145 |     52.086 |   1.4513 |     42.555 |     0.2
    2 |   1.3421 |     40.485 |   1.2719 |     38.327 |     0.3
    3 |   1.1967 |     36.395 |   1.1676 |     36.489 |     0.5
    4 |   1.0844 |     33.453 |   1.0531 |     32.108 |     0.6
    5 |   0.9935 |     30.608 |   1.0044 |     31.036 |     0.8
    6 |   0.9143 |     28.137 |   0.9585 |     30.331 |     0.9
    7 |   0.8455 |     26.230 |   0.9114 |     28.554 |     1.1
    8 |   0.7888 |     24.713 |   0.8891 |     28.186 |     1.2
    9 |   0.7324 |     23.011 |   0.8680 |     27.083 |     1.4
   10 |   0.6784 |     21.110 |   0.8254 |     27.114 |     1.6
   11 |   0.6325 |     19.538 |   0.8123 |     24.908 |     1.7
   12 |   0.5989 |     18.596 |   0.8023 |     25.398 |     1.9
   13 |   0.5528 |     17.225 |   0.8129 |     25.521 |     2.0
   14 |   0.5229 |     16.688 |   0.7935 |     24.173 |     2.2
   15 |   0.4858 |     15.198 |   0.7830 |     23.744 |     2.3
   16 |   0.4601 |     14.348 |   0.7878 |     24.203 |     2.5
   17 |   0.4443 |     14.077 |   0.7837 |     23.162 |     2.7
   18 |   0.4161 |     13.177 |   0.7614 |     22.947 |     2.8
   19 |   0.3905 |     12.522 |   0.7989 |     22.886 |     3.0
   20 |   0.3807 |     11.958 |   0.7969 |     23.376 |     3.1
   21 |   0.3594 |     11.671 |   0.7554 |     21.998 |     3.3
   22 |   0.3412 |     11.297 |   0.7872 |     21.936 |     3.4
   23 |   0.3110 |     10.067 |   0.7685 |     21.477 |     3.6
   24 |   0.3072 |     10.008 |   0.7867 |     22.794 |     3.7
   25 |   0.2941 |      9.726 |   0.7978 |     22.396 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 172,930

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8897 |     49.404 |   1.4228 |     42.647 |     0.1
    2 |   1.3181 |     41.287 |   1.2577 |     39.645 |     0.2
    3 |   1.1753 |     37.570 |   1.1170 |     36.458 |     0.3
    4 |   1.0715 |     34.715 |   1.0483 |     35.478 |     0.5
    5 |   0.9996 |     32.819 |   1.0012 |     33.609 |     0.6
    6 |   0.9345 |     30.852 |   0.9815 |     33.211 |     0.7
    7 |   0.8823 |     29.362 |   0.8988 |     30.607 |     0.8
    8 |   0.8220 |     27.335 |   0.8677 |     28.707 |     0.9
    9 |   0.7971 |     26.512 |   0.8511 |     28.707 |     1.0
   10 |   0.7483 |     24.973 |   0.8519 |     28.125 |     1.1
   11 |   0.7314 |     24.442 |   0.8413 |     27.788 |     1.3
   12 |   0.6930 |     23.207 |   0.7958 |     25.980 |     1.4
   13 |   0.6632 |     22.394 |   0.8297 |     27.145 |     1.5
   14 |   0.6488 |     22.166 |   0.8151 |     26.808 |     1.6
   15 |   0.6117 |     20.801 |   0.7892 |     25.980 |     1.7
   16 |   0.5807 |     19.620 |   0.7744 |     25.123 |     1.8
   17 |   0.5592 |     18.861 |   0.7987 |     26.225 |     2.0
   18 |   0.5463 |     18.606 |   0.8106 |     25.306 |     2.1
   19 |   0.5211 |     17.891 |   0.7827 |     25.000 |     2.2
   20 |   0.5067 |     16.927 |   0.7710 |     24.081 |     2.3
   21 |   0.4963 |     17.246 |   0.7620 |     23.652 |     2.4
   22 |   0.4774 |     16.369 |   0.7664 |     23.192 |     2.5
   23 |   0.4525 |     15.529 |   0.7859 |     23.621 |     2.6
   24 |   0.4412 |     15.485 |   0.7773 |     23.591 |     2.8
   25 |   0.4229 |     14.749 |   0.7611 |     22.580 |     2.9
   26 |   0.4167 |     14.369 |   0.8130 |     23.805 |     3.0
   27 |   0.4209 |     14.749 |   0.8089 |     23.284 |     3.1
   28 |   0.3976 |     13.995 |   0.7741 |     22.855 |     3.2
   29 |   0.3785 |     13.286 |   0.8080 |     22.794 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 303,138

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8487 |     70.557 |   2.2375 |     51.195 |     0.1
    2 |   2.1190 |     49.837 |   1.7097 |     44.761 |     0.2
    3 |   1.7571 |     45.844 |   1.5214 |     44.485 |     0.3
    4 |   1.5880 |     44.983 |   1.4235 |     43.413 |     0.4
    5 |   1.4965 |     44.056 |   1.3654 |     41.820 |     0.4
    6 |   1.4278 |     42.544 |   1.3156 |     40.319 |     0.5
    7 |   1.3782 |     42.003 |   1.2740 |     39.737 |     0.6
    8 |   1.3350 |     41.087 |   1.2500 |     38.327 |     0.7
    9 |   1.2906 |     40.068 |   1.2206 |     37.439 |     0.8
   10 |   1.2591 |     39.017 |   1.1952 |     36.612 |     0.9
   11 |   1.2233 |     38.291 |   1.1733 |     36.213 |     1.0
   12 |   1.1947 |     37.289 |   1.1582 |     36.458 |     1.1
   13 |   1.1678 |     37.034 |   1.1394 |     35.876 |     1.2
   14 |   1.1473 |     36.080 |   1.1375 |     35.294 |     1.3
   15 |   1.1196 |     35.436 |   1.1235 |     35.080 |     1.3
   16 |   1.0990 |     34.498 |   1.0996 |     34.773 |     1.4
   17 |   1.0763 |     34.086 |   1.0929 |     34.773 |     1.5
   18 |   1.0600 |     33.599 |   1.0872 |     33.701 |     1.6
   19 |   1.0466 |     32.905 |   1.0851 |     33.793 |     1.7
   20 |   1.0293 |     32.829 |   1.0695 |     33.150 |     1.8
   21 |   1.0048 |     31.952 |   1.0709 |     33.640 |     1.9
   22 |   0.9963 |     31.713 |   1.0628 |     32.966 |     2.0
   23 |   0.9772 |     30.873 |   1.0496 |     32.322 |     2.1
   24 |   0.9603 |     30.743 |   1.0591 |     32.843 |     2.2
   25 |   0.9436 |     30.196 |   1.0386 |     32.567 |     2.2
   26 |   0.9371 |     29.681 |   1.0495 |     31.924 |     2.3
   27 |   0.9184 |     29.389 |   1.0469 |     32.659 |     2.4
   28 |   0.9074 |     29.080 |   1.0560 |     33.027 |     2.5
   29 |   0.8969 |     28.858 |   1.0474 |     31.893 |     2.6
   30 |   0.8845 |     28.397 |   1.0323 |     31.587 |     2.7
   31 |   0.8710 |     28.148 |   1.0509 |     32.108 |     2.8
   32 |   0.8619 |     27.839 |   1.0321 |     31.127 |     2.9
   33 |   0.8487 |     27.433 |   1.0290 |     31.526 |     3.0
   34 |   0.8384 |     27.352 |   1.0360 |     31.311 |     3.0
   35 |   0.8348 |     27.048 |   1.0350 |     31.464 |     3.1
   36 |   0.8188 |     26.143 |   1.0228 |     31.066 |     3.2
   37 |   0.8064 |     26.268 |   1.0321 |     31.495 |     3.3
   38 |   0.8047 |     25.964 |   1.0276 |     31.403 |     3.4
   39 |   0.7836 |     25.433 |   1.0409 |     31.434 |     3.5
   40 |   0.7765 |     25.379 |   1.0334 |     31.066 |     3.6
   41 |   0.7714 |     24.967 |   1.0193 |     30.760 |     3.7
   42 |   0.7594 |     24.805 |   1.0270 |     31.219 |     3.8
   43 |   0.7593 |     24.924 |   1.0271 |     30.729 |     3.9
   44 |   0.7419 |     24.485 |   1.0392 |     30.790 |     3.9
   45 |   0.7398 |     24.236 |   1.0264 |     31.066 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8054 |     71.283 |   2.0957 |     49.571 |     0.2
    2 |   1.9326 |     47.502 |   1.6135 |     45.190 |     0.3
    3 |   1.6295 |     45.178 |   1.4796 |     43.658 |     0.5
    4 |   1.5078 |     44.045 |   1.3921 |     42.004 |     0.7
    5 |   1.4193 |     42.274 |   1.3308 |     40.778 |     0.8
    6 |   1.3535 |     40.778 |   1.2743 |     39.124 |     1.0
    7 |   1.2917 |     39.440 |   1.2344 |     37.439 |     1.2
    8 |   1.2481 |     38.226 |   1.1924 |     37.010 |     1.3
    9 |   1.2013 |     36.638 |   1.1633 |     35.080 |     1.5
   10 |   1.1628 |     35.967 |   1.1306 |     34.926 |     1.7
   11 |   1.1327 |     34.943 |   1.1167 |     35.263 |     1.8
   12 |   1.0931 |     33.875 |   1.0838 |     34.038 |     2.0
   13 |   1.0599 |     32.884 |   1.0725 |     33.701 |     2.2
   14 |   1.0359 |     32.412 |   1.0578 |     33.548 |     2.4
   15 |   1.0176 |     31.876 |   1.0341 |     32.904 |     2.5
   16 |   0.9821 |     30.819 |   1.0349 |     32.904 |     2.7
   17 |   0.9599 |     30.012 |   1.0126 |     31.618 |     2.9
   18 |   0.9384 |     29.513 |   1.0163 |     32.322 |     3.0
   19 |   0.9166 |     29.140 |   0.9772 |     30.821 |     3.2
   20 |   0.8910 |     28.078 |   0.9868 |     31.127 |     3.4
   21 |   0.8735 |     27.666 |   0.9557 |     29.688 |     3.5
   22 |   0.8500 |     26.680 |   0.9533 |     28.922 |     3.7
   23 |   0.8322 |     26.262 |   0.9655 |     30.423 |     3.9
   24 |   0.8100 |     25.331 |   0.9481 |     29.075 |     4.0
   25 |   0.8002 |     25.498 |   0.9444 |     29.381 |     4.2
   26 |   0.7857 |     24.800 |   0.9560 |     29.473 |     4.4
   27 |   0.7683 |     24.550 |   0.9421 |     28.615 |     4.5
   28 |   0.7496 |     24.182 |   0.9446 |     29.167 |     4.7
   29 |   0.7354 |     23.613 |   0.9315 |     28.370 |     4.9
   30 |   0.7159 |     22.816 |   0.9326 |     27.788 |     5.0
   31 |   0.7063 |     22.551 |   0.9363 |     27.972 |     5.2
   32 |   0.7009 |     22.378 |   0.9429 |     28.523 |     5.4
   33 |   0.6792 |     21.787 |   0.9303 |     28.248 |     5.5
   34 |   0.6690 |     21.467 |   0.9382 |     27.941 |     5.7
   35 |   0.6627 |     21.402 |   0.9300 |     27.819 |     5.9
   36 |   0.6499 |     21.191 |   0.9339 |     27.574 |     6.1
   37 |   0.6372 |     20.497 |   0.9330 |     27.420 |     6.2
   38 |   0.6264 |     20.292 |   0.9491 |     27.543 |     6.4
   39 |   0.6122 |     19.685 |   0.9511 |     27.298 |     6.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,472,162

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6442 |     49.106 |   1.3311 |     43.474 |     0.1
    2 |   1.2975 |     42.891 |   1.2425 |     40.901 |     0.3
    3 |   1.2409 |     41.439 |   1.1637 |     38.511 |     0.4
    4 |   1.1845 |     39.440 |   1.1233 |     37.776 |     0.5
    5 |   1.1491 |     38.481 |   1.0912 |     36.642 |     0.7
    6 |   1.1043 |     37.527 |   1.0611 |     35.662 |     0.8
    7 |   1.0691 |     36.205 |   1.0524 |     35.110 |     1.0
    8 |   1.0399 |     35.522 |   1.0334 |     34.222 |     1.1
    9 |   1.0186 |     34.379 |   1.0174 |     33.609 |     1.2
   10 |   0.9722 |     33.203 |   0.9857 |     32.843 |     1.4
   11 |   0.9520 |     32.461 |   0.9994 |     33.517 |     1.5
   12 |   0.9277 |     31.643 |   0.9900 |     32.843 |     1.6
   13 |   0.9190 |     31.578 |   0.9878 |     32.598 |     1.8
   14 |   0.8804 |     30.007 |   0.9722 |     31.985 |     1.9
   15 |   0.8504 |     29.264 |   1.0041 |     32.230 |     2.0
   16 |   0.8383 |     28.343 |   0.9670 |     31.955 |     2.2
   17 |   0.8119 |     27.807 |   0.9538 |     31.526 |     2.3
   18 |   0.8080 |     27.476 |   0.9610 |     31.801 |     2.5
   19 |   0.7740 |     26.495 |   0.9238 |     30.760 |     2.6
   20 |   0.7562 |     26.225 |   0.9146 |     29.810 |     2.7
   21 |   0.7351 |     25.536 |   0.9531 |     30.147 |     2.9
   22 |   0.7224 |     24.897 |   0.9880 |     30.852 |     3.0
   23 |   0.6987 |     23.965 |   0.9903 |     30.729 |     3.1
   24 |   0.6838 |     23.732 |   0.9655 |     31.618 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 320,546

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7394 |     68.959 |   2.1697 |     46.477 |     0.1
    2 |   1.8570 |     45.519 |   1.6653 |     43.811 |     0.3
    3 |   1.5660 |     43.574 |   1.4941 |     41.575 |     0.4
    4 |   1.4261 |     41.363 |   1.3808 |     40.380 |     0.5
    5 |   1.3280 |     39.700 |   1.3187 |     38.787 |     0.7
    6 |   1.2507 |     37.614 |   1.2545 |     37.561 |     0.8
    7 |   1.1924 |     35.967 |   1.2093 |     36.244 |     1.0
    8 |   1.1383 |     34.417 |   1.1759 |     35.202 |     1.1
    9 |   1.0915 |     32.905 |   1.1414 |     34.375 |     1.2
   10 |   1.0520 |     31.627 |   1.1161 |     33.977 |     1.4
   11 |   1.0154 |     30.619 |   1.0931 |     33.150 |     1.5
   12 |   0.9792 |     29.719 |   1.0757 |     32.874 |     1.7
   13 |   0.9494 |     29.058 |   1.0597 |     32.537 |     1.8
   14 |   0.9259 |     28.349 |   1.0274 |     31.801 |     1.9
   15 |   0.8928 |     27.845 |   1.0240 |     32.016 |     2.1
   16 |   0.8655 |     26.582 |   1.0188 |     31.219 |     2.2
   17 |   0.8450 |     26.035 |   0.9904 |     30.453 |     2.3
   18 |   0.8151 |     25.271 |   0.9804 |     31.036 |     2.5
   19 |   0.7953 |     24.550 |   0.9722 |     30.637 |     2.6
   20 |   0.7740 |     23.976 |   0.9556 |     29.749 |     2.8
   21 |   0.7501 |     23.331 |   0.9665 |     29.871 |     2.9
   22 |   0.7368 |     23.120 |   0.9511 |     30.116 |     3.0
   23 |   0.7141 |     22.096 |   0.9510 |     29.105 |     3.2
   24 |   0.6996 |     21.722 |   0.9350 |     29.259 |     3.3
   25 |   0.6799 |     21.348 |   0.9397 |     29.994 |     3.4
   26 |   0.6699 |     20.877 |   0.9320 |     28.248 |     3.6
   27 |   0.6492 |     20.156 |   0.9361 |     28.278 |     3.7
   28 |   0.6380 |     19.435 |   0.9128 |     28.217 |     3.9
   29 |   0.6239 |     19.528 |   0.9309 |     28.523 |     4.0
   30 |   0.6092 |     18.823 |   0.9184 |     27.145 |     4.1
   31 |   0.5973 |     18.623 |   0.9272 |     28.278 |     4.3
   32 |   0.5827 |     18.005 |   0.9127 |     27.819 |     4.4
   33 |   0.5647 |     17.723 |   0.9010 |     27.083 |     4.5
   34 |   0.5539 |     17.409 |   0.9254 |     27.328 |     4.7
   35 |   0.5514 |     17.469 |   0.9045 |     26.746 |     4.8
   36 |   0.5244 |     16.217 |   0.9285 |     27.298 |     5.0
   37 |   0.5274 |     16.531 |   0.9081 |     26.961 |     5.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 135,266

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.2633 |     85.224 |   2.8672 |     74.540 |     0.1
    2 |   2.8095 |     68.438 |   2.4379 |     53.860 |     0.1
    3 |   2.4462 |     54.909 |   2.0749 |     49.387 |     0.2
    4 |   2.1459 |     50.293 |   1.8613 |     48.070 |     0.3
    5 |   1.9534 |     48.342 |   1.7228 |     47.365 |     0.4
    6 |   1.8169 |     47.215 |   1.6270 |     45.037 |     0.5
    7 |   1.7162 |     46.343 |   1.5547 |     43.382 |     0.5
    8 |   1.6383 |     45.546 |   1.5025 |     42.800 |     0.6
    9 |   1.5791 |     45.124 |   1.4635 |     43.199 |     0.7
   10 |   1.5286 |     44.576 |   1.4285 |     42.892 |     0.7
   11 |   1.4937 |     44.154 |   1.4022 |     42.586 |     0.8
   12 |   1.4627 |     43.780 |   1.3748 |     42.004 |     0.9
   13 |   1.4275 |     43.270 |   1.3527 |     41.973 |     1.0
   14 |   1.4013 |     42.924 |   1.3363 |     41.422 |     1.0
   15 |   1.3794 |     42.523 |   1.3176 |     41.360 |     1.1
   16 |   1.3604 |     41.992 |   1.3057 |     40.533 |     1.2
   17 |   1.3360 |     41.482 |   1.2947 |     40.319 |     1.3
   18 |   1.3160 |     41.098 |   1.2793 |     39.890 |     1.3
   19 |   1.3009 |     41.060 |   1.2729 |     39.032 |     1.4
   20 |   1.2877 |     40.870 |   1.2669 |     38.971 |     1.5
   21 |   1.2743 |     40.366 |   1.2521 |     38.450 |     1.6
   22 |   1.2547 |     39.749 |   1.2391 |     37.745 |     1.6
   23 |   1.2428 |     39.619 |   1.2446 |     38.235 |     1.7
   24 |   1.2315 |     39.299 |   1.2369 |     38.051 |     1.8
   25 |   1.2122 |     38.524 |   1.2300 |     37.868 |     1.9
   26 |   1.2048 |     38.378 |   1.2219 |     37.316 |     1.9
   27 |   1.1933 |     37.684 |   1.2157 |     37.500 |     2.0
   28 |   1.1829 |     37.977 |   1.2167 |     37.653 |     2.1
   29 |   1.1731 |     37.603 |   1.2127 |     37.255 |     2.1
   30 |   1.1627 |     37.256 |   1.2091 |     36.979 |     2.2
   31 |   1.1520 |     36.633 |   1.2054 |     37.439 |     2.3
   32 |   1.1433 |     36.579 |   1.2024 |     36.949 |     2.4
   33 |   1.1315 |     36.162 |   1.2001 |     36.918 |     2.4
   34 |   1.1216 |     36.015 |   1.1994 |     37.040 |     2.5
   35 |   1.1152 |     35.636 |   1.1973 |     36.673 |     2.6
   36 |   1.1072 |     35.631 |   1.1876 |     36.642 |     2.7
   37 |   1.0986 |     35.284 |   1.1853 |     35.662 |     2.7
   38 |   1.0877 |     35.105 |   1.1821 |     36.612 |     2.8
   39 |   1.0833 |     34.813 |   1.1801 |     36.029 |     2.9
   40 |   1.0723 |     34.552 |   1.1773 |     36.949 |     3.0
   41 |   1.0700 |     34.504 |   1.1877 |     36.244 |     3.0
   42 |   1.0552 |     34.298 |   1.1886 |     36.060 |     3.1
   43 |   1.0515 |     33.940 |   1.1744 |     35.754 |     3.2
   44 |   1.0451 |     33.853 |   1.1929 |     36.489 |     3.2
   45 |   1.0326 |     33.588 |   1.1804 |     35.692 |     3.3
   46 |   1.0251 |     33.149 |   1.1871 |     35.478 |     3.4
   47 |   1.0225 |     32.943 |   1.1632 |     35.662 |     3.5
   48 |   1.0164 |     32.689 |   1.1708 |     35.907 |     3.5
   49 |   1.0080 |     32.710 |   1.1641 |     35.631 |     3.6
   50 |   1.0030 |     32.754 |   1.1717 |     35.938 |     3.7
   51 |   0.9931 |     32.163 |   1.1685 |     35.815 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5100 |     45.682 |   1.2359 |     39.553 |     0.1
    2 |   1.1898 |     39.402 |   1.1474 |     37.868 |     0.2
    3 |   1.0720 |     36.075 |   1.0253 |     34.436 |     0.4
    4 |   0.9936 |     33.751 |   1.0124 |     33.640 |     0.5
    5 |   0.9254 |     31.605 |   0.9216 |     31.250 |     0.6
    6 |   0.8732 |     29.866 |   0.9565 |     31.464 |     0.7
    7 |   0.8238 |     27.877 |   0.8989 |     30.331 |     0.9
    8 |   0.7821 |     26.875 |   0.8518 |     28.523 |     1.0
    9 |   0.7412 |     25.439 |   0.8681 |     29.442 |     1.1
   10 |   0.7211 |     24.751 |   0.8616 |     28.554 |     1.2
   11 |   0.6965 |     23.998 |   0.8184 |     27.083 |     1.4
   12 |   0.6544 |     22.524 |   0.8443 |     27.880 |     1.5
   13 |   0.6437 |     22.080 |   0.8604 |     27.911 |     1.6
   14 |   0.6356 |     21.543 |   0.8410 |     26.624 |     1.7
   15 |   0.5926 |     20.378 |   0.8049 |     25.888 |     1.9
   16 |   0.5553 |     19.230 |   0.8224 |     26.471 |     2.0
   17 |   0.5520 |     19.067 |   0.8116 |     25.827 |     2.1
   18 |   0.5314 |     18.590 |   0.7749 |     24.081 |     2.2
   19 |   0.5218 |     18.200 |   0.8154 |     24.786 |     2.4
   20 |   0.5091 |     17.951 |   0.8576 |     26.256 |     2.5
   21 |   0.5076 |     17.707 |   0.7830 |     23.958 |     2.6
   22 |   0.4887 |     16.981 |   0.7819 |     23.744 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 130,978

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9572 |     50.043 |   1.4520 |     43.566 |     0.1
    2 |   1.3476 |     42.046 |   1.2528 |     39.400 |     0.2
    3 |   1.2034 |     38.058 |   1.1388 |     35.754 |     0.2
    4 |   1.1029 |     35.268 |   1.0836 |     34.498 |     0.3
    5 |   1.0368 |     33.783 |   1.0200 |     32.721 |     0.4
    6 |   0.9651 |     31.388 |   1.0048 |     32.904 |     0.5
    7 |   0.9160 |     30.066 |   0.9496 |     30.729 |     0.5
    8 |   0.8698 |     28.533 |   0.9295 |     30.637 |     0.6
    9 |   0.8230 |     27.086 |   0.9127 |     30.637 |     0.7
   10 |   0.7858 |     26.035 |   0.9049 |     30.974 |     0.8
   11 |   0.7594 |     25.347 |   0.8798 |     29.075 |     0.9
   12 |   0.7230 |     23.987 |   0.8603 |     28.401 |     0.9
   13 |   0.7034 |     23.532 |   0.8761 |     29.105 |     1.0
   14 |   0.6732 |     22.486 |   0.8769 |     28.707 |     1.1
   15 |   0.6490 |     21.641 |   0.8381 |     26.991 |     1.2
   16 |   0.6242 |     20.947 |   0.8491 |     27.880 |     1.2
   17 |   0.6118 |     20.590 |   0.8257 |     26.716 |     1.3
   18 |   0.6017 |     19.885 |   0.8371 |     26.164 |     1.4
   19 |   0.5800 |     19.327 |   0.8082 |     26.195 |     1.5
   20 |   0.5545 |     18.579 |   0.8164 |     25.551 |     1.6
   21 |   0.5382 |     18.471 |   0.8477 |     26.532 |     1.6
   22 |   0.5305 |     18.054 |   0.8264 |     25.950 |     1.7
   23 |   0.5142 |     17.566 |   0.8505 |     25.551 |     1.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 379,298

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5563 |     64.689 |   1.8823 |     46.324 |     0.1
    2 |   1.6554 |     44.408 |   1.5246 |     43.229 |     0.2
    3 |   1.4436 |     41.520 |   1.3908 |     40.870 |     0.4
    4 |   1.3340 |     39.472 |   1.3115 |     39.491 |     0.5
    5 |   1.2500 |     37.803 |   1.2498 |     37.592 |     0.6
    6 |   1.1834 |     36.075 |   1.1967 |     36.673 |     0.8
    7 |   1.1235 |     34.130 |   1.1423 |     34.804 |     0.9
    8 |   1.0662 |     32.689 |   1.1122 |     34.191 |     1.0
    9 |   1.0222 |     31.361 |   1.0801 |     33.088 |     1.1
   10 |   0.9788 |     29.828 |   1.0488 |     32.843 |     1.3
   11 |   0.9415 |     28.814 |   1.0206 |     32.016 |     1.4
   12 |   0.9052 |     27.883 |   1.0008 |     31.403 |     1.5
   13 |   0.8711 |     26.842 |   0.9705 |     30.760 |     1.6
   14 |   0.8342 |     25.596 |   0.9738 |     29.534 |     1.8
   15 |   0.8070 |     25.108 |   0.9418 |     29.136 |     1.9
   16 |   0.7797 |     23.938 |   0.9438 |     29.350 |     2.0
   17 |   0.7573 |     22.968 |   0.9239 |     29.320 |     2.1
   18 |   0.7351 |     22.697 |   0.9193 |     27.911 |     2.3
   19 |   0.7075 |     21.760 |   0.9208 |     28.431 |     2.4
   20 |   0.6886 |     20.925 |   0.8959 |     27.420 |     2.5
   21 |   0.6647 |     20.210 |   0.9084 |     28.064 |     2.6
   22 |   0.6518 |     19.826 |   0.8955 |     26.930 |     2.8
   23 |   0.6294 |     19.213 |   0.8759 |     26.409 |     2.9
   24 |   0.6065 |     18.796 |   0.8765 |     26.225 |     3.0
   25 |   0.5941 |     18.168 |   0.8712 |     26.317 |     3.1
   26 |   0.5739 |     17.539 |   0.8772 |     26.011 |     3.3
   27 |   0.5680 |     17.328 |   0.8665 |     25.858 |     3.4
   28 |   0.5429 |     16.992 |   0.8912 |     27.482 |     3.5
   29 |   0.5339 |     16.547 |   0.8748 |     25.490 |     3.6
   30 |   0.5218 |     15.870 |   0.8985 |     26.195 |     3.8
   31 |   0.5059 |     15.708 |   0.8886 |     26.072 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 894,178

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4009 |     60.116 |   1.5924 |     42.923 |     0.1
    2 |   1.5378 |     43.574 |   1.3459 |     41.820 |     0.2
    3 |   1.3617 |     41.141 |   1.2507 |     39.246 |     0.3
    4 |   1.2742 |     39.039 |   1.1945 |     37.745 |     0.5
    5 |   1.2121 |     37.998 |   1.1431 |     35.784 |     0.6
    6 |   1.1545 |     36.151 |   1.1152 |     35.539 |     0.7
    7 |   1.1072 |     35.067 |   1.0808 |     34.467 |     0.8
    8 |   1.0640 |     33.680 |   1.0589 |     33.364 |     0.9
    9 |   1.0335 |     33.165 |   1.0286 |     33.211 |     1.0
   10 |   1.0006 |     31.914 |   1.0091 |     31.955 |     1.2
   11 |   0.9678 |     31.058 |   0.9985 |     32.169 |     1.3
   12 |   0.9325 |     29.757 |   0.9685 |     30.944 |     1.4
   13 |   0.9079 |     28.988 |   0.9561 |     31.127 |     1.5
   14 |   0.8783 |     28.099 |   0.9500 |     30.668 |     1.6
   15 |   0.8520 |     27.335 |   0.9238 |     29.442 |     1.7
   16 |   0.8292 |     26.691 |   0.9373 |     30.055 |     1.9
   17 |   0.8099 |     26.544 |   0.9219 |     29.228 |     2.0
   18 |   0.7838 |     25.016 |   0.9077 |     28.922 |     2.1
   19 |   0.7627 |     24.865 |   0.8947 |     27.849 |     2.2
   20 |   0.7499 |     24.214 |   0.9003 |     28.462 |     2.3
   21 |   0.7332 |     23.412 |   0.8868 |     28.339 |     2.4
   22 |   0.7201 |     23.098 |   0.8803 |     28.156 |     2.5
   23 |   0.7049 |     23.185 |   0.8649 |     27.237 |     2.7
   24 |   0.6725 |     22.025 |   0.8767 |     27.727 |     2.8
   25 |   0.6595 |     21.332 |   0.8676 |     26.716 |     2.9
   26 |   0.6469 |     20.936 |   0.8621 |     27.022 |     3.0
   27 |   0.6323 |     20.925 |   0.8674 |     26.042 |     3.1
   28 |   0.6228 |     20.064 |   0.8608 |     26.532 |     3.2
   29 |   0.6101 |     19.896 |   0.8776 |     26.501 |     3.4
   30 |   0.5958 |     19.495 |   0.8812 |     26.348 |     3.5
   31 |   0.5848 |     19.002 |   0.8728 |     26.409 |     3.6
   32 |   0.5771 |     18.785 |   0.8468 |     25.797 |     3.7
   33 |   0.5605 |     18.270 |   0.8564 |     25.368 |     3.8
   34 |   0.5476 |     17.826 |   0.8851 |     25.980 |     3.9
   35 |   0.5399 |     17.945 |   0.8591 |     25.000 |     4.1
   36 |   0.5265 |     17.236 |   0.8675 |     25.123 |     4.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 419,170

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6407 |     47.616 |   1.2716 |     40.349 |     0.1
    2 |   1.2520 |     40.957 |   1.1576 |     38.082 |     0.2
    3 |   1.1514 |     37.733 |   1.0736 |     35.692 |     0.4
    4 |   1.0741 |     35.875 |   1.0194 |     33.946 |     0.5
    5 |   1.0099 |     33.740 |   0.9694 |     32.904 |     0.6
    6 |   0.9646 |     32.531 |   0.9265 |     31.250 |     0.8
    7 |   0.9173 |     31.280 |   0.9123 |     30.300 |     0.9
    8 |   0.8856 |     29.622 |   0.8821 |     29.841 |     1.0
    9 |   0.8356 |     28.506 |   0.8943 |     30.760 |     1.1
   10 |   0.8056 |     26.902 |   0.8615 |     27.941 |     1.3
   11 |   0.7801 |     26.615 |   0.8255 |     27.727 |     1.4
   12 |   0.7468 |     25.352 |   0.8187 |     27.053 |     1.5
   13 |   0.7207 |     24.745 |   0.8185 |     26.685 |     1.6
   14 |   0.6962 |     23.797 |   0.8345 |     27.145 |     1.8
   15 |   0.6580 |     22.860 |   0.8270 |     27.359 |     1.9
   16 |   0.6449 |     22.258 |   0.8298 |     26.256 |     2.0
   17 |   0.6238 |     21.527 |   0.8017 |     25.827 |     2.1
   18 |   0.6066 |     21.018 |   0.7821 |     24.479 |     2.3
   19 |   0.5783 |     19.977 |   0.8097 |     24.510 |     2.4
   20 |   0.5560 |     19.170 |   0.8138 |     25.276 |     2.5
   21 |   0.5453 |     19.116 |   0.8096 |     24.816 |     2.6
   22 |   0.5215 |     17.972 |   0.7771 |     24.387 |     2.8
   23 |   0.5039 |     17.441 |   0.7843 |     24.020 |     2.9
   24 |   0.4907 |     17.230 |   0.8046 |     23.836 |     3.0
   25 |   0.4713 |     16.591 |   0.8045 |     23.958 |     3.1
   26 |   0.4720 |     16.580 |   0.8163 |     24.265 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 894,178

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5937 |     47.551 |   1.2568 |     40.809 |     0.1
    2 |   1.2244 |     40.220 |   1.1536 |     36.857 |     0.2
    3 |   1.1130 |     37.354 |   1.0707 |     36.305 |     0.3
    4 |   1.0554 |     35.327 |   1.0723 |     36.213 |     0.4
    5 |   0.9865 |     33.306 |   1.0195 |     34.559 |     0.5
    6 |   0.9629 |     32.607 |   0.9752 |     32.230 |     0.6
    7 |   0.9120 |     31.334 |   0.9546 |     32.537 |     0.7
    8 |   0.8634 |     29.660 |   0.9669 |     31.648 |     0.8
    9 |   0.8294 |     28.240 |   0.9168 |     31.587 |     0.9
   10 |   0.8075 |     27.671 |   0.9274 |     31.036 |     0.9
   11 |   0.7752 |     26.571 |   0.9210 |     31.403 |     1.0
   12 |   0.7416 |     25.336 |   0.8973 |     29.688 |     1.1
   13 |   0.7219 |     24.697 |   0.8862 |     29.749 |     1.2
   14 |   0.6978 |     23.998 |   0.8929 |     29.871 |     1.3
   15 |   0.6845 |     23.580 |   0.8498 |     28.738 |     1.4
   16 |   0.6550 |     22.464 |   0.8929 |     29.381 |     1.5
   17 |   0.6384 |     21.933 |   0.8915 |     29.320 |     1.6
   18 |   0.6190 |     21.115 |   0.9312 |     29.504 |     1.7
   19 |   0.6049 |     21.169 |   0.8698 |     28.125 |     1.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 370,082

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6487 |     47.231 |   1.2897 |     41.789 |     0.1
    2 |   1.2195 |     40.030 |   1.1658 |     39.645 |     0.2
    3 |   1.0973 |     36.844 |   1.0815 |     36.520 |     0.3
    4 |   1.0156 |     34.119 |   1.0066 |     34.344 |     0.4
    5 |   0.9502 |     31.963 |   0.9611 |     32.874 |     0.5
    6 |   0.8880 |     30.294 |   0.8993 |     30.729 |     0.6
    7 |   0.8408 |     28.652 |   0.8883 |     30.116 |     0.7
    8 |   0.8009 |     27.622 |   0.8647 |     29.013 |     0.8
    9 |   0.7494 |     25.731 |   0.8465 |     28.523 |     0.9
   10 |   0.7158 |     24.355 |   0.8290 |     27.145 |     1.0
   11 |   0.6996 |     24.138 |   0.8090 |     27.022 |     1.1
   12 |   0.6562 |     22.562 |   0.8042 |     26.869 |     1.2
   13 |   0.6315 |     21.511 |   0.8053 |     26.317 |     1.3
   14 |   0.6171 |     21.251 |   0.8176 |     26.777 |     1.4
   15 |   0.5757 |     19.977 |   0.7572 |     24.142 |     1.5
   16 |   0.5524 |     19.159 |   0.8276 |     26.072 |     1.6
   17 |   0.5336 |     18.531 |   0.7743 |     25.368 |     1.7
   18 |   0.5122 |     17.788 |   0.7702 |     23.866 |     1.8
   19 |   0.4953 |     17.078 |   0.7846 |     24.663 |     1.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 180,546

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0541 |     52.384 |   1.4501 |     43.689 |     0.1
    2 |   1.4143 |     43.953 |   1.2925 |     40.993 |     0.2
    3 |   1.3031 |     41.954 |   1.2262 |     39.369 |     0.3
    4 |   1.2373 |     40.626 |   1.1635 |     37.837 |     0.5
    5 |   1.1791 |     39.185 |   1.1304 |     36.826 |     0.6
    6 |   1.1423 |     38.129 |   1.0934 |     36.336 |     0.7
    7 |   1.0986 |     36.638 |   1.0576 |     35.631 |     0.8
    8 |   1.0607 |     35.311 |   1.0428 |     34.865 |     0.9
    9 |   1.0384 |     35.105 |   1.0402 |     34.957 |     1.0
   10 |   1.0104 |     33.832 |   1.0036 |     32.996 |     1.1
   11 |   0.9852 |     33.062 |   0.9926 |     32.812 |     1.2
   12 |   0.9606 |     32.114 |   1.0001 |     34.314 |     1.4
   13 |   0.9354 |     31.567 |   0.9777 |     32.414 |     1.5
   14 |   0.9121 |     30.651 |   0.9518 |     31.924 |     1.6
   15 |   0.8885 |     29.790 |   0.9812 |     32.598 |     1.7
   16 |   0.8677 |     29.297 |   0.9244 |     30.760 |     1.8
   17 |   0.8458 |     28.749 |   0.9368 |     30.882 |     1.9
   18 |   0.8319 |     28.013 |   0.9334 |     31.097 |     2.0
   19 |   0.8110 |     27.259 |   0.9039 |     30.515 |     2.2
   20 |   0.7923 |     26.945 |   0.9094 |     30.362 |     2.3
   21 |   0.7763 |     26.214 |   0.9185 |     30.116 |     2.4
   22 |   0.7572 |     25.759 |   0.9137 |     30.576 |     2.5
   23 |   0.7407 |     24.713 |   0.9259 |     29.902 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 827,874

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4904 |     45.524 |   1.2382 |     41.176 |     0.1
    2 |   1.1735 |     39.028 |   1.1047 |     37.255 |     0.2
    3 |   1.0809 |     36.357 |   1.0417 |     35.172 |     0.3
    4 |   1.0082 |     33.967 |   1.0069 |     33.701 |     0.4
    5 |   0.9358 |     31.925 |   0.9696 |     32.567 |     0.5
    6 |   0.8688 |     29.400 |   0.9322 |     31.281 |     0.6
    7 |   0.8205 |     28.067 |   0.9013 |     29.167 |     0.7
    8 |   0.7979 |     26.831 |   0.8953 |     29.381 |     0.9
    9 |   0.7703 |     26.333 |   0.8710 |     29.596 |     1.0
   10 |   0.7341 |     25.206 |   0.8302 |     28.033 |     1.1
   11 |   0.6898 |     23.738 |   0.8397 |     27.665 |     1.2
   12 |   0.6783 |     23.315 |   0.8330 |     27.665 |     1.3
   13 |   0.6526 |     22.350 |   0.8107 |     26.256 |     1.4
   14 |   0.6206 |     21.381 |   0.7923 |     25.919 |     1.5
   15 |   0.6005 |     20.454 |   0.8036 |     26.011 |     1.6
   16 |   0.5844 |     20.351 |   0.8105 |     26.103 |     1.7
   17 |   0.5607 |     19.625 |   0.7811 |     24.632 |     1.8
   18 |   0.5509 |     19.040 |   0.7820 |     25.674 |     1.9
   19 |   0.5207 |     18.048 |   0.8070 |     24.663 |     2.0
   20 |   0.5127 |     17.702 |   0.7768 |     25.061 |     2.1
   21 |   0.5041 |     17.501 |   0.7684 |     24.724 |     2.2
   22 |   0.4765 |     16.688 |   0.8039 |     24.847 |     2.4
   23 |   0.4622 |     16.119 |   0.7683 |     23.866 |     2.5
   24 |   0.4676 |     16.445 |   0.8097 |     24.265 |     2.6
   25 |   0.4664 |     16.390 |   0.7739 |     24.724 |     2.7
   26 |   0.4336 |     15.280 |   0.7956 |     23.958 |     2.8
   27 |   0.4214 |     14.906 |   0.7866 |     23.805 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 942,114

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3430 |     58.187 |   1.5606 |     44.516 |     0.1
    2 |   1.5461 |     44.777 |   1.3448 |     42.034 |     0.2
    3 |   1.3867 |     42.680 |   1.2590 |     39.124 |     0.3
    4 |   1.3011 |     40.247 |   1.1931 |     37.561 |     0.4
    5 |   1.2324 |     38.486 |   1.1545 |     36.183 |     0.6
    6 |   1.1808 |     37.354 |   1.1096 |     35.294 |     0.7
    7 |   1.1322 |     35.392 |   1.0849 |     34.804 |     0.8
    8 |   1.0947 |     34.796 |   1.0680 |     33.885 |     0.9
    9 |   1.0585 |     33.220 |   1.0468 |     34.130 |     1.0
   10 |   1.0211 |     32.326 |   1.0137 |     32.047 |     1.1
   11 |   0.9890 |     31.112 |   1.0110 |     31.342 |     1.2
   12 |   0.9653 |     30.868 |   0.9954 |     32.475 |     1.3
   13 |   0.9319 |     29.421 |   0.9816 |     31.710 |     1.4
   14 |   0.9038 |     28.728 |   0.9659 |     30.760 |     1.6
   15 |   0.8773 |     28.208 |   0.9673 |     30.208 |     1.7
   16 |   0.8560 |     27.525 |   0.9446 |     29.810 |     1.8
   17 |   0.8334 |     27.292 |   0.9373 |     29.320 |     1.9
   18 |   0.8123 |     26.094 |   0.9365 |     29.902 |     2.0
   19 |   0.7933 |     25.634 |   0.9220 |     28.431 |     2.1
   20 |   0.7714 |     24.800 |   0.9228 |     28.033 |     2.2
   21 |   0.7549 |     24.269 |   0.9256 |     27.880 |     2.3
   22 |   0.7333 |     23.613 |   0.9290 |     28.339 |     2.4
   23 |   0.7168 |     23.364 |   0.9366 |     28.339 |     2.6
   24 |   0.6997 |     22.779 |   0.9067 |     27.420 |     2.7
   25 |   0.6816 |     22.145 |   0.9186 |     27.911 |     2.8
   26 |   0.6746 |     22.518 |   0.9321 |     27.635 |     2.9
   27 |   0.6580 |     21.353 |   0.9107 |     27.022 |     3.0
   28 |   0.6389 |     20.817 |   0.9251 |     26.900 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 419,170

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6678 |     47.903 |   1.3038 |     41.360 |     0.1
    2 |   1.2770 |     41.802 |   1.1809 |     38.113 |     0.2
    3 |   1.1789 |     38.416 |   1.0883 |     35.876 |     0.3
    4 |   1.0886 |     36.205 |   1.0287 |     33.915 |     0.4
    5 |   1.0276 |     34.487 |   0.9745 |     32.445 |     0.4
    6 |   0.9807 |     32.835 |   0.9330 |     31.342 |     0.5
    7 |   0.9310 |     31.388 |   0.9235 |     31.311 |     0.6
    8 |   0.8892 |     30.039 |   0.8958 |     30.147 |     0.7
    9 |   0.8412 |     28.544 |   0.8960 |     30.331 |     0.8
   10 |   0.8116 |     27.655 |   0.8463 |     28.615 |     0.9
   11 |   0.7941 |     27.162 |   0.8328 |     27.512 |     1.0
   12 |   0.7546 |     25.856 |   0.8347 |     27.880 |     1.1
   13 |   0.7266 |     24.371 |   0.8111 |     26.777 |     1.2
   14 |   0.7089 |     24.117 |   0.7940 |     26.440 |     1.3
   15 |   0.6831 |     23.380 |   0.7982 |     26.317 |     1.3
   16 |   0.6452 |     22.004 |   0.7793 |     25.582 |     1.4
   17 |   0.6266 |     21.424 |   0.8088 |     26.348 |     1.5
   18 |   0.6078 |     20.617 |   0.7937 |     25.092 |     1.6
   19 |   0.5960 |     20.454 |   0.7744 |     24.112 |     1.7
   20 |   0.5663 |     19.392 |   0.7811 |     25.337 |     1.8
   21 |   0.5477 |     18.877 |   0.7796 |     24.571 |     1.9
   22 |   0.5283 |     18.314 |   0.8057 |     25.092 |     2.0
   23 |   0.5224 |     18.016 |   0.7928 |     24.173 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 320,546

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7991 |     67.572 |   2.1551 |     48.376 |     0.1
    2 |   2.0000 |     47.616 |   1.6969 |     45.650 |     0.3
    3 |   1.6992 |     45.774 |   1.5315 |     44.393 |     0.4
    4 |   1.5622 |     44.798 |   1.4374 |     42.770 |     0.6
    5 |   1.4705 |     43.200 |   1.3732 |     41.575 |     0.7
    6 |   1.4012 |     41.905 |   1.3218 |     38.787 |     0.9
    7 |   1.3392 |     40.415 |   1.2814 |     38.480 |     1.1
    8 |   1.2901 |     38.968 |   1.2487 |     37.163 |     1.2
    9 |   1.2484 |     38.248 |   1.2317 |     37.929 |     1.4
   10 |   1.2094 |     37.164 |   1.1968 |     36.581 |     1.5
   11 |   1.1775 |     36.270 |   1.1757 |     35.662 |     1.7
   12 |   1.1396 |     35.224 |   1.1697 |     36.673 |     1.8
   13 |   1.1126 |     34.395 |   1.1524 |     36.366 |     2.0
   14 |   1.0895 |     33.637 |   1.1379 |     35.233 |     2.1
   15 |   1.0641 |     33.057 |   1.1286 |     35.509 |     2.3
   16 |   1.0423 |     32.434 |   1.1048 |     34.130 |     2.4
   17 |   1.0195 |     31.778 |   1.1049 |     34.835 |     2.6
   18 |   0.9985 |     31.296 |   1.0984 |     34.957 |     2.7
   19 |   0.9812 |     30.700 |   1.0945 |     34.007 |     2.9
   20 |   0.9557 |     30.028 |   1.0928 |     34.375 |     3.0
   21 |   0.9469 |     29.627 |   1.0964 |     34.926 |     3.2
   22 |   0.9226 |     28.977 |   1.0824 |     33.793 |     3.3
   23 |   0.9107 |     28.565 |   1.0747 |     33.241 |     3.5
   24 |   0.8884 |     27.942 |   1.0682 |     31.985 |     3.6
   25 |   0.8758 |     27.883 |   1.0724 |     33.824 |     3.8
   26 |   0.8564 |     27.178 |   1.0693 |     32.904 |     3.9
   27 |   0.8504 |     27.075 |   1.0699 |     32.475 |     4.1
   28 |   0.8296 |     26.403 |   1.0740 |     32.690 |     4.2
   29 |   0.8137 |     26.051 |   1.0589 |     32.629 |     4.4
   30 |   0.7954 |     25.444 |   1.0590 |     32.047 |     4.5
   31 |   0.7866 |     25.168 |   1.0628 |     31.924 |     4.7
   32 |   0.7759 |     24.751 |   1.0536 |     31.648 |     4.8
   33 |   0.7601 |     24.512 |   1.0592 |     31.281 |     5.0
   34 |   0.7475 |     23.960 |   1.0547 |     30.944 |     5.1
   35 |   0.7366 |     23.840 |   1.0652 |     31.464 |     5.3
   36 |   0.7323 |     23.667 |   1.0570 |     31.434 |     5.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 155,938

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0539 |     52.693 |   1.4665 |     44.761 |     0.1
    2 |   1.3994 |     43.774 |   1.2767 |     41.330 |     0.2
    3 |   1.2704 |     41.228 |   1.1856 |     39.583 |     0.3
    4 |   1.1911 |     39.191 |   1.1408 |     37.040 |     0.3
    5 |   1.1302 |     36.974 |   1.0756 |     35.600 |     0.4
    6 |   1.0769 |     35.517 |   1.0287 |     34.191 |     0.5
    7 |   1.0424 |     34.314 |   1.0129 |     33.609 |     0.6
    8 |   1.0030 |     33.469 |   0.9862 |     31.955 |     0.7
    9 |   0.9691 |     32.185 |   0.9677 |     32.721 |     0.8
   10 |   0.9293 |     31.356 |   0.9371 |     31.342 |     0.8
   11 |   0.9013 |     29.871 |   0.9358 |     30.944 |     0.9
   12 |   0.8733 |     29.508 |   0.9280 |     30.944 |     1.0
   13 |   0.8601 |     29.107 |   0.8852 |     29.381 |     1.1
   14 |   0.8334 |     28.061 |   0.8966 |     29.718 |     1.2
   15 |   0.8023 |     27.205 |   0.8806 |     28.401 |     1.3
   16 |   0.7888 |     26.685 |   0.8691 |     28.830 |     1.3
   17 |   0.7578 |     25.585 |   0.8646 |     28.431 |     1.4
   18 |   0.7423 |     25.179 |   0.8569 |     27.543 |     1.5
   19 |   0.7249 |     24.648 |   0.8626 |     28.156 |     1.6
   20 |   0.7154 |     24.502 |   0.8440 |     27.267 |     1.7
   21 |   0.6846 |     23.456 |   0.8402 |     27.022 |     1.8
   22 |   0.6780 |     23.011 |   0.8530 |     26.685 |     1.8
   23 |   0.6649 |     22.735 |   0.8646 |     27.083 |     1.9
   24 |   0.6558 |     22.345 |   0.8597 |     26.961 |     2.0
   25 |   0.6414 |     21.998 |   0.8535 |     25.980 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 303,138

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6069 |     65.312 |   2.0637 |     48.989 |     0.1
    2 |   1.7577 |     46.462 |   1.5866 |     44.240 |     0.1
    3 |   1.5049 |     43.292 |   1.4477 |     41.605 |     0.2
    4 |   1.3931 |     41.390 |   1.3729 |     40.319 |     0.2
    5 |   1.3104 |     39.499 |   1.3023 |     38.572 |     0.3
    6 |   1.2462 |     37.879 |   1.2486 |     37.592 |     0.4
    7 |   1.1888 |     36.281 |   1.2150 |     36.795 |     0.4
    8 |   1.1408 |     35.132 |   1.1760 |     35.294 |     0.5
    9 |   1.0995 |     34.005 |   1.1484 |     35.080 |     0.6
   10 |   1.0584 |     32.689 |   1.1309 |     34.375 |     0.6
   11 |   1.0269 |     32.033 |   1.0992 |     33.640 |     0.7
   12 |   0.9913 |     30.966 |   1.0855 |     33.241 |     0.7
   13 |   0.9647 |     30.093 |   1.0722 |     33.211 |     0.8
   14 |   0.9381 |     29.318 |   1.0556 |     32.935 |     0.9
   15 |   0.9061 |     28.240 |   1.0338 |     31.985 |     0.9
   16 |   0.8805 |     27.492 |   1.0181 |     31.342 |     1.0
   17 |   0.8521 |     26.772 |   1.0085 |     31.434 |     1.1
   18 |   0.8242 |     25.932 |   0.9964 |     31.127 |     1.1
   19 |   0.8007 |     25.130 |   0.9857 |     30.055 |     1.2
   20 |   0.7765 |     24.382 |   0.9803 |     30.208 |     1.2
   21 |   0.7554 |     23.510 |   0.9586 |     29.228 |     1.3
   22 |   0.7355 |     23.337 |   0.9573 |     29.289 |     1.4
   23 |   0.7141 |     22.182 |   0.9583 |     29.810 |     1.4
   24 |   0.6962 |     21.792 |   0.9403 |     28.738 |     1.5
   25 |   0.6826 |     21.527 |   0.9396 |     28.615 |     1.6
   26 |   0.6628 |     20.443 |   0.9356 |     28.646 |     1.6
   27 |   0.6429 |     19.891 |   0.9304 |     27.941 |     1.7
   28 |   0.6267 |     19.392 |   0.9335 |     28.339 |     1.7
   29 |   0.6185 |     19.468 |   0.9480 |     28.493 |     1.8
   30 |   0.6037 |     18.942 |   0.9288 |     28.339 |     1.9
   31 |   0.5883 |     18.666 |   0.9278 |     27.727 |     1.9
   32 |   0.5713 |     18.070 |   0.9486 |     28.278 |     2.0
   33 |   0.5628 |     17.913 |   0.9257 |     27.175 |     2.1
   34 |   0.5498 |     17.387 |   0.9379 |     27.237 |     2.1
   35 |   0.5461 |     17.268 |   0.9267 |     26.471 |     2.2
   36 |   0.5314 |     16.981 |   0.9294 |     26.869 |     2.2
   37 |   0.5113 |     16.450 |   0.9343 |     26.716 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,140,898

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0083 |     52.308 |   1.4312 |     41.850 |     0.1
    2 |   1.3317 |     40.426 |   1.2553 |     36.458 |     0.2
    3 |   1.1971 |     37.153 |   1.1769 |     36.275 |     0.3
    4 |   1.0970 |     33.902 |   1.0947 |     33.732 |     0.4
    5 |   1.0087 |     31.675 |   1.0394 |     32.659 |     0.6
    6 |   0.9386 |     29.692 |   0.9836 |     31.464 |     0.7
    7 |   0.8778 |     27.525 |   0.9442 |     29.626 |     0.8
    8 |   0.8145 |     25.303 |   0.9205 |     28.768 |     0.9
    9 |   0.7765 |     24.274 |   0.9069 |     28.339 |     1.0
   10 |   0.7288 |     22.844 |   0.8590 |     27.175 |     1.1
   11 |   0.6814 |     21.413 |   0.8378 |     25.950 |     1.2
   12 |   0.6401 |     20.156 |   0.8355 |     25.643 |     1.3
   13 |   0.6157 |     19.251 |   0.8118 |     24.816 |     1.5
   14 |   0.5869 |     18.401 |   0.8064 |     25.582 |     1.6
   15 |   0.5496 |     17.328 |   0.7913 |     24.540 |     1.7
   16 |   0.5068 |     15.881 |   0.8068 |     24.387 |     1.8
   17 |   0.4841 |     15.339 |   0.7902 |     24.326 |     1.9
   18 |   0.4701 |     14.960 |   0.8072 |     25.092 |     2.0
   19 |   0.4586 |     14.342 |   0.7836 |     24.081 |     2.1
   20 |   0.4205 |     13.340 |   0.7954 |     23.744 |     2.3
   21 |   0.4026 |     13.156 |   0.7983 |     23.897 |     2.4
   22 |   0.3841 |     12.300 |   0.7839 |     22.825 |     2.5
   23 |   0.3588 |     11.454 |   0.7945 |     22.365 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 126,242

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1361 |     55.153 |   1.4643 |     44.822 |     0.1
    2 |   1.4310 |     44.311 |   1.2956 |     42.034 |     0.2
    3 |   1.3096 |     42.138 |   1.2239 |     40.012 |     0.2
    4 |   1.2416 |     40.529 |   1.1625 |     37.990 |     0.3
    5 |   1.1871 |     39.001 |   1.1263 |     37.010 |     0.4
    6 |   1.1364 |     37.186 |   1.0971 |     35.631 |     0.5
    7 |   1.1006 |     36.368 |   1.0786 |     35.386 |     0.6
    8 |   1.0630 |     35.046 |   1.0527 |     34.926 |     0.7
    9 |   1.0383 |     34.254 |   1.0284 |     34.344 |     0.7
   10 |   1.0062 |     33.306 |   1.0048 |     32.659 |     0.8
   11 |   0.9751 |     32.320 |   0.9906 |     32.200 |     0.9
   12 |   0.9611 |     31.827 |   0.9920 |     32.659 |     1.0
   13 |   0.9327 |     30.884 |   0.9755 |     32.138 |     1.1
   14 |   0.9151 |     30.581 |   0.9714 |     31.863 |     1.2
   15 |   0.8891 |     29.595 |   0.9705 |     31.801 |     1.2
   16 |   0.8734 |     29.167 |   0.9584 |     30.944 |     1.3
   17 |   0.8561 |     28.170 |   0.9450 |     31.219 |     1.4
   18 |   0.8412 |     27.530 |   0.9452 |     30.208 |     1.5
   19 |   0.8184 |     27.465 |   0.9517 |     29.933 |     1.6
   20 |   0.7987 |     26.788 |   0.9596 |     30.025 |     1.6
   21 |   0.7879 |     26.187 |   0.9384 |     29.657 |     1.7
   22 |   0.7767 |     26.062 |   0.9339 |     30.147 |     1.8
   23 |   0.7597 |     25.840 |   0.9462 |     29.167 |     1.9
   24 |   0.7462 |     25.011 |   0.9608 |     30.392 |     2.0
   25 |   0.7414 |     25.368 |   0.9402 |     29.044 |     2.1
   26 |   0.7197 |     24.117 |   0.9531 |     29.320 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 160,226

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.2179 |     81.507 |   2.8469 |     64.828 |     0.1
    2 |   2.7346 |     63.226 |   2.3401 |     54.197 |     0.1
    3 |   2.3418 |     53.305 |   1.9972 |     48.039 |     0.2
    4 |   2.0503 |     48.190 |   1.7898 |     45.650 |     0.3
    5 |   1.8628 |     46.559 |   1.6752 |     45.588 |     0.4
    6 |   1.7457 |     46.001 |   1.5943 |     45.190 |     0.5
    7 |   1.6674 |     45.411 |   1.5362 |     43.934 |     0.5
    8 |   1.6040 |     44.988 |   1.4898 |     42.984 |     0.6
    9 |   1.5531 |     44.630 |   1.4514 |     42.708 |     0.7
   10 |   1.5087 |     43.834 |   1.4166 |     41.728 |     0.8
   11 |   1.4715 |     43.482 |   1.3920 |     41.513 |     0.8
   12 |   1.4402 |     42.832 |   1.3641 |     40.962 |     0.9
   13 |   1.4131 |     42.301 |   1.3366 |     40.502 |     1.0
   14 |   1.3803 |     41.818 |   1.3142 |     40.196 |     1.1
   15 |   1.3606 |     41.634 |   1.2980 |     39.308 |     1.1
   16 |   1.3331 |     41.179 |   1.2778 |     39.828 |     1.2
   17 |   1.3119 |     40.307 |   1.2677 |     39.706 |     1.3
   18 |   1.2940 |     40.242 |   1.2527 |     39.124 |     1.4
   19 |   1.2717 |     39.830 |   1.2398 |     39.001 |     1.4
   20 |   1.2614 |     39.434 |   1.2293 |     38.143 |     1.5
   21 |   1.2399 |     39.039 |   1.2178 |     37.377 |     1.6
   22 |   1.2292 |     38.562 |   1.2051 |     37.194 |     1.7
   23 |   1.2111 |     37.906 |   1.2017 |     37.010 |     1.7
   24 |   1.1965 |     37.776 |   1.1918 |     36.275 |     1.8
   25 |   1.1858 |     37.663 |   1.1821 |     36.397 |     1.9
   26 |   1.1698 |     36.980 |   1.1798 |     36.458 |     2.0
   27 |   1.1601 |     36.563 |   1.1778 |     36.183 |     2.0
   28 |   1.1528 |     36.633 |   1.1675 |     36.183 |     2.1
   29 |   1.1366 |     36.107 |   1.1607 |     35.539 |     2.2
   30 |   1.1274 |     35.891 |   1.1500 |     35.080 |     2.2
   31 |   1.1135 |     35.457 |   1.1525 |     35.754 |     2.3
   32 |   1.1065 |     34.872 |   1.1579 |     35.754 |     2.4
   33 |   1.0958 |     35.029 |   1.1433 |     35.876 |     2.5
   34 |   1.0832 |     34.509 |   1.1416 |     34.988 |     2.6
   35 |   1.0802 |     34.623 |   1.1360 |     34.436 |     2.6
   36 |   1.0694 |     34.162 |   1.1342 |     34.589 |     2.7
   37 |   1.0581 |     33.415 |   1.1297 |     34.069 |     2.8
   38 |   1.0562 |     33.518 |   1.1311 |     35.110 |     2.8
   39 |   1.0435 |     33.398 |   1.1286 |     34.589 |     2.9
   40 |   1.0363 |     33.431 |   1.1200 |     34.344 |     3.0
   41 |   1.0270 |     33.203 |   1.1236 |     34.712 |     3.1
   42 |   1.0214 |     32.699 |   1.1269 |     34.835 |     3.1
   43 |   1.0095 |     32.179 |   1.1124 |     35.202 |     3.2
   44 |   1.0026 |     32.244 |   1.1147 |     34.314 |     3.3
   45 |   0.9951 |     31.968 |   1.1131 |     34.681 |     3.4
   46 |   0.9917 |     31.795 |   1.1055 |     34.865 |     3.4
   47 |   0.9849 |     31.795 |   1.1117 |     34.344 |     3.5
   48 |   0.9782 |     31.307 |   1.1157 |     34.375 |     3.6
   49 |   0.9702 |     31.339 |   1.1219 |     34.620 |     3.7
   50 |   0.9648 |     31.301 |   1.1164 |     34.773 |     3.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 911,010

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4095 |     57.959 |   1.6782 |     48.223 |     0.1
    2 |   1.5900 |     44.603 |   1.3645 |     40.564 |     0.3
    3 |   1.3784 |     41.325 |   1.2499 |     38.542 |     0.4
    4 |   1.2730 |     39.071 |   1.1826 |     37.316 |     0.6
    5 |   1.1953 |     37.289 |   1.1308 |     35.355 |     0.7
    6 |   1.1408 |     35.360 |   1.0974 |     34.222 |     0.8
    7 |   1.0888 |     33.978 |   1.0539 |     32.935 |     1.0
    8 |   1.0397 |     32.353 |   1.0285 |     31.985 |     1.1
    9 |   1.0001 |     31.242 |   1.0029 |     32.138 |     1.3
   10 |   0.9632 |     30.321 |   0.9850 |     31.710 |     1.4
   11 |   0.9293 |     29.140 |   0.9872 |     31.403 |     1.5
   12 |   0.8922 |     28.110 |   0.9495 |     30.239 |     1.7
   13 |   0.8718 |     27.362 |   0.9609 |     30.699 |     1.8
   14 |   0.8380 |     26.268 |   0.9502 |     29.994 |     2.0
   15 |   0.8186 |     25.656 |   0.9288 |     29.565 |     2.1
   16 |   0.7914 |     24.930 |   0.9125 |     28.339 |     2.2
   17 |   0.7622 |     24.144 |   0.9098 |     28.676 |     2.4
   18 |   0.7449 |     23.710 |   0.9162 |     28.339 |     2.5
   19 |   0.7207 |     22.827 |   0.9179 |     28.768 |     2.7
   20 |   0.7037 |     22.573 |   0.9085 |     28.922 |     2.8
   21 |   0.6896 |     21.917 |   0.9176 |     28.707 |     2.9
   22 |   0.6714 |     21.706 |   0.9056 |     28.217 |     3.1
   23 |   0.6521 |     20.850 |   0.9141 |     27.175 |     3.2
   24 |   0.6333 |     20.346 |   0.9271 |     28.462 |     3.4
   25 |   0.6256 |     20.329 |   0.9306 |     28.002 |     3.5
   26 |   0.6087 |     19.528 |   0.9182 |     27.604 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 231,170

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9890 |     72.188 |   2.3656 |     51.042 |     0.1
    2 |   2.2017 |     48.093 |   1.8902 |     44.975 |     0.3
    3 |   1.8989 |     45.568 |   1.7363 |     44.792 |     0.4
    4 |   1.7585 |     44.901 |   1.6366 |     43.750 |     0.5
    5 |   1.6585 |     43.861 |   1.5538 |     42.923 |     0.6
    6 |   1.5796 |     42.891 |   1.4888 |     41.667 |     0.8
    7 |   1.5108 |     42.084 |   1.4304 |     39.828 |     0.9
    8 |   1.4559 |     41.488 |   1.3865 |     38.971 |     1.0
    9 |   1.3998 |     40.236 |   1.3380 |     38.266 |     1.2
   10 |   1.3546 |     39.239 |   1.3021 |     37.806 |     1.3
   11 |   1.3167 |     38.497 |   1.2725 |     37.316 |     1.4
   12 |   1.2812 |     37.988 |   1.2472 |     36.734 |     1.6
   13 |   1.2529 |     37.327 |   1.2155 |     36.520 |     1.7
   14 |   1.2228 |     36.487 |   1.1945 |     35.631 |     1.8
   15 |   1.1931 |     35.701 |   1.1785 |     35.631 |     2.0
   16 |   1.1649 |     34.997 |   1.1548 |     34.835 |     2.1
   17 |   1.1424 |     34.715 |   1.1308 |     34.498 |     2.2
   18 |   1.1220 |     34.303 |   1.1193 |     34.222 |     2.3
   19 |   1.0985 |     33.528 |   1.1082 |     33.977 |     2.5
   20 |   1.0766 |     32.992 |   1.0907 |     33.027 |     2.6
   21 |   1.0568 |     32.531 |   1.0760 |     32.874 |     2.7
   22 |   1.0393 |     31.908 |   1.0683 |     33.364 |     2.9
   23 |   1.0277 |     31.540 |   1.0587 |     32.751 |     3.0
   24 |   1.0087 |     31.063 |   1.0575 |     32.077 |     3.1
   25 |   0.9912 |     30.657 |   1.0389 |     32.292 |     3.3
   26 |   0.9799 |     30.348 |   1.0358 |     31.801 |     3.4
   27 |   0.9623 |     29.996 |   1.0267 |     31.618 |     3.5
   28 |   0.9478 |     29.676 |   1.0176 |     31.495 |     3.6
   29 |   0.9366 |     29.058 |   1.0154 |     31.373 |     3.8
   30 |   0.9269 |     28.934 |   1.0022 |     31.097 |     3.9
   31 |   0.9142 |     28.706 |   1.0024 |     31.250 |     4.0
   32 |   0.8928 |     28.289 |   0.9892 |     31.219 |     4.2
   33 |   0.8834 |     27.969 |   0.9936 |     30.974 |     4.3
   34 |   0.8705 |     27.373 |   0.9955 |     30.944 |     4.4
   35 |   0.8575 |     27.119 |   0.9816 |     29.963 |     4.5
   36 |   0.8506 |     26.875 |   0.9728 |     29.810 |     4.7
   37 |   0.8465 |     26.896 |   0.9773 |     30.239 |     4.8
   38 |   0.8314 |     26.067 |   0.9774 |     30.607 |     4.9
   39 |   0.8193 |     25.737 |   0.9683 |     29.596 |     5.1
   40 |   0.8130 |     26.008 |   0.9660 |     29.412 |     5.2
   41 |   0.8082 |     25.656 |   0.9534 |     29.779 |     5.3
   42 |   0.7958 |     25.309 |   0.9507 |     29.534 |     5.5
   43 |   0.7795 |     24.837 |   0.9576 |     29.534 |     5.6
   44 |   0.7741 |     24.729 |   0.9619 |     29.534 |     5.7
   45 |   0.7736 |     24.539 |   0.9469 |     30.423 |     5.8
   46 |   0.7588 |     24.111 |   0.9470 |     28.830 |     6.0
   47 |   0.7553 |     23.943 |   0.9554 |     29.412 |     6.1
   48 |   0.7519 |     23.840 |   0.9565 |     29.289 |     6.2
   49 |   0.7407 |     23.667 |   0.9397 |     29.136 |     6.4
   50 |   0.7275 |     23.445 |   0.9463 |     29.013 |     6.5
   51 |   0.7267 |     23.304 |   0.9465 |     29.381 |     6.6
   52 |   0.7140 |     22.957 |   0.9458 |     29.105 |     6.8
   53 |   0.7081 |     22.784 |   0.9429 |     28.768 |     6.9
   54 |   0.6975 |     22.480 |   0.9358 |     28.462 |     7.0
   55 |   0.6958 |     22.410 |   0.9520 |     28.891 |     7.1
   56 |   0.6883 |     21.939 |   0.9359 |     28.309 |     7.3
   57 |   0.6794 |     21.689 |   0.9503 |     28.554 |     7.4
   58 |   0.6727 |     21.516 |   0.9459 |     28.462 |     7.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 379,298

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8674 |     51.701 |   1.3360 |     43.199 |     0.1
    2 |   1.3138 |     42.604 |   1.2041 |     38.266 |     0.2
    3 |   1.2079 |     39.673 |   1.1455 |     37.071 |     0.3
    4 |   1.1363 |     37.825 |   1.0775 |     35.355 |     0.4
    5 |   1.0677 |     35.501 |   1.0573 |     35.386 |     0.5
    6 |   1.0260 |     34.596 |   0.9888 |     32.506 |     0.6
    7 |   0.9768 |     32.970 |   0.9546 |     32.475 |     0.7
    8 |   0.9347 |     31.507 |   0.9365 |     31.127 |     0.8
    9 |   0.9078 |     30.424 |   0.9266 |     31.219 |     0.9
   10 |   0.8743 |     29.112 |   0.9196 |     30.362 |     1.0
   11 |   0.8445 |     28.652 |   0.8997 |     29.902 |     1.1
   12 |   0.8212 |     27.698 |   0.8648 |     28.554 |     1.2
   13 |   0.7838 |     26.306 |   0.8752 |     29.136 |     1.3
   14 |   0.7755 |     26.311 |   0.8339 |     27.114 |     1.4
   15 |   0.7484 |     25.672 |   0.8717 |     28.370 |     1.5
   16 |   0.7245 |     24.556 |   0.8621 |     29.596 |     1.6
   17 |   0.7124 |     24.030 |   0.8732 |     28.370 |     1.7
   18 |   0.6831 |     23.120 |   0.8450 |     28.217 |     1.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,009,698

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4604 |     59.948 |   1.6870 |     46.415 |     0.2
    2 |   1.6432 |     45.183 |   1.3830 |     41.452 |     0.4
    3 |   1.4340 |     42.821 |   1.2807 |     39.645 |     0.5
    4 |   1.3333 |     41.081 |   1.2222 |     37.806 |     0.7
    5 |   1.2566 |     39.174 |   1.1860 |     36.520 |     0.9
    6 |   1.2066 |     37.831 |   1.1487 |     35.478 |     1.1
    7 |   1.1601 |     36.308 |   1.1092 |     34.681 |     1.3
    8 |   1.1073 |     34.980 |   1.1004 |     34.498 |     1.4
    9 |   1.0732 |     34.162 |   1.0857 |     34.130 |     1.6
   10 |   1.0382 |     32.667 |   1.0820 |     33.517 |     1.8
   11 |   1.0062 |     32.006 |   1.0544 |     32.475 |     2.0
   12 |   0.9678 |     30.657 |   1.0295 |     32.690 |     2.2
   13 |   0.9393 |     29.746 |   1.0284 |     31.679 |     2.3
   14 |   0.9119 |     28.825 |   1.0237 |     31.863 |     2.5
   15 |   0.8884 |     28.359 |   1.0102 |     31.710 |     2.7
   16 |   0.8641 |     27.525 |   1.0119 |     31.587 |     2.9
   17 |   0.8424 |     26.777 |   1.0169 |     31.158 |     3.1
   18 |   0.8242 |     26.458 |   1.0293 |     31.097 |     3.3
   19 |   0.7985 |     25.802 |   1.0203 |     30.637 |     3.4
   20 |   0.7818 |     25.098 |   0.9972 |     30.025 |     3.6
   21 |   0.7685 |     24.913 |   0.9989 |     29.871 |     3.8
   22 |   0.7340 |     23.618 |   1.0122 |     30.637 |     4.0
   23 |   0.7214 |     23.066 |   0.9861 |     29.779 |     4.2
   24 |   0.7071 |     22.703 |   1.0001 |     29.167 |     4.3
   25 |   0.6824 |     22.069 |   0.9920 |     28.554 |     4.5
   26 |   0.6687 |     21.679 |   1.0111 |     29.749 |     4.7
   27 |   0.6570 |     21.245 |   1.0205 |     29.963 |     4.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 295,330

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7024 |     48.017 |   1.2991 |     42.065 |     0.1
    2 |   1.2337 |     40.160 |   1.1673 |     38.266 |     0.2
    3 |   1.1109 |     36.823 |   1.0879 |     35.846 |     0.2
    4 |   1.0137 |     33.555 |   1.0207 |     33.762 |     0.3
    5 |   0.9499 |     32.158 |   0.9595 |     32.537 |     0.4
    6 |   0.8857 |     29.671 |   0.9257 |     30.607 |     0.5
    7 |   0.8371 |     27.926 |   0.8875 |     30.025 |     0.6
    8 |   0.7903 |     26.636 |   0.8907 |     29.963 |     0.6
    9 |   0.7541 |     25.607 |   0.8524 |     28.707 |     0.7
   10 |   0.7095 |     24.008 |   0.8381 |     28.278 |     0.8
   11 |   0.6724 |     22.800 |   0.8552 |     27.727 |     0.9
   12 |   0.6599 |     22.616 |   0.8125 |     27.053 |     0.9
   13 |   0.6314 |     21.614 |   0.8196 |     27.420 |     1.0
   14 |   0.6026 |     20.579 |   0.8271 |     26.103 |     1.1
   15 |   0.5791 |     19.587 |   0.8032 |     25.582 |     1.2
   16 |   0.5564 |     19.051 |   0.8194 |     25.827 |     1.3
   17 |   0.5406 |     18.856 |   0.8050 |     25.184 |     1.3
   18 |   0.5132 |     17.463 |   0.7995 |     25.766 |     1.4
   19 |   0.4955 |     17.095 |   0.7824 |     24.265 |     1.5
   20 |   0.4786 |     16.640 |   0.8104 |     25.184 |     1.6
   21 |   0.4548 |     15.854 |   0.8257 |     26.164 |     1.7
   22 |   0.4488 |     15.448 |   0.8016 |     23.866 |     1.7
   23 |   0.4274 |     14.911 |   0.8174 |     25.460 |     1.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 894,178

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6251 |     67.431 |   1.8013 |     48.039 |     0.1
    2 |   1.7120 |     45.844 |   1.4047 |     42.310 |     0.2
    3 |   1.4600 |     43.173 |   1.3024 |     40.901 |     0.3
    4 |   1.3500 |     41.428 |   1.2391 |     38.664 |     0.5
    5 |   1.2883 |     40.106 |   1.2040 |     37.714 |     0.6
    6 |   1.2390 |     39.104 |   1.1627 |     35.600 |     0.7
    7 |   1.1851 |     37.565 |   1.1316 |     35.049 |     0.8
    8 |   1.1529 |     36.698 |   1.1083 |     34.712 |     0.9
    9 |   1.1180 |     35.360 |   1.0937 |     34.712 |     1.0
   10 |   1.0825 |     34.585 |   1.0750 |     34.314 |     1.2
   11 |   1.0562 |     33.415 |   1.0665 |     33.824 |     1.3
   12 |   1.0298 |     32.905 |   1.0414 |     33.027 |     1.4
   13 |   1.0047 |     32.212 |   1.0345 |     33.088 |     1.5
   14 |   0.9746 |     30.987 |   1.0280 |     32.384 |     1.6
   15 |   0.9607 |     31.041 |   1.0157 |     31.924 |     1.7
   16 |   0.9322 |     29.904 |   1.0100 |     31.924 |     1.9
   17 |   0.9160 |     29.351 |   1.0108 |     31.740 |     2.0
   18 |   0.8956 |     28.831 |   1.0141 |     31.832 |     2.1
   19 |   0.8794 |     28.408 |   1.0025 |     31.801 |     2.2
   20 |   0.8559 |     28.013 |   0.9851 |     31.005 |     2.3
   21 |   0.8378 |     27.335 |   0.9766 |     30.147 |     2.4
   22 |   0.8240 |     26.772 |   0.9998 |     31.740 |     2.6
   23 |   0.8086 |     26.327 |   1.0005 |     31.189 |     2.7
   24 |   0.7964 |     26.138 |   0.9786 |     30.178 |     2.8
   25 |   0.7802 |     25.428 |   0.9788 |     30.453 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 552,674

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8453 |     71.207 |   2.0265 |     49.510 |     0.1
    2 |   1.9198 |     47.751 |   1.5739 |     43.689 |     0.3
    3 |   1.6320 |     45.134 |   1.4591 |     42.463 |     0.4
    4 |   1.5227 |     44.251 |   1.3800 |     42.188 |     0.6
    5 |   1.4458 |     43.298 |   1.3306 |     40.901 |     0.7
    6 |   1.3855 |     41.851 |   1.2909 |     39.920 |     0.9
    7 |   1.3339 |     41.071 |   1.2619 |     39.032 |     1.0
    8 |   1.2951 |     39.732 |   1.2262 |     37.316 |     1.1
    9 |   1.2551 |     38.714 |   1.2115 |     37.377 |     1.3
   10 |   1.2215 |     37.939 |   1.1899 |     36.826 |     1.4
   11 |   1.1922 |     37.202 |   1.1619 |     35.938 |     1.6
   12 |   1.1645 |     36.232 |   1.1527 |     35.631 |     1.7
   13 |   1.1393 |     35.409 |   1.1430 |     34.681 |     1.8
   14 |   1.1116 |     34.672 |   1.1196 |     34.161 |     2.0
   15 |   1.0858 |     34.070 |   1.1159 |     34.191 |     2.1
   16 |   1.0663 |     33.230 |   1.1189 |     34.773 |     2.3
   17 |   1.0447 |     32.922 |   1.1061 |     34.865 |     2.4
   18 |   1.0178 |     31.572 |   1.0996 |     33.701 |     2.6
   19 |   1.0012 |     31.432 |   1.0768 |     32.506 |     2.7
   20 |   0.9811 |     31.058 |   1.0684 |     33.487 |     2.8
   21 |   0.9647 |     30.516 |   1.0612 |     32.537 |     3.0
   22 |   0.9493 |     30.109 |   1.0691 |     33.027 |     3.1
   23 |   0.9268 |     29.660 |   1.0557 |     32.537 |     3.3
   24 |   0.9144 |     29.069 |   1.0620 |     32.537 |     3.4
   25 |   0.9025 |     28.560 |   1.0511 |     32.200 |     3.6
   26 |   0.8824 |     28.354 |   1.0569 |     32.047 |     3.7
   27 |   0.8671 |     27.709 |   1.0407 |     31.066 |     3.8
   28 |   0.8551 |     27.287 |   1.0417 |     32.230 |     4.0
   29 |   0.8466 |     27.135 |   1.0305 |     30.974 |     4.1
   30 |   0.8290 |     26.788 |   1.0417 |     32.016 |     4.3
   31 |   0.8063 |     25.921 |   1.0420 |     30.576 |     4.4
   32 |   0.8031 |     26.013 |   1.0494 |     32.384 |     4.6
   33 |   0.7851 |     25.358 |   1.0495 |     30.944 |     4.7
   34 |   0.7804 |     25.098 |   1.0259 |     31.403 |     4.8
   35 |   0.7637 |     24.789 |   1.0206 |     30.362 |     5.0
   36 |   0.7555 |     24.604 |   1.0319 |     30.913 |     5.1
   37 |   0.7464 |     23.992 |   1.0265 |     30.178 |     5.3
   38 |   0.7344 |     23.900 |   1.0225 |     30.055 |     5.4
   39 |   0.7226 |     23.342 |   1.0477 |     30.852 |     5.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 159,522

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8252 |     48.423 |   1.4096 |     44.240 |     0.1
    2 |   1.2912 |     40.659 |   1.2137 |     37.500 |     0.1
    3 |   1.1475 |     36.817 |   1.1076 |     34.865 |     0.2
    4 |   1.0496 |     34.162 |   1.0317 |     33.425 |     0.2
    5 |   0.9736 |     32.000 |   1.0060 |     33.548 |     0.3
    6 |   0.9081 |     30.007 |   0.9736 |     32.384 |     0.3
    7 |   0.8574 |     28.365 |   0.9179 |     30.882 |     0.4
    8 |   0.8063 |     26.766 |   0.8986 |     29.565 |     0.5
    9 |   0.7563 |     25.016 |   0.8976 |     29.167 |     0.5
   10 |   0.7193 |     24.057 |   0.8692 |     28.248 |     0.6
   11 |   0.6792 |     22.600 |   0.8626 |     28.186 |     0.6
   12 |   0.6537 |     21.819 |   0.8545 |     28.431 |     0.7
   13 |   0.6406 |     21.971 |   0.8217 |     26.501 |     0.7
   14 |   0.5793 |     19.576 |   0.8356 |     26.134 |     0.8
   15 |   0.5652 |     18.921 |   0.8294 |     26.256 |     0.9
   16 |   0.5313 |     17.550 |   0.8075 |     25.153 |     0.9
   17 |   0.5233 |     17.658 |   0.8212 |     24.540 |     1.0
   18 |   0.5040 |     17.198 |   0.8052 |     24.540 |     1.0
   19 |   0.4686 |     15.919 |   0.8166 |     25.153 |     1.1
   20 |   0.4554 |     15.897 |   0.8141 |     23.958 |     1.1
   21 |   0.4398 |     14.830 |   0.8251 |     24.295 |     1.2
   22 |   0.4124 |     14.337 |   0.8287 |     23.683 |     1.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,209,890

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1100 |     54.248 |   1.4654 |     42.831 |     0.2
    2 |   1.3717 |     41.905 |   1.2917 |     39.614 |     0.4
    3 |   1.2291 |     38.313 |   1.1914 |     36.091 |     0.5
    4 |   1.1390 |     35.560 |   1.1262 |     35.141 |     0.7
    5 |   1.0516 |     32.781 |   1.0923 |     34.467 |     0.9
    6 |   0.9794 |     30.397 |   1.0334 |     32.292 |     1.1
    7 |   0.9134 |     28.256 |   0.9606 |     30.055 |     1.3
    8 |   0.8549 |     26.360 |   0.9471 |     29.473 |     1.5
    9 |   0.8077 |     24.967 |   0.9060 |     28.125 |     1.7
   10 |   0.7697 |     23.591 |   0.8994 |     27.420 |     1.8
   11 |   0.7215 |     22.172 |   0.8768 |     27.114 |     2.0
   12 |   0.6823 |     21.137 |   0.8699 |     25.919 |     2.2
   13 |   0.6463 |     19.983 |   0.8530 |     26.103 |     2.4
   14 |   0.6155 |     19.295 |   0.8240 |     25.123 |     2.6
   15 |   0.5800 |     17.967 |   0.8468 |     25.980 |     2.8
   16 |   0.5550 |     17.572 |   0.8295 |     25.061 |     2.9
   17 |   0.5252 |     16.786 |   0.8223 |     24.449 |     3.1
   18 |   0.5022 |     15.903 |   0.8326 |     25.337 |     3.3
   19 |   0.4829 |     15.377 |   0.8285 |     25.184 |     3.5
   20 |   0.4543 |     14.423 |   0.8131 |     23.897 |     3.7
   21 |   0.4401 |     13.887 |   0.8051 |     24.724 |     3.9
   22 |   0.4271 |     13.725 |   0.8220 |     23.529 |     4.1
   23 |   0.4123 |     13.199 |   0.8033 |     23.499 |     4.2
   24 |   0.3857 |     12.522 |   0.8033 |     23.131 |     4.4
   25 |   0.3731 |     11.958 |   0.7918 |     23.560 |     4.6
   26 |   0.3627 |     11.498 |   0.8141 |     23.376 |     4.8
   27 |   0.3611 |     11.671 |   0.8149 |     22.855 |     5.0
   28 |   0.3311 |     10.734 |   0.8454 |     23.713 |     5.2
   29 |   0.3286 |     10.772 |   0.8476 |     23.284 |     5.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 810,530

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5239 |     46.039 |   1.2312 |     39.400 |     0.1
    2 |   1.1854 |     39.158 |   1.1185 |     37.040 |     0.2
    3 |   1.0933 |     36.427 |   1.0657 |     36.121 |     0.3
    4 |   1.0213 |     34.076 |   1.0001 |     32.812 |     0.4
    5 |   0.9622 |     32.185 |   0.9594 |     32.506 |     0.5
    6 |   0.9062 |     30.743 |   0.9195 |     30.974 |     0.6
    7 |   0.8662 |     29.573 |   0.9052 |     29.688 |     0.8
    8 |   0.8383 |     28.408 |   0.8906 |     29.412 |     0.9
    9 |   0.8022 |     27.482 |   0.8597 |     28.156 |     1.0
   10 |   0.7659 |     25.964 |   0.8200 |     26.961 |     1.1
   11 |   0.7417 |     25.000 |   0.8327 |     27.604 |     1.2
   12 |   0.7117 |     24.236 |   0.8102 |     27.114 |     1.3
   13 |   0.6726 |     23.114 |   0.8088 |     25.674 |     1.4
   14 |   0.6483 |     22.535 |   0.8402 |     26.838 |     1.5
   15 |   0.6328 |     21.679 |   0.7952 |     25.858 |     1.6
   16 |   0.6295 |     21.419 |   0.7947 |     24.877 |     1.7
   17 |   0.6051 |     21.023 |   0.8032 |     25.398 |     1.8
   18 |   0.5704 |     19.712 |   0.7821 |     25.551 |     1.9
   19 |   0.5581 |     19.463 |   0.7948 |     23.713 |     2.0
   20 |   0.5509 |     18.921 |   0.7925 |     24.877 |     2.2
   21 |   0.5384 |     18.764 |   0.7820 |     24.142 |     2.3
   22 |   0.5062 |     17.582 |   0.8027 |     23.499 |     2.4
   23 |   0.4988 |     17.507 |   0.8002 |     23.315 |     2.5
   24 |   0.4855 |     16.981 |   0.8085 |     23.713 |     2.6
   25 |   0.4750 |     16.900 |   0.8071 |     24.632 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 337,314

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6614 |     47.556 |   1.2835 |     41.330 |     0.1
    2 |   1.2092 |     39.261 |   1.1272 |     36.060 |     0.2
    3 |   1.0814 |     35.755 |   1.0348 |     34.344 |     0.3
    4 |   0.9838 |     32.813 |   1.0007 |     33.977 |     0.3
    5 |   0.9177 |     31.220 |   0.9120 |     30.545 |     0.4
    6 |   0.8474 |     28.522 |   0.9091 |     30.576 |     0.5
    7 |   0.7898 |     26.799 |   0.8729 |     29.565 |     0.6
    8 |   0.7605 |     25.775 |   0.8378 |     27.390 |     0.7
    9 |   0.7185 |     24.258 |   0.8077 |     26.072 |     0.8
   10 |   0.6846 |     23.098 |   0.8028 |     26.624 |     0.9
   11 |   0.6497 |     21.917 |   0.7984 |     26.134 |     0.9
   12 |   0.6298 |     21.624 |   0.7948 |     26.072 |     1.0
   13 |   0.5975 |     20.270 |   0.7903 |     25.276 |     1.1
   14 |   0.5904 |     20.665 |   0.7526 |     24.694 |     1.2
   15 |   0.5553 |     19.029 |   0.7911 |     25.184 |     1.3
   16 |   0.5274 |     18.173 |   0.7640 |     24.387 |     1.4
   17 |   0.5169 |     17.653 |   0.7767 |     23.928 |     1.5
   18 |   0.4951 |     17.116 |   0.7814 |     24.326 |     1.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 977,314

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3290 |     57.932 |   1.5799 |     44.301 |     0.1
    2 |   1.5438 |     43.796 |   1.3628 |     40.931 |     0.3
    3 |   1.3796 |     41.710 |   1.2630 |     39.216 |     0.5
    4 |   1.2842 |     39.629 |   1.1967 |     37.040 |     0.6
    5 |   1.2128 |     37.912 |   1.1463 |     35.355 |     0.8
    6 |   1.1562 |     35.772 |   1.1010 |     35.110 |     0.9
    7 |   1.0994 |     34.894 |   1.0695 |     34.314 |     1.1
    8 |   1.0589 |     33.106 |   1.0407 |     33.609 |     1.2
    9 |   1.0167 |     32.017 |   1.0165 |     32.659 |     1.4
   10 |   0.9800 |     30.922 |   1.0075 |     32.384 |     1.5
   11 |   0.9485 |     30.256 |   0.9746 |     30.790 |     1.7
   12 |   0.9110 |     28.939 |   0.9616 |     30.668 |     1.8
   13 |   0.8822 |     28.040 |   0.9470 |     30.086 |     2.0
   14 |   0.8537 |     27.194 |   0.9434 |     29.596 |     2.1
   15 |   0.8282 |     26.495 |   0.9276 |     29.075 |     2.3
   16 |   0.8088 |     26.176 |   0.9133 |     28.248 |     2.4
   17 |   0.7846 |     25.580 |   0.9194 |     28.676 |     2.6
   18 |   0.7598 |     24.176 |   0.9019 |     27.941 |     2.7
   19 |   0.7396 |     23.651 |   0.8954 |     28.125 |     2.9
   20 |   0.7157 |     23.228 |   0.8786 |     27.083 |     3.0
   21 |   0.6949 |     22.573 |   0.8891 |     27.727 |     3.2
   22 |   0.6770 |     21.641 |   0.8915 |     27.911 |     3.3
   23 |   0.6611 |     21.576 |   0.8738 |     26.838 |     3.5
   24 |   0.6430 |     20.579 |   0.8932 |     27.451 |     3.7
   25 |   0.6299 |     20.432 |   0.8831 |     27.022 |     3.8
   26 |   0.6193 |     20.048 |   0.8835 |     26.900 |     4.0
   27 |   0.6030 |     20.010 |   0.8818 |     26.103 |     4.1
   28 |   0.5800 |     19.110 |   0.8674 |     25.429 |     4.3
   29 |   0.5688 |     18.839 |   0.8882 |     26.287 |     4.4
   30 |   0.5548 |     18.373 |   0.8959 |     26.471 |     4.6
   31 |   0.5413 |     18.227 |   0.8733 |     25.368 |     4.7
   32 |   0.5270 |     17.355 |   0.8983 |     25.521 |     4.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 894,178

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5159 |     45.747 |   1.2026 |     39.093 |     0.1
    2 |   1.1347 |     38.058 |   1.0671 |     35.141 |     0.2
    3 |   1.0282 |     34.032 |   1.0285 |     33.333 |     0.3
    4 |   0.9487 |     31.957 |   0.9576 |     32.108 |     0.4
    5 |   0.8739 |     29.421 |   0.9229 |     30.760 |     0.5
    6 |   0.8266 |     27.823 |   0.8775 |     29.013 |     0.7
    7 |   0.7625 |     25.699 |   0.8990 |     29.473 |     0.8
    8 |   0.7373 |     24.756 |   0.8538 |     28.401 |     0.9
    9 |   0.6973 |     23.591 |   0.8375 |     26.624 |     1.0
   10 |   0.6613 |     22.145 |   0.8265 |     27.237 |     1.1
   11 |   0.6236 |     21.614 |   0.8906 |     29.412 |     1.2
   12 |   0.6136 |     20.871 |   0.7867 |     25.092 |     1.3
   13 |   0.5825 |     19.993 |   0.7968 |     25.521 |     1.4
   14 |   0.5543 |     18.986 |   0.8057 |     25.888 |     1.5
   15 |   0.5552 |     19.327 |   0.7693 |     25.368 |     1.6
   16 |   0.5078 |     17.810 |   0.7810 |     24.510 |     1.7
   17 |   0.4967 |     17.485 |   0.7680 |     23.897 |     1.8
   18 |   0.4762 |     16.542 |   0.7980 |     25.092 |     2.0
   19 |   0.4679 |     16.266 |   0.7881 |     24.081 |     2.1
   20 |   0.4542 |     15.794 |   0.7808 |     24.632 |     2.2
   21 |   0.4281 |     14.998 |   0.7811 |     23.836 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 419,170

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6636 |     65.247 |   1.9728 |     46.078 |     0.1
    2 |   1.9106 |     46.814 |   1.5986 |     43.505 |     0.2
    3 |   1.6463 |     44.993 |   1.4620 |     42.739 |     0.4
    4 |   1.5233 |     43.444 |   1.3877 |     41.942 |     0.5
    5 |   1.4383 |     42.577 |   1.3253 |     40.625 |     0.6
    6 |   1.3746 |     41.212 |   1.2809 |     39.246 |     0.8
    7 |   1.3254 |     40.182 |   1.2476 |     38.297 |     0.9
    8 |   1.2803 |     39.050 |   1.2076 |     37.010 |     1.0
    9 |   1.2413 |     38.378 |   1.1842 |     36.305 |     1.1
   10 |   1.2032 |     37.224 |   1.1729 |     36.612 |     1.3
   11 |   1.1710 |     36.541 |   1.1484 |     35.815 |     1.4
   12 |   1.1465 |     36.015 |   1.1304 |     35.018 |     1.5
   13 |   1.1122 |     35.056 |   1.1193 |     35.018 |     1.6
   14 |   1.0881 |     34.086 |   1.0972 |     34.099 |     1.8
   15 |   1.0675 |     33.626 |   1.0768 |     33.885 |     1.9
   16 |   1.0450 |     32.905 |   1.0718 |     33.640 |     2.0
   17 |   1.0260 |     32.450 |   1.0646 |     33.303 |     2.1
   18 |   1.0072 |     31.854 |   1.0658 |     33.425 |     2.3
   19 |   0.9870 |     31.058 |   1.0540 |     33.150 |     2.4
   20 |   0.9582 |     30.429 |   1.0434 |     32.169 |     2.5
   21 |   0.9424 |     29.969 |   1.0469 |     32.537 |     2.6
   22 |   0.9249 |     29.140 |   1.0279 |     31.863 |     2.8
   23 |   0.9076 |     28.782 |   1.0307 |     31.771 |     2.9
   24 |   0.8894 |     28.381 |   1.0115 |     31.679 |     3.0
   25 |   0.8676 |     27.725 |   1.0135 |     31.097 |     3.1
   26 |   0.8547 |     26.945 |   1.0001 |     31.495 |     3.3
   27 |   0.8363 |     26.707 |   1.0131 |     31.097 |     3.4
   28 |   0.8266 |     26.642 |   1.0000 |     30.699 |     3.5
   29 |   0.8093 |     25.970 |   0.9889 |     30.760 |     3.7
   30 |   0.8007 |     25.807 |   1.0038 |     30.453 |     3.8
   31 |   0.7849 |     25.217 |   0.9934 |     30.331 |     3.9
   32 |   0.7705 |     24.778 |   1.0177 |     30.055 |     4.0
   33 |   0.7597 |     24.323 |   0.9907 |     29.473 |     4.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5414 |     47.231 |   1.2651 |     42.494 |     0.2
    2 |   1.2146 |     40.702 |   1.1256 |     37.806 |     0.4
    3 |   1.1291 |     38.508 |   1.0628 |     36.275 |     0.6
    4 |   1.0689 |     36.346 |   1.0192 |     36.305 |     0.8
    5 |   1.0290 |     35.522 |   1.0175 |     35.386 |     1.0
    6 |   0.9888 |     33.664 |   0.9547 |     32.475 |     1.2
    7 |   0.9405 |     32.201 |   0.9155 |     31.863 |     1.4
    8 |   0.9241 |     31.892 |   0.9216 |     31.618 |     1.6
    9 |   0.8928 |     30.966 |   0.9062 |     31.311 |     1.8
   10 |   0.8710 |     30.012 |   0.8903 |     30.852 |     2.0
   11 |   0.8270 |     28.972 |   0.8632 |     28.922 |     2.2
   12 |   0.8209 |     28.397 |   0.8497 |     30.116 |     2.4
   13 |   0.7935 |     27.812 |   0.8571 |     28.676 |     2.6
   14 |   0.7756 |     26.978 |   0.8166 |     27.574 |     2.8
   15 |   0.7434 |     25.601 |   0.8328 |     29.289 |     3.0
   16 |   0.7264 |     24.940 |   0.8173 |     28.064 |     3.2
   17 |   0.7107 |     24.247 |   0.8245 |     27.482 |     3.4
   18 |   0.6972 |     24.225 |   0.7961 |     27.145 |     3.5
   19 |   0.6876 |     23.868 |   0.8109 |     27.819 |     3.7
   20 |   0.6738 |     23.266 |   0.8085 |     27.175 |     3.9
   21 |   0.6706 |     23.450 |   0.7915 |     26.134 |     4.1
   22 |   0.6272 |     21.473 |   0.7916 |     25.674 |     4.3
   23 |   0.6146 |     21.299 |   0.7735 |     25.460 |     4.5
   24 |   0.6103 |     21.511 |   0.7842 |     25.827 |     4.7
   25 |   0.5979 |     21.137 |   0.7771 |     25.582 |     4.9
   26 |   0.5710 |     19.950 |   0.7647 |     24.571 |     5.1
   27 |   0.5668 |     19.744 |   0.8028 |     25.919 |     5.3
   28 |   0.5477 |     19.392 |   0.7633 |     23.805 |     5.5
   29 |   0.5441 |     19.370 |   0.7872 |     25.368 |     5.7
   30 |   0.5272 |     18.769 |   0.7959 |     25.184 |     5.9
   31 |   0.5171 |     18.444 |   0.7750 |     25.153 |     6.1
   32 |   0.5082 |     17.945 |   0.7614 |     24.050 |     6.3
   33 |   0.4810 |     17.100 |   0.7800 |     23.713 |     6.5
   34 |   0.4823 |     17.176 |   0.7935 |     25.551 |     6.7
   35 |   0.4873 |     17.257 |   0.7548 |     23.621 |     6.9
   36 |   0.4625 |     16.271 |   0.7741 |     23.468 |     7.1
   37 |   0.4635 |     16.298 |   0.7672 |     23.284 |     7.3
   38 |   0.4447 |     15.762 |   0.7942 |     23.897 |     7.5
   39 |   0.4486 |     15.957 |   0.7587 |     22.641 |     7.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5385 |     47.031 |   1.2221 |     41.483 |     0.2
    2 |   1.2016 |     40.556 |   1.1182 |     38.021 |     0.3
    3 |   1.1142 |     37.646 |   1.0949 |     37.684 |     0.5
    4 |   1.0635 |     35.923 |   1.0103 |     33.854 |     0.6
    5 |   1.0049 |     34.070 |   0.9766 |     32.414 |     0.8
    6 |   0.9524 |     32.434 |   0.9521 |     32.475 |     0.9
    7 |   0.9268 |     31.394 |   0.9584 |     32.812 |     1.1
    8 |   0.8749 |     29.687 |   0.9187 |     31.250 |     1.2
    9 |   0.8571 |     29.465 |   0.9179 |     32.138 |     1.4
   10 |   0.8211 |     28.110 |   0.9289 |     31.618 |     1.5
   11 |   0.7844 |     26.994 |   0.9202 |     31.403 |     1.7
   12 |   0.7632 |     26.176 |   0.8582 |     29.933 |     1.9
   13 |   0.7400 |     25.688 |   0.8868 |     30.331 |     2.0
   14 |   0.7233 |     24.940 |   0.8454 |     28.830 |     2.2
   15 |   0.6946 |     23.960 |   0.8443 |     29.473 |     2.3
   16 |   0.6659 |     22.838 |   0.8522 |     28.339 |     2.5
   17 |   0.6574 |     22.638 |   0.8589 |     29.688 |     2.6
   18 |   0.6384 |     22.226 |   0.8814 |     29.044 |     2.8
   19 |   0.6153 |     21.456 |   0.8429 |     28.339 |     2.9
   20 |   0.5930 |     20.931 |   0.8499 |     27.941 |     3.1
   21 |   0.5729 |     19.793 |   0.8888 |     29.013 |     3.2
   22 |   0.5738 |     19.885 |   0.8466 |     27.972 |     3.4
   23 |   0.5453 |     18.980 |   0.8655 |     28.922 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 435,938

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8744 |     73.667 |   2.1904 |     51.562 |     0.1
    2 |   2.0279 |     49.306 |   1.6252 |     46.048 |     0.2
    3 |   1.6709 |     45.806 |   1.4739 |     43.444 |     0.2
    4 |   1.5327 |     44.473 |   1.3944 |     41.452 |     0.3
    5 |   1.4525 |     43.140 |   1.3342 |     40.502 |     0.4
    6 |   1.3921 |     41.889 |   1.2939 |     38.879 |     0.5
    7 |   1.3408 |     40.849 |   1.2594 |     38.082 |     0.5
    8 |   1.2964 |     39.743 |   1.2282 |     37.439 |     0.6
    9 |   1.2589 |     38.876 |   1.2068 |     37.071 |     0.7
   10 |   1.2300 |     38.107 |   1.1742 |     36.060 |     0.8
   11 |   1.1983 |     37.191 |   1.1607 |     35.999 |     0.8
   12 |   1.1695 |     36.503 |   1.1379 |     35.325 |     0.9
   13 |   1.1410 |     35.474 |   1.1259 |     35.080 |     1.0
   14 |   1.1222 |     35.262 |   1.1200 |     34.283 |     1.1
   15 |   1.0948 |     34.347 |   1.0990 |     34.589 |     1.2
   16 |   1.0697 |     33.469 |   1.0889 |     33.609 |     1.2
   17 |   1.0511 |     33.285 |   1.0692 |     32.812 |     1.3
   18 |   1.0310 |     32.721 |   1.0662 |     32.966 |     1.4
   19 |   1.0086 |     31.664 |   1.0548 |     32.812 |     1.5
   20 |   0.9920 |     31.594 |   1.0468 |     32.230 |     1.5
   21 |   0.9752 |     30.852 |   1.0317 |     32.690 |     1.6
   22 |   0.9546 |     30.093 |   1.0280 |     32.475 |     1.7
   23 |   0.9407 |     29.974 |   1.0245 |     31.832 |     1.8
   24 |   0.9259 |     29.470 |   1.0242 |     31.710 |     1.9
   25 |   0.9091 |     29.064 |   1.0135 |     31.189 |     1.9
   26 |   0.9002 |     28.652 |   1.0082 |     31.311 |     2.0
   27 |   0.8801 |     28.506 |   0.9982 |     31.250 |     2.1
   28 |   0.8689 |     27.893 |   1.0051 |     31.036 |     2.2
   29 |   0.8614 |     27.774 |   0.9983 |     31.219 |     2.2
   30 |   0.8424 |     26.842 |   0.9830 |     30.423 |     2.3
   31 |   0.8357 |     26.842 |   0.9908 |     30.882 |     2.4
   32 |   0.8262 |     26.680 |   0.9849 |     30.576 |     2.5
   33 |   0.8101 |     26.138 |   0.9850 |     30.515 |     2.6
   34 |   0.7928 |     25.791 |   0.9866 |     29.963 |     2.6
   35 |   0.7841 |     25.412 |   0.9803 |     30.086 |     2.7
   36 |   0.7728 |     25.098 |   1.0003 |     30.760 |     2.8
   37 |   0.7663 |     24.832 |   0.9822 |     29.596 |     2.9
   38 |   0.7510 |     24.274 |   0.9855 |     29.841 |     2.9
   39 |   0.7465 |     24.296 |   0.9798 |     29.688 |     3.0
   40 |   0.7416 |     23.943 |   0.9758 |     29.412 |     3.1
   41 |   0.7212 |     23.689 |   0.9786 |     29.350 |     3.2
   42 |   0.7043 |     22.627 |   0.9690 |     29.320 |     3.2
   43 |   0.7041 |     22.849 |   0.9813 |     29.044 |     3.3
   44 |   0.6883 |     22.676 |   0.9788 |     28.585 |     3.4
   45 |   0.6889 |     22.784 |   0.9828 |     28.952 |     3.5
   46 |   0.6736 |     21.993 |   0.9854 |     29.075 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 143,810

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0533 |     53.148 |   1.4567 |     43.566 |     0.1
    2 |   1.4158 |     44.083 |   1.3028 |     41.575 |     0.2
    3 |   1.2957 |     41.856 |   1.2351 |     38.971 |     0.3
    4 |   1.2289 |     39.656 |   1.1618 |     37.286 |     0.4
    5 |   1.1698 |     37.890 |   1.1162 |     35.600 |     0.5
    6 |   1.1259 |     36.915 |   1.0886 |     34.528 |     0.5
    7 |   1.0896 |     35.940 |   1.0546 |     33.548 |     0.6
    8 |   1.0491 |     34.693 |   1.0145 |     33.517 |     0.7
    9 |   1.0109 |     33.518 |   1.0044 |     32.812 |     0.8
   10 |   0.9863 |     33.014 |   0.9801 |     31.893 |     0.9
   11 |   0.9550 |     31.773 |   0.9794 |     32.261 |     1.0
   12 |   0.9299 |     31.085 |   0.9664 |     32.598 |     1.1
   13 |   0.8990 |     30.337 |   0.9460 |     30.729 |     1.2
   14 |   0.8786 |     29.183 |   0.9361 |     31.740 |     1.3
   15 |   0.8608 |     28.923 |   0.9334 |     30.913 |     1.4
   16 |   0.8359 |     28.018 |   0.8974 |     29.718 |     1.5
   17 |   0.8226 |     27.476 |   0.9162 |     30.270 |     1.5
   18 |   0.7973 |     26.945 |   0.9032 |     28.339 |     1.6
   19 |   0.7835 |     26.219 |   0.8832 |     28.309 |     1.7
   20 |   0.7595 |     25.862 |   0.9143 |     29.320 |     1.8
   21 |   0.7410 |     25.190 |   0.8843 |     28.585 |     1.9
   22 |   0.7302 |     24.865 |   0.8935 |     28.830 |     2.0
   23 |   0.7185 |     24.355 |   0.8832 |     28.309 |     2.1
   24 |   0.7059 |     23.981 |   0.8880 |     28.278 |     2.2
   25 |   0.6839 |     23.494 |   0.8880 |     29.044 |     2.3
   26 |   0.6734 |     23.212 |   0.8648 |     27.145 |     2.4
   27 |   0.6674 |     22.497 |   0.8805 |     28.339 |     2.4
   28 |   0.6497 |     21.803 |   0.8865 |     28.033 |     2.5
   29 |   0.6472 |     22.405 |   0.8881 |     27.911 |     2.6
   30 |   0.6252 |     21.278 |   0.8767 |     26.961 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 744,738

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4997 |     45.595 |   1.2085 |     39.706 |     0.1
    2 |   1.1455 |     38.464 |   1.0939 |     34.773 |     0.2
    3 |   1.0473 |     35.452 |   1.0179 |     33.915 |     0.2
    4 |   0.9520 |     32.022 |   0.9997 |     32.659 |     0.3
    5 |   0.8954 |     30.397 |   0.9630 |     31.189 |     0.4
    6 |   0.8431 |     28.587 |   0.9279 |     31.189 |     0.5
    7 |   0.7963 |     27.162 |   0.8767 |     29.381 |     0.6
    8 |   0.7626 |     25.780 |   0.8937 |     28.891 |     0.6
    9 |   0.7144 |     24.301 |   0.8552 |     28.156 |     0.7
   10 |   0.6660 |     22.708 |   0.8238 |     27.757 |     0.8
   11 |   0.6562 |     22.508 |   0.8433 |     27.880 |     0.9
   12 |   0.6173 |     21.294 |   0.8273 |     26.808 |     1.0
   13 |   0.5929 |     20.611 |   0.8343 |     26.562 |     1.1
   14 |   0.5733 |     19.733 |   0.8137 |     26.777 |     1.1
   15 |   0.5535 |     19.208 |   0.7855 |     24.510 |     1.2
   16 |   0.5129 |     18.000 |   0.8012 |     25.429 |     1.3
   17 |   0.5106 |     17.696 |   0.7868 |     24.326 |     1.4
   18 |   0.4932 |     17.198 |   0.8082 |     24.724 |     1.5
   19 |   0.5057 |     17.674 |   0.8089 |     24.173 |     1.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 911,010

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4102 |     57.916 |   1.6394 |     45.251 |     0.2
    2 |   1.6399 |     45.118 |   1.4073 |     42.065 |     0.4
    3 |   1.4474 |     43.113 |   1.3125 |     39.553 |     0.5
    4 |   1.3481 |     41.325 |   1.2486 |     38.542 |     0.7
    5 |   1.2822 |     39.684 |   1.2178 |     37.377 |     0.9
    6 |   1.2273 |     38.226 |   1.1985 |     37.469 |     1.1
    7 |   1.1737 |     36.915 |   1.1679 |     36.275 |     1.2
    8 |   1.1354 |     35.549 |   1.1425 |     35.417 |     1.4
    9 |   1.0996 |     34.531 |   1.1398 |     35.846 |     1.6
   10 |   1.0646 |     33.713 |   1.1173 |     34.406 |     1.8
   11 |   1.0287 |     32.515 |   1.1234 |     35.417 |     2.0
   12 |   1.0029 |     31.811 |   1.1046 |     33.578 |     2.1
   13 |   0.9808 |     31.394 |   1.1132 |     35.386 |     2.3
   14 |   0.9496 |     30.191 |   1.0895 |     33.211 |     2.5
   15 |   0.9318 |     29.914 |   1.0915 |     33.364 |     2.7
   16 |   0.8974 |     28.603 |   1.1014 |     34.191 |     2.9
   17 |   0.8750 |     27.709 |   1.0961 |     32.598 |     3.0
   18 |   0.8659 |     27.812 |   1.1071 |     33.762 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,043,618

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5415 |     46.402 |   1.2425 |     41.115 |     0.1
    2 |   1.1630 |     38.513 |   1.1133 |     36.336 |     0.2
    3 |   1.0406 |     34.471 |   1.0230 |     34.651 |     0.4
    4 |   0.9525 |     32.152 |   0.9578 |     31.801 |     0.5
    5 |   0.8875 |     30.207 |   0.9285 |     30.362 |     0.6
    6 |   0.8367 |     28.311 |   0.8801 |     28.646 |     0.7
    7 |   0.7843 |     26.642 |   0.8619 |     28.952 |     0.8
    8 |   0.7490 |     25.574 |   0.8664 |     29.197 |     0.9
    9 |   0.7306 |     25.076 |   0.8142 |     27.237 |     1.1
   10 |   0.6865 |     23.689 |   0.8309 |     26.900 |     1.2
   11 |   0.6571 |     22.865 |   0.8292 |     26.317 |     1.3
   12 |   0.6381 |     21.998 |   0.8059 |     25.551 |     1.4
   13 |   0.6016 |     20.562 |   0.7930 |     25.705 |     1.5
   14 |   0.5741 |     19.647 |   0.8221 |     25.705 |     1.7
   15 |   0.5506 |     18.969 |   0.8101 |     25.980 |     1.8
   16 |   0.5399 |     18.850 |   0.8178 |     25.000 |     1.9
   17 |   0.5206 |     17.794 |   0.7870 |     25.123 |     2.0
   18 |   0.5044 |     17.268 |   0.8396 |     26.624 |     2.1
   19 |   0.4943 |     17.176 |   0.7789 |     23.958 |     2.3
   20 |   0.4745 |     16.585 |   0.7832 |     23.621 |     2.4
   21 |   0.4595 |     16.222 |   0.7858 |     23.376 |     2.5
   22 |   0.4484 |     15.697 |   0.8255 |     23.989 |     2.6
   23 |   0.4407 |     15.523 |   0.7982 |     23.836 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 810,530

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4000 |     59.412 |   1.6370 |     45.741 |     0.1
    2 |   1.5641 |     44.891 |   1.3725 |     41.054 |     0.2
    3 |   1.3830 |     41.965 |   1.2731 |     39.246 |     0.3
    4 |   1.2837 |     39.624 |   1.2018 |     36.060 |     0.3
    5 |   1.2106 |     37.489 |   1.1642 |     36.305 |     0.4
    6 |   1.1554 |     35.782 |   1.1192 |     35.141 |     0.5
    7 |   1.1055 |     34.655 |   1.0852 |     33.977 |     0.6
    8 |   1.0568 |     32.965 |   1.0569 |     33.456 |     0.7
    9 |   1.0205 |     32.223 |   1.0337 |     33.272 |     0.8
   10 |   0.9791 |     30.884 |   1.0144 |     32.506 |     0.9
   11 |   0.9433 |     29.774 |   0.9961 |     31.526 |     1.0
   12 |   0.9173 |     29.112 |   0.9752 |     31.036 |     1.1
   13 |   0.8858 |     28.273 |   0.9589 |     30.147 |     1.1
   14 |   0.8571 |     27.471 |   0.9513 |     30.300 |     1.2
   15 |   0.8289 |     26.880 |   0.9383 |     30.270 |     1.3
   16 |   0.8020 |     25.694 |   0.9287 |     29.442 |     1.4
   17 |   0.7765 |     24.881 |   0.9185 |     28.707 |     1.5
   18 |   0.7566 |     24.193 |   0.9176 |     28.646 |     1.6
   19 |   0.7329 |     23.618 |   0.8950 |     28.033 |     1.7
   20 |   0.7085 |     22.968 |   0.9071 |     28.064 |     1.8
   21 |   0.6957 |     22.573 |   0.8968 |     27.451 |     1.8
   22 |   0.6748 |     21.879 |   0.8855 |     26.777 |     1.9
   23 |   0.6593 |     21.359 |   0.8939 |     27.696 |     2.0
   24 |   0.6481 |     21.012 |   0.8858 |     26.716 |     2.1
   25 |   0.6278 |     20.530 |   0.8838 |     26.103 |     2.2
   26 |   0.6074 |     19.728 |   0.8739 |     26.317 |     2.3
   27 |   0.6003 |     19.744 |   0.8620 |     25.827 |     2.4
   28 |   0.5820 |     18.834 |   0.8771 |     25.705 |     2.5
   29 |   0.5670 |     18.590 |   0.8726 |     25.061 |     2.5
   30 |   0.5544 |     18.325 |   0.8720 |     25.643 |     2.6
   31 |   0.5495 |     18.146 |   0.8785 |     25.643 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 205,858

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9313 |     71.435 |   2.3147 |     51.011 |     0.1
    2 |   2.0620 |     48.163 |   1.8798 |     43.719 |     0.2
    3 |   1.8015 |     43.634 |   1.7166 |     42.892 |     0.2
    4 |   1.6615 |     42.425 |   1.6010 |     41.636 |     0.3
    5 |   1.5545 |     41.168 |   1.5094 |     39.920 |     0.4
    6 |   1.4679 |     40.187 |   1.4353 |     39.308 |     0.5
    7 |   1.3985 |     38.795 |   1.3743 |     38.358 |     0.6
    8 |   1.3376 |     37.749 |   1.3226 |     36.979 |     0.6
    9 |   1.2865 |     36.568 |   1.2860 |     36.734 |     0.7
   10 |   1.2392 |     35.349 |   1.2526 |     35.417 |     0.8
   11 |   1.1970 |     34.336 |   1.2188 |     35.417 |     0.9
   12 |   1.1614 |     33.149 |   1.1940 |     34.865 |     1.0
   13 |   1.1239 |     32.450 |   1.1795 |     34.436 |     1.1
   14 |   1.0889 |     31.421 |   1.1419 |     34.038 |     1.1
   15 |   1.0603 |     30.933 |   1.1204 |     33.732 |     1.2
   16 |   1.0286 |     29.627 |   1.0939 |     33.119 |     1.3
   17 |   0.9978 |     29.324 |   1.0826 |     32.475 |     1.4
   18 |   0.9736 |     28.690 |   1.0850 |     33.058 |     1.5
   19 |   0.9474 |     28.246 |   1.0430 |     31.893 |     1.5
   20 |   0.9250 |     27.362 |   1.0371 |     31.495 |     1.6
   21 |   0.8973 |     26.734 |   1.0190 |     31.373 |     1.7
   22 |   0.8764 |     26.317 |   1.0073 |     30.392 |     1.8
   23 |   0.8535 |     25.520 |   1.0105 |     30.699 |     1.9
   24 |   0.8334 |     25.060 |   1.0078 |     31.434 |     2.0
   25 |   0.8175 |     24.680 |   0.9780 |     29.933 |     2.0
   26 |   0.8025 |     24.036 |   0.9761 |     29.871 |     2.1
   27 |   0.7931 |     23.992 |   0.9708 |     29.994 |     2.2
   28 |   0.7720 |     23.125 |   0.9523 |     28.860 |     2.3
   29 |   0.7475 |     22.589 |   0.9460 |     29.442 |     2.4
   30 |   0.7328 |     22.080 |   0.9582 |     28.952 |     2.4
   31 |   0.7174 |     21.370 |   0.9538 |     28.983 |     2.5
   32 |   0.7049 |     21.343 |   0.9294 |     27.757 |     2.6
   33 |   0.6931 |     20.839 |   0.9475 |     28.891 |     2.7
   34 |   0.6778 |     20.524 |   0.9338 |     28.217 |     2.8
   35 |   0.6627 |     19.918 |   0.9324 |     28.186 |     2.8
   36 |   0.6582 |     20.037 |   0.9229 |     27.237 |     2.9
   37 |   0.6440 |     19.500 |   0.9336 |     28.339 |     3.0
   38 |   0.6330 |     19.354 |   0.9371 |     27.911 |     3.1
   39 |   0.6222 |     19.143 |   0.9245 |     27.420 |     3.2
   40 |   0.6037 |     18.298 |   0.9153 |     27.175 |     3.3
   41 |   0.5952 |     18.010 |   0.9379 |     27.543 |     3.3
   42 |   0.5863 |     18.016 |   0.9197 |     26.838 |     3.4
   43 |   0.5784 |     17.712 |   0.9278 |     27.053 |     3.5
   44 |   0.5638 |     17.214 |   0.9252 |     26.930 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 911,010

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3503 |     57.179 |   1.6290 |     44.056 |     0.1
    2 |   1.5588 |     44.305 |   1.3714 |     42.249 |     0.3
    3 |   1.3780 |     42.122 |   1.2752 |     39.216 |     0.4
    4 |   1.2856 |     40.160 |   1.2248 |     37.898 |     0.6
    5 |   1.2163 |     38.324 |   1.1696 |     36.244 |     0.7
    6 |   1.1630 |     36.129 |   1.1311 |     35.692 |     0.8
    7 |   1.1157 |     35.132 |   1.1074 |     35.141 |     1.0
    8 |   1.0670 |     33.832 |   1.0836 |     33.946 |     1.1
    9 |   1.0285 |     32.656 |   1.0523 |     34.038 |     1.3
   10 |   0.9940 |     31.264 |   1.0408 |     33.425 |     1.4
   11 |   0.9622 |     30.960 |   1.0282 |     32.721 |     1.5
   12 |   0.9254 |     29.876 |   1.0115 |     31.955 |     1.7
   13 |   0.8941 |     28.370 |   0.9943 |     31.189 |     1.8
   14 |   0.8640 |     27.395 |   0.9922 |     31.342 |     2.0
   15 |   0.8408 |     27.037 |   0.9972 |     31.618 |     2.1
   16 |   0.8243 |     26.658 |   0.9717 |     30.637 |     2.2
   17 |   0.7967 |     25.379 |   0.9703 |     30.576 |     2.4
   18 |   0.7711 |     24.529 |   0.9780 |     30.637 |     2.5
   19 |   0.7492 |     23.960 |   0.9751 |     30.515 |     2.7
   20 |   0.7310 |     23.136 |   0.9668 |     29.718 |     2.8
   21 |   0.7134 |     22.995 |   0.9693 |     29.994 |     3.0
   22 |   0.6941 |     21.950 |   0.9585 |     29.626 |     3.1
   23 |   0.6748 |     21.733 |   0.9795 |     30.116 |     3.2
   24 |   0.6528 |     21.310 |   0.9554 |     29.075 |     3.4
   25 |   0.6345 |     20.974 |   0.9708 |     29.289 |     3.5
   26 |   0.6266 |     20.443 |   0.9796 |     29.167 |     3.7
   27 |   0.6134 |     19.847 |   0.9818 |     29.871 |     3.8
   28 |   0.5933 |     19.143 |   0.9937 |     29.534 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 437,090

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5047 |     59.980 |   1.7888 |     43.719 |     0.1
    2 |   1.6237 |     44.164 |   1.4973 |     42.433 |     0.2
    3 |   1.4401 |     41.412 |   1.3952 |     40.686 |     0.3
    4 |   1.3304 |     38.806 |   1.2919 |     37.990 |     0.4
    5 |   1.2451 |     36.926 |   1.2268 |     36.121 |     0.5
    6 |   1.1726 |     35.176 |   1.1616 |     34.589 |     0.6
    7 |   1.1064 |     33.393 |   1.1208 |     33.609 |     0.7
    8 |   1.0503 |     31.843 |   1.0961 |     33.487 |     0.8
    9 |   1.0101 |     30.489 |   1.0464 |     31.863 |     0.9
   10 |   0.9576 |     28.923 |   1.0118 |     31.005 |     1.0
   11 |   0.9202 |     27.492 |   1.0020 |     30.453 |     1.0
   12 |   0.8793 |     26.430 |   0.9774 |     30.515 |     1.1
   13 |   0.8537 |     26.094 |   0.9783 |     30.576 |     1.2
   14 |   0.8126 |     24.984 |   0.9435 |     29.381 |     1.3
   15 |   0.7800 |     23.938 |   0.9179 |     28.523 |     1.4
   16 |   0.7535 |     22.730 |   0.9025 |     28.033 |     1.5
   17 |   0.7303 |     22.421 |   0.9037 |     28.125 |     1.6
   18 |   0.7040 |     21.202 |   0.8904 |     27.175 |     1.7
   19 |   0.6867 |     20.877 |   0.8735 |     27.083 |     1.8
   20 |   0.6484 |     19.668 |   0.8860 |     27.482 |     1.9
   21 |   0.6312 |     19.175 |   0.8504 |     25.888 |     2.0
   22 |   0.6104 |     18.503 |   0.8489 |     26.593 |     2.1
   23 |   0.5866 |     17.886 |   0.8780 |     26.317 |     2.2
   24 |   0.5771 |     17.712 |   0.8418 |     25.184 |     2.3
   25 |   0.5539 |     16.948 |   0.8493 |     25.460 |     2.4
   26 |   0.5356 |     16.515 |   0.8328 |     24.908 |     2.5
   27 |   0.5211 |     15.930 |   0.8738 |     26.011 |     2.6
   28 |   0.5051 |     15.572 |   0.8434 |     25.245 |     2.7
   29 |   0.4959 |     15.442 |   0.8268 |     24.816 |     2.8
   30 |   0.4715 |     14.678 |   0.8326 |     24.449 |     2.9
   31 |   0.4592 |     14.158 |   0.8538 |     24.632 |     2.9
   32 |   0.4495 |     14.256 |   0.8335 |     23.989 |     3.0
   33 |   0.4325 |     13.383 |   0.8422 |     24.479 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,474

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5916 |     48.396 |   1.2734 |     41.299 |     0.2
    2 |   1.2531 |     41.564 |   1.1469 |     37.347 |     0.3
    3 |   1.1673 |     39.163 |   1.1415 |     37.531 |     0.5
    4 |   1.1146 |     37.755 |   1.0613 |     35.631 |     0.6
    5 |   1.0637 |     36.037 |   1.0241 |     34.222 |     0.8
    6 |   1.0222 |     35.002 |   1.0229 |     34.743 |     1.0
    7 |   0.9820 |     33.507 |   0.9828 |     33.487 |     1.1
    8 |   0.9508 |     32.678 |   0.9769 |     32.629 |     1.3
    9 |   0.9314 |     31.562 |   0.9794 |     34.559 |     1.4
   10 |   0.9228 |     31.562 |   0.9105 |     30.576 |     1.6
   11 |   0.8676 |     29.562 |   0.9058 |     30.545 |     1.8
   12 |   0.8451 |     28.977 |   0.8846 |     30.668 |     1.9
   13 |   0.8384 |     28.408 |   0.8800 |     29.412 |     2.1
   14 |   0.8162 |     28.105 |   0.8263 |     27.972 |     2.2
   15 |   0.7823 |     26.235 |   0.8288 |     27.451 |     2.4
   16 |   0.7537 |     25.829 |   0.8524 |     28.615 |     2.6
   17 |   0.7277 |     25.070 |   0.8249 |     27.665 |     2.7
   18 |   0.7061 |     24.485 |   0.8353 |     28.002 |     2.9
   19 |   0.6888 |     23.586 |   0.7913 |     26.746 |     3.1
   20 |   0.6742 |     23.483 |   0.8006 |     26.409 |     3.2
   21 |   0.6458 |     22.323 |   0.8226 |     27.482 |     3.4
   22 |   0.6313 |     21.852 |   0.7821 |     26.103 |     3.5
   23 |   0.6113 |     21.158 |   0.7914 |     25.735 |     3.7
   24 |   0.6012 |     20.936 |   0.7863 |     25.398 |     3.9
   25 |   0.5792 |     20.069 |   0.7858 |     24.418 |     4.0
   26 |   0.5760 |     20.237 |   0.8161 |     25.674 |     4.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 130,978

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9511 |     50.255 |   1.4365 |     43.873 |     0.1
    2 |   1.3229 |     41.585 |   1.2473 |     39.124 |     0.2
    3 |   1.1880 |     38.324 |   1.1502 |     35.999 |     0.3
    4 |   1.1010 |     35.701 |   1.0744 |     34.406 |     0.4
    5 |   1.0232 |     33.523 |   1.0223 |     33.395 |     0.5
    6 |   0.9679 |     31.827 |   0.9853 |     33.150 |     0.6
    7 |   0.9152 |     30.494 |   0.9471 |     31.005 |     0.8
    8 |   0.8724 |     29.020 |   0.9113 |     30.178 |     0.9
    9 |   0.8168 |     26.772 |   0.9278 |     30.300 |     1.0
   10 |   0.7912 |     26.398 |   0.8973 |     29.596 |     1.1
   11 |   0.7493 |     24.848 |   0.8728 |     28.615 |     1.2
   12 |   0.7228 |     23.878 |   0.8959 |     29.442 |     1.3
   13 |   0.6907 |     23.163 |   0.8717 |     27.512 |     1.4
   14 |   0.6650 |     22.302 |   0.8579 |     27.512 |     1.5
   15 |   0.6391 |     21.278 |   0.8372 |     27.206 |     1.6
   16 |   0.6197 |     20.942 |   0.8444 |     26.562 |     1.7
   17 |   0.5903 |     19.912 |   0.8688 |     27.420 |     1.8
   18 |   0.5738 |     19.446 |   0.8317 |     26.225 |     1.9
   19 |   0.5547 |     18.948 |   0.8209 |     25.368 |     2.1
   20 |   0.5461 |     18.661 |   0.8162 |     26.011 |     2.2
   21 |   0.5245 |     18.016 |   0.8013 |     24.694 |     2.3
   22 |   0.4986 |     16.743 |   0.8406 |     24.540 |     2.4
   23 |   0.4948 |     16.596 |   0.8356 |     25.123 |     2.5
   24 |   0.5139 |     17.750 |   0.8222 |     25.521 |     2.6
   25 |   0.4706 |     16.141 |   0.8392 |     24.786 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 226,882

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0201 |     52.297 |   1.4706 |     45.159 |     0.1
    2 |   1.4312 |     44.966 |   1.3184 |     43.658 |     0.2
    3 |   1.3222 |     42.870 |   1.2373 |     39.859 |     0.3
    4 |   1.2499 |     40.767 |   1.1678 |     38.634 |     0.4
    5 |   1.1858 |     39.321 |   1.1264 |     36.795 |     0.5
    6 |   1.1504 |     37.982 |   1.1077 |     35.509 |     0.6
    7 |   1.1221 |     37.191 |   1.0646 |     35.325 |     0.7
    8 |   1.0827 |     36.265 |   1.0476 |     34.651 |     0.8
    9 |   1.0511 |     34.650 |   1.0285 |     34.283 |     0.9
   10 |   1.0352 |     34.639 |   1.0113 |     33.578 |     1.0
   11 |   1.0046 |     33.415 |   0.9995 |     32.721 |     1.2
   12 |   0.9908 |     33.257 |   0.9851 |     32.567 |     1.3
   13 |   0.9610 |     32.103 |   0.9512 |     32.108 |     1.4
   14 |   0.9444 |     31.757 |   0.9545 |     32.138 |     1.5
   15 |   0.9156 |     30.608 |   0.9495 |     31.526 |     1.6
   16 |   0.9025 |     30.174 |   0.9470 |     31.373 |     1.7
   17 |   0.8892 |     29.714 |   0.9336 |     31.036 |     1.8
   18 |   0.8592 |     29.085 |   0.9200 |     30.699 |     1.9
   19 |   0.8451 |     28.614 |   0.9176 |     30.270 |     2.0
   20 |   0.8249 |     28.240 |   0.9284 |     29.504 |     2.1
   21 |   0.8058 |     27.102 |   0.9353 |     30.116 |     2.2
   22 |   0.7979 |     27.438 |   0.8787 |     29.259 |     2.3
   23 |   0.7772 |     26.620 |   0.8828 |     28.554 |     2.4
   24 |   0.7564 |     25.910 |   0.8959 |     29.596 |     2.5
   25 |   0.7492 |     25.461 |   0.8872 |     28.493 |     2.6
   26 |   0.7305 |     24.772 |   0.9148 |     29.013 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6633 |     48.440 |   1.3043 |     42.739 |     0.1
    2 |   1.2295 |     40.513 |   1.1601 |     38.388 |     0.2
    3 |   1.1189 |     37.841 |   1.0727 |     35.784 |     0.3
    4 |   1.0302 |     34.829 |   0.9743 |     32.169 |     0.4
    5 |   0.9635 |     32.624 |   0.9598 |     31.893 |     0.6
    6 |   0.9089 |     30.684 |   0.9045 |     31.158 |     0.7
    7 |   0.8538 |     29.140 |   0.9069 |     31.158 |     0.8
    8 |   0.8082 |     27.633 |   0.8732 |     29.810 |     0.9
    9 |   0.7701 |     26.100 |   0.8384 |     28.370 |     1.0
   10 |   0.7425 |     25.222 |   0.8549 |     28.401 |     1.1
   11 |   0.7157 |     24.697 |   0.8416 |     27.451 |     1.2
   12 |   0.6820 |     23.250 |   0.7995 |     25.613 |     1.3
   13 |   0.6352 |     21.950 |   0.7929 |     25.214 |     1.5
   14 |   0.6140 |     21.050 |   0.7657 |     24.602 |     1.6
   15 |   0.6006 |     20.774 |   0.7719 |     24.939 |     1.7
   16 |   0.5802 |     20.389 |   0.7709 |     25.031 |     1.8
   17 |   0.5570 |     19.576 |   0.7437 |     24.112 |     1.9
   18 |   0.5240 |     18.227 |   0.7581 |     24.050 |     2.0
   19 |   0.5287 |     18.493 |   0.7562 |     23.683 |     2.1
   20 |   0.4980 |     17.257 |   0.7796 |     24.326 |     2.2
   21 |   0.5012 |     17.626 |   0.7679 |     23.744 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 362,530

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6827 |     65.220 |   1.9976 |     48.376 |     0.1
    2 |   1.7517 |     46.586 |   1.5920 |     43.474 |     0.3
    3 |   1.5124 |     43.081 |   1.4416 |     41.759 |     0.4
    4 |   1.3883 |     40.903 |   1.3528 |     40.288 |     0.6
    5 |   1.2993 |     39.342 |   1.2814 |     38.603 |     0.7
    6 |   1.2257 |     36.980 |   1.2269 |     36.550 |     0.9
    7 |   1.1643 |     34.943 |   1.1835 |     35.478 |     1.0
    8 |   1.1068 |     33.068 |   1.1422 |     34.467 |     1.2
    9 |   1.0615 |     31.827 |   1.1068 |     34.283 |     1.3
   10 |   1.0152 |     30.619 |   1.0741 |     32.537 |     1.5
   11 |   0.9735 |     29.324 |   1.0537 |     31.679 |     1.6
   12 |   0.9411 |     28.273 |   1.0307 |     30.913 |     1.8
   13 |   0.9060 |     27.698 |   1.0213 |     30.944 |     1.9
   14 |   0.8747 |     26.837 |   0.9969 |     30.760 |     2.0
   15 |   0.8446 |     26.051 |   0.9578 |     29.504 |     2.2
   16 |   0.8138 |     24.854 |   0.9530 |     29.412 |     2.3
   17 |   0.7882 |     24.334 |   0.9503 |     29.442 |     2.5
   18 |   0.7690 |     23.808 |   0.9339 |     28.922 |     2.6
   19 |   0.7458 |     23.152 |   0.9330 |     28.278 |     2.8
   20 |   0.7130 |     22.090 |   0.9185 |     28.339 |     2.9
   21 |   0.6965 |     21.646 |   0.9150 |     28.002 |     3.1
   22 |   0.6758 |     20.931 |   0.8891 |     27.390 |     3.2
   23 |   0.6485 |     20.124 |   0.9069 |     27.359 |     3.4
   24 |   0.6345 |     19.815 |   0.8843 |     26.654 |     3.5
   25 |   0.6205 |     19.105 |   0.9082 |     27.911 |     3.7
   26 |   0.6044 |     18.699 |   0.9136 |     26.746 |     3.8
   27 |   0.5862 |     17.875 |   0.8783 |     26.409 |     4.0
   28 |   0.5691 |     17.739 |   0.8847 |     26.746 |     4.1
   29 |   0.5521 |     17.414 |   0.8855 |     26.624 |     4.2
   30 |   0.5391 |     16.878 |   0.8974 |     26.624 |     4.4
   31 |   0.5273 |     16.450 |   0.8824 |     25.888 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,043,618

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6161 |     47.936 |   1.2591 |     39.583 |     0.1
    2 |   1.2204 |     40.139 |   1.1397 |     36.336 |     0.2
    3 |   1.1127 |     37.061 |   1.0711 |     34.252 |     0.4
    4 |   1.0393 |     34.845 |   1.0139 |     33.762 |     0.5
    5 |   0.9856 |     33.079 |   1.0035 |     33.241 |     0.6
    6 |   0.9485 |     31.740 |   0.9858 |     32.506 |     0.8
    7 |   0.9076 |     30.668 |   0.9555 |     31.403 |     0.9
    8 |   0.8628 |     28.917 |   0.9324 |     30.392 |     1.0
    9 |   0.8312 |     28.267 |   0.9247 |     30.637 |     1.1
   10 |   0.7946 |     27.259 |   0.9346 |     31.526 |     1.3
   11 |   0.7654 |     26.262 |   0.9289 |     29.994 |     1.4
   12 |   0.7407 |     25.320 |   0.8897 |     30.270 |     1.5
   13 |   0.7191 |     24.810 |   0.8921 |     29.596 |     1.6
   14 |   0.6966 |     23.992 |   0.9079 |     29.075 |     1.8
   15 |   0.6836 |     23.575 |   0.8852 |     29.105 |     1.9
   16 |   0.6685 |     23.060 |   0.8658 |     28.554 |     2.0
   17 |   0.6324 |     22.009 |   0.8690 |     28.431 |     2.1
   18 |   0.6186 |     21.581 |   0.8629 |     27.543 |     2.3
   19 |   0.5968 |     20.915 |   0.8725 |     27.574 |     2.4
   20 |   0.5985 |     20.915 |   0.8951 |     29.228 |     2.5
   21 |   0.5814 |     20.134 |   0.8735 |     27.696 |     2.6
   22 |   0.5693 |     19.782 |   0.8506 |     26.532 |     2.8
   23 |   0.5409 |     19.137 |   0.8370 |     26.409 |     2.9
   24 |   0.5323 |     18.644 |   0.8738 |     27.420 |     3.0
   25 |   0.5158 |     18.086 |   0.8625 |     27.022 |     3.2
   26 |   0.5043 |     17.750 |   0.8667 |     26.348 |     3.3
   27 |   0.5011 |     17.582 |   0.8587 |     26.042 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 160,226

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1138 |     54.611 |   1.4743 |     43.995 |     0.1
    2 |   1.4377 |     44.360 |   1.3183 |     42.647 |     0.2
    3 |   1.3247 |     42.805 |   1.2352 |     39.553 |     0.3
    4 |   1.2543 |     40.805 |   1.1890 |     38.113 |     0.4
    5 |   1.2139 |     39.613 |   1.1608 |     37.714 |     0.5
    6 |   1.1651 |     38.069 |   1.1288 |     36.183 |     0.6
    7 |   1.1247 |     36.487 |   1.1003 |     35.509 |     0.7
    8 |   1.0830 |     35.539 |   1.0775 |     34.988 |     0.8
    9 |   1.0505 |     34.726 |   1.0521 |     34.252 |     0.9
   10 |   1.0237 |     33.713 |   1.0375 |     33.732 |     1.0
   11 |   0.9939 |     32.997 |   1.0223 |     32.506 |     1.1
   12 |   0.9623 |     31.860 |   1.0170 |     33.762 |     1.2
   13 |   0.9405 |     31.258 |   0.9827 |     32.598 |     1.3
   14 |   0.9166 |     30.462 |   0.9798 |     31.648 |     1.4
   15 |   0.8964 |     29.958 |   0.9680 |     31.740 |     1.5
   16 |   0.8843 |     29.746 |   1.0048 |     32.384 |     1.6
   17 |   0.8584 |     29.053 |   0.9863 |     31.495 |     1.7
   18 |   0.8277 |     28.007 |   0.9707 |     30.974 |     1.8
   19 |   0.8216 |     27.520 |   0.9780 |     31.311 |     1.9
   20 |   0.8011 |     26.902 |   0.9377 |     30.576 |     2.0
   21 |   0.7850 |     26.430 |   0.9551 |     30.699 |     2.1
   22 |   0.7728 |     26.154 |   0.9413 |     30.392 |     2.2
   23 |   0.7551 |     25.677 |   0.9597 |     30.974 |     2.3
   24 |   0.7395 |     25.119 |   0.9755 |     30.913 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 231,170

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9818 |     51.718 |   1.4523 |     43.934 |     0.1
    2 |   1.3934 |     44.327 |   1.3020 |     41.023 |     0.3
    3 |   1.2715 |     40.849 |   1.1975 |     39.032 |     0.4
    4 |   1.1878 |     38.524 |   1.1358 |     37.102 |     0.5
    5 |   1.1285 |     37.094 |   1.0932 |     36.275 |     0.6
    6 |   1.0743 |     35.674 |   1.0381 |     34.007 |     0.8
    7 |   1.0362 |     34.081 |   1.0029 |     33.609 |     0.9
    8 |   0.9796 |     32.353 |   0.9867 |     32.659 |     1.0
    9 |   0.9519 |     31.372 |   0.9643 |     32.843 |     1.2
   10 |   0.9157 |     30.662 |   0.9169 |     31.250 |     1.3
   11 |   0.8885 |     30.044 |   0.9144 |     30.576 |     1.4
   12 |   0.8487 |     28.099 |   0.9086 |     30.423 |     1.5
   13 |   0.8219 |     27.292 |   0.8835 |     29.749 |     1.7
   14 |   0.8013 |     27.151 |   0.8685 |     29.657 |     1.8
   15 |   0.7721 |     25.683 |   0.8332 |     27.972 |     1.9
   16 |   0.7560 |     25.536 |   0.8339 |     27.328 |     2.1
   17 |   0.7268 |     24.567 |   0.8429 |     28.094 |     2.2
   18 |   0.7082 |     23.645 |   0.8449 |     26.930 |     2.3
   19 |   0.6896 |     23.385 |   0.8242 |     27.022 |     2.5
   20 |   0.6602 |     22.546 |   0.8351 |     27.022 |     2.6
   21 |   0.6439 |     21.912 |   0.8177 |     27.053 |     2.7
   22 |   0.6364 |     21.874 |   0.8108 |     25.582 |     2.8
   23 |   0.6056 |     20.644 |   0.8215 |     25.429 |     3.0
   24 |   0.6052 |     20.774 |   0.7975 |     25.000 |     3.1
   25 |   0.5965 |     20.422 |   0.8147 |     25.613 |     3.2
   26 |   0.5735 |     19.614 |   0.8204 |     24.908 |     3.4
   27 |   0.5632 |     19.408 |   0.8346 |     24.847 |     3.5
   28 |   0.5458 |     18.531 |   0.8669 |     25.919 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 139,522

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9929 |     66.938 |   2.5310 |     49.387 |     0.1
    2 |   2.2728 |     49.101 |   2.0641 |     48.254 |     0.3
    3 |   1.9290 |     46.706 |   1.8189 |     43.781 |     0.4
    4 |   1.7441 |     43.503 |   1.6810 |     41.299 |     0.5
    5 |   1.6256 |     41.970 |   1.5860 |     41.268 |     0.7
    6 |   1.5414 |     41.293 |   1.5128 |     40.594 |     0.8
    7 |   1.4697 |     40.464 |   1.4485 |     39.890 |     0.9
    8 |   1.4094 |     39.732 |   1.3976 |     39.890 |     1.1
    9 |   1.3539 |     38.730 |   1.3546 |     39.308 |     1.2
   10 |   1.3053 |     37.901 |   1.3154 |     37.929 |     1.3
   11 |   1.2602 |     36.747 |   1.2882 |     37.040 |     1.4
   12 |   1.2235 |     35.750 |   1.2684 |     36.673 |     1.6
   13 |   1.1885 |     34.813 |   1.2435 |     36.673 |     1.7
   14 |   1.1542 |     33.772 |   1.2160 |     35.294 |     1.8
   15 |   1.1252 |     33.100 |   1.2142 |     35.662 |     2.0
   16 |   1.1022 |     32.309 |   1.1834 |     34.559 |     2.1
   17 |   1.0732 |     31.995 |   1.1713 |     34.344 |     2.2
   18 |   1.0533 |     31.469 |   1.1611 |     34.804 |     2.4
   19 |   1.0282 |     30.657 |   1.1510 |     34.436 |     2.5
   20 |   1.0061 |     30.348 |   1.1339 |     33.885 |     2.6
   21 |   0.9868 |     29.681 |   1.1244 |     33.946 |     2.8
   22 |   0.9697 |     29.226 |   1.1086 |     32.966 |     2.9
   23 |   0.9449 |     28.538 |   1.1098 |     33.333 |     3.0
   24 |   0.9334 |     28.121 |   1.1076 |     33.915 |     3.2
   25 |   0.9149 |     28.132 |   1.0947 |     33.150 |     3.3
   26 |   0.9007 |     27.417 |   1.0886 |     32.659 |     3.4
   27 |   0.8868 |     27.005 |   1.0644 |     32.169 |     3.6
   28 |   0.8717 |     26.403 |   1.0741 |     32.812 |     3.7
   29 |   0.8530 |     26.317 |   1.0591 |     32.475 |     3.8
   30 |   0.8373 |     25.450 |   1.0567 |     32.138 |     4.0
   31 |   0.8189 |     25.385 |   1.0536 |     32.108 |     4.1
   32 |   0.8080 |     24.583 |   1.0574 |     32.353 |     4.2
   33 |   0.7984 |     24.328 |   1.0454 |     31.556 |     4.4
   34 |   0.7805 |     24.133 |   1.0409 |     31.955 |     4.5
   35 |   0.7687 |     23.499 |   1.0433 |     31.801 |     4.6
   36 |   0.7614 |     23.505 |   1.0408 |     31.342 |     4.7
   37 |   0.7496 |     23.044 |   1.0363 |     31.801 |     4.9
   38 |   0.7395 |     22.567 |   1.0343 |     31.373 |     5.0
   39 |   0.7241 |     22.128 |   1.0210 |     31.036 |     5.1
   40 |   0.7193 |     22.155 |   1.0217 |     30.607 |     5.3
   41 |   0.7085 |     21.852 |   1.0246 |     30.852 |     5.4
   42 |   0.6977 |     21.489 |   1.0300 |     30.362 |     5.5
   43 |   0.6903 |     21.272 |   1.0120 |     29.933 |     5.7
   44 |   0.6786 |     21.332 |   1.0118 |     29.994 |     5.8
   45 |   0.6691 |     20.866 |   1.0195 |     29.902 |     5.9
   46 |   0.6594 |     20.665 |   1.0111 |     29.718 |     6.1
   47 |   0.6547 |     20.427 |   1.0097 |     29.442 |     6.2
   48 |   0.6453 |     20.302 |   1.0152 |     30.453 |     6.3
   49 |   0.6327 |     19.679 |   1.0325 |     29.994 |     6.5
   50 |   0.6297 |     19.750 |   1.0180 |     29.688 |     6.6
   51 |   0.6200 |     19.192 |   1.0162 |     29.167 |     6.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 336,610

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8002 |     50.233 |   1.3232 |     43.382 |     0.1
    2 |   1.3083 |     41.905 |   1.2020 |     39.614 |     0.2
    3 |   1.2093 |     39.694 |   1.1324 |     37.194 |     0.4
    4 |   1.1439 |     37.581 |   1.0602 |     34.865 |     0.5
    5 |   1.0948 |     35.950 |   1.0375 |     34.620 |     0.6
    6 |   1.0548 |     35.013 |   1.0183 |     33.915 |     0.7
    7 |   1.0050 |     33.723 |   0.9868 |     33.180 |     0.8
    8 |   0.9758 |     32.716 |   0.9580 |     31.679 |     1.0
    9 |   0.9306 |     31.101 |   0.9289 |     30.637 |     1.1
   10 |   0.9063 |     30.370 |   0.9258 |     31.066 |     1.2
   11 |   0.8815 |     29.904 |   0.9139 |     30.239 |     1.3
   12 |   0.8472 |     28.516 |   0.9198 |     30.790 |     1.5
   13 |   0.8297 |     28.489 |   0.9053 |     30.423 |     1.6
   14 |   0.8062 |     27.173 |   0.8670 |     29.105 |     1.7
   15 |   0.7797 |     26.539 |   0.9100 |     29.075 |     1.8
   16 |   0.7651 |     26.127 |   0.8701 |     29.688 |     1.9
   17 |   0.7322 |     25.461 |   0.9141 |     29.504 |     2.1
   18 |   0.7218 |     24.675 |   0.8823 |     28.860 |     2.2
   19 |   0.7141 |     24.556 |   0.8576 |     28.370 |     2.3
   20 |   0.6881 |     23.575 |   0.8713 |     28.585 |     2.4
   21 |   0.6654 |     22.865 |   0.8560 |     28.064 |     2.5
   22 |   0.6514 |     22.415 |   0.8671 |     27.788 |     2.7
   23 |   0.6366 |     21.749 |   0.8500 |     27.696 |     2.8
   24 |   0.6199 |     21.413 |   0.8522 |     27.604 |     2.9
   25 |   0.5975 |     20.232 |   0.8813 |     28.248 |     3.0
   26 |   0.5826 |     20.243 |   0.8423 |     26.256 |     3.2
   27 |   0.5616 |     19.609 |   0.8563 |     25.919 |     3.3
   28 |   0.5571 |     19.208 |   0.8681 |     27.053 |     3.4
   29 |   0.5625 |     19.387 |   0.8918 |     27.574 |     3.5
   30 |   0.5469 |     18.823 |   0.8704 |     26.930 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,339,682

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6254 |     48.797 |   1.2764 |     41.667 |     0.1
    2 |   1.2784 |     41.959 |   1.1768 |     37.837 |     0.2
    3 |   1.1886 |     39.060 |   1.0916 |     35.539 |     0.3
    4 |   1.1245 |     37.522 |   1.1064 |     37.132 |     0.4
    5 |   1.0828 |     36.476 |   1.0841 |     36.520 |     0.5
    6 |   1.0356 |     35.067 |   1.0077 |     33.517 |     0.6
    7 |   1.0072 |     34.103 |   1.0022 |     33.150 |     0.8
    8 |   0.9537 |     32.380 |   0.9871 |     33.180 |     0.9
    9 |   0.9286 |     31.459 |   0.9677 |     31.893 |     1.0
   10 |   0.8906 |     30.435 |   0.9379 |     32.108 |     1.1
   11 |   0.8599 |     29.167 |   0.9292 |     31.281 |     1.2
   12 |   0.8464 |     29.102 |   0.9422 |     30.545 |     1.3
   13 |   0.8053 |     27.568 |   0.8949 |     29.136 |     1.4
   14 |   0.7835 |     26.810 |   0.8768 |     29.350 |     1.5
   15 |   0.7524 |     25.937 |   0.8722 |     28.830 |     1.6
   16 |   0.7234 |     24.902 |   0.8640 |     27.390 |     1.7
   17 |   0.6972 |     23.992 |   0.8748 |     27.665 |     1.8
   18 |   0.6716 |     23.304 |   0.8328 |     26.991 |     1.9
   19 |   0.6538 |     22.816 |   0.8861 |     27.972 |     2.1
   20 |   0.6281 |     21.906 |   0.8609 |     26.746 |     2.2
   21 |   0.6151 |     20.709 |   0.8298 |     26.042 |     2.3
   22 |   0.5970 |     20.459 |   0.8437 |     25.919 |     2.4
   23 |   0.5731 |     19.977 |   0.8336 |     25.735 |     2.5
   24 |   0.5637 |     19.441 |   0.8671 |     26.532 |     2.6
   25 |   0.5443 |     18.845 |   0.8498 |     25.184 |     2.7
   26 |   0.5124 |     17.528 |   0.8269 |     25.153 |     2.8
   27 |   0.5051 |     17.436 |   0.8337 |     24.326 |     2.9
   28 |   0.4860 |     16.753 |   0.8524 |     24.663 |     3.0
   29 |   0.4773 |     16.770 |   0.8646 |     25.306 |     3.1
   30 |   0.4467 |     15.886 |   0.8538 |     24.540 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 369,186

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6121 |     61.373 |   1.9011 |     44.730 |     0.1
    2 |   1.7860 |     45.541 |   1.5521 |     42.647 |     0.1
    3 |   1.5622 |     43.780 |   1.4308 |     41.759 |     0.2
    4 |   1.4533 |     42.322 |   1.3479 |     40.104 |     0.3
    5 |   1.3733 |     40.491 |   1.2908 |     38.480 |     0.3
    6 |   1.3128 |     39.299 |   1.2444 |     36.887 |     0.4
    7 |   1.2608 |     38.540 |   1.2008 |     36.336 |     0.5
    8 |   1.2169 |     37.370 |   1.1710 |     35.815 |     0.6
    9 |   1.1716 |     36.107 |   1.1396 |     34.589 |     0.6
   10 |   1.1312 |     34.802 |   1.1129 |     34.252 |     0.7
   11 |   1.0985 |     34.108 |   1.0896 |     33.885 |     0.8
   12 |   1.0630 |     33.024 |   1.0746 |     33.915 |     0.8
   13 |   1.0406 |     32.109 |   1.0681 |     33.211 |     0.9
   14 |   1.0092 |     31.459 |   1.0367 |     32.598 |     1.0
   15 |   0.9777 |     30.711 |   1.0276 |     32.659 |     1.0
   16 |   0.9541 |     29.958 |   1.0138 |     32.475 |     1.1
   17 |   0.9382 |     29.671 |   1.0060 |     31.710 |     1.2
   18 |   0.9165 |     28.609 |   0.9919 |     31.587 |     1.2
   19 |   0.8919 |     28.126 |   0.9900 |     31.036 |     1.3
   20 |   0.8694 |     27.568 |   0.9771 |     30.944 |     1.4
   21 |   0.8535 |     27.427 |   0.9751 |     31.066 |     1.5
   22 |   0.8367 |     26.636 |   0.9603 |     30.913 |     1.5
   23 |   0.8220 |     26.100 |   0.9669 |     30.699 |     1.6
   24 |   0.8066 |     25.661 |   0.9560 |     29.688 |     1.7
   25 |   0.7932 |     25.482 |   0.9540 |     29.902 |     1.7
   26 |   0.7760 |     24.567 |   0.9534 |     29.963 |     1.8
   27 |   0.7567 |     24.258 |   0.9374 |     29.565 |     1.9
   28 |   0.7409 |     24.052 |   0.9458 |     29.718 |     1.9
   29 |   0.7270 |     23.250 |   0.9370 |     29.289 |     2.0
   30 |   0.7204 |     22.968 |   0.9406 |     29.075 |     2.1
   31 |   0.7104 |     22.854 |   0.9278 |     28.952 |     2.1
   32 |   0.6902 |     22.248 |   0.9318 |     29.167 |     2.2
   33 |   0.6830 |     21.933 |   0.9310 |     28.493 |     2.3
   34 |   0.6636 |     21.278 |   0.9482 |     28.799 |     2.4
   35 |   0.6553 |     21.115 |   0.9345 |     28.125 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 469,154

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5941 |     46.505 |   1.3326 |     44.056 |     0.1
    2 |   1.2377 |     40.794 |   1.1652 |     38.174 |     0.2
    3 |   1.1196 |     37.169 |   1.0586 |     34.773 |     0.3
    4 |   1.0119 |     33.919 |   1.0015 |     33.548 |     0.4
    5 |   0.9403 |     31.930 |   0.9775 |     32.567 |     0.5
    6 |   0.8880 |     29.876 |   0.9342 |     30.453 |     0.6
    7 |   0.8351 |     28.457 |   0.9158 |     30.760 |     0.7
    8 |   0.7959 |     27.454 |   0.8747 |     29.749 |     0.8
    9 |   0.7498 |     25.574 |   0.8501 |     28.125 |     0.9
   10 |   0.7273 |     24.897 |   0.8207 |     27.022 |     1.0
   11 |   0.6840 |     23.450 |   0.8401 |     28.033 |     1.1
   12 |   0.6513 |     22.659 |   0.8028 |     26.624 |     1.2
   13 |   0.6415 |     21.966 |   0.8039 |     25.766 |     1.3
   14 |   0.5996 |     20.292 |   0.8357 |     25.521 |     1.4
   15 |   0.6089 |     20.860 |   0.8004 |     25.950 |     1.5
   16 |   0.5613 |     19.089 |   0.7781 |     24.847 |     1.6
   17 |   0.5396 |     18.796 |   0.7784 |     25.214 |     1.7
   18 |   0.5078 |     17.685 |   0.7827 |     24.173 |     1.8
   19 |   0.4814 |     16.878 |   0.8007 |     25.276 |     1.9
   20 |   0.4673 |     16.266 |   0.7980 |     24.081 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 126,690

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0079 |     50.607 |   1.4566 |     42.862 |     0.1
    2 |   1.3502 |     41.710 |   1.2504 |     38.695 |     0.2
    3 |   1.2050 |     38.605 |   1.1663 |     36.857 |     0.4
    4 |   1.1241 |     36.427 |   1.1240 |     35.754 |     0.5
    5 |   1.0563 |     34.731 |   1.0922 |     35.509 |     0.6
    6 |   0.9981 |     32.857 |   1.0132 |     33.088 |     0.8
    7 |   0.9408 |     31.415 |   0.9731 |     32.996 |     0.9
    8 |   0.9013 |     29.925 |   0.9620 |     31.526 |     1.0
    9 |   0.8613 |     29.232 |   0.9241 |     30.760 |     1.1
   10 |   0.8296 |     27.752 |   0.9020 |     31.158 |     1.3
   11 |   0.8011 |     27.254 |   0.8870 |     30.208 |     1.4
   12 |   0.7669 |     25.845 |   0.8696 |     28.860 |     1.5
   13 |   0.7351 |     24.778 |   0.8767 |     29.504 |     1.6
   14 |   0.7129 |     24.241 |   0.8572 |     27.420 |     1.8
   15 |   0.6886 |     23.239 |   0.8730 |     28.094 |     1.9
   16 |   0.6748 |     22.741 |   0.8343 |     27.298 |     2.0
   17 |   0.6489 |     22.069 |   0.8232 |     27.053 |     2.1
   18 |   0.6219 |     21.164 |   0.8458 |     27.145 |     2.3
   19 |   0.6171 |     21.012 |   0.8300 |     26.838 |     2.4
   20 |   0.5924 |     20.161 |   0.8129 |     26.471 |     2.5
   21 |   0.5657 |     19.143 |   0.8526 |     26.961 |     2.6
   22 |   0.5528 |     18.910 |   0.8498 |     26.501 |     2.7
   23 |   0.5477 |     18.910 |   0.8371 |     25.919 |     2.9
   24 |   0.5221 |     17.962 |   0.8655 |     26.317 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 160,226

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0259 |     52.232 |   1.4225 |     40.962 |     0.1
    2 |   1.3022 |     40.150 |   1.2145 |     38.021 |     0.1
    3 |   1.1546 |     37.191 |   1.1187 |     36.244 |     0.2
    4 |   1.0541 |     34.623 |   1.0577 |     34.681 |     0.3
    5 |   0.9900 |     32.775 |   0.9783 |     32.200 |     0.4
    6 |   0.9156 |     30.370 |   0.9307 |     30.852 |     0.4
    7 |   0.8571 |     28.511 |   0.8976 |     29.228 |     0.5
    8 |   0.8146 |     27.189 |   0.8853 |     28.983 |     0.6
    9 |   0.7699 |     25.249 |   0.8961 |     31.036 |     0.6
   10 |   0.7255 |     24.279 |   0.8638 |     28.248 |     0.7
   11 |   0.6949 |     23.320 |   0.8413 |     28.248 |     0.8
   12 |   0.6609 |     22.291 |   0.8275 |     27.237 |     0.8
   13 |   0.6218 |     20.839 |   0.8324 |     26.471 |     0.9
   14 |   0.6139 |     20.655 |   0.8124 |     25.705 |     1.0
   15 |   0.5737 |     19.441 |   0.8169 |     26.103 |     1.1
   16 |   0.5615 |     18.964 |   0.7907 |     25.429 |     1.1
   17 |   0.5381 |     18.265 |   0.8105 |     25.490 |     1.2
   18 |   0.5272 |     17.696 |   0.7790 |     23.591 |     1.3
   19 |   0.5040 |     17.013 |   0.8089 |     25.276 |     1.3
   20 |   0.4856 |     16.184 |   0.8119 |     25.214 |     1.4
   21 |   0.4811 |     16.450 |   0.8018 |     24.571 |     1.5
   22 |   0.4537 |     15.626 |   0.7939 |     24.387 |     1.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 126,242

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9921 |     74.247 |   2.5802 |     54.136 |     0.1
    2 |   2.3079 |     48.266 |   2.0520 |     45.343 |     0.1
    3 |   1.9261 |     44.934 |   1.8036 |     42.800 |     0.2
    4 |   1.7406 |     43.298 |   1.6707 |     42.004 |     0.2
    5 |   1.6230 |     42.409 |   1.5777 |     41.575 |     0.3
    6 |   1.5357 |     41.596 |   1.5032 |     40.839 |     0.3
    7 |   1.4656 |     40.729 |   1.4417 |     40.257 |     0.4
    8 |   1.4016 |     39.776 |   1.3953 |     39.614 |     0.4
    9 |   1.3526 |     39.115 |   1.3555 |     39.062 |     0.5
   10 |   1.3072 |     38.302 |   1.3165 |     38.450 |     0.5
   11 |   1.2653 |     37.370 |   1.2839 |     37.286 |     0.6
   12 |   1.2321 |     36.503 |   1.2577 |     36.949 |     0.7
   13 |   1.1955 |     35.864 |   1.2304 |     36.244 |     0.7
   14 |   1.1649 |     34.894 |   1.2038 |     35.723 |     0.8
   15 |   1.1377 |     34.422 |   1.1806 |     35.325 |     0.8
   16 |   1.1073 |     33.696 |   1.1683 |     35.386 |     0.9
   17 |   1.0826 |     32.802 |   1.1525 |     34.865 |     0.9
   18 |   1.0592 |     32.515 |   1.1304 |     34.161 |     1.0
   19 |   1.0370 |     31.935 |   1.1192 |     34.161 |     1.0
   20 |   1.0145 |     31.144 |   1.0938 |     33.333 |     1.1
   21 |   0.9949 |     30.456 |   1.0848 |     33.609 |     1.2
   22 |   0.9761 |     29.893 |   1.0725 |     32.966 |     1.2
   23 |   0.9610 |     29.757 |   1.0658 |     33.211 |     1.3
   24 |   0.9381 |     29.031 |   1.0546 |     32.751 |     1.3
   25 |   0.9222 |     28.473 |   1.0542 |     33.027 |     1.4
   26 |   0.9085 |     28.262 |   1.0420 |     32.414 |     1.4
   27 |   0.8898 |     27.763 |   1.0301 |     31.985 |     1.5
   28 |   0.8783 |     27.482 |   1.0204 |     32.016 |     1.5
   29 |   0.8629 |     26.869 |   1.0126 |     31.801 |     1.6
   30 |   0.8510 |     26.642 |   1.0025 |     31.189 |     1.7
   31 |   0.8379 |     26.192 |   1.0003 |     31.495 |     1.7
   32 |   0.8264 |     25.845 |   0.9923 |     30.790 |     1.8
   33 |   0.8135 |     25.629 |   0.9899 |     30.699 |     1.8
   34 |   0.8034 |     25.336 |   0.9874 |     30.882 |     1.9
   35 |   0.7886 |     24.680 |   0.9805 |     30.668 |     1.9
   36 |   0.7766 |     24.480 |   0.9808 |     30.392 |     2.0
   37 |   0.7691 |     24.144 |   0.9798 |     30.484 |     2.0
   38 |   0.7542 |     23.683 |   0.9653 |     29.626 |     2.1
   39 |   0.7411 |     23.580 |   0.9777 |     29.718 |     2.2
   40 |   0.7349 |     23.239 |   0.9721 |     29.841 |     2.2
   41 |   0.7245 |     22.941 |   0.9609 |     29.075 |     2.3
   42 |   0.7166 |     22.648 |   0.9613 |     29.167 |     2.3
   43 |   0.7081 |     22.177 |   0.9535 |     29.534 |     2.4
   44 |   0.7005 |     21.922 |   0.9570 |     29.013 |     2.4
   45 |   0.6859 |     21.803 |   0.9544 |     28.830 |     2.5
   46 |   0.6783 |     21.863 |   0.9539 |     28.768 |     2.5
   47 |   0.6686 |     21.364 |   0.9516 |     28.891 |     2.6
   48 |   0.6620 |     20.882 |   0.9500 |     28.462 |     2.7
   49 |   0.6533 |     20.990 |   0.9527 |     28.830 |     2.7
   50 |   0.6447 |     20.546 |   0.9577 |     29.289 |     2.8
   51 |   0.6357 |     20.156 |   0.9479 |     28.891 |     2.8
   52 |   0.6310 |     20.449 |   0.9506 |     28.738 |     2.9
   53 |   0.6225 |     19.988 |   0.9349 |     28.186 |     2.9
   54 |   0.6177 |     19.544 |   0.9528 |     28.738 |     3.0
   55 |   0.6101 |     19.457 |   0.9493 |     28.707 |     3.0
   56 |   0.6023 |     19.332 |   0.9503 |     28.585 |     3.1
   57 |   0.5930 |     19.327 |   0.9508 |     28.217 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 312,098

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6719 |     47.762 |   1.2722 |     39.706 |     0.1
    2 |   1.2095 |     38.974 |   1.1648 |     38.235 |     0.1
    3 |   1.0949 |     35.940 |   1.0705 |     35.202 |     0.2
    4 |   1.0022 |     32.976 |   1.0005 |     32.537 |     0.3
    5 |   0.9291 |     30.873 |   0.9609 |     31.648 |     0.3
    6 |   0.8597 |     28.663 |   0.9190 |     30.637 |     0.4
    7 |   0.8058 |     26.772 |   0.8681 |     28.646 |     0.5
    8 |   0.7631 |     25.303 |   0.9049 |     29.136 |     0.5
    9 |   0.7296 |     24.220 |   0.8453 |     28.125 |     0.6
   10 |   0.6779 |     22.600 |   0.8307 |     28.217 |     0.7
   11 |   0.6462 |     21.646 |   0.8233 |     27.175 |     0.8
   12 |   0.6201 |     20.524 |   0.7938 |     25.950 |     0.8
   13 |   0.5956 |     20.292 |   0.8340 |     26.869 |     0.9
   14 |   0.5642 |     19.305 |   0.8104 |     25.827 |     1.0
   15 |   0.5386 |     18.395 |   0.8405 |     26.991 |     1.0
   16 |   0.5209 |     17.989 |   0.8415 |     26.011 |     1.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 312,098

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7764 |     49.610 |   1.3095 |     42.341 |     0.1
    2 |   1.2733 |     40.897 |   1.1964 |     39.461 |     0.2
    3 |   1.1601 |     37.998 |   1.0780 |     35.325 |     0.3
    4 |   1.0765 |     35.441 |   1.0497 |     34.804 |     0.4
    5 |   1.0251 |     34.211 |   0.9761 |     32.292 |     0.5
    6 |   0.9646 |     32.065 |   0.9388 |     31.863 |     0.6
    7 |   0.9165 |     30.575 |   0.9258 |     30.362 |     0.7
    8 |   0.8707 |     29.085 |   0.8966 |     30.270 |     0.8
    9 |   0.8516 |     28.901 |   0.8844 |     29.933 |     0.9
   10 |   0.8222 |     27.595 |   0.8672 |     29.105 |     1.0
   11 |   0.7749 |     26.322 |   0.8601 |     28.094 |     1.1
   12 |   0.7667 |     25.970 |   0.8341 |     27.635 |     1.2
   13 |   0.7342 |     25.065 |   0.8389 |     27.574 |     1.3
   14 |   0.7079 |     24.334 |   0.8418 |     27.574 |     1.4
   15 |   0.6911 |     23.440 |   0.8301 |     27.359 |     1.5
   16 |   0.6726 |     23.028 |   0.8059 |     26.409 |     1.6
   17 |   0.6480 |     21.971 |   0.8209 |     25.919 |     1.7
   18 |   0.6337 |     21.646 |   0.7976 |     24.908 |     1.8
   19 |   0.6191 |     21.267 |   0.8092 |     25.735 |     1.9
   20 |   0.5991 |     20.362 |   0.7957 |     24.816 |     2.0
   21 |   0.5846 |     20.004 |   0.8233 |     25.797 |     2.1
   22 |   0.5681 |     19.522 |   0.8109 |     25.398 |     2.2
   23 |   0.5636 |     19.593 |   0.8261 |     24.694 |     2.3
   24 |   0.5455 |     18.823 |   0.8259 |     25.123 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 435,938

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4861 |     61.005 |   1.7710 |     43.689 |     0.1
    2 |   1.5984 |     43.411 |   1.4727 |     41.973 |     0.2
    3 |   1.4081 |     41.174 |   1.3458 |     39.828 |     0.3
    4 |   1.2984 |     38.638 |   1.2640 |     37.377 |     0.4
    5 |   1.2180 |     36.498 |   1.2053 |     34.498 |     0.5
    6 |   1.1496 |     34.894 |   1.1565 |     35.417 |     0.6
    7 |   1.0921 |     33.382 |   1.1243 |     34.528 |     0.7
    8 |   1.0397 |     31.762 |   1.0729 |     32.629 |     0.7
    9 |   0.9956 |     30.267 |   1.0490 |     32.445 |     0.8
   10 |   0.9547 |     29.096 |   1.0094 |     30.974 |     0.9
   11 |   0.9062 |     27.520 |   0.9807 |     30.025 |     1.0
   12 |   0.8689 |     26.506 |   0.9746 |     29.902 |     1.1
   13 |   0.8329 |     25.618 |   0.9713 |     29.504 |     1.2
   14 |   0.8016 |     24.095 |   0.9433 |     28.738 |     1.3
   15 |   0.7733 |     23.656 |   0.9226 |     28.370 |     1.4
   16 |   0.7375 |     22.388 |   0.8975 |     27.972 |     1.5
   17 |   0.7050 |     21.408 |   0.8795 |     26.562 |     1.6
   18 |   0.6834 |     20.752 |   0.8756 |     26.593 |     1.7
   19 |   0.6561 |     20.302 |   0.8700 |     26.471 |     1.8
   20 |   0.6375 |     19.593 |   0.8611 |     25.827 |     1.9
   21 |   0.6116 |     18.596 |   0.8565 |     26.103 |     2.0
   22 |   0.5876 |     17.680 |   0.8605 |     25.827 |     2.1
   23 |   0.5732 |     17.360 |   0.8345 |     25.153 |     2.2
   24 |   0.5532 |     17.116 |   0.8477 |     25.245 |     2.3
   25 |   0.5306 |     16.217 |   0.8340 |     24.847 |     2.3
   26 |   0.5147 |     15.908 |   0.8385 |     25.674 |     2.4
   27 |   0.5040 |     15.507 |   0.8502 |     24.908 |     2.5
   28 |   0.4801 |     14.776 |   0.8380 |     24.449 |     2.6
   29 |   0.4667 |     14.489 |   0.8201 |     24.816 |     2.7
   30 |   0.4511 |     14.082 |   0.8437 |     24.694 |     2.8
   31 |   0.4365 |     13.925 |   0.8320 |     24.326 |     2.9
   32 |   0.4251 |     13.253 |   0.8311 |     23.928 |     3.0
   33 |   0.4176 |     13.145 |   0.8626 |     24.786 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 910,114

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5613 |     46.543 |   1.2703 |     41.299 |     0.1
    2 |   1.2481 |     41.266 |   1.1657 |     39.062 |     0.3
    3 |   1.1638 |     38.952 |   1.1018 |     37.347 |     0.4
    4 |   1.1030 |     37.029 |   1.0636 |     36.244 |     0.6
    5 |   1.0645 |     35.755 |   1.0152 |     34.099 |     0.7
    6 |   1.0139 |     34.401 |   1.0015 |     33.762 |     0.9
    7 |   0.9744 |     32.959 |   0.9557 |     32.782 |     1.0
    8 |   0.9337 |     31.897 |   0.9361 |     31.771 |     1.2
    9 |   0.9080 |     30.895 |   0.9020 |     30.178 |     1.3
   10 |   0.8756 |     29.811 |   0.9080 |     30.882 |     1.4
   11 |   0.8558 |     29.524 |   0.8704 |     29.504 |     1.6
   12 |   0.8196 |     28.300 |   0.8534 |     28.983 |     1.7
   13 |   0.8009 |     27.384 |   0.8729 |     28.493 |     1.9
   14 |   0.7804 |     26.631 |   0.8495 |     28.094 |     2.0
   15 |   0.7556 |     26.122 |   0.8913 |     29.442 |     2.2
   16 |   0.7360 |     25.293 |   0.8376 |     27.390 |     2.3
   17 |   0.7073 |     24.366 |   0.8524 |     27.328 |     2.5
   18 |   0.6993 |     24.399 |   0.8257 |     28.339 |     2.6
   19 |   0.6768 |     23.429 |   0.8395 |     26.900 |     2.7
   20 |   0.6612 |     22.892 |   0.8066 |     26.624 |     2.9
   21 |   0.6411 |     22.340 |   0.8132 |     25.735 |     3.0
   22 |   0.6260 |     21.841 |   0.8104 |     26.685 |     3.2
   23 |   0.5992 |     20.524 |   0.8002 |     26.042 |     3.3
   24 |   0.5848 |     20.031 |   0.8156 |     25.705 |     3.5
   25 |   0.5789 |     20.226 |   0.8548 |     26.746 |     3.6
   26 |   0.5571 |     19.083 |   0.8241 |     25.245 |     3.8
   27 |   0.5466 |     18.764 |   0.8415 |     26.103 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 810,530

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5422 |     46.635 |   1.2067 |     40.135 |     0.1
    2 |   1.1714 |     38.860 |   1.0914 |     36.152 |     0.2
    3 |   1.0630 |     35.333 |   0.9980 |     33.395 |     0.3
    4 |   0.9903 |     33.068 |   0.9502 |     31.710 |     0.4
    5 |   0.9239 |     30.603 |   0.9303 |     31.097 |     0.5
    6 |   0.8854 |     29.741 |   0.8876 |     29.228 |     0.6
    7 |   0.8367 |     28.327 |   0.8720 |     29.259 |     0.8
    8 |   0.7953 |     26.783 |   0.8615 |     29.289 |     0.9
    9 |   0.7593 |     26.051 |   0.8723 |     28.830 |     1.0
   10 |   0.7331 |     24.978 |   0.8367 |     27.512 |     1.1
   11 |   0.7077 |     24.063 |   0.8417 |     27.420 |     1.2
   12 |   0.6895 |     23.505 |   0.8306 |     27.665 |     1.3
   13 |   0.6384 |     21.673 |   0.8794 |     28.738 |     1.4
   14 |   0.6340 |     22.155 |   0.8488 |     27.053 |     1.5
   15 |   0.6102 |     21.662 |   0.7901 |     26.042 |     1.6
   16 |   0.5721 |     19.603 |   0.8177 |     25.490 |     1.7
   17 |   0.5616 |     19.533 |   0.8708 |     26.471 |     1.8
   18 |   0.5560 |     19.533 |   0.7978 |     24.112 |     1.9
   19 |   0.5411 |     18.991 |   0.8689 |     26.869 |     2.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 160,226

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.2300 |     84.092 |   2.8025 |     63.021 |     0.1
    2 |   2.6637 |     60.739 |   2.1980 |     51.961 |     0.2
    3 |   2.2083 |     50.829 |   1.8937 |     46.538 |     0.2
    4 |   1.9510 |     47.448 |   1.7294 |     46.538 |     0.3
    5 |   1.7984 |     46.310 |   1.6266 |     45.466 |     0.4
    6 |   1.6949 |     45.850 |   1.5570 |     44.822 |     0.5
    7 |   1.6239 |     45.232 |   1.5049 |     44.301 |     0.5
    8 |   1.5692 |     44.961 |   1.4666 |     43.382 |     0.6
    9 |   1.5205 |     44.717 |   1.4331 |     42.984 |     0.7
   10 |   1.4843 |     43.764 |   1.4035 |     42.310 |     0.8
   11 |   1.4548 |     43.736 |   1.3719 |     41.422 |     0.8
   12 |   1.4223 |     42.609 |   1.3436 |     40.839 |     0.9
   13 |   1.3947 |     42.366 |   1.3286 |     40.748 |     1.0
   14 |   1.3698 |     41.997 |   1.3161 |     40.533 |     1.1
   15 |   1.3494 |     41.542 |   1.2899 |     39.706 |     1.1
   16 |   1.3272 |     40.751 |   1.2806 |     39.154 |     1.2
   17 |   1.3087 |     40.545 |   1.2636 |     39.001 |     1.3
   18 |   1.2876 |     40.220 |   1.2566 |     39.032 |     1.4
   19 |   1.2715 |     39.521 |   1.2406 |     38.542 |     1.4
   20 |   1.2547 |     38.963 |   1.2354 |     38.205 |     1.5
   21 |   1.2391 |     38.844 |   1.2201 |     37.714 |     1.6
   22 |   1.2235 |     38.253 |   1.2167 |     38.051 |     1.7
   23 |   1.2085 |     37.841 |   1.2092 |     37.102 |     1.7
   24 |   1.1925 |     37.365 |   1.1970 |     36.949 |     1.8
   25 |   1.1820 |     37.050 |   1.1916 |     37.224 |     1.9
   26 |   1.1710 |     36.936 |   1.1847 |     36.887 |     2.0
   27 |   1.1538 |     36.443 |   1.1886 |     36.857 |     2.0
   28 |   1.1461 |     36.032 |   1.1846 |     36.366 |     2.1
   29 |   1.1331 |     35.842 |   1.1786 |     36.336 |     2.2
   30 |   1.1214 |     35.273 |   1.1675 |     36.029 |     2.3
   31 |   1.1119 |     34.785 |   1.1588 |     35.999 |     2.4
   32 |   1.1002 |     34.829 |   1.1647 |     36.121 |     2.4
   33 |   1.0879 |     34.493 |   1.1597 |     35.233 |     2.5
   34 |   1.0754 |     33.843 |   1.1502 |     35.325 |     2.6
   35 |   1.0716 |     34.070 |   1.1483 |     35.417 |     2.7
   36 |   1.0609 |     33.480 |   1.1435 |     35.080 |     2.7
   37 |   1.0510 |     33.458 |   1.1540 |     35.263 |     2.8
   38 |   1.0440 |     32.954 |   1.1396 |     34.865 |     2.9
   39 |   1.0356 |     32.970 |   1.1350 |     34.651 |     3.0
   40 |   1.0292 |     32.613 |   1.1259 |     34.865 |     3.0
   41 |   1.0229 |     32.261 |   1.1410 |     35.355 |     3.1
   42 |   1.0116 |     31.881 |   1.1369 |     35.294 |     3.2
   43 |   0.9975 |     31.773 |   1.1382 |     34.835 |     3.3
   44 |   0.9985 |     32.141 |   1.1329 |     34.375 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 894,178

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6520 |     48.656 |   1.2948 |     42.065 |     0.1
    2 |   1.2737 |     41.618 |   1.1944 |     38.051 |     0.2
    3 |   1.1964 |     39.624 |   1.1612 |     38.388 |     0.3
    4 |   1.1364 |     37.733 |   1.1049 |     35.325 |     0.4
    5 |   1.0836 |     36.265 |   1.0612 |     34.130 |     0.5
    6 |   1.0294 |     34.552 |   1.0861 |     35.294 |     0.6
    7 |   0.9963 |     34.005 |   1.0688 |     35.325 |     0.7
    8 |   0.9678 |     32.396 |   1.0804 |     35.570 |     0.7
    9 |   0.9458 |     32.103 |   1.0790 |     35.631 |     0.8
   10 |   0.8976 |     30.229 |   1.0147 |     32.506 |     0.9
   11 |   0.8700 |     29.860 |   1.0455 |     34.314 |     1.0
   12 |   0.8409 |     28.695 |   1.0896 |     34.773 |     1.1
   13 |   0.8281 |     28.419 |   1.0636 |     35.723 |     1.2
   14 |   0.8035 |     27.709 |   1.0810 |     34.498 |     1.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 362,530

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8638 |     70.671 |   2.2114 |     53.064 |     0.1
    2 |   2.1445 |     49.810 |   1.6904 |     45.466 |     0.2
    3 |   1.7783 |     46.413 |   1.5280 |     43.995 |     0.3
    4 |   1.6068 |     45.400 |   1.4519 |     43.352 |     0.4
    5 |   1.5148 |     44.565 |   1.4125 |     43.382 |     0.6
    6 |   1.4479 |     43.682 |   1.3697 |     41.422 |     0.7
    7 |   1.3952 |     42.669 |   1.3329 |     39.737 |     0.8
    8 |   1.3538 |     41.862 |   1.3068 |     38.450 |     0.9
    9 |   1.3188 |     40.778 |   1.2952 |     38.940 |     1.0
   10 |   1.2796 |     39.770 |   1.2784 |     37.623 |     1.1
   11 |   1.2478 |     39.109 |   1.2669 |     37.255 |     1.2
   12 |   1.2227 |     38.231 |   1.2608 |     37.347 |     1.3
   13 |   1.1932 |     37.240 |   1.2455 |     36.520 |     1.4
   14 |   1.1669 |     36.590 |   1.2184 |     36.183 |     1.6
   15 |   1.1425 |     36.286 |   1.2345 |     37.286 |     1.7
   16 |   1.1198 |     35.159 |   1.2237 |     36.826 |     1.8
   17 |   1.1025 |     34.563 |   1.2050 |     36.121 |     1.9
   18 |   1.0819 |     34.303 |   1.2179 |     35.968 |     2.0
   19 |   1.0618 |     33.615 |   1.1984 |     36.458 |     2.1
   20 |   1.0468 |     33.008 |   1.2022 |     35.202 |     2.2
   21 |   1.0284 |     32.298 |   1.2162 |     36.489 |     2.3
   22 |   1.0101 |     32.304 |   1.2009 |     35.723 |     2.5
   23 |   0.9939 |     31.469 |   1.2134 |     36.121 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,322

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6228 |     46.733 |   1.2788 |     42.034 |     0.1
    2 |   1.1894 |     39.261 |   1.1178 |     36.489 |     0.3
    3 |   1.0727 |     36.129 |   1.0430 |     34.926 |     0.4
    4 |   0.9911 |     33.247 |   1.0019 |     34.038 |     0.6
    5 |   0.9307 |     31.854 |   0.9506 |     31.771 |     0.7
    6 |   0.8644 |     29.318 |   0.9118 |     30.607 |     0.9
    7 |   0.8124 |     27.281 |   0.9199 |     31.495 |     1.0
    8 |   0.7952 |     27.162 |   0.8505 |     28.676 |     1.2
    9 |   0.7330 |     24.973 |   0.8555 |     28.860 |     1.3
   10 |   0.6932 |     23.673 |   0.8324 |     27.819 |     1.5
   11 |   0.6648 |     22.621 |   0.7837 |     25.980 |     1.6
   12 |   0.6367 |     21.673 |   0.8146 |     26.685 |     1.8
   13 |   0.6153 |     21.245 |   0.8036 |     26.134 |     1.9
   14 |   0.5945 |     20.335 |   0.7741 |     25.398 |     2.1
   15 |   0.5702 |     19.728 |   0.7737 |     24.908 |     2.2
   16 |   0.5479 |     18.877 |   0.7748 |     24.816 |     2.4
   17 |   0.5170 |     18.184 |   0.7604 |     23.928 |     2.5
   18 |   0.5114 |     17.712 |   0.8029 |     25.153 |     2.7
   19 |   0.4930 |     17.539 |   0.7702 |     24.020 |     2.8
   20 |   0.4784 |     16.661 |   0.7542 |     23.989 |     3.0
   21 |   0.4493 |     15.708 |   0.7741 |     23.621 |     3.1
   22 |   0.4402 |     15.616 |   0.7850 |     23.989 |     3.3
   23 |   0.4223 |     14.814 |   0.7774 |     22.120 |     3.4
   24 |   0.4169 |     14.721 |   0.7535 |     22.365 |     3.5
   25 |   0.4045 |     14.218 |   0.7640 |     22.212 |     3.7
   26 |   0.3893 |     13.871 |   0.8118 |     23.744 |     3.8
   27 |   0.3837 |     13.578 |   0.8239 |     23.744 |     4.0
   28 |   0.3664 |     13.004 |   0.8069 |     23.131 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3019 |     55.120 |   1.7113 |     45.558 |     0.1
    2 |   1.5943 |     44.490 |   1.5014 |     42.586 |     0.3
    3 |   1.4361 |     41.732 |   1.3798 |     41.330 |     0.5
    4 |   1.3227 |     39.104 |   1.2870 |     37.745 |     0.6
    5 |   1.2307 |     36.519 |   1.2113 |     35.876 |     0.8
    6 |   1.1519 |     34.531 |   1.1605 |     34.988 |     0.9
    7 |   1.0847 |     32.927 |   1.1112 |     33.640 |     1.1
    8 |   1.0305 |     31.361 |   1.0746 |     32.812 |     1.2
    9 |   0.9781 |     29.633 |   1.0333 |     31.985 |     1.4
   10 |   0.9274 |     28.251 |   1.0003 |     31.526 |     1.5
   11 |   0.8852 |     27.064 |   0.9775 |     30.300 |     1.7
   12 |   0.8455 |     25.612 |   0.9711 |     30.239 |     1.8
   13 |   0.8045 |     24.529 |   0.9388 |     29.442 |     2.0
   14 |   0.7686 |     23.169 |   0.9376 |     29.228 |     2.1
   15 |   0.7393 |     22.280 |   0.9253 |     28.278 |     2.3
   16 |   0.7090 |     21.565 |   0.9070 |     27.696 |     2.4
   17 |   0.6792 |     20.443 |   0.9066 |     28.707 |     2.6
   18 |   0.6505 |     19.717 |   0.8839 |     27.635 |     2.7
   19 |   0.6222 |     18.926 |   0.8803 |     27.175 |     2.9
   20 |   0.6028 |     18.200 |   0.8856 |     25.888 |     3.1
   21 |   0.5803 |     17.431 |   0.8748 |     26.379 |     3.2
   22 |   0.5546 |     16.981 |   0.8881 |     27.175 |     3.4
   23 |   0.5348 |     16.054 |   0.8737 |     25.797 |     3.5
   24 |   0.5175 |     15.914 |   0.8695 |     26.471 |     3.7
   25 |   0.4957 |     15.355 |   0.8587 |     25.276 |     3.8
   26 |   0.4737 |     14.575 |   0.8759 |     25.153 |     4.0
   27 |   0.4567 |     13.979 |   0.8803 |     26.134 |     4.1
   28 |   0.4404 |     13.649 |   0.8905 |     25.398 |     4.3
   29 |   0.4301 |     13.269 |   0.8842 |     25.643 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 810,530

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5635 |     47.199 |   1.2495 |     40.656 |     0.1
    2 |   1.2450 |     40.951 |   1.1384 |     37.010 |     0.2
    3 |   1.1540 |     38.210 |   1.0836 |     35.876 |     0.3
    4 |   1.0888 |     36.438 |   1.0284 |     34.069 |     0.4
    5 |   1.0288 |     34.634 |   0.9824 |     33.180 |     0.5
    6 |   0.9819 |     33.198 |   0.9750 |     33.058 |     0.6
    7 |   0.9439 |     31.724 |   0.9632 |     31.771 |     0.8
    8 |   0.9042 |     30.527 |   0.9159 |     31.036 |     0.9
    9 |   0.8718 |     29.508 |   0.9247 |     31.189 |     1.0
   10 |   0.8437 |     28.462 |   0.9204 |     30.392 |     1.1
   11 |   0.8169 |     27.682 |   0.9110 |     30.637 |     1.2
   12 |   0.7702 |     26.647 |   0.8862 |     29.381 |     1.3
   13 |   0.7527 |     26.111 |   0.8890 |     29.381 |     1.4
   14 |   0.7441 |     25.704 |   0.9241 |     29.933 |     1.5
   15 |   0.7111 |     24.241 |   0.9020 |     28.646 |     1.6
   16 |   0.6963 |     24.328 |   0.8671 |     27.328 |     1.7
   17 |   0.6827 |     23.532 |   0.8788 |     27.788 |     1.8
   18 |   0.6444 |     22.475 |   0.8694 |     27.420 |     1.9
   19 |   0.6300 |     21.478 |   0.9113 |     29.167 |     2.0
   20 |   0.6318 |     21.630 |   0.9096 |     28.248 |     2.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5724 |     47.659 |   1.3159 |     44.669 |     0.2
    2 |   1.2880 |     42.940 |   1.2384 |     41.085 |     0.3
    3 |   1.2263 |     40.968 |   1.1387 |     38.480 |     0.5
    4 |   1.1713 |     39.223 |   1.1067 |     37.408 |     0.6
    5 |   1.1291 |     38.486 |   1.0822 |     37.316 |     0.8
    6 |   1.0879 |     37.337 |   1.0329 |     34.896 |     0.9
    7 |   1.0624 |     36.021 |   1.0228 |     34.528 |     1.1
    8 |   1.0330 |     35.116 |   1.0011 |     34.375 |     1.3
    9 |   1.0012 |     34.222 |   0.9797 |     32.874 |     1.4
   10 |   0.9774 |     33.577 |   0.9480 |     31.924 |     1.6
   11 |   0.9616 |     32.634 |   0.9312 |     31.679 |     1.7
   12 |   0.9232 |     31.415 |   0.9501 |     32.751 |     1.9
   13 |   0.9158 |     31.301 |   0.9271 |     32.384 |     2.1
   14 |   0.9091 |     31.128 |   0.9137 |     31.158 |     2.2
   15 |   0.8841 |     30.061 |   0.9081 |     31.893 |     2.4
   16 |   0.8440 |     29.188 |   0.9096 |     31.189 |     2.5
   17 |   0.8301 |     28.722 |   0.9440 |     32.537 |     2.7
   18 |   0.8152 |     28.424 |   0.9065 |     31.158 |     2.9
   19 |   0.8079 |     27.763 |   0.9031 |     30.852 |     3.0
   20 |   0.7929 |     27.211 |   0.9206 |     30.913 |     3.2
   21 |   0.7602 |     26.327 |   0.8985 |     31.373 |     3.3
   22 |   0.7670 |     26.528 |   0.8541 |     28.738 |     3.5
   23 |   0.7475 |     26.105 |   0.9082 |     31.250 |     3.6
   24 |   0.7228 |     25.114 |   0.9261 |     31.464 |     3.8
   25 |   0.7092 |     24.702 |   0.8816 |     28.676 |     4.0
   26 |   0.6926 |     23.965 |   0.9244 |     30.913 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,472,162

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6758 |     49.615 |   1.3108 |     42.494 |     0.2
    2 |   1.3073 |     43.119 |   1.2577 |     41.667 |     0.3
    3 |   1.2378 |     40.686 |   1.1770 |     38.143 |     0.5
    4 |   1.1836 |     39.570 |   1.1080 |     37.439 |     0.7
    5 |   1.1310 |     37.896 |   1.1017 |     36.152 |     0.8
    6 |   1.0969 |     36.774 |   1.0801 |     35.263 |     1.0
    7 |   1.0648 |     35.994 |   1.0441 |     34.283 |     1.2
    8 |   1.0287 |     34.834 |   1.0215 |     34.528 |     1.4
    9 |   0.9952 |     33.751 |   1.0348 |     33.640 |     1.5
   10 |   0.9802 |     33.404 |   1.0170 |     33.119 |     1.7
   11 |   0.9410 |     31.908 |   0.9948 |     32.322 |     1.9
   12 |   0.9033 |     30.288 |   0.9475 |     32.016 |     2.0
   13 |   0.8869 |     29.801 |   0.9558 |     32.047 |     2.2
   14 |   0.8808 |     29.763 |   0.9614 |     32.077 |     2.4
   15 |   0.8421 |     28.603 |   0.9159 |     30.362 |     2.5
   16 |   0.8040 |     27.314 |   0.9440 |     31.464 |     2.7
   17 |   0.7914 |     27.352 |   0.9197 |     30.270 |     2.9
   18 |   0.7777 |     26.593 |   0.9345 |     30.362 |     3.1
   19 |   0.7574 |     25.688 |   0.9059 |     29.534 |     3.2
   20 |   0.7401 |     25.580 |   0.9034 |     30.790 |     3.4
   21 |   0.7266 |     25.049 |   0.9293 |     31.311 |     3.6
   22 |   0.7099 |     24.312 |   0.8866 |     29.381 |     3.7
   23 |   0.6788 |     23.488 |   0.8957 |     30.086 |     3.9
   24 |   0.7041 |     24.003 |   0.8870 |     29.228 |     4.1
   25 |   0.6982 |     23.786 |   0.9132 |     30.086 |     4.2
   26 |   0.6429 |     22.361 |   0.9124 |     29.412 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 469,154

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6447 |     47.415 |   1.2845 |     40.962 |     0.2
    2 |   1.2603 |     41.770 |   1.1776 |     38.419 |     0.3
    3 |   1.1664 |     39.115 |   1.0959 |     36.795 |     0.5
    4 |   1.0981 |     37.132 |   1.0476 |     34.988 |     0.6
    5 |   1.0335 |     34.986 |   0.9989 |     33.517 |     0.8
    6 |   0.9875 |     33.929 |   0.9596 |     32.322 |     0.9
    7 |   0.9433 |     32.125 |   0.9401 |     31.832 |     1.1
    8 |   0.9209 |     31.464 |   0.8856 |     30.362 |     1.3
    9 |   0.8787 |     30.007 |   0.8650 |     30.300 |     1.4
   10 |   0.8439 |     29.313 |   0.8651 |     29.596 |     1.6
   11 |   0.8134 |     27.687 |   0.8498 |     28.431 |     1.7
   12 |   0.7883 |     27.254 |   0.8592 |     28.585 |     1.9
   13 |   0.7599 |     26.024 |   0.8459 |     28.952 |     2.1
   14 |   0.7351 |     25.439 |   0.8082 |     27.757 |     2.2
   15 |   0.7084 |     24.366 |   0.8013 |     27.788 |     2.4
   16 |   0.6930 |     24.225 |   0.7971 |     27.298 |     2.5
   17 |   0.6603 |     22.659 |   0.8098 |     26.532 |     2.7
   18 |   0.6679 |     23.022 |   0.7824 |     25.827 |     2.8
   19 |   0.6296 |     21.771 |   0.7794 |     26.654 |     3.0
   20 |   0.6098 |     21.310 |   0.8294 |     27.451 |     3.2
   21 |   0.6002 |     20.866 |   0.7696 |     25.490 |     3.3
   22 |   0.5809 |     20.124 |   0.7728 |     24.694 |     3.5
   23 |   0.5583 |     19.587 |   0.7811 |     25.061 |     3.6
   24 |   0.5432 |     18.937 |   0.7571 |     23.897 |     3.8
   25 |   0.5385 |     19.121 |   0.7688 |     25.184 |     4.0
   26 |   0.5066 |     17.886 |   0.7682 |     23.744 |     4.1
   27 |   0.4971 |     17.138 |   0.7715 |     25.092 |     4.3
   28 |   0.4837 |     17.046 |   0.7586 |     23.775 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,074,594

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0360 |     53.403 |   1.4707 |     41.605 |     0.1
    2 |   1.3639 |     40.892 |   1.2808 |     37.837 |     0.3
    3 |   1.2156 |     37.592 |   1.2004 |     37.623 |     0.4
    4 |   1.1080 |     34.574 |   1.1153 |     34.375 |     0.6
    5 |   1.0205 |     32.065 |   1.0486 |     32.721 |     0.7
    6 |   0.9480 |     29.643 |   1.0098 |     31.526 |     0.8
    7 |   0.8888 |     28.056 |   0.9732 |     30.974 |     1.0
    8 |   0.8398 |     26.691 |   0.9426 |     30.208 |     1.1
    9 |   0.7821 |     24.886 |   0.9288 |     28.891 |     1.2
   10 |   0.7372 |     22.963 |   0.8831 |     28.033 |     1.4
   11 |   0.6911 |     21.646 |   0.8779 |     27.298 |     1.5
   12 |   0.6524 |     20.644 |   0.8473 |     26.225 |     1.7
   13 |   0.6182 |     19.295 |   0.8557 |     26.348 |     1.8
   14 |   0.5809 |     18.303 |   0.8463 |     25.735 |     1.9
   15 |   0.5532 |     17.311 |   0.8132 |     24.540 |     2.1
   16 |   0.5282 |     16.780 |   0.8422 |     26.134 |     2.2
   17 |   0.4954 |     15.610 |   0.8348 |     24.939 |     2.4
   18 |   0.4808 |     15.388 |   0.8420 |     25.582 |     2.5
   19 |   0.4583 |     14.602 |   0.8138 |     24.142 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 827,874

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4646 |     61.655 |   1.6729 |     45.098 |     0.1
    2 |   1.6872 |     46.050 |   1.4115 |     42.279 |     0.2
    3 |   1.4823 |     44.164 |   1.3186 |     40.625 |     0.3
    4 |   1.3751 |     41.770 |   1.2497 |     38.879 |     0.5
    5 |   1.2949 |     39.982 |   1.2171 |     37.745 |     0.6
    6 |   1.2388 |     38.427 |   1.1764 |     36.581 |     0.7
    7 |   1.1906 |     37.386 |   1.1715 |     35.754 |     0.8
    8 |   1.1465 |     35.972 |   1.1346 |     35.631 |     0.9
    9 |   1.1143 |     35.409 |   1.1221 |     35.110 |     1.0
   10 |   1.0760 |     33.826 |   1.1077 |     34.835 |     1.1
   11 |   1.0502 |     33.317 |   1.1042 |     34.406 |     1.2
   12 |   1.0213 |     32.483 |   1.0865 |     33.854 |     1.4
   13 |   0.9961 |     31.708 |   1.0762 |     34.038 |     1.5
   14 |   0.9703 |     30.846 |   1.0799 |     34.559 |     1.6
   15 |   0.9435 |     30.256 |   1.0821 |     34.926 |     1.7
   16 |   0.9204 |     29.465 |   1.0697 |     33.456 |     1.8
   17 |   0.9040 |     28.988 |   1.0678 |     33.058 |     1.9
   18 |   0.8790 |     28.067 |   1.0589 |     32.966 |     2.0
   19 |   0.8561 |     27.698 |   1.0651 |     32.904 |     2.2
   20 |   0.8386 |     26.756 |   1.0588 |     32.812 |     2.3
   21 |   0.8274 |     26.842 |   1.0496 |     32.567 |     2.4
   22 |   0.8058 |     25.878 |   1.0503 |     32.475 |     2.5
   23 |   0.7906 |     25.677 |   1.0408 |     32.261 |     2.6
   24 |   0.7783 |     25.190 |   1.0605 |     31.893 |     2.7
   25 |   0.7625 |     24.491 |   1.0659 |     33.180 |     2.8
   26 |   0.7501 |     24.263 |   1.0724 |     32.629 |     3.0
   27 |   0.7362 |     24.003 |   1.0504 |     31.036 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 155,938

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0044 |     50.921 |   1.4459 |     42.984 |     0.1
    2 |   1.3301 |     42.084 |   1.2246 |     38.450 |     0.2
    3 |   1.1699 |     37.516 |   1.1383 |     36.152 |     0.2
    4 |   1.0683 |     34.856 |   1.0416 |     34.252 |     0.3
    5 |   0.9826 |     32.255 |   1.0010 |     32.475 |     0.4
    6 |   0.9213 |     30.592 |   0.9337 |     30.515 |     0.5
    7 |   0.8617 |     28.614 |   0.9167 |     29.688 |     0.6
    8 |   0.8206 |     27.276 |   0.8941 |     29.565 |     0.6
    9 |   0.7706 |     25.580 |   0.9079 |     29.167 |     0.7
   10 |   0.7417 |     24.984 |   0.8505 |     27.788 |     0.8
   11 |   0.6971 |     23.423 |   0.8396 |     27.267 |     0.9
   12 |   0.6693 |     22.567 |   0.8367 |     27.451 |     0.9
   13 |   0.6426 |     21.646 |   0.8163 |     26.348 |     1.0
   14 |   0.6079 |     20.438 |   0.8256 |     26.348 |     1.1
   15 |   0.5903 |     20.140 |   0.8231 |     25.766 |     1.2
   16 |   0.5601 |     18.894 |   0.8004 |     25.521 |     1.3
   17 |   0.5438 |     18.579 |   0.7778 |     24.969 |     1.3
   18 |   0.5171 |     17.485 |   0.7904 |     24.418 |     1.4
   19 |   0.5045 |     17.328 |   0.7757 |     23.775 |     1.5
   20 |   0.4898 |     16.845 |   0.7790 |     23.928 |     1.6
   21 |   0.4740 |     16.667 |   0.7988 |     24.203 |     1.7
   22 |   0.4890 |     16.764 |   0.8020 |     24.786 |     1.7
   23 |   0.4515 |     15.903 |   0.8198 |     24.755 |     1.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 379,298

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8213 |     70.980 |   2.1407 |     50.276 |     0.1
    2 |   1.9981 |     48.445 |   1.6430 |     45.588 |     0.3
    3 |   1.6750 |     45.167 |   1.4947 |     43.536 |     0.4
    4 |   1.5339 |     44.013 |   1.3995 |     41.085 |     0.5
    5 |   1.4426 |     42.626 |   1.3401 |     40.564 |     0.7
    6 |   1.3804 |     41.358 |   1.2903 |     39.369 |     0.8
    7 |   1.3267 |     40.280 |   1.2539 |     38.940 |     0.9
    8 |   1.2794 |     39.169 |   1.2122 |     36.826 |     1.1
    9 |   1.2353 |     37.950 |   1.1866 |     36.458 |     1.2
   10 |   1.2026 |     37.094 |   1.1654 |     35.631 |     1.4
   11 |   1.1665 |     36.313 |   1.1402 |     35.325 |     1.5
   12 |   1.1387 |     35.354 |   1.1207 |     34.712 |     1.6
   13 |   1.1084 |     34.428 |   1.1112 |     34.835 |     1.8
   14 |   1.0805 |     33.718 |   1.0904 |     33.701 |     1.9
   15 |   1.0611 |     33.176 |   1.0755 |     33.915 |     2.0
   16 |   1.0353 |     32.412 |   1.0591 |     32.996 |     2.2
   17 |   1.0165 |     31.838 |   1.0448 |     32.659 |     2.3
   18 |   0.9916 |     30.955 |   1.0442 |     32.016 |     2.5
   19 |   0.9729 |     30.375 |   1.0317 |     32.016 |     2.6
   20 |   0.9539 |     29.763 |   1.0336 |     32.353 |     2.7
   21 |   0.9349 |     29.681 |   1.0168 |     31.066 |     2.9
   22 |   0.9153 |     28.782 |   1.0229 |     31.495 |     3.0
   23 |   0.9013 |     28.489 |   1.0106 |     31.893 |     3.1
   24 |   0.8832 |     27.823 |   1.0132 |     31.771 |     3.3
   25 |   0.8702 |     27.129 |   0.9994 |     31.648 |     3.4
   26 |   0.8570 |     26.718 |   0.9894 |     30.913 |     3.5
   27 |   0.8355 |     26.458 |   0.9851 |     30.147 |     3.7
   28 |   0.8225 |     25.916 |   0.9982 |     30.208 |     3.8
   29 |   0.8149 |     25.905 |   0.9820 |     29.841 |     4.0
   30 |   0.7991 |     25.591 |   0.9767 |     30.545 |     4.1
   31 |   0.7844 |     24.642 |   0.9747 |     29.626 |     4.2
   32 |   0.7715 |     24.626 |   0.9750 |     29.442 |     4.4
   33 |   0.7598 |     24.063 |   0.9902 |     31.066 |     4.5
   34 |   0.7541 |     24.144 |   0.9737 |     29.136 |     4.6
   35 |   0.7428 |     23.943 |   0.9625 |     29.473 |     4.8
   36 |   0.7274 |     22.735 |   0.9602 |     29.994 |     4.9
   37 |   0.7199 |     23.011 |   0.9614 |     29.167 |     5.0
   38 |   0.7081 |     22.665 |   0.9430 |     29.105 |     5.2
   39 |   0.6945 |     22.399 |   0.9549 |     28.830 |     5.3
   40 |   0.6870 |     22.307 |   0.9524 |     29.197 |     5.5
   41 |   0.6810 |     22.199 |   0.9665 |     27.819 |     5.6
   42 |   0.6660 |     21.570 |   0.9578 |     28.462 |     5.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 138,946

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1064 |     52.221 |   1.4649 |     44.240 |     0.1
    2 |   1.3962 |     43.265 |   1.2920 |     41.513 |     0.2
    3 |   1.2718 |     41.076 |   1.1966 |     39.154 |     0.2
    4 |   1.1946 |     39.223 |   1.1417 |     38.174 |     0.3
    5 |   1.1290 |     37.218 |   1.0846 |     35.417 |     0.4
    6 |   1.0779 |     35.327 |   1.0547 |     33.241 |     0.5
    7 |   1.0422 |     34.428 |   1.0212 |     33.517 |     0.5
    8 |   1.0042 |     33.090 |   1.0028 |     33.456 |     0.6
    9 |   0.9665 |     32.130 |   0.9823 |     32.966 |     0.7
   10 |   0.9408 |     31.274 |   0.9539 |     31.495 |     0.8
   11 |   0.9097 |     30.332 |   0.9548 |     32.598 |     0.8
   12 |   0.8868 |     29.611 |   0.9359 |     30.699 |     0.9
   13 |   0.8548 |     28.603 |   0.9262 |     30.239 |     1.0
   14 |   0.8313 |     28.148 |   0.9301 |     30.362 |     1.1
   15 |   0.8141 |     27.324 |   0.8935 |     28.952 |     1.1
   16 |   0.7843 |     26.544 |   0.8685 |     28.646 |     1.2
   17 |   0.7689 |     25.905 |   0.8734 |     29.596 |     1.3
   18 |   0.7511 |     25.542 |   0.8740 |     28.370 |     1.4
   19 |   0.7334 |     24.843 |   0.8735 |     28.339 |     1.4
   20 |   0.7132 |     24.008 |   0.8646 |     28.125 |     1.5
   21 |   0.6979 |     23.775 |   0.8652 |     28.309 |     1.6
   22 |   0.6870 |     23.624 |   0.8690 |     27.727 |     1.7
   23 |   0.6710 |     22.925 |   0.8514 |     27.911 |     1.7
   24 |   0.6717 |     23.093 |   0.8563 |     28.094 |     1.8
   25 |   0.6472 |     22.182 |   0.8479 |     27.022 |     1.9
   26 |   0.6215 |     21.321 |   0.8806 |     27.665 |     2.0
   27 |   0.6238 |     21.137 |   0.8633 |     27.145 |     2.1
   28 |   0.6152 |     20.866 |   0.8586 |     27.512 |     2.1
   29 |   0.6000 |     20.996 |   0.8736 |     26.593 |     2.2
   30 |   0.5838 |     20.259 |   0.8391 |     25.460 |     2.3
   31 |   0.5803 |     19.928 |   0.8635 |     26.042 |     2.4
   32 |   0.5669 |     19.706 |   0.8666 |     26.287 |     2.4
   33 |   0.5594 |     19.511 |   0.8708 |     26.440 |     2.5
   34 |   0.5620 |     19.463 |   0.8817 |     27.022 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 320,546

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8939 |     52.075 |   1.3478 |     42.923 |     0.1
    2 |   1.3324 |     42.989 |   1.2479 |     40.288 |     0.3
    3 |   1.2397 |     40.345 |   1.1558 |     37.806 |     0.4
    4 |   1.1738 |     38.605 |   1.1229 |     37.040 |     0.6
    5 |   1.1244 |     37.576 |   1.0985 |     35.662 |     0.7
    6 |   1.0769 |     35.772 |   1.0704 |     35.631 |     0.9
    7 |   1.0464 |     35.165 |   1.0371 |     35.141 |     1.0
    8 |   1.0111 |     33.940 |   0.9881 |     32.843 |     1.2
    9 |   0.9688 |     32.922 |   0.9863 |     32.659 |     1.4
   10 |   0.9439 |     31.832 |   0.9805 |     32.445 |     1.5
   11 |   0.9242 |     31.074 |   0.9562 |     31.127 |     1.7
   12 |   0.8916 |     29.979 |   0.9649 |     31.648 |     1.8
   13 |   0.8724 |     29.486 |   0.9447 |     31.036 |     2.0
   14 |   0.8439 |     28.533 |   0.9278 |     30.362 |     2.1
   15 |   0.8258 |     27.942 |   0.9506 |     30.607 |     2.3
   16 |   0.8023 |     27.216 |   0.9085 |     29.871 |     2.4
   17 |   0.7888 |     26.696 |   0.9213 |     29.596 |     2.6
   18 |   0.7665 |     25.639 |   0.9330 |     29.810 |     2.7
   19 |   0.7530 |     25.569 |   0.9426 |     29.657 |     2.9
   20 |   0.7298 |     24.854 |   0.9573 |     29.596 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 386,850

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6182 |     46.717 |   1.2515 |     39.338 |     0.1
    2 |   1.1629 |     37.939 |   1.0833 |     35.110 |     0.2
    3 |   1.0526 |     34.785 |   0.9948 |     33.150 |     0.4
    4 |   0.9434 |     31.274 |   0.9430 |     32.721 |     0.5
    5 |   0.8892 |     29.822 |   0.9096 |     31.005 |     0.6
    6 |   0.8240 |     27.861 |   0.8900 |     30.086 |     0.7
    7 |   0.7691 |     26.176 |   0.8335 |     28.676 |     0.8
    8 |   0.7169 |     24.344 |   0.8122 |     26.624 |     1.0
    9 |   0.6870 |     23.450 |   0.7967 |     26.685 |     1.1
   10 |   0.6531 |     22.318 |   0.8125 |     26.900 |     1.2
   11 |   0.6152 |     20.888 |   0.8066 |     26.777 |     1.3
   12 |   0.5923 |     20.313 |   0.7745 |     25.490 |     1.4
   13 |   0.5614 |     19.365 |   0.7530 |     23.928 |     1.6
   14 |   0.5190 |     17.891 |   0.7657 |     24.326 |     1.7
   15 |   0.5096 |     17.512 |   0.7654 |     24.265 |     1.8
   16 |   0.4888 |     16.981 |   0.7650 |     23.131 |     1.9
   17 |   0.5028 |     17.685 |   0.7571 |     24.112 |     2.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 469,154

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7042 |     48.635 |   1.3357 |     43.689 |     0.2
    2 |   1.3174 |     43.384 |   1.2268 |     40.533 |     0.3
    3 |   1.2325 |     40.989 |   1.1365 |     37.469 |     0.5
    4 |   1.1600 |     38.746 |   1.0809 |     35.631 |     0.6
    5 |   1.1124 |     37.392 |   1.0319 |     34.069 |     0.8
    6 |   1.0738 |     35.923 |   0.9934 |     33.333 |     0.9
    7 |   1.0295 |     34.666 |   0.9754 |     32.169 |     1.1
    8 |   0.9903 |     33.469 |   0.9616 |     32.108 |     1.3
    9 |   0.9648 |     32.689 |   0.9735 |     32.874 |     1.4
   10 |   0.9487 |     32.271 |   0.9172 |     31.097 |     1.6
   11 |   0.9051 |     30.873 |   0.9430 |     31.281 |     1.7
   12 |   0.8838 |     30.277 |   0.8958 |     29.442 |     1.9
   13 |   0.8563 |     28.961 |   0.8903 |     29.626 |     2.1
   14 |   0.8242 |     27.861 |   0.8948 |     29.841 |     2.2
   15 |   0.8097 |     27.476 |   0.8552 |     28.554 |     2.4
   16 |   0.7919 |     26.929 |   0.8722 |     28.830 |     2.5
   17 |   0.7743 |     26.122 |   0.8618 |     28.615 |     2.7
   18 |   0.7612 |     26.089 |   0.8583 |     28.431 |     2.8
   19 |   0.7425 |     25.433 |   0.8331 |     27.665 |     3.0
   20 |   0.7264 |     24.810 |   0.8292 |     27.727 |     3.2
   21 |   0.6947 |     23.808 |   0.8289 |     27.604 |     3.3
   22 |   0.6790 |     23.234 |   0.8557 |     26.930 |     3.5
   23 |   0.6586 |     22.405 |   0.8399 |     27.359 |     3.6
   24 |   0.6411 |     21.912 |   0.8037 |     25.735 |     3.8
   25 |   0.6375 |     21.874 |   0.8233 |     26.379 |     4.0
   26 |   0.6215 |     21.467 |   0.8180 |     26.471 |     4.1
   27 |   0.5953 |     20.145 |   0.8235 |     25.613 |     4.3
   28 |   0.5946 |     20.319 |   0.8411 |     26.716 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 404,514

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6115 |     62.365 |   1.9385 |     45.221 |     0.1
    2 |   1.7214 |     44.311 |   1.5643 |     42.402 |     0.3
    3 |   1.4936 |     41.883 |   1.4271 |     40.319 |     0.5
    4 |   1.3710 |     40.198 |   1.3382 |     39.185 |     0.6
    5 |   1.2834 |     38.649 |   1.2681 |     37.806 |     0.8
    6 |   1.2165 |     36.985 |   1.2310 |     36.703 |     0.9
    7 |   1.1615 |     35.241 |   1.1778 |     35.202 |     1.1
    8 |   1.1090 |     33.794 |   1.1313 |     33.977 |     1.2
    9 |   1.0560 |     32.228 |   1.0972 |     32.567 |     1.4
   10 |   1.0106 |     30.830 |   1.0673 |     32.598 |     1.5
   11 |   0.9692 |     29.627 |   1.0440 |     31.924 |     1.7
   12 |   0.9279 |     28.451 |   1.0234 |     31.342 |     1.8
   13 |   0.8968 |     27.249 |   1.0022 |     30.086 |     2.0
   14 |   0.8606 |     26.225 |   0.9910 |     30.729 |     2.2
   15 |   0.8318 |     25.255 |   0.9643 |     29.933 |     2.3
   16 |   0.7940 |     24.220 |   0.9473 |     29.963 |     2.5
   17 |   0.7741 |     23.472 |   0.9440 |     29.473 |     2.6
   18 |   0.7425 |     22.708 |   0.9425 |     28.860 |     2.8
   19 |   0.7158 |     21.744 |   0.9313 |     29.259 |     2.9
   20 |   0.6917 |     21.326 |   0.9143 |     29.136 |     3.1
   21 |   0.6697 |     20.503 |   0.9188 |     28.002 |     3.2
   22 |   0.6524 |     19.939 |   0.8958 |     27.022 |     3.4
   23 |   0.6334 |     19.403 |   0.9023 |     27.727 |     3.5
   24 |   0.6202 |     19.164 |   0.8817 |     27.512 |     3.7
   25 |   0.6059 |     18.612 |   0.8828 |     27.237 |     3.8
   26 |   0.5724 |     17.723 |   0.8802 |     26.869 |     4.0
   27 |   0.5625 |     17.252 |   0.8877 |     26.961 |     4.2
   28 |   0.5434 |     16.883 |   0.8812 |     26.287 |     4.3
   29 |   0.5304 |     16.558 |   0.8932 |     27.145 |     4.5
   30 |   0.5179 |     16.125 |   0.8696 |     25.521 |     4.6
   31 |   0.5083 |     15.789 |   0.8768 |     26.348 |     4.8
   32 |   0.4942 |     15.274 |   0.8815 |     25.950 |     4.9
   33 |   0.4792 |     15.242 |   0.8798 |     25.797 |     5.1
   34 |   0.4586 |     14.326 |   0.8889 |     26.134 |     5.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 435,938

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5874 |     46.267 |   1.2463 |     39.185 |     0.1
    2 |   1.1810 |     38.546 |   1.1223 |     36.550 |     0.1
    3 |   1.0435 |     34.162 |   1.0226 |     33.762 |     0.2
    4 |   0.9376 |     31.215 |   0.9221 |     30.423 |     0.3
    5 |   0.8588 |     28.722 |   0.9053 |     29.933 |     0.4
    6 |   0.7877 |     26.262 |   0.8623 |     28.186 |     0.4
    7 |   0.7413 |     25.173 |   0.8233 |     27.053 |     0.5
    8 |   0.6901 |     23.266 |   0.8258 |     27.267 |     0.6
    9 |   0.6601 |     22.350 |   0.7993 |     26.225 |     0.6
   10 |   0.6044 |     20.308 |   0.7818 |     25.000 |     0.7
   11 |   0.5668 |     19.062 |   0.7740 |     24.908 |     0.8
   12 |   0.5443 |     18.476 |   0.7618 |     23.805 |     0.9
   13 |   0.5095 |     17.528 |   0.7695 |     23.407 |     0.9
   14 |   0.4933 |     16.705 |   0.7496 |     23.683 |     1.0
   15 |   0.4609 |     16.000 |   0.7547 |     23.499 |     1.1
   16 |   0.4592 |     15.881 |   0.7698 |     23.376 |     1.1
   17 |   0.4129 |     14.310 |   0.7816 |     23.958 |     1.2
   18 |   0.3891 |     13.519 |   0.7530 |     22.426 |     1.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 152,354

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3416 |     61.210 |   1.5261 |     44.945 |     0.1
    2 |   1.4871 |     45.357 |   1.3639 |     43.382 |     0.2
    3 |   1.3683 |     43.487 |   1.2884 |     41.422 |     0.3
    4 |   1.2953 |     42.236 |   1.2302 |     39.308 |     0.4
    5 |   1.2412 |     40.740 |   1.1966 |     38.021 |     0.5
    6 |   1.2001 |     39.662 |   1.1655 |     37.806 |     0.6
    7 |   1.1622 |     38.199 |   1.1474 |     37.194 |     0.7
    8 |   1.1275 |     37.484 |   1.1235 |     36.642 |     0.9
    9 |   1.0915 |     36.671 |   1.1230 |     36.703 |     1.0
   10 |   1.0563 |     35.463 |   1.1029 |     35.539 |     1.1
   11 |   1.0348 |     34.823 |   1.0766 |     34.651 |     1.2
   12 |   1.0160 |     34.282 |   1.0870 |     35.294 |     1.3
   13 |   0.9845 |     32.965 |   1.0623 |     34.620 |     1.4
   14 |   0.9659 |     32.472 |   1.0538 |     34.007 |     1.5
   15 |   0.9404 |     31.784 |   1.0491 |     33.977 |     1.6
   16 |   0.9195 |     30.836 |   1.0407 |     33.487 |     1.7
   17 |   0.9061 |     30.575 |   1.0252 |     32.384 |     1.8
   18 |   0.8780 |     29.600 |   1.0152 |     32.567 |     1.9
   19 |   0.8571 |     28.798 |   1.0405 |     32.690 |     2.0
   20 |   0.8438 |     28.549 |   1.0462 |     32.812 |     2.1
   21 |   0.8341 |     28.262 |   1.0263 |     31.618 |     2.2
   22 |   0.8130 |     27.850 |   1.0616 |     32.904 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 205,858

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1050 |     53.820 |   1.4863 |     45.558 |     0.1
    2 |   1.4358 |     44.777 |   1.3049 |     42.004 |     0.2
    3 |   1.3170 |     42.978 |   1.2400 |     40.809 |     0.3
    4 |   1.2432 |     41.174 |   1.1718 |     38.388 |     0.3
    5 |   1.1856 |     39.283 |   1.1195 |     36.765 |     0.4
    6 |   1.1434 |     38.551 |   1.0962 |     36.213 |     0.5
    7 |   1.0996 |     36.519 |   1.0509 |     34.130 |     0.6
    8 |   1.0717 |     35.967 |   1.0393 |     35.018 |     0.7
    9 |   1.0343 |     34.742 |   1.0019 |     33.303 |     0.8
   10 |   1.0036 |     33.621 |   0.9946 |     33.548 |     0.9
   11 |   0.9725 |     33.073 |   0.9749 |     32.445 |     1.0
   12 |   0.9577 |     32.531 |   0.9781 |     33.211 |     1.0
   13 |   0.9195 |     31.134 |   0.9481 |     31.801 |     1.1
   14 |   0.9017 |     30.483 |   0.9405 |     31.955 |     1.2
   15 |   0.8804 |     30.017 |   0.9347 |     30.882 |     1.3
   16 |   0.8515 |     28.917 |   0.9123 |     29.902 |     1.4
   17 |   0.8355 |     28.533 |   0.9080 |     30.668 |     1.5
   18 |   0.8346 |     28.451 |   0.9270 |     31.219 |     1.6
   19 |   0.8053 |     27.287 |   0.9022 |     30.208 |     1.6
   20 |   0.7819 |     26.317 |   0.9402 |     31.005 |     1.7
   21 |   0.7721 |     25.937 |   0.8674 |     28.554 |     1.8
   22 |   0.7443 |     25.173 |   0.8935 |     29.749 |     1.9
   23 |   0.7227 |     24.610 |   0.8715 |     28.860 |     2.0
   24 |   0.7185 |     24.702 |   0.8967 |     29.167 |     2.1
   25 |   0.6958 |     23.678 |   0.8971 |     28.217 |     2.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 126,690

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0418 |     51.685 |   1.4444 |     43.290 |     0.1
    2 |   1.3505 |     42.501 |   1.2705 |     41.360 |     0.2
    3 |   1.2128 |     39.142 |   1.1681 |     37.960 |     0.3
    4 |   1.1372 |     37.251 |   1.1180 |     36.366 |     0.3
    5 |   1.0631 |     34.991 |   1.0567 |     34.344 |     0.4
    6 |   1.0101 |     33.550 |   1.0258 |     34.161 |     0.5
    7 |   0.9515 |     31.897 |   0.9815 |     32.659 |     0.6
    8 |   0.9117 |     30.380 |   0.9792 |     32.108 |     0.7
    9 |   0.8757 |     29.703 |   0.9677 |     32.537 |     0.8
   10 |   0.8373 |     28.056 |   0.9231 |     30.607 |     0.8
   11 |   0.8070 |     27.194 |   0.9179 |     30.178 |     0.9
   12 |   0.7723 |     26.013 |   0.8916 |     29.167 |     1.0
   13 |   0.7537 |     25.076 |   0.8874 |     28.646 |     1.1
   14 |   0.7422 |     24.810 |   0.8719 |     28.064 |     1.2
   15 |   0.7019 |     23.483 |   0.8717 |     27.819 |     1.3
   16 |   0.6797 |     22.502 |   0.8846 |     28.707 |     1.3
   17 |   0.6643 |     22.107 |   0.8743 |     27.420 |     1.4
   18 |   0.6402 |     21.744 |   0.8349 |     27.022 |     1.5
   19 |   0.6189 |     21.121 |   0.8569 |     27.359 |     1.6
   20 |   0.5972 |     20.059 |   0.8564 |     27.114 |     1.7
   21 |   0.5920 |     20.069 |   0.8257 |     25.613 |     1.8
   22 |   0.5812 |     19.300 |   0.8333 |     25.919 |     1.9
   23 |   0.5576 |     18.845 |   0.8421 |     26.501 |     1.9
   24 |   0.5376 |     18.086 |   0.8533 |     26.225 |     2.0
   25 |   0.5328 |     18.086 |   0.8499 |     25.429 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,642

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1503 |     55.770 |   1.4603 |     43.505 |     0.2
    2 |   1.4583 |     44.381 |   1.3165 |     41.452 |     0.3
    3 |   1.3240 |     41.363 |   1.2258 |     38.664 |     0.5
    4 |   1.2283 |     38.470 |   1.1440 |     35.447 |     0.7
    5 |   1.1544 |     36.178 |   1.1059 |     34.988 |     0.8
    6 |   1.0850 |     34.065 |   1.0623 |     33.640 |     1.0
    7 |   1.0240 |     32.347 |   1.0185 |     32.874 |     1.2
    8 |   0.9733 |     30.630 |   0.9799 |     30.974 |     1.3
    9 |   0.9246 |     29.259 |   0.9618 |     30.239 |     1.5
   10 |   0.8794 |     27.893 |   0.9440 |     29.994 |     1.7
   11 |   0.8437 |     26.642 |   0.9265 |     29.534 |     1.8
   12 |   0.8088 |     25.959 |   0.8956 |     28.064 |     2.0
   13 |   0.7723 |     24.902 |   0.9034 |     28.523 |     2.2
   14 |   0.7559 |     23.889 |   0.8771 |     27.911 |     2.3
   15 |   0.7143 |     22.936 |   0.8719 |     27.328 |     2.5
   16 |   0.6862 |     22.350 |   0.8628 |     26.961 |     2.7
   17 |   0.6604 |     21.494 |   0.8647 |     26.348 |     2.8
   18 |   0.6382 |     20.801 |   0.8891 |     26.808 |     3.0
   19 |   0.6101 |     19.658 |   0.8603 |     26.072 |     3.2
   20 |   0.5903 |     19.289 |   0.8510 |     25.551 |     3.3
   21 |   0.5640 |     18.428 |   0.8896 |     26.716 |     3.5
   22 |   0.5521 |     17.864 |   0.8637 |     25.490 |     3.7
   23 |   0.5293 |     17.322 |   0.8650 |     25.460 |     3.8
   24 |   0.5182 |     17.084 |   0.8521 |     24.877 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,472,162

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4704 |     63.681 |   1.5872 |     45.067 |     0.1
    2 |   1.5851 |     45.031 |   1.3612 |     42.034 |     0.3
    3 |   1.4176 |     43.292 |   1.2812 |     39.982 |     0.4
    4 |   1.3316 |     41.320 |   1.2174 |     37.837 |     0.5
    5 |   1.2681 |     40.036 |   1.1657 |     36.826 |     0.7
    6 |   1.2043 |     37.982 |   1.1320 |     35.570 |     0.8
    7 |   1.1635 |     36.438 |   1.0981 |     34.559 |     1.0
    8 |   1.1115 |     34.980 |   1.0714 |     34.467 |     1.1
    9 |   1.0696 |     33.783 |   1.0448 |     32.812 |     1.2
   10 |   1.0338 |     32.754 |   1.0272 |     32.782 |     1.4
   11 |   1.0001 |     31.616 |   1.0122 |     31.373 |     1.5
   12 |   0.9702 |     30.554 |   0.9976 |     31.281 |     1.7
   13 |   0.9357 |     29.557 |   0.9849 |     31.250 |     1.8
   14 |   0.9040 |     28.804 |   0.9564 |     30.208 |     1.9
   15 |   0.8765 |     27.704 |   0.9624 |     30.270 |     2.1
   16 |   0.8492 |     27.270 |   0.9567 |     30.086 |     2.2
   17 |   0.8251 |     26.409 |   0.9504 |     29.105 |     2.3
   18 |   0.7979 |     25.287 |   0.9524 |     29.320 |     2.5
   19 |   0.7816 |     25.260 |   0.9453 |     29.381 |     2.6
   20 |   0.7517 |     24.149 |   0.9349 |     28.278 |     2.8
   21 |   0.7364 |     23.949 |   0.9365 |     28.278 |     2.9
   22 |   0.7121 |     23.028 |   0.9400 |     28.064 |     3.0
   23 |   0.6967 |     22.307 |   0.9361 |     27.604 |     3.2
   24 |   0.6799 |     21.917 |   0.9598 |     28.523 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,126,754

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5500 |     47.063 |   1.2099 |     41.054 |     0.1
    2 |   1.1609 |     38.979 |   1.0886 |     36.366 |     0.3
    3 |   1.0526 |     35.631 |   1.0140 |     35.325 |     0.5
    4 |   0.9627 |     32.808 |   0.9754 |     33.364 |     0.6
    5 |   0.9041 |     30.445 |   0.9270 |     31.097 |     0.8
    6 |   0.8595 |     29.503 |   0.9237 |     31.036 |     0.9
    7 |   0.8156 |     27.996 |   0.8798 |     29.994 |     1.1
    8 |   0.7694 |     26.403 |   0.8683 |     29.259 |     1.2
    9 |   0.7407 |     25.314 |   0.8486 |     27.665 |     1.4
   10 |   0.7174 |     24.642 |   0.8200 |     26.777 |     1.5
   11 |   0.6829 |     23.748 |   0.8212 |     27.849 |     1.7
   12 |   0.6670 |     22.990 |   0.8184 |     26.501 |     1.8
   13 |   0.6457 |     22.275 |   0.8238 |     27.482 |     2.0
   14 |   0.6447 |     22.405 |   0.7924 |     25.490 |     2.1
   15 |   0.5952 |     20.741 |   0.7927 |     25.551 |     2.3
   16 |   0.5833 |     20.259 |   0.7734 |     24.939 |     2.4
   17 |   0.5626 |     19.679 |   0.8051 |     25.460 |     2.6
   18 |   0.5548 |     19.397 |   0.7740 |     24.112 |     2.7
   19 |   0.5288 |     18.460 |   0.7721 |     24.265 |     2.9
   20 |   0.5192 |     18.476 |   0.7758 |     23.866 |     3.0
   21 |   0.4940 |     17.534 |   0.7497 |     23.897 |     3.2
   22 |   0.4862 |     17.165 |   0.7354 |     23.897 |     3.3
   23 |   0.4869 |     17.084 |   0.7611 |     24.020 |     3.5
   24 |   0.4710 |     16.645 |   0.7630 |     22.917 |     3.6
   25 |   0.4620 |     16.157 |   0.8050 |     23.805 |     3.8
   26 |   0.4598 |     16.114 |   0.7573 |     23.560 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 172,930

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.1628 |     83.008 |   2.8132 |     65.288 |     0.1
    2 |   2.7281 |     63.654 |   2.3492 |     49.203 |     0.2
    3 |   2.3309 |     50.607 |   1.9712 |     47.763 |     0.3
    4 |   2.0230 |     47.036 |   1.7621 |     44.271 |     0.4
    5 |   1.8318 |     45.980 |   1.6495 |     44.056 |     0.5
    6 |   1.7194 |     45.416 |   1.5810 |     44.363 |     0.6
    7 |   1.6380 |     45.134 |   1.5277 |     44.271 |     0.6
    8 |   1.5877 |     45.075 |   1.4828 |     44.118 |     0.7
    9 |   1.5382 |     44.674 |   1.4448 |     42.984 |     0.8
   10 |   1.5022 |     44.208 |   1.4125 |     42.034 |     0.9
   11 |   1.4626 |     43.899 |   1.3849 |     41.360 |     1.0
   12 |   1.4281 |     43.314 |   1.3581 |     40.319 |     1.1
   13 |   1.4034 |     42.637 |   1.3377 |     40.135 |     1.2
   14 |   1.3754 |     41.818 |   1.3290 |     40.104 |     1.3
   15 |   1.3486 |     41.488 |   1.3045 |     39.369 |     1.4
   16 |   1.3270 |     40.561 |   1.2948 |     39.185 |     1.5
   17 |   1.3091 |     40.323 |   1.2810 |     38.572 |     1.6
   18 |   1.2830 |     39.727 |   1.2640 |     38.143 |     1.7
   19 |   1.2640 |     39.044 |   1.2561 |     37.714 |     1.8
   20 |   1.2495 |     38.909 |   1.2463 |     37.316 |     1.8
   21 |   1.2254 |     37.885 |   1.2446 |     37.347 |     1.9
   22 |   1.2074 |     37.749 |   1.2419 |     37.010 |     2.0
   23 |   1.1909 |     37.240 |   1.2304 |     37.071 |     2.1
   24 |   1.1751 |     36.606 |   1.2221 |     36.918 |     2.2
   25 |   1.1605 |     36.162 |   1.2039 |     37.010 |     2.3
   26 |   1.1473 |     35.669 |   1.2059 |     37.316 |     2.4
   27 |   1.1361 |     35.062 |   1.2006 |     35.968 |     2.5
   28 |   1.1202 |     35.170 |   1.1915 |     35.539 |     2.6
   29 |   1.1043 |     34.563 |   1.1937 |     35.999 |     2.7
   30 |   1.0942 |     34.086 |   1.1900 |     35.662 |     2.8
   31 |   1.0805 |     33.545 |   1.1968 |     36.826 |     2.9
   32 |   1.0750 |     33.875 |   1.1906 |     36.275 |     2.9
   33 |   1.0601 |     33.127 |   1.1825 |     36.060 |     3.0
   34 |   1.0507 |     32.878 |   1.1717 |     35.355 |     3.1
   35 |   1.0456 |     32.743 |   1.1994 |     36.734 |     3.2
   36 |   1.0319 |     32.542 |   1.1906 |     36.366 |     3.3
   37 |   1.0195 |     32.363 |   1.1900 |     35.723 |     3.4
   38 |   1.0192 |     32.271 |   1.1838 |     35.662 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 744,738

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2123 |     54.102 |   1.5652 |     44.210 |     0.1
    2 |   1.4293 |     42.127 |   1.3300 |     40.104 |     0.2
    3 |   1.2660 |     38.367 |   1.2369 |     37.990 |     0.3
    4 |   1.1654 |     35.669 |   1.1693 |     35.539 |     0.4
    5 |   1.0921 |     33.984 |   1.1112 |     34.467 |     0.5
    6 |   1.0328 |     32.374 |   1.0692 |     33.548 |     0.6
    7 |   0.9797 |     30.678 |   1.0250 |     32.322 |     0.7
    8 |   0.9331 |     29.140 |   1.0134 |     32.016 |     0.8
    9 |   0.8857 |     27.866 |   0.9858 |     31.066 |     0.9
   10 |   0.8434 |     26.376 |   0.9504 |     29.504 |     1.0
   11 |   0.8066 |     25.526 |   0.9247 |     29.779 |     1.1
   12 |   0.7754 |     24.269 |   0.9211 |     29.963 |     1.2
   13 |   0.7436 |     23.488 |   0.9094 |     28.401 |     1.3
   14 |   0.7148 |     22.437 |   0.8991 |     28.217 |     1.4
   15 |   0.6825 |     21.700 |   0.8778 |     27.604 |     1.5
   16 |   0.6567 |     20.698 |   0.8807 |     27.420 |     1.6
   17 |   0.6302 |     19.565 |   0.8756 |     27.053 |     1.7
   18 |   0.6098 |     19.484 |   0.8501 |     26.379 |     1.8
   19 |   0.5777 |     18.140 |   0.8541 |     26.409 |     1.9
   20 |   0.5652 |     17.739 |   0.8412 |     24.939 |     2.0
   21 |   0.5391 |     17.024 |   0.8525 |     26.072 |     2.1
   22 |   0.5159 |     16.184 |   0.8546 |     25.797 |     2.2
   23 |   0.5031 |     15.805 |   0.8371 |     24.969 |     2.3
   24 |   0.4879 |     15.209 |   0.8503 |     24.969 |     2.4
   25 |   0.4685 |     14.749 |   0.8470 |     24.939 |     2.5
   26 |   0.4493 |     14.174 |   0.8640 |     24.847 |     2.6
   27 |   0.4386 |     13.979 |   0.8502 |     24.816 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 139,522

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9344 |     50.363 |   1.4472 |     44.271 |     0.1
    2 |   1.3552 |     42.886 |   1.2943 |     41.268 |     0.3
    3 |   1.2161 |     39.331 |   1.1659 |     37.960 |     0.4
    4 |   1.1114 |     36.221 |   1.0863 |     35.355 |     0.5
    5 |   1.0350 |     33.702 |   1.0432 |     34.314 |     0.7
    6 |   0.9746 |     32.412 |   0.9703 |     32.322 |     0.8
    7 |   0.9243 |     30.733 |   0.9617 |     31.924 |     0.9
    8 |   0.8732 |     29.010 |   0.9325 |     31.281 |     1.1
    9 |   0.8265 |     27.482 |   0.9249 |     30.392 |     1.2
   10 |   0.7953 |     26.414 |   0.9435 |     30.545 |     1.3
   11 |   0.7523 |     25.098 |   0.8799 |     28.309 |     1.5
   12 |   0.7259 |     24.436 |   0.9055 |     29.596 |     1.6
   13 |   0.7114 |     23.645 |   0.8557 |     27.267 |     1.7
   14 |   0.6723 |     22.768 |   0.8493 |     27.574 |     1.9
   15 |   0.6490 |     22.025 |   0.8377 |     26.225 |     2.0
   16 |   0.6240 |     20.958 |   0.8458 |     25.950 |     2.1
   17 |   0.6064 |     20.595 |   0.8272 |     26.195 |     2.3
   18 |   0.5900 |     20.069 |   0.8343 |     25.919 |     2.4
   19 |   0.5733 |     19.495 |   0.8214 |     25.276 |     2.5
   20 |   0.5484 |     18.541 |   0.8334 |     25.888 |     2.6
   21 |   0.5364 |     18.466 |   0.8121 |     24.847 |     2.8
   22 |   0.5373 |     18.428 |   0.8308 |     25.766 |     2.9
   23 |   0.5180 |     17.761 |   0.8358 |     25.153 |     3.0
   24 |   0.4918 |     16.916 |   0.8326 |     24.786 |     3.2
   25 |   0.4823 |     16.661 |   0.8450 |     24.908 |     3.3
   26 |   0.4641 |     15.865 |   0.8118 |     23.928 |     3.4
   27 |   0.4428 |     15.431 |   0.8477 |     24.571 |     3.6
   28 |   0.4413 |     14.857 |   0.8473 |     24.357 |     3.7
   29 |   0.4319 |     15.393 |   0.8480 |     23.683 |     3.8
   30 |   0.4203 |     14.564 |   0.8530 |     24.387 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 270,114

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7034 |     65.399 |   2.1549 |     48.376 |     0.1
    2 |   1.8419 |     45.270 |   1.6312 |     42.678 |     0.2
    3 |   1.5334 |     43.086 |   1.4627 |     41.207 |     0.2
    4 |   1.4029 |     41.033 |   1.3616 |     39.614 |     0.3
    5 |   1.3185 |     39.651 |   1.2936 |     38.634 |     0.4
    6 |   1.2529 |     37.625 |   1.2438 |     36.857 |     0.5
    7 |   1.1956 |     36.292 |   1.2068 |     35.999 |     0.6
    8 |   1.1491 |     35.100 |   1.1707 |     35.172 |     0.7
    9 |   1.1040 |     33.826 |   1.1434 |     34.926 |     0.7
   10 |   1.0724 |     33.127 |   1.1131 |     33.977 |     0.8
   11 |   1.0335 |     32.011 |   1.0922 |     33.150 |     0.9
   12 |   1.0114 |     31.188 |   1.0848 |     33.548 |     1.0
   13 |   0.9784 |     30.321 |   1.0521 |     33.058 |     1.1
   14 |   0.9435 |     29.443 |   1.0367 |     32.445 |     1.2
   15 |   0.9145 |     28.619 |   1.0177 |     31.648 |     1.2
   16 |   0.8876 |     27.742 |   1.0160 |     32.108 |     1.3
   17 |   0.8638 |     27.276 |   1.0025 |     31.158 |     1.4
   18 |   0.8408 |     26.430 |   0.9809 |     30.913 |     1.5
   19 |   0.8157 |     25.564 |   0.9846 |     30.882 |     1.6
   20 |   0.7966 |     25.184 |   0.9759 |     30.699 |     1.7
   21 |   0.7783 |     24.431 |   0.9671 |     30.453 |     1.7
   22 |   0.7598 |     24.052 |   0.9527 |     29.289 |     1.8
   23 |   0.7365 |     23.147 |   0.9462 |     29.442 |     1.9
   24 |   0.7144 |     22.594 |   0.9361 |     29.075 |     2.0
   25 |   0.7006 |     21.787 |   0.9317 |     29.473 |     2.1
   26 |   0.6842 |     21.484 |   0.9281 |     28.585 |     2.1
   27 |   0.6647 |     20.882 |   0.9235 |     28.431 |     2.2
   28 |   0.6443 |     20.237 |   0.9345 |     28.799 |     2.3
   29 |   0.6347 |     19.836 |   0.9264 |     28.064 |     2.4
   30 |   0.6178 |     19.484 |   0.9134 |     27.941 |     2.5
   31 |   0.6065 |     18.872 |   0.9048 |     27.328 |     2.6
   32 |   0.5922 |     18.536 |   0.9064 |     27.696 |     2.6
   33 |   0.5826 |     18.216 |   0.9038 |     27.451 |     2.7
   34 |   0.5654 |     17.750 |   0.9077 |     27.604 |     2.8
   35 |   0.5588 |     17.382 |   0.9009 |     26.930 |     2.9
   36 |   0.5464 |     17.143 |   0.9377 |     27.696 |     3.0
   37 |   0.5318 |     16.520 |   0.8986 |     26.317 |     3.1
   38 |   0.5199 |     16.428 |   0.9077 |     26.746 |     3.1
   39 |   0.5149 |     16.401 |   0.9135 |     26.256 |     3.2
   40 |   0.5046 |     15.762 |   0.9248 |     26.072 |     3.3
   41 |   0.4898 |     15.469 |   0.9145 |     26.256 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,339,682

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4782 |     63.058 |   1.6217 |     46.415 |     0.1
    2 |   1.5987 |     45.584 |   1.3625 |     42.096 |     0.3
    3 |   1.4136 |     43.314 |   1.2771 |     40.165 |     0.4
    4 |   1.3214 |     40.957 |   1.2016 |     38.113 |     0.5
    5 |   1.2517 |     39.228 |   1.1578 |     37.010 |     0.7
    6 |   1.2015 |     38.237 |   1.1165 |     35.968 |     0.8
    7 |   1.1558 |     36.492 |   1.0850 |     34.099 |     0.9
    8 |   1.1186 |     35.414 |   1.0666 |     34.222 |     1.0
    9 |   1.0760 |     33.870 |   1.0543 |     33.732 |     1.2
   10 |   1.0414 |     33.035 |   1.0229 |     32.598 |     1.3
   11 |   1.0180 |     32.201 |   1.0037 |     32.996 |     1.4
   12 |   0.9845 |     30.944 |   0.9945 |     32.200 |     1.6
   13 |   0.9553 |     30.272 |   0.9759 |     31.526 |     1.7
   14 |   0.9235 |     29.589 |   0.9625 |     31.740 |     1.8
   15 |   0.8973 |     28.354 |   0.9619 |     30.944 |     2.0
   16 |   0.8760 |     27.899 |   0.9406 |     30.270 |     2.1
   17 |   0.8449 |     26.994 |   0.9436 |     30.515 |     2.2
   18 |   0.8290 |     26.848 |   0.9220 |     29.197 |     2.4
   19 |   0.8083 |     26.214 |   0.9238 |     29.289 |     2.5
   20 |   0.7846 |     25.748 |   0.9272 |     28.401 |     2.6
   21 |   0.7598 |     24.388 |   0.9031 |     28.401 |     2.8
   22 |   0.7461 |     24.285 |   0.9075 |     28.646 |     2.9
   23 |   0.7280 |     23.857 |   0.9039 |     27.849 |     3.0
   24 |   0.7111 |     22.898 |   0.9056 |     28.064 |     3.2
   25 |   0.6943 |     22.751 |   0.9021 |     27.880 |     3.3
   26 |   0.6723 |     21.836 |   0.8971 |     27.390 |     3.4
   27 |   0.6589 |     21.901 |   0.9034 |     26.869 |     3.5
   28 |   0.6478 |     21.142 |   0.9153 |     27.512 |     3.7
   29 |   0.6351 |     20.763 |   0.9173 |     27.114 |     3.8
   30 |   0.6236 |     20.454 |   0.9158 |     26.838 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 469,154

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5769 |     45.703 |   1.2481 |     39.614 |     0.1
    2 |   1.1895 |     38.844 |   1.1153 |     36.949 |     0.3
    3 |   1.0789 |     36.384 |   1.0450 |     34.988 |     0.4
    4 |   0.9925 |     33.436 |   0.9980 |     32.996 |     0.6
    5 |   0.9324 |     31.860 |   0.9476 |     32.353 |     0.7
    6 |   0.8778 |     29.947 |   0.8987 |     29.902 |     0.9
    7 |   0.8359 |     28.571 |   0.8811 |     30.392 |     1.0
    8 |   0.7852 |     26.756 |   0.8526 |     28.033 |     1.2
    9 |   0.7500 |     25.564 |   0.8411 |     28.033 |     1.3
   10 |   0.7220 |     24.529 |   0.8398 |     27.451 |     1.5
   11 |   0.6883 |     23.803 |   0.8076 |     27.083 |     1.6
   12 |   0.6554 |     22.513 |   0.7952 |     26.317 |     1.7
   13 |   0.6306 |     21.538 |   0.7892 |     25.919 |     1.9
   14 |   0.6095 |     21.072 |   0.7892 |     25.613 |     2.0
   15 |   0.5662 |     19.766 |   0.7731 |     25.521 |     2.2
   16 |   0.5465 |     19.002 |   0.7896 |     25.000 |     2.3
   17 |   0.5247 |     18.303 |   0.7807 |     24.786 |     2.5
   18 |   0.5459 |     19.034 |   0.7777 |     23.683 |     2.6
   19 |   0.4856 |     16.938 |   0.7664 |     23.162 |     2.8
   20 |   0.4636 |     16.244 |   0.7826 |     24.020 |     2.9
   21 |   0.4499 |     15.762 |   0.7676 |     23.621 |     3.1
   22 |   0.4276 |     14.889 |   0.7828 |     23.284 |     3.2
   23 |   0.4462 |     15.616 |   0.7696 |     22.855 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 152,354

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.2468 |     86.048 |   2.9747 |     81.679 |     0.1
    2 |   2.8736 |     69.175 |   2.5277 |     53.983 |     0.2
    3 |   2.4917 |     55.603 |   2.2054 |     53.768 |     0.3
    4 |   2.2163 |     53.018 |   1.9701 |     52.819 |     0.4
    5 |   1.9899 |     50.439 |   1.7900 |     47.457 |     0.5
    6 |   1.8231 |     47.546 |   1.6798 |     45.772 |     0.6
    7 |   1.7041 |     45.996 |   1.6103 |     44.577 |     0.7
    8 |   1.6268 |     45.118 |   1.5652 |     43.566 |     0.9
    9 |   1.5691 |     44.820 |   1.5402 |     42.739 |     1.0
   10 |   1.5256 |     44.305 |   1.5035 |     42.249 |     1.1
   11 |   1.4839 |     43.319 |   1.4924 |     41.667 |     1.2
   12 |   1.4500 |     43.054 |   1.4675 |     41.881 |     1.3
   13 |   1.4212 |     42.328 |   1.4511 |     40.441 |     1.4
   14 |   1.3973 |     42.051 |   1.4350 |     40.931 |     1.5
   15 |   1.3676 |     41.466 |   1.4229 |     40.625 |     1.6
   16 |   1.3506 |     41.125 |   1.4212 |     41.238 |     1.7
   17 |   1.3309 |     41.163 |   1.4217 |     40.993 |     1.8
   18 |   1.3114 |     40.513 |   1.4269 |     40.748 |     1.9
   19 |   1.2955 |     40.112 |   1.4080 |     39.828 |     2.0
   20 |   1.2719 |     39.586 |   1.4146 |     41.422 |     2.1
   21 |   1.2586 |     39.331 |   1.4002 |     40.901 |     2.2
   22 |   1.2460 |     39.066 |   1.3870 |     40.319 |     2.4
   23 |   1.2299 |     38.811 |   1.4178 |     41.085 |     2.5
   24 |   1.2126 |     38.183 |   1.4199 |     41.483 |     2.6
   25 |   1.2027 |     37.961 |   1.4046 |     41.207 |     2.7
   26 |   1.1922 |     37.657 |   1.4167 |     41.238 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7713 |     50.759 |   1.3393 |     41.085 |     0.2
    2 |   1.2990 |     42.582 |   1.2213 |     41.544 |     0.3
    3 |   1.2044 |     40.269 |   1.1316 |     37.653 |     0.5
    4 |   1.1350 |     38.405 |   1.0836 |     37.010 |     0.7
    5 |   1.0782 |     36.704 |   1.0257 |     33.854 |     0.8
    6 |   1.0282 |     35.138 |   1.0041 |     33.762 |     1.0
    7 |   0.9915 |     33.577 |   0.9698 |     32.537 |     1.2
    8 |   0.9573 |     32.103 |   0.9247 |     30.576 |     1.3
    9 |   0.9201 |     31.231 |   0.9112 |     30.974 |     1.5
   10 |   0.8785 |     29.513 |   0.9192 |     31.281 |     1.7
   11 |   0.8587 |     29.286 |   0.8964 |     30.300 |     1.9
   12 |   0.8164 |     27.969 |   0.8673 |     28.891 |     2.0
   13 |   0.7990 |     27.395 |   0.8572 |     28.646 |     2.2
   14 |   0.7696 |     26.425 |   0.8325 |     27.267 |     2.4
   15 |   0.7391 |     25.276 |   0.8617 |     28.125 |     2.5
   16 |   0.7272 |     25.060 |   0.8485 |     27.420 |     2.7
   17 |   0.6963 |     23.916 |   0.8273 |     26.869 |     2.9
   18 |   0.6915 |     23.792 |   0.8116 |     27.022 |     3.0
   19 |   0.6417 |     22.031 |   0.8408 |     27.053 |     3.2
   20 |   0.6437 |     22.155 |   0.8040 |     25.184 |     3.4
   21 |   0.6199 |     21.186 |   0.7964 |     24.816 |     3.5
   22 |   0.6088 |     20.936 |   0.8009 |     25.184 |     3.7
   23 |   0.5881 |     20.221 |   0.8023 |     25.368 |     3.9
   24 |   0.5628 |     19.685 |   0.7909 |     24.632 |     4.0
   25 |   0.5453 |     18.937 |   0.8100 |     25.214 |     4.2
   26 |   0.5492 |     19.099 |   0.8085 |     24.786 |     4.4
   27 |   0.5309 |     18.644 |   0.8086 |     24.908 |     4.6
   28 |   0.5376 |     18.568 |   0.8072 |     25.306 |     4.7
   29 |   0.5290 |     18.774 |   0.7905 |     24.755 |     4.9
   30 |   0.5000 |     17.566 |   0.8151 |     24.449 |     5.1
   31 |   0.4814 |     16.732 |   0.8183 |     24.112 |     5.2
   32 |   0.4795 |     16.710 |   0.8263 |     24.755 |     5.4
   33 |   0.4459 |     15.735 |   0.8229 |     24.265 |     5.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 139,522

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.0752 |     82.754 |   2.7194 |     58.517 |     0.1
    2 |   2.5717 |     57.217 |   2.2229 |     47.304 |     0.2
    3 |   2.1835 |     47.930 |   1.9126 |     45.282 |     0.3
    4 |   1.9312 |     46.261 |   1.7420 |     45.067 |     0.4
    5 |   1.7770 |     45.844 |   1.6344 |     44.945 |     0.5
    6 |   1.6765 |     45.432 |   1.5642 |     44.485 |     0.6
    7 |   1.6001 |     45.151 |   1.5055 |     43.964 |     0.7
    8 |   1.5433 |     44.582 |   1.4580 |     43.658 |     0.8
    9 |   1.4921 |     43.801 |   1.4186 |     43.015 |     0.9
   10 |   1.4556 |     43.308 |   1.3819 |     40.962 |     1.0
   11 |   1.4160 |     42.604 |   1.3558 |     40.564 |     1.1
   12 |   1.3835 |     41.715 |   1.3265 |     39.767 |     1.2
   13 |   1.3603 |     41.168 |   1.3069 |     39.277 |     1.3
   14 |   1.3343 |     40.458 |   1.2891 |     38.817 |     1.4
   15 |   1.3054 |     39.651 |   1.2653 |     38.235 |     1.5
   16 |   1.2781 |     39.050 |   1.2458 |     37.653 |     1.6
   17 |   1.2625 |     38.838 |   1.2454 |     37.868 |     1.7
   18 |   1.2352 |     38.053 |   1.2237 |     37.653 |     1.8
   19 |   1.2164 |     37.321 |   1.2284 |     37.714 |     1.9
   20 |   1.1991 |     37.137 |   1.2015 |     37.224 |     2.0
   21 |   1.1835 |     37.067 |   1.1981 |     37.040 |     2.1
   22 |   1.1672 |     36.303 |   1.1885 |     36.673 |     2.2
   23 |   1.1501 |     35.766 |   1.1864 |     36.887 |     2.3
   24 |   1.1378 |     35.495 |   1.1874 |     36.918 |     2.4
   25 |   1.1198 |     35.143 |   1.1630 |     36.550 |     2.5
   26 |   1.1084 |     34.850 |   1.1707 |     36.121 |     2.6
   27 |   1.0976 |     34.189 |   1.1583 |     35.754 |     2.7
   28 |   1.0914 |     34.238 |   1.1428 |     35.294 |     2.8
   29 |   1.0707 |     33.729 |   1.1569 |     35.600 |     2.9
   30 |   1.0602 |     33.133 |   1.1452 |     35.447 |     3.0
   31 |   1.0463 |     32.792 |   1.1459 |     35.754 |     3.1
   32 |   1.0372 |     32.857 |   1.1511 |     36.091 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 180,546

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.0680 |     79.329 |   2.7052 |     58.915 |     0.1
    2 |   2.4318 |     52.823 |   2.0941 |     45.925 |     0.2
    3 |   2.0330 |     46.213 |   1.8397 |     44.577 |     0.3
    4 |   1.8365 |     44.977 |   1.6998 |     44.240 |     0.5
    5 |   1.7110 |     44.045 |   1.6049 |     42.188 |     0.6
    6 |   1.6210 |     43.401 |   1.5330 |     42.065 |     0.7
    7 |   1.5511 |     42.393 |   1.4717 |     41.605 |     0.8
    8 |   1.4835 |     41.618 |   1.4199 |     41.176 |     0.9
    9 |   1.4322 |     40.865 |   1.3819 |     40.748 |     1.0
   10 |   1.3863 |     40.160 |   1.3453 |     39.553 |     1.1
   11 |   1.3471 |     39.516 |   1.3153 |     39.062 |     1.3
   12 |   1.3094 |     38.681 |   1.2864 |     38.511 |     1.4
   13 |   1.2787 |     38.064 |   1.2630 |     38.051 |     1.5
   14 |   1.2442 |     37.424 |   1.2363 |     37.500 |     1.6
   15 |   1.2149 |     36.633 |   1.2223 |     36.581 |     1.7
   16 |   1.1886 |     36.048 |   1.2026 |     36.581 |     1.8
   17 |   1.1697 |     35.669 |   1.1865 |     36.428 |     1.9
   18 |   1.1410 |     34.834 |   1.1696 |     35.263 |     2.1
   19 |   1.1229 |     34.271 |   1.1591 |     34.559 |     2.2
   20 |   1.1049 |     33.859 |   1.1422 |     34.620 |     2.3
   21 |   1.0832 |     33.014 |   1.1242 |     33.854 |     2.4
   22 |   1.0620 |     32.510 |   1.1164 |     33.824 |     2.5
   23 |   1.0476 |     32.428 |   1.1083 |     32.843 |     2.6
   24 |   1.0312 |     31.903 |   1.0962 |     32.874 |     2.7
   25 |   1.0119 |     31.388 |   1.0818 |     33.150 |     2.9
   26 |   0.9984 |     30.695 |   1.0902 |     33.701 |     3.0
   27 |   0.9821 |     30.798 |   1.0638 |     32.384 |     3.1
   28 |   0.9685 |     30.256 |   1.0653 |     32.690 |     3.2
   29 |   0.9569 |     29.969 |   1.0551 |     32.322 |     3.3
   30 |   0.9448 |     29.627 |   1.0445 |     32.108 |     3.4
   31 |   0.9368 |     29.400 |   1.0427 |     31.863 |     3.5
   32 |   0.9230 |     28.945 |   1.0376 |     31.556 |     3.6
   33 |   0.9069 |     28.300 |   1.0324 |     31.740 |     3.8
   34 |   0.8974 |     28.050 |   1.0285 |     32.016 |     3.9
   35 |   0.8841 |     28.018 |   1.0240 |     31.556 |     4.0
   36 |   0.8792 |     27.839 |   1.0092 |     31.036 |     4.1
   37 |   0.8670 |     27.389 |   1.0061 |     31.342 |     4.2
   38 |   0.8524 |     26.945 |   1.0097 |     30.882 |     4.3
   39 |   0.8486 |     26.923 |   1.0124 |     30.668 |     4.4
   40 |   0.8365 |     26.620 |   1.0150 |     30.974 |     4.6
   41 |   0.8257 |     26.214 |   1.0106 |     31.219 |     4.7
   42 |   0.8184 |     26.208 |   0.9985 |     31.097 |     4.8
   43 |   0.8137 |     25.927 |   0.9927 |     30.790 |     4.9
   44 |   0.8029 |     25.591 |   0.9932 |     30.392 |     5.0
   45 |   0.7972 |     25.363 |   0.9938 |     30.331 |     5.1
   46 |   0.7857 |     24.984 |   0.9863 |     30.025 |     5.2
   47 |   0.7779 |     24.745 |   0.9837 |     30.147 |     5.4
   48 |   0.7769 |     24.843 |   0.9970 |     30.760 |     5.5
   49 |   0.7599 |     24.518 |   0.9896 |     30.362 |     5.6
   50 |   0.7548 |     24.003 |   0.9928 |     29.749 |     5.7
   51 |   0.7511 |     24.030 |   0.9980 |     29.657 |     5.8
   52 |   0.7461 |     23.770 |   0.9811 |     29.412 |     5.9
   53 |   0.7389 |     23.548 |   0.9985 |     30.086 |     6.0
   54 |   0.7372 |     23.391 |   0.9773 |     29.626 |     6.2
   55 |   0.7290 |     23.505 |   0.9794 |     29.626 |     6.3
   56 |   0.7134 |     23.109 |   0.9892 |     29.963 |     6.4
   57 |   0.7074 |     22.524 |   0.9880 |     29.442 |     6.5
   58 |   0.7074 |     22.995 |   0.9979 |     29.596 |     6.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 180,546

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.0457 |     74.485 |   2.5916 |     55.300 |     0.1
    2 |   2.2862 |     50.022 |   2.0502 |     44.761 |     0.1
    3 |   1.9179 |     44.739 |   1.8107 |     43.505 |     0.2
    4 |   1.7387 |     43.476 |   1.6709 |     41.759 |     0.3
    5 |   1.6167 |     42.122 |   1.5640 |     40.931 |     0.4
    6 |   1.5204 |     40.735 |   1.4867 |     39.951 |     0.4
    7 |   1.4405 |     39.304 |   1.4170 |     39.216 |     0.5
    8 |   1.3752 |     38.437 |   1.3618 |     37.776 |     0.6
    9 |   1.3202 |     37.202 |   1.3219 |     37.776 |     0.7
   10 |   1.2725 |     36.243 |   1.2841 |     36.428 |     0.7
   11 |   1.2325 |     35.241 |   1.2473 |     35.631 |     0.8
   12 |   1.1882 |     34.563 |   1.2271 |     35.815 |     0.9
   13 |   1.1552 |     33.891 |   1.1939 |     35.263 |     0.9
   14 |   1.1225 |     33.008 |   1.1776 |     34.436 |     1.0
   15 |   1.0925 |     32.195 |   1.1535 |     34.467 |     1.1
   16 |   1.0596 |     31.448 |   1.1471 |     34.375 |     1.2
   17 |   1.0354 |     30.998 |   1.1182 |     33.395 |     1.2
   18 |   1.0121 |     30.212 |   1.1082 |     32.996 |     1.3
   19 |   0.9906 |     29.849 |   1.0915 |     33.150 |     1.4
   20 |   0.9659 |     29.264 |   1.0748 |     33.211 |     1.5
   21 |   0.9460 |     28.706 |   1.0663 |     32.598 |     1.5
   22 |   0.9233 |     28.278 |   1.0493 |     32.384 |     1.6
   23 |   0.9043 |     27.752 |   1.0380 |     32.812 |     1.7
   24 |   0.8873 |     27.238 |   1.0351 |     31.771 |     1.8
   25 |   0.8706 |     26.804 |   1.0255 |     31.342 |     1.8
   26 |   0.8505 |     26.555 |   1.0195 |     31.679 |     1.9
   27 |   0.8357 |     25.851 |   1.0124 |     31.127 |     2.0
   28 |   0.8197 |     25.553 |   1.0165 |     31.832 |     2.0
   29 |   0.8031 |     25.000 |   1.0012 |     30.974 |     2.1
   30 |   0.7889 |     24.512 |   0.9899 |     30.790 |     2.2
   31 |   0.7796 |     24.095 |   0.9915 |     30.974 |     2.3
   32 |   0.7664 |     23.748 |   0.9787 |     30.423 |     2.3
   33 |   0.7495 |     23.358 |   0.9910 |     30.453 |     2.4
   34 |   0.7383 |     23.250 |   0.9671 |     29.779 |     2.5
   35 |   0.7227 |     22.480 |   0.9839 |     30.025 |     2.6
   36 |   0.7138 |     22.367 |   0.9704 |     29.902 |     2.6
   37 |   0.7016 |     21.619 |   0.9721 |     30.055 |     2.7
   38 |   0.6876 |     21.700 |   0.9656 |     29.259 |     2.8
   39 |   0.6739 |     21.175 |   0.9736 |     30.025 |     2.9
   40 |   0.6669 |     21.061 |   0.9616 |     29.259 |     2.9
   41 |   0.6579 |     20.779 |   0.9529 |     29.075 |     3.0
   42 |   0.6445 |     20.210 |   0.9541 |     29.075 |     3.1
   43 |   0.6392 |     19.880 |   0.9955 |     30.178 |     3.2
   44 |   0.6345 |     19.706 |   0.9544 |     28.799 |     3.2
   45 |   0.6156 |     19.403 |   0.9653 |     29.105 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 379,298

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0077 |     55.039 |   1.3621 |     43.689 |     0.1
    2 |   1.3667 |     43.872 |   1.2674 |     40.748 |     0.2
    3 |   1.2764 |     41.748 |   1.2319 |     39.614 |     0.3
    4 |   1.2106 |     39.586 |   1.1453 |     37.255 |     0.4
    5 |   1.1556 |     37.760 |   1.1249 |     37.469 |     0.5
    6 |   1.1168 |     36.926 |   1.1042 |     36.060 |     0.6
    7 |   1.0654 |     35.100 |   1.0878 |     35.386 |     0.7
    8 |   1.0258 |     34.249 |   1.0599 |     33.058 |     0.8
    9 |   1.0008 |     33.371 |   1.0339 |     32.567 |     0.9
   10 |   0.9606 |     32.033 |   1.0174 |     33.578 |     1.0
   11 |   0.9334 |     31.312 |   1.0122 |     32.904 |     1.1
   12 |   0.9055 |     30.478 |   1.0033 |     32.384 |     1.2
   13 |   0.8872 |     30.126 |   0.9489 |     31.434 |     1.3
   14 |   0.8455 |     28.587 |   0.9759 |     30.944 |     1.4
   15 |   0.8349 |     28.381 |   0.9691 |     30.515 |     1.5
   16 |   0.8073 |     27.162 |   0.9396 |     29.412 |     1.6
   17 |   0.7871 |     26.669 |   0.9306 |     30.025 |     1.7
   18 |   0.7615 |     25.932 |   0.9530 |     30.025 |     1.8
   19 |   0.7439 |     24.875 |   0.9488 |     29.718 |     1.9
   20 |   0.7421 |     25.607 |   0.9338 |     28.278 |     2.0
   21 |   0.7052 |     24.128 |   0.9616 |     29.933 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 552,674

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7763 |     50.715 |   1.3490 |     43.597 |     0.1
    2 |   1.3328 |     43.736 |   1.2493 |     41.023 |     0.3
    3 |   1.2483 |     41.222 |   1.2034 |     39.583 |     0.4
    4 |   1.1748 |     38.876 |   1.1213 |     38.235 |     0.6
    5 |   1.1270 |     37.587 |   1.0374 |     34.191 |     0.7
    6 |   1.0599 |     35.046 |   1.0323 |     33.670 |     0.9
    7 |   1.0241 |     34.401 |   0.9979 |     33.241 |     1.0
    8 |   1.0001 |     33.415 |   0.9684 |     31.955 |     1.1
    9 |   0.9599 |     32.055 |   0.9294 |     30.116 |     1.3
   10 |   0.9243 |     31.253 |   0.9116 |     31.127 |     1.4
   11 |   0.8842 |     29.752 |   0.8958 |     30.116 |     1.6
   12 |   0.8539 |     28.961 |   0.8846 |     29.657 |     1.7
   13 |   0.8252 |     27.715 |   0.8756 |     29.044 |     1.9
   14 |   0.7969 |     27.200 |   0.8584 |     28.401 |     2.0
   15 |   0.7777 |     26.176 |   0.8867 |     29.136 |     2.1
   16 |   0.7500 |     25.455 |   0.8444 |     28.156 |     2.3
   17 |   0.7233 |     24.962 |   0.8383 |     28.094 |     2.4
   18 |   0.7028 |     24.323 |   0.8423 |     27.145 |     2.6
   19 |   0.6781 |     23.364 |   0.8211 |     26.654 |     2.7
   20 |   0.6610 |     22.589 |   0.8191 |     27.145 |     2.9
   21 |   0.6367 |     21.830 |   0.8390 |     27.145 |     3.0
   22 |   0.6174 |     21.186 |   0.8447 |     27.451 |     3.1
   23 |   0.6014 |     20.692 |   0.8253 |     26.317 |     3.3
   24 |   0.5854 |     19.928 |   0.8306 |     27.053 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 126,242

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1388 |     54.443 |   1.4727 |     44.271 |     0.1
    2 |   1.4390 |     44.322 |   1.3189 |     42.708 |     0.2
    3 |   1.3247 |     42.767 |   1.2413 |     40.074 |     0.2
    4 |   1.2462 |     40.941 |   1.1840 |     39.430 |     0.3
    5 |   1.1924 |     39.461 |   1.1496 |     38.266 |     0.4
    6 |   1.1438 |     37.868 |   1.0951 |     36.029 |     0.5
    7 |   1.1058 |     36.676 |   1.0718 |     35.723 |     0.6
    8 |   1.0653 |     35.219 |   1.0471 |     35.141 |     0.7
    9 |   1.0333 |     34.580 |   1.0304 |     33.793 |     0.7
   10 |   1.0065 |     33.778 |   1.0173 |     33.670 |     0.8
   11 |   0.9829 |     32.987 |   0.9898 |     32.537 |     0.9
   12 |   0.9493 |     31.925 |   0.9757 |     31.832 |     1.0
   13 |   0.9248 |     31.204 |   0.9609 |     31.495 |     1.1
   14 |   0.9082 |     30.673 |   0.9698 |     31.679 |     1.2
   15 |   0.8810 |     29.725 |   0.9401 |     31.158 |     1.2
   16 |   0.8647 |     29.302 |   0.9440 |     31.556 |     1.3
   17 |   0.8478 |     28.544 |   0.9403 |     31.036 |     1.4
   18 |   0.8268 |     28.365 |   0.9245 |     29.688 |     1.5
   19 |   0.8092 |     27.482 |   0.9420 |     30.300 |     1.6
   20 |   0.7948 |     27.368 |   0.9522 |     30.974 |     1.7
   21 |   0.7819 |     26.723 |   0.9438 |     29.841 |     1.7
   22 |   0.7679 |     26.230 |   0.9375 |     29.963 |     1.8
   23 |   0.7534 |     25.526 |   0.9214 |     29.565 |     1.9
   24 |   0.7397 |     25.596 |   0.9228 |     29.320 |     2.0
   25 |   0.7333 |     24.935 |   0.9394 |     28.799 |     2.1
   26 |   0.7192 |     24.724 |   0.9278 |     29.197 |     2.1
   27 |   0.7086 |     24.231 |   0.9467 |     29.657 |     2.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,126,754

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7066 |     50.363 |   1.3278 |     43.934 |     0.2
    2 |   1.2869 |     42.236 |   1.2409 |     40.257 |     0.3
    3 |   1.2261 |     40.491 |   1.1903 |     38.603 |     0.5
    4 |   1.1547 |     38.860 |   1.1641 |     38.480 |     0.6
    5 |   1.1124 |     37.348 |   1.1846 |     38.082 |     0.8
    6 |   1.0705 |     36.210 |   1.1888 |     39.001 |     1.0
    7 |   1.0414 |     35.257 |   1.1503 |     36.366 |     1.1
    8 |   1.0071 |     33.891 |   1.1362 |     37.010 |     1.3
    9 |   0.9743 |     33.182 |   1.1165 |     35.539 |     1.5
   10 |   0.9338 |     31.486 |   1.0988 |     35.784 |     1.6
   11 |   0.9188 |     31.231 |   1.0574 |     35.539 |     1.8
   12 |   0.8811 |     30.174 |   1.1285 |     37.316 |     1.9
   13 |   0.8547 |     29.096 |   1.0395 |     34.559 |     2.1
   14 |   0.8341 |     28.500 |   1.0571 |     35.417 |     2.3
   15 |   0.8031 |     27.525 |   1.0324 |     34.804 |     2.4
   16 |   0.7827 |     27.086 |   1.0154 |     33.915 |     2.6
   17 |   0.7470 |     25.851 |   1.0048 |     34.498 |     2.8
   18 |   0.7505 |     25.666 |   1.0396 |     35.141 |     2.9
   19 |   0.7166 |     24.762 |   1.0249 |     33.977 |     3.1
   20 |   0.6933 |     23.895 |   1.0930 |     36.336 |     3.2
   21 |   0.6777 |     23.358 |   1.0454 |     34.896 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 226,882

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0601 |     52.622 |   1.4714 |     44.638 |     0.1
    2 |   1.4309 |     45.075 |   1.3299 |     44.210 |     0.3
    3 |   1.3281 |     43.157 |   1.2491 |     40.288 |     0.5
    4 |   1.2582 |     41.466 |   1.1946 |     39.645 |     0.6
    5 |   1.2111 |     40.106 |   1.1523 |     37.592 |     0.8
    6 |   1.1663 |     38.719 |   1.1132 |     38.051 |     0.9
    7 |   1.1432 |     38.248 |   1.1008 |     36.949 |     1.1
    8 |   1.1004 |     36.747 |   1.0723 |     35.539 |     1.2
    9 |   1.0793 |     35.896 |   1.0422 |     35.141 |     1.4
   10 |   1.0537 |     35.127 |   1.0299 |     34.528 |     1.5
   11 |   1.0234 |     34.601 |   1.0123 |     33.670 |     1.7
   12 |   0.9932 |     33.355 |   0.9870 |     32.292 |     1.8
   13 |   0.9770 |     32.726 |   0.9788 |     33.150 |     2.0
   14 |   0.9539 |     32.060 |   0.9547 |     32.200 |     2.1
   15 |   0.9244 |     31.101 |   0.9459 |     31.311 |     2.3
   16 |   0.9122 |     30.554 |   0.9411 |     31.771 |     2.4
   17 |   0.8960 |     30.202 |   0.9250 |     31.066 |     2.6
   18 |   0.8635 |     29.335 |   0.9239 |     30.729 |     2.7
   19 |   0.8443 |     28.652 |   0.9191 |     30.055 |     2.9
   20 |   0.8270 |     28.072 |   0.9015 |     29.657 |     3.0
   21 |   0.8119 |     27.606 |   0.9237 |     30.208 |     3.2
   22 |   0.7914 |     26.837 |   0.9032 |     29.381 |     3.3
   23 |   0.7862 |     26.761 |   0.9086 |     29.197 |     3.5
   24 |   0.7678 |     26.555 |   0.8951 |     29.167 |     3.6
   25 |   0.7576 |     25.954 |   0.8874 |     28.738 |     3.8
   26 |   0.7319 |     24.854 |   0.8725 |     28.707 |     3.9
   27 |   0.7092 |     23.906 |   0.8899 |     28.370 |     4.1
   28 |   0.7012 |     24.149 |   0.9008 |     28.339 |     4.2
   29 |   0.6815 |     23.358 |   0.8995 |     28.125 |     4.4
   30 |   0.6770 |     23.309 |   0.8921 |     29.075 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 370,082

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8718 |     70.595 |   2.2244 |     48.254 |     0.1
    2 |   2.0436 |     48.803 |   1.6965 |     47.549 |     0.2
    3 |   1.6894 |     45.579 |   1.4976 |     43.566 |     0.3
    4 |   1.5178 |     43.666 |   1.4022 |     41.759 |     0.4
    5 |   1.4252 |     42.111 |   1.3371 |     40.993 |     0.5
    6 |   1.3568 |     40.740 |   1.2905 |     38.848 |     0.6
    7 |   1.2973 |     39.673 |   1.2501 |     38.235 |     0.7
    8 |   1.2540 |     38.519 |   1.2261 |     37.347 |     0.8
    9 |   1.2203 |     37.419 |   1.1983 |     37.255 |     0.9
   10 |   1.1833 |     36.389 |   1.1697 |     35.478 |     1.1
   11 |   1.1481 |     35.620 |   1.1603 |     35.509 |     1.2
   12 |   1.1205 |     34.850 |   1.1466 |     34.926 |     1.3
   13 |   1.0909 |     33.577 |   1.1260 |     34.651 |     1.4
   14 |   1.0603 |     32.656 |   1.1290 |     34.957 |     1.5
   15 |   1.0391 |     32.071 |   1.1071 |     34.283 |     1.6
   16 |   1.0150 |     31.177 |   1.1040 |     33.762 |     1.7
   17 |   0.9959 |     30.987 |   1.0894 |     33.548 |     1.8
   18 |   0.9689 |     30.126 |   1.0751 |     32.782 |     1.9
   19 |   0.9500 |     29.448 |   1.0804 |     33.456 |     2.0
   20 |   0.9317 |     29.053 |   1.0639 |     33.548 |     2.1
   21 |   0.9109 |     28.614 |   1.0657 |     32.322 |     2.2
   22 |   0.8910 |     27.807 |   1.0574 |     31.893 |     2.3
   23 |   0.8767 |     27.465 |   1.0568 |     32.261 |     2.4
   24 |   0.8608 |     26.913 |   1.0552 |     32.138 |     2.5
   25 |   0.8444 |     26.062 |   1.0435 |     32.016 |     2.6
   26 |   0.8255 |     26.122 |   1.0526 |     31.801 |     2.7
   27 |   0.8114 |     25.368 |   1.0391 |     31.066 |     2.9
   28 |   0.7949 |     25.125 |   1.0462 |     30.760 |     3.0
   29 |   0.7818 |     24.561 |   1.0407 |     31.036 |     3.1
   30 |   0.7648 |     24.258 |   1.0569 |     31.556 |     3.2
   31 |   0.7523 |     23.797 |   1.0453 |     30.882 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 404,514

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8921 |     51.951 |   1.3298 |     42.157 |     0.2
    2 |   1.3009 |     42.149 |   1.1998 |     39.400 |     0.3
    3 |   1.2046 |     40.052 |   1.1089 |     36.428 |     0.5
    4 |   1.1333 |     37.722 |   1.0566 |     34.344 |     0.7
    5 |   1.0759 |     35.918 |   1.0394 |     34.957 |     0.8
    6 |   1.0246 |     34.720 |   1.0143 |     33.670 |     1.0
    7 |   0.9919 |     33.425 |   0.9868 |     32.904 |     1.2
    8 |   0.9473 |     32.125 |   0.9519 |     31.710 |     1.3
    9 |   0.9179 |     30.678 |   0.9097 |     30.239 |     1.5
   10 |   0.8760 |     29.389 |   0.9082 |     30.699 |     1.7
   11 |   0.8468 |     28.890 |   0.8770 |     29.810 |     1.8
   12 |   0.8143 |     27.487 |   0.8621 |     28.983 |     2.0
   13 |   0.7928 |     27.102 |   0.8603 |     28.615 |     2.2
   14 |   0.7759 |     26.393 |   0.8524 |     29.320 |     2.3
   15 |   0.7450 |     25.547 |   0.8498 |     28.462 |     2.5
   16 |   0.7451 |     25.325 |   0.8138 |     27.420 |     2.7
   17 |   0.7020 |     24.111 |   0.8318 |     27.604 |     2.8
   18 |   0.6839 |     23.602 |   0.8358 |     26.777 |     3.0
   19 |   0.6657 |     22.757 |   0.8255 |     27.022 |     3.2
   20 |   0.6504 |     22.378 |   0.8185 |     26.103 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,140,898

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5087 |     45.611 |   1.2545 |     40.748 |     0.1
    2 |   1.1962 |     39.895 |   1.1281 |     38.205 |     0.2
    3 |   1.0993 |     36.584 |   1.0662 |     34.988 |     0.4
    4 |   1.0382 |     34.867 |   0.9770 |     32.567 |     0.5
    5 |   0.9698 |     32.922 |   0.9695 |     32.384 |     0.6
    6 |   0.9181 |     30.630 |   0.9309 |     31.219 |     0.7
    7 |   0.8696 |     29.481 |   0.8737 |     30.392 |     0.8
    8 |   0.8240 |     27.942 |   0.8867 |     29.228 |     1.0
    9 |   0.7888 |     27.070 |   0.8636 |     28.615 |     1.1
   10 |   0.7617 |     25.796 |   0.8463 |     27.390 |     1.2
   11 |   0.7174 |     24.426 |   0.8352 |     27.420 |     1.3
   12 |   0.6996 |     24.128 |   0.8287 |     27.114 |     1.5
   13 |   0.6706 |     23.131 |   0.8153 |     26.072 |     1.6
   14 |   0.6426 |     22.264 |   0.8281 |     26.409 |     1.7
   15 |   0.6348 |     21.933 |   0.7773 |     24.969 |     1.8
   16 |   0.5845 |     20.373 |   0.7894 |     25.031 |     1.9
   17 |   0.5754 |     19.896 |   0.7983 |     24.295 |     2.1
   18 |   0.5451 |     18.715 |   0.7593 |     24.142 |     2.2
   19 |   0.5216 |     17.956 |   0.7925 |     23.989 |     2.3
   20 |   0.5182 |     18.189 |   0.7868 |     23.315 |     2.4
   21 |   0.5032 |     17.441 |   0.8290 |     25.000 |     2.5
   22 |   0.4901 |     16.883 |   0.8079 |     24.142 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 32
Descriptors dimension: 1136
Feedforward dimension: 64
Encoder layers: 3
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 118,146

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   3.1260 |     78.365 |   2.7294 |     59.222 |     0.1
    2 |   2.5895 |     54.822 |   2.2918 |     47.488 |     0.2
    3 |   2.2420 |     48.212 |   1.9991 |     46.998 |     0.3
    4 |   1.9998 |     46.852 |   1.8064 |     45.466 |     0.4
    5 |   1.8325 |     45.812 |   1.6802 |     44.118 |     0.5
    6 |   1.7136 |     45.373 |   1.5922 |     43.750 |     0.7
    7 |   1.6288 |     44.788 |   1.5262 |     43.382 |     0.8
    8 |   1.5623 |     43.915 |   1.4749 |     43.107 |     0.9
    9 |   1.5093 |     43.130 |   1.4335 |     41.697 |     1.0
   10 |   1.4580 |     42.490 |   1.3944 |     40.839 |     1.1
   11 |   1.4200 |     41.721 |   1.3607 |     40.594 |     1.2
   12 |   1.3851 |     41.119 |   1.3401 |     40.043 |     1.3
   13 |   1.3535 |     40.480 |   1.3059 |     39.246 |     1.4
   14 |   1.3191 |     39.846 |   1.2832 |     38.787 |     1.5
   15 |   1.2961 |     39.245 |   1.2635 |     38.634 |     1.6
   16 |   1.2628 |     38.486 |   1.2447 |     37.898 |     1.8
   17 |   1.2449 |     38.334 |   1.2304 |     37.531 |     1.9
   18 |   1.2188 |     37.570 |   1.2214 |     37.439 |     2.0
   19 |   1.2007 |     37.272 |   1.2091 |     36.703 |     2.1
   20 |   1.1776 |     36.671 |   1.1964 |     36.857 |     2.2
   21 |   1.1647 |     35.972 |   1.1867 |     36.397 |     2.3
   22 |   1.1498 |     35.501 |   1.1762 |     35.938 |     2.4
   23 |   1.1358 |     35.669 |   1.1638 |     35.662 |     2.5
   24 |   1.1208 |     35.062 |   1.1639 |     35.907 |     2.6
   25 |   1.1028 |     34.585 |   1.1598 |     35.447 |     2.7
   26 |   1.0916 |     34.146 |   1.1471 |     35.355 |     2.8
   27 |   1.0801 |     33.859 |   1.1540 |     35.447 |     3.0
   28 |   1.0689 |     33.919 |   1.1378 |     35.386 |     3.1
   29 |   1.0578 |     33.545 |   1.1347 |     34.804 |     3.2
   30 |   1.0421 |     33.257 |   1.1306 |     34.498 |     3.3
   31 |   1.0364 |     32.916 |   1.1345 |     34.773 |     3.4
   32 |   1.0257 |     32.596 |   1.1279 |     35.018 |     3.5
   33 |   1.0172 |     32.223 |   1.1108 |     34.099 |     3.6
   34 |   1.0044 |     31.930 |   1.1144 |     34.038 |     3.7
   35 |   0.9947 |     31.681 |   1.1136 |     33.701 |     3.8
   36 |   0.9791 |     31.188 |   1.1110 |     34.161 |     3.9
   37 |   0.9772 |     31.215 |   1.1036 |     33.578 |     4.0
   38 |   0.9689 |     31.215 |   1.1053 |     33.640 |     4.2
   39 |   0.9595 |     30.738 |   1.1104 |     33.701 |     4.3
   40 |   0.9498 |     30.158 |   1.1074 |     33.088 |     4.4
   41 |   0.9426 |     29.931 |   1.1000 |     33.640 |     4.5
   42 |   0.9321 |     29.893 |   1.0937 |     33.487 |     4.6
   43 |   0.9271 |     29.530 |   1.1022 |     33.824 |     4.7
   44 |   0.9196 |     29.573 |   1.0993 |     33.824 |     4.8
   45 |   0.9078 |     29.270 |   1.0980 |     33.333 |     4.9
   46 |   0.8996 |     28.901 |   1.1082 |     33.977 |     5.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 303,138

Training started
X_train.shape: torch.Size([3076, 702])
Y_train.shape: torch.Size([3076, 7])
X_dev.shape: torch.Size([544, 337])
Y_dev.shape: torch.Size([544, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7872 |     50.038 |   1.2942 |     41.605 |     0.1
    2 |   1.2954 |     42.008 |   1.1939 |     39.461 |     0.2
    3 |   1.1983 |     39.277 |   1.1113 |     35.355 |     0.3
    4 |   1.1327 |     37.408 |   1.0737 |     34.926 |     0.4
    5 |   1.0765 |     35.517 |   1.0422 |     33.915 |     0.5
    6 |   1.0218 |     34.184 |   0.9983 |     32.261 |     0.5
    7 |   0.9822 |     32.997 |   0.9558 |     30.607 |     0.6
    8 |   0.9478 |     31.941 |   0.9373 |     30.821 |     0.7
    9 |   0.9201 |     31.123 |   0.9178 |     30.699 |     0.8
   10 |   0.8768 |     29.687 |   0.9177 |     30.545 |     0.9
   11 |   0.8547 |     28.945 |   0.8939 |     29.105 |     1.0
   12 |   0.8177 |     27.520 |   0.8961 |     29.289 |     1.1
   13 |   0.7950 |     26.923 |   0.8835 |     28.707 |     1.2
   14 |   0.7742 |     26.160 |   0.8855 |     29.320 |     1.3
   15 |   0.7647 |     25.769 |   0.8980 |     29.289 |     1.4
   16 |   0.7292 |     24.474 |   0.9050 |     29.259 |     1.4
   17 |   0.7147 |     24.545 |   0.8852 |     27.543 |     1.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>