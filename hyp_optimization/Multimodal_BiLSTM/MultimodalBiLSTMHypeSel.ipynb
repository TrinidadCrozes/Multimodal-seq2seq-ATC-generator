{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91a67c3-3164-402b-9c3d-ed5f98d41c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "from seq2seq import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58483fc7-4a85-42d3-93dd-b16044d8711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa18d3e-cd26-4b6a-85c0-cc550fb60feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string that simulates a list to a real list\n",
    "def convert_string_list(element):\n",
    "    # Delete [] of the string\n",
    "    element = element[0:len(element)]\n",
    "    # Create a list that contains each code as e.g. 'A'\n",
    "    ATC_list = list(element.split('; '))\n",
    "    for index, code in enumerate(ATC_list):\n",
    "        # Delete '' of the code\n",
    "        ATC_list[index] = code[0:len(code)]\n",
    "    return ATC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c013c98c-badd-464a-8c6f-6568e8ce8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../../Data/train_set.csv')\n",
    "test_set = pd.read_csv('../../Data/test_set.csv')\n",
    "val_set = pd.read_csv('../../Data/val_set.csv')\n",
    "set_seeds(78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdf13a86-4c48-475c-a5f3-ef21ffe19b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicate_rows(df):\n",
    "    # Duplicate each compound the number of ATC codes associated to it, copying its SMILES in new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        atc_codes = row['ATC Codes']\n",
    "        atc_codes_list = convert_string_list(atc_codes)\n",
    "        \n",
    "        if len(atc_codes_list) > 1:\n",
    "            for code in atc_codes_list:\n",
    "                if len(code) == 5:\n",
    "                    new_row = row.copy()\n",
    "                    new_row['ATC Codes'] = code\n",
    "                    new_rows.append(new_row)\n",
    "        else:\n",
    "            if len(atc_codes_list[0]) == 5:\n",
    "                new_rows.append(row)\n",
    "    \n",
    "    new_set = pd.DataFrame(new_rows)\n",
    "    new_set = new_set.reset_index(drop=True)\n",
    "\n",
    "    return new_set\n",
    "\n",
    "#Extract molecular descriptors from the dataframe.\n",
    "def extract_descriptors(df):\n",
    "    descriptors = df.iloc[:, 2:-5].values\n",
    "    \n",
    "    # descriptors[pd.isinf(descriptors)] = pd.nan\n",
    "    descriptors[pd.isna(descriptors)] = np.nanmedian(descriptors)\n",
    "\n",
    "    return torch.tensor(descriptors, dtype=torch.float32)\n",
    "    \n",
    "# Create vocabularies\n",
    "# Tokenize the data\n",
    "def source(df):\n",
    "    source = []\n",
    "    for compound in df['Neutralized SMILES']:\n",
    "        # A list containing each SMILES character separated\n",
    "        source.append(list(compound))\n",
    "    return source\n",
    "def target(df):\n",
    "    target = []\n",
    "    for codes in df['ATC Codes']:  \n",
    "        code = convert_string_list(codes) \n",
    "        # A list of lists, each one containing each ATC code character separated \n",
    "        for c in code:\n",
    "            list_c = list(c)\n",
    "            target.append(list_c)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb280583-cbda-4ad4-b078-af63747f769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_set = multiplicate_rows(train_set)\n",
    "new_val_set = multiplicate_rows(val_set)\n",
    "new_test_set = multiplicate_rows(test_set)\n",
    "\n",
    "new_test_set.to_csv(\"onecodeperdrug_test_set.csv\", index = False)\n",
    "new_val_set.to_csv(\"onecodeperdrug_val_set.csv\", index = False)\n",
    "\n",
    "train_descriptors = extract_descriptors(new_train_set)\n",
    "test_descriptors = extract_descriptors(new_test_set)\n",
    "test_descriptors2 = extract_descriptors(test_set)\n",
    "val_descriptors = extract_descriptors(new_val_set)\n",
    "val_descriptors2 = extract_descriptors(val_set)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_descriptors = torch.tensor(scaler.fit_transform(train_descriptors.numpy()), dtype=torch.float32)\n",
    "val_descriptors = torch.tensor(scaler.transform(val_descriptors.numpy()), dtype=torch.float32)\n",
    "test_descriptors = torch.tensor(scaler.transform(test_descriptors.numpy()), dtype=torch.float32)\n",
    "val_descriptors2 = torch.tensor(scaler.transform(val_descriptors2.numpy()), dtype=torch.float32)\n",
    "test_descriptors2 = torch.tensor(scaler.transform(test_descriptors2.numpy()), dtype=torch.float32)\n",
    "\n",
    "source_train = source(new_train_set)\n",
    "source_test = source(new_test_set)\n",
    "# Test set without duplicated compounds\n",
    "source_test2 = source(test_set)\n",
    "source_val = source(new_val_set)\n",
    "# Val set without duplicated compounds\n",
    "source_val2 = source(val_set)\n",
    "\n",
    "target_train = target(new_train_set)\n",
    "target_test = target(new_test_set)\n",
    "target_val = target(new_val_set)\n",
    "\n",
    "# An Index object represents a mapping from the vocabulary to integers (indices) to feed into the models\n",
    "source_index = index.Index(source_train)\n",
    "target_index = index.Index(target_train)\n",
    "\n",
    "# Create tensors\n",
    "X_train = source_index.text2tensor(source_train)\n",
    "y_train = target_index.text2tensor(target_train)\n",
    "X_val = source_index.text2tensor(source_val)\n",
    "X_val2 = source_index.text2tensor(source_val2)\n",
    "y_val = target_index.text2tensor(target_val)     \n",
    "X_test = source_index.text2tensor(source_test)\n",
    "X_test2 = source_index.text2tensor(source_test2)\n",
    "y_test = target_index.text2tensor(target_test)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X_train = X_train.to(\"cuda\")\n",
    "    y_train = y_train.to(\"cuda\")\n",
    "    train_descriptors = train_descriptors.to(\"cuda\") \n",
    "    test_descriptors = test_descriptors.to(\"cuda\")\n",
    "    test_descriptors2 = test_descriptors2.to(\"cuda\")\n",
    "    val_descriptors = val_descriptors.to(\"cuda\")\n",
    "    val_descriptors2 = val_descriptors2.to(\"cuda\")\n",
    "    X_val = X_val.to(\"cuda\")\n",
    "    X_val2 = X_val2.to(\"cuda\")\n",
    "    y_val = y_val.to(\"cuda\")\n",
    "    X_test= X_test.to(\"cuda\")\n",
    "    y_test = y_test.to(\"cuda\")\n",
    "    X_test2 = X_test2.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7641f295-ce61-41ee-be47-4a1803b58c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_grid = { \n",
    "    'enc_embedding_dim': [32, 64, 128],\n",
    "    'dec_embedding_dim': [32, 64, 128],\n",
    "    'enc_hidden_units': [32, 64, 128],\n",
    "    'dec_hidden_units': [32, 64, 128],\n",
    "    'enc_layers': [2, 3, 4],\n",
    "    'dec_layers': [2, 3, 4],\n",
    "    'dropout': [0.0, 0.1, 0.2],\n",
    "    'weight_decays': [10**-4, 10**-5],\n",
    "    'learning_rates': [10**-3, 10**-4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f2019a6-d989-48dc-a15c-7c21e9a3bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample from dictionary\n",
    "random_params = {k: random.sample(v, 1)[0] for k, v in hyperparameters_grid.items()}\n",
    "print(random_params['enc_embedding_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a490840-35bf-4fa9-8fe8-f70edf3ab319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_search(max_evals):\n",
    "    tested_params = set()\n",
    "    df_tests = pd.DataFrame(columns = ['#epochs', 'encoder_embedding_dim', 'decoder_embedding_dim', 'enc_layers', 'dec_layers', 'enc_hidden_units', 'dec_hidden_units', 'dropout', 'weight_decay', 'learning_rate', 'Precisionatn nivel1', 'Precisionatn nivel2', 'Precisionatn nivel3', 'Precisionatn nivel4', 'Precision nivel1', 'Precision nivel2', 'Precision nivel3', 'Precision nivel4', 'Recall nivel1', 'Recall nivel2', 'Recall nivel3', 'Recall nivel4', 'Drugs that have at least one match'], index = list(range(max_evals)))\n",
    "    sys.stdout = open('log.txt', 'w')\n",
    "    for i in range(max_evals):\n",
    "        while True:\n",
    "            random_params = {k: random.sample(v, 1)[0] for k, v in hyperparameters_grid.items()}\n",
    "            params_tuple = tuple(random_params.values())\n",
    "            if params_tuple not in tested_params:\n",
    "                tested_params.add(params_tuple)\n",
    "                break   \n",
    "        model = multimodal_models.MultimodalBiLSTM(\n",
    "                 source_index, \n",
    "                 target_index,\n",
    "                 encoder_embedding_dimension = random_params['enc_embedding_dim'],\n",
    "                 descriptors_dimension = train_descriptors.shape[1],\n",
    "                 decoder_embedding_dimension = random_params['dec_embedding_dim'],\n",
    "                 encoder_hidden_units = random_params['enc_hidden_units'],\n",
    "                 encoder_layers = random_params['enc_layers'],\n",
    "                 decoder_hidden_units = random_params['dec_hidden_units'],\n",
    "                 decoder_layers = random_params['dec_layers'],\n",
    "                 dropout = random_params['dropout'])   \n",
    "        model.to(\"cuda\")\n",
    "        model.fit(\n",
    "                X_train,\n",
    "                train_descriptors,\n",
    "                y_train,\n",
    "                X_val, \n",
    "                val_descriptors,\n",
    "                y_val, \n",
    "                batch_size = 32, \n",
    "                epochs = 500, \n",
    "                learning_rate = random_params['learning_rates'], \n",
    "                weight_decay = random_params['weight_decays'],\n",
    "                progress_bar = 0, \n",
    "                save_path = None\n",
    "        ) \n",
    "        model.load_state_dict(torch.load(\"best_multimodalmodel.pth\", weights_only=True))\n",
    "        ep = model.early_stopping.best_epoch\n",
    "        loss, error_rate = model.evaluate(X_val, val_descriptors, y_val)    \n",
    "        predictions, log_probabilities = search_algorithms.multimodal_beam_search(\n",
    "            model, \n",
    "            X_val,\n",
    "            val_descriptors,\n",
    "            predictions = 6, # max length of the predicted sequence\n",
    "            beam_width = 3,\n",
    "            batch_size = 32, \n",
    "            progress_bar = 0\n",
    "        )\n",
    "        output_beam = [target_index.tensor2text(p) for p in predictions]\n",
    "        predictions2, log_probabilities2 = search_algorithms.multimodal_beam_search(\n",
    "            model, \n",
    "            X_val2,\n",
    "            val_descriptors2,\n",
    "            predictions = 6, # max length of the predicted sequence\n",
    "            beam_width = 3,\n",
    "            batch_size = 32, \n",
    "            progress_bar = 0\n",
    "        )\n",
    "        output_beam2 = [target_index.tensor2text(p) for p in predictions2]\n",
    "        \n",
    "        predictions_onecodeperdrug = []\n",
    "        for preds in output_beam:\n",
    "            interm = []\n",
    "            for pred in preds:\n",
    "                clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "                if len(clean_pred) == 5:\n",
    "                    interm.append(clean_pred)\n",
    "            predictions_onecodeperdrug.append(interm)\n",
    "                \n",
    "        predictions = []\n",
    "        for preds in output_beam2:\n",
    "            interm = []\n",
    "            for pred in preds:\n",
    "                clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "                if len(clean_pred) == 5:\n",
    "                    interm.append(clean_pred)\n",
    "            predictions.append(interm)\n",
    "                \n",
    "        precisionatn_1, precisionatn_2, precisionatn_3, precisionatn_4 = defined_metrics.precisionatn(predictions_onecodeperdrug, \"onecodeperdrug_val_set.csv\", 'ATC Codes')\n",
    "        precision_1, precision_2, precision_3, precision_4 = defined_metrics.precision(predictions, \"../../Data/val_set.csv\", 'ATC Codes')\n",
    "        recall_1, recall_2, recall_3, recall_4, comp = defined_metrics.recall(predictions, \"../../Data/val_set.csv\", 'ATC Codes')\n",
    "        df_tests.iloc[i, :] = [f\"{ep}\", f\"{random_params['enc_embedding_dim']}\", f\"{random_params['dec_embedding_dim']}\", f\"{random_params['enc_layers']}\", f\"{random_params['dec_layers']}\", f\"{random_params['enc_hidden_units']}\", f\"{random_params['dec_hidden_units']}\", f\"{random_params['dropout']}\", f\"{random_params['weight_decays']}\", f\"{random_params['learning_rates']}\", f\"{precisionatn_1}\", f\"{precisionatn_2}\", f\"{precisionatn_3}\", f\"{precisionatn_4}\", f\"{precision_1}\", f\"{precision_2}\", f\"{precision_3}\", f\"{precision_4}\", f\"{recall_1}\", f\"{recall_2}\", f\"{recall_3}\", f\"{recall_4}\", f\"{comp}\"]\n",
    "        df_tests.to_csv(\"multimodalbilstm_results.csv\", index = False)\n",
    "    sys.stdout = sys.__stdout__\n",
    "    return df_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15be5934-9315-4279-8ce0-ef8f4388c811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tests = random_search(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a48ca1-35fc-4558-bd5b-4d5557d9ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "df_res = pd.read_csv(\"multimodalbilstm_results.csv\")\n",
    "df_res = df_res[[\"encoder_embedding_dim\", \"decoder_embedding_dim\", \"enc_layers\", \"dec_layers\", \"enc_hidden_units\", \"dec_hidden_units\", \"dropout\", \n",
    "                 \"weight_decay\", \"learning_rate\", \"Precision nivel1\", \"Recall nivel1\"]]\n",
    "\n",
    "df_res['embedding dimension'] = df_res.apply(\n",
    "    lambda row: f'enc_{int(row[\"encoder_embedding_dim\"])} - dec_{int(row[\"decoder_embedding_dim\"])}', axis=1)\n",
    "emb_dim_map = {\"enc_64 - dec_64\": 'o', \"enc_128 - dec_128\": '^', \"enc_64 - dec_128\": 's', \"enc_128 - dec_64\": '*'}\n",
    "df_res['embedding dimension'] = df_res['embedding dimension'].map(emb_dim_map)\n",
    "\n",
    "df_res['encoder and decoder layers'] = df_res.apply(\n",
    "    lambda row: f'enc_{int(row[\"enc_layers\"])} - dec_{int(row[\"dec_layers\"])}', axis=1)\n",
    "df_res['weight_decay and learning_rate'] = df_res.apply(\n",
    "    lambda row: f'WD_{row[\"weight_decay\"]} - LR_{row[\"learning_rate\"]}', axis=1)\n",
    "\n",
    "size_map = {0.1: 100, 0.2: 300}\n",
    "df_res['dropout value'] = df_res['dropout'].map(size_map)\n",
    "\n",
    "df_res['encoder and decoder hidden units'] = df_res.apply(\n",
    "    lambda row: f'enc_{int(row[\"enc_hidden_units\"])} - dec_{int(row[\"dec_hidden_units\"])}', axis=1)\n",
    "df_res['edgewidth'] = df_res['encoder and decoder hidden units'].map({\"enc_32 - dec_32\": 0.5, \"enc_32 - dec_64\": 1.5,  \"enc_64 - dec_32\": 2.5, \"enc_64 - dec_64\": 3.5})\n",
    "\n",
    "color_palette = sns.color_palette(\"Pastel1\", n_colors=df_res['encoder and decoder layers'].nunique())\n",
    "\n",
    "unique_wd_lr = df_res['weight_decay and learning_rate'].unique()\n",
    "color_palette2 = sns.color_palette(\"Set1\", n_colors=len(unique_wd_lr))\n",
    "wd_lr_color_map = dict(zip(unique_wd_lr, color_palette2))\n",
    "\n",
    "unique_enc_dec = df_res['encoder and decoder layers'].unique()\n",
    "enc_dec_color_map = dict(zip(unique_enc_dec, color_palette))\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, row in df_res.iterrows():\n",
    "    plt.scatter(\n",
    "        x=row['Precision nivel1'],\n",
    "        y=row['Recall nivel1'],\n",
    "        s=row['dropout value'],  \n",
    "        color=enc_dec_color_map[row['encoder and decoder layers']],  \n",
    "        marker=row['embedding dimension'], \n",
    "        edgecolor=wd_lr_color_map[row['weight_decay and learning_rate']],  \n",
    "        linewidth=row['edgewidth'],  \n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='none', label='Encoder and decoder embedding dimension'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markersize=10, label='enc_64 - dec_64'),\n",
    "    Line2D([0], [0], marker='^', color='w', markerfacecolor='black', markersize=10, label='enc_128 - dec_128'),\n",
    "    Line2D([0], [0], marker='s', color='w', markerfacecolor='black', markersize=10, label='enc_64 - dec_128'),\n",
    "    Line2D([0], [0], marker='*', color='w', markerfacecolor='black', markersize=10, label='enc_128 - dec_64'),\n",
    "    Line2D([0], [0], color='black', linewidth=0.5, label='enc_32 - dec_32'),\n",
    "    Line2D([0], [0], color='black', linewidth=1.5, label='enc_32 - dec_64'),\n",
    "    Line2D([0], [0], color='black', linewidth=2.5, label='enc_64 - dec_32'),\n",
    "    Line2D([0], [0], color='black', linewidth=3.5, label='enc_64 - dec_64'),\n",
    "    Line2D([0], [0], color='none', label='Encoder - Decoder layers'),\n",
    "    *[Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10, label=label) for label, color in enc_dec_color_map.items()],\n",
    "    Line2D([0], [0], color='none', label='Weight decay - Learning rate'),\n",
    "    *[Line2D([0], [0], marker='o', color='w', markeredgecolor=color, markerfacecolor='none', markersize=10, label=label) for label, color in wd_lr_color_map.items()]\n",
    "]\n",
    "\n",
    "size_mapping = {\n",
    "    100: \"0.1\",\n",
    "    300: \"0.2\"\n",
    "}\n",
    "\n",
    "size_legend = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markersize=size/18, label=f'{size_mapping.get(int(size))}') \n",
    "    for size in df_res['dropout value'].unique() \n",
    "]\n",
    "\n",
    "plt.legend(title='Hiperparámetros', handles = legend_elements + [Line2D([0], [0], color='none', label='Dropout')] + size_legend, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.title(\"Multimodal BiLSTM Hyperparameter optimization\", fontsize=16)\n",
    "plt.xlabel(\"Precision level 1\", fontsize=14)\n",
    "plt.ylabel(\"Recall level 1\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('multimodalbilstm_hyperparams.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573e653c-499a-43e0-9695-9b2e14d591c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#epochs</th>\n",
       "      <th>encoder_embedding_dim</th>\n",
       "      <th>decoder_embedding_dim</th>\n",
       "      <th>enc_layers</th>\n",
       "      <th>dec_layers</th>\n",
       "      <th>enc_hidden_units</th>\n",
       "      <th>dec_hidden_units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Precisionatn nivel4</th>\n",
       "      <th>Precision nivel1</th>\n",
       "      <th>Precision nivel2</th>\n",
       "      <th>Precision nivel3</th>\n",
       "      <th>Precision nivel4</th>\n",
       "      <th>Recall nivel1</th>\n",
       "      <th>Recall nivel2</th>\n",
       "      <th>Recall nivel3</th>\n",
       "      <th>Recall nivel4</th>\n",
       "      <th>Drugs that have at least one match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>82</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>28.57142857142857</td>\n",
       "      <td>0.14125753660637397</td>\n",
       "      <td>0.330749354005168</td>\n",
       "      <td>0.46969696969696967</td>\n",
       "      <td>0.23015873015873017</td>\n",
       "      <td>0.30835486649440136</td>\n",
       "      <td>0.32945736434108525</td>\n",
       "      <td>0.4772727272727273</td>\n",
       "      <td>0.2857142857142857</td>\n",
       "      <td>[129, 44, 21, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>110</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.16192937123169693</td>\n",
       "      <td>0.3434004474272931</td>\n",
       "      <td>0.4294871794871795</td>\n",
       "      <td>0.2638888888888889</td>\n",
       "      <td>0.35831180017226527</td>\n",
       "      <td>0.33557046979865773</td>\n",
       "      <td>0.46153846153846156</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>[149, 52, 24, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>120</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>37.03703703703704</td>\n",
       "      <td>0.1662360034453059</td>\n",
       "      <td>0.30666666666666664</td>\n",
       "      <td>0.5141843971631206</td>\n",
       "      <td>0.3148148148148148</td>\n",
       "      <td>0.35977605512489236</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5638297872340425</td>\n",
       "      <td>0.37037037037037035</td>\n",
       "      <td>[150, 47, 27, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>91</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>13.636363636363635</td>\n",
       "      <td>0.1670973298880276</td>\n",
       "      <td>0.2358024691358025</td>\n",
       "      <td>0.5333333333333334</td>\n",
       "      <td>0.13636363636363635</td>\n",
       "      <td>0.3270456503014642</td>\n",
       "      <td>0.2851851851851852</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.13636363636363635</td>\n",
       "      <td>[135, 40, 22, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>122</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>14.285714285714285</td>\n",
       "      <td>0.17054263565891492</td>\n",
       "      <td>0.16013071895424835</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14285714285714285</td>\n",
       "      <td>0.3683893195521103</td>\n",
       "      <td>0.16666666666666666</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14285714285714285</td>\n",
       "      <td>[153, 28, 14, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>21</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>83.91608391608392</td>\n",
       "      <td>0.5676141257536605</td>\n",
       "      <td>0.7785547785547784</td>\n",
       "      <td>0.8187830687830687</td>\n",
       "      <td>0.6687853107344633</td>\n",
       "      <td>0.707249497559575</td>\n",
       "      <td>0.8659188034188035</td>\n",
       "      <td>0.9073034769463341</td>\n",
       "      <td>0.8498587570621469</td>\n",
       "      <td>[286, 252, 236, 206]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>77.431906614786</td>\n",
       "      <td>0.568906115417743</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.7921985815602839</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.6785673270169394</td>\n",
       "      <td>0.8306565656565656</td>\n",
       "      <td>0.8872948328267478</td>\n",
       "      <td>0.7820987654320987</td>\n",
       "      <td>[275, 235, 216, 175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>79.46768060836501</td>\n",
       "      <td>0.5736434108527131</td>\n",
       "      <td>0.749413145539906</td>\n",
       "      <td>0.7791842475386778</td>\n",
       "      <td>0.6131498470948009</td>\n",
       "      <td>0.7007464829170257</td>\n",
       "      <td>0.8186130672926447</td>\n",
       "      <td>0.8867691380349608</td>\n",
       "      <td>0.802446483180428</td>\n",
       "      <td>[284, 237, 218, 180]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>76.63934426229508</td>\n",
       "      <td>0.5770887166236002</td>\n",
       "      <td>0.7649253731343285</td>\n",
       "      <td>0.7186147186147186</td>\n",
       "      <td>0.6059870550161811</td>\n",
       "      <td>0.654364053976457</td>\n",
       "      <td>0.8419879767827528</td>\n",
       "      <td>0.8598639455782313</td>\n",
       "      <td>0.7892394822006473</td>\n",
       "      <td>[268, 231, 206, 170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>36</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>81.640625</td>\n",
       "      <td>0.5848406546080964</td>\n",
       "      <td>0.7478787878787877</td>\n",
       "      <td>0.8034188034188032</td>\n",
       "      <td>0.5989345509893453</td>\n",
       "      <td>0.6736146999712892</td>\n",
       "      <td>0.8264949494949495</td>\n",
       "      <td>0.8968457468457468</td>\n",
       "      <td>0.8315068493150685</td>\n",
       "      <td>[275, 234, 219, 188]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    #epochs encoder_embedding_dim decoder_embedding_dim enc_layers dec_layers  \\\n",
       "189      82                   128                    32          3          4   \n",
       "91      110                    64                   128          4          4   \n",
       "39      120                   128                    64          3          4   \n",
       "190      91                    32                    32          3          4   \n",
       "35      122                    64                    32          4          4   \n",
       "..      ...                   ...                   ...        ...        ...   \n",
       "141      21                    64                    64          2          2   \n",
       "21       22                    32                    32          3          2   \n",
       "146      29                    32                   128          2          3   \n",
       "116      49                    64                    64          3          4   \n",
       "66       36                    64                   128          3          2   \n",
       "\n",
       "    enc_hidden_units dec_hidden_units dropout weight_decay learning_rate  ...  \\\n",
       "189               32               64     0.0       0.0001        0.0001  ...   \n",
       "91                32               32     0.2       0.0001        0.0001  ...   \n",
       "39                64               32     0.1        1e-05        0.0001  ...   \n",
       "190               64               32     0.0       0.0001        0.0001  ...   \n",
       "35                32               32     0.0       0.0001        0.0001  ...   \n",
       "..               ...              ...     ...          ...           ...  ...   \n",
       "141               32              128     0.1        1e-05         0.001  ...   \n",
       "21                32              128     0.0       0.0001         0.001  ...   \n",
       "146               64              128     0.1       0.0001         0.001  ...   \n",
       "116               64              128     0.2       0.0001         0.001  ...   \n",
       "66               128              128     0.2        1e-05         0.001  ...   \n",
       "\n",
       "    Precisionatn nivel4     Precision nivel1     Precision nivel2  \\\n",
       "189   28.57142857142857  0.14125753660637397    0.330749354005168   \n",
       "91                 32.0  0.16192937123169693   0.3434004474272931   \n",
       "39    37.03703703703704   0.1662360034453059  0.30666666666666664   \n",
       "190  13.636363636363635   0.1670973298880276   0.2358024691358025   \n",
       "35   14.285714285714285  0.17054263565891492  0.16013071895424835   \n",
       "..                  ...                  ...                  ...   \n",
       "141   83.91608391608392   0.5676141257536605   0.7785547785547784   \n",
       "21      77.431906614786    0.568906115417743                 0.76   \n",
       "146   79.46768060836501   0.5736434108527131    0.749413145539906   \n",
       "116   76.63934426229508   0.5770887166236002   0.7649253731343285   \n",
       "66            81.640625   0.5848406546080964   0.7478787878787877   \n",
       "\n",
       "        Precision nivel3     Precision nivel4        Recall nivel1  \\\n",
       "189  0.46969696969696967  0.23015873015873017  0.30835486649440136   \n",
       "91    0.4294871794871795   0.2638888888888889  0.35831180017226527   \n",
       "39    0.5141843971631206   0.3148148148148148  0.35977605512489236   \n",
       "190   0.5333333333333334  0.13636363636363635   0.3270456503014642   \n",
       "35                   0.5  0.14285714285714285   0.3683893195521103   \n",
       "..                   ...                  ...                  ...   \n",
       "141   0.8187830687830687   0.6687853107344633    0.707249497559575   \n",
       "21    0.7921985815602839               0.5625   0.6785673270169394   \n",
       "146   0.7791842475386778   0.6131498470948009   0.7007464829170257   \n",
       "116   0.7186147186147186   0.6059870550161811    0.654364053976457   \n",
       "66    0.8034188034188032   0.5989345509893453   0.6736146999712892   \n",
       "\n",
       "           Recall nivel2        Recall nivel3        Recall nivel4  \\\n",
       "189  0.32945736434108525   0.4772727272727273   0.2857142857142857   \n",
       "91   0.33557046979865773  0.46153846153846156               0.3125   \n",
       "39                   0.3   0.5638297872340425  0.37037037037037035   \n",
       "190   0.2851851851851852               0.5375  0.13636363636363635   \n",
       "35   0.16666666666666666                  0.5  0.14285714285714285   \n",
       "..                   ...                  ...                  ...   \n",
       "141   0.8659188034188035   0.9073034769463341   0.8498587570621469   \n",
       "21    0.8306565656565656   0.8872948328267478   0.7820987654320987   \n",
       "146   0.8186130672926447   0.8867691380349608    0.802446483180428   \n",
       "116   0.8419879767827528   0.8598639455782313   0.7892394822006473   \n",
       "66    0.8264949494949495   0.8968457468457468   0.8315068493150685   \n",
       "\n",
       "    Drugs that have at least one match  \n",
       "189                   [129, 44, 21, 6]  \n",
       "91                    [149, 52, 24, 8]  \n",
       "39                   [150, 47, 27, 10]  \n",
       "190                   [135, 40, 22, 3]  \n",
       "35                    [153, 28, 14, 2]  \n",
       "..                                 ...  \n",
       "141               [286, 252, 236, 206]  \n",
       "21                [275, 235, 216, 175]  \n",
       "146               [284, 237, 218, 180]  \n",
       "116               [268, 231, 206, 170]  \n",
       "66                [275, 234, 219, 188]  \n",
       "\n",
       "[200 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tests.sort_values(by = \"Precision nivel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "623b55c8-8163-4155-8329-c23cf637e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_tests.sort_values(by = \"Precision nivel1\")).to_csv(\"multimodalbilstm_sortedresults.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef9704-3b2c-473e-87df-d7911562c22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
