{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91a67c3-3164-402b-9c3d-ed5f98d41c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "from seq2seq import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58483fc7-4a85-42d3-93dd-b16044d8711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa18d3e-cd26-4b6a-85c0-cc550fb60feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string that simulates a list to a real list\n",
    "def convert_string_list(element):\n",
    "    # Delete [] of the string\n",
    "    element = element[0:len(element)]\n",
    "    # Create a list that contains each code as e.g. 'A'\n",
    "    ATC_list = list(element.split('; '))\n",
    "    for index, code in enumerate(ATC_list):\n",
    "        # Delete '' of the code\n",
    "        ATC_list[index] = code[0:len(code)]\n",
    "    return ATC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c013c98c-badd-464a-8c6f-6568e8ce8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../../Data/train_set.csv')\n",
    "test_set = pd.read_csv('../../Data/test_set.csv')\n",
    "val_set = pd.read_csv('../../Data/val_set.csv')\n",
    "set_seeds(78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdf13a86-4c48-475c-a5f3-ef21ffe19b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicate_rows(df):\n",
    "    # Duplicate each compound the number of ATC codes associated to it, copying its SMILES in new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        atc_codes = row['ATC Codes']\n",
    "        atc_codes_list = convert_string_list(atc_codes)\n",
    "        \n",
    "        if len(atc_codes_list) > 1:\n",
    "            for code in atc_codes_list:\n",
    "                if len(code) == 5:\n",
    "                    new_row = row.copy()\n",
    "                    new_row['ATC Codes'] = code\n",
    "                    new_rows.append(new_row)\n",
    "        else:\n",
    "            if len(atc_codes_list[0]) == 5:\n",
    "                new_rows.append(row)\n",
    "    \n",
    "    new_set = pd.DataFrame(new_rows)\n",
    "    new_set = new_set.reset_index(drop=True)\n",
    "\n",
    "    return new_set\n",
    "    \n",
    "# Create vocabularies\n",
    "# Tokenize the data\n",
    "def source(df):\n",
    "    source = []\n",
    "    for compound in df['Neutralized SMILES']:\n",
    "        # A list containing each SMILES character separated\n",
    "        source.append(list(compound))\n",
    "    return source\n",
    "def target(df):\n",
    "    target = []\n",
    "    for codes in df['ATC Codes']:  \n",
    "        code = convert_string_list(codes) \n",
    "        # A list of lists, each one containing each ATC code character separated \n",
    "        for c in code:\n",
    "            list_c = list(c)\n",
    "            target.append(list_c)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb280583-cbda-4ad4-b078-af63747f769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_set = multiplicate_rows(train_set)\n",
    "new_val_set = multiplicate_rows(val_set)\n",
    "new_test_set = multiplicate_rows(test_set)\n",
    "\n",
    "new_test_set.to_csv(\"onecodeperdrug_test_set.csv\", index = False)\n",
    "new_val_set.to_csv(\"onecodeperdrug_val_set.csv\", index = False)\n",
    "\n",
    "source_train = source(new_train_set)\n",
    "source_test = source(new_test_set)\n",
    "# Test set without duplicated compounds\n",
    "source_test2 = source(test_set)\n",
    "source_val = source(new_val_set)\n",
    "# Val set without duplicated compounds\n",
    "source_val2 = source(val_set)\n",
    "\n",
    "target_train = target(new_train_set)\n",
    "target_test = target(new_test_set)\n",
    "target_val = target(new_val_set)\n",
    "\n",
    "# An Index object represents a mapping from the vocabulary to integers (indices) to feed into the models\n",
    "source_index = index.Index(source_train)\n",
    "target_index = index.Index(target_train)\n",
    "\n",
    "# Create tensors\n",
    "X_train = source_index.text2tensor(source_train)\n",
    "y_train = target_index.text2tensor(target_train)\n",
    "X_val = source_index.text2tensor(source_val)\n",
    "X_val2 = source_index.text2tensor(source_val2)\n",
    "y_val = target_index.text2tensor(target_val)     \n",
    "X_test = source_index.text2tensor(source_test)\n",
    "X_test2 = source_index.text2tensor(source_test2)\n",
    "y_test = target_index.text2tensor(target_test)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X_train = X_train.to(\"cuda\")\n",
    "    y_train = y_train.to(\"cuda\")\n",
    "    X_val = X_val.to(\"cuda\")\n",
    "    X_val2 = X_val2.to(\"cuda\")\n",
    "    y_val = y_val.to(\"cuda\")\n",
    "    X_test= X_test.to(\"cuda\")\n",
    "    y_test = y_test.to(\"cuda\")\n",
    "    X_test2 = X_test2.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7641f295-ce61-41ee-be47-4a1803b58c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_grid = { \n",
    "    'enc_embedding_dim': [32, 64, 128],\n",
    "    'dec_embedding_dim': [32, 64, 128],\n",
    "    'enc_hidden_units': [32, 64, 128],\n",
    "    'dec_hidden_units': [32, 64, 128],\n",
    "    'enc_layers': [2, 3, 4],\n",
    "    'dec_layers': [2, 3, 4],\n",
    "    'dropout': [0.0, 0.1, 0.2],\n",
    "    'weight_decays': [10**-4, 10**-5],\n",
    "    'learning_rates': [10**-3, 10**-4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f2019a6-d989-48dc-a15c-7c21e9a3bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample from dictionary\n",
    "random_params = {k: random.sample(v, 1)[0] for k, v in hyperparameters_grid.items()}\n",
    "print(random_params['enc_embedding_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a490840-35bf-4fa9-8fe8-f70edf3ab319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_search(max_evals):\n",
    "    tested_params = set()\n",
    "    df_tests = pd.DataFrame(columns = ['#epochs', 'encoder_embedding_dim', 'decoder_embedding_dim', 'enc_layers', 'dec_layers', 'enc_hidden_units', 'dec_hidden_units', 'dropout', 'weight_decay', 'learning_rate', 'Precisionatn nivel1', 'Precisionatn nivel2', 'Precisionatn nivel3', 'Precisionatn nivel4', 'Precision nivel1', 'Precision nivel2', 'Precision nivel3', 'Precision nivel4', 'Recall nivel1', 'Recall nivel2', 'Recall nivel3', 'Recall nivel4', 'Drugs that have at least one match'], index = list(range(max_evals)))\n",
    "    sys.stdout = open('log.txt', 'w')\n",
    "    for i in range(max_evals):\n",
    "        while True:\n",
    "            random_params = {k: random.sample(v, 1)[0] for k, v in hyperparameters_grid.items()}\n",
    "            params_tuple = tuple(random_params.values())\n",
    "            if params_tuple not in tested_params:\n",
    "                tested_params.add(params_tuple)\n",
    "                break   \n",
    "        model = models.BiLSTM(\n",
    "                 source_index, \n",
    "                 target_index,\n",
    "                 encoder_embedding_dimension = random_params['enc_embedding_dim'],\n",
    "                 decoder_embedding_dimension = random_params['dec_embedding_dim'],\n",
    "                 encoder_hidden_units = random_params['enc_hidden_units'],\n",
    "                 encoder_layers = random_params['enc_layers'],\n",
    "                 decoder_hidden_units = random_params['dec_hidden_units'],\n",
    "                 decoder_layers = random_params['dec_layers'],\n",
    "                 dropout = random_params['dropout'])   \n",
    "        model.to(\"cuda\")\n",
    "        model.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                X_val, \n",
    "                y_val, \n",
    "                batch_size = 32, \n",
    "                epochs = 500, \n",
    "                learning_rate = random_params['learning_rates'], \n",
    "                weight_decay = random_params['weight_decays'],\n",
    "                progress_bar = 0, \n",
    "                save_path = None\n",
    "        ) \n",
    "        model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "        ep = model.early_stopping.best_epoch\n",
    "        loss, error_rate = model.evaluate(X_val, y_val)    \n",
    "        predictions, log_probabilities = search_algorithms.beam_search(\n",
    "            model, \n",
    "            X_val,\n",
    "            predictions = 6, # max length of the predicted sequence\n",
    "            beam_width = 3,\n",
    "            batch_size = 32, \n",
    "            progress_bar = 0\n",
    "        )\n",
    "        output_beam = [target_index.tensor2text(p) for p in predictions]\n",
    "        predictions2, log_probabilities2 = search_algorithms.beam_search(\n",
    "            model, \n",
    "            X_val2,\n",
    "            predictions = 6, # max length of the predicted sequence\n",
    "            beam_width = 3,\n",
    "            batch_size = 32, \n",
    "            progress_bar = 0\n",
    "        )\n",
    "        output_beam2 = [target_index.tensor2text(p) for p in predictions2]\n",
    "        \n",
    "        predictions_onecodeperdrug = []\n",
    "        for preds in output_beam:\n",
    "            interm = []\n",
    "            for pred in preds:\n",
    "                clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "                if len(clean_pred) == 5:\n",
    "                    interm.append(clean_pred)\n",
    "            predictions_onecodeperdrug.append(interm)\n",
    "                \n",
    "        predictions = []\n",
    "        for preds in output_beam2:\n",
    "            interm = []\n",
    "            for pred in preds:\n",
    "                clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "                if len(clean_pred) == 5:\n",
    "                    interm.append(clean_pred)\n",
    "            predictions.append(interm)\n",
    "                \n",
    "        precisionatn_1, precisionatn_2, precisionatn_3, precisionatn_4 = defined_metrics.precisionatn(predictions_onecodeperdrug, \"onecodeperdrug_val_set.csv\", 'ATC Codes')\n",
    "        precision_1, precision_2, precision_3, precision_4 = defined_metrics.precision(predictions, \"../../Data/val_set.csv\", 'ATC Codes')\n",
    "        recall_1, recall_2, recall_3, recall_4, comp = defined_metrics.recall(predictions, \"../../Data/val_set.csv\", 'ATC Codes')\n",
    "        df_tests.iloc[i, :] = [f\"{ep}\", f\"{random_params['enc_embedding_dim']}\", f\"{random_params['dec_embedding_dim']}\", f\"{random_params['enc_layers']}\", f\"{random_params['dec_layers']}\", f\"{random_params['enc_hidden_units']}\", f\"{random_params['dec_hidden_units']}\", f\"{random_params['dropout']}\", f\"{random_params['weight_decays']}\", f\"{random_params['learning_rates']}\", f\"{precisionatn_1}\", f\"{precisionatn_2}\", f\"{precisionatn_3}\", f\"{precisionatn_4}\", f\"{precision_1}\", f\"{precision_2}\", f\"{precision_3}\", f\"{precision_4}\", f\"{recall_1}\", f\"{recall_2}\", f\"{recall_3}\", f\"{recall_4}\", f\"{comp}\"]\n",
    "        df_tests.to_csv(\"bilstm_results.csv\", index = False)\n",
    "    sys.stdout = sys.__stdout__\n",
    "    return df_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15be5934-9315-4279-8ce0-ef8f4388c811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tests = random_search(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4a48ca1-35fc-4558-bd5b-4d5557d9ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "# from matplotlib.lines import Line2D\n",
    "\n",
    "# # Cargar datos\n",
    "# df_res = pd.read_csv(\"results_transformer.csv\")\n",
    "# df_res = df_res[[\"embedding_dim\", \"enc_layers\", \"dec_layers\", \"attention_heads\", \"dropout\", \n",
    "#                  \"weight_decay\", \"learning_rate\", \"Precision nivel1\", \"Recall nivel1\"]]\n",
    "\n",
    "# size_map = {32: 100, 64: 200, 128: 300}\n",
    "# df_res['embedding dimension'] = df_res['embedding_dim'].map(size_map)\n",
    "# # Normalizar tamaño de los puntos\n",
    "# # df_res['embedding dimension'] = (df_res['embedding_dim'] - df_res['embedding_dim'].min()) / (df_res['embedding_dim'].max() - df_res['embedding_dim'].min()) * 100 + 50\n",
    "\n",
    "# df_res['encoder and decoder layers'] = df_res.apply(\n",
    "#     lambda row: f'enc_{int(row[\"enc_layers\"])} - dec_{int(row[\"dec_layers\"])}', axis=1)\n",
    "# df_res['weight_decay and learning_rate'] = df_res.apply(\n",
    "#     lambda row: f'WD_{row[\"weight_decay\"]} - LR_{row[\"learning_rate\"]}', axis=1)\n",
    "\n",
    "# # Mapear 'dropout' a formas\n",
    "# dropout_map = {0.0: 'o', 0.1: '^', 0.2: 's'}\n",
    "# df_res['dropout value'] = df_res['dropout'].map(dropout_map)\n",
    "\n",
    "# df_res['edgewidth'] = df_res['attention_heads'].map({2: 1.0, 4: 2.0})\n",
    "# color_palette = sns.color_palette(\"Pastel1\", n_colors=df_res['encoder and decoder layers'].nunique())\n",
    "\n",
    "# # Mapa de colores para 'weight_decay and learning_rate'\n",
    "# unique_wd_lr = df_res['weight_decay and learning_rate'].unique()\n",
    "# color_palette2 = sns.color_palette(\"Set1\", n_colors=len(unique_wd_lr))\n",
    "# wd_lr_color_map = dict(zip(unique_wd_lr, color_palette2))\n",
    "\n",
    "# # Mapa de colores para 'encoder and decoder layers'\n",
    "# unique_enc_dec = df_res['encoder and decoder layers'].unique()\n",
    "# enc_dec_color_map = dict(zip(unique_enc_dec, color_palette))\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "\n",
    "# # Dibujar puntos con Matplotlib\n",
    "# for i, row in df_res.iterrows():\n",
    "#     plt.scatter(\n",
    "#         x=row['Precision nivel1'],\n",
    "#         y=row['Recall nivel1'],\n",
    "#         s=row['embedding dimension'],  # Tamaño de los puntos\n",
    "#         color=enc_dec_color_map[row['encoder and decoder layers']],  # Color del punto\n",
    "#         marker=row['dropout value'],  # Forma del punto\n",
    "#         edgecolor=wd_lr_color_map[row['weight_decay and learning_rate']],  # Borde basado en mapa precalculado\n",
    "#         linewidth=row['edgewidth'],  # Grosor del borde\n",
    "#         alpha=0.7\n",
    "#     )\n",
    "    \n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], color='none', label='Dropout'),\n",
    "#     Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markersize=10, label='Dropout 0.0'),\n",
    "#     Line2D([0], [0], marker='^', color='w', markerfacecolor='black', markersize=10, label='Dropout 0.1'),\n",
    "#     Line2D([0], [0], marker='s', color='w', markerfacecolor='black', markersize=10, label='Dropout 0.2'),\n",
    "#     Line2D([0], [0], color='none', label='Attention heads'),\n",
    "#     Line2D([0], [0], color='black', linewidth=1.0, label='2 attention heads'),\n",
    "#     Line2D([0], [0], color='black', linewidth=2.0, label='4 attention heads'),\n",
    "#     Line2D([0], [0], color='none', label='Encoder - Decoder layers'),\n",
    "#     *[Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10, label=label) for label, color in enc_dec_color_map.items()],\n",
    "#     Line2D([0], [0], color='none', label='Weight decay - Learning rate'),\n",
    "#     *[Line2D([0], [0], marker='o', color='w', markeredgecolor=color, markerfacecolor='none', markersize=10, label=label) for label, color in wd_lr_color_map.items()]\n",
    "# ]\n",
    "\n",
    "# size_mapping = {\n",
    "#     100: \"32\",\n",
    "#     200: \"64\",\n",
    "#     300: \"128\"\n",
    "# }\n",
    "\n",
    "# size_legend = [\n",
    "#     Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markersize=size/18, label=f'{size_mapping.get(int(size))}') \n",
    "#     for size in df_res['embedding dimension'].unique() \n",
    "# ]\n",
    "\n",
    "# plt.legend(title='Hiperparámetros', handles=[Line2D([0], [0], color='none', label='Embedding Dimension')] + size_legend + legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "# plt.title(\"Combinación de hiperparámetros\", fontsize=16)\n",
    "# plt.xlabel(\"Precision nivel 1\", fontsize=14)\n",
    "# plt.ylabel(\"Recall nivel 1\", fontsize=14)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('multimodaltransformer_hyperparams.png', bbox_inches='tight')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573e653c-499a-43e0-9695-9b2e14d591c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#epochs</th>\n",
       "      <th>encoder_embedding_dim</th>\n",
       "      <th>decoder_embedding_dim</th>\n",
       "      <th>enc_layers</th>\n",
       "      <th>dec_layers</th>\n",
       "      <th>enc_hidden_units</th>\n",
       "      <th>dec_hidden_units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Precisionatn nivel4</th>\n",
       "      <th>Precision nivel1</th>\n",
       "      <th>Precision nivel2</th>\n",
       "      <th>Precision nivel3</th>\n",
       "      <th>Precision nivel4</th>\n",
       "      <th>Recall nivel1</th>\n",
       "      <th>Recall nivel2</th>\n",
       "      <th>Recall nivel3</th>\n",
       "      <th>Recall nivel4</th>\n",
       "      <th>Drugs that have at least one match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>294</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>84.21052631578947</td>\n",
       "      <td>0.1309216192937123</td>\n",
       "      <td>0.2727272727272727</td>\n",
       "      <td>0.6333333333333333</td>\n",
       "      <td>0.6052631578947368</td>\n",
       "      <td>0.26546080964685614</td>\n",
       "      <td>0.2681818181818182</td>\n",
       "      <td>0.6166666666666667</td>\n",
       "      <td>0.8421052631578947</td>\n",
       "      <td>[110, 30, 19, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>269</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.14211886304909555</td>\n",
       "      <td>0.2196969696969697</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.26485788113695086</td>\n",
       "      <td>0.22272727272727272</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[110, 25, 10, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>228</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.14728682170542637</td>\n",
       "      <td>0.20216049382716048</td>\n",
       "      <td>0.5466666666666667</td>\n",
       "      <td>0.4642857142857143</td>\n",
       "      <td>0.26076658053402235</td>\n",
       "      <td>0.21862139917695472</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[108, 25, 14, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>133</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>57.57575757575758</td>\n",
       "      <td>0.15073212747631362</td>\n",
       "      <td>0.37926509186351703</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.4494949494949495</td>\n",
       "      <td>0.31201550387596894</td>\n",
       "      <td>0.378827646544182</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.5757575757575758</td>\n",
       "      <td>[127, 50, 33, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>239</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>64.28571428571429</td>\n",
       "      <td>0.1515934539190354</td>\n",
       "      <td>0.3364485981308411</td>\n",
       "      <td>0.6495726495726496</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2592592592592593</td>\n",
       "      <td>0.3561786085150571</td>\n",
       "      <td>0.6923076923076923</td>\n",
       "      <td>0.6428571428571429</td>\n",
       "      <td>[107, 39, 28, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>45</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>78.19905213270142</td>\n",
       "      <td>0.4651162790697675</td>\n",
       "      <td>0.6464435146443513</td>\n",
       "      <td>0.7855902777777778</td>\n",
       "      <td>0.6861598440545809</td>\n",
       "      <td>0.5929514786103933</td>\n",
       "      <td>0.775092980009298</td>\n",
       "      <td>0.8472470238095237</td>\n",
       "      <td>0.8115009746588693</td>\n",
       "      <td>[239, 192, 171, 144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>28</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>83.33333333333334</td>\n",
       "      <td>0.47200689061154183</td>\n",
       "      <td>0.7009222661396575</td>\n",
       "      <td>0.7629107981220657</td>\n",
       "      <td>0.7138888888888889</td>\n",
       "      <td>0.627878265862762</td>\n",
       "      <td>0.8208058849363199</td>\n",
       "      <td>0.8108540129666889</td>\n",
       "      <td>0.8537037037037039</td>\n",
       "      <td>[253, 213, 180, 159]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>39</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>76.036866359447</td>\n",
       "      <td>0.4737295434969856</td>\n",
       "      <td>0.7319727891156462</td>\n",
       "      <td>0.7315270935960592</td>\n",
       "      <td>0.6505681818181818</td>\n",
       "      <td>0.5989376973873098</td>\n",
       "      <td>0.8186281179138323</td>\n",
       "      <td>0.8371979826413324</td>\n",
       "      <td>0.7931818181818181</td>\n",
       "      <td>[245, 203, 176, 147]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>67.8048780487805</td>\n",
       "      <td>0.4909560723514214</td>\n",
       "      <td>0.640456989247312</td>\n",
       "      <td>0.782986111111111</td>\n",
       "      <td>0.5994152046783625</td>\n",
       "      <td>0.5972437553832902</td>\n",
       "      <td>0.7477598566308243</td>\n",
       "      <td>0.8566592261904762</td>\n",
       "      <td>0.713840155945419</td>\n",
       "      <td>[248, 192, 171, 129]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>84.18972332015811</td>\n",
       "      <td>0.4926787252368652</td>\n",
       "      <td>0.7120051085568323</td>\n",
       "      <td>0.8234398782343988</td>\n",
       "      <td>0.7272727272727273</td>\n",
       "      <td>0.6497846683893196</td>\n",
       "      <td>0.8195828011919967</td>\n",
       "      <td>0.8763861709067188</td>\n",
       "      <td>0.8643939393939394</td>\n",
       "      <td>[261, 219, 198, 179]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    #epochs encoder_embedding_dim decoder_embedding_dim enc_layers dec_layers  \\\n",
       "59      294                    64                    32          4          4   \n",
       "14      269                    32                   128          3          4   \n",
       "193     228                    64                   128          2          4   \n",
       "114     133                    32                    64          2          4   \n",
       "163     239                    64                   128          2          3   \n",
       "..      ...                   ...                   ...        ...        ...   \n",
       "128      45                   128                    32          2          2   \n",
       "99       28                    64                    64          4          2   \n",
       "144      39                   128                    32          2          2   \n",
       "101      40                   128                   128          3          2   \n",
       "6        26                   128                   128          4          2   \n",
       "\n",
       "    enc_hidden_units dec_hidden_units dropout weight_decay learning_rate  ...  \\\n",
       "59                32               64     0.0       0.0001        0.0001  ...   \n",
       "14                32               32     0.1       0.0001        0.0001  ...   \n",
       "193               32               32     0.0       0.0001        0.0001  ...   \n",
       "114               32              128     0.0        1e-05        0.0001  ...   \n",
       "163               32               32     0.2        1e-05        0.0001  ...   \n",
       "..               ...              ...     ...          ...           ...  ...   \n",
       "128              128              128     0.1       0.0001         0.001  ...   \n",
       "99               128              128     0.2        1e-05         0.001  ...   \n",
       "144              128               64     0.1        1e-05         0.001  ...   \n",
       "101              128               32     0.1        1e-05         0.001  ...   \n",
       "6                128              128     0.2        1e-05         0.001  ...   \n",
       "\n",
       "    Precisionatn nivel4     Precision nivel1     Precision nivel2  \\\n",
       "59    84.21052631578947   0.1309216192937123   0.2727272727272727   \n",
       "14                 20.0  0.14211886304909555   0.2196969696969697   \n",
       "193                50.0  0.14728682170542637  0.20216049382716048   \n",
       "114   57.57575757575758  0.15073212747631362  0.37926509186351703   \n",
       "163   64.28571428571429   0.1515934539190354   0.3364485981308411   \n",
       "..                  ...                  ...                  ...   \n",
       "128   78.19905213270142   0.4651162790697675   0.6464435146443513   \n",
       "99    83.33333333333334  0.47200689061154183   0.7009222661396575   \n",
       "144     76.036866359447   0.4737295434969856   0.7319727891156462   \n",
       "101    67.8048780487805   0.4909560723514214    0.640456989247312   \n",
       "6     84.18972332015811   0.4926787252368652   0.7120051085568323   \n",
       "\n",
       "       Precision nivel3    Precision nivel4        Recall nivel1  \\\n",
       "59   0.6333333333333333  0.6052631578947368  0.26546080964685614   \n",
       "14                  0.4                0.15  0.26485788113695086   \n",
       "193  0.5466666666666667  0.4642857142857143  0.26076658053402235   \n",
       "114                0.62  0.4494949494949495  0.31201550387596894   \n",
       "163  0.6495726495726496                 0.5   0.2592592592592593   \n",
       "..                  ...                 ...                  ...   \n",
       "128  0.7855902777777778  0.6861598440545809   0.5929514786103933   \n",
       "99   0.7629107981220657  0.7138888888888889    0.627878265862762   \n",
       "144  0.7315270935960592  0.6505681818181818   0.5989376973873098   \n",
       "101   0.782986111111111  0.5994152046783625   0.5972437553832902   \n",
       "6    0.8234398782343988  0.7272727272727273   0.6497846683893196   \n",
       "\n",
       "           Recall nivel2       Recall nivel3       Recall nivel4  \\\n",
       "59    0.2681818181818182  0.6166666666666667  0.8421052631578947   \n",
       "14   0.22272727272727272                 0.4                 0.2   \n",
       "193  0.21862139917695472                0.54                 0.5   \n",
       "114    0.378827646544182                0.65  0.5757575757575758   \n",
       "163   0.3561786085150571  0.6923076923076923  0.6428571428571429   \n",
       "..                   ...                 ...                 ...   \n",
       "128    0.775092980009298  0.8472470238095237  0.8115009746588693   \n",
       "99    0.8208058849363199  0.8108540129666889  0.8537037037037039   \n",
       "144   0.8186281179138323  0.8371979826413324  0.7931818181818181   \n",
       "101   0.7477598566308243  0.8566592261904762   0.713840155945419   \n",
       "6     0.8195828011919967  0.8763861709067188  0.8643939393939394   \n",
       "\n",
       "    Drugs that have at least one match  \n",
       "59                   [110, 30, 19, 16]  \n",
       "14                    [110, 25, 10, 2]  \n",
       "193                   [108, 25, 14, 7]  \n",
       "114                  [127, 50, 33, 19]  \n",
       "163                  [107, 39, 28, 18]  \n",
       "..                                 ...  \n",
       "128               [239, 192, 171, 144]  \n",
       "99                [253, 213, 180, 159]  \n",
       "144               [245, 203, 176, 147]  \n",
       "101               [248, 192, 171, 129]  \n",
       "6                 [261, 219, 198, 179]  \n",
       "\n",
       "[200 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tests.sort_values(by = \"Precision nivel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "623b55c8-8163-4155-8329-c23cf637e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_tests.sort_values(by = \"Precision nivel1\")).to_csv(\"bilstm_sortedresults.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
