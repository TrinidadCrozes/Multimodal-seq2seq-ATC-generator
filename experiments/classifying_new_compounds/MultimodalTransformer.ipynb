{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91a67c3-3164-402b-9c3d-ed5f98d41c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "from seq2seq import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566324b4-cf15-44bc-9f49-c6c019367e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa18d3e-cd26-4b6a-85c0-cc550fb60feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string that simulates a list to a real list\n",
    "def convert_string_list(element):\n",
    "    # Delete [] of the string\n",
    "    element = element[0:len(element)]\n",
    "    # Create a list that contains each code as e.g. 'A'\n",
    "    ATC_list = list(element.split('; '))\n",
    "    for index, code in enumerate(ATC_list):\n",
    "        # Delete '' of the code\n",
    "        ATC_list[index] = code[0:len(code)]\n",
    "    return ATC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e165f52-d611-4847-a003-d336dd9fe491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicate_rows(df):\n",
    "    # Duplicate each compound the number of ATC codes associated to it, copying its SMILES in new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        atc_codes = row['ATC Codes']\n",
    "        atc_codes_list = convert_string_list(atc_codes)\n",
    "        \n",
    "        if len(atc_codes_list) > 1:\n",
    "            for code in atc_codes_list:\n",
    "                if len(code) == 5:\n",
    "                    new_row = row.copy()\n",
    "                    new_row['ATC Codes'] = code\n",
    "                    new_rows.append(new_row)\n",
    "        else:\n",
    "            if len(atc_codes_list[0]) == 5:\n",
    "                new_rows.append(row)\n",
    "    \n",
    "    new_set = pd.DataFrame(new_rows)\n",
    "    new_set = new_set.reset_index(drop=True)\n",
    "\n",
    "    return new_set\n",
    "\n",
    "def extract_descriptors(df):\n",
    "    \"\"\"\n",
    "    Extract molecular descriptors from your dataset.\n",
    "    You'll need to implement this based on your descriptor source.\n",
    "    \n",
    "    Returns FloatTensor of shape (n_molecules, descriptor_dimension)\n",
    "    \"\"\"\n",
    "    descriptors = df.iloc[:, 2:-5].values\n",
    "    # Convert to numpy for easier handling\n",
    "    if isinstance(descriptors, torch.Tensor):\n",
    "        desc_array = descriptors.numpy()\n",
    "    else:\n",
    "        desc_array = np.array(descriptors)\n",
    "    # Replace infinite values with NaN first\n",
    "    desc_array[np.isinf(desc_array)] = np.nan\n",
    "    \n",
    "    # Calculate median for each feature (column-wise)\n",
    "    medians = np.nanmedian(desc_array, axis=0)\n",
    "    \n",
    "    # Replace NaN values with corresponding median\n",
    "    for i in range(desc_array.shape[1]):\n",
    "        mask = np.isnan(desc_array[:, i])\n",
    "        desc_array[mask, i] = medians[i]\n",
    "    return torch.tensor(desc_array, dtype=torch.float32)\n",
    "    \n",
    "# Create vocabularies\n",
    "# Tokenize the data\n",
    "def source(df):\n",
    "    source = []\n",
    "    for compound in df['Neutralized SMILES']:\n",
    "        # A list containing each SMILES character separated\n",
    "        source.append(list(compound))\n",
    "    return source\n",
    "def target(df):\n",
    "    target = []\n",
    "    for codes in df['ATC Codes']:  \n",
    "        code = convert_string_list(codes) \n",
    "        # A list of lists, each one containing each ATC code character separated \n",
    "        for c in code:\n",
    "            list_c = list(c)\n",
    "            target.append(list_c)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3256e6-ad40-454b-80a0-e415b76ab19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 43 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,346\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3057, 702])\n",
      "Y_train.shape: torch.Size([3057, 7])\n",
      "X_dev.shape: torch.Size([546, 337])\n",
      "Y_dev.shape: torch.Size([546, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.9469 |     50.273 |   1.4584 |     43.651 |     0.2\n",
      "    2 |   1.3092 |     39.576 |   1.2756 |     38.828 |     0.4\n",
      "    3 |   1.1661 |     35.863 |   1.1842 |     36.142 |     0.6\n",
      "    4 |   1.0628 |     33.110 |   1.1212 |     34.860 |     0.8\n",
      "    5 |   0.9767 |     30.738 |   1.0837 |     33.944 |     1.0\n",
      "    6 |   0.9016 |     28.557 |   1.0070 |     32.143 |     1.1\n",
      "    7 |   0.8344 |     26.360 |   0.9881 |     31.807 |     1.3\n",
      "    8 |   0.7682 |     24.043 |   0.9511 |     29.884 |     1.5\n",
      "    9 |   0.7143 |     22.108 |   0.9281 |     29.151 |     1.7\n",
      "   10 |   0.6722 |     21.219 |   0.9156 |     29.365 |     1.9\n",
      "   11 |   0.6252 |     19.627 |   0.8666 |     27.289 |     2.1\n",
      "   12 |   0.5777 |     18.122 |   0.8923 |     27.167 |     2.3\n",
      "   13 |   0.5541 |     17.632 |   0.8611 |     26.374 |     2.4\n",
      "   14 |   0.5169 |     16.405 |   0.8668 |     27.106 |     2.6\n",
      "   15 |   0.4848 |     15.489 |   0.8826 |     26.954 |     2.8\n",
      "   16 |   0.4548 |     14.159 |   0.8599 |     25.336 |     3.0\n",
      "   17 |   0.4303 |     13.739 |   0.8351 |     25.946 |     3.2\n",
      "   18 |   0.4070 |     13.057 |   0.8508 |     26.007 |     3.4\n",
      "   19 |   0.3834 |     12.540 |   0.8742 |     25.794 |     3.5\n",
      "   20 |   0.3647 |     11.722 |   0.8561 |     25.519 |     3.7\n",
      "   21 |   0.3456 |     11.264 |   0.8660 |     25.488 |     3.9\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Temp\\ipykernel_11092\\3793583644.py:187: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n",
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,602\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3048, 649])\n",
      "Y_train.shape: torch.Size([3048, 7])\n",
      "X_dev.shape: torch.Size([541, 337])\n",
      "Y_dev.shape: torch.Size([541, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.9461 |     50.421 |   1.4390 |     43.500 |     0.2\n",
      "    2 |   1.3260 |     40.890 |   1.2568 |     38.201 |     0.3\n",
      "    3 |   1.1848 |     36.822 |   1.1457 |     35.336 |     0.5\n",
      "    4 |   1.0788 |     33.547 |   1.0940 |     33.672 |     0.7\n",
      "    5 |   0.9950 |     30.971 |   1.0354 |     32.840 |     0.9\n",
      "    6 |   0.9152 |     28.614 |   0.9863 |     31.392 |     1.1\n",
      "    7 |   0.8502 |     26.526 |   0.9614 |     30.468 |     1.2\n",
      "    8 |   0.7907 |     24.880 |   0.9235 |     28.928 |     1.4\n",
      "    9 |   0.7275 |     22.977 |   0.9017 |     27.726 |     1.6\n",
      "   10 |   0.6810 |     21.140 |   0.9109 |     28.250 |     1.8\n",
      "   11 |   0.6357 |     20.051 |   0.8920 |     26.987 |     2.0\n",
      "   12 |   0.5907 |     18.323 |   0.8741 |     26.802 |     2.1\n",
      "   13 |   0.5535 |     17.323 |   0.8618 |     26.278 |     2.3\n",
      "   14 |   0.5139 |     15.989 |   0.8776 |     26.278 |     2.5\n",
      "   15 |   0.4806 |     15.037 |   0.8569 |     24.985 |     2.7\n",
      "   16 |   0.4493 |     14.124 |   0.8623 |     24.738 |     2.8\n",
      "   17 |   0.4209 |     13.468 |   0.8558 |     24.985 |     3.0\n",
      "   18 |   0.4046 |     12.713 |   0.8665 |     25.354 |     3.2\n",
      "   19 |   0.3784 |     12.216 |   0.8602 |     24.522 |     3.4\n",
      "   20 |   0.3586 |     11.614 |   0.8663 |     24.677 |     3.5\n",
      "   21 |   0.3411 |     11.319 |   0.8711 |     24.338 |     3.7\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 44 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,474\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3064, 649])\n",
      "Y_train.shape: torch.Size([3064, 7])\n",
      "X_dev.shape: torch.Size([541, 702])\n",
      "Y_dev.shape: torch.Size([541, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.9362 |     51.110 |   1.4153 |     43.222 |     0.2\n",
      "    2 |   1.3174 |     40.535 |   1.2632 |     39.248 |     0.4\n",
      "    3 |   1.1828 |     36.858 |   1.1635 |     36.630 |     0.5\n",
      "    4 |   1.0743 |     33.491 |   1.1002 |     35.336 |     0.7\n",
      "    5 |   0.9879 |     31.000 |   1.0477 |     33.426 |     0.9\n",
      "    6 |   0.9101 |     28.492 |   1.0208 |     32.840 |     1.1\n",
      "    7 |   0.8442 |     26.523 |   0.9728 |     30.776 |     1.3\n",
      "    8 |   0.7826 |     24.260 |   0.9578 |     29.267 |     1.4\n",
      "    9 |   0.7229 |     22.520 |   0.9186 |     29.051 |     1.6\n",
      "   10 |   0.6693 |     20.997 |   0.9063 |     28.343 |     1.8\n",
      "   11 |   0.6257 |     19.479 |   0.8976 |     27.665 |     2.0\n",
      "   12 |   0.5893 |     18.614 |   0.8868 |     27.388 |     2.2\n",
      "   13 |   0.5444 |     16.960 |   0.8747 |     26.587 |     2.3\n",
      "   14 |   0.5146 |     16.030 |   0.8759 |     27.449 |     2.5\n",
      "   15 |   0.4835 |     15.187 |   0.8651 |     25.385 |     2.7\n",
      "   16 |   0.4547 |     14.311 |   0.8587 |     26.217 |     2.9\n",
      "   17 |   0.4258 |     13.408 |   0.8626 |     25.940 |     3.1\n",
      "   18 |   0.4051 |     13.049 |   0.8594 |     24.985 |     3.3\n",
      "   19 |   0.3799 |     12.168 |   0.8654 |     25.508 |     3.4\n",
      "   20 |   0.3599 |     11.472 |   0.8487 |     25.200 |     3.6\n",
      "   21 |   0.3395 |     10.884 |   0.8781 |     25.200 |     3.8\n",
      "   22 |   0.3234 |     10.319 |   0.8548 |     24.276 |     4.0\n",
      "   23 |   0.3121 |     10.205 |   0.8654 |     24.522 |     4.2\n",
      "   24 |   0.2968 |      9.704 |   0.8783 |     24.800 |     4.4\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 43 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,346\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3072, 702])\n",
      "Y_train.shape: torch.Size([3072, 7])\n",
      "X_dev.shape: torch.Size([566, 649])\n",
      "Y_dev.shape: torch.Size([566, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.9545 |     50.743 |   1.4650 |     44.346 |     0.2\n",
      "    2 |   1.3304 |     40.614 |   1.2966 |     40.047 |     0.4\n",
      "    3 |   1.1891 |     36.643 |   1.1962 |     37.574 |     0.6\n",
      "    4 |   1.0848 |     34.093 |   1.1233 |     35.012 |     0.7\n",
      "    5 |   1.0034 |     31.727 |   1.0559 |     33.746 |     0.9\n",
      "    6 |   0.9236 |     29.308 |   1.0190 |     32.715 |     1.1\n",
      "    7 |   0.8485 |     26.752 |   0.9964 |     31.832 |     1.3\n",
      "    8 |   0.7893 |     25.174 |   0.9726 |     31.037 |     1.5\n",
      "    9 |   0.7364 |     23.579 |   0.9331 |     29.388 |     1.7\n",
      "   10 |   0.6809 |     21.555 |   0.9004 |     28.210 |     1.9\n",
      "   11 |   0.6319 |     19.835 |   0.9042 |     28.445 |     2.1\n",
      "   12 |   0.5981 |     18.842 |   0.8976 |     28.681 |     2.3\n",
      "   13 |   0.5581 |     17.839 |   0.8968 |     27.621 |     2.5\n",
      "   14 |   0.5165 |     16.401 |   0.8817 |     26.855 |     2.7\n",
      "   15 |   0.4870 |     15.435 |   0.8835 |     26.443 |     2.8\n",
      "   16 |   0.4532 |     14.399 |   0.8961 |     26.443 |     3.0\n",
      "   17 |   0.4358 |     14.068 |   0.8642 |     25.471 |     3.2\n",
      "   18 |   0.4012 |     12.712 |   0.8827 |     26.207 |     3.4\n",
      "   19 |   0.3819 |     12.598 |   0.8711 |     25.501 |     3.6\n",
      "   20 |   0.3600 |     11.697 |   0.8923 |     26.001 |     3.8\n",
      "   21 |   0.3518 |     11.420 |   0.8912 |     25.383 |     4.0\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,602\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3034, 702])\n",
      "Y_train.shape: torch.Size([3034, 7])\n",
      "X_dev.shape: torch.Size([542, 350])\n",
      "Y_dev.shape: torch.Size([542, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.8831 |     49.863 |   1.4242 |     43.020 |     0.2\n",
      "    2 |   1.3054 |     39.788 |   1.2654 |     39.545 |     0.4\n",
      "    3 |   1.1691 |     36.250 |   1.1755 |     36.654 |     0.5\n",
      "    4 |   1.0773 |     33.553 |   1.1067 |     35.240 |     0.7\n",
      "    5 |   0.9871 |     30.850 |   1.0882 |     34.871 |     0.9\n",
      "    6 |   0.9090 |     28.587 |   1.0083 |     32.042 |     1.1\n",
      "    7 |   0.8333 |     26.230 |   0.9721 |     30.443 |     1.3\n",
      "    8 |   0.7729 |     24.116 |   0.9395 |     29.305 |     1.5\n",
      "    9 |   0.7170 |     22.275 |   0.9300 |     28.444 |     1.7\n",
      "   10 |   0.6638 |     20.743 |   0.9159 |     29.244 |     1.9\n",
      "   11 |   0.6140 |     19.062 |   0.8733 |     26.845 |     2.1\n",
      "   12 |   0.5683 |     17.425 |   0.8736 |     26.691 |     2.3\n",
      "   13 |   0.5268 |     16.463 |   0.8838 |     25.861 |     2.5\n",
      "   14 |   0.4999 |     15.661 |   0.8558 |     26.230 |     2.7\n",
      "   15 |   0.4691 |     14.750 |   0.8529 |     25.769 |     2.9\n",
      "   16 |   0.4367 |     13.827 |   0.8689 |     25.892 |     3.1\n",
      "   17 |   0.4125 |     12.887 |   0.8801 |     25.523 |     3.3\n",
      "   18 |   0.3896 |     12.162 |   0.8707 |     25.492 |     3.5\n",
      "   19 |   0.3664 |     11.607 |   0.8671 |     25.062 |     3.7\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,602\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3059, 350])\n",
      "Y_train.shape: torch.Size([3059, 7])\n",
      "X_dev.shape: torch.Size([553, 649])\n",
      "Y_dev.shape: torch.Size([553, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.9504 |     51.607 |   1.4308 |     42.405 |     0.1\n",
      "    2 |   1.3009 |     39.457 |   1.2570 |     39.150 |     0.2\n",
      "    3 |   1.1452 |     35.088 |   1.1604 |     35.955 |     0.3\n",
      "    4 |   1.0369 |     32.129 |   1.1118 |     35.413 |     0.4\n",
      "    5 |   0.9540 |     30.070 |   1.0605 |     33.876 |     0.5\n",
      "    6 |   0.8833 |     27.907 |   1.0343 |     32.791 |     0.6\n",
      "    7 |   0.8181 |     25.782 |   1.0040 |     32.459 |     0.7\n",
      "    8 |   0.7546 |     23.646 |   0.9489 |     29.717 |     0.9\n",
      "    9 |   0.7103 |     22.562 |   0.9275 |     29.566 |     1.0\n",
      "   10 |   0.6649 |     20.818 |   0.9514 |     30.500 |     1.1\n",
      "   11 |   0.6182 |     19.369 |   0.9302 |     27.788 |     1.2\n",
      "   12 |   0.5712 |     17.691 |   0.9007 |     27.848 |     1.3\n",
      "   13 |   0.5395 |     17.250 |   0.8774 |     27.155 |     1.4\n",
      "   14 |   0.5080 |     16.133 |   0.8814 |     26.944 |     1.5\n",
      "   15 |   0.4752 |     15.076 |   0.8863 |     27.456 |     1.6\n",
      "   16 |   0.4395 |     14.090 |   0.8663 |     25.407 |     1.7\n",
      "   17 |   0.4197 |     13.479 |   0.8791 |     25.980 |     1.8\n",
      "   18 |   0.3932 |     12.640 |   0.8858 |     26.371 |     1.9\n",
      "   19 |   0.3792 |     12.264 |   0.9155 |     26.341 |     2.1\n",
      "   20 |   0.3548 |     11.660 |   0.8931 |     26.100 |     2.2\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,602\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3063, 649])\n",
      "Y_train.shape: torch.Size([3063, 7])\n",
      "X_dev.shape: torch.Size([558, 702])\n",
      "Y_dev.shape: torch.Size([558, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.9813 |     51.366 |   1.4254 |     41.577 |     0.2\n",
      "    2 |   1.3462 |     40.913 |   1.2551 |     39.427 |     0.4\n",
      "    3 |   1.2001 |     36.990 |   1.1552 |     35.394 |     0.6\n",
      "    4 |   1.0900 |     34.111 |   1.0951 |     34.498 |     0.8\n",
      "    5 |   0.9952 |     31.004 |   1.0362 |     32.826 |     1.0\n",
      "    6 |   0.9243 |     29.078 |   1.0067 |     32.049 |     1.2\n",
      "    7 |   0.8503 |     26.766 |   0.9651 |     30.137 |     1.4\n",
      "    8 |   0.7897 |     25.008 |   0.9437 |     30.317 |     1.6\n",
      "    9 |   0.7321 |     23.142 |   0.8914 |     28.823 |     1.8\n",
      "   10 |   0.6734 |     21.319 |   0.8879 |     27.419 |     1.9\n",
      "   11 |   0.6381 |     20.541 |   0.8659 |     27.599 |     2.1\n",
      "   12 |   0.5929 |     18.685 |   0.8523 |     27.270 |     2.3\n",
      "   13 |   0.5514 |     17.390 |   0.8583 |     27.121 |     2.5\n",
      "   14 |   0.5169 |     16.133 |   0.8559 |     25.478 |     2.7\n",
      "   15 |   0.4821 |     15.508 |   0.8934 |     27.031 |     2.9\n",
      "   16 |   0.4565 |     14.561 |   0.8474 |     25.926 |     3.1\n",
      "   17 |   0.4264 |     13.690 |   0.8398 |     25.179 |     3.3\n",
      "   18 |   0.4078 |     13.054 |   0.8400 |     24.761 |     3.5\n",
      "   19 |   0.3778 |     12.466 |   0.8468 |     25.030 |     3.7\n",
      "   20 |   0.3672 |     11.764 |   0.8427 |     24.223 |     3.9\n",
      "   21 |   0.3412 |     11.318 |   0.8618 |     24.313 |     4.1\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 44 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,474\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3052, 702])\n",
      "Y_train.shape: torch.Size([3052, 7])\n",
      "X_dev.shape: torch.Size([533, 266])\n",
      "Y_dev.shape: torch.Size([533, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.0189 |     53.866 |   1.4124 |     42.933 |     0.2\n",
      "    2 |   1.3188 |     40.312 |   1.2509 |     38.962 |     0.4\n",
      "    3 |   1.1852 |     36.730 |   1.1675 |     35.679 |     0.6\n",
      "    4 |   1.0902 |     34.207 |   1.1139 |     34.709 |     0.8\n",
      "    5 |   1.0042 |     31.684 |   1.0412 |     32.145 |     1.0\n",
      "    6 |   0.9275 |     29.298 |   1.0089 |     31.488 |     1.2\n",
      "    7 |   0.8606 |     26.933 |   0.9679 |     30.300 |     1.4\n",
      "    8 |   0.7939 |     25.066 |   0.9372 |     29.174 |     1.6\n",
      "    9 |   0.7342 |     23.001 |   0.9194 |     27.705 |     1.8\n",
      "   10 |   0.6833 |     21.532 |   0.8989 |     27.830 |     2.0\n",
      "   11 |   0.6379 |     19.905 |   0.8718 |     26.923 |     2.2\n",
      "   12 |   0.5998 |     18.731 |   0.9123 |     27.580 |     2.4\n",
      "   13 |   0.5560 |     17.562 |   0.9221 |     28.205 |     2.6\n",
      "   14 |   0.5229 |     16.405 |   0.8801 |     25.860 |     2.8\n",
      "   15 |   0.4921 |     15.394 |   0.8727 |     25.922 |     3.0\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 43 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,346\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3085, 702])\n",
      "Y_train.shape: torch.Size([3085, 7])\n",
      "X_dev.shape: torch.Size([537, 649])\n",
      "Y_dev.shape: torch.Size([537, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.0134 |     52.901 |   1.4515 |     43.234 |     0.2\n",
      "    2 |   1.3298 |     40.529 |   1.2714 |     39.665 |     0.4\n",
      "    3 |   1.1840 |     36.926 |   1.1858 |     36.840 |     0.6\n",
      "    4 |   1.0732 |     33.668 |   1.1203 |     35.506 |     0.8\n",
      "    5 |   0.9891 |     31.205 |   1.0581 |     33.085 |     1.0\n",
      "    6 |   0.9066 |     28.320 |   1.0072 |     31.719 |     1.2\n",
      "    7 |   0.8368 |     26.391 |   0.9630 |     30.012 |     1.5\n",
      "    8 |   0.7750 |     24.257 |   0.9544 |     29.454 |     1.7\n",
      "    9 |   0.7188 |     22.453 |   0.9470 |     29.857 |     1.9\n",
      "   10 |   0.6701 |     21.016 |   0.9193 |     28.461 |     2.1\n",
      "   11 |   0.6220 |     19.141 |   0.9116 |     27.716 |     2.3\n",
      "   12 |   0.5901 |     18.552 |   0.8991 |     27.654 |     2.5\n",
      "   13 |   0.5372 |     16.829 |   0.8671 |     25.698 |     2.7\n",
      "   14 |   0.5087 |     16.148 |   0.8550 |     24.674 |     3.0\n",
      "   15 |   0.4818 |     15.057 |   0.8582 |     25.109 |     3.2\n",
      "   16 |   0.4484 |     14.398 |   0.8665 |     25.854 |     3.4\n",
      "   17 |   0.4210 |     13.301 |   0.8460 |     24.178 |     3.6\n",
      "   18 |   0.4018 |     12.755 |   0.8635 |     24.519 |     3.8\n",
      "   19 |   0.3840 |     12.350 |   0.8662 |     24.829 |     4.0\n",
      "   20 |   0.3533 |     11.486 |   0.8580 |     24.364 |     4.2\n",
      "   21 |   0.3352 |     10.886 |   0.8720 |     23.960 |     4.5\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,405,730\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3057, 702])\n",
      "Y_train.shape: torch.Size([3057, 7])\n",
      "X_dev.shape: torch.Size([521, 307])\n",
      "Y_dev.shape: torch.Size([521, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.9756 |     51.690 |   1.4530 |     43.282 |     0.2\n",
      "    2 |   1.3371 |     41.277 |   1.2817 |     39.571 |     0.4\n",
      "    3 |   1.1840 |     36.136 |   1.1811 |     37.172 |     0.6\n",
      "    4 |   1.0765 |     33.421 |   1.1031 |     35.317 |     0.8\n",
      "    5 |   0.9878 |     30.776 |   1.0694 |     33.685 |     1.0\n",
      "    6 |   0.9192 |     29.114 |   1.0042 |     32.118 |     1.2\n",
      "    7 |   0.8437 |     26.338 |   0.9928 |     31.126 |     1.4\n",
      "    8 |   0.7895 |     24.779 |   0.9821 |     30.806 |     1.6\n",
      "    9 |   0.7303 |     22.533 |   0.9224 |     29.271 |     1.8\n",
      "   10 |   0.6807 |     21.274 |   0.8890 |     28.183 |     2.0\n",
      "   11 |   0.6295 |     19.425 |   0.8749 |     27.383 |     2.2\n",
      "   12 |   0.5877 |     18.302 |   0.9003 |     27.351 |     2.4\n",
      "   13 |   0.5504 |     17.201 |   0.8916 |     26.743 |     2.6\n",
      "   14 |   0.5195 |     16.492 |   0.8691 |     26.520 |     2.8\n",
      "   15 |   0.4827 |     15.058 |   0.8827 |     26.008 |     3.1\n",
      "   16 |   0.4550 |     14.257 |   0.8714 |     25.304 |     3.3\n",
      "   17 |   0.4258 |     13.537 |   0.8841 |     25.848 |     3.5\n",
      "   18 |   0.4092 |     13.003 |   0.8687 |     24.984 |     3.7\n",
      "   19 |   0.3816 |     12.142 |   0.8687 |     25.112 |     3.9\n",
      "   20 |   0.3619 |     11.542 |   0.8847 |     25.240 |     4.1\n",
      "   21 |   0.3355 |     10.664 |   0.9141 |     24.984 |     4.3\n",
      "   22 |   0.3250 |     10.457 |   0.9210 |     25.176 |     4.5\n",
      "   23 |   0.3107 |     10.266 |   0.9151 |     24.920 |     4.7\n",
      "Early stopping\n",
      "\n",
      "Mean: Precision            0.183645\n",
      "Recall               0.412234\n",
      "F1                   0.241216\n",
      "Precision_level3     0.233385\n",
      "Recall_level3        0.529138\n",
      "F1_level3            0.309142\n",
      "Precision_level2     0.286423\n",
      "Recall_level2        0.601251\n",
      "F1_level2            0.368679\n",
      "Precision level 1    0.555088\n",
      "Precision level 2    0.761709\n",
      "Precision level 3    0.800360\n",
      "Precision level 4    0.618029\n",
      "Recall level 1       0.660666\n",
      "Recall level 2       0.849497\n",
      "Recall level 3       0.890276\n",
      "Recall level 4       0.820439\n",
      "dtype: float64\n",
      "Std: Precision            0.011208\n",
      "Recall               0.029621\n",
      "F1                   0.016466\n",
      "Precision_level3     0.008973\n",
      "Recall_level3        0.023791\n",
      "F1_level3            0.012260\n",
      "Precision_level2     0.011867\n",
      "Recall_level2        0.026311\n",
      "F1_level2            0.014830\n",
      "Precision level 1    0.018489\n",
      "Precision level 2    0.017659\n",
      "Precision level 3    0.020937\n",
      "Precision level 4    0.031440\n",
      "Recall level 1       0.024118\n",
      "Recall level 2       0.017234\n",
      "Recall level 3       0.014381\n",
      "Recall level 4       0.032551\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 47899, 2025, 1, 20, 99, 1020, 345, 78] \n",
    "columns = [\n",
    "    'Seed', \n",
    "    'Precision', 'Recall', 'F1',\n",
    "    'Precision_level3', 'Recall_level3', 'F1_level3',\n",
    "    'Precision_level2', 'Recall_level2', 'F1_level2',\n",
    "    'Precision level 1', 'Precision level 2', 'Precision level 3', 'Precision level 4',\n",
    "    'Recall level 1', 'Recall level 2', 'Recall level 3', 'Recall level 4',\n",
    "    '#Compounds that have at least one match'\n",
    "]\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seeds(seed)\n",
    "\n",
    "    train_set = pd.read_csv(f'Datasets/train_set{seed}.csv')\n",
    "    test_set = pd.read_csv(f'Datasets/test_set{seed}.csv')\n",
    "    val_set = pd.read_csv(f'Datasets/val_set{seed}.csv')\n",
    "    \n",
    "    new_train_set = multiplicate_rows(train_set)\n",
    "    new_val_set = multiplicate_rows(val_set)\n",
    "    new_test_set = multiplicate_rows(test_set)\n",
    "    \n",
    "    train_descriptors = extract_descriptors(new_train_set)\n",
    "    test_descriptors = extract_descriptors(new_test_set)\n",
    "    test_descriptors2 = extract_descriptors(test_set)\n",
    "    val_descriptors = extract_descriptors(new_val_set)\n",
    "    val_descriptors2 = extract_descriptors(val_set)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_descriptors = torch.tensor(scaler.fit_transform(train_descriptors.numpy()), dtype=torch.float32)\n",
    "    val_descriptors = torch.tensor(scaler.transform(val_descriptors.numpy()), dtype=torch.float32)\n",
    "    test_descriptors = torch.tensor(scaler.transform(test_descriptors.numpy()), dtype=torch.float32)\n",
    "    val_descriptors2 = torch.tensor(scaler.transform(val_descriptors2.numpy()), dtype=torch.float32)\n",
    "    test_descriptors2 = torch.tensor(scaler.transform(test_descriptors2.numpy()), dtype=torch.float32)\n",
    "    \n",
    "    source_train = source(new_train_set)\n",
    "    source_test = source(new_test_set)\n",
    "    # Test set without duplicated compounds\n",
    "    source_test2 = source(test_set)\n",
    "    source_val = source(new_val_set)\n",
    "    # Val set without duplicated compounds\n",
    "    source_val2 = source(val_set)\n",
    "    \n",
    "    target_train = target(new_train_set)\n",
    "    target_test = target(new_test_set)\n",
    "    target_val = target(new_val_set)\n",
    "    \n",
    "    # An Index object represents a mapping from the vocabulary to integers (indices) to feed into the models\n",
    "    source_index = index.Index(source_train)\n",
    "    target_index = index.Index(target_train)\n",
    "    \n",
    "    # Create tensors\n",
    "    X_train = source_index.text2tensor(source_train)\n",
    "    y_train = target_index.text2tensor(target_train)\n",
    "    X_val = source_index.text2tensor(source_val)\n",
    "    X_val2 = source_index.text2tensor(source_val2)\n",
    "    y_val = target_index.text2tensor(target_val)     \n",
    "    X_test = source_index.text2tensor(source_test)\n",
    "    X_test2 = source_index.text2tensor(source_test2)\n",
    "    y_test = target_index.text2tensor(target_test)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        X_train = X_train.to(\"cuda\")\n",
    "        y_train = y_train.to(\"cuda\")\n",
    "        train_descriptors = train_descriptors.to(\"cuda\") \n",
    "        test_descriptors = test_descriptors.to(\"cuda\")\n",
    "        test_descriptors2 = test_descriptors2.to(\"cuda\")\n",
    "        val_descriptors = val_descriptors.to(\"cuda\")\n",
    "        val_descriptors2 = val_descriptors2.to(\"cuda\")\n",
    "        X_val = X_val.to(\"cuda\")\n",
    "        X_val2 = X_val2.to(\"cuda\")\n",
    "        y_val = y_val.to(\"cuda\")\n",
    "        X_test= X_test.to(\"cuda\")\n",
    "        y_test = y_test.to(\"cuda\")\n",
    "        X_test2 = X_test2.to(\"cuda\")\n",
    "\n",
    "    model = multimodal_models.MultimodalTransformer(\n",
    "                source_index, \n",
    "                target_index,\n",
    "                max_sequence_length = 800,\n",
    "                embedding_dimension = 128,\n",
    "                descriptors_dimension=train_descriptors.shape[1],\n",
    "                feedforward_dimension = 256,\n",
    "                encoder_layers = 4,\n",
    "                decoder_layers = 3,\n",
    "                attention_heads = 4,\n",
    "                activation = \"relu\",\n",
    "                dropout = 0.0)   \n",
    "    model.to(\"cuda\")\n",
    "    q = model.fit(X_train, \n",
    "            train_descriptors,\n",
    "            y_train,\n",
    "            X_val, \n",
    "            val_descriptors,\n",
    "            y_val, \n",
    "            batch_size = 32, \n",
    "            epochs = 150, \n",
    "            learning_rate = 0.0001, \n",
    "            weight_decay = 1e-05,\n",
    "            progress_bar = 0, \n",
    "            save_path = None)\n",
    "    model.load_state_dict(torch.load(\"best_multimodalmodel.pth\", weights_only=True))\n",
    "    loss, error_rate = model.evaluate(X_test, test_descriptors, y_test, batch_size = 32) \n",
    "\n",
    "    predictions, log_probabilities = search_algorithms.multimodal_beam_search(\n",
    "        model, \n",
    "        X_test2, \n",
    "        test_descriptors2,\n",
    "        predictions = 6, # max length of the predicted sequence\n",
    "        beam_width = 10,\n",
    "        batch_size = 32, \n",
    "        progress_bar = 0\n",
    "    )\n",
    "    output_beam = [target_index.tensor2text(p) for p in predictions]\n",
    "    predictions_clean = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            if len(clean_pred) == 5:\n",
    "                interm.append(clean_pred)\n",
    "            if len(interm) == 3:\n",
    "                break\n",
    "        predictions_clean.append(interm)\n",
    "    predictions_clean_level3 = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            pred_3 = clean_pred[0:4]\n",
    "            if len(pred_3) == 4 and pred_3 not in interm:\n",
    "                interm.append(pred_3)\n",
    "        predictions_clean_level3.append(interm[0:3])\n",
    "    predictions_clean_level2 = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            pred_2 = clean_pred[0:3]\n",
    "            if len(pred_2) == 3 and pred_2 not in interm:\n",
    "                interm.append(pred_2)\n",
    "        predictions_clean_level2.append(interm[0:3])\n",
    "    precision_1, precision_2, precision_3, precision_4 = defined_metrics.precision(predictions_clean, f'Datasets/test_set{seed}.csv', 'ATC Codes')\n",
    "    recall_1, recall_2, recall_3, recall_4, counter_compound_match = defined_metrics.recall(predictions_clean, f'Datasets/test_set{seed}.csv', 'ATC Codes')\n",
    "    precisions, recalls, f1s = defined_metrics.complete_metrics(predictions_clean, f'Datasets/test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_level3, recalls_level3, f1s_level3 = defined_metrics.complete_metrics_level3(predictions_clean_level3, f'Datasets/test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_level2, recalls_level2, f1s_level2 = defined_metrics.complete_metrics_level2(predictions_clean_level2, f'Datasets/test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_average = sum(precisions)/len(precisions)\n",
    "    recalls_average = sum(recalls)/len(recalls)\n",
    "    f1s_average = sum(f1s)/len(f1s)\n",
    "\n",
    "    precisions_average_level3 = sum(precisions_level3)/len(precisions_level3)\n",
    "    recalls_average_level3 = sum(recalls_level3)/len(recalls_level3)\n",
    "    f1s_average_level3 = sum(f1s_level3)/len(f1s_level3)\n",
    "\n",
    "    precisions_average_level2 = sum(precisions_level2)/len(precisions_level2)\n",
    "    recalls_average_level2 = sum(recalls_level2)/len(recalls_level2)\n",
    "    f1s_average_level2 = sum(f1s_level2)/len(f1s_level2)\n",
    "    \n",
    "    metrics = {\n",
    "        'Precision': precisions_average, \n",
    "        'Recall': recalls_average,\n",
    "        'F1': f1s_average,\n",
    "        'Precision_level3': precisions_average_level3, \n",
    "        'Recall_level3': recalls_average_level3,\n",
    "        'F1_level3': f1s_average_level3,\n",
    "        'Precision_level2': precisions_average_level2, \n",
    "        'Recall_level2': recalls_average_level2,\n",
    "        'F1_level2': f1s_average_level2,\n",
    "        'Precision level 1': precision_1,\n",
    "        'Precision level 2': precision_2,\n",
    "        'Precision level 3': precision_3,\n",
    "        'Precision level 4': precision_4,\n",
    "        'Recall level 1': recall_1,\n",
    "        'Recall level 2': recall_2,\n",
    "        'Recall level 3': recall_3,\n",
    "        'Recall level 4': recall_4,\n",
    "        '#Compounds that have at least one match': counter_compound_match\n",
    "    }\n",
    "    \n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "metrics_df.to_csv(\"multimodaltransformer_metrics.csv\", index=False)\n",
    "print(\"Mean:\", metrics_df.mean(numeric_only=True))\n",
    "print(\"Std:\", metrics_df.std(numeric_only=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
