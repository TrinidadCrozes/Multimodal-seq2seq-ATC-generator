{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91a67c3-3164-402b-9c3d-ed5f98d41c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))\n",
    "from seq2seq import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa18d3e-cd26-4b6a-85c0-cc550fb60feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string that simulates a list to a real list\n",
    "def convert_string_list(element):\n",
    "    # Delete [] of the string\n",
    "    element = element[0:len(element)]\n",
    "    # Create a list that contains each code as e.g. 'A'\n",
    "    ATC_list = list(element.split('; '))\n",
    "    for index, code in enumerate(ATC_list):\n",
    "        # Delete '' of the code\n",
    "        ATC_list[index] = code[0:len(code)]\n",
    "    return ATC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd300a6-a7e0-4bc8-ac44-2a94f4dcf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../Data/splittedATC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0bfcef-2d83-44b4-8150-48558154e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Neutralized SMILES']\n",
    "y = df['ATC Codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4873b22b-46e5-49b4-bbcd-2e7232dd71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def create_partitions(df, seed):\n",
    "    # Create a new column that indicates if the compound has more than 1 ATC code associated (1) or not (0)\n",
    "    df['multiple_ATC'] = df['ATC Codes'].apply(lambda x: len(convert_string_list(x)) > 1)\n",
    "    \n",
    "    # Divide the dataset depending on multiple_ATC column\n",
    "    group_more_than_one = df[df['multiple_ATC']]  # Compounds with more than one ATC code associated\n",
    "    group_one = df[~df['multiple_ATC']]          # Compounds with just one ATC code associated\n",
    "\n",
    "    conteo_longitudes = Counter(len(convert_string_list(codes)) for codes in group_more_than_one['ATC Codes'])\n",
    "    group_more_than_one = group_more_than_one.reset_index(drop=True)\n",
    "    group_one = group_one.reset_index(drop=True)\n",
    "\n",
    "    # Divide each set into train, validation and test subsets\n",
    "    train_more, test_more = train_test_split(group_more_than_one, test_size=0.2, random_state=seed)\n",
    "    train_one, test_one = train_test_split(group_one, test_size=0.2, random_state=seed)\n",
    "    train_more, val_more = train_test_split(train_more, test_size=0.15, random_state=seed)\n",
    "    train_one, val_one = train_test_split(train_one, test_size=0.15, random_state=seed)\n",
    "    \n",
    "    # Combine each set\n",
    "    train_set = pd.concat([train_more, train_one])\n",
    "    test_set = pd.concat([test_more, test_one])\n",
    "    val_set = pd.concat([val_more, val_one])\n",
    "    train_set = shuffle(train_set, random_state = seed)\n",
    "    test_set = shuffle(test_set, random_state = seed)\n",
    "    val_set = shuffle(val_set, random_state = seed)\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d548faf7-aeed-49f6-8172-38fa7a828a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seeds = [42, 123, 47899, 2025, 1, 20, 99, 1020, 345, 78] \n",
    "\n",
    "for seed in seeds:\n",
    "    set_seeds(seed)\n",
    "\n",
    "    train_set, val_set, test_set = create_partitions(df, seed)\n",
    "    train_set.to_csv(f'train_set{seed}.csv', index = False)\n",
    "    test_set.to_csv(f'test_set{seed}.csv', index = False)\n",
    "    val_set.to_csv(f'val_set{seed}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e4b9c-bf69-44c7-8f64-13e3a234d17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
