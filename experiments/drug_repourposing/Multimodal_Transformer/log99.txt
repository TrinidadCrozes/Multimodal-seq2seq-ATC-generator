Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2074 |     54.498 |   1.5119 |     43.296 |     0.1
    2 |   1.4979 |     43.500 |   1.3282 |     40.937 |     0.2
    3 |   1.3462 |     41.508 |   1.2331 |     38.516 |     0.4
    4 |   1.2585 |     39.270 |   1.1666 |     37.678 |     0.5
    5 |   1.1844 |     36.917 |   1.1136 |     36.127 |     0.6
    6 |   1.1291 |     35.391 |   1.0795 |     35.692 |     0.7
    7 |   1.0752 |     34.176 |   1.0346 |     32.651 |     0.9
    8 |   1.0248 |     32.660 |   0.9986 |     31.844 |     1.0
    9 |   0.9764 |     30.685 |   0.9733 |     31.533 |     1.1
   10 |   0.9435 |     29.777 |   0.9389 |     29.112 |     1.2
   11 |   0.9003 |     28.661 |   0.9257 |     28.492 |     1.4
   12 |   0.8632 |     27.681 |   0.9012 |     28.181 |     1.5
   13 |   0.8253 |     26.062 |   0.8810 |     27.374 |     1.6
   14 |   0.7968 |     25.328 |   0.8909 |     27.933 |     1.7
   15 |   0.7635 |     24.223 |   0.8762 |     27.033 |     1.9
   16 |   0.7397 |     23.550 |   0.8708 |     26.443 |     2.0
   17 |   0.7039 |     22.417 |   0.8595 |     25.854 |     2.1
   18 |   0.6785 |     21.684 |   0.8582 |     25.357 |     2.2
   19 |   0.6552 |     20.732 |   0.8405 |     25.419 |     2.4
   20 |   0.6332 |     19.922 |   0.8518 |     24.798 |     2.5
   21 |   0.6192 |     19.868 |   0.8477 |     24.736 |     2.6
   22 |   0.5901 |     19.041 |   0.8652 |     25.388 |     2.7
   23 |   0.5695 |     17.892 |   0.8375 |     24.457 |     2.9
   24 |   0.5470 |     17.564 |   0.8644 |     25.388 |     3.0
   25 |   0.5390 |     17.050 |   0.8680 |     24.550 |     3.1
   26 |   0.5152 |     16.415 |   0.8644 |     23.805 |     3.2
   27 |   0.4981 |     15.846 |   0.8641 |     23.898 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5091 |     46.651 |   1.2886 |     43.637 |     0.2
    2 |   1.2535 |     42.028 |   1.1753 |     40.379 |     0.3
    3 |   1.1730 |     39.680 |   1.1153 |     37.647 |     0.5
    4 |   1.1129 |     38.105 |   1.0588 |     35.785 |     0.6
    5 |   1.0603 |     36.255 |   1.0168 |     34.420 |     0.8
    6 |   1.0215 |     35.330 |   0.9924 |     33.892 |     1.0
    7 |   0.9782 |     33.837 |   0.9771 |     32.868 |     1.1
    8 |   0.9507 |     32.759 |   0.9462 |     31.782 |     1.3
    9 |   0.9247 |     32.042 |   0.9753 |     33.520 |     1.4
   10 |   0.8986 |     30.970 |   0.9090 |     31.254 |     1.6
   11 |   0.8626 |     29.821 |   0.9121 |     30.850 |     1.7
   12 |   0.8394 |     28.803 |   0.8858 |     29.609 |     1.9
   13 |   0.8239 |     28.272 |   0.8587 |     28.740 |     2.1
   14 |   0.7874 |     27.216 |   0.8578 |     28.367 |     2.2
   15 |   0.7765 |     26.860 |   0.8347 |     28.243 |     2.4
   16 |   0.7345 |     25.301 |   0.8448 |     27.964 |     2.5
   17 |   0.7119 |     24.371 |   0.8214 |     26.878 |     2.7
   18 |   0.6905 |     23.616 |   0.8151 |     26.319 |     2.9
   19 |   0.6591 |     22.549 |   0.8337 |     26.350 |     3.0
   20 |   0.6427 |     22.308 |   0.8052 |     24.984 |     3.2
   21 |   0.6137 |     20.973 |   0.7988 |     24.395 |     3.3
   22 |   0.5854 |     19.977 |   0.8230 |     25.481 |     3.5
   23 |   0.5724 |     19.900 |   0.8021 |     24.457 |     3.7
   24 |   0.5449 |     18.740 |   0.8186 |     25.109 |     3.8
   25 |   0.5261 |     18.379 |   0.8179 |     24.426 |     4.0
   26 |   0.5086 |     17.777 |   0.7791 |     23.060 |     4.1
   27 |   0.4883 |     16.853 |   0.8494 |     25.109 |     4.3
   28 |   0.4650 |     16.065 |   0.8142 |     23.712 |     4.4
   29 |   0.4470 |     15.540 |   0.8194 |     23.029 |     4.6
   30 |   0.4278 |     15.129 |   0.7996 |     22.533 |     4.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2509 |     57.513 |   1.5093 |     43.731 |     0.2
    2 |   1.4942 |     43.877 |   1.3258 |     41.775 |     0.3
    3 |   1.3483 |     41.213 |   1.2324 |     38.765 |     0.5
    4 |   1.2513 |     39.276 |   1.1723 |     36.530 |     0.6
    5 |   1.1805 |     36.994 |   1.1169 |     35.599 |     0.8
    6 |   1.1208 |     35.095 |   1.0619 |     33.457 |     0.9
    7 |   1.0655 |     33.596 |   1.0272 |     32.433 |     1.1
    8 |   1.0152 |     32.387 |   0.9983 |     31.595 |     1.2
    9 |   0.9750 |     30.975 |   0.9766 |     31.068 |     1.4
   10 |   0.9337 |     29.574 |   0.9379 |     29.485 |     1.5
   11 |   0.8931 |     28.278 |   0.9378 |     29.981 |     1.7
   12 |   0.8540 |     26.877 |   0.8976 |     28.492 |     1.9
   13 |   0.8192 |     25.936 |   0.8922 |     27.219 |     2.0
   14 |   0.7897 |     24.458 |   0.8672 |     26.009 |     2.2
   15 |   0.7515 |     23.577 |   0.8806 |     26.847 |     2.3
   16 |   0.7274 |     23.129 |   0.8617 |     25.264 |     2.5
   17 |   0.6954 |     22.319 |   0.8542 |     25.698 |     2.6
   18 |   0.6748 |     21.225 |   0.8436 |     24.674 |     2.8
   19 |   0.6405 |     20.256 |   0.8453 |     24.891 |     2.9
   20 |   0.6209 |     19.457 |   0.8484 |     24.581 |     3.1
   21 |   0.6067 |     19.441 |   0.8170 |     24.022 |     3.2
   22 |   0.5881 |     18.839 |   0.8319 |     23.774 |     3.4
   23 |   0.5629 |     17.652 |   0.8297 |     23.743 |     3.6
   24 |   0.5417 |     17.197 |   0.8512 |     24.146 |     3.7
   25 |   0.5165 |     16.814 |   0.8451 |     23.836 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8642 |     52.736 |   1.3168 |     42.675 |     0.2
    2 |   1.3027 |     42.586 |   1.2184 |     40.348 |     0.3
    3 |   1.2007 |     40.135 |   1.1402 |     38.827 |     0.5
    4 |   1.1341 |     38.127 |   1.0853 |     36.220 |     0.7
    5 |   1.0803 |     36.573 |   1.0394 |     34.668 |     0.8
    6 |   1.0192 |     34.477 |   0.9774 |     31.533 |     1.0
    7 |   0.9853 |     33.257 |   0.9642 |     32.092 |     1.2
    8 |   0.9456 |     31.818 |   0.9509 |     31.347 |     1.4
    9 |   0.8999 |     30.302 |   0.9139 |     30.012 |     1.5
   10 |   0.8745 |     29.673 |   0.8970 |     29.764 |     1.7
   11 |   0.8337 |     28.190 |   0.8793 |     28.988 |     1.9
   12 |   0.8095 |     27.528 |   0.8444 |     27.778 |     2.0
   13 |   0.7862 |     26.707 |   0.8579 |     27.467 |     2.2
   14 |   0.7543 |     25.492 |   0.8527 |     28.430 |     2.4
   15 |   0.7359 |     25.044 |   0.8453 |     26.723 |     2.5
   16 |   0.7036 |     23.785 |   0.8252 |     25.791 |     2.7
   17 |   0.6752 |     22.943 |   0.8300 |     27.592 |     2.9
   18 |   0.6483 |     22.073 |   0.8455 |     25.978 |     3.0
   19 |   0.6291 |     21.318 |   0.8313 |     26.195 |     3.2
   20 |   0.6031 |     20.464 |   0.8179 |     24.798 |     3.4
   21 |   0.5934 |     19.786 |   0.7966 |     24.953 |     3.6
   22 |   0.5724 |     19.320 |   0.7957 |     24.302 |     3.7
   23 |   0.5446 |     18.407 |   0.8112 |     23.371 |     3.9
   24 |   0.5253 |     17.586 |   0.8563 |     25.698 |     4.1
   25 |   0.5078 |     17.520 |   0.8297 |     24.240 |     4.2
   26 |   0.4909 |     16.721 |   0.8443 |     24.457 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,586

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5668 |     46.963 |   1.2401 |     42.489 |     0.2
    2 |   1.2180 |     40.649 |   1.1342 |     38.641 |     0.4
    3 |   1.1360 |     38.198 |   1.1009 |     37.182 |     0.6
    4 |   1.0698 |     36.430 |   1.0483 |     35.009 |     0.8
    5 |   1.0271 |     35.095 |   1.0038 |     34.171 |     0.9
    6 |   0.9869 |     33.388 |   0.9909 |     34.171 |     1.1
    7 |   0.9551 |     32.463 |   0.9362 |     31.719 |     1.3
    8 |   0.9115 |     31.030 |   0.9303 |     31.719 |     1.5
    9 |   0.8780 |     29.864 |   0.9009 |     29.640 |     1.7
   10 |   0.8458 |     29.065 |   0.9183 |     31.378 |     1.9
   11 |   0.8158 |     27.692 |   0.8920 |     29.330 |     2.1
   12 |   0.7902 |     26.806 |   0.8661 |     28.895 |     2.3
   13 |   0.7701 |     26.231 |   0.8631 |     28.740 |     2.5
   14 |   0.7472 |     25.525 |   0.8797 |     29.236 |     2.7
   15 |   0.7265 |     25.022 |   0.8360 |     27.592 |     2.8
   16 |   0.6846 |     23.249 |   0.8575 |     28.150 |     3.0
   17 |   0.6639 |     22.598 |   0.8317 |     26.102 |     3.2
   18 |   0.6465 |     21.772 |   0.8160 |     26.660 |     3.4
   19 |   0.6154 |     20.836 |   0.8312 |     26.071 |     3.6
   20 |   0.6144 |     21.175 |   0.8135 |     25.605 |     3.8
   21 |   0.5912 |     20.256 |   0.8115 |     25.202 |     4.0
   22 |   0.5573 |     18.981 |   0.8453 |     25.512 |     4.2
   23 |   0.5490 |     18.686 |   0.8271 |     24.364 |     4.4
   24 |   0.5282 |     18.040 |   0.8412 |     25.419 |     4.6
   25 |   0.5232 |     17.974 |   0.7977 |     23.960 |     4.7
   26 |   0.4888 |     16.634 |   0.8246 |     24.395 |     4.9
   27 |   0.4688 |     16.360 |   0.8399 |     25.233 |     5.1
   28 |   0.4653 |     16.005 |   0.8231 |     23.774 |     5.3
   29 |   0.4321 |     15.200 |   0.8372 |     24.178 |     5.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5014 |     46.246 |   1.2111 |     39.541 |     0.1
    2 |   1.1461 |     38.696 |   1.1129 |     37.120 |     0.2
    3 |   1.0554 |     35.533 |   1.0603 |     35.878 |     0.3
    4 |   0.9639 |     32.469 |   0.9506 |     32.402 |     0.5
    5 |   0.8920 |     30.302 |   0.9394 |     30.726 |     0.6
    6 |   0.8508 |     29.197 |   0.8858 |     29.764 |     0.7
    7 |   0.8060 |     27.511 |   0.8796 |     29.081 |     0.8
    8 |   0.7553 |     25.793 |   0.8835 |     30.354 |     0.9
    9 |   0.7194 |     24.557 |   0.8489 |     27.964 |     1.1
   10 |   0.6822 |     23.561 |   0.8085 |     26.226 |     1.2
   11 |   0.6616 |     22.346 |   0.8373 |     28.274 |     1.3
   12 |   0.6249 |     21.361 |   0.8243 |     26.350 |     1.4
   13 |   0.5943 |     20.502 |   0.8031 |     25.729 |     1.5
   14 |   0.5597 |     19.238 |   0.7922 |     25.419 |     1.6
   15 |   0.5300 |     18.160 |   0.8035 |     25.698 |     1.8
   16 |   0.5229 |     17.849 |   0.7846 |     24.302 |     1.9
   17 |   0.5100 |     17.203 |   0.8006 |     25.171 |     2.0
   18 |   0.4886 |     17.017 |   0.7765 |     22.843 |     2.1
   19 |   0.4538 |     15.518 |   0.7922 |     24.178 |     2.2
   20 |   0.4436 |     15.534 |   0.8322 |     24.922 |     2.3
   21 |   0.4347 |     15.282 |   0.8163 |     23.650 |     2.5
   22 |   0.4060 |     13.969 |   0.8059 |     23.433 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0979 |     54.153 |   1.4402 |     43.265 |     0.2
    2 |   1.4299 |     42.892 |   1.2909 |     39.634 |     0.3
    3 |   1.2978 |     40.282 |   1.1965 |     37.182 |     0.5
    4 |   1.2062 |     37.486 |   1.1334 |     36.375 |     0.6
    5 |   1.1381 |     35.686 |   1.0962 |     34.482 |     0.8
    6 |   1.0810 |     33.968 |   1.0460 |     33.613 |     1.0
    7 |   1.0320 |     32.305 |   1.0089 |     31.999 |     1.1
    8 |   0.9783 |     30.685 |   0.9822 |     31.006 |     1.3
    9 |   0.9316 |     29.585 |   0.9479 |     29.733 |     1.4
   10 |   0.8880 |     27.840 |   0.9219 |     28.212 |     1.6
   11 |   0.8481 |     26.942 |   0.9171 |     28.709 |     1.7
   12 |   0.8117 |     25.492 |   0.9121 |     28.430 |     1.9
   13 |   0.7677 |     24.048 |   0.8791 |     26.629 |     2.1
   14 |   0.7335 |     23.353 |   0.8607 |     25.791 |     2.2
   15 |   0.6970 |     21.898 |   0.8585 |     26.009 |     2.4
   16 |   0.6645 |     20.809 |   0.8572 |     25.450 |     2.5
   17 |   0.6358 |     19.682 |   0.8360 |     24.457 |     2.7
   18 |   0.6096 |     19.134 |   0.8539 |     24.798 |     2.9
   19 |   0.5831 |     18.456 |   0.8504 |     24.550 |     3.0
   20 |   0.5578 |     17.690 |   0.8685 |     24.860 |     3.2
   21 |   0.5298 |     16.924 |   0.8502 |     23.495 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 485,922

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4126 |     57.108 |   1.7739 |     43.606 |     0.1
    2 |   1.6170 |     43.286 |   1.4926 |     41.744 |     0.2
    3 |   1.4288 |     41.005 |   1.3705 |     39.603 |     0.3
    4 |   1.3133 |     38.843 |   1.2790 |     37.523 |     0.4
    5 |   1.2302 |     36.726 |   1.2263 |     37.492 |     0.5
    6 |   1.1618 |     35.117 |   1.1731 |     35.258 |     0.6
    7 |   1.1069 |     33.525 |   1.1318 |     34.327 |     0.6
    8 |   1.0494 |     31.790 |   1.0899 |     33.302 |     0.7
    9 |   1.0013 |     30.362 |   1.0635 |     31.906 |     0.8
   10 |   0.9583 |     29.158 |   1.0303 |     31.223 |     0.9
   11 |   0.9130 |     27.840 |   0.9908 |     30.074 |     1.0
   12 |   0.8730 |     26.778 |   0.9683 |     28.740 |     1.1
   13 |   0.8301 |     25.394 |   0.9444 |     28.957 |     1.2
   14 |   0.7975 |     24.540 |   0.9253 |     28.305 |     1.3
   15 |   0.7616 |     23.249 |   0.9242 |     28.367 |     1.4
   16 |   0.7310 |     22.401 |   0.8903 |     26.474 |     1.5
   17 |   0.6999 |     21.263 |   0.8777 |     25.822 |     1.6
   18 |   0.6653 |     20.032 |   0.8705 |     25.605 |     1.7
   19 |   0.6476 |     19.917 |   0.8492 |     25.543 |     1.8
   20 |   0.6157 |     18.587 |   0.8474 |     25.233 |     1.8
   21 |   0.5895 |     17.947 |   0.8344 |     24.705 |     1.9
   22 |   0.5602 |     16.858 |   0.8329 |     24.302 |     2.0
   23 |   0.5409 |     16.087 |   0.8411 |     25.171 |     2.1
   24 |   0.5111 |     15.315 |   0.8227 |     24.178 |     2.2
   25 |   0.4906 |     14.407 |   0.8443 |     24.053 |     2.3
   26 |   0.4791 |     14.215 |   0.8151 |     22.936 |     2.4
   27 |   0.4461 |     12.951 |   0.8335 |     24.209 |     2.5
   28 |   0.4315 |     12.908 |   0.8390 |     23.650 |     2.6
   29 |   0.4167 |     12.448 |   0.8443 |     23.991 |     2.7
   30 |   0.3979 |     11.945 |   0.8280 |     22.812 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6052 |     48.326 |   1.2873 |     42.272 |     0.2
    2 |   1.2391 |     41.185 |   1.1501 |     38.516 |     0.3
    3 |   1.1532 |     38.318 |   1.0949 |     36.375 |     0.5
    4 |   1.0849 |     36.392 |   1.0318 |     34.109 |     0.7
    5 |   1.0250 |     34.663 |   1.0058 |     33.240 |     0.8
    6 |   0.9766 |     32.994 |   0.9888 |     33.240 |     1.0
    7 |   0.9468 |     32.135 |   0.9546 |     31.502 |     1.1
    8 |   0.9033 |     30.231 |   0.9331 |     31.564 |     1.3
    9 |   0.8551 |     28.961 |   0.8954 |     29.019 |     1.5
   10 |   0.8296 |     28.475 |   0.8658 |     27.747 |     1.6
   11 |   0.7940 |     26.904 |   0.8773 |     28.554 |     1.8
   12 |   0.7507 |     25.706 |   0.8590 |     28.430 |     2.0
   13 |   0.7388 |     24.973 |   0.8374 |     27.188 |     2.1
   14 |   0.7030 |     23.736 |   0.8380 |     26.754 |     2.3
   15 |   0.6846 |     23.391 |   0.8601 |     27.809 |     2.5
   16 |   0.6471 |     22.051 |   0.8449 |     26.381 |     2.6
   17 |   0.6357 |     21.722 |   0.8219 |     26.288 |     2.8
   18 |   0.5843 |     19.851 |   0.8250 |     25.295 |     3.0
   19 |   0.5767 |     19.446 |   0.8412 |     25.729 |     3.1
   20 |   0.5555 |     18.981 |   0.8397 |     25.078 |     3.3
   21 |   0.5320 |     18.363 |   0.8109 |     24.922 |     3.4
   22 |   0.5139 |     17.756 |   0.8072 |     23.712 |     3.6
   23 |   0.4973 |     17.176 |   0.7854 |     24.022 |     3.8
   24 |   0.4708 |     16.054 |   0.8299 |     24.643 |     3.9
   25 |   0.4702 |     16.481 |   0.8209 |     24.829 |     4.1
   26 |   0.4399 |     15.178 |   0.8198 |     23.433 |     4.3
   27 |   0.4358 |     14.883 |   0.8054 |     23.774 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,378

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1628 |     56.626 |   1.4393 |     42.706 |     0.2
    2 |   1.4296 |     43.122 |   1.2901 |     40.099 |     0.3
    3 |   1.3016 |     40.206 |   1.2094 |     37.554 |     0.5
    4 |   1.2118 |     37.536 |   1.1389 |     35.754 |     0.6
    5 |   1.1421 |     35.960 |   1.0954 |     34.792 |     0.8
    6 |   1.0866 |     34.023 |   1.0601 |     34.171 |     1.0
    7 |   1.0309 |     32.611 |   1.0181 |     32.930 |     1.1
    8 |   0.9803 |     30.948 |   0.9912 |     31.409 |     1.3
    9 |   0.9328 |     29.487 |   0.9625 |     30.819 |     1.4
   10 |   0.8851 |     28.228 |   0.9406 |     29.050 |     1.6
   11 |   0.8499 |     26.756 |   0.9047 |     27.964 |     1.8
   12 |   0.8114 |     25.569 |   0.8876 |     27.592 |     1.9
   13 |   0.7697 |     24.234 |   0.8974 |     27.623 |     2.1
   14 |   0.7421 |     23.200 |   0.8570 |     25.574 |     2.2
   15 |   0.7036 |     22.199 |   0.8625 |     26.474 |     2.4
   16 |   0.6739 |     21.558 |   0.8557 |     26.816 |     2.5
   17 |   0.6445 |     20.409 |   0.8619 |     25.791 |     2.7
   18 |   0.6171 |     19.638 |   0.8392 |     25.047 |     2.9
   19 |   0.5956 |     18.456 |   0.8438 |     24.767 |     3.0
   20 |   0.5705 |     18.325 |   0.8337 |     24.674 |     3.2
   21 |   0.5435 |     16.946 |   0.8395 |     24.767 |     3.3
   22 |   0.5221 |     16.579 |   0.8422 |     24.643 |     3.5
   23 |   0.5016 |     15.819 |   0.8234 |     23.743 |     3.7
   24 |   0.4832 |     15.233 |   0.8314 |     23.619 |     3.8
   25 |   0.4663 |     14.812 |   0.8589 |     23.805 |     4.0
   26 |   0.4454 |     14.232 |   0.8515 |     23.743 |     4.1
   27 |   0.4208 |     13.406 |   0.8634 |     24.209 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4717 |     45.940 |   1.2417 |     41.155 |     0.1
    2 |   1.1677 |     39.757 |   1.1384 |     39.261 |     0.3
    3 |   1.0797 |     36.934 |   1.0419 |     34.327 |     0.4
    4 |   1.0164 |     34.898 |   0.9890 |     33.489 |     0.6
    5 |   0.9649 |     33.169 |   0.9648 |     32.123 |     0.7
    6 |   0.9305 |     32.578 |   0.9487 |     32.247 |     0.9
    7 |   0.8801 |     30.455 |   0.9175 |     31.347 |     1.0
    8 |   0.8499 |     29.476 |   0.9305 |     30.757 |     1.2
    9 |   0.8324 |     28.961 |   0.9100 |     31.006 |     1.3
   10 |   0.8065 |     27.834 |   0.8862 |     30.788 |     1.5
   11 |   0.7653 |     26.795 |   0.8736 |     29.454 |     1.6
   12 |   0.7426 |     25.689 |   0.8736 |     29.361 |     1.8
   13 |   0.7211 |     25.131 |   0.8396 |     27.778 |     1.9
   14 |   0.6848 |     23.878 |   0.8386 |     27.561 |     2.1
   15 |   0.6578 |     23.063 |   0.8589 |     28.336 |     2.2
   16 |   0.6421 |     22.691 |   0.8596 |     27.840 |     2.4
   17 |   0.6396 |     22.341 |   0.8395 |     27.312 |     2.5
   18 |   0.6408 |     22.510 |   0.8091 |     26.381 |     2.7
   19 |   0.5865 |     20.809 |   0.8250 |     24.953 |     2.8
   20 |   0.5671 |     19.709 |   0.8705 |     27.716 |     3.0
   21 |   0.5965 |     20.628 |   0.8280 |     25.326 |     3.1
   22 |   0.5405 |     18.812 |   0.7846 |     25.047 |     3.3
   23 |   0.5426 |     19.003 |   0.7875 |     25.326 |     3.4
   24 |   0.5290 |     18.412 |   0.7827 |     24.053 |     3.6
   25 |   0.4885 |     17.165 |   0.7907 |     24.084 |     3.7
   26 |   0.4871 |     17.345 |   0.7940 |     23.433 |     3.9
   27 |   0.4649 |     16.464 |   0.8188 |     25.047 |     4.0
   28 |   0.4605 |     16.059 |   0.8098 |     24.333 |     4.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7441 |     69.118 |   1.9624 |     44.941 |     0.2
    2 |   1.8790 |     46.088 |   1.5752 |     42.706 |     0.3
    3 |   1.6133 |     44.621 |   1.4506 |     41.589 |     0.5
    4 |   1.4949 |     43.418 |   1.3671 |     40.410 |     0.7
    5 |   1.4096 |     41.453 |   1.3022 |     39.323 |     0.8
    6 |   1.3456 |     40.288 |   1.2537 |     38.765 |     1.0
    7 |   1.2856 |     38.893 |   1.2070 |     38.051 |     1.2
    8 |   1.2394 |     37.700 |   1.1842 |     36.623 |     1.4
    9 |   1.1943 |     36.649 |   1.1490 |     35.258 |     1.5
   10 |   1.1583 |     35.358 |   1.1212 |     35.413 |     1.7
   11 |   1.1230 |     34.346 |   1.0938 |     33.954 |     1.9
   12 |   1.0911 |     33.634 |   1.0672 |     32.868 |     2.0
   13 |   1.0588 |     32.458 |   1.0452 |     31.782 |     2.2
   14 |   1.0273 |     31.812 |   1.0362 |     31.626 |     2.4
   15 |   1.0041 |     30.920 |   1.0135 |     31.440 |     2.5
   16 |   0.9689 |     29.755 |   1.0219 |     31.657 |     2.7
   17 |   0.9504 |     29.487 |   0.9992 |     30.975 |     2.9
   18 |   0.9219 |     28.234 |   0.9839 |     30.012 |     3.1
   19 |   0.9057 |     28.102 |   0.9834 |     29.516 |     3.2
   20 |   0.8844 |     27.511 |   0.9729 |     29.640 |     3.4
   21 |   0.8634 |     27.041 |   0.9747 |     29.702 |     3.6
   22 |   0.8381 |     25.985 |   0.9743 |     29.516 |     3.7
   23 |   0.8243 |     25.580 |   0.9651 |     29.050 |     3.9
   24 |   0.8024 |     24.907 |   0.9644 |     28.864 |     4.1
   25 |   0.7861 |     24.617 |   0.9601 |     29.205 |     4.2
   26 |   0.7688 |     23.747 |   0.9681 |     29.143 |     4.4
   27 |   0.7549 |     23.577 |   0.9447 |     28.305 |     4.6
   28 |   0.7358 |     22.910 |   0.9352 |     27.840 |     4.7
   29 |   0.7217 |     22.335 |   0.9551 |     28.554 |     4.9
   30 |   0.7092 |     22.319 |   0.9374 |     27.809 |     5.1
   31 |   0.6945 |     21.646 |   0.9319 |     28.057 |     5.3
   32 |   0.6779 |     21.252 |   0.9529 |     27.840 |     5.4
   33 |   0.6603 |     20.787 |   0.9412 |     27.250 |     5.6
   34 |   0.6507 |     20.344 |   0.9457 |     27.281 |     5.8
   35 |   0.6390 |     19.911 |   0.9601 |     26.878 |     5.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 386,850

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6050 |     65.988 |   1.9233 |     47.983 |     0.1
    2 |   1.7120 |     45.874 |   1.5479 |     42.613 |     0.2
    3 |   1.4849 |     42.192 |   1.4123 |     40.161 |     0.4
    4 |   1.3612 |     39.533 |   1.3126 |     38.268 |     0.5
    5 |   1.2706 |     37.541 |   1.2481 |     36.716 |     0.6
    6 |   1.1956 |     35.675 |   1.1797 |     34.544 |     0.7
    7 |   1.1302 |     33.902 |   1.1337 |     33.302 |     0.8
    8 |   1.0766 |     32.365 |   1.0913 |     32.588 |     1.0
    9 |   1.0243 |     30.701 |   1.0574 |     31.285 |     1.1
   10 |   0.9756 |     29.148 |   1.0287 |     31.595 |     1.2
   11 |   0.9345 |     27.812 |   1.0039 |     29.826 |     1.3
   12 |   0.8916 |     26.849 |   0.9734 |     29.236 |     1.4
   13 |   0.8590 |     25.865 |   0.9525 |     28.305 |     1.6
   14 |   0.8274 |     24.787 |   0.9350 |     28.181 |     1.7
   15 |   0.7956 |     23.917 |   0.9162 |     27.188 |     1.8
   16 |   0.7624 |     22.866 |   0.9213 |     27.654 |     1.9
   17 |   0.7293 |     21.947 |   0.8924 |     26.785 |     2.0
   18 |   0.7016 |     21.028 |   0.8841 |     26.350 |     2.2
   19 |   0.6765 |     20.218 |   0.8982 |     27.064 |     2.3
   20 |   0.6578 |     19.747 |   0.8810 |     26.350 |     2.4
   21 |   0.6308 |     18.746 |   0.8728 |     25.667 |     2.5
   22 |   0.6031 |     17.854 |   0.8574 |     25.574 |     2.6
   23 |   0.5829 |     17.279 |   0.8471 |     25.140 |     2.8
   24 |   0.5669 |     16.858 |   0.8753 |     25.978 |     2.9
   25 |   0.5466 |     16.557 |   0.8938 |     26.009 |     3.0
   26 |   0.5292 |     15.873 |   0.8553 |     25.171 |     3.1
   27 |   0.5070 |     15.124 |   0.8572 |     24.922 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,642

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2124 |     56.057 |   1.4615 |     44.010 |     0.2
    2 |   1.4490 |     43.051 |   1.2857 |     40.286 |     0.3
    3 |   1.3044 |     39.960 |   1.1852 |     37.213 |     0.5
    4 |   1.2107 |     37.481 |   1.1271 |     35.537 |     0.7
    5 |   1.1325 |     35.380 |   1.0808 |     35.040 |     0.8
    6 |   1.0730 |     33.459 |   1.0383 |     33.023 |     1.0
    7 |   1.0173 |     32.141 |   0.9950 |     31.502 |     1.2
    8 |   0.9607 |     30.559 |   0.9651 |     30.385 |     1.3
    9 |   0.9134 |     28.754 |   0.9370 |     29.454 |     1.5
   10 |   0.8685 |     26.844 |   0.9049 |     28.274 |     1.7
   11 |   0.8249 |     26.007 |   0.8847 |     26.878 |     1.8
   12 |   0.7794 |     24.059 |   0.8770 |     26.847 |     2.0
   13 |   0.7427 |     22.992 |   0.8737 |     26.474 |     2.2
   14 |   0.7094 |     22.592 |   0.8580 |     26.133 |     2.3
   15 |   0.6787 |     21.367 |   0.8526 |     25.791 |     2.5
   16 |   0.6464 |     20.272 |   0.8290 |     24.395 |     2.7
   17 |   0.6184 |     19.370 |   0.8324 |     24.240 |     2.8
   18 |   0.5902 |     18.456 |   0.8231 |     24.209 |     3.0
   19 |   0.5753 |     18.149 |   0.8165 |     24.364 |     3.2
   20 |   0.5393 |     16.590 |   0.8331 |     24.426 |     3.3
   21 |   0.5107 |     16.054 |   0.8320 |     23.681 |     3.5
   22 |   0.4954 |     15.545 |   0.8292 |     23.898 |     3.7
   23 |   0.4725 |     14.763 |   0.8450 |     23.836 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 437,090

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5207 |     61.381 |   1.8192 |     43.793 |     0.1
    2 |   1.6346 |     43.954 |   1.4956 |     41.651 |     0.3
    3 |   1.4331 |     41.765 |   1.3710 |     39.323 |     0.4
    4 |   1.3236 |     39.144 |   1.2788 |     37.741 |     0.5
    5 |   1.2421 |     37.382 |   1.2191 |     36.313 |     0.6
    6 |   1.1688 |     35.506 |   1.1680 |     35.289 |     0.8
    7 |   1.1089 |     33.935 |   1.1233 |     33.892 |     0.9
    8 |   1.0551 |     32.097 |   1.0859 |     32.495 |     1.0
    9 |   1.0103 |     30.767 |   1.0415 |     31.657 |     1.2
   10 |   0.9637 |     29.372 |   1.0213 |     30.850 |     1.3
   11 |   0.9188 |     27.927 |   1.0046 |     30.664 |     1.4
   12 |   0.8777 |     26.871 |   0.9618 |     29.112 |     1.5
   13 |   0.8365 |     25.585 |   0.9377 |     28.243 |     1.7
   14 |   0.8049 |     24.524 |   0.9501 |     29.236 |     1.8
   15 |   0.7683 |     23.435 |   0.8966 |     26.878 |     1.9
   16 |   0.7491 |     22.757 |   0.9075 |     27.747 |     2.1
   17 |   0.7094 |     21.515 |   0.8856 |     25.947 |     2.2
   18 |   0.6812 |     20.694 |   0.8790 |     26.971 |     2.3
   19 |   0.6598 |     19.950 |   0.8690 |     26.009 |     2.4
   20 |   0.6368 |     19.326 |   0.8540 |     26.754 |     2.6
   21 |   0.6054 |     18.281 |   0.8450 |     25.512 |     2.7
   22 |   0.5843 |     17.739 |   0.8635 |     25.791 |     2.8
   23 |   0.5590 |     16.913 |   0.8820 |     26.164 |     3.0
   24 |   0.5466 |     16.508 |   0.8513 |     24.984 |     3.1
   25 |   0.5263 |     15.868 |   0.8489 |     25.078 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5820 |     46.252 |   1.2539 |     40.223 |     0.1
    2 |   1.1902 |     39.773 |   1.1537 |     39.230 |     0.2
    3 |   1.0984 |     37.120 |   1.0962 |     37.523 |     0.3
    4 |   1.0049 |     34.253 |   1.0127 |     34.482 |     0.4
    5 |   0.9417 |     31.812 |   0.9769 |     33.333 |     0.5
    6 |   0.8886 |     30.171 |   0.9110 |     29.702 |     0.7
    7 |   0.8410 |     28.310 |   0.9062 |     29.795 |     0.8
    8 |   0.7854 |     26.275 |   0.9121 |     30.695 |     0.9
    9 |   0.7483 |     25.613 |   0.8396 |     27.126 |     1.0
   10 |   0.7246 |     24.896 |   0.8391 |     26.909 |     1.1
   11 |   0.6730 |     22.751 |   0.7849 |     25.171 |     1.2
   12 |   0.6303 |     21.208 |   0.8203 |     26.443 |     1.3
   13 |   0.6070 |     20.863 |   0.8257 |     26.102 |     1.4
   14 |   0.5768 |     19.966 |   0.7912 |     25.295 |     1.5
   15 |   0.5519 |     18.981 |   0.7582 |     23.867 |     1.7
   16 |   0.5205 |     17.832 |   0.8016 |     24.953 |     1.8
   17 |   0.5018 |     17.301 |   0.7890 |     24.022 |     1.9
   18 |   0.5057 |     17.301 |   0.7960 |     24.053 |     2.0
   19 |   0.4609 |     15.961 |   0.7881 |     23.122 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 552,674

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6336 |     47.538 |   1.2519 |     40.782 |     0.1
    2 |   1.2077 |     40.014 |   1.1337 |     38.051 |     0.2
    3 |   1.0885 |     36.507 |   1.0710 |     36.034 |     0.3
    4 |   1.0018 |     33.667 |   1.0100 |     33.209 |     0.4
    5 |   0.9202 |     30.871 |   0.9143 |     30.447 |     0.5
    6 |   0.8521 |     28.743 |   0.9117 |     31.161 |     0.6
    7 |   0.7935 |     26.592 |   0.8781 |     28.678 |     0.7
    8 |   0.7400 |     24.814 |   0.8708 |     28.336 |     0.8
    9 |   0.7027 |     23.545 |   0.8128 |     25.760 |     0.9
   10 |   0.6541 |     21.974 |   0.8209 |     26.567 |     1.0
   11 |   0.6117 |     20.732 |   0.8288 |     26.133 |     1.1
   12 |   0.5802 |     19.671 |   0.8247 |     25.916 |     1.2
   13 |   0.5465 |     18.751 |   0.7811 |     24.426 |     1.3
   14 |   0.5108 |     17.482 |   0.7995 |     24.302 |     1.4
   15 |   0.4941 |     16.771 |   0.8127 |     25.171 |     1.5
   16 |   0.4636 |     15.780 |   0.7776 |     22.564 |     1.6
   17 |   0.4292 |     14.423 |   0.8652 |     25.140 |     1.7
   18 |   0.4252 |     14.418 |   0.8393 |     24.084 |     1.8
   19 |   0.3985 |     13.805 |   0.7789 |     23.060 |     1.9
   20 |   0.3686 |     12.557 |   0.8074 |     22.502 |     2.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,642

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0051 |     52.769 |   1.4005 |     41.558 |     0.2
    2 |   1.3164 |     40.069 |   1.2565 |     38.330 |     0.4
    3 |   1.1691 |     36.151 |   1.1436 |     34.575 |     0.6
    4 |   1.0650 |     33.519 |   1.0747 |     32.806 |     0.8
    5 |   0.9794 |     30.614 |   1.0057 |     31.813 |     1.0
    6 |   0.8998 |     27.905 |   0.9473 |     29.423 |     1.1
    7 |   0.8261 |     25.689 |   0.9063 |     27.716 |     1.3
    8 |   0.7665 |     24.163 |   0.8699 |     26.691 |     1.5
    9 |   0.7117 |     21.919 |   0.8865 |     27.592 |     1.7
   10 |   0.6675 |     20.573 |   0.8481 |     25.698 |     1.9
   11 |   0.6062 |     18.839 |   0.8060 |     24.674 |     2.1
   12 |   0.5571 |     16.814 |   0.8429 |     25.171 |     2.3
   13 |   0.5226 |     15.939 |   0.8299 |     24.891 |     2.5
   14 |   0.4789 |     14.686 |   0.8120 |     24.395 |     2.7
   15 |   0.4561 |     13.996 |   0.7919 |     23.774 |     2.9
   16 |   0.4090 |     12.344 |   0.7792 |     22.843 |     3.1
   17 |   0.3851 |     11.748 |   0.7706 |     22.657 |     3.3
   18 |   0.3619 |     11.255 |   0.8070 |     22.719 |     3.5
   19 |   0.3353 |     10.188 |   0.7813 |     22.222 |     3.6
   20 |   0.2995 |      8.957 |   0.8488 |     23.681 |     3.8
   21 |   0.2860 |      8.809 |   0.8082 |     22.222 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 420,322

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5559 |     59.679 |   1.8443 |     44.165 |     0.1
    2 |   1.6728 |     44.320 |   1.5441 |     42.737 |     0.2
    3 |   1.4754 |     42.438 |   1.4119 |     41.217 |     0.3
    4 |   1.3614 |     40.474 |   1.3158 |     39.230 |     0.4
    5 |   1.2747 |     38.187 |   1.2471 |     37.585 |     0.5
    6 |   1.2046 |     36.315 |   1.2027 |     36.934 |     0.6
    7 |   1.1435 |     34.800 |   1.1568 |     35.537 |     0.7
    8 |   1.0888 |     33.251 |   1.1186 |     33.706 |     0.8
    9 |   1.0379 |     31.654 |   1.0798 |     33.240 |     1.0
   10 |   0.9912 |     30.466 |   1.0492 |     32.526 |     1.1
   11 |   0.9502 |     29.224 |   1.0121 |     31.130 |     1.2
   12 |   0.9045 |     27.566 |   1.0058 |     30.664 |     1.3
   13 |   0.8679 |     26.652 |   0.9900 |     29.671 |     1.4
   14 |   0.8283 |     25.339 |   0.9638 |     28.895 |     1.5
   15 |   0.7987 |     24.442 |   0.9438 |     28.367 |     1.6
   16 |   0.7653 |     23.413 |   0.9360 |     28.492 |     1.7
   17 |   0.7322 |     22.401 |   0.9053 |     27.033 |     1.8
   18 |   0.7073 |     21.432 |   0.8989 |     27.250 |     1.9
   19 |   0.6761 |     20.469 |   0.8915 |     26.723 |     2.0
   20 |   0.6597 |     19.758 |   0.9028 |     27.343 |     2.1
   21 |   0.6343 |     19.288 |   0.8734 |     25.295 |     2.2
   22 |   0.6042 |     18.210 |   0.8703 |     26.164 |     2.3
   23 |   0.5869 |     17.575 |   0.8802 |     25.791 |     2.4
   24 |   0.5634 |     17.263 |   0.8811 |     26.412 |     2.6
   25 |   0.5445 |     16.371 |   0.8826 |     25.481 |     2.7
   26 |   0.5273 |     16.152 |   0.8662 |     24.581 |     2.8
   27 |   0.5126 |     15.337 |   0.8715 |     25.016 |     2.9
   28 |   0.4954 |     14.872 |   0.8803 |     24.891 |     3.0
   29 |   0.4813 |     14.670 |   0.8723 |     24.860 |     3.1
   30 |   0.4562 |     13.805 |   0.8735 |     24.426 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,273,378

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9794 |     52.205 |   1.4049 |     41.124 |     0.1
    2 |   1.3192 |     40.518 |   1.2426 |     37.647 |     0.3
    3 |   1.1792 |     36.999 |   1.1415 |     36.158 |     0.4
    4 |   1.0856 |     34.094 |   1.0815 |     33.085 |     0.6
    5 |   1.0025 |     31.199 |   1.0379 |     32.651 |     0.7
    6 |   0.9311 |     29.142 |   0.9808 |     30.819 |     0.9
    7 |   0.8622 |     26.910 |   0.9332 |     29.299 |     1.0
    8 |   0.7987 |     25.230 |   0.8888 |     27.064 |     1.2
    9 |   0.7384 |     22.839 |   0.8683 |     26.257 |     1.3
   10 |   0.6886 |     21.181 |   0.8445 |     26.071 |     1.5
   11 |   0.6479 |     19.972 |   0.8116 |     25.295 |     1.6
   12 |   0.5948 |     18.210 |   0.8426 |     25.481 |     1.8
   13 |   0.5548 |     16.946 |   0.7930 |     23.650 |     1.9
   14 |   0.5185 |     15.851 |   0.8036 |     23.712 |     2.1
   15 |   0.4824 |     14.888 |   0.7676 |     22.905 |     2.2
   16 |   0.4412 |     13.427 |   0.8539 |     25.233 |     2.4
   17 |   0.4245 |     13.055 |   0.7793 |     21.881 |     2.5
   18 |   0.3923 |     12.005 |   0.7824 |     22.222 |     2.7
   19 |   0.3635 |     11.042 |   0.7923 |     22.595 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0345 |     53.278 |   1.4583 |     43.482 |     0.1
    2 |   1.3710 |     41.568 |   1.2958 |     39.199 |     0.3
    3 |   1.2285 |     37.924 |   1.2127 |     37.027 |     0.4
    4 |   1.1275 |     35.172 |   1.1171 |     33.333 |     0.5
    5 |   1.0420 |     32.403 |   1.0551 |     32.371 |     0.7
    6 |   0.9595 |     30.100 |   1.0056 |     31.844 |     0.8
    7 |   0.8882 |     27.550 |   0.9630 |     29.764 |     0.9
    8 |   0.8280 |     25.815 |   0.9285 |     29.112 |     1.1
    9 |   0.7734 |     23.752 |   0.8946 |     27.871 |     1.2
   10 |   0.7226 |     22.800 |   0.8631 |     25.822 |     1.4
   11 |   0.6697 |     20.852 |   0.8458 |     25.791 |     1.5
   12 |   0.6245 |     19.091 |   0.8369 |     24.860 |     1.7
   13 |   0.5885 |     17.772 |   0.8381 |     25.326 |     1.8
   14 |   0.5496 |     16.667 |   0.8217 |     24.829 |     1.9
   15 |   0.5174 |     15.578 |   0.8087 |     24.426 |     2.1
   16 |   0.4816 |     14.489 |   0.8092 |     23.898 |     2.2
   17 |   0.4596 |     14.024 |   0.7870 |     23.029 |     2.3
   18 |   0.4158 |     12.563 |   0.8025 |     22.812 |     2.5
   19 |   0.4019 |     12.289 |   0.8409 |     25.047 |     2.6
   20 |   0.3745 |     11.414 |   0.7961 |     22.843 |     2.7
   21 |   0.3555 |     10.735 |   0.8139 |     22.719 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,273,378

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4344 |     45.081 |   1.1890 |     40.286 |     0.1
    2 |   1.1453 |     38.772 |   1.0969 |     37.989 |     0.3
    3 |   1.0405 |     35.626 |   1.0163 |     34.264 |     0.4
    4 |   0.9704 |     32.994 |   0.9656 |     32.123 |     0.6
    5 |   0.9059 |     30.964 |   0.9449 |     31.626 |     0.7
    6 |   0.8496 |     28.945 |   0.8974 |     29.950 |     0.9
    7 |   0.8069 |     27.648 |   0.8892 |     29.547 |     1.0
    8 |   0.7634 |     26.144 |   0.8608 |     28.305 |     1.2
    9 |   0.7307 |     25.159 |   0.8324 |     27.592 |     1.3
   10 |   0.6840 |     23.484 |   0.8204 |     26.102 |     1.5
   11 |   0.6451 |     22.242 |   0.8477 |     28.212 |     1.6
   12 |   0.6240 |     21.225 |   0.8038 |     25.729 |     1.8
   13 |   0.5986 |     20.491 |   0.7915 |     24.829 |     1.9
   14 |   0.5648 |     19.671 |   0.7760 |     24.364 |     2.1
   15 |   0.5325 |     18.210 |   0.7869 |     25.295 |     2.2
   16 |   0.5242 |     18.533 |   0.8084 |     24.798 |     2.4
   17 |   0.4991 |     17.039 |   0.8069 |     25.202 |     2.5
   18 |   0.4577 |     15.797 |   0.7712 |     23.402 |     2.7
   19 |   0.4405 |     15.277 |   0.8111 |     24.426 |     2.8
   20 |   0.4302 |     14.637 |   0.7635 |     22.253 |     3.0
   21 |   0.4141 |     14.462 |   0.8303 |     23.681 |     3.1
   22 |   0.3950 |     13.914 |   0.7972 |     22.750 |     3.3
   23 |   0.3832 |     13.482 |   0.8178 |     23.371 |     3.4
   24 |   0.3718 |     13.072 |   0.8150 |     22.160 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 437,090

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7360 |     68.839 |   2.0703 |     49.441 |     0.1
    2 |   1.9082 |     47.483 |   1.5898 |     43.731 |     0.2
    3 |   1.6181 |     44.972 |   1.4590 |     42.955 |     0.3
    4 |   1.4961 |     43.390 |   1.3760 |     41.279 |     0.4
    5 |   1.4125 |     42.028 |   1.3121 |     40.037 |     0.5
    6 |   1.3444 |     40.643 |   1.2660 |     38.361 |     0.6
    7 |   1.2931 |     39.500 |   1.2312 |     37.616 |     0.8
    8 |   1.2440 |     37.995 |   1.1930 |     37.027 |     0.9
    9 |   1.2045 |     37.010 |   1.1656 |     36.282 |     1.0
   10 |   1.1626 |     35.817 |   1.1272 |     34.947 |     1.1
   11 |   1.1320 |     35.030 |   1.1114 |     34.885 |     1.2
   12 |   1.0987 |     33.924 |   1.0881 |     34.171 |     1.3
   13 |   1.0732 |     33.071 |   1.0763 |     33.271 |     1.4
   14 |   1.0383 |     31.840 |   1.0508 |     33.302 |     1.5
   15 |   1.0116 |     31.385 |   1.0331 |     32.247 |     1.6
   16 |   0.9893 |     30.532 |   1.0156 |     31.440 |     1.7
   17 |   0.9601 |     29.602 |   1.0073 |     31.968 |     1.9
   18 |   0.9359 |     29.257 |   0.9879 |     30.819 |     2.0
   19 |   0.9156 |     28.480 |   0.9908 |     31.037 |     2.1
   20 |   0.8878 |     27.692 |   0.9910 |     31.440 |     2.2
   21 |   0.8734 |     27.041 |   0.9604 |     30.012 |     2.3
   22 |   0.8532 |     26.461 |   0.9713 |     30.757 |     2.4
   23 |   0.8277 |     25.739 |   0.9515 |     29.174 |     2.5
   24 |   0.8105 |     24.951 |   0.9479 |     29.019 |     2.6
   25 |   0.7975 |     24.852 |   0.9354 |     28.585 |     2.7
   26 |   0.7784 |     24.415 |   0.9483 |     28.802 |     2.8
   27 |   0.7595 |     23.769 |   0.9539 |     29.299 |     2.9
   28 |   0.7460 |     23.326 |   0.9365 |     28.523 |     3.1
   29 |   0.7321 |     22.603 |   0.9308 |     27.840 |     3.2
   30 |   0.7204 |     22.281 |   0.9153 |     27.312 |     3.3
   31 |   0.7020 |     22.007 |   0.9361 |     27.498 |     3.4
   32 |   0.6930 |     21.482 |   0.9293 |     27.343 |     3.5
   33 |   0.6710 |     20.863 |   0.9470 |     28.212 |     3.6
   34 |   0.6748 |     21.039 |   0.9184 |     26.754 |     3.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0894 |     54.842 |   1.4363 |     41.993 |     0.2
    2 |   1.3433 |     41.125 |   1.2568 |     38.610 |     0.3
    3 |   1.2061 |     37.601 |   1.1628 |     35.444 |     0.5
    4 |   1.1087 |     34.969 |   1.1170 |     34.420 |     0.6
    5 |   1.0312 |     32.485 |   1.0283 |     31.564 |     0.8
    6 |   0.9533 |     29.717 |   0.9827 |     30.416 |     0.9
    7 |   0.8866 |     27.785 |   0.9458 |     29.236 |     1.1
    8 |   0.8259 |     25.596 |   0.9132 |     27.561 |     1.2
    9 |   0.7619 |     23.638 |   0.8915 |     27.002 |     1.4
   10 |   0.7172 |     22.116 |   0.8773 |     27.281 |     1.6
   11 |   0.6664 |     20.437 |   0.8481 |     26.381 |     1.7
   12 |   0.6406 |     19.446 |   0.8351 |     25.140 |     1.9
   13 |   0.5883 |     17.909 |   0.8313 |     24.953 |     2.0
   14 |   0.5451 |     16.606 |   0.8037 |     24.240 |     2.2
   15 |   0.5179 |     15.813 |   0.7956 |     24.209 |     2.3
   16 |   0.4859 |     14.773 |   0.8032 |     23.464 |     2.5
   17 |   0.4550 |     13.860 |   0.7965 |     23.650 |     2.6
   18 |   0.4264 |     13.088 |   0.8029 |     23.712 |     2.8
   19 |   0.4049 |     12.366 |   0.8071 |     23.588 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 420,322

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5542 |     62.645 |   1.8631 |     44.879 |     0.1
    2 |   1.6746 |     45.141 |   1.5419 |     43.482 |     0.2
    3 |   1.4813 |     42.832 |   1.4242 |     40.999 |     0.3
    4 |   1.3661 |     40.490 |   1.3301 |     39.603 |     0.4
    5 |   1.2775 |     38.564 |   1.2521 |     37.865 |     0.5
    6 |   1.2051 |     36.759 |   1.2031 |     36.034 |     0.6
    7 |   1.1418 |     34.937 |   1.1529 |     34.978 |     0.7
    8 |   1.0906 |     33.125 |   1.1166 |     34.109 |     0.9
    9 |   1.0404 |     31.670 |   1.0859 |     32.775 |     1.0
   10 |   0.9926 |     30.390 |   1.0574 |     32.061 |     1.1
   11 |   0.9506 |     29.093 |   1.0127 |     30.074 |     1.2
   12 |   0.9135 |     28.124 |   1.0153 |     30.726 |     1.3
   13 |   0.8736 |     26.877 |   0.9862 |     30.571 |     1.4
   14 |   0.8433 |     25.695 |   0.9828 |     30.385 |     1.5
   15 |   0.8106 |     24.967 |   0.9592 |     29.423 |     1.6
   16 |   0.7770 |     23.709 |   0.9473 |     29.205 |     1.7
   17 |   0.7534 |     22.751 |   0.9254 |     28.243 |     1.8
   18 |   0.7259 |     22.259 |   0.9172 |     27.498 |     1.9
   19 |   0.6982 |     21.318 |   0.9215 |     28.057 |     2.0
   20 |   0.6697 |     20.272 |   0.9080 |     27.685 |     2.1
   21 |   0.6489 |     20.048 |   0.9107 |     28.430 |     2.2
   22 |   0.6318 |     19.304 |   0.8970 |     27.126 |     2.4
   23 |   0.6023 |     18.434 |   0.8757 |     26.164 |     2.5
   24 |   0.5746 |     17.559 |   0.8794 |     26.816 |     2.6
   25 |   0.5571 |     16.771 |   0.8843 |     27.002 |     2.7
   26 |   0.5429 |     16.409 |   0.8735 |     26.226 |     2.8
   27 |   0.5219 |     15.802 |   0.8533 |     25.140 |     2.9
   28 |   0.5023 |     15.096 |   0.8696 |     25.202 |     3.0
   29 |   0.4884 |     14.746 |   0.8808 |     25.822 |     3.1
   30 |   0.4719 |     14.172 |   0.8698 |     25.140 |     3.2
   31 |   0.4556 |     13.707 |   0.8747 |     25.698 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 386,850

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6724 |     67.739 |   1.9713 |     50.590 |     0.1
    2 |   1.8619 |     47.685 |   1.5686 |     43.017 |     0.3
    3 |   1.6036 |     44.982 |   1.4468 |     42.768 |     0.4
    4 |   1.4859 |     43.691 |   1.3722 |     41.372 |     0.5
    5 |   1.4077 |     41.940 |   1.3094 |     40.255 |     0.7
    6 |   1.3475 |     40.923 |   1.2628 |     39.820 |     0.8
    7 |   1.2926 |     39.385 |   1.2262 |     37.709 |     0.9
    8 |   1.2469 |     38.269 |   1.1948 |     36.499 |     1.1
    9 |   1.2049 |     37.508 |   1.1645 |     36.034 |     1.2
   10 |   1.1704 |     36.288 |   1.1398 |     35.599 |     1.3
   11 |   1.1379 |     35.473 |   1.1123 |     34.482 |     1.5
   12 |   1.1047 |     34.389 |   1.0915 |     33.426 |     1.6
   13 |   1.0751 |     33.558 |   1.0679 |     32.619 |     1.7
   14 |   1.0494 |     32.863 |   1.0485 |     32.278 |     1.9
   15 |   1.0223 |     31.883 |   1.0461 |     32.030 |     2.0
   16 |   0.9967 |     30.975 |   1.0171 |     31.130 |     2.1
   17 |   0.9765 |     30.740 |   1.0003 |     31.254 |     2.2
   18 |   0.9434 |     29.722 |   1.0109 |     30.633 |     2.4
   19 |   0.9284 |     29.301 |   0.9825 |     30.509 |     2.5
   20 |   0.9005 |     28.381 |   0.9791 |     29.981 |     2.6
   21 |   0.8891 |     28.135 |   0.9617 |     29.392 |     2.8
   22 |   0.8678 |     27.287 |   0.9618 |     29.950 |     2.9
   23 |   0.8431 |     26.926 |   0.9512 |     29.485 |     3.0
   24 |   0.8285 |     26.269 |   0.9396 |     28.088 |     3.2
   25 |   0.8081 |     25.591 |   0.9443 |     28.181 |     3.3
   26 |   0.7881 |     24.967 |   0.9391 |     27.405 |     3.4
   27 |   0.7755 |     24.425 |   0.9291 |     27.654 |     3.5
   28 |   0.7621 |     24.141 |   0.9315 |     27.933 |     3.7
   29 |   0.7422 |     23.763 |   0.9260 |     27.374 |     3.8
   30 |   0.7328 |     23.238 |   0.9285 |     27.809 |     3.9
   31 |   0.7107 |     22.319 |   0.9339 |     27.498 |     4.1
   32 |   0.7041 |     22.122 |   0.9073 |     26.878 |     4.2
   33 |   0.6789 |     21.525 |   0.9193 |     27.529 |     4.3
   34 |   0.6757 |     21.099 |   0.9180 |     27.747 |     4.5
   35 |   0.6621 |     21.274 |   0.9304 |     27.219 |     4.6
   36 |   0.6522 |     20.759 |   0.9140 |     26.629 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,378

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5214 |     46.717 |   1.2645 |     42.117 |     0.1
    2 |   1.2279 |     41.010 |   1.1316 |     38.113 |     0.3
    3 |   1.1260 |     38.230 |   1.0692 |     36.282 |     0.4
    4 |   1.0624 |     36.206 |   1.0256 |     34.761 |     0.5
    5 |   1.0053 |     34.050 |   0.9581 |     32.495 |     0.6
    6 |   0.9669 |     33.093 |   0.9544 |     31.968 |     0.8
    7 |   0.9076 |     31.046 |   0.9545 |     31.844 |     0.9
    8 |   0.8754 |     29.848 |   0.9158 |     31.223 |     1.0
    9 |   0.8365 |     28.573 |   0.8997 |     29.299 |     1.2
   10 |   0.7995 |     27.025 |   0.8787 |     28.895 |     1.3
   11 |   0.7654 |     26.094 |   0.8587 |     27.840 |     1.4
   12 |   0.7293 |     24.601 |   0.8791 |     27.654 |     1.6
   13 |   0.6987 |     23.884 |   0.8445 |     27.840 |     1.7
   14 |   0.6719 |     23.090 |   0.8898 |     28.181 |     1.8
   15 |   0.6438 |     22.264 |   0.8458 |     27.188 |     1.9
   16 |   0.6150 |     21.153 |   0.8599 |     27.002 |     2.1
   17 |   0.6002 |     20.699 |   0.8637 |     27.219 |     2.2
   18 |   0.5828 |     20.371 |   0.8433 |     26.226 |     2.3
   19 |   0.5533 |     18.877 |   0.8475 |     26.567 |     2.5
   20 |   0.5358 |     18.407 |   0.8388 |     25.947 |     2.6
   21 |   0.5160 |     17.843 |   0.8524 |     26.009 |     2.7
   22 |   0.4874 |     16.924 |   0.8503 |     25.295 |     2.8
   23 |   0.4869 |     16.946 |   0.8678 |     25.450 |     3.0
   24 |   0.4668 |     16.054 |   0.9115 |     25.729 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 485,922

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6752 |     48.550 |   1.2894 |     42.303 |     0.1
    2 |   1.2651 |     41.596 |   1.1828 |     39.137 |     0.2
    3 |   1.1756 |     38.920 |   1.1303 |     37.616 |     0.3
    4 |   1.0986 |     36.649 |   1.0409 |     34.233 |     0.4
    5 |   1.0446 |     35.166 |   1.0206 |     33.923 |     0.5
    6 |   0.9973 |     33.366 |   0.9690 |     33.271 |     0.6
    7 |   0.9440 |     31.654 |   0.9329 |     30.323 |     0.7
    8 |   0.8939 |     30.280 |   0.9384 |     31.844 |     0.8
    9 |   0.8629 |     29.186 |   0.8802 |     28.554 |     0.9
   10 |   0.8102 |     27.566 |   0.8681 |     27.623 |     1.0
   11 |   0.7782 |     26.165 |   0.8426 |     27.716 |     1.1
   12 |   0.7449 |     25.033 |   0.8457 |     26.847 |     1.2
   13 |   0.7178 |     24.185 |   0.8474 |     26.629 |     1.3
   14 |   0.6981 |     23.402 |   0.8236 |     25.978 |     1.4
   15 |   0.6553 |     22.051 |   0.8542 |     26.754 |     1.5
   16 |   0.6413 |     21.821 |   0.8051 |     25.481 |     1.6
   17 |   0.6095 |     20.639 |   0.8126 |     24.581 |     1.7
   18 |   0.5824 |     19.720 |   0.8262 |     25.605 |     1.8
   19 |   0.5750 |     19.742 |   0.8003 |     24.240 |     1.9
   20 |   0.5318 |     18.319 |   0.7978 |     23.309 |     2.0
   21 |   0.5089 |     17.422 |   0.8230 |     24.302 |     2.1
   22 |   0.4827 |     16.524 |   0.8154 |     22.967 |     2.2
   23 |   0.4766 |     16.371 |   0.8226 |     22.812 |     2.3
   24 |   0.4544 |     15.523 |   0.8114 |     23.712 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,378

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5260 |     46.848 |   1.2411 |     41.899 |     0.1
    2 |   1.2299 |     41.010 |   1.1324 |     36.872 |     0.3
    3 |   1.1436 |     38.832 |   1.0787 |     36.344 |     0.4
    4 |   1.0762 |     36.474 |   1.0144 |     34.358 |     0.5
    5 |   1.0276 |     34.586 |   1.0061 |     34.668 |     0.6
    6 |   0.9753 |     33.246 |   0.9614 |     31.782 |     0.8
    7 |   0.9412 |     32.130 |   0.9373 |     30.416 |     0.9
    8 |   0.8954 |     30.302 |   0.9108 |     30.540 |     1.0
    9 |   0.8577 |     29.262 |   0.8892 |     29.361 |     1.2
   10 |   0.8144 |     27.637 |   0.8851 |     28.740 |     1.3
   11 |   0.7960 |     27.101 |   0.8595 |     28.399 |     1.4
   12 |   0.7677 |     26.094 |   0.8379 |     27.685 |     1.6
   13 |   0.7341 |     25.055 |   0.8449 |     27.840 |     1.7
   14 |   0.7024 |     24.032 |   0.8230 |     26.567 |     1.8
   15 |   0.6760 |     23.008 |   0.7909 |     25.016 |     1.9
   16 |   0.6487 |     22.149 |   0.7945 |     25.543 |     2.1
   17 |   0.6244 |     21.657 |   0.7872 |     24.798 |     2.2
   18 |   0.5971 |     20.344 |   0.7884 |     24.209 |     2.3
   19 |   0.5679 |     19.211 |   0.7780 |     24.115 |     2.5
   20 |   0.5479 |     18.658 |   0.7736 |     24.240 |     2.6
   21 |   0.5284 |     18.117 |   0.7828 |     23.340 |     2.7
   22 |   0.5067 |     17.460 |   0.8031 |     23.929 |     2.9
   23 |   0.4833 |     16.568 |   0.8002 |     23.588 |     3.0
   24 |   0.4644 |     15.944 |   0.7936 |     22.843 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 420,322

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7684 |     51.308 |   1.3158 |     43.420 |     0.1
    2 |   1.2989 |     43.024 |   1.2034 |     41.061 |     0.2
    3 |   1.2111 |     40.747 |   1.1355 |     38.268 |     0.3
    4 |   1.1416 |     38.455 |   1.0660 |     35.599 |     0.5
    5 |   1.0879 |     36.622 |   1.0415 |     34.978 |     0.6
    6 |   1.0373 |     34.947 |   0.9978 |     33.457 |     0.7
    7 |   0.9950 |     33.656 |   0.9747 |     32.092 |     0.8
    8 |   0.9552 |     32.474 |   0.9431 |     31.223 |     0.9
    9 |   0.9172 |     31.002 |   0.9280 |     30.975 |     1.0
   10 |   0.8835 |     29.946 |   0.8945 |     29.578 |     1.2
   11 |   0.8563 |     28.978 |   0.9200 |     30.354 |     1.3
   12 |   0.8273 |     28.124 |   0.8859 |     28.802 |     1.4
   13 |   0.8009 |     27.035 |   0.8732 |     28.057 |     1.5
   14 |   0.7728 |     26.138 |   0.8438 |     26.816 |     1.6
   15 |   0.7392 |     24.748 |   0.8467 |     27.002 |     1.7
   16 |   0.7182 |     23.977 |   0.8278 |     26.567 |     1.8
   17 |   0.6965 |     23.402 |   0.8333 |     25.822 |     2.0
   18 |   0.6557 |     22.127 |   0.8197 |     25.450 |     2.1
   19 |   0.6380 |     21.810 |   0.8788 |     26.567 |     2.2
   20 |   0.6385 |     21.739 |   0.8484 |     25.512 |     2.3
   21 |   0.6087 |     20.792 |   0.8306 |     25.512 |     2.4
   22 |   0.5837 |     20.070 |   0.8231 |     24.953 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6151 |     47.412 |   1.2710 |     40.596 |     0.1
    2 |   1.2025 |     39.916 |   1.1275 |     37.275 |     0.2
    3 |   1.0880 |     36.097 |   1.0736 |     35.723 |     0.3
    4 |   1.0085 |     34.231 |   1.0216 |     34.140 |     0.5
    5 |   0.9498 |     32.217 |   0.9610 |     31.130 |     0.6
    6 |   0.8823 |     29.946 |   0.9152 |     30.509 |     0.7
    7 |   0.8328 |     27.867 |   0.9024 |     30.416 |     0.8
    8 |   0.7861 |     26.745 |   0.8916 |     28.988 |     0.9
    9 |   0.7501 |     25.547 |   0.9039 |     28.895 |     1.0
   10 |   0.7055 |     24.097 |   0.8296 |     26.971 |     1.1
   11 |   0.6714 |     22.959 |   0.8375 |     27.561 |     1.3
   12 |   0.6387 |     21.903 |   0.8385 |     27.095 |     1.4
   13 |   0.6215 |     21.602 |   0.8213 |     26.288 |     1.5
   14 |   0.5897 |     20.021 |   0.8059 |     25.947 |     1.6
   15 |   0.5589 |     19.069 |   0.8072 |     25.574 |     1.7
   16 |   0.5253 |     18.007 |   0.7878 |     24.240 |     1.8
   17 |   0.5030 |     17.263 |   0.8224 |     24.798 |     1.9
   18 |   0.4923 |     16.907 |   0.8185 |     24.457 |     2.1
   19 |   0.4746 |     16.448 |   0.8032 |     23.433 |     2.2
   20 |   0.4472 |     15.676 |   0.8315 |     24.767 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 602,658

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6866 |     49.032 |   1.3063 |     42.303 |     0.1
    2 |   1.2736 |     41.973 |   1.1938 |     40.379 |     0.3
    3 |   1.1903 |     40.063 |   1.1265 |     37.337 |     0.4
    4 |   1.1224 |     37.853 |   1.0711 |     35.816 |     0.5
    5 |   1.0633 |     36.255 |   1.0570 |     34.544 |     0.6
    6 |   1.0306 |     34.882 |   0.9982 |     33.985 |     0.8
    7 |   0.9944 |     33.804 |   0.9983 |     33.644 |     0.9
    8 |   0.9581 |     32.578 |   0.9516 |     31.657 |     1.0
    9 |   0.9154 |     31.128 |   0.9334 |     30.944 |     1.2
   10 |   0.8856 |     30.045 |   0.9085 |     30.137 |     1.3
   11 |   0.8438 |     28.748 |   0.8943 |     29.640 |     1.4
   12 |   0.8234 |     28.168 |   0.8909 |     29.578 |     1.5
   13 |   0.7872 |     27.041 |   0.8769 |     28.957 |     1.7
   14 |   0.7667 |     26.220 |   0.8475 |     28.119 |     1.8
   15 |   0.7360 |     25.394 |   0.8527 |     28.336 |     1.9
   16 |   0.7094 |     24.365 |   0.8188 |     26.847 |     2.0
   17 |   0.6909 |     23.813 |   0.8466 |     28.212 |     2.2
   18 |   0.6690 |     22.888 |   0.8337 |     27.809 |     2.3
   19 |   0.6357 |     21.679 |   0.8303 |     27.281 |     2.4
   20 |   0.6165 |     21.640 |   0.8134 |     26.691 |     2.6
   21 |   0.5887 |     20.065 |   0.8159 |     26.226 |     2.7
   22 |   0.5672 |     19.545 |   0.8025 |     26.195 |     2.8
   23 |   0.5439 |     18.615 |   0.8463 |     28.026 |     2.9
   24 |   0.5251 |     18.122 |   0.8173 |     26.754 |     3.1
   25 |   0.5157 |     17.630 |   0.8251 |     25.916 |     3.2
   26 |   0.5064 |     17.515 |   0.8714 |     27.871 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5242 |     46.646 |   1.2456 |     41.248 |     0.1
    2 |   1.1721 |     39.363 |   1.1498 |     38.392 |     0.2
    3 |   1.0780 |     36.447 |   1.0899 |     37.554 |     0.4
    4 |   1.0260 |     34.991 |   1.0321 |     34.761 |     0.5
    5 |   0.9404 |     32.146 |   0.9479 |     31.875 |     0.6
    6 |   0.8977 |     30.171 |   0.9179 |     30.416 |     0.8
    7 |   0.8405 |     28.836 |   0.9082 |     30.261 |     0.9
    8 |   0.7995 |     27.429 |   0.8638 |     29.143 |     1.0
    9 |   0.7541 |     25.492 |   0.8649 |     28.523 |     1.1
   10 |   0.7331 |     24.973 |   0.8525 |     28.336 |     1.3
   11 |   0.6935 |     23.517 |   0.8410 |     27.281 |     1.4
   12 |   0.6639 |     22.822 |   0.8155 |     26.443 |     1.5
   13 |   0.6162 |     21.093 |   0.8080 |     25.760 |     1.6
   14 |   0.5897 |     20.086 |   0.8144 |     24.953 |     1.8
   15 |   0.5811 |     19.824 |   0.8419 |     25.698 |     1.9
   16 |   0.5528 |     18.937 |   0.7808 |     23.650 |     2.0
   17 |   0.5152 |     17.438 |   0.7903 |     24.053 |     2.1
   18 |   0.4916 |     16.880 |   0.8066 |     24.705 |     2.3
   19 |   0.4909 |     17.028 |   0.7906 |     22.936 |     2.4
   20 |   0.4518 |     15.572 |   0.7942 |     23.091 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,472,162

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2003 |     56.851 |   1.4292 |     43.358 |     0.2
    2 |   1.4295 |     43.046 |   1.2762 |     40.410 |     0.3
    3 |   1.3048 |     40.310 |   1.1887 |     38.020 |     0.5
    4 |   1.2186 |     38.351 |   1.1297 |     35.444 |     0.7
    5 |   1.1429 |     35.927 |   1.0799 |     34.389 |     0.8
    6 |   1.0851 |     34.017 |   1.0277 |     31.875 |     1.0
    7 |   1.0233 |     32.327 |   1.0046 |     31.750 |     1.2
    8 |   0.9741 |     30.816 |   0.9664 |     31.099 |     1.4
    9 |   0.9193 |     28.978 |   0.9477 |     29.950 |     1.5
   10 |   0.8809 |     27.966 |   0.9107 |     28.802 |     1.7
   11 |   0.8372 |     26.466 |   0.9117 |     28.678 |     1.9
   12 |   0.7963 |     25.000 |   0.8775 |     27.343 |     2.0
   13 |   0.7597 |     24.103 |   0.8666 |     26.071 |     2.2
   14 |   0.7308 |     23.304 |   0.8550 |     26.257 |     2.4
   15 |   0.6997 |     22.363 |   0.8431 |     25.729 |     2.5
   16 |   0.6653 |     21.022 |   0.8419 |     25.512 |     2.7
   17 |   0.6358 |     20.054 |   0.8165 |     24.209 |     2.9
   18 |   0.6133 |     19.463 |   0.8391 |     25.171 |     3.1
   19 |   0.5868 |     18.604 |   0.8217 |     24.426 |     3.2
   20 |   0.5644 |     18.013 |   0.8237 |     24.364 |     3.4
   21 |   0.5387 |     17.148 |   0.8323 |     24.426 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 602,658

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6240 |     47.445 |   1.2565 |     40.720 |     0.2
    2 |   1.2033 |     40.397 |   1.1540 |     37.399 |     0.3
    3 |   1.0919 |     36.863 |   1.0597 |     34.854 |     0.5
    4 |   1.0065 |     33.744 |   1.0252 |     35.133 |     0.6
    5 |   0.9364 |     31.539 |   0.9410 |     31.533 |     0.8
    6 |   0.8755 |     29.728 |   0.9036 |     29.826 |     1.0
    7 |   0.8314 |     28.201 |   0.8926 |     29.609 |     1.1
    8 |   0.7840 |     26.992 |   0.8644 |     28.523 |     1.3
    9 |   0.7337 |     24.798 |   0.8317 |     27.126 |     1.5
   10 |   0.7026 |     23.949 |   0.8150 |     26.040 |     1.6
   11 |   0.6622 |     22.855 |   0.8039 |     26.505 |     1.8
   12 |   0.6221 |     21.673 |   0.7804 |     26.629 |     2.0
   13 |   0.5911 |     20.037 |   0.7974 |     25.605 |     2.1
   14 |   0.5776 |     19.851 |   0.7981 |     25.512 |     2.3
   15 |   0.5459 |     19.102 |   0.7963 |     25.326 |     2.5
   16 |   0.5223 |     18.117 |   0.7981 |     24.922 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0767 |     53.130 |   1.4717 |     41.744 |     0.1
    2 |   1.3773 |     41.486 |   1.2863 |     38.827 |     0.2
    3 |   1.2265 |     37.930 |   1.2009 |     38.579 |     0.4
    4 |   1.1222 |     35.134 |   1.1095 |     34.327 |     0.5
    5 |   1.0318 |     32.441 |   1.0499 |     32.744 |     0.6
    6 |   0.9666 |     30.034 |   1.0029 |     31.378 |     0.7
    7 |   0.9048 |     28.212 |   0.9665 |     29.764 |     0.9
    8 |   0.8461 |     26.291 |   0.9507 |     29.516 |     1.0
    9 |   0.8009 |     24.945 |   0.8894 |     27.250 |     1.1
   10 |   0.7486 |     23.052 |   0.9288 |     28.367 |     1.2
   11 |   0.7023 |     21.826 |   0.8729 |     26.443 |     1.3
   12 |   0.6566 |     20.245 |   0.8747 |     26.940 |     1.5
   13 |   0.6162 |     18.965 |   0.8406 |     25.202 |     1.6
   14 |   0.5864 |     17.799 |   0.8240 |     24.798 |     1.7
   15 |   0.5457 |     16.853 |   0.8515 |     25.667 |     1.8
   16 |   0.5303 |     16.284 |   0.8067 |     24.395 |     1.9
   17 |   0.4892 |     15.151 |   0.8271 |     24.891 |     2.1
   18 |   0.4651 |     14.330 |   0.7983 |     23.433 |     2.2
   19 |   0.4380 |     13.553 |   0.8122 |     23.464 |     2.3
   20 |   0.4077 |     12.514 |   0.8061 |     22.967 |     2.4
   21 |   0.3898 |     11.753 |   0.8154 |     23.433 |     2.5
   22 |   0.3732 |     11.348 |   0.8100 |     22.502 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4688 |     59.422 |   1.7560 |     44.941 |     0.2
    2 |   1.5975 |     43.910 |   1.4702 |     40.968 |     0.3
    3 |   1.4130 |     40.545 |   1.3497 |     38.610 |     0.5
    4 |   1.3033 |     38.241 |   1.2862 |     37.647 |     0.6
    5 |   1.2192 |     36.157 |   1.2002 |     35.723 |     0.8
    6 |   1.1461 |     34.800 |   1.1382 |     34.823 |     0.9
    7 |   1.0934 |     33.180 |   1.1088 |     33.706 |     1.1
    8 |   1.0345 |     31.167 |   1.0644 |     32.340 |     1.3
    9 |   0.9784 |     29.574 |   1.0375 |     31.099 |     1.4
   10 |   0.9306 |     28.414 |   1.0021 |     30.323 |     1.6
   11 |   0.8901 |     26.652 |   0.9701 |     29.361 |     1.8
   12 |   0.8512 |     25.700 |   0.9652 |     29.547 |     1.9
   13 |   0.8155 |     24.754 |   0.9436 |     29.485 |     2.1
   14 |   0.7776 |     23.583 |   0.9268 |     27.778 |     2.2
   15 |   0.7494 |     22.565 |   0.9108 |     27.498 |     2.4
   16 |   0.7141 |     21.575 |   0.8948 |     27.281 |     2.6
   17 |   0.6853 |     20.814 |   0.8871 |     25.916 |     2.7
   18 |   0.6645 |     20.114 |   0.8882 |     26.536 |     2.9
   19 |   0.6371 |     19.463 |   0.8866 |     26.102 |     3.0
   20 |   0.6068 |     18.341 |   0.8784 |     25.822 |     3.2
   21 |   0.5820 |     17.586 |   0.8688 |     25.512 |     3.4
   22 |   0.5662 |     17.115 |   0.8678 |     25.357 |     3.5
   23 |   0.5383 |     16.158 |   0.8522 |     24.550 |     3.7
   24 |   0.5176 |     15.244 |   0.8411 |     24.271 |     3.8
   25 |   0.5044 |     15.096 |   0.8445 |     24.457 |     4.0
   26 |   0.4781 |     14.073 |   0.8591 |     24.395 |     4.2
   27 |   0.4642 |     13.794 |   0.8515 |     23.774 |     4.3
   28 |   0.4449 |     13.143 |   0.8603 |     23.619 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0761 |     53.376 |   1.4522 |     41.620 |     0.2
    2 |   1.3548 |     40.370 |   1.2737 |     38.113 |     0.3
    3 |   1.2023 |     36.983 |   1.1721 |     35.599 |     0.5
    4 |   1.1040 |     34.362 |   1.0873 |     33.085 |     0.6
    5 |   1.0199 |     31.774 |   1.0343 |     32.216 |     0.8
    6 |   0.9431 |     29.011 |   0.9943 |     30.975 |     0.9
    7 |   0.8851 |     27.462 |   0.9287 |     29.050 |     1.1
    8 |   0.8257 |     25.503 |   0.8978 |     27.840 |     1.3
    9 |   0.7657 |     23.906 |   0.8775 |     26.133 |     1.4
   10 |   0.7172 |     22.051 |   0.8468 |     25.760 |     1.6
   11 |   0.6770 |     20.710 |   0.8346 |     25.605 |     1.7
   12 |   0.6277 |     19.167 |   0.8130 |     24.767 |     1.9
   13 |   0.5954 |     18.226 |   0.8144 |     24.333 |     2.0
   14 |   0.5555 |     16.858 |   0.7924 |     24.146 |     2.2
   15 |   0.5189 |     15.802 |   0.7726 |     22.967 |     2.4
   16 |   0.4836 |     14.735 |   0.7962 |     24.022 |     2.5
   17 |   0.4641 |     14.106 |   0.7825 |     23.340 |     2.7
   18 |   0.4293 |     13.055 |   0.7748 |     22.315 |     2.8
   19 |   0.4112 |     12.640 |   0.7849 |     22.471 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0610 |     52.654 |   1.4321 |     41.930 |     0.1
    2 |   1.3351 |     40.430 |   1.2539 |     39.261 |     0.3
    3 |   1.2006 |     37.366 |   1.1550 |     35.971 |     0.4
    4 |   1.1051 |     34.482 |   1.1045 |     34.420 |     0.5
    5 |   1.0187 |     32.113 |   1.0332 |     31.130 |     0.6
    6 |   0.9503 |     29.957 |   0.9785 |     30.230 |     0.8
    7 |   0.8704 |     27.200 |   0.9355 |     28.492 |     0.9
    8 |   0.8127 |     25.131 |   0.9204 |     28.864 |     1.0
    9 |   0.7516 |     23.096 |   0.8805 |     27.188 |     1.2
   10 |   0.7019 |     21.460 |   0.8516 |     26.102 |     1.3
   11 |   0.6509 |     20.048 |   0.8242 |     26.164 |     1.4
   12 |   0.6046 |     18.461 |   0.8166 |     24.612 |     1.6
   13 |   0.5656 |     17.296 |   0.7888 |     23.153 |     1.7
   14 |   0.5231 |     16.016 |   0.7846 |     23.805 |     1.8
   15 |   0.4920 |     15.031 |   0.7781 |     22.750 |     2.0
   16 |   0.4604 |     13.865 |   0.7977 |     23.060 |     2.1
   17 |   0.4439 |     13.679 |   0.7858 |     22.533 |     2.2
   18 |   0.4030 |     12.016 |   0.7978 |     22.564 |     2.3
   19 |   0.3836 |     11.786 |   0.7947 |     22.315 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,642

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2084 |     56.101 |   1.4797 |     44.196 |     0.2
    2 |   1.4649 |     43.593 |   1.3040 |     40.441 |     0.3
    3 |   1.3221 |     40.819 |   1.2005 |     38.361 |     0.5
    4 |   1.2281 |     38.236 |   1.1346 |     35.568 |     0.7
    5 |   1.1571 |     36.272 |   1.0966 |     34.761 |     0.9
    6 |   1.0948 |     34.647 |   1.0406 |     32.837 |     1.0
    7 |   1.0345 |     32.310 |   0.9963 |     31.192 |     1.2
    8 |   0.9828 |     31.063 |   0.9893 |     31.347 |     1.4
    9 |   0.9339 |     29.251 |   0.9321 |     29.547 |     1.6
   10 |   0.8813 |     28.135 |   0.9207 |     29.174 |     1.7
   11 |   0.8420 |     26.477 |   0.9005 |     28.026 |     1.9
   12 |   0.8000 |     25.279 |   0.8862 |     27.250 |     2.1
   13 |   0.7600 |     23.878 |   0.8569 |     26.443 |     2.2
   14 |   0.7225 |     22.757 |   0.8517 |     25.947 |     2.4
   15 |   0.6911 |     21.750 |   0.8512 |     25.512 |     2.6
   16 |   0.6551 |     20.606 |   0.8521 |     25.885 |     2.8
   17 |   0.6211 |     19.589 |   0.8509 |     25.574 |     2.9
   18 |   0.5910 |     18.533 |   0.8463 |     25.760 |     3.1
   19 |   0.5753 |     18.303 |   0.8306 |     24.922 |     3.3
   20 |   0.5456 |     17.334 |   0.8281 |     24.519 |     3.4
   21 |   0.5175 |     16.284 |   0.8424 |     24.240 |     3.6
   22 |   0.5077 |     16.470 |   0.8388 |     24.209 |     3.8
   23 |   0.4761 |     14.877 |   0.8225 |     23.184 |     3.9
   24 |   0.4560 |     14.401 |   0.8323 |     23.060 |     4.1
   25 |   0.4396 |     13.942 |   0.8419 |     23.433 |     4.3
   26 |   0.4213 |     13.241 |   0.8585 |     23.774 |     4.4
   27 |   0.4077 |     13.116 |   0.8802 |     23.991 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,341,474

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0864 |     54.826 |   1.4606 |     41.713 |     0.1
    2 |   1.3617 |     41.196 |   1.2795 |     38.641 |     0.3
    3 |   1.2166 |     37.880 |   1.1722 |     36.344 |     0.5
    4 |   1.1109 |     34.783 |   1.0962 |     33.551 |     0.6
    5 |   1.0334 |     32.168 |   1.0289 |     31.037 |     0.8
    6 |   0.9571 |     29.875 |   0.9898 |     29.919 |     0.9
    7 |   0.8831 |     27.353 |   0.9477 |     29.112 |     1.1
    8 |   0.8238 |     25.854 |   0.9183 |     28.367 |     1.2
    9 |   0.7611 |     23.271 |   0.8957 |     27.374 |     1.4
   10 |   0.7125 |     21.848 |   0.8748 |     26.754 |     1.5
   11 |   0.6557 |     20.245 |   0.8435 |     25.636 |     1.7
   12 |   0.6046 |     18.598 |   0.8466 |     25.109 |     1.8
   13 |   0.5713 |     17.455 |   0.8158 |     23.774 |     2.0
   14 |   0.5377 |     16.546 |   0.8249 |     24.457 |     2.2
   15 |   0.4951 |     14.998 |   0.8301 |     24.891 |     2.3
   16 |   0.4598 |     13.942 |   0.8312 |     24.457 |     2.5
   17 |   0.4381 |     13.220 |   0.8151 |     23.526 |     2.6
   18 |   0.4115 |     12.590 |   0.8200 |     22.998 |     2.8
   19 |   0.3754 |     11.507 |   0.8327 |     22.750 |     3.0
   20 |   0.3575 |     10.998 |   0.8304 |     22.377 |     3.1
   21 |   0.3432 |     10.500 |   0.8248 |     21.757 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6857 |     64.670 |   1.9273 |     47.672 |     0.1
    2 |   1.8547 |     46.405 |   1.5684 |     42.024 |     0.2
    3 |   1.6069 |     44.156 |   1.4451 |     41.434 |     0.4
    4 |   1.4847 |     42.706 |   1.3669 |     40.286 |     0.5
    5 |   1.4061 |     41.453 |   1.3062 |     39.448 |     0.6
    6 |   1.3409 |     39.910 |   1.2547 |     37.741 |     0.8
    7 |   1.2909 |     38.789 |   1.2242 |     37.244 |     0.9
    8 |   1.2389 |     37.497 |   1.1854 |     35.909 |     1.0
    9 |   1.1963 |     36.611 |   1.1541 |     35.754 |     1.1
   10 |   1.1598 |     35.445 |   1.1267 |     35.102 |     1.3
   11 |   1.1270 |     34.827 |   1.1284 |     34.823 |     1.4
   12 |   1.0951 |     33.842 |   1.0823 |     33.333 |     1.5
   13 |   1.0593 |     32.797 |   1.0543 |     32.433 |     1.6
   14 |   1.0342 |     32.195 |   1.0305 |     31.750 |     1.8
   15 |   1.0049 |     31.243 |   1.0369 |     31.999 |     1.9
   16 |   0.9838 |     30.773 |   1.0090 |     31.533 |     2.0
   17 |   0.9527 |     29.574 |   1.0294 |     32.216 |     2.1
   18 |   0.9315 |     29.432 |   1.0043 |     31.161 |     2.3
   19 |   0.9098 |     28.480 |   0.9910 |     30.912 |     2.4
   20 |   0.8876 |     27.648 |   0.9796 |     30.354 |     2.5
   21 |   0.8627 |     26.981 |   0.9811 |     30.323 |     2.6
   22 |   0.8382 |     26.193 |   0.9696 |     29.857 |     2.8
   23 |   0.8240 |     25.854 |   0.9636 |     29.950 |     2.9
   24 |   0.8105 |     25.454 |   0.9718 |     29.795 |     3.0
   25 |   0.7911 |     24.858 |   0.9411 |     29.268 |     3.1
   26 |   0.7687 |     24.026 |   0.9562 |     29.547 |     3.3
   27 |   0.7521 |     23.720 |   0.9336 |     28.274 |     3.4
   28 |   0.7313 |     22.899 |   0.9348 |     28.336 |     3.5
   29 |   0.7153 |     22.406 |   0.9364 |     28.181 |     3.7
   30 |   0.7034 |     21.848 |   0.9450 |     28.895 |     3.8
   31 |   0.6893 |     21.646 |   0.9556 |     28.554 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,322

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6108 |     47.166 |   1.2864 |     41.341 |     0.1
    2 |   1.2106 |     40.063 |   1.1332 |     36.996 |     0.3
    3 |   1.0966 |     36.622 |   1.0407 |     34.482 |     0.4
    4 |   1.0006 |     33.804 |   0.9892 |     33.023 |     0.6
    5 |   0.9391 |     31.774 |   0.9715 |     31.782 |     0.7
    6 |   0.8841 |     29.842 |   0.9448 |     32.185 |     0.9
    7 |   0.8353 |     28.677 |   0.8911 |     30.695 |     1.0
    8 |   0.7797 |     26.373 |   0.8769 |     28.647 |     1.2
    9 |   0.7473 |     25.394 |   0.8458 |     28.181 |     1.3
   10 |   0.7102 |     24.316 |   0.8349 |     27.374 |     1.5
   11 |   0.6655 |     22.789 |   0.8412 |     27.654 |     1.6
   12 |   0.6331 |     21.394 |   0.8339 |     26.474 |     1.8
   13 |   0.6090 |     20.765 |   0.7806 |     25.078 |     1.9
   14 |   0.5768 |     19.840 |   0.8011 |     25.357 |     2.1
   15 |   0.5507 |     18.456 |   0.8045 |     25.854 |     2.2
   16 |   0.5248 |     18.073 |   0.7794 |     25.202 |     2.4
   17 |   0.5029 |     17.186 |   0.8127 |     24.550 |     2.5
   18 |   0.4865 |     16.409 |   0.8006 |     24.519 |     2.7
   19 |   0.4588 |     15.446 |   0.7968 |     24.271 |     2.9
   20 |   0.4341 |     14.981 |   0.8046 |     23.340 |     3.0
   21 |   0.4299 |     15.025 |   0.7642 |     23.060 |     3.2
   22 |   0.4018 |     14.106 |   0.7814 |     22.967 |     3.3
   23 |   0.3883 |     13.296 |   0.8000 |     22.750 |     3.5
   24 |   0.3836 |     13.564 |   0.7969 |     22.160 |     3.6
   25 |   0.3621 |     12.448 |   0.8352 |     22.346 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,642

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5707 |     47.866 |   1.2649 |     42.613 |     0.2
    2 |   1.2504 |     42.077 |   1.1960 |     40.751 |     0.4
    3 |   1.1631 |     39.566 |   1.1266 |     38.237 |     0.6
    4 |   1.1198 |     38.280 |   1.0577 |     36.065 |     0.8
    5 |   1.0523 |     36.025 |   1.0143 |     34.730 |     1.1
    6 |   1.0042 |     34.099 |   1.0091 |     35.071 |     1.3
    7 |   0.9861 |     33.448 |   0.9775 |     33.799 |     1.5
    8 |   0.9488 |     32.622 |   0.9488 |     32.216 |     1.7
    9 |   0.9154 |     31.467 |   0.9358 |     31.750 |     1.9
   10 |   0.8901 |     30.603 |   0.9213 |     31.409 |     2.1
   11 |   0.8566 |     29.766 |   0.8975 |     30.509 |     2.3
   12 |   0.8406 |     29.405 |   0.8604 |     28.492 |     2.6
   13 |   0.7972 |     27.451 |   0.8795 |     29.826 |     2.8
   14 |   0.7722 |     26.696 |   0.8459 |     28.026 |     3.0
   15 |   0.7519 |     25.870 |   0.8476 |     28.243 |     3.2
   16 |   0.7230 |     24.803 |   0.8068 |     26.164 |     3.4
   17 |   0.6906 |     24.152 |   0.8397 |     27.623 |     3.6
   18 |   0.6912 |     23.835 |   0.8146 |     26.629 |     3.8
   19 |   0.6537 |     22.587 |   0.8008 |     26.257 |     4.1
   20 |   0.6363 |     21.947 |   0.8036 |     25.822 |     4.3
   21 |   0.6073 |     21.285 |   0.7915 |     25.450 |     4.5
   22 |   0.5858 |     20.272 |   0.7511 |     24.767 |     4.7
   23 |   0.5581 |     19.260 |   0.7858 |     24.426 |     4.9
   24 |   0.5372 |     18.702 |   0.7678 |     23.743 |     5.1
   25 |   0.5204 |     18.270 |   0.7555 |     23.184 |     5.3
   26 |   0.5044 |     17.296 |   0.8065 |     24.115 |     5.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,322

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6275 |     46.602 |   1.2776 |     39.665 |     0.1
    2 |   1.1974 |     39.204 |   1.1246 |     36.778 |     0.3
    3 |   1.0877 |     36.677 |   1.0798 |     35.630 |     0.4
    4 |   1.0027 |     33.902 |   1.0121 |     33.892 |     0.6
    5 |   0.9347 |     31.374 |   0.9611 |     31.378 |     0.7
    6 |   0.8798 |     29.903 |   0.9191 |     30.540 |     0.9
    7 |   0.8179 |     27.194 |   0.8902 |     30.074 |     1.1
    8 |   0.7672 |     25.859 |   0.8712 |     28.585 |     1.2
    9 |   0.7284 |     24.349 |   0.8413 |     27.902 |     1.4
   10 |   0.6869 |     23.030 |   0.8272 |     26.536 |     1.5
   11 |   0.6430 |     21.602 |   0.8007 |     25.512 |     1.7
   12 |   0.6180 |     21.055 |   0.8025 |     25.854 |     1.8
   13 |   0.5749 |     19.446 |   0.7968 |     25.078 |     2.0
   14 |   0.5461 |     18.412 |   0.8008 |     25.419 |     2.1
   15 |   0.5232 |     17.673 |   0.7781 |     23.867 |     2.3
   16 |   0.5012 |     17.104 |   0.8060 |     24.550 |     2.4
   17 |   0.4837 |     16.213 |   0.7873 |     24.146 |     2.6
   18 |   0.4608 |     15.715 |   0.8062 |     23.805 |     2.7
   19 |   0.4327 |     14.675 |   0.8039 |     23.557 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 386,850

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6579 |     67.756 |   1.9265 |     47.207 |     0.1
    2 |   1.8418 |     46.684 |   1.5596 |     43.110 |     0.3
    3 |   1.5859 |     44.162 |   1.4338 |     41.962 |     0.4
    4 |   1.4668 |     42.684 |   1.3592 |     40.875 |     0.5
    5 |   1.3866 |     41.683 |   1.3017 |     40.192 |     0.7
    6 |   1.3226 |     40.359 |   1.2507 |     39.323 |     0.8
    7 |   1.2718 |     38.800 |   1.2077 |     38.268 |     0.9
    8 |   1.2276 |     37.640 |   1.1847 |     36.778 |     1.1
    9 |   1.1864 |     36.293 |   1.1483 |     36.127 |     1.2
   10 |   1.1421 |     35.298 |   1.1192 |     35.537 |     1.3
   11 |   1.1056 |     34.023 |   1.1021 |     33.737 |     1.5
   12 |   1.0721 |     32.890 |   1.0883 |     34.047 |     1.6
   13 |   1.0407 |     32.086 |   1.0590 |     32.682 |     1.7
   14 |   1.0114 |     31.424 |   1.0438 |     32.682 |     1.9
   15 |   0.9820 |     30.608 |   1.0220 |     31.347 |     2.0
   16 |   0.9517 |     29.722 |   1.0099 |     30.850 |     2.1
   17 |   0.9242 |     28.600 |   1.0017 |     30.416 |     2.3
   18 |   0.9030 |     28.124 |   0.9910 |     30.695 |     2.4
   19 |   0.8859 |     27.391 |   0.9734 |     29.609 |     2.6
   20 |   0.8534 |     26.718 |   0.9679 |     29.112 |     2.7
   21 |   0.8362 |     25.832 |   0.9617 |     28.926 |     2.8
   22 |   0.8199 |     25.372 |   0.9441 |     28.523 |     3.0
   23 |   0.7993 |     24.748 |   0.9550 |     29.081 |     3.1
   24 |   0.7831 |     24.447 |   0.9528 |     28.523 |     3.3
   25 |   0.7672 |     23.917 |   0.9376 |     28.305 |     3.4
   26 |   0.7529 |     23.545 |   0.9518 |     27.995 |     3.5
   27 |   0.7325 |     22.839 |   0.9445 |     28.833 |     3.7
   28 |   0.7202 |     22.724 |   0.9316 |     27.374 |     3.8
   29 |   0.6987 |     21.695 |   0.9484 |     28.243 |     3.9
   30 |   0.6890 |     21.876 |   0.9440 |     27.561 |     4.1
   31 |   0.6732 |     21.301 |   0.9521 |     27.778 |     4.2
   32 |   0.6642 |     21.126 |   0.9417 |     27.002 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,474

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6379 |     49.042 |   1.2705 |     42.148 |     0.2
    2 |   1.2642 |     42.247 |   1.1885 |     42.086 |     0.3
    3 |   1.1802 |     39.976 |   1.1274 |     36.623 |     0.5
    4 |   1.1163 |     38.017 |   1.0763 |     36.096 |     0.7
    5 |   1.0679 |     36.682 |   1.0304 |     35.506 |     0.8
    6 |   1.0300 |     35.123 |   1.0082 |     33.985 |     1.0
    7 |   0.9940 |     34.176 |   1.0088 |     34.730 |     1.2
    8 |   0.9574 |     32.677 |   0.9836 |     32.371 |     1.3
    9 |   0.9156 |     31.216 |   0.9496 |     31.657 |     1.5
   10 |   0.8899 |     30.362 |   0.9295 |     31.564 |     1.7
   11 |   0.8735 |     29.738 |   0.8968 |     30.106 |     1.8
   12 |   0.8360 |     28.365 |   0.9213 |     30.602 |     2.0
   13 |   0.8065 |     27.451 |   0.8808 |     28.895 |     2.2
   14 |   0.7790 |     26.724 |   0.8353 |     27.995 |     2.4
   15 |   0.7552 |     25.996 |   0.8279 |     27.498 |     2.5
   16 |   0.7363 |     25.257 |   0.8528 |     28.181 |     2.7
   17 |   0.7048 |     23.993 |   0.8248 |     27.033 |     2.9
   18 |   0.6702 |     22.948 |   0.8175 |     26.754 |     3.0
   19 |   0.6749 |     22.992 |   0.7980 |     26.257 |     3.2
   20 |   0.6388 |     22.040 |   0.7789 |     24.922 |     3.4
   21 |   0.6173 |     21.132 |   0.8006 |     25.326 |     3.5
   22 |   0.5987 |     20.869 |   0.7777 |     23.960 |     3.7
   23 |   0.5763 |     19.972 |   0.7788 |     23.774 |     3.9
   24 |   0.5561 |     19.047 |   0.7842 |     24.364 |     4.0
   25 |   0.5472 |     18.916 |   0.7866 |     24.053 |     4.2
   26 |   0.5138 |     17.876 |   0.8187 |     25.388 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7046 |     67.077 |   1.9263 |     48.293 |     0.1
    2 |   1.8373 |     46.810 |   1.5384 |     43.172 |     0.3
    3 |   1.5783 |     44.671 |   1.4230 |     41.806 |     0.4
    4 |   1.4699 |     43.319 |   1.3513 |     40.999 |     0.5
    5 |   1.3947 |     41.864 |   1.2978 |     39.292 |     0.6
    6 |   1.3318 |     40.605 |   1.2594 |     38.982 |     0.8
    7 |   1.2814 |     39.166 |   1.2218 |     38.454 |     0.9
    8 |   1.2434 |     38.570 |   1.2055 |     38.051 |     1.0
    9 |   1.2031 |     37.317 |   1.1653 |     36.002 |     1.1
   10 |   1.1689 |     36.348 |   1.1391 |     35.196 |     1.3
   11 |   1.1314 |     35.128 |   1.1282 |     35.102 |     1.4
   12 |   1.1020 |     34.340 |   1.0814 |     34.109 |     1.5
   13 |   1.0702 |     33.481 |   1.0702 |     33.923 |     1.6
   14 |   1.0414 |     32.502 |   1.0604 |     32.495 |     1.8
   15 |   1.0179 |     31.801 |   1.0519 |     32.961 |     1.9
   16 |   0.9910 |     31.161 |   1.0336 |     31.750 |     2.0
   17 |   0.9664 |     30.143 |   1.0154 |     31.130 |     2.1
   18 |   0.9492 |     29.438 |   1.0163 |     30.881 |     2.3
   19 |   0.9249 |     29.087 |   0.9977 |     30.571 |     2.4
   20 |   0.9015 |     28.633 |   0.9851 |     30.292 |     2.5
   21 |   0.8795 |     27.736 |   0.9723 |     29.702 |     2.7
   22 |   0.8595 |     27.227 |   0.9766 |     30.137 |     2.8
   23 |   0.8397 |     26.297 |   0.9622 |     29.361 |     2.9
   24 |   0.8270 |     26.127 |   0.9743 |     29.236 |     3.1
   25 |   0.8041 |     25.263 |   0.9458 |     28.957 |     3.2
   26 |   0.7835 |     24.617 |   0.9523 |     28.740 |     3.3
   27 |   0.7729 |     24.688 |   0.9375 |     28.926 |     3.5
   28 |   0.7608 |     23.966 |   0.9540 |     29.112 |     3.6
   29 |   0.7321 |     23.047 |   0.9605 |     28.988 |     3.7
   30 |   0.7243 |     22.724 |   0.9517 |     28.430 |     3.8
   31 |   0.7079 |     22.259 |   0.9530 |     28.461 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,474

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2280 |     58.032 |   1.4844 |     44.413 |     0.2
    2 |   1.4854 |     43.916 |   1.3104 |     41.248 |     0.3
    3 |   1.3390 |     41.032 |   1.2151 |     37.989 |     0.5
    4 |   1.2528 |     38.789 |   1.1571 |     36.623 |     0.7
    5 |   1.1795 |     36.791 |   1.1103 |     35.537 |     0.8
    6 |   1.1228 |     35.166 |   1.0607 |     33.333 |     1.0
    7 |   1.0700 |     33.470 |   1.0288 |     33.116 |     1.2
    8 |   1.0183 |     32.141 |   1.0107 |     32.619 |     1.3
    9 |   0.9749 |     30.767 |   0.9667 |     30.447 |     1.5
   10 |   0.9271 |     29.098 |   0.9603 |     30.944 |     1.7
   11 |   0.8887 |     28.190 |   0.9330 |     29.019 |     1.8
   12 |   0.8597 |     27.107 |   0.9173 |     29.112 |     2.0
   13 |   0.8218 |     25.689 |   0.9046 |     28.243 |     2.2
   14 |   0.7976 |     25.159 |   0.8917 |     27.716 |     2.3
   15 |   0.7508 |     23.654 |   0.8894 |     27.374 |     2.5
   16 |   0.7278 |     22.970 |   0.8681 |     26.754 |     2.7
   17 |   0.7036 |     22.078 |   0.8720 |     26.474 |     2.8
   18 |   0.6718 |     21.454 |   0.8617 |     25.947 |     3.0
   19 |   0.6518 |     20.568 |   0.8580 |     25.326 |     3.2
   20 |   0.6287 |     19.961 |   0.8853 |     25.636 |     3.3
   21 |   0.6035 |     19.107 |   0.8792 |     25.791 |     3.5
   22 |   0.5832 |     18.341 |   0.8539 |     24.674 |     3.7
   23 |   0.5653 |     17.827 |   0.8668 |     25.854 |     3.9
   24 |   0.5409 |     17.258 |   0.8847 |     26.071 |     4.0
   25 |   0.5258 |     16.760 |   0.8922 |     25.729 |     4.2
   26 |   0.5052 |     16.207 |   0.8815 |     24.922 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 294])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1923 |     56.478 |   1.4632 |     43.824 |     0.2
    2 |   1.4576 |     43.423 |   1.2993 |     40.813 |     0.4
    3 |   1.3127 |     40.507 |   1.2077 |     38.144 |     0.6
    4 |   1.2148 |     37.579 |   1.1321 |     35.040 |     0.8
    5 |   1.1370 |     35.708 |   1.0827 |     33.861 |     1.0
    6 |   1.0823 |     34.028 |   1.0557 |     33.737 |     1.2
    7 |   1.0210 |     31.960 |   0.9974 |     31.409 |     1.4
    8 |   0.9702 |     30.860 |   0.9864 |     31.068 |     1.6
    9 |   0.9163 |     29.098 |   0.9583 |     30.478 |     1.8
   10 |   0.8717 |     27.577 |   0.9129 |     28.119 |     2.0
   11 |   0.8303 |     25.936 |   0.8952 |     28.243 |     2.2
   12 |   0.7859 |     24.584 |   0.8930 |     27.654 |     2.5
   13 |   0.7469 |     23.359 |   0.8737 |     26.474 |     2.7
   14 |   0.7092 |     22.292 |   0.8681 |     26.257 |     2.9
   15 |   0.6878 |     21.575 |   0.8539 |     26.257 |     3.1
   16 |   0.6531 |     20.437 |   0.8496 |     25.605 |     3.3
   17 |   0.6238 |     19.621 |   0.8696 |     26.288 |     3.5
   18 |   0.5976 |     18.790 |   0.8495 |     25.326 |     3.7
   19 |   0.5659 |     17.695 |   0.8677 |     24.984 |     3.9
   20 |   0.5478 |     17.132 |   0.8821 |     25.760 |     4.1
   21 |   0.5175 |     16.262 |   0.8520 |     24.333 |     4.3
   22 |   0.4956 |     15.769 |   0.8608 |     24.643 |     4.5
Early stopping

