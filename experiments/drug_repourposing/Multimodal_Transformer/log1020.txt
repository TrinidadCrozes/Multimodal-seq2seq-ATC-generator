Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,473

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1481 |     55.417 |   1.4392 |     43.917 |     0.2
    2 |   1.4279 |     43.018 |   1.2986 |     40.968 |     0.3
    3 |   1.3025 |     40.124 |   1.2239 |     38.827 |     0.5
    4 |   1.2136 |     38.220 |   1.1512 |     36.127 |     0.7
    5 |   1.1435 |     35.921 |   1.0993 |     35.009 |     0.8
    6 |   1.0876 |     33.771 |   1.0693 |     32.899 |     1.0
    7 |   1.0245 |     32.108 |   1.0240 |     31.968 |     1.2
    8 |   0.9787 |     30.406 |   1.0006 |     31.533 |     1.3
    9 |   0.9309 |     29.251 |   0.9595 |     30.106 |     1.5
   10 |   0.8765 |     27.287 |   0.9548 |     29.485 |     1.7
   11 |   0.8378 |     26.373 |   0.9476 |     29.547 |     1.8
   12 |   0.7960 |     24.601 |   0.9214 |     28.336 |     2.0
   13 |   0.7566 |     23.605 |   0.9072 |     28.492 |     2.2
   14 |   0.7230 |     22.450 |   0.9009 |     27.405 |     2.3
   15 |   0.6901 |     21.460 |   0.9030 |     27.561 |     2.5
   16 |   0.6578 |     20.387 |   0.8980 |     27.561 |     2.7
   17 |   0.6292 |     19.692 |   0.8997 |     26.350 |     2.8
   18 |   0.5980 |     18.319 |   0.9107 |     26.350 |     3.0
   19 |   0.5728 |     17.963 |   0.8965 |     26.102 |     3.1
   20 |   0.5488 |     17.323 |   0.8968 |     26.319 |     3.3
   21 |   0.5274 |     16.798 |   0.9141 |     26.785 |     3.5
   22 |   0.5126 |     16.245 |   0.9220 |     25.791 |     3.6
   23 |   0.4828 |     15.206 |   0.9112 |     25.388 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,471,777

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6052 |     48.960 |   1.2884 |     41.868 |     0.1
    2 |   1.2473 |     41.606 |   1.1653 |     37.927 |     0.3
    3 |   1.1615 |     39.084 |   1.0935 |     35.847 |     0.4
    4 |   1.0894 |     36.753 |   1.0661 |     35.878 |     0.6
    5 |   1.0413 |     35.746 |   1.0652 |     35.506 |     0.7
    6 |   0.9996 |     34.088 |   0.9974 |     33.768 |     0.8
    7 |   0.9491 |     32.622 |   1.0090 |     33.799 |     1.0
    8 |   0.9196 |     31.232 |   0.9675 |     32.402 |     1.1
    9 |   0.8867 |     30.466 |   0.9428 |     31.099 |     1.3
   10 |   0.8328 |     28.031 |   0.9857 |     33.333 |     1.4
   11 |   0.8181 |     28.091 |   0.9219 |     30.137 |     1.6
   12 |   0.7771 |     26.434 |   0.9272 |     30.788 |     1.7
   13 |   0.7527 |     25.651 |   0.9137 |     30.478 |     1.9
   14 |   0.7284 |     24.814 |   0.8712 |     29.454 |     2.0
   15 |   0.6896 |     23.331 |   0.9247 |     30.292 |     2.1
   16 |   0.6801 |     23.293 |   0.9160 |     29.112 |     2.3
   17 |   0.6500 |     21.892 |   0.9060 |     28.771 |     2.4
   18 |   0.6272 |     21.449 |   0.9083 |     28.864 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 470,369

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4395 |     58.328 |   1.7942 |     45.407 |     0.1
    2 |   1.6371 |     44.545 |   1.5353 |     43.048 |     0.2
    3 |   1.4546 |     41.393 |   1.4029 |     40.099 |     0.4
    4 |   1.3413 |     39.035 |   1.3140 |     38.051 |     0.5
    5 |   1.2492 |     36.988 |   1.2391 |     36.530 |     0.6
    6 |   1.1777 |     35.434 |   1.1825 |     35.351 |     0.7
    7 |   1.1141 |     33.645 |   1.1338 |     32.868 |     0.8
    8 |   1.0532 |     31.446 |   1.0973 |     32.588 |     0.9
    9 |   1.0049 |     30.390 |   1.0583 |     31.254 |     1.1
   10 |   0.9602 |     28.715 |   1.0383 |     31.223 |     1.2
   11 |   0.9150 |     27.304 |   1.0041 |     30.354 |     1.3
   12 |   0.8738 |     26.242 |   0.9922 |     29.392 |     1.4
   13 |   0.8395 |     25.192 |   0.9673 |     29.423 |     1.5
   14 |   0.8003 |     23.835 |   0.9530 |     28.802 |     1.7
   15 |   0.7752 |     23.380 |   0.9312 |     27.716 |     1.8
   16 |   0.7423 |     22.335 |   0.9277 |     28.119 |     1.9
   17 |   0.7124 |     21.307 |   0.9054 |     27.157 |     2.0
   18 |   0.6880 |     20.459 |   0.9344 |     28.523 |     2.1
   19 |   0.6614 |     20.070 |   0.8960 |     27.219 |     2.3
   20 |   0.6342 |     19.134 |   0.8930 |     27.095 |     2.4
   21 |   0.6121 |     18.193 |   0.9075 |     26.536 |     2.5
   22 |   0.5938 |     17.635 |   0.8959 |     26.443 |     2.6
   23 |   0.5830 |     17.761 |   0.8813 |     25.791 |     2.7
   24 |   0.5485 |     16.481 |   0.8983 |     25.760 |     2.9
   25 |   0.5350 |     16.300 |   0.9006 |     26.505 |     3.0
   26 |   0.5162 |     15.534 |   0.8959 |     26.102 |     3.1
   27 |   0.4984 |     15.107 |   0.8960 |     26.102 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 485,729

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5880 |     46.509 |   1.2709 |     41.092 |     0.1
    2 |   1.1914 |     39.155 |   1.1995 |     39.944 |     0.2
    3 |   1.0855 |     36.283 |   1.0570 |     35.258 |     0.3
    4 |   0.9909 |     32.830 |   1.0179 |     33.830 |     0.4
    5 |   0.9185 |     30.915 |   0.9511 |     31.937 |     0.5
    6 |   0.8647 |     28.951 |   0.9198 |     30.695 |     0.6
    7 |   0.7993 |     27.090 |   0.9049 |     29.981 |     0.7
    8 |   0.7552 |     25.591 |   0.8641 |     28.647 |     0.8
    9 |   0.7056 |     23.774 |   0.8642 |     28.026 |     0.9
   10 |   0.6680 |     22.456 |   0.8401 |     27.126 |     1.0
   11 |   0.6194 |     20.617 |   0.8155 |     25.947 |     1.1
   12 |   0.5954 |     19.889 |   0.8298 |     25.916 |     1.2
   13 |   0.5572 |     18.708 |   0.8307 |     25.481 |     1.3
   14 |   0.5316 |     17.985 |   0.8336 |     25.605 |     1.3
   15 |   0.5100 |     17.011 |   0.7957 |     23.650 |     1.4
   16 |   0.4717 |     15.764 |   0.8215 |     23.867 |     1.5
   17 |   0.4371 |     14.850 |   0.8058 |     23.805 |     1.6
   18 |   0.4222 |     14.631 |   0.7762 |     22.967 |     1.7
   19 |   0.3895 |     13.017 |   0.8474 |     24.426 |     1.8
   20 |   0.3836 |     13.006 |   0.8355 |     23.277 |     1.9
   21 |   0.3738 |     12.754 |   0.8391 |     22.346 |     2.0
   22 |   0.3368 |     11.523 |   0.8494 |     22.812 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,505

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3325 |     60.237 |   1.5371 |     44.134 |     0.2
    2 |   1.5001 |     44.156 |   1.3313 |     40.379 |     0.3
    3 |   1.3462 |     41.076 |   1.2315 |     37.772 |     0.5
    4 |   1.2529 |     39.095 |   1.1673 |     36.034 |     0.7
    5 |   1.1879 |     37.098 |   1.1130 |     34.916 |     0.8
    6 |   1.1259 |     35.309 |   1.0857 |     33.054 |     1.0
    7 |   1.0730 |     33.388 |   1.0593 |     33.178 |     1.2
    8 |   1.0208 |     31.889 |   1.0203 |     32.216 |     1.3
    9 |   0.9755 |     30.915 |   0.9995 |     31.099 |     1.5
   10 |   0.9312 |     29.427 |   0.9758 |     30.819 |     1.7
   11 |   0.8936 |     28.004 |   0.9572 |     29.671 |     1.8
   12 |   0.8625 |     27.156 |   0.9407 |     28.430 |     2.0
   13 |   0.8296 |     25.919 |   0.9146 |     28.895 |     2.2
   14 |   0.7963 |     24.989 |   0.9207 |     27.778 |     2.3
   15 |   0.7693 |     24.157 |   0.9139 |     28.430 |     2.5
   16 |   0.7352 |     23.047 |   0.9004 |     27.840 |     2.7
   17 |   0.7070 |     22.144 |   0.8997 |     27.840 |     2.9
   18 |   0.6769 |     21.197 |   0.8914 |     27.312 |     3.0
   19 |   0.6547 |     20.721 |   0.8909 |     26.691 |     3.2
   20 |   0.6370 |     20.125 |   0.9000 |     26.536 |     3.4
   21 |   0.6145 |     19.446 |   0.8981 |     27.095 |     3.6
   22 |   0.5978 |     18.905 |   0.9035 |     26.629 |     3.7
   23 |   0.5684 |     18.073 |   0.8852 |     25.636 |     3.9
   24 |   0.5544 |     17.471 |   0.8985 |     26.350 |     4.1
   25 |   0.5329 |     16.694 |   0.8895 |     26.040 |     4.2
   26 |   0.5152 |     16.273 |   0.8989 |     25.264 |     4.4
   27 |   0.5047 |     15.709 |   0.9123 |     25.605 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,505

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3004 |     59.548 |   1.5193 |     45.562 |     0.1
    2 |   1.5010 |     44.698 |   1.3527 |     42.489 |     0.3
    3 |   1.3619 |     41.951 |   1.2599 |     39.013 |     0.4
    4 |   1.2696 |     39.566 |   1.1934 |     37.399 |     0.6
    5 |   1.2069 |     38.044 |   1.1465 |     36.158 |     0.7
    6 |   1.1459 |     36.359 |   1.1010 |     34.947 |     0.8
    7 |   1.0962 |     34.614 |   1.0717 |     34.295 |     1.0
    8 |   1.0514 |     33.437 |   1.0524 |     33.551 |     1.1
    9 |   1.0103 |     32.223 |   1.0248 |     32.961 |     1.3
   10 |   0.9668 |     30.384 |   0.9886 |     31.099 |     1.4
   11 |   0.9324 |     29.541 |   0.9868 |     30.881 |     1.5
   12 |   0.8992 |     28.278 |   0.9728 |     31.223 |     1.7
   13 |   0.8604 |     27.254 |   0.9532 |     29.826 |     1.8
   14 |   0.8297 |     26.280 |   0.9498 |     29.733 |     1.9
   15 |   0.7924 |     25.011 |   0.9269 |     28.802 |     2.1
   16 |   0.7630 |     24.135 |   0.9280 |     28.678 |     2.2
   17 |   0.7268 |     22.762 |   0.9298 |     28.523 |     2.4
   18 |   0.7073 |     22.292 |   0.9131 |     27.405 |     2.5
   19 |   0.6818 |     21.383 |   0.9134 |     28.057 |     2.6
   20 |   0.6644 |     20.940 |   0.9175 |     27.561 |     2.8
   21 |   0.6341 |     20.043 |   0.8983 |     27.250 |     2.9
   22 |   0.6159 |     19.545 |   0.9084 |     26.847 |     3.0
   23 |   0.5923 |     18.527 |   0.9238 |     26.474 |     3.2
   24 |   0.5695 |     18.089 |   0.9228 |     26.909 |     3.3
   25 |   0.5482 |     17.405 |   0.9290 |     26.847 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 420,129

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6986 |     64.648 |   1.9607 |     48.386 |     0.2
    2 |   1.8511 |     46.307 |   1.5755 |     44.910 |     0.3
    3 |   1.5944 |     44.474 |   1.4408 |     42.737 |     0.5
    4 |   1.4713 |     42.947 |   1.3597 |     40.937 |     0.7
    5 |   1.3858 |     40.944 |   1.2897 |     38.827 |     0.8
    6 |   1.3187 |     39.494 |   1.2388 |     37.399 |     1.0
    7 |   1.2626 |     38.143 |   1.2012 |     36.189 |     1.1
    8 |   1.2126 |     36.863 |   1.1612 |     35.320 |     1.3
    9 |   1.1704 |     35.724 |   1.1457 |     34.947 |     1.5
   10 |   1.1270 |     34.318 |   1.1153 |     34.606 |     1.6
   11 |   1.0976 |     33.952 |   1.0953 |     34.140 |     1.8
   12 |   1.0597 |     32.365 |   1.0752 |     33.302 |     2.0
   13 |   1.0291 |     31.708 |   1.0598 |     32.651 |     2.1
   14 |   0.9961 |     30.488 |   1.0426 |     32.651 |     2.3
   15 |   0.9667 |     29.706 |   1.0441 |     31.906 |     2.5
   16 |   0.9428 |     29.148 |   1.0188 |     31.626 |     2.6
   17 |   0.9219 |     28.403 |   1.0025 |     31.254 |     2.8
   18 |   0.8936 |     27.446 |   1.0190 |     31.533 |     3.0
   19 |   0.8732 |     27.145 |   1.0077 |     30.695 |     3.1
   20 |   0.8545 |     26.488 |   1.0089 |     30.540 |     3.3
   21 |   0.8309 |     25.640 |   0.9995 |     29.950 |     3.4
   22 |   0.8117 |     25.055 |   1.0103 |     30.137 |     3.6
   23 |   0.8016 |     24.776 |   0.9849 |     29.671 |     3.8
   24 |   0.7767 |     24.228 |   0.9763 |     29.019 |     3.9
   25 |   0.7614 |     23.621 |   0.9733 |     29.174 |     4.1
   26 |   0.7432 |     22.740 |   0.9718 |     28.864 |     4.3
   27 |   0.7261 |     22.319 |   0.9741 |     28.461 |     4.4
   28 |   0.7117 |     21.991 |   0.9741 |     28.150 |     4.6
   29 |   0.6955 |     21.673 |   0.9930 |     29.081 |     4.8
   30 |   0.6897 |     21.487 |   0.9823 |     28.554 |     4.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,713

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6049 |     46.887 |   1.2945 |     42.551 |     0.2
    2 |   1.2071 |     40.151 |   1.1476 |     37.741 |     0.3
    3 |   1.0913 |     36.687 |   1.0516 |     34.358 |     0.5
    4 |   1.0009 |     33.919 |   1.0264 |     33.271 |     0.6
    5 |   0.9362 |     31.555 |   0.9677 |     32.154 |     0.8
    6 |   0.8648 |     29.022 |   0.9453 |     31.595 |     0.9
    7 |   0.8334 |     28.381 |   0.8930 |     28.554 |     1.1
    8 |   0.7754 |     26.231 |   0.8508 |     28.243 |     1.2
    9 |   0.7260 |     24.480 |   0.8629 |     27.902 |     1.4
   10 |   0.7020 |     23.988 |   0.8620 |     28.274 |     1.5
   11 |   0.6540 |     22.253 |   0.8396 |     26.195 |     1.7
   12 |   0.6323 |     21.372 |   0.8252 |     26.102 |     1.9
   13 |   0.5931 |     19.966 |   0.8062 |     26.071 |     2.0
   14 |   0.5681 |     19.457 |   0.7906 |     24.519 |     2.2
   15 |   0.5476 |     18.363 |   0.8126 |     25.388 |     2.3
   16 |   0.5342 |     18.511 |   0.8039 |     24.115 |     2.5
   17 |   0.4960 |     17.241 |   0.8080 |     24.488 |     2.6
   18 |   0.4717 |     16.289 |   0.8240 |     24.209 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 386,657

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6723 |     48.238 |   1.2999 |     42.396 |     0.1
    2 |   1.2027 |     39.385 |   1.1316 |     36.840 |     0.2
    3 |   1.0670 |     35.451 |   1.0526 |     33.861 |     0.4
    4 |   0.9834 |     32.753 |   1.0074 |     33.333 |     0.5
    5 |   0.8997 |     29.952 |   0.9518 |     30.912 |     0.6
    6 |   0.8436 |     28.179 |   0.9110 |     30.074 |     0.7
    7 |   0.7827 |     26.023 |   0.8787 |     29.299 |     0.9
    8 |   0.7457 |     25.356 |   0.8600 |     28.181 |     1.0
    9 |   0.6906 |     23.222 |   0.8620 |     28.119 |     1.1
   10 |   0.6511 |     21.925 |   0.8411 |     27.529 |     1.2
   11 |   0.6210 |     20.852 |   0.8317 |     26.133 |     1.3
   12 |   0.5912 |     19.906 |   0.8066 |     26.691 |     1.5
   13 |   0.5466 |     18.450 |   0.8133 |     25.140 |     1.6
   14 |   0.5233 |     17.701 |   0.8175 |     24.891 |     1.7
   15 |   0.4951 |     16.749 |   0.7943 |     23.743 |     1.8
   16 |   0.4724 |     16.076 |   0.8160 |     24.271 |     2.0
   17 |   0.4517 |     15.102 |   0.8232 |     24.271 |     2.1
   18 |   0.4398 |     14.839 |   0.8199 |     24.271 |     2.2
   19 |   0.4215 |     14.341 |   0.8106 |     22.346 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 485,729

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6271 |     47.428 |   1.2968 |     42.179 |     0.1
    2 |   1.2589 |     41.005 |   1.1392 |     37.554 |     0.2
    3 |   1.1517 |     38.482 |   1.0804 |     36.002 |     0.3
    4 |   1.0773 |     36.004 |   1.0223 |     34.047 |     0.4
    5 |   1.0124 |     33.798 |   0.9955 |     32.899 |     0.5
    6 |   0.9702 |     32.496 |   0.9906 |     33.147 |     0.6
    7 |   0.9216 |     30.767 |   0.9484 |     31.161 |     0.7
    8 |   0.8708 |     28.989 |   0.9306 |     31.006 |     0.8
    9 |   0.8424 |     28.190 |   0.9013 |     30.385 |     0.9
   10 |   0.8088 |     27.156 |   0.8760 |     28.957 |     1.0
   11 |   0.7752 |     25.717 |   0.8452 |     27.529 |     1.1
   12 |   0.7378 |     24.759 |   0.8547 |     28.461 |     1.2
   13 |   0.7100 |     24.267 |   0.8530 |     26.940 |     1.3
   14 |   0.6830 |     22.981 |   0.8138 |     25.450 |     1.4
   15 |   0.6613 |     22.428 |   0.8423 |     26.940 |     1.5
   16 |   0.6279 |     20.978 |   0.8206 |     25.264 |     1.6
   17 |   0.6026 |     20.727 |   0.8347 |     25.978 |     1.8
   18 |   0.5737 |     19.654 |   0.8212 |     24.922 |     1.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,257

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9409 |     51.548 |   1.4012 |     41.806 |     0.2
    2 |   1.3088 |     40.304 |   1.2428 |     37.709 |     0.3
    3 |   1.1686 |     36.480 |   1.1502 |     35.475 |     0.5
    4 |   1.0641 |     33.317 |   1.0683 |     33.023 |     0.7
    5 |   0.9734 |     30.116 |   0.9881 |     31.285 |     0.8
    6 |   0.8975 |     27.982 |   0.9626 |     31.378 |     1.0
    7 |   0.8284 |     25.443 |   0.9201 |     29.423 |     1.2
    8 |   0.7720 |     23.588 |   0.8874 |     27.623 |     1.3
    9 |   0.7025 |     21.460 |   0.8582 |     26.288 |     1.5
   10 |   0.6418 |     19.610 |   0.8420 |     25.885 |     1.7
   11 |   0.6024 |     18.385 |   0.8572 |     27.157 |     1.8
   12 |   0.5514 |     16.699 |   0.8254 |     25.109 |     2.0
   13 |   0.5124 |     15.523 |   0.8576 |     26.040 |     2.2
   14 |   0.4837 |     14.680 |   0.8171 |     24.984 |     2.3
   15 |   0.4488 |     13.707 |   0.8131 |     24.178 |     2.5
   16 |   0.4129 |     12.377 |   0.8232 |     24.084 |     2.6
   17 |   0.3901 |     11.879 |   0.8097 |     23.122 |     2.8
   18 |   0.3502 |     10.347 |   0.8063 |     23.215 |     3.0
   19 |   0.3333 |      9.947 |   0.8265 |     23.340 |     3.1
   20 |   0.3081 |      9.198 |   0.8303 |     23.619 |     3.3
   21 |   0.2871 |      8.601 |   0.8599 |     22.998 |     3.4
   22 |   0.2733 |      8.120 |   0.8530 |     23.929 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,129

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6379 |     47.609 |   1.2750 |     42.117 |     0.1
    2 |   1.2130 |     40.446 |   1.1579 |     39.323 |     0.3
    3 |   1.0955 |     36.791 |   1.0628 |     35.754 |     0.4
    4 |   1.0078 |     33.596 |   0.9960 |     32.651 |     0.6
    5 |   0.9360 |     31.539 |   0.9610 |     32.526 |     0.8
    6 |   0.8800 |     29.607 |   0.9366 |     31.316 |     0.9
    7 |   0.8262 |     27.905 |   0.8943 |     29.143 |     1.1
    8 |   0.7729 |     25.897 |   0.9147 |     30.106 |     1.2
    9 |   0.7288 |     24.311 |   0.8377 |     27.374 |     1.4
   10 |   0.6922 |     23.025 |   0.8491 |     26.878 |     1.5
   11 |   0.6624 |     22.253 |   0.8389 |     26.723 |     1.7
   12 |   0.6255 |     20.770 |   0.8388 |     26.288 |     1.8
   13 |   0.5846 |     19.687 |   0.8534 |     26.567 |     2.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,272,993

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0085 |     53.075 |   1.4086 |     41.713 |     0.1
    2 |   1.3114 |     40.195 |   1.2444 |     38.268 |     0.3
    3 |   1.1678 |     36.277 |   1.1418 |     35.133 |     0.4
    4 |   1.0621 |     32.950 |   1.0696 |     32.961 |     0.6
    5 |   0.9775 |     30.477 |   1.0171 |     30.912 |     0.7
    6 |   0.9039 |     27.752 |   0.9727 |     29.764 |     0.9
    7 |   0.8325 |     25.662 |   0.9557 |     29.702 |     1.0
    8 |   0.7768 |     23.835 |   0.9254 |     28.895 |     1.2
    9 |   0.7208 |     21.887 |   0.8890 |     27.529 |     1.4
   10 |   0.6769 |     20.617 |   0.8796 |     27.157 |     1.5
   11 |   0.6248 |     19.162 |   0.8759 |     27.592 |     1.7
   12 |   0.5825 |     17.515 |   0.8462 |     25.791 |     1.8
   13 |   0.5464 |     16.689 |   0.8674 |     26.226 |     2.0
   14 |   0.5182 |     15.813 |   0.8371 |     26.164 |     2.1
   15 |   0.4758 |     14.396 |   0.8247 |     24.705 |     2.3
   16 |   0.4398 |     13.345 |   0.8160 |     24.146 |     2.4
   17 |   0.4143 |     12.355 |   0.8326 |     24.333 |     2.6
   18 |   0.3899 |     12.016 |   0.8408 |     24.674 |     2.7
   19 |   0.3553 |     10.845 |   0.8445 |     23.526 |     2.9
   20 |   0.3375 |     10.243 |   0.8321 |     23.650 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,089

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3697 |     61.283 |   1.5300 |     43.544 |     0.2
    2 |   1.4909 |     43.658 |   1.3221 |     40.751 |     0.3
    3 |   1.3356 |     40.709 |   1.2252 |     38.082 |     0.5
    4 |   1.2442 |     38.696 |   1.1699 |     35.971 |     0.7
    5 |   1.1771 |     36.939 |   1.1236 |     35.227 |     0.8
    6 |   1.1188 |     35.030 |   1.0774 |     34.109 |     1.0
    7 |   1.0688 |     33.749 |   1.0377 |     32.992 |     1.1
    8 |   1.0221 |     32.283 |   1.0090 |     31.316 |     1.3
    9 |   0.9731 |     30.461 |   0.9896 |     30.695 |     1.5
   10 |   0.9323 |     28.929 |   0.9657 |     30.012 |     1.6
   11 |   0.8931 |     27.741 |   0.9479 |     29.485 |     1.8
   12 |   0.8553 |     26.860 |   0.9545 |     29.454 |     2.0
   13 |   0.8224 |     25.739 |   0.9234 |     28.678 |     2.1
   14 |   0.7887 |     24.798 |   0.9403 |     28.461 |     2.3
   15 |   0.7591 |     23.621 |   0.9238 |     27.902 |     2.5
   16 |   0.7350 |     22.718 |   0.9229 |     28.181 |     2.6
   17 |   0.7005 |     21.996 |   0.9045 |     27.467 |     2.8
   18 |   0.6768 |     21.214 |   0.9150 |     26.909 |     3.0
   19 |   0.6501 |     20.541 |   0.9463 |     27.064 |     3.1
   20 |   0.6291 |     19.578 |   0.9143 |     27.219 |     3.3
   21 |   0.6036 |     19.014 |   0.9028 |     26.319 |     3.5
   22 |   0.5824 |     18.084 |   0.9384 |     26.567 |     3.6
   23 |   0.5604 |     17.668 |   0.9224 |     26.257 |     3.8
   24 |   0.5401 |     17.033 |   0.9270 |     26.133 |     4.0
   25 |   0.5264 |     16.535 |   0.9234 |     26.164 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,201

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4721 |     45.896 |   1.2403 |     42.179 |     0.1
    2 |   1.1802 |     39.784 |   1.1133 |     37.275 |     0.3
    3 |   1.0904 |     37.103 |   1.1249 |     37.616 |     0.4
    4 |   1.0207 |     34.504 |   1.0093 |     33.892 |     0.6
    5 |   0.9587 |     32.627 |   0.9800 |     33.054 |     0.7
    6 |   0.9101 |     31.358 |   0.9613 |     31.533 |     0.9
    7 |   0.8769 |     30.357 |   0.9166 |     30.416 |     1.0
    8 |   0.8372 |     28.513 |   0.9358 |     31.782 |     1.2
    9 |   0.8029 |     27.659 |   0.8734 |     29.764 |     1.3
   10 |   0.7725 |     26.280 |   0.8539 |     28.802 |     1.5
   11 |   0.7521 |     25.974 |   0.8503 |     28.430 |     1.6
   12 |   0.7153 |     24.568 |   0.8400 |     27.716 |     1.7
   13 |   0.6993 |     23.802 |   0.8470 |     28.274 |     1.9
   14 |   0.6704 |     23.337 |   0.8685 |     26.940 |     2.0
   15 |   0.6293 |     21.739 |   0.8137 |     27.312 |     2.2
   16 |   0.6339 |     21.887 |   0.8689 |     27.995 |     2.3
   17 |   0.6192 |     21.093 |   0.8776 |     28.336 |     2.5
   18 |   0.5959 |     20.502 |   0.8390 |     26.319 |     2.6
   19 |   0.5855 |     20.420 |   0.8118 |     25.760 |     2.8
   20 |   0.5446 |     18.926 |   0.8365 |     26.226 |     2.9
   21 |   0.5511 |     19.413 |   0.8257 |     26.133 |     3.1
   22 |   0.5181 |     17.788 |   0.8181 |     24.736 |     3.2
   23 |   0.5085 |     17.504 |   0.8436 |     25.667 |     3.3
   24 |   0.5145 |     17.854 |   0.7812 |     23.929 |     3.5
   25 |   0.4992 |     17.099 |   0.8390 |     25.171 |     3.6
   26 |   0.4806 |     16.793 |   0.8145 |     25.016 |     3.8
   27 |   0.4625 |     16.016 |   0.8320 |     25.202 |     3.9
   28 |   0.4447 |     15.660 |   0.7932 |     23.867 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 535,713

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6601 |     47.915 |   1.2867 |     42.086 |     0.2
    2 |   1.2562 |     41.628 |   1.1770 |     39.044 |     0.3
    3 |   1.1596 |     39.183 |   1.1098 |     37.151 |     0.5
    4 |   1.0989 |     37.809 |   1.0655 |     36.499 |     0.7
    5 |   1.0409 |     35.073 |   1.0428 |     35.164 |     0.8
    6 |   0.9982 |     33.755 |   0.9843 |     32.185 |     1.0
    7 |   0.9458 |     31.462 |   0.9449 |     32.185 |     1.2
    8 |   0.9184 |     30.838 |   0.9532 |     31.937 |     1.3
    9 |   0.8747 |     29.717 |   0.9049 |     30.385 |     1.5
   10 |   0.8414 |     28.671 |   0.9018 |     30.137 |     1.7
   11 |   0.8126 |     27.572 |   0.8684 |     28.802 |     1.9
   12 |   0.7767 |     25.974 |   0.8642 |     28.957 |     2.0
   13 |   0.7419 |     24.699 |   0.8658 |     27.685 |     2.2
   14 |   0.7194 |     24.048 |   0.8381 |     27.592 |     2.4
   15 |   0.6977 |     23.599 |   0.8525 |     27.467 |     2.5
   16 |   0.6613 |     22.571 |   0.8175 |     26.164 |     2.7
   17 |   0.6418 |     21.717 |   0.8298 |     26.257 |     2.9
   18 |   0.6098 |     20.584 |   0.8054 |     25.078 |     3.0
   19 |   0.5788 |     19.791 |   0.8094 |     24.519 |     3.2
   20 |   0.5700 |     19.102 |   0.8078 |     24.457 |     3.4
   21 |   0.5432 |     18.669 |   0.8218 |     24.674 |     3.5
   22 |   0.5277 |     17.597 |   0.8383 |     25.357 |     3.7
   23 |   0.5098 |     17.307 |   0.8013 |     23.991 |     3.9
   24 |   0.4661 |     15.846 |   0.8501 |     24.053 |     4.1
   25 |   0.4757 |     16.191 |   0.8243 |     23.960 |     4.2
   26 |   0.4473 |     15.337 |   0.8345 |     23.774 |     4.4
   27 |   0.4277 |     14.418 |   0.8456 |     23.495 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,473

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5044 |     46.640 |   1.2453 |     41.465 |     0.2
    2 |   1.2364 |     41.617 |   1.1903 |     40.099 |     0.3
    3 |   1.1643 |     39.823 |   1.1037 |     37.523 |     0.5
    4 |   1.1053 |     37.749 |   1.0872 |     37.430 |     0.6
    5 |   1.0650 |     36.671 |   1.0318 |     34.699 |     0.8
    6 |   1.0128 |     34.980 |   1.0132 |     34.047 |     1.0
    7 |   0.9862 |     33.984 |   0.9855 |     33.085 |     1.1
    8 |   0.9442 |     32.496 |   0.9572 |     32.278 |     1.3
    9 |   0.9124 |     31.123 |   0.9120 |     31.440 |     1.4
   10 |   0.8761 |     29.968 |   0.9265 |     32.030 |     1.6
   11 |   0.8488 |     28.983 |   0.9004 |     29.112 |     1.8
   12 |   0.8184 |     27.895 |   0.8896 |     29.547 |     1.9
   13 |   0.7836 |     27.025 |   0.8805 |     29.640 |     2.1
   14 |   0.7629 |     26.051 |   0.8767 |     30.478 |     2.3
   15 |   0.7369 |     25.454 |   0.8489 |     28.274 |     2.4
   16 |   0.7102 |     24.190 |   0.8245 |     27.343 |     2.6
   17 |   0.6930 |     23.714 |   0.8191 |     27.964 |     2.7
   18 |   0.6568 |     22.335 |   0.7969 |     26.785 |     2.9
   19 |   0.6442 |     22.144 |   0.8275 |     27.343 |     3.1
   20 |   0.6230 |     21.307 |   0.7863 |     26.878 |     3.2
   21 |   0.5987 |     20.338 |   0.8029 |     25.947 |     3.4
   22 |   0.5735 |     19.556 |   0.8139 |     26.319 |     3.5
   23 |   0.5514 |     19.019 |   0.7957 |     26.009 |     3.7
   24 |   0.5411 |     18.801 |   0.7804 |     24.364 |     3.9
   25 |   0.5162 |     17.723 |   0.7893 |     24.457 |     4.0
   26 |   0.4945 |     16.809 |   0.7941 |     24.643 |     4.2
   27 |   0.4655 |     15.780 |   0.7764 |     24.084 |     4.3
   28 |   0.4599 |     15.972 |   0.7998 |     24.364 |     4.5
   29 |   0.4457 |     15.343 |   0.8053 |     24.488 |     4.7
   30 |   0.4271 |     14.522 |   0.8112 |     24.891 |     4.8
   31 |   0.4118 |     14.035 |   0.7969 |     23.898 |     5.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,201

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5342 |     46.821 |   1.2751 |     41.403 |     0.1
    2 |   1.2393 |     41.530 |   1.1702 |     38.703 |     0.3
    3 |   1.1696 |     39.270 |   1.1194 |     37.834 |     0.5
    4 |   1.1076 |     37.486 |   1.0593 |     35.568 |     0.6
    5 |   1.0619 |     36.228 |   1.0249 |     35.413 |     0.8
    6 |   1.0201 |     34.772 |   1.0096 |     34.327 |     0.9
    7 |   0.9816 |     33.601 |   0.9631 |     32.092 |     1.1
    8 |   0.9549 |     32.441 |   0.9548 |     32.216 |     1.2
    9 |   0.9148 |     31.101 |   0.9375 |     31.006 |     1.4
   10 |   0.8857 |     30.417 |   0.9165 |     30.944 |     1.5
   11 |   0.8539 |     28.961 |   0.9061 |     30.447 |     1.7
   12 |   0.8192 |     27.561 |   0.9253 |     31.409 |     1.9
   13 |   0.8109 |     27.402 |   0.8742 |     28.864 |     2.0
   14 |   0.7683 |     26.302 |   0.8476 |     28.709 |     2.2
   15 |   0.7485 |     25.208 |   0.8641 |     28.430 |     2.3
   16 |   0.7177 |     24.354 |   0.8729 |     28.616 |     2.5
   17 |   0.7047 |     23.966 |   0.8586 |     27.654 |     2.6
   18 |   0.6678 |     22.800 |   0.8662 |     27.126 |     2.8
   19 |   0.6523 |     21.826 |   0.8308 |     27.002 |     2.9
   20 |   0.6366 |     21.613 |   0.8634 |     27.250 |     3.1
   21 |   0.6127 |     20.995 |   0.8346 |     26.629 |     3.2
   22 |   0.5932 |     20.311 |   0.8408 |     26.319 |     3.4
   23 |   0.5688 |     19.348 |   0.8407 |     25.854 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 485,729

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6713 |     47.543 |   1.2973 |     41.899 |     0.1
    2 |   1.2537 |     40.972 |   1.1646 |     39.106 |     0.3
    3 |   1.1587 |     38.865 |   1.0794 |     35.568 |     0.4
    4 |   1.0909 |     36.906 |   1.0183 |     33.675 |     0.5
    5 |   1.0316 |     34.707 |   1.0042 |     33.737 |     0.7
    6 |   0.9826 |     32.830 |   0.9687 |     32.682 |     0.8
    7 |   0.9327 |     31.276 |   0.9490 |     31.626 |     0.9
    8 |   0.8870 |     29.853 |   0.9209 |     29.981 |     1.1
    9 |   0.8609 |     28.671 |   0.9095 |     30.168 |     1.2
   10 |   0.8183 |     27.134 |   0.8932 |     30.106 |     1.4
   11 |   0.7814 |     26.034 |   0.9001 |     28.988 |     1.5
   12 |   0.7443 |     25.011 |   0.8617 |     28.243 |     1.6
   13 |   0.7131 |     23.955 |   0.8330 |     26.909 |     1.8
   14 |   0.6803 |     22.850 |   0.8430 |     27.654 |     1.9
   15 |   0.6478 |     21.887 |   0.8324 |     26.133 |     2.0
   16 |   0.6216 |     20.749 |   0.8149 |     25.047 |     2.2
   17 |   0.5993 |     19.955 |   0.7920 |     24.053 |     2.3
   18 |   0.5786 |     19.463 |   0.8159 |     24.178 |     2.4
   19 |   0.5516 |     18.565 |   0.8234 |     24.581 |     2.6
   20 |   0.5186 |     17.416 |   0.8506 |     24.022 |     2.7
   21 |   0.5053 |     17.110 |   0.8108 |     23.246 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 386,657

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7083 |     67.953 |   1.9603 |     45.345 |     0.1
    2 |   1.8585 |     46.487 |   1.5766 |     44.538 |     0.2
    3 |   1.6011 |     44.364 |   1.4516 |     43.110 |     0.3
    4 |   1.4846 |     43.226 |   1.3723 |     41.713 |     0.4
    5 |   1.4028 |     41.803 |   1.3139 |     40.223 |     0.5
    6 |   1.3392 |     40.118 |   1.2684 |     39.199 |     0.6
    7 |   1.2877 |     38.860 |   1.2384 |     37.865 |     0.7
    8 |   1.2388 |     37.667 |   1.1938 |     36.592 |     0.8
    9 |   1.1963 |     36.660 |   1.1611 |     35.599 |     0.9
   10 |   1.1575 |     35.774 |   1.1347 |     35.102 |     1.0
   11 |   1.1196 |     34.811 |   1.1085 |     34.854 |     1.1
   12 |   1.0893 |     33.667 |   1.0931 |     34.140 |     1.2
   13 |   1.0587 |     32.748 |   1.0747 |     33.364 |     1.3
   14 |   1.0367 |     32.359 |   1.0643 |     32.682 |     1.4
   15 |   1.0051 |     31.276 |   1.0443 |     32.464 |     1.4
   16 |   0.9782 |     30.176 |   1.0268 |     32.092 |     1.5
   17 |   0.9614 |     29.946 |   1.0187 |     31.192 |     1.6
   18 |   0.9371 |     29.372 |   1.0174 |     31.533 |     1.7
   19 |   0.9144 |     28.540 |   1.0004 |     30.975 |     1.8
   20 |   0.8949 |     27.812 |   0.9916 |     30.292 |     1.9
   21 |   0.8788 |     27.413 |   1.0037 |     30.726 |     2.0
   22 |   0.8591 |     26.997 |   0.9862 |     30.168 |     2.1
   23 |   0.8431 |     26.521 |   0.9859 |     29.888 |     2.2
   24 |   0.8246 |     26.122 |   0.9733 |     30.043 |     2.3
   25 |   0.8069 |     25.454 |   0.9874 |     30.602 |     2.4
   26 |   0.7890 |     25.005 |   0.9864 |     30.168 |     2.5
   27 |   0.7742 |     24.207 |   0.9673 |     28.895 |     2.6
   28 |   0.7598 |     24.108 |   0.9700 |     29.826 |     2.7
   29 |   0.7449 |     23.506 |   0.9806 |     30.385 |     2.8
   30 |   0.7327 |     22.970 |   0.9600 |     29.112 |     2.9
   31 |   0.7156 |     22.653 |   0.9622 |     28.678 |     3.0
   32 |   0.7042 |     22.352 |   0.9690 |     28.709 |     3.1
   33 |   0.6923 |     21.783 |   0.9716 |     29.143 |     3.2
   34 |   0.6729 |     21.389 |   0.9803 |     29.516 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,471,777

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1504 |     55.734 |   1.4560 |     44.041 |     0.2
    2 |   1.4388 |     43.407 |   1.2968 |     40.130 |     0.3
    3 |   1.3077 |     40.359 |   1.2184 |     37.151 |     0.5
    4 |   1.2177 |     37.618 |   1.1601 |     36.313 |     0.7
    5 |   1.1475 |     35.801 |   1.0988 |     34.854 |     0.9
    6 |   1.0915 |     34.411 |   1.0542 |     33.178 |     1.0
    7 |   1.0335 |     32.250 |   1.0202 |     32.433 |     1.2
    8 |   0.9799 |     30.920 |   0.9930 |     31.719 |     1.4
    9 |   0.9326 |     28.890 |   0.9738 |     30.199 |     1.5
   10 |   0.8926 |     27.626 |   0.9427 |     30.043 |     1.7
   11 |   0.8473 |     26.543 |   0.9255 |     28.523 |     1.9
   12 |   0.8106 |     25.192 |   0.9064 |     28.026 |     2.1
   13 |   0.7689 |     24.157 |   0.8995 |     27.778 |     2.2
   14 |   0.7336 |     23.003 |   0.9024 |     27.467 |     2.4
   15 |   0.7054 |     22.073 |   0.8965 |     26.971 |     2.6
   16 |   0.6762 |     21.164 |   0.8738 |     26.660 |     2.7
   17 |   0.6431 |     20.136 |   0.8717 |     26.040 |     2.9
   18 |   0.6144 |     19.107 |   0.8958 |     26.660 |     3.1
   19 |   0.5911 |     18.511 |   0.8633 |     25.822 |     3.3
   20 |   0.5721 |     17.876 |   0.8766 |     25.450 |     3.4
   21 |   0.5457 |     16.957 |   0.8867 |     25.947 |     3.6
   22 |   0.5279 |     16.869 |   0.8852 |     25.140 |     3.8
   23 |   0.4992 |     15.928 |   0.8839 |     24.705 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,505

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1284 |     55.138 |   1.4803 |     43.513 |     0.1
    2 |   1.3700 |     41.371 |   1.2986 |     39.013 |     0.3
    3 |   1.2157 |     37.273 |   1.1816 |     36.251 |     0.4
    4 |   1.1059 |     34.242 |   1.1072 |     33.675 |     0.5
    5 |   1.0118 |     30.778 |   1.0518 |     33.489 |     0.6
    6 |   0.9344 |     28.589 |   1.0131 |     31.782 |     0.8
    7 |   0.8723 |     26.685 |   0.9801 |     30.323 |     0.9
    8 |   0.8093 |     24.781 |   0.9357 |     28.771 |     1.0
    9 |   0.7627 |     23.172 |   0.9134 |     27.467 |     1.1
   10 |   0.7055 |     21.673 |   0.9024 |     28.119 |     1.3
   11 |   0.6606 |     20.043 |   0.8754 |     27.126 |     1.4
   12 |   0.6182 |     18.719 |   0.8669 |     26.536 |     1.5
   13 |   0.5845 |     17.947 |   0.8620 |     26.288 |     1.7
   14 |   0.5454 |     16.612 |   0.8524 |     25.264 |     1.8
   15 |   0.5157 |     15.660 |   0.8716 |     25.698 |     1.9
   16 |   0.4885 |     14.664 |   0.8373 |     25.109 |     2.0
   17 |   0.4558 |     13.843 |   0.8194 |     23.526 |     2.2
   18 |   0.4288 |     12.683 |   0.8387 |     24.488 |     2.3
   19 |   0.4009 |     12.322 |   0.8327 |     23.371 |     2.4
   20 |   0.3782 |     11.518 |   0.8225 |     23.402 |     2.6
   21 |   0.3689 |     11.365 |   0.8403 |     23.277 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 602,465

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5766 |     47.073 |   1.2928 |     41.092 |     0.1
    2 |   1.2008 |     39.850 |   1.1528 |     38.175 |     0.2
    3 |   1.0833 |     36.036 |   1.0326 |     34.885 |     0.4
    4 |   0.9945 |     33.301 |   0.9954 |     32.961 |     0.5
    5 |   0.9321 |     31.353 |   0.9680 |     32.651 |     0.6
    6 |   0.8734 |     29.470 |   0.9143 |     29.950 |     0.7
    7 |   0.8303 |     27.834 |   0.8873 |     29.795 |     0.8
    8 |   0.7802 |     26.204 |   0.8764 |     29.454 |     1.0
    9 |   0.7374 |     25.093 |   0.8548 |     28.492 |     1.1
   10 |   0.7102 |     24.420 |   0.8190 |     25.854 |     1.2
   11 |   0.6648 |     22.800 |   0.8414 |     27.685 |     1.3
   12 |   0.6306 |     21.318 |   0.8091 |     25.450 |     1.4
   13 |   0.6105 |     20.562 |   0.7917 |     24.364 |     1.6
   14 |   0.5675 |     19.309 |   0.8074 |     26.164 |     1.7
   15 |   0.5595 |     19.255 |   0.8448 |     26.226 |     1.8
   16 |   0.5326 |     18.040 |   0.8111 |     25.388 |     1.9
   17 |   0.5119 |     17.482 |   0.8445 |     25.667 |     2.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,272,993

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4536 |     45.256 |   1.2273 |     40.565 |     0.1
    2 |   1.1441 |     38.789 |   1.1015 |     36.561 |     0.2
    3 |   1.0349 |     35.046 |   1.0528 |     35.320 |     0.4
    4 |   0.9626 |     32.633 |   0.9550 |     31.688 |     0.5
    5 |   0.8834 |     29.979 |   0.9326 |     31.719 |     0.6
    6 |   0.8321 |     28.228 |   0.9152 |     30.912 |     0.7
    7 |   0.7899 |     26.505 |   0.8827 |     29.981 |     0.9
    8 |   0.7448 |     25.421 |   0.8668 |     28.926 |     1.0
    9 |   0.7020 |     23.960 |   0.8411 |     27.716 |     1.1
   10 |   0.6762 |     22.882 |   0.8347 |     26.909 |     1.2
   11 |   0.6409 |     21.909 |   0.8382 |     26.629 |     1.4
   12 |   0.6252 |     21.438 |   0.8335 |     26.847 |     1.5
   13 |   0.5767 |     19.446 |   0.8147 |     25.698 |     1.6
   14 |   0.5395 |     18.336 |   0.7985 |     24.457 |     1.7
   15 |   0.5223 |     17.766 |   0.8178 |     24.953 |     1.8
   16 |   0.5045 |     17.279 |   0.8051 |     24.550 |     2.0
   17 |   0.4591 |     15.660 |   0.8152 |     24.612 |     2.1
   18 |   0.4403 |     15.124 |   0.8026 |     23.929 |     2.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,201

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0837 |     55.357 |   1.4759 |     43.234 |     0.2
    2 |   1.3732 |     41.393 |   1.2917 |     38.858 |     0.4
    3 |   1.2315 |     38.072 |   1.1976 |     36.778 |     0.5
    4 |   1.1260 |     34.942 |   1.1190 |     35.009 |     0.7
    5 |   1.0377 |     32.223 |   1.0583 |     33.147 |     0.9
    6 |   0.9609 |     29.815 |   1.0230 |     31.999 |     1.1
    7 |   0.9060 |     28.004 |   0.9765 |     30.850 |     1.3
    8 |   0.8405 |     26.122 |   0.9386 |     28.678 |     1.4
    9 |   0.7893 |     24.261 |   0.9474 |     29.423 |     1.6
   10 |   0.7345 |     22.467 |   0.9015 |     28.305 |     1.8
   11 |   0.6866 |     20.874 |   0.8937 |     27.529 |     2.0
   12 |   0.6507 |     19.796 |   0.8753 |     26.909 |     2.1
   13 |   0.6073 |     18.439 |   0.8561 |     26.909 |     2.3
   14 |   0.5641 |     16.995 |   0.8279 |     24.922 |     2.5
   15 |   0.5308 |     15.758 |   0.8626 |     25.978 |     2.7
   16 |   0.5034 |     15.047 |   0.8348 |     24.426 |     2.9
   17 |   0.4745 |     14.308 |   0.8379 |     25.295 |     3.0
   18 |   0.4394 |     13.050 |   0.8413 |     25.047 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,471,777

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5204 |     46.805 |   1.2378 |     39.851 |     0.1
    2 |   1.1890 |     39.954 |   1.1943 |     40.006 |     0.3
    3 |   1.0839 |     36.764 |   1.0984 |     37.337 |     0.4
    4 |   1.0093 |     34.045 |   1.0247 |     33.954 |     0.5
    5 |   0.9505 |     32.009 |   0.9993 |     33.271 |     0.7
    6 |   0.8972 |     30.286 |   0.9634 |     32.371 |     0.8
    7 |   0.8453 |     28.491 |   0.9218 |     30.819 |     0.9
    8 |   0.8013 |     27.041 |   0.9239 |     30.850 |     1.1
    9 |   0.7589 |     25.810 |   0.8630 |     28.678 |     1.2
   10 |   0.7142 |     24.283 |   0.8602 |     28.523 |     1.3
   11 |   0.6899 |     23.320 |   0.8669 |     27.716 |     1.5
   12 |   0.6341 |     21.263 |   0.8396 |     26.723 |     1.6
   13 |   0.6057 |     20.836 |   0.8170 |     25.698 |     1.7
   14 |   0.5841 |     19.599 |   0.8234 |     26.288 |     1.9
   15 |   0.5717 |     19.424 |   0.8407 |     26.288 |     2.0
   16 |   0.5498 |     18.658 |   0.8131 |     24.953 |     2.2
   17 |   0.5151 |     17.624 |   0.8101 |     24.426 |     2.3
   18 |   0.4795 |     16.191 |   0.7920 |     24.612 |     2.4
   19 |   0.4466 |     15.397 |   0.7888 |     24.053 |     2.6
   20 |   0.4335 |     14.894 |   0.8306 |     24.364 |     2.7
   21 |   0.4202 |     14.462 |   0.8004 |     22.967 |     2.8
   22 |   0.3983 |     13.603 |   0.8584 |     23.991 |     3.0
   23 |   0.4081 |     14.254 |   0.8293 |     22.657 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 470,369

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4689 |     59.537 |   1.7825 |     45.779 |     0.2
    2 |   1.6217 |     44.654 |   1.5027 |     44.010 |     0.3
    3 |   1.4395 |     41.738 |   1.3781 |     39.323 |     0.5
    4 |   1.3293 |     39.013 |   1.2905 |     38.020 |     0.6
    5 |   1.2432 |     36.731 |   1.2252 |     36.437 |     0.8
    6 |   1.1679 |     34.630 |   1.1669 |     34.606 |     1.0
    7 |   1.1064 |     33.000 |   1.1249 |     33.333 |     1.1
    8 |   1.0485 |     31.495 |   1.0888 |     33.209 |     1.3
    9 |   1.0034 |     30.242 |   1.0790 |     33.364 |     1.4
   10 |   0.9452 |     28.568 |   1.0421 |     32.216 |     1.6
   11 |   0.9030 |     27.298 |   1.0044 |     31.006 |     1.8
   12 |   0.8630 |     25.777 |   0.9968 |     31.099 |     1.9
   13 |   0.8222 |     25.060 |   0.9768 |     29.547 |     2.1
   14 |   0.7878 |     23.627 |   0.9626 |     29.268 |     2.2
   15 |   0.7512 |     22.631 |   0.9485 |     28.864 |     2.4
   16 |   0.7248 |     21.629 |   0.9360 |     28.709 |     2.6
   17 |   0.7008 |     21.044 |   0.9383 |     28.895 |     2.7
   18 |   0.6677 |     20.048 |   0.9119 |     27.592 |     2.9
   19 |   0.6358 |     18.910 |   0.9140 |     27.095 |     3.1
   20 |   0.6100 |     18.139 |   0.9113 |     28.026 |     3.2
   21 |   0.5889 |     17.362 |   0.8977 |     26.847 |     3.4
   22 |   0.5683 |     17.154 |   0.8983 |     26.381 |     3.6
   23 |   0.5411 |     16.180 |   0.9092 |     26.288 |     3.7
   24 |   0.5197 |     15.446 |   0.9049 |     26.909 |     3.9
   25 |   0.5069 |     15.053 |   0.9082 |     25.885 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 485,729

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4305 |     58.224 |   1.7316 |     45.065 |     0.1
    2 |   1.6777 |     45.568 |   1.5038 |     43.389 |     0.3
    3 |   1.5088 |     43.833 |   1.4013 |     41.217 |     0.4
    4 |   1.4166 |     42.099 |   1.3289 |     40.223 |     0.6
    5 |   1.3420 |     40.414 |   1.2724 |     38.672 |     0.7
    6 |   1.2760 |     38.466 |   1.2283 |     37.027 |     0.9
    7 |   1.2267 |     37.393 |   1.1791 |     36.903 |     1.0
    8 |   1.1755 |     36.091 |   1.1495 |     35.351 |     1.1
    9 |   1.1345 |     34.564 |   1.1295 |     35.599 |     1.3
   10 |   1.0954 |     33.651 |   1.0942 |     34.513 |     1.4
   11 |   1.0616 |     32.781 |   1.0739 |     33.551 |     1.6
   12 |   1.0270 |     31.807 |   1.0566 |     32.495 |     1.7
   13 |   0.9965 |     30.904 |   1.0491 |     32.495 |     1.9
   14 |   0.9681 |     30.012 |   1.0349 |     31.782 |     2.0
   15 |   0.9390 |     29.109 |   1.0035 |     30.881 |     2.2
   16 |   0.9066 |     27.971 |   0.9981 |     31.037 |     2.3
   17 |   0.8863 |     27.265 |   0.9874 |     30.509 |     2.4
   18 |   0.8570 |     26.510 |   0.9754 |     30.074 |     2.6
   19 |   0.8307 |     25.750 |   0.9735 |     29.547 |     2.7
   20 |   0.8140 |     25.235 |   0.9621 |     28.616 |     2.9
   21 |   0.7874 |     24.354 |   0.9421 |     28.864 |     3.0
   22 |   0.7740 |     23.922 |   0.9591 |     28.647 |     3.1
   23 |   0.7511 |     23.227 |   0.9563 |     28.988 |     3.3
   24 |   0.7364 |     22.445 |   0.9339 |     28.367 |     3.4
   25 |   0.7099 |     22.116 |   0.9511 |     28.492 |     3.5
   26 |   0.7019 |     21.777 |   0.9407 |     28.057 |     3.7
   27 |   0.6803 |     21.099 |   0.9364 |     27.685 |     3.8
   28 |   0.6659 |     20.623 |   0.9508 |     28.430 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 470,369

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7617 |     50.624 |   1.3344 |     43.793 |     0.1
    2 |   1.2985 |     42.531 |   1.2391 |     41.155 |     0.2
    3 |   1.2111 |     40.561 |   1.1421 |     38.703 |     0.4
    4 |   1.1455 |     38.285 |   1.0892 |     36.685 |     0.5
    5 |   1.0897 |     36.753 |   1.0357 |     34.637 |     0.6
    6 |   1.0319 |     34.663 |   0.9924 |     32.930 |     0.7
    7 |   0.9802 |     33.104 |   0.9860 |     33.023 |     0.9
    8 |   0.9425 |     31.736 |   0.9410 |     31.782 |     1.0
    9 |   0.9037 |     30.324 |   0.9446 |     31.875 |     1.1
   10 |   0.8791 |     29.219 |   0.8908 |     29.112 |     1.3
   11 |   0.8314 |     27.812 |   0.8923 |     29.671 |     1.4
   12 |   0.8086 |     26.981 |   0.8833 |     29.205 |     1.6
   13 |   0.7851 |     26.691 |   0.9005 |     29.081 |     1.7
   14 |   0.7556 |     25.186 |   0.8617 |     28.212 |     1.9
   15 |   0.7361 |     24.951 |   0.8803 |     28.026 |     2.0
   16 |   0.6977 |     23.348 |   0.8626 |     27.685 |     2.1
   17 |   0.6784 |     23.047 |   0.8637 |     28.181 |     2.3
   18 |   0.6581 |     22.012 |   0.8608 |     26.629 |     2.4
   19 |   0.6297 |     21.509 |   0.8528 |     26.226 |     2.5
   20 |   0.6072 |     20.803 |   0.8667 |     26.785 |     2.6
   21 |   0.5796 |     19.714 |   0.8620 |     26.505 |     2.8
   22 |   0.5780 |     19.381 |   0.8834 |     26.847 |     2.9
   23 |   0.5503 |     18.549 |   0.8426 |     25.481 |     3.0
   24 |   0.5215 |     17.575 |   0.8680 |     24.705 |     3.1
   25 |   0.5103 |     17.422 |   0.8402 |     25.481 |     3.3
   26 |   0.5019 |     17.055 |   0.8577 |     24.550 |     3.4
   27 |   0.4989 |     16.907 |   0.8598 |     25.667 |     3.5
   28 |   0.4651 |     15.851 |   0.8615 |     24.643 |     3.6
   29 |   0.4484 |     15.228 |   0.8860 |     25.822 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,201

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5452 |     46.876 |   1.2479 |     41.248 |     0.1
    2 |   1.2351 |     41.311 |   1.1862 |     39.913 |     0.3
    3 |   1.1517 |     39.325 |   1.0692 |     35.878 |     0.5
    4 |   1.0925 |     37.076 |   1.0582 |     36.530 |     0.6
    5 |   1.0342 |     35.030 |   1.0161 |     34.575 |     0.8
    6 |   0.9959 |     33.651 |   1.0036 |     34.544 |     0.9
    7 |   0.9620 |     32.868 |   0.9705 |     32.278 |     1.1
    8 |   0.9195 |     31.205 |   0.9854 |     32.495 |     1.2
    9 |   0.8961 |     30.723 |   0.9441 |     32.123 |     1.4
   10 |   0.8633 |     29.509 |   0.9686 |     32.278 |     1.6
   11 |   0.8464 |     29.054 |   0.9137 |     30.695 |     1.7
   12 |   0.8155 |     27.867 |   0.8954 |     30.509 |     1.9
   13 |   0.7858 |     26.844 |   0.9166 |     30.354 |     2.1
   14 |   0.7560 |     26.034 |   0.9319 |     31.161 |     2.2
   15 |   0.7435 |     25.268 |   0.9269 |     29.764 |     2.4
   16 |   0.7208 |     24.557 |   0.9310 |     30.819 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,369

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7640 |     50.115 |   1.3449 |     42.613 |     0.2
    2 |   1.3038 |     42.476 |   1.2364 |     40.565 |     0.4
    3 |   1.2207 |     40.890 |   1.1728 |     39.323 |     0.5
    4 |   1.1580 |     39.040 |   1.1063 |     37.058 |     0.7
    5 |   1.0944 |     36.808 |   1.0623 |     36.034 |     0.9
    6 |   1.0478 |     35.730 |   1.0283 |     33.706 |     1.1
    7 |   0.9993 |     33.667 |   0.9907 |     32.278 |     1.3
    8 |   0.9606 |     32.469 |   0.9752 |     32.619 |     1.4
    9 |   0.9176 |     31.139 |   0.9377 |     31.471 |     1.6
   10 |   0.8854 |     29.695 |   0.9348 |     30.323 |     1.8
   11 |   0.8549 |     28.874 |   0.9153 |     29.764 |     2.0
   12 |   0.8245 |     27.665 |   0.8775 |     28.895 |     2.2
   13 |   0.7900 |     26.838 |   0.8727 |     28.057 |     2.4
   14 |   0.7668 |     26.237 |   0.8797 |     29.143 |     2.5
   15 |   0.7373 |     24.529 |   0.8655 |     27.778 |     2.7
   16 |   0.7113 |     23.703 |   0.8870 |     27.995 |     2.9
   17 |   0.6972 |     23.452 |   0.8917 |     27.716 |     3.1
   18 |   0.6627 |     22.127 |   0.8617 |     27.529 |     3.3
   19 |   0.6417 |     21.755 |   0.8330 |     26.567 |     3.5
   20 |   0.6118 |     20.634 |   0.8580 |     26.505 |     3.7
   21 |   0.5946 |     19.857 |   0.8357 |     25.854 |     3.8
   22 |   0.5714 |     19.583 |   0.8602 |     25.233 |     4.0
   23 |   0.5552 |     18.790 |   0.8304 |     25.574 |     4.2
   24 |   0.5458 |     18.543 |   0.8481 |     25.109 |     4.4
   25 |   0.5325 |     17.963 |   0.8480 |     25.264 |     4.5
   26 |   0.4982 |     17.083 |   0.8578 |     24.767 |     4.7
   27 |   0.4921 |     16.689 |   0.8740 |     25.450 |     4.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 386,657

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6008 |     46.411 |   1.2670 |     41.310 |     0.1
    2 |   1.1989 |     39.330 |   1.1257 |     36.685 |     0.2
    3 |   1.0790 |     35.763 |   1.0257 |     33.520 |     0.3
    4 |   0.9848 |     32.775 |   1.0082 |     33.333 |     0.4
    5 |   0.9048 |     30.308 |   0.9449 |     31.564 |     0.5
    6 |   0.8498 |     28.283 |   0.9160 |     30.540 |     0.6
    7 |   0.7902 |     26.335 |   0.8694 |     28.399 |     0.7
    8 |   0.7349 |     24.513 |   0.8660 |     27.964 |     0.8
    9 |   0.6972 |     23.271 |   0.8165 |     26.816 |     0.9
   10 |   0.6628 |     22.494 |   0.8376 |     26.660 |     1.0
   11 |   0.6215 |     20.743 |   0.8111 |     26.040 |     1.0
   12 |   0.5809 |     19.326 |   0.7801 |     24.488 |     1.1
   13 |   0.5452 |     18.281 |   0.8069 |     24.395 |     1.2
   14 |   0.5258 |     17.739 |   0.8061 |     23.960 |     1.3
   15 |   0.5089 |     17.225 |   0.8170 |     24.953 |     1.4
   16 |   0.4751 |     16.016 |   0.7641 |     23.557 |     1.5
   17 |   0.4538 |     15.244 |   0.7989 |     23.960 |     1.6
   18 |   0.4398 |     14.752 |   0.8248 |     23.743 |     1.7
   19 |   0.4192 |     14.286 |   0.7926 |     22.812 |     1.8
   20 |   0.3907 |     13.220 |   0.7808 |     21.819 |     1.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,201

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5469 |     47.319 |   1.2782 |     42.768 |     0.2
    2 |   1.2354 |     41.327 |   1.1550 |     37.834 |     0.4
    3 |   1.1522 |     39.117 |   1.0975 |     36.499 |     0.6
    4 |   1.0850 |     36.726 |   1.0260 |     34.047 |     0.8
    5 |   1.0286 |     35.106 |   1.0324 |     34.389 |     1.0
    6 |   0.9856 |     33.339 |   1.0015 |     34.078 |     1.2
    7 |   0.9511 |     32.277 |   0.9533 |     31.782 |     1.4
    8 |   0.9293 |     31.741 |   0.9448 |     31.750 |     1.6
    9 |   0.8869 |     30.477 |   0.9260 |     30.912 |     1.8
   10 |   0.8659 |     29.328 |   0.9102 |     29.888 |     2.0
   11 |   0.8477 |     28.896 |   0.9064 |     29.826 |     2.3
   12 |   0.8182 |     27.856 |   0.8797 |     29.857 |     2.4
   13 |   0.7866 |     26.953 |   0.8845 |     28.895 |     2.6
   14 |   0.7578 |     25.689 |   0.8759 |     28.957 |     2.9
   15 |   0.7334 |     24.705 |   0.8375 |     27.685 |     3.1
   16 |   0.7158 |     24.097 |   0.8277 |     27.250 |     3.3
   17 |   0.7007 |     23.763 |   0.8657 |     27.809 |     3.5
   18 |   0.6715 |     22.965 |   0.8326 |     27.467 |     3.7
   19 |   0.6606 |     22.707 |   0.8286 |     27.312 |     3.9
   20 |   0.6393 |     21.684 |   0.8375 |     27.374 |     4.1
   21 |   0.6417 |     21.952 |   0.8196 |     26.288 |     4.3
   22 |   0.6103 |     21.022 |   0.8362 |     26.723 |     4.5
   23 |   0.5866 |     20.289 |   0.8062 |     25.698 |     4.7
   24 |   0.5703 |     19.534 |   0.8271 |     25.822 |     4.9
   25 |   0.5631 |     19.463 |   0.8325 |     26.505 |     5.1
   26 |   0.5443 |     18.686 |   0.8606 |     25.854 |     5.3
   27 |   0.5394 |     18.511 |   0.8201 |     25.140 |     5.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,505

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9756 |     52.692 |   1.4043 |     41.930 |     0.2
    2 |   1.3172 |     39.828 |   1.2339 |     37.151 |     0.3
    3 |   1.1868 |     36.917 |   1.1699 |     35.847 |     0.5
    4 |   1.0875 |     33.591 |   1.0963 |     34.171 |     0.6
    5 |   1.0127 |     31.019 |   1.0357 |     32.154 |     0.8
    6 |   0.9348 |     29.054 |   0.9928 |     30.757 |     1.0
    7 |   0.8742 |     27.030 |   0.9414 |     28.740 |     1.1
    8 |   0.8109 |     24.688 |   0.9168 |     28.399 |     1.3
    9 |   0.7637 |     23.468 |   0.8970 |     27.871 |     1.4
   10 |   0.7094 |     22.067 |   0.8669 |     27.312 |     1.6
   11 |   0.6663 |     20.245 |   0.8686 |     26.878 |     1.8
   12 |   0.6242 |     18.954 |   0.8466 |     25.388 |     1.9
   13 |   0.5837 |     17.723 |   0.8457 |     25.233 |     2.1
   14 |   0.5591 |     17.050 |   0.8435 |     25.978 |     2.3
   15 |   0.5225 |     15.873 |   0.8506 |     25.729 |     2.4
   16 |   0.4905 |     14.795 |   0.8292 |     24.705 |     2.6
   17 |   0.4589 |     14.090 |   0.7970 |     23.619 |     2.8
   18 |   0.4286 |     12.897 |   0.8136 |     23.588 |     2.9
   19 |   0.4032 |     12.103 |   0.8209 |     24.053 |     3.1
   20 |   0.3737 |     11.217 |   0.8224 |     23.153 |     3.3
   21 |   0.3657 |     10.987 |   0.8334 |     22.688 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 436,897

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7659 |     50.569 |   1.3196 |     42.800 |     0.1
    2 |   1.2905 |     42.466 |   1.2315 |     40.720 |     0.2
    3 |   1.1931 |     39.691 |   1.1325 |     37.678 |     0.3
    4 |   1.1123 |     37.081 |   1.0534 |     34.171 |     0.4
    5 |   1.0523 |     35.538 |   1.0359 |     34.171 |     0.5
    6 |   0.9982 |     33.142 |   1.0133 |     34.016 |     0.7
    7 |   0.9546 |     31.922 |   0.9746 |     33.426 |     0.8
    8 |   0.9055 |     30.362 |   0.9442 |     30.788 |     0.9
    9 |   0.8722 |     29.399 |   0.9323 |     30.726 |     1.0
   10 |   0.8250 |     27.457 |   0.9135 |     29.174 |     1.1
   11 |   0.7959 |     26.828 |   0.8979 |     28.988 |     1.2
   12 |   0.7613 |     25.432 |   0.8722 |     28.057 |     1.3
   13 |   0.7292 |     24.409 |   0.8870 |     28.212 |     1.4
   14 |   0.7028 |     23.649 |   0.8661 |     28.274 |     1.5
   15 |   0.6780 |     22.675 |   0.8550 |     27.002 |     1.6
   16 |   0.6518 |     21.952 |   0.8448 |     26.598 |     1.7
   17 |   0.6239 |     20.935 |   0.8509 |     27.064 |     1.8
   18 |   0.5961 |     20.043 |   0.8598 |     26.629 |     2.0
   19 |   0.5764 |     19.807 |   0.8397 |     26.226 |     2.1
   20 |   0.5640 |     18.987 |   0.8349 |     26.164 |     2.2
   21 |   0.5384 |     18.007 |   0.8434 |     25.202 |     2.3
   22 |   0.5246 |     17.542 |   0.8784 |     25.357 |     2.4
   23 |   0.5180 |     17.794 |   0.8766 |     26.629 |     2.5
   24 |   0.4962 |     16.732 |   0.8514 |     24.519 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 436,897

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6518 |     47.948 |   1.2676 |     40.441 |     0.1
    2 |   1.2013 |     39.571 |   1.1420 |     38.268 |     0.3
    3 |   1.0649 |     35.462 |   1.0542 |     35.133 |     0.4
    4 |   0.9616 |     31.610 |   0.9700 |     31.750 |     0.5
    5 |   0.8938 |     29.410 |   0.9436 |     31.161 |     0.7
    6 |   0.8220 |     27.391 |   0.9101 |     30.168 |     0.8
    7 |   0.7726 |     26.023 |   0.8763 |     28.399 |     0.9
    8 |   0.7203 |     23.960 |   0.8537 |     27.592 |     1.1
    9 |   0.6804 |     22.915 |   0.8626 |     27.281 |     1.2
   10 |   0.6324 |     21.301 |   0.8447 |     26.940 |     1.3
   11 |   0.6029 |     20.262 |   0.8422 |     25.978 |     1.4
   12 |   0.5712 |     19.238 |   0.8210 |     26.102 |     1.6
   13 |   0.5301 |     17.821 |   0.8104 |     24.302 |     1.7
   14 |   0.5011 |     16.628 |   0.8348 |     25.357 |     1.8
   15 |   0.4993 |     16.869 |   0.8087 |     24.302 |     2.0
   16 |   0.4631 |     15.901 |   0.8286 |     24.519 |     2.1
   17 |   0.4378 |     14.795 |   0.8252 |     23.681 |     2.2
   18 |   0.4249 |     14.505 |   0.8260 |     23.371 |     2.4
   19 |   0.3972 |     13.422 |   0.8242 |     23.060 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,272,993

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2062 |     56.856 |   1.4823 |     44.475 |     0.1
    2 |   1.4513 |     43.439 |   1.3042 |     40.192 |     0.3
    3 |   1.3106 |     40.446 |   1.2229 |     38.454 |     0.4
    4 |   1.2257 |     38.247 |   1.1765 |     36.530 |     0.5
    5 |   1.1599 |     36.556 |   1.1249 |     35.071 |     0.7
    6 |   1.1072 |     34.723 |   1.0905 |     34.202 |     0.8
    7 |   1.0507 |     33.082 |   1.0350 |     32.154 |     0.9
    8 |   0.9994 |     31.199 |   1.0149 |     31.906 |     1.1
    9 |   0.9480 |     29.864 |   0.9950 |     30.944 |     1.2
   10 |   0.9041 |     28.234 |   0.9742 |     30.944 |     1.3
   11 |   0.8647 |     27.063 |   0.9419 |     29.547 |     1.5
   12 |   0.8196 |     25.547 |   0.9309 |     28.926 |     1.6
   13 |   0.7887 |     24.781 |   0.9276 |     28.212 |     1.7
   14 |   0.7549 |     23.676 |   0.9281 |     28.430 |     1.9
   15 |   0.7189 |     22.740 |   0.9063 |     28.305 |     2.0
   16 |   0.6897 |     21.826 |   0.9070 |     28.057 |     2.1
   17 |   0.6622 |     20.863 |   0.9026 |     27.467 |     2.3
   18 |   0.6330 |     19.818 |   0.8741 |     26.536 |     2.4
   19 |   0.6041 |     19.047 |   0.8971 |     26.598 |     2.5
   20 |   0.5822 |     18.450 |   0.9005 |     26.660 |     2.7
   21 |   0.5541 |     17.219 |   0.8959 |     26.009 |     2.8
   22 |   0.5349 |     16.683 |   0.9084 |     26.412 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 386,657

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7459 |     49.146 |   1.3312 |     42.800 |     0.1
    2 |   1.2832 |     41.776 |   1.2056 |     39.479 |     0.2
    3 |   1.1906 |     38.805 |   1.1213 |     36.903 |     0.3
    4 |   1.1135 |     37.092 |   1.0686 |     35.164 |     0.4
    5 |   1.0479 |     34.564 |   1.0366 |     34.327 |     0.5
    6 |   1.0008 |     33.585 |   0.9915 |     33.364 |     0.6
    7 |   0.9559 |     31.768 |   0.9917 |     32.185 |     0.7
    8 |   0.9067 |     30.007 |   0.9498 |     30.819 |     0.8
    9 |   0.8660 |     28.666 |   0.9202 |     29.702 |     0.9
   10 |   0.8295 |     27.298 |   0.9228 |     30.323 |     1.0
   11 |   0.7958 |     26.603 |   0.8756 |     28.957 |     1.1
   12 |   0.7610 |     25.394 |   0.8739 |     27.995 |     1.2
   13 |   0.7346 |     24.562 |   0.8526 |     27.840 |     1.3
   14 |   0.7005 |     23.490 |   0.8754 |     26.940 |     1.4
   15 |   0.6803 |     22.592 |   0.8501 |     26.319 |     1.5
   16 |   0.6645 |     21.969 |   0.8712 |     26.660 |     1.6
   17 |   0.6267 |     21.099 |   0.8543 |     26.909 |     1.7
   18 |   0.6067 |     20.322 |   0.8621 |     25.854 |     1.8
   19 |   0.5928 |     19.769 |   0.8161 |     24.426 |     1.9
   20 |   0.5715 |     19.184 |   0.8606 |     25.326 |     2.0
   21 |   0.5464 |     18.341 |   0.8539 |     25.264 |     2.1
   22 |   0.5238 |     17.750 |   0.8470 |     24.674 |     2.2
   23 |   0.5008 |     16.951 |   0.8842 |     25.698 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 420,129

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4306 |     59.395 |   1.8161 |     44.972 |     0.1
    2 |   1.6521 |     43.757 |   1.5302 |     41.962 |     0.2
    3 |   1.4648 |     42.033 |   1.4048 |     40.223 |     0.3
    4 |   1.3521 |     39.845 |   1.3206 |     39.044 |     0.5
    5 |   1.2649 |     37.229 |   1.2559 |     37.647 |     0.6
    6 |   1.1932 |     35.686 |   1.1988 |     35.164 |     0.7
    7 |   1.1310 |     33.503 |   1.1458 |     34.016 |     0.8
    8 |   1.0716 |     31.993 |   1.1002 |     33.240 |     0.9
    9 |   1.0178 |     30.291 |   1.0658 |     32.185 |     1.0
   10 |   0.9742 |     28.951 |   1.0455 |     31.471 |     1.2
   11 |   0.9353 |     27.966 |   1.0086 |     31.037 |     1.3
   12 |   0.8932 |     26.581 |   1.0079 |     30.602 |     1.4
   13 |   0.8605 |     25.711 |   0.9893 |     30.447 |     1.5
   14 |   0.8276 |     24.869 |   0.9620 |     29.578 |     1.6
   15 |   0.7883 |     23.462 |   0.9405 |     28.181 |     1.7
   16 |   0.7598 |     22.647 |   0.9367 |     29.050 |     1.9
   17 |   0.7320 |     21.602 |   0.9280 |     28.554 |     2.0
   18 |   0.7058 |     21.082 |   0.9065 |     27.716 |     2.1
   19 |   0.6760 |     20.289 |   0.9329 |     28.181 |     2.2
   20 |   0.6595 |     19.758 |   0.9033 |     27.436 |     2.3
   21 |   0.6364 |     18.937 |   0.9064 |     27.126 |     2.4
   22 |   0.6130 |     18.516 |   0.9059 |     27.405 |     2.6
   23 |   0.5886 |     17.635 |   0.9230 |     27.778 |     2.7
   24 |   0.5673 |     16.902 |   0.9044 |     27.561 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,257

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5735 |     47.664 |   1.3020 |     44.507 |     0.2
    2 |   1.2415 |     41.732 |   1.1392 |     39.199 |     0.4
    3 |   1.1632 |     39.549 |   1.1219 |     37.523 |     0.7
    4 |   1.1051 |     37.273 |   1.0744 |     36.716 |     0.9
    5 |   1.0700 |     36.348 |   1.0362 |     35.878 |     1.1
    6 |   1.0284 |     35.024 |   1.0237 |     34.792 |     1.3
    7 |   0.9841 |     33.503 |   0.9997 |     33.799 |     1.5
    8 |   0.9587 |     32.595 |   0.9698 |     32.278 |     1.8
    9 |   0.9237 |     31.643 |   0.9334 |     32.154 |     2.0
   10 |   0.8923 |     30.455 |   0.9010 |     31.161 |     2.2
   11 |   0.9079 |     31.139 |   0.9139 |     30.912 |     2.4
   12 |   0.8702 |     29.897 |   0.8993 |     30.633 |     2.6
   13 |   0.8299 |     28.185 |   0.9132 |     31.316 |     2.9
   14 |   0.8030 |     27.741 |   0.8736 |     29.268 |     3.1
   15 |   0.7812 |     26.910 |   0.8920 |     29.081 |     3.3
   16 |   0.7720 |     26.182 |   0.8743 |     29.205 |     3.5
   17 |   0.7347 |     25.142 |   0.8450 |     28.026 |     3.7
   18 |   0.7196 |     24.590 |   0.8467 |     28.678 |     4.0
   19 |   0.7125 |     24.622 |   0.8488 |     27.778 |     4.2
   20 |   0.7027 |     24.387 |   0.8680 |     28.399 |     4.4
   21 |   0.6698 |     23.167 |   0.8283 |     27.685 |     4.6
   22 |   0.6515 |     22.313 |   0.8565 |     27.033 |     4.9
   23 |   0.6436 |     22.040 |   0.8402 |     26.505 |     5.1
   24 |   0.6314 |     21.991 |   0.8074 |     26.288 |     5.3
   25 |   0.6064 |     21.000 |   0.8181 |     25.947 |     5.5
   26 |   0.6050 |     21.159 |   0.8403 |     26.909 |     5.7
   27 |   0.5870 |     20.125 |   0.8381 |     26.505 |     5.9
   28 |   0.5705 |     19.840 |   0.8384 |     25.636 |     6.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,257

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9299 |     51.187 |   1.3955 |     40.286 |     0.2
    2 |   1.3002 |     39.675 |   1.2396 |     36.840 |     0.4
    3 |   1.1710 |     36.288 |   1.1389 |     34.358 |     0.6
    4 |   1.0569 |     32.507 |   1.0728 |     33.364 |     0.8
    5 |   0.9734 |     30.100 |   1.0104 |     31.688 |     1.0
    6 |   0.8905 |     27.517 |   0.9559 |     28.926 |     1.2
    7 |   0.8177 |     25.044 |   0.9258 |     29.268 |     1.4
    8 |   0.7639 |     23.659 |   0.9146 |     28.181 |     1.6
    9 |   0.7064 |     21.547 |   0.8967 |     28.181 |     1.8
   10 |   0.6610 |     20.026 |   0.8806 |     26.878 |     2.0
   11 |   0.6071 |     18.615 |   0.8888 |     26.723 |     2.2
   12 |   0.5623 |     16.864 |   0.8469 |     25.357 |     2.3
   13 |   0.5192 |     15.594 |   0.8151 |     23.805 |     2.5
   14 |   0.4847 |     14.670 |   0.8768 |     26.567 |     2.7
   15 |   0.4433 |     13.417 |   0.8215 |     24.053 |     2.9
   16 |   0.4010 |     12.158 |   0.8483 |     24.488 |     3.1
   17 |   0.3805 |     11.447 |   0.8558 |     23.929 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 485,729

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5791 |     46.318 |   1.2583 |     40.813 |     0.1
    2 |   1.1875 |     39.330 |   1.1193 |     36.313 |     0.2
    3 |   1.0685 |     35.681 |   1.0461 |     33.985 |     0.4
    4 |   0.9784 |     32.545 |   0.9881 |     32.992 |     0.5
    5 |   0.9068 |     30.138 |   0.9557 |     31.999 |     0.6
    6 |   0.8448 |     28.097 |   0.8958 |     29.826 |     0.7
    7 |   0.7843 |     26.286 |   0.8733 |     28.988 |     0.9
    8 |   0.7287 |     24.261 |   0.8701 |     28.367 |     1.0
    9 |   0.6853 |     23.238 |   0.8417 |     27.126 |     1.1
   10 |   0.6544 |     21.575 |   0.8197 |     25.854 |     1.3
   11 |   0.5992 |     19.840 |   0.8086 |     25.233 |     1.4
   12 |   0.5795 |     19.835 |   0.7967 |     24.922 |     1.5
   13 |   0.5416 |     18.571 |   0.7676 |     23.774 |     1.6
   14 |   0.4981 |     16.847 |   0.7958 |     24.426 |     1.8
   15 |   0.4720 |     15.879 |   0.8046 |     25.295 |     1.9
   16 |   0.4576 |     15.485 |   0.7837 |     22.719 |     2.0
   17 |   0.4255 |     14.571 |   0.7788 |     21.695 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 552,481

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4223 |     57.518 |   1.7520 |     44.941 |     0.1
    2 |   1.6029 |     43.423 |   1.5013 |     41.496 |     0.2
    3 |   1.4316 |     41.202 |   1.3825 |     40.596 |     0.3
    4 |   1.3169 |     38.323 |   1.2868 |     36.934 |     0.4
    5 |   1.2282 |     36.042 |   1.2137 |     35.320 |     0.5
    6 |   1.1534 |     34.247 |   1.1640 |     33.209 |     0.6
    7 |   1.0908 |     32.584 |   1.1100 |     33.023 |     0.7
    8 |   1.0322 |     30.548 |   1.0761 |     31.688 |     0.8
    9 |   0.9749 |     29.005 |   1.0385 |     30.850 |     0.9
   10 |   0.9247 |     27.287 |   1.0176 |     30.819 |     1.0
   11 |   0.8783 |     26.165 |   0.9834 |     29.702 |     1.1
   12 |   0.8360 |     25.055 |   0.9641 |     28.864 |     1.2
   13 |   0.7967 |     23.867 |   0.9477 |     28.678 |     1.3
   14 |   0.7614 |     22.560 |   0.9447 |     28.430 |     1.4
   15 |   0.7258 |     21.515 |   0.9177 |     27.840 |     1.5
   16 |   0.6897 |     20.688 |   0.8949 |     26.598 |     1.6
   17 |   0.6633 |     19.605 |   0.8852 |     26.847 |     1.7
   18 |   0.6341 |     18.932 |   0.8879 |     26.009 |     1.8
   19 |   0.6069 |     18.160 |   0.8632 |     24.953 |     1.9
   20 |   0.5747 |     17.159 |   0.8705 |     26.133 |     2.0
   21 |   0.5583 |     16.907 |   0.8756 |     25.729 |     2.1
   22 |   0.5292 |     15.643 |   0.8603 |     25.729 |     2.2
   23 |   0.5099 |     15.063 |   0.8742 |     24.767 |     2.3
   24 |   0.4824 |     14.363 |   0.8644 |     24.612 |     2.4
   25 |   0.4683 |     13.646 |   0.8881 |     25.450 |     2.5
   26 |   0.4572 |     13.789 |   0.8691 |     24.457 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 436,897

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4900 |     61.666 |   1.8016 |     45.127 |     0.1
    2 |   1.6157 |     43.987 |   1.4988 |     42.582 |     0.3
    3 |   1.4271 |     41.617 |   1.3839 |     39.323 |     0.4
    4 |   1.3209 |     38.761 |   1.3075 |     37.213 |     0.5
    5 |   1.2381 |     36.425 |   1.2279 |     35.692 |     0.6
    6 |   1.1709 |     34.532 |   1.1732 |     34.947 |     0.8
    7 |   1.1066 |     33.011 |   1.1315 |     33.737 |     0.9
    8 |   1.0548 |     31.254 |   1.0945 |     33.644 |     1.0
    9 |   1.0019 |     30.078 |   1.0522 |     31.844 |     1.2
   10 |   0.9590 |     28.743 |   1.0406 |     31.533 |     1.3
   11 |   0.9131 |     27.320 |   1.0073 |     31.099 |     1.4
   12 |   0.8789 |     26.483 |   0.9809 |     30.106 |     1.6
   13 |   0.8387 |     25.005 |   0.9608 |     29.019 |     1.7
   14 |   0.8055 |     24.010 |   0.9772 |     30.106 |     1.8
   15 |   0.7732 |     23.276 |   0.9417 |     28.895 |     2.0
   16 |   0.7386 |     21.821 |   0.9167 |     28.336 |     2.1
   17 |   0.7140 |     21.339 |   0.9202 |     27.964 |     2.2
   18 |   0.6883 |     20.535 |   0.9173 |     27.592 |     2.3
   19 |   0.6703 |     20.119 |   0.9137 |     27.529 |     2.5
   20 |   0.6361 |     18.937 |   0.9128 |     27.188 |     2.6
   21 |   0.6202 |     18.467 |   0.8967 |     26.660 |     2.7
   22 |   0.5988 |     17.805 |   0.8973 |     27.405 |     2.9
   23 |   0.5748 |     17.247 |   0.9135 |     27.157 |     3.0
   24 |   0.5541 |     16.409 |   0.8840 |     25.854 |     3.1
   25 |   0.5342 |     15.731 |   0.9040 |     26.195 |     3.3
   26 |   0.5275 |     15.802 |   0.8980 |     26.505 |     3.4
   27 |   0.5084 |     15.425 |   0.8769 |     25.481 |     3.5
   28 |   0.4854 |     14.177 |   0.8902 |     25.543 |     3.7
   29 |   0.4728 |     14.232 |   0.8707 |     25.326 |     3.8
   30 |   0.4561 |     13.810 |   0.8726 |     25.016 |     3.9
   31 |   0.4314 |     12.782 |   0.9066 |     26.195 |     4.0
   32 |   0.4324 |     12.940 |   0.8653 |     24.488 |     4.2
   33 |   0.4097 |     12.202 |   0.8905 |     25.667 |     4.3
   34 |   0.4001 |     12.076 |   0.8694 |     24.705 |     4.4
   35 |   0.3816 |     11.064 |   0.8944 |     24.395 |     4.6
   36 |   0.3793 |     11.408 |   0.9232 |     25.016 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,505

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5104 |     46.230 |   1.2225 |     40.751 |     0.2
    2 |   1.1780 |     39.527 |   1.0955 |     36.623 |     0.3
    3 |   1.0559 |     35.533 |   1.0172 |     33.799 |     0.5
    4 |   0.9789 |     33.164 |   0.9776 |     32.402 |     0.6
    5 |   0.9002 |     30.138 |   0.9283 |     31.223 |     0.8
    6 |   0.8387 |     28.628 |   0.9263 |     31.037 |     0.9
    7 |   0.8085 |     27.364 |   0.9121 |     30.012 |     1.1
    8 |   0.7680 |     25.974 |   0.8668 |     28.461 |     1.2
    9 |   0.7162 |     24.081 |   0.8414 |     27.436 |     1.4
   10 |   0.6864 |     23.156 |   0.7951 |     26.691 |     1.5
   11 |   0.6377 |     21.848 |   0.8068 |     26.195 |     1.7
   12 |   0.6154 |     20.776 |   0.8010 |     25.605 |     1.9
   13 |   0.5853 |     20.059 |   0.8385 |     26.164 |     2.0
   14 |   0.5576 |     19.025 |   0.8205 |     25.016 |     2.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,473

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2203 |     56.829 |   1.4783 |     44.072 |     0.2
    2 |   1.4546 |     43.593 |   1.3079 |     39.572 |     0.4
    3 |   1.3159 |     40.457 |   1.2210 |     37.958 |     0.6
    4 |   1.2218 |     37.738 |   1.1719 |     36.530 |     0.8
    5 |   1.1481 |     35.807 |   1.1080 |     33.985 |     1.0
    6 |   1.0812 |     33.787 |   1.0540 |     32.744 |     1.2
    7 |   1.0118 |     31.555 |   1.0137 |     31.937 |     1.4
    8 |   0.9557 |     29.837 |   0.9789 |     30.757 |     1.6
    9 |   0.9067 |     28.113 |   0.9608 |     29.702 |     1.8
   10 |   0.8668 |     26.986 |   0.9388 |     29.578 |     2.0
   11 |   0.8224 |     25.175 |   0.9367 |     28.833 |     2.2
   12 |   0.7868 |     24.261 |   0.9101 |     27.933 |     2.4
   13 |   0.7451 |     22.970 |   0.9178 |     28.150 |     2.6
   14 |   0.7131 |     22.127 |   0.9096 |     27.312 |     2.8
   15 |   0.6753 |     20.858 |   0.8854 |     26.412 |     3.0
   16 |   0.6495 |     20.218 |   0.9080 |     27.623 |     3.2
   17 |   0.6170 |     19.080 |   0.9238 |     27.312 |     3.4
   18 |   0.5922 |     18.139 |   0.9319 |     27.343 |     3.6
   19 |   0.5643 |     17.657 |   0.8997 |     26.567 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,713

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2972 |     54.251 |   1.7224 |     44.444 |     0.1
    2 |   1.5886 |     43.111 |   1.4786 |     40.379 |     0.3
    3 |   1.4119 |     40.244 |   1.3647 |     38.361 |     0.5
    4 |   1.3016 |     37.787 |   1.2694 |     36.996 |     0.6
    5 |   1.2230 |     36.611 |   1.2110 |     35.692 |     0.8
    6 |   1.1540 |     34.335 |   1.1610 |     33.954 |     0.9
    7 |   1.0954 |     33.098 |   1.1348 |     34.482 |     1.1
    8 |   1.0451 |     31.621 |   1.0865 |     32.464 |     1.2
    9 |   0.9913 |     30.247 |   1.0647 |     32.713 |     1.4
   10 |   0.9446 |     28.628 |   1.0379 |     31.719 |     1.5
   11 |   0.9017 |     27.265 |   0.9986 |     30.416 |     1.7
   12 |   0.8552 |     25.668 |   0.9973 |     30.664 |     1.9
   13 |   0.8178 |     24.535 |   0.9888 |     30.012 |     2.0
   14 |   0.7788 |     23.342 |   0.9541 |     28.864 |     2.2
   15 |   0.7434 |     22.264 |   0.9462 |     28.492 |     2.3
   16 |   0.6990 |     20.677 |   0.9198 |     27.529 |     2.5
   17 |   0.6723 |     19.922 |   0.9275 |     28.461 |     2.6
   18 |   0.6401 |     18.746 |   0.9299 |     28.088 |     2.8
   19 |   0.6108 |     17.985 |   0.9211 |     27.219 |     2.9
   20 |   0.5888 |     17.427 |   0.9055 |     26.288 |     3.1
   21 |   0.5566 |     16.453 |   0.8991 |     26.909 |     3.2
   22 |   0.5326 |     15.643 |   0.9068 |     26.660 |     3.4
   23 |   0.5155 |     15.206 |   0.9034 |     26.133 |     3.6
   24 |   0.4832 |     14.215 |   0.8871 |     25.264 |     3.7
   25 |   0.4704 |     13.816 |   0.9208 |     26.226 |     3.9
   26 |   0.4431 |     13.066 |   0.9312 |     26.598 |     4.0
   27 |   0.4302 |     12.760 |   0.9112 |     25.947 |     4.2
   28 |   0.4122 |     11.977 |   0.9160 |     25.885 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,505

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3378 |     59.953 |   1.5474 |     44.848 |     0.2
    2 |   1.5150 |     44.118 |   1.3421 |     41.186 |     0.3
    3 |   1.3560 |     41.678 |   1.2573 |     39.168 |     0.5
    4 |   1.2636 |     39.609 |   1.1948 |     37.430 |     0.7
    5 |   1.1885 |     37.125 |   1.1340 |     35.289 |     0.8
    6 |   1.1299 |     35.232 |   1.0866 |     34.295 |     1.0
    7 |   1.0785 |     33.716 |   1.0573 |     33.333 |     1.2
    8 |   1.0241 |     31.933 |   1.0123 |     31.533 |     1.3
    9 |   0.9743 |     30.198 |   0.9923 |     31.099 |     1.5
   10 |   0.9390 |     29.016 |   0.9714 |     30.261 |     1.7
   11 |   0.8948 |     27.801 |   0.9472 |     28.802 |     1.8
   12 |   0.8565 |     26.926 |   0.9308 |     28.678 |     2.0
   13 |   0.8230 |     25.591 |   0.9153 |     28.243 |     2.2
   14 |   0.7869 |     24.283 |   0.9190 |     28.523 |     2.3
   15 |   0.7552 |     23.342 |   0.9023 |     27.250 |     2.5
   16 |   0.7302 |     22.729 |   0.8857 |     27.064 |     2.7
   17 |   0.7070 |     22.237 |   0.8824 |     26.785 |     2.8
   18 |   0.6729 |     21.082 |   0.8808 |     25.947 |     3.0
   19 |   0.6514 |     20.360 |   0.8909 |     26.629 |     3.2
   20 |   0.6283 |     19.578 |   0.9031 |     26.660 |     3.3
   21 |   0.6163 |     19.638 |   0.8740 |     26.071 |     3.5
   22 |   0.5860 |     18.281 |   0.8739 |     25.543 |     3.7
   23 |   0.5639 |     17.690 |   0.8718 |     25.450 |     3.8
   24 |   0.5447 |     17.296 |   0.8782 |     24.674 |     4.0
   25 |   0.5328 |     16.814 |   0.8948 |     25.605 |     4.2
   26 |   0.5147 |     16.344 |   0.8794 |     26.164 |     4.3
   27 |   0.4943 |     15.939 |   0.8913 |     24.922 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,471,777

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9287 |     51.499 |   1.4177 |     42.086 |     0.1
    2 |   1.3198 |     40.627 |   1.2709 |     38.982 |     0.3
    3 |   1.1805 |     36.622 |   1.1638 |     35.816 |     0.4
    4 |   1.0850 |     34.077 |   1.1088 |     34.109 |     0.5
    5 |   1.0062 |     31.380 |   1.0290 |     32.123 |     0.7
    6 |   0.9285 |     28.496 |   1.0025 |     31.254 |     0.8
    7 |   0.8585 |     26.641 |   0.9602 |     29.671 |     0.9
    8 |   0.7874 |     24.497 |   0.9370 |     28.678 |     1.1
    9 |   0.7304 |     22.324 |   0.9088 |     28.057 |     1.2
   10 |   0.6838 |     20.825 |   0.8835 |     26.909 |     1.3
   11 |   0.6286 |     19.030 |   0.8778 |     26.567 |     1.5
   12 |   0.5860 |     17.821 |   0.8918 |     25.729 |     1.6
   13 |   0.5469 |     16.519 |   0.8692 |     27.374 |     1.7
   14 |   0.4996 |     14.877 |   0.8545 |     24.891 |     1.9
   15 |   0.4686 |     14.248 |   0.8378 |     24.488 |     2.0
   16 |   0.4436 |     13.449 |   0.8385 |     24.519 |     2.1
   17 |   0.3986 |     11.939 |   0.8560 |     24.426 |     2.3
   18 |   0.3834 |     11.753 |   0.8615 |     23.836 |     2.4
   19 |   0.3625 |     10.653 |   0.8849 |     24.209 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,471,777

Training started
X_train.shape: torch.Size([3046, 702])
Y_train.shape: torch.Size([3046, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4824 |     46.323 |   1.2339 |     41.372 |     0.1
    2 |   1.1825 |     40.129 |   1.1158 |     38.237 |     0.3
    3 |   1.0893 |     36.983 |   1.0692 |     36.996 |     0.4
    4 |   0.9954 |     33.591 |   0.9980 |     33.333 |     0.5
    5 |   0.9356 |     31.648 |   0.9749 |     32.744 |     0.7
    6 |   0.9013 |     30.559 |   0.9197 |     31.130 |     0.8
    7 |   0.8450 |     28.425 |   0.9108 |     31.657 |     0.9
    8 |   0.8036 |     27.358 |   0.8923 |     29.609 |     1.1
    9 |   0.7794 |     26.510 |   0.8672 |     29.950 |     1.2
   10 |   0.7339 |     24.825 |   0.8466 |     29.050 |     1.3
   11 |   0.6968 |     23.446 |   0.8555 |     27.902 |     1.5
   12 |   0.6623 |     22.494 |   0.8727 |     28.243 |     1.6
   13 |   0.6485 |     22.478 |   0.8247 |     26.381 |     1.7
   14 |   0.6098 |     20.688 |   0.8447 |     26.723 |     1.8
   15 |   0.6007 |     20.962 |   0.8080 |     26.164 |     2.0
   16 |   0.5740 |     19.567 |   0.8231 |     25.822 |     2.1
   17 |   0.5299 |     18.089 |   0.8032 |     25.667 |     2.2
   18 |   0.5154 |     17.772 |   0.7722 |     23.309 |     2.4
   19 |   0.4842 |     16.645 |   0.7927 |     23.991 |     2.5
   20 |   0.4889 |     16.880 |   0.8055 |     24.767 |     2.6
   21 |   0.4532 |     15.736 |   0.7889 |     23.929 |     2.8
   22 |   0.4361 |     14.970 |   0.8040 |     23.091 |     2.9
Early stopping

