Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,586

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4723 |     45.998 |   1.2376 |     41.529 |     0.2
    2 |   1.1620 |     39.172 |   1.1452 |     38.428 |     0.3
    3 |   1.0578 |     36.398 |   1.0470 |     35.175 |     0.5
    4 |   0.9730 |     33.443 |   1.0145 |     34.039 |     0.7
    5 |   0.9143 |     31.310 |   0.9683 |     32.014 |     0.9
    6 |   0.8697 |     29.720 |   0.9367 |     31.860 |     1.0
    7 |   0.8290 |     28.657 |   0.9069 |     30.847 |     1.2
    8 |   0.7901 |     27.105 |   0.9200 |     29.988 |     1.4
    9 |   0.7446 |     25.389 |   0.8872 |     29.681 |     1.6
   10 |   0.7142 |     24.435 |   0.8564 |     28.484 |     1.7
   11 |   0.6802 |     23.273 |   0.8603 |     28.484 |     1.9
   12 |   0.6577 |     22.423 |   0.8624 |     28.576 |     2.1
   13 |   0.6294 |     21.716 |   0.8112 |     26.120 |     2.3
   14 |   0.6056 |     20.948 |   0.8680 |     28.852 |     2.4
   15 |   0.5875 |     20.302 |   0.8290 |     26.796 |     2.6
   16 |   0.5591 |     19.073 |   0.8273 |     26.765 |     2.8
   17 |   0.5365 |     18.454 |   0.8358 |     26.090 |     3.0
   18 |   0.5326 |     18.405 |   0.7759 |     24.309 |     3.1
   19 |   0.5018 |     17.314 |   0.8061 |     25.445 |     3.3
   20 |   0.4772 |     16.431 |   0.8141 |     25.476 |     3.5
   21 |   0.4577 |     15.954 |   0.7821 |     24.095 |     3.7
   22 |   0.4360 |     15.016 |   0.8047 |     24.095 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 386,850

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5709 |     46.091 |   1.2706 |     40.915 |     0.1
    2 |   1.1939 |     39.052 |   1.1526 |     38.152 |     0.2
    3 |   1.0706 |     35.927 |   1.0679 |     35.942 |     0.3
    4 |   0.9701 |     32.692 |   0.9951 |     33.671 |     0.3
    5 |   0.8924 |     29.907 |   0.9710 |     32.014 |     0.4
    6 |   0.8378 |     27.950 |   0.9373 |     30.755 |     0.5
    7 |   0.7732 |     25.959 |   0.9177 |     30.939 |     0.6
    8 |   0.7289 |     24.474 |   0.8907 |     29.098 |     0.7
    9 |   0.6756 |     22.577 |   0.8777 |     28.944 |     0.8
   10 |   0.6499 |     21.952 |   0.8656 |     27.409 |     0.9
   11 |   0.6202 |     20.948 |   0.8249 |     25.752 |     1.0
   12 |   0.5793 |     19.677 |   0.8260 |     25.936 |     1.0
   13 |   0.5398 |     18.059 |   0.8041 |     25.077 |     1.1
   14 |   0.5092 |     17.061 |   0.8172 |     25.138 |     1.2
   15 |   0.4773 |     16.036 |   0.8391 |     25.353 |     1.3
   16 |   0.4621 |     15.822 |   0.8710 |     26.151 |     1.4
   17 |   0.4430 |     14.770 |   0.8255 |     25.230 |     1.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 386,850

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7729 |     49.507 |   1.3367 |     42.112 |     0.1
    2 |   1.2860 |     41.425 |   1.2048 |     40.516 |     0.2
    3 |   1.1741 |     38.465 |   1.1268 |     37.538 |     0.3
    4 |   1.0981 |     36.113 |   1.0857 |     36.710 |     0.4
    5 |   1.0378 |     34.485 |   1.0301 |     34.377 |     0.5
    6 |   0.9787 |     32.785 |   1.0249 |     33.211 |     0.6
    7 |   0.9354 |     31.223 |   0.9728 |     31.952 |     0.7
    8 |   0.9043 |     30.471 |   0.9753 |     32.965 |     0.7
    9 |   0.8624 |     29.057 |   0.9348 |     30.939 |     0.8
   10 |   0.8263 |     27.571 |   0.9253 |     30.878 |     0.9
   11 |   0.7890 |     26.601 |   0.9011 |     29.374 |     1.0
   12 |   0.7503 |     25.411 |   0.8941 |     28.392 |     1.1
   13 |   0.7303 |     24.627 |   0.9025 |     28.545 |     1.2
   14 |   0.6999 |     23.432 |   0.8866 |     28.514 |     1.3
   15 |   0.6746 |     22.856 |   0.8764 |     27.348 |     1.4
   16 |   0.6486 |     21.787 |   0.8756 |     27.287 |     1.5
   17 |   0.6222 |     21.223 |   0.8794 |     27.624 |     1.6
   18 |   0.6011 |     20.334 |   0.8971 |     27.287 |     1.7
   19 |   0.5938 |     19.698 |   0.8994 |     27.563 |     1.8
   20 |   0.5597 |     19.019 |   0.8894 |     27.502 |     1.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6180 |     48.081 |   1.2326 |     41.252 |     0.2
    2 |   1.2243 |     40.680 |   1.1679 |     39.687 |     0.3
    3 |   1.1377 |     37.747 |   1.1300 |     37.723 |     0.5
    4 |   1.0659 |     35.707 |   1.0719 |     35.482 |     0.6
    5 |   1.0073 |     33.964 |   1.0036 |     33.088 |     0.8
    6 |   0.9609 |     32.231 |   0.9839 |     33.088 |     1.0
    7 |   0.9202 |     30.729 |   0.9455 |     31.093 |     1.1
    8 |   0.8771 |     29.655 |   0.9404 |     31.277 |     1.3
    9 |   0.8434 |     28.936 |   0.9174 |     30.417 |     1.5
   10 |   0.8121 |     27.171 |   0.9141 |     31.001 |     1.6
   11 |   0.7701 |     26.294 |   0.9041 |     29.466 |     1.8
   12 |   0.7426 |     25.208 |   0.8855 |     28.514 |     1.9
   13 |   0.7146 |     24.172 |   0.8774 |     28.207 |     2.1
   14 |   0.6881 |     23.152 |   0.8708 |     27.133 |     2.3
   15 |   0.6600 |     22.122 |   0.8420 |     26.489 |     2.4
   16 |   0.6304 |     21.760 |   0.8705 |     27.993 |     2.6
   17 |   0.6152 |     21.075 |   0.8570 |     26.826 |     2.8
   18 |   0.5831 |     19.819 |   0.9130 |     27.133 |     2.9
   19 |   0.5603 |     19.271 |   0.8604 |     27.317 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6130 |     46.875 |   1.2802 |     41.406 |     0.1
    2 |   1.1879 |     39.013 |   1.1671 |     38.766 |     0.3
    3 |   1.0832 |     36.754 |   1.0632 |     36.341 |     0.4
    4 |   0.9987 |     33.728 |   1.0481 |     34.561 |     0.6
    5 |   0.9349 |     31.294 |   0.9972 |     32.689 |     0.8
    6 |   0.8925 |     30.351 |   0.9813 |     32.351 |     0.9
    7 |   0.8365 |     28.481 |   0.9312 |     30.939 |     1.1
    8 |   0.7766 |     26.255 |   0.8881 |     29.220 |     1.2
    9 |   0.7411 |     25.214 |   0.8979 |     29.220 |     1.4
   10 |   0.7033 |     23.893 |   0.8739 |     28.821 |     1.5
   11 |   0.6674 |     22.522 |   0.8760 |     28.453 |     1.7
   12 |   0.6427 |     22.007 |   0.8748 |     28.576 |     1.8
   13 |   0.6125 |     20.674 |   0.8482 |     27.348 |     2.0
   14 |   0.5779 |     20.049 |   0.8358 |     26.397 |     2.1
   15 |   0.5373 |     18.306 |   0.8260 |     25.691 |     2.3
   16 |   0.5102 |     17.144 |   0.8194 |     25.138 |     2.4
   17 |   0.4982 |     17.231 |   0.8439 |     25.905 |     2.6
   18 |   0.4666 |     15.702 |   0.8308 |     25.599 |     2.7
   19 |   0.4455 |     15.132 |   0.8186 |     24.678 |     2.9
   20 |   0.4215 |     14.649 |   0.8541 |     25.200 |     3.0
   21 |   0.4089 |     14.068 |   0.8383 |     24.647 |     3.2
   22 |   0.4103 |     14.079 |   0.8500 |     24.125 |     3.3
   23 |   0.3715 |     12.906 |   0.8680 |     24.371 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4404 |     44.846 |   1.2037 |     39.810 |     0.2
    2 |   1.1424 |     38.964 |   1.0985 |     37.139 |     0.4
    3 |   1.0530 |     36.107 |   1.0614 |     35.789 |     0.5
    4 |   0.9822 |     33.624 |   1.0205 |     34.500 |     0.7
    5 |   0.9355 |     31.842 |   0.9705 |     32.873 |     0.9
    6 |   0.8810 |     30.521 |   0.9335 |     31.860 |     1.1
    7 |   0.8521 |     29.441 |   0.9371 |     31.829 |     1.3
    8 |   0.8289 |     28.893 |   0.9206 |     30.970 |     1.4
    9 |   0.7874 |     27.198 |   0.9088 |     30.724 |     1.6
   10 |   0.7746 |     26.848 |   0.8790 |     29.343 |     1.8
   11 |   0.7272 |     25.455 |   0.8620 |     28.852 |     2.0
   12 |   0.7053 |     24.753 |   0.8506 |     28.269 |     2.2
   13 |   0.6828 |     23.569 |   0.8700 |     27.962 |     2.3
   14 |   0.6674 |     23.306 |   0.8415 |     27.901 |     2.5
   15 |   0.6375 |     22.166 |   0.8817 |     28.269 |     2.7
   16 |   0.6175 |     21.705 |   0.8602 |     27.993 |     2.9
   17 |   0.5981 |     20.927 |   0.8383 |     26.857 |     3.1
   18 |   0.5708 |     20.099 |   0.8251 |     26.397 |     3.2
   19 |   0.5503 |     18.991 |   0.8592 |     26.304 |     3.4
   20 |   0.5487 |     18.821 |   0.8280 |     25.998 |     3.6
   21 |   0.5206 |     18.262 |   0.8242 |     25.629 |     3.8
   22 |   0.5027 |     17.418 |   0.8586 |     25.783 |     4.0
   23 |   0.4861 |     16.957 |   0.8498 |     26.090 |     4.1
   24 |   0.4763 |     16.513 |   0.8352 |     25.813 |     4.3
   25 |   0.4514 |     16.102 |   0.8464 |     24.800 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4672 |     45.258 |   1.2419 |     41.621 |     0.1
    2 |   1.1529 |     38.547 |   1.1310 |     38.306 |     0.3
    3 |   1.0437 |     35.110 |   1.0528 |     34.929 |     0.4
    4 |   0.9582 |     32.412 |   1.0128 |     34.438 |     0.6
    5 |   0.8971 |     30.883 |   0.9691 |     32.597 |     0.7
    6 |   0.8453 |     28.684 |   0.9466 |     31.123 |     0.8
    7 |   0.8070 |     27.796 |   0.9280 |     30.387 |     1.0
    8 |   0.7597 |     25.899 |   0.9146 |     30.755 |     1.1
    9 |   0.7222 |     24.726 |   0.8685 |     28.668 |     1.3
   10 |   0.6774 |     22.895 |   0.8754 |     28.975 |     1.4
   11 |   0.6393 |     22.122 |   0.8671 |     27.931 |     1.6
   12 |   0.6124 |     20.625 |   0.8658 |     27.931 |     1.7
   13 |   0.5932 |     20.115 |   0.8468 |     27.471 |     1.8
   14 |   0.5550 |     19.046 |   0.8320 |     25.752 |     2.0
   15 |   0.5358 |     18.322 |   0.8145 |     26.182 |     2.1
   16 |   0.5040 |     17.505 |   0.8235 |     25.660 |     2.3
   17 |   0.4890 |     16.634 |   0.8536 |     25.414 |     2.4
   18 |   0.4722 |     16.261 |   0.8139 |     24.862 |     2.6
   19 |   0.4584 |     15.850 |   0.8388 |     25.414 |     2.7
   20 |   0.4280 |     14.682 |   0.8521 |     24.862 |     2.8
   21 |   0.4128 |     14.441 |   0.8694 |     25.015 |     3.0
   22 |   0.4003 |     14.024 |   0.8800 |     25.384 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 437,090

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8322 |     73.262 |   2.1405 |     49.662 |     0.1
    2 |   1.9012 |     46.870 |   1.5865 |     45.641 |     0.2
    3 |   1.6006 |     45.164 |   1.4643 |     44.537 |     0.3
    4 |   1.4877 |     44.002 |   1.3882 |     42.634 |     0.4
    5 |   1.4084 |     42.505 |   1.3175 |     40.393 |     0.5
    6 |   1.3440 |     40.855 |   1.2721 |     39.963 |     0.6
    7 |   1.2885 |     39.457 |   1.2306 |     38.275 |     0.7
    8 |   1.2410 |     37.840 |   1.2018 |     38.183 |     0.8
    9 |   1.2001 |     37.193 |   1.1704 |     36.924 |     0.9
   10 |   1.1599 |     35.817 |   1.1413 |     36.280 |     1.0
   11 |   1.1250 |     34.644 |   1.1296 |     35.635 |     1.1
   12 |   1.0935 |     33.827 |   1.1107 |     34.408 |     1.2
   13 |   1.0580 |     32.648 |   1.0856 |     33.732 |     1.3
   14 |   1.0285 |     31.864 |   1.0722 |     33.702 |     1.4
   15 |   1.0076 |     30.916 |   1.0588 |     33.640 |     1.5
   16 |   0.9803 |     30.609 |   1.0364 |     32.535 |     1.6
   17 |   0.9514 |     29.688 |   1.0407 |     32.842 |     1.7
   18 |   0.9313 |     28.865 |   1.0337 |     33.026 |     1.8
   19 |   0.9078 |     28.202 |   1.0144 |     31.707 |     1.9
   20 |   0.8855 |     27.719 |   1.0180 |     31.308 |     2.1
   21 |   0.8718 |     27.434 |   1.0100 |     31.983 |     2.2
   22 |   0.8509 |     26.656 |   0.9895 |     31.707 |     2.3
   23 |   0.8260 |     25.565 |   0.9909 |     31.123 |     2.4
   24 |   0.8154 |     25.811 |   0.9786 |     30.080 |     2.5
   25 |   0.7899 |     24.616 |   0.9741 |     29.957 |     2.6
   26 |   0.7731 |     24.386 |   0.9863 |     30.387 |     2.7
   27 |   0.7574 |     23.520 |   0.9695 |     30.295 |     2.8
   28 |   0.7439 |     23.487 |   0.9882 |     30.049 |     2.9
   29 |   0.7252 |     22.752 |   0.9866 |     29.589 |     3.0
   30 |   0.7134 |     22.697 |   0.9748 |     29.589 |     3.1
   31 |   0.7015 |     22.078 |   0.9719 |     29.435 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,642

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5238 |     46.656 |   1.2510 |     41.467 |     0.2
    2 |   1.2236 |     40.620 |   1.1759 |     38.582 |     0.3
    3 |   1.1533 |     38.925 |   1.1173 |     37.385 |     0.5
    4 |   1.0916 |     36.864 |   1.0842 |     36.525 |     0.7
    5 |   1.0599 |     35.609 |   1.0562 |     35.697 |     0.8
    6 |   1.0209 |     34.929 |   1.0480 |     35.820 |     1.0
    7 |   0.9944 |     33.865 |   1.0011 |     35.052 |     1.2
    8 |   0.9631 |     32.802 |   0.9966 |     34.561 |     1.3
    9 |   0.9323 |     32.045 |   0.9741 |     33.118 |     1.5
   10 |   0.8931 |     30.751 |   0.9656 |     32.965 |     1.6
   11 |   0.8743 |     30.126 |   0.9506 |     32.290 |     1.8
   12 |   0.8380 |     28.761 |   0.9357 |     32.167 |     2.0
   13 |   0.8244 |     28.860 |   0.9192 |     30.479 |     2.1
   14 |   0.7974 |     27.566 |   0.9226 |     31.430 |     2.3
   15 |   0.7666 |     26.414 |   0.8952 |     30.602 |     2.5
   16 |   0.7426 |     25.565 |   0.9210 |     30.510 |     2.6
   17 |   0.7137 |     24.677 |   0.8654 |     29.190 |     2.8
   18 |   0.7011 |     24.112 |   0.8676 |     28.054 |     3.0
   19 |   0.6760 |     23.279 |   0.8819 |     30.080 |     3.1
   20 |   0.6503 |     22.505 |   0.8400 |     28.085 |     3.3
   21 |   0.6491 |     22.401 |   0.9151 |     30.632 |     3.5
   22 |   0.6289 |     21.700 |   0.8657 |     29.036 |     3.6
   23 |   0.5916 |     20.488 |   0.8710 |     27.532 |     3.8
   24 |   0.5668 |     19.836 |   0.8858 |     28.085 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1983 |     55.779 |   1.4756 |     43.585 |     0.2
    2 |   1.4502 |     43.163 |   1.3115 |     41.713 |     0.4
    3 |   1.3130 |     40.203 |   1.2215 |     38.828 |     0.6
    4 |   1.2152 |     37.802 |   1.1525 |     37.109 |     0.8
    5 |   1.1435 |     35.965 |   1.1025 |     34.991 |     1.0
    6 |   1.0729 |     33.849 |   1.0603 |     34.561 |     1.2
    7 |   1.0126 |     32.193 |   1.0227 |     33.211 |     1.4
    8 |   0.9598 |     30.230 |   1.0047 |     32.904 |     1.6
    9 |   0.9101 |     28.936 |   0.9829 |     31.430 |     1.8
   10 |   0.8607 |     26.957 |   0.9635 |     31.584 |     2.0
   11 |   0.8166 |     25.543 |   0.9528 |     30.540 |     2.1
   12 |   0.7798 |     24.742 |   0.9326 |     29.650 |     2.3
   13 |   0.7363 |     23.196 |   0.9315 |     29.312 |     2.5
   14 |   0.6984 |     21.639 |   0.9228 |     28.238 |     2.7
   15 |   0.6607 |     20.493 |   0.9233 |     28.207 |     2.9
   16 |   0.6365 |     19.962 |   0.9268 |     28.146 |     3.1
   17 |   0.6052 |     18.953 |   0.9154 |     27.409 |     3.3
   18 |   0.5747 |     17.950 |   0.9105 |     26.151 |     3.5
   19 |   0.5526 |     17.374 |   0.9336 |     27.655 |     3.7
   20 |   0.5292 |     16.672 |   0.9100 |     26.120 |     3.9
   21 |   0.5033 |     15.795 |   0.9426 |     26.397 |     4.1
   22 |   0.4845 |     15.291 |   0.9286 |     26.182 |     4.3
   23 |   0.4582 |     14.561 |   0.9347 |     26.090 |     4.5
   24 |   0.4382 |     13.695 |   0.9258 |     25.721 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,586

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1027 |     53.832 |   1.4936 |     43.738 |     0.1
    2 |   1.3816 |     41.870 |   1.3265 |     40.516 |     0.3
    3 |   1.2374 |     38.388 |   1.2181 |     37.937 |     0.4
    4 |   1.1309 |     35.214 |   1.1424 |     35.605 |     0.6
    5 |   1.0459 |     32.489 |   1.0858 |     34.101 |     0.7
    6 |   0.9756 |     30.214 |   1.0419 |     33.487 |     0.8
    7 |   0.9104 |     28.070 |   0.9942 |     31.246 |     1.0
    8 |   0.8477 |     26.173 |   0.9922 |     31.277 |     1.1
    9 |   0.7893 |     24.359 |   0.9377 |     29.251 |     1.3
   10 |   0.7415 |     23.032 |   0.9136 |     28.146 |     1.4
   11 |   0.6939 |     20.910 |   0.9115 |     28.607 |     1.6
   12 |   0.6473 |     19.496 |   0.9008 |     27.686 |     1.7
   13 |   0.6067 |     18.564 |   0.8951 |     27.256 |     1.8
   14 |   0.5656 |     17.056 |   0.8740 |     26.888 |     2.0
   15 |   0.5319 |     16.058 |   0.8740 |     25.783 |     2.1
   16 |   0.5010 |     15.241 |   0.8795 |     25.875 |     2.3
   17 |   0.4580 |     13.635 |   0.8901 |     25.691 |     2.4
   18 |   0.4366 |     13.229 |   0.8743 |     24.432 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3949 |     61.365 |   1.5527 |     44.475 |     0.2
    2 |   1.5138 |     43.964 |   1.3556 |     41.928 |     0.3
    3 |   1.3512 |     41.365 |   1.2698 |     40.270 |     0.5
    4 |   1.2575 |     38.920 |   1.1929 |     37.937 |     0.6
    5 |   1.1839 |     36.804 |   1.1514 |     36.556 |     0.8
    6 |   1.1330 |     35.614 |   1.1160 |     35.175 |     1.0
    7 |   1.0722 |     33.476 |   1.0802 |     35.021 |     1.1
    8 |   1.0231 |     32.127 |   1.0487 |     32.842 |     1.3
    9 |   0.9738 |     30.707 |   1.0254 |     32.996 |     1.5
   10 |   0.9326 |     29.523 |   0.9987 |     31.584 |     1.6
   11 |   0.8925 |     28.125 |   0.9810 |     30.632 |     1.8
   12 |   0.8574 |     27.018 |   0.9612 |     30.571 |     2.0
   13 |   0.8254 |     26.118 |   0.9487 |     29.711 |     2.1
   14 |   0.7922 |     25.258 |   0.9383 |     28.699 |     2.3
   15 |   0.7629 |     24.068 |   0.9433 |     28.545 |     2.4
   16 |   0.7387 |     23.717 |   0.9311 |     28.484 |     2.6
   17 |   0.7133 |     22.654 |   0.9208 |     27.839 |     2.8
   18 |   0.6817 |     21.557 |   0.9383 |     28.453 |     2.9
   19 |   0.6579 |     20.724 |   0.9330 |     27.471 |     3.1
   20 |   0.6345 |     20.312 |   0.9241 |     27.409 |     3.3
   21 |   0.6169 |     19.419 |   0.9436 |     27.594 |     3.4
   22 |   0.5943 |     18.860 |   0.9155 |     26.703 |     3.6
   23 |   0.5766 |     18.344 |   0.9294 |     26.397 |     3.7
   24 |   0.5600 |     17.982 |   0.9166 |     26.304 |     3.9
   25 |   0.5326 |     16.919 |   0.9313 |     26.550 |     4.1
   26 |   0.5191 |     16.557 |   0.9156 |     25.875 |     4.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0607 |     53.432 |   1.4524 |     42.664 |     0.1
    2 |   1.3490 |     40.943 |   1.2772 |     39.380 |     0.3
    3 |   1.2110 |     37.374 |   1.1926 |     37.354 |     0.5
    4 |   1.1085 |     34.611 |   1.1320 |     35.513 |     0.6
    5 |   1.0310 |     32.122 |   1.0553 |     33.487 |     0.8
    6 |   0.9443 |     29.512 |   1.0211 |     31.737 |     0.9
    7 |   0.8783 |     27.127 |   0.9910 |     31.001 |     1.1
    8 |   0.8214 |     25.362 |   0.9414 |     29.711 |     1.2
    9 |   0.7685 |     23.750 |   0.9387 |     29.098 |     1.4
   10 |   0.7142 |     21.837 |   0.8993 |     28.146 |     1.5
   11 |   0.6702 |     20.526 |   0.8927 |     27.072 |     1.7
   12 |   0.6216 |     18.860 |   0.8852 |     27.256 |     1.8
   13 |   0.5829 |     17.632 |   0.8829 |     26.857 |     2.0
   14 |   0.5451 |     16.584 |   0.8642 |     25.875 |     2.1
   15 |   0.5125 |     15.482 |   0.8573 |     25.476 |     2.3
   16 |   0.4791 |     14.211 |   0.8502 |     25.599 |     2.4
   17 |   0.4530 |     13.624 |   0.8899 |     26.182 |     2.6
   18 |   0.4145 |     12.445 |   0.8840 |     24.862 |     2.7
   19 |   0.3931 |     11.880 |   0.8571 |     24.954 |     2.9
   20 |   0.3733 |     11.502 |   0.8612 |     24.340 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,378

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1254 |     53.969 |   1.4502 |     43.616 |     0.2
    2 |   1.4298 |     42.812 |   1.3054 |     40.853 |     0.3
    3 |   1.2970 |     39.929 |   1.2255 |     39.656 |     0.5
    4 |   1.2114 |     37.818 |   1.1675 |     37.784 |     0.6
    5 |   1.1437 |     35.927 |   1.1187 |     35.881 |     0.8
    6 |   1.0786 |     34.084 |   1.0796 |     34.715 |     0.9
    7 |   1.0244 |     32.418 |   1.0610 |     33.671 |     1.1
    8 |   0.9720 |     30.439 |   1.0285 |     33.088 |     1.3
    9 |   0.9258 |     29.331 |   1.0076 |     31.891 |     1.4
   10 |   0.8806 |     27.834 |   1.0047 |     32.136 |     1.6
   11 |   0.8408 |     26.617 |   0.9759 |     30.510 |     1.7
   12 |   0.8013 |     25.044 |   0.9558 |     29.650 |     1.9
   13 |   0.7615 |     23.755 |   0.9541 |     29.619 |     2.0
   14 |   0.7321 |     22.944 |   0.9439 |     28.821 |     2.2
   15 |   0.6936 |     21.919 |   0.9319 |     28.852 |     2.4
   16 |   0.6646 |     20.932 |   0.9272 |     28.607 |     2.5
   17 |   0.6284 |     19.644 |   0.9213 |     27.901 |     2.7
   18 |   0.6114 |     19.435 |   0.9407 |     27.624 |     2.8
   19 |   0.5778 |     18.191 |   0.9220 |     27.041 |     3.0
   20 |   0.5549 |     17.654 |   0.9128 |     27.471 |     3.1
   21 |   0.5270 |     16.360 |   0.9152 |     26.857 |     3.3
   22 |   0.5038 |     15.806 |   0.9190 |     27.103 |     3.5
   23 |   0.4832 |     15.055 |   0.9370 |     26.611 |     3.6
   24 |   0.4727 |     15.000 |   0.9182 |     25.568 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,472,162

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2259 |     57.845 |   1.5040 |     43.831 |     0.1
    2 |   1.4697 |     43.492 |   1.3125 |     41.130 |     0.3
    3 |   1.3213 |     40.954 |   1.2294 |     38.920 |     0.4
    4 |   1.2362 |     38.717 |   1.1744 |     37.569 |     0.5
    5 |   1.1607 |     36.590 |   1.1181 |     36.188 |     0.7
    6 |   1.0988 |     35.121 |   1.0876 |     35.574 |     0.8
    7 |   1.0422 |     33.207 |   1.0586 |     34.837 |     1.0
    8 |   0.9946 |     31.584 |   1.0315 |     33.303 |     1.1
    9 |   0.9448 |     29.819 |   0.9975 |     32.136 |     1.2
   10 |   0.8975 |     28.531 |   0.9684 |     31.062 |     1.4
   11 |   0.8550 |     26.667 |   0.9554 |     30.295 |     1.5
   12 |   0.8166 |     25.636 |   0.9314 |     28.975 |     1.6
   13 |   0.7823 |     24.353 |   0.9189 |     28.821 |     1.8
   14 |   0.7458 |     23.487 |   0.9289 |     29.006 |     1.9
   15 |   0.7134 |     22.204 |   0.9199 |     28.422 |     2.0
   16 |   0.6822 |     21.305 |   0.9136 |     28.392 |     2.2
   17 |   0.6566 |     20.724 |   0.8992 |     26.918 |     2.3
   18 |   0.6285 |     19.704 |   0.8935 |     26.857 |     2.5
   19 |   0.6010 |     18.838 |   0.8803 |     26.888 |     2.6
   20 |   0.5818 |     18.427 |   0.8959 |     26.642 |     2.7
   21 |   0.5506 |     17.445 |   0.8989 |     26.151 |     2.9
   22 |   0.5289 |     16.431 |   0.9015 |     26.243 |     3.0
   23 |   0.5002 |     15.680 |   0.9312 |     26.980 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 485,922

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6341 |     46.656 |   1.3101 |     42.050 |     0.1
    2 |   1.2104 |     39.786 |   1.1743 |     39.932 |     0.2
    3 |   1.0736 |     35.910 |   1.0443 |     34.745 |     0.4
    4 |   0.9792 |     33.076 |   1.0016 |     33.241 |     0.5
    5 |   0.9117 |     30.603 |   0.9705 |     33.026 |     0.6
    6 |   0.8448 |     28.553 |   0.9402 |     31.707 |     0.7
    7 |   0.7995 |     26.826 |   0.8933 |     29.098 |     0.9
    8 |   0.7429 |     24.940 |   0.9016 |     29.865 |     1.0
    9 |   0.7027 |     23.734 |   0.8791 |     27.808 |     1.1
   10 |   0.6569 |     22.160 |   0.8437 |     27.870 |     1.2
   11 |   0.6186 |     20.691 |   0.8511 |     26.949 |     1.3
   12 |   0.5818 |     19.868 |   0.8376 |     25.783 |     1.5
   13 |   0.5392 |     18.498 |   0.8185 |     25.967 |     1.6
   14 |   0.5093 |     17.116 |   0.8331 |     25.783 |     1.7
   15 |   0.4865 |     16.650 |   0.8393 |     25.506 |     1.8
   16 |   0.4505 |     15.263 |   0.8331 |     25.292 |     1.9
   17 |   0.4323 |     14.709 |   0.8541 |     25.261 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 602,658

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6281 |     46.908 |   1.2942 |     41.835 |     0.1
    2 |   1.2067 |     40.033 |   1.1451 |     38.858 |     0.2
    3 |   1.0861 |     36.530 |   1.0832 |     36.710 |     0.3
    4 |   1.0034 |     33.766 |   1.0397 |     35.789 |     0.5
    5 |   0.9436 |     31.908 |   1.0359 |     34.653 |     0.6
    6 |   0.8941 |     30.323 |   0.9757 |     32.290 |     0.7
    7 |   0.8364 |     28.520 |   0.9392 |     30.356 |     0.8
    8 |   0.7983 |     27.467 |   0.9026 |     30.080 |     0.9
    9 |   0.7552 |     25.691 |   0.9201 |     30.172 |     1.0
   10 |   0.7203 |     24.539 |   0.8554 |     27.409 |     1.2
   11 |   0.6808 |     22.988 |   0.8781 |     28.085 |     1.3
   12 |   0.6516 |     22.270 |   0.8402 |     26.489 |     1.4
   13 |   0.6217 |     20.828 |   0.8523 |     27.103 |     1.5
   14 |   0.5955 |     20.334 |   0.8300 |     26.212 |     1.6
   15 |   0.5648 |     19.359 |   0.8439 |     25.905 |     1.7
   16 |   0.5460 |     18.854 |   0.8316 |     26.458 |     1.9
   17 |   0.5147 |     17.939 |   0.8419 |     25.292 |     2.0
   18 |   0.4929 |     16.996 |   0.8556 |     25.629 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3803 |     55.367 |   1.7505 |     45.150 |     0.1
    2 |   1.5898 |     42.944 |   1.4984 |     42.327 |     0.3
    3 |   1.4157 |     40.927 |   1.3867 |     40.669 |     0.4
    4 |   1.3093 |     38.854 |   1.3101 |     38.490 |     0.6
    5 |   1.2249 |     36.310 |   1.2368 |     36.832 |     0.7
    6 |   1.1474 |     34.041 |   1.1717 |     35.697 |     0.9
    7 |   1.0804 |     32.385 |   1.1301 |     34.960 |     1.1
    8 |   1.0209 |     30.757 |   1.0882 |     33.333 |     1.2
    9 |   0.9700 |     28.953 |   1.0590 |     32.842 |     1.4
   10 |   0.9152 |     27.462 |   1.0413 |     32.812 |     1.5
   11 |   0.8740 |     26.513 |   1.0006 |     30.295 |     1.7
   12 |   0.8295 |     24.589 |   0.9926 |     30.602 |     1.8
   13 |   0.7906 |     23.745 |   0.9597 |     29.405 |     2.0
   14 |   0.7546 |     22.462 |   0.9504 |     29.220 |     2.1
   15 |   0.7172 |     21.354 |   0.9410 |     28.944 |     2.3
   16 |   0.6862 |     20.521 |   0.9512 |     29.220 |     2.4
   17 |   0.6493 |     19.320 |   0.9498 |     29.405 |     2.6
   18 |   0.6236 |     18.569 |   0.9176 |     27.839 |     2.7
   19 |   0.5919 |     17.445 |   0.9183 |     27.379 |     2.9
   20 |   0.5653 |     16.628 |   0.9137 |     27.624 |     3.0
   21 |   0.5421 |     16.118 |   0.9001 |     27.010 |     3.2
   22 |   0.5161 |     15.126 |   0.9019 |     26.335 |     3.3
   23 |   0.4932 |     14.534 |   0.9151 |     26.796 |     3.5
   24 |   0.4730 |     13.964 |   0.8990 |     26.151 |     3.6
   25 |   0.4587 |     13.586 |   0.9011 |     26.212 |     3.8
   26 |   0.4255 |     12.396 |   0.9147 |     25.967 |     3.9
   27 |   0.4080 |     11.880 |   0.9288 |     25.783 |     4.1
   28 |   0.3933 |     11.519 |   0.9230 |     26.059 |     4.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5405 |     46.645 |   1.2573 |     41.682 |     0.1
    2 |   1.2034 |     40.126 |   1.1424 |     38.244 |     0.3
    3 |   1.1061 |     37.012 |   1.0670 |     35.390 |     0.5
    4 |   1.0510 |     35.455 |   1.0250 |     34.899 |     0.6
    5 |   0.9803 |     33.037 |   1.0227 |     34.868 |     0.8
    6 |   0.9396 |     31.486 |   0.9790 |     32.505 |     0.9
    7 |   0.9003 |     30.197 |   0.9327 |     31.001 |     1.1
    8 |   0.8412 |     28.465 |   0.9166 |     31.522 |     1.2
    9 |   0.8205 |     27.791 |   0.8935 |     29.834 |     1.4
   10 |   0.7781 |     26.584 |   0.8915 |     29.773 |     1.5
   11 |   0.7608 |     26.047 |   0.8695 |     29.190 |     1.7
   12 |   0.7207 |     24.446 |   0.8425 |     28.975 |     1.8
   13 |   0.6947 |     23.624 |   0.8816 |     28.115 |     2.0
   14 |   0.6719 |     22.802 |   0.8127 |     26.642 |     2.1
   15 |   0.6377 |     21.880 |   0.8458 |     27.839 |     2.3
   16 |   0.6097 |     20.850 |   0.8164 |     26.120 |     2.4
   17 |   0.5917 |     20.274 |   0.8101 |     25.292 |     2.6
   18 |   0.5755 |     19.627 |   0.8546 |     26.949 |     2.7
   19 |   0.5527 |     19.079 |   0.8159 |     25.476 |     2.9
   20 |   0.5293 |     18.092 |   0.8378 |     26.458 |     3.0
   21 |   0.5183 |     17.769 |   0.8151 |     25.537 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,642

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2244 |     57.440 |   1.4745 |     44.138 |     0.2
    2 |   1.4415 |     43.470 |   1.3077 |     41.375 |     0.4
    3 |   1.2941 |     39.863 |   1.2040 |     37.907 |     0.6
    4 |   1.1987 |     37.116 |   1.1600 |     36.618 |     0.8
    5 |   1.1247 |     35.192 |   1.0923 |     34.715 |     1.0
    6 |   1.0559 |     33.388 |   1.0496 |     33.640 |     1.2
    7 |   0.9940 |     31.261 |   1.0144 |     32.259 |     1.4
    8 |   0.9476 |     29.825 |   1.0145 |     32.750 |     1.6
    9 |   0.8990 |     28.498 |   0.9746 |     30.755 |     1.8
   10 |   0.8506 |     26.996 |   0.9470 |     29.650 |     2.0
   11 |   0.8046 |     25.417 |   0.9347 |     29.926 |     2.3
   12 |   0.7674 |     23.958 |   0.9278 |     28.607 |     2.5
   13 |   0.7225 |     22.582 |   0.9224 |     28.453 |     2.7
   14 |   0.6904 |     21.700 |   0.9170 |     28.146 |     2.9
   15 |   0.6565 |     20.592 |   0.9008 |     27.287 |     3.1
   16 |   0.6278 |     19.550 |   0.9145 |     27.563 |     3.3
   17 |   0.5910 |     18.487 |   0.8926 |     27.133 |     3.5
   18 |   0.5665 |     18.010 |   0.9024 |     27.010 |     3.7
   19 |   0.5401 |     16.946 |   0.9134 |     25.875 |     3.9
   20 |   0.5150 |     15.921 |   0.9116 |     26.734 |     4.1
   21 |   0.4928 |     15.488 |   0.9193 |     25.599 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 602,658

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6329 |     66.464 |   1.7885 |     45.058 |     0.1
    2 |   1.7419 |     45.274 |   1.5403 |     44.168 |     0.3
    3 |   1.5494 |     43.865 |   1.4405 |     43.432 |     0.4
    4 |   1.4457 |     42.412 |   1.3585 |     41.713 |     0.5
    5 |   1.3626 |     40.702 |   1.2909 |     39.564 |     0.6
    6 |   1.2906 |     39.041 |   1.2412 |     38.521 |     0.8
    7 |   1.2295 |     37.648 |   1.2018 |     37.293 |     0.9
    8 |   1.1784 |     36.113 |   1.1771 |     36.771 |     1.0
    9 |   1.1319 |     34.693 |   1.1337 |     35.052 |     1.1
   10 |   1.0899 |     33.871 |   1.1374 |     35.267 |     1.3
   11 |   1.0491 |     32.270 |   1.1070 |     34.316 |     1.4
   12 |   1.0133 |     31.404 |   1.0834 |     33.794 |     1.5
   13 |   0.9796 |     30.323 |   1.0590 |     32.934 |     1.6
   14 |   0.9436 |     29.200 |   1.0487 |     32.904 |     1.8
   15 |   0.9165 |     28.624 |   1.0294 |     32.413 |     1.9
   16 |   0.8840 |     27.368 |   1.0209 |     32.014 |     2.0
   17 |   0.8562 |     26.168 |   1.0100 |     31.461 |     2.1
   18 |   0.8293 |     25.620 |   1.0154 |     31.707 |     2.3
   19 |   0.8009 |     24.342 |   1.0072 |     31.185 |     2.4
   20 |   0.7829 |     24.348 |   0.9971 |     30.694 |     2.5
   21 |   0.7582 |     23.607 |   0.9766 |     30.172 |     2.6
   22 |   0.7383 |     22.697 |   1.0031 |     30.632 |     2.8
   23 |   0.7147 |     22.198 |   0.9863 |     29.405 |     2.9
   24 |   0.7012 |     21.431 |   0.9934 |     30.325 |     3.0
   25 |   0.6790 |     20.779 |   1.0009 |     29.834 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 552,674

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3958 |     59.079 |   1.7017 |     45.304 |     0.1
    2 |   1.5570 |     43.871 |   1.4671 |     42.910 |     0.3
    3 |   1.3914 |     40.417 |   1.3582 |     40.209 |     0.4
    4 |   1.2853 |     37.829 |   1.2968 |     38.766 |     0.5
    5 |   1.1990 |     35.625 |   1.2191 |     37.078 |     0.6
    6 |   1.1270 |     33.810 |   1.1709 |     35.942 |     0.8
    7 |   1.0618 |     31.985 |   1.1199 |     34.377 |     0.9
    8 |   1.0013 |     30.400 |   1.0849 |     32.965 |     1.0
    9 |   0.9451 |     28.547 |   1.0652 |     33.118 |     1.2
   10 |   0.8948 |     26.946 |   1.0334 |     32.136 |     1.3
   11 |   0.8496 |     25.614 |   0.9987 |     31.400 |     1.4
   12 |   0.8030 |     24.342 |   0.9689 |     30.264 |     1.6
   13 |   0.7652 |     23.087 |   0.9558 |     30.018 |     1.7
   14 |   0.7256 |     22.138 |   0.9509 |     29.650 |     1.8
   15 |   0.6880 |     20.828 |   0.9290 |     28.607 |     1.9
   16 |   0.6523 |     19.441 |   0.9107 |     28.668 |     2.1
   17 |   0.6326 |     19.139 |   0.9379 |     28.760 |     2.2
   18 |   0.5961 |     17.834 |   0.9069 |     27.624 |     2.3
   19 |   0.5671 |     16.711 |   0.9020 |     26.949 |     2.5
   20 |   0.5365 |     15.938 |   0.9086 |     27.563 |     2.6
   21 |   0.5135 |     15.334 |   0.8864 |     26.765 |     2.7
   22 |   0.4925 |     14.529 |   0.9119 |     27.041 |     2.8
   23 |   0.4710 |     13.838 |   0.8946 |     26.427 |     3.0
   24 |   0.4494 |     13.218 |   0.9094 |     26.581 |     3.1
   25 |   0.4338 |     12.791 |   0.9051 |     26.182 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3333 |     58.569 |   1.5454 |     45.058 |     0.1
    2 |   1.5109 |     44.600 |   1.3564 |     42.142 |     0.3
    3 |   1.3550 |     41.502 |   1.2633 |     39.932 |     0.5
    4 |   1.2598 |     39.337 |   1.1956 |     38.091 |     0.6
    5 |   1.1902 |     37.445 |   1.1554 |     36.924 |     0.8
    6 |   1.1251 |     35.576 |   1.1117 |     35.635 |     0.9
    7 |   1.0713 |     33.810 |   1.0756 |     33.794 |     1.1
    8 |   1.0243 |     32.643 |   1.0462 |     33.149 |     1.2
    9 |   0.9814 |     31.102 |   1.0312 |     33.456 |     1.4
   10 |   0.9345 |     29.391 |   0.9906 |     30.939 |     1.5
   11 |   0.8970 |     28.481 |   0.9826 |     31.553 |     1.7
   12 |   0.8586 |     27.209 |   0.9681 |     29.711 |     1.8
   13 |   0.8217 |     26.025 |   0.9510 |     29.650 |     2.0
   14 |   0.7851 |     24.446 |   0.9487 |     29.497 |     2.1
   15 |   0.7601 |     23.876 |   0.9400 |     28.422 |     2.3
   16 |   0.7318 |     22.906 |   0.9314 |     28.361 |     2.4
   17 |   0.7025 |     22.023 |   0.9126 |     27.471 |     2.6
   18 |   0.6788 |     21.628 |   0.9213 |     27.532 |     2.7
   19 |   0.6552 |     20.367 |   0.9143 |     27.716 |     2.9
   20 |   0.6324 |     19.600 |   0.9126 |     27.348 |     3.0
   21 |   0.6120 |     19.106 |   0.9182 |     27.317 |     3.2
   22 |   0.5829 |     18.372 |   0.9121 |     27.103 |     3.4
   23 |   0.5637 |     17.752 |   0.9244 |     27.164 |     3.5
   24 |   0.5475 |     17.352 |   0.9077 |     26.611 |     3.7
   25 |   0.5270 |     16.535 |   0.9224 |     26.304 |     3.8
   26 |   0.5108 |     16.299 |   0.9317 |     26.581 |     4.0
   27 |   0.4932 |     15.570 |   0.9203 |     25.844 |     4.1
   28 |   0.4791 |     15.033 |   0.9274 |     26.274 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,472,162

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5438 |     46.842 |   1.2614 |     41.252 |     0.2
    2 |   1.2375 |     40.948 |   1.1784 |     39.503 |     0.3
    3 |   1.1402 |     38.158 |   1.1365 |     37.937 |     0.5
    4 |   1.0746 |     36.053 |   1.0736 |     35.758 |     0.7
    5 |   1.0124 |     34.090 |   1.0167 |     33.947 |     0.8
    6 |   0.9748 |     33.054 |   0.9995 |     32.719 |     1.0
    7 |   0.9341 |     31.431 |   1.0007 |     32.689 |     1.2
    8 |   0.8899 |     30.307 |   0.9682 |     31.983 |     1.3
    9 |   0.8507 |     28.717 |   0.9154 |     30.264 |     1.5
   10 |   0.8214 |     27.823 |   0.8986 |     29.159 |     1.7
   11 |   0.7862 |     26.656 |   0.9032 |     29.558 |     1.8
   12 |   0.7507 |     25.247 |   0.8702 |     28.576 |     2.0
   13 |   0.7199 |     24.221 |   0.8609 |     28.637 |     2.2
   14 |   0.6919 |     23.311 |   0.8623 |     28.085 |     2.3
   15 |   0.6535 |     22.270 |   0.8885 |     27.870 |     2.5
   16 |   0.6365 |     21.705 |   0.8608 |     28.023 |     2.7
   17 |   0.5993 |     20.389 |   0.8520 |     26.366 |     2.8
   18 |   0.5747 |     19.468 |   0.8563 |     26.489 |     3.0
   19 |   0.5457 |     18.454 |   0.8539 |     26.611 |     3.2
   20 |   0.5331 |     18.092 |   0.8414 |     25.506 |     3.3
   21 |   0.5263 |     17.643 |   0.8455 |     25.138 |     3.5
   22 |   0.4861 |     16.689 |   0.8614 |     26.059 |     3.7
   23 |   0.4728 |     16.053 |   0.8594 |     24.862 |     3.8
   24 |   0.4542 |     15.471 |   0.8446 |     24.586 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6708 |     48.048 |   1.3115 |     42.449 |     0.1
    2 |   1.2155 |     39.830 |   1.1728 |     38.613 |     0.2
    3 |   1.0937 |     36.118 |   1.0910 |     36.280 |     0.3
    4 |   1.0158 |     34.073 |   1.0338 |     34.254 |     0.4
    5 |   0.9317 |     31.486 |   0.9808 |     32.627 |     0.6
    6 |   0.8824 |     29.512 |   0.9435 |     31.400 |     0.7
    7 |   0.8304 |     28.032 |   0.9378 |     30.356 |     0.8
    8 |   0.7893 |     26.787 |   0.8922 |     29.804 |     0.9
    9 |   0.7438 |     25.005 |   0.8698 |     29.128 |     1.0
   10 |   0.7012 |     23.827 |   0.8864 |     28.361 |     1.1
   11 |   0.6644 |     22.418 |   0.8679 |     27.839 |     1.2
   12 |   0.6176 |     20.894 |   0.8707 |     27.594 |     1.3
   13 |   0.5969 |     20.005 |   0.8618 |     27.931 |     1.5
   14 |   0.5796 |     19.693 |   0.8713 |     27.993 |     1.6
   15 |   0.5369 |     18.043 |   0.8466 |     25.998 |     1.7
   16 |   0.5186 |     17.670 |   0.8471 |     27.686 |     1.8
   17 |   0.4936 |     16.963 |   0.8224 |     25.261 |     1.9
   18 |   0.4679 |     16.064 |   0.8434 |     24.985 |     2.0
   19 |   0.4584 |     15.488 |   0.8372 |     25.568 |     2.1
   20 |   0.4236 |     14.380 |   0.8598 |     26.335 |     2.2
   21 |   0.4159 |     14.364 |   0.8826 |     25.445 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 470,562

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7411 |     49.002 |   1.3032 |     42.388 |     0.1
    2 |   1.2748 |     41.590 |   1.2029 |     40.147 |     0.2
    3 |   1.1725 |     38.975 |   1.1316 |     37.937 |     0.4
    4 |   1.1069 |     36.897 |   1.1042 |     36.280 |     0.5
    5 |   1.0607 |     35.592 |   1.0469 |     35.513 |     0.6
    6 |   1.0032 |     33.509 |   1.0163 |     34.101 |     0.7
    7 |   0.9589 |     32.182 |   0.9870 |     33.026 |     0.8
    8 |   0.9259 |     31.118 |   0.9540 |     31.154 |     1.0
    9 |   0.8814 |     29.545 |   0.9556 |     31.338 |     1.1
   10 |   0.8528 |     28.788 |   0.9287 |     30.663 |     1.2
   11 |   0.8308 |     28.185 |   0.9221 |     31.492 |     1.3
   12 |   0.7891 |     26.310 |   0.8857 |     28.913 |     1.4
   13 |   0.7681 |     26.195 |   0.8978 |     29.466 |     1.6
   14 |   0.7337 |     24.901 |   0.8875 |     29.220 |     1.7
   15 |   0.7176 |     24.304 |   0.8822 |     28.607 |     1.8
   16 |   0.6882 |     23.032 |   0.8828 |     28.484 |     1.9
   17 |   0.6571 |     22.637 |   0.8478 |     27.103 |     2.1
   18 |   0.6424 |     21.853 |   0.8789 |     27.686 |     2.2
   19 |   0.6191 |     21.091 |   0.8531 |     26.274 |     2.3
   20 |   0.6080 |     20.636 |   0.8708 |     27.348 |     2.4
   21 |   0.5705 |     19.441 |   0.8674 |     26.642 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5560 |     46.623 |   1.2607 |     42.296 |     0.2
    2 |   1.2220 |     40.592 |   1.1698 |     39.380 |     0.3
    3 |   1.1421 |     38.454 |   1.1088 |     38.152 |     0.5
    4 |   1.0739 |     36.118 |   1.0498 |     35.513 |     0.6
    5 |   1.0185 |     34.364 |   1.0212 |     34.684 |     0.8
    6 |   0.9635 |     32.511 |   0.9951 |     33.824 |     1.0
    7 |   0.9322 |     31.497 |   0.9929 |     33.671 |     1.1
    8 |   0.8887 |     30.049 |   0.9307 |     30.694 |     1.3
    9 |   0.8467 |     28.361 |   0.9210 |     30.786 |     1.5
   10 |   0.8205 |     27.812 |   0.9456 |     31.676 |     1.6
   11 |   0.7822 |     26.568 |   0.8869 |     28.975 |     1.8
   12 |   0.7479 |     25.312 |   0.8911 |     28.207 |     1.9
   13 |   0.7188 |     24.529 |   0.9205 |     29.865 |     2.1
   14 |   0.7023 |     23.920 |   0.8999 |     29.497 |     2.3
   15 |   0.6643 |     22.834 |   0.8831 |     28.484 |     2.4
   16 |   0.6452 |     21.864 |   0.8802 |     27.778 |     2.6
   17 |   0.6318 |     21.480 |   0.9015 |     28.484 |     2.8
   18 |   0.6103 |     20.883 |   0.8925 |     28.699 |     2.9
   19 |   0.5900 |     20.362 |   0.8957 |     28.146 |     3.1
   20 |   0.5789 |     19.934 |   0.8859 |     28.207 |     3.2
   21 |   0.5568 |     19.145 |   0.8637 |     26.796 |     3.4
   22 |   0.5248 |     18.180 |   0.8832 |     26.765 |     3.6
   23 |   0.5113 |     17.791 |   0.8957 |     26.949 |     3.7
   24 |   0.4967 |     17.056 |   0.8943 |     26.673 |     3.9
   25 |   0.4794 |     16.656 |   0.9103 |     27.471 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,378

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2078 |     55.844 |   1.4768 |     44.598 |     0.1
    2 |   1.4520 |     43.394 |   1.3040 |     39.840 |     0.3
    3 |   1.3097 |     40.115 |   1.2183 |     38.950 |     0.4
    4 |   1.2229 |     37.917 |   1.1592 |     37.416 |     0.5
    5 |   1.1438 |     36.036 |   1.1123 |     36.403 |     0.6
    6 |   1.0853 |     34.293 |   1.0773 |     34.162 |     0.8
    7 |   1.0309 |     32.484 |   1.0361 |     33.211 |     0.9
    8 |   0.9805 |     30.992 |   1.0307 |     32.996 |     1.0
    9 |   0.9359 |     29.666 |   0.9973 |     31.737 |     1.1
   10 |   0.8909 |     28.109 |   0.9821 |     32.014 |     1.3
   11 |   0.8490 |     26.859 |   0.9693 |     31.093 |     1.4
   12 |   0.8094 |     25.461 |   0.9541 |     30.049 |     1.5
   13 |   0.7730 |     24.194 |   0.9546 |     29.282 |     1.7
   14 |   0.7394 |     23.251 |   0.9369 |     28.607 |     1.8
   15 |   0.7122 |     22.330 |   0.9203 |     27.594 |     1.9
   16 |   0.6769 |     21.069 |   0.9248 |     28.484 |     2.0
   17 |   0.6505 |     20.356 |   0.9245 |     28.238 |     2.2
   18 |   0.6199 |     19.348 |   0.9330 |     28.238 |     2.3
   19 |   0.5931 |     18.328 |   0.9274 |     27.256 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 437,090

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5304 |     62.473 |   1.8538 |     45.457 |     0.1
    2 |   1.6435 |     44.123 |   1.5097 |     42.327 |     0.2
    3 |   1.4339 |     41.239 |   1.3744 |     39.687 |     0.3
    4 |   1.3168 |     38.755 |   1.2925 |     38.828 |     0.4
    5 |   1.2309 |     36.689 |   1.2286 |     36.863 |     0.5
    6 |   1.1613 |     34.879 |   1.1799 |     35.635 |     0.6
    7 |   1.1020 |     33.180 |   1.1544 |     35.298 |     0.7
    8 |   1.0470 |     31.727 |   1.1053 |     33.241 |     0.8
    9 |   0.9936 |     30.175 |   1.0740 |     32.842 |     0.9
   10 |   0.9456 |     28.629 |   1.0365 |     31.768 |     1.0
   11 |   0.9009 |     27.352 |   1.0262 |     32.106 |     1.1
   12 |   0.8596 |     25.537 |   1.0048 |     30.632 |     1.1
   13 |   0.8264 |     25.044 |   0.9955 |     30.602 |     1.2
   14 |   0.7864 |     23.904 |   0.9752 |     29.773 |     1.3
   15 |   0.7505 |     22.610 |   0.9662 |     29.896 |     1.4
   16 |   0.7227 |     21.771 |   0.9464 |     29.128 |     1.5
   17 |   0.6955 |     21.195 |   0.9407 |     28.852 |     1.6
   18 |   0.6664 |     20.252 |   0.9285 |     28.821 |     1.7
   19 |   0.6369 |     19.326 |   0.9349 |     28.545 |     1.8
   20 |   0.6120 |     18.317 |   0.9269 |     28.545 |     1.9
   21 |   0.5893 |     17.571 |   0.9153 |     28.330 |     2.0
   22 |   0.5685 |     16.924 |   0.9180 |     28.207 |     2.1
   23 |   0.5421 |     16.354 |   0.9057 |     27.440 |     2.2
   24 |   0.5286 |     15.718 |   0.9196 |     28.146 |     2.3
   25 |   0.5046 |     15.022 |   0.9245 |     27.778 |     2.4
   26 |   0.4904 |     14.671 |   0.9202 |     27.133 |     2.5
   27 |   0.4700 |     14.101 |   0.9061 |     27.133 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 437,090

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6486 |     67.177 |   1.9715 |     50.092 |     0.1
    2 |   1.6802 |     44.709 |   1.5479 |     43.370 |     0.2
    3 |   1.4590 |     41.913 |   1.4161 |     40.915 |     0.4
    4 |   1.3502 |     39.934 |   1.3293 |     39.564 |     0.5
    5 |   1.2615 |     37.626 |   1.2598 |     38.490 |     0.6
    6 |   1.1912 |     35.570 |   1.2263 |     37.968 |     0.8
    7 |   1.1244 |     33.766 |   1.1599 |     36.065 |     0.9
    8 |   1.0633 |     31.749 |   1.1219 |     34.561 |     1.0
    9 |   1.0118 |     30.411 |   1.0903 |     33.640 |     1.1
   10 |   0.9586 |     28.657 |   1.0703 |     33.395 |     1.3
   11 |   0.9187 |     27.275 |   1.0486 |     32.842 |     1.4
   12 |   0.8783 |     26.524 |   1.0205 |     31.215 |     1.5
   13 |   0.8368 |     25.203 |   1.0151 |     31.492 |     1.6
   14 |   0.8079 |     24.095 |   1.0011 |     31.676 |     1.8
   15 |   0.7737 |     23.207 |   0.9676 |     29.589 |     1.9
   16 |   0.7397 |     22.078 |   0.9444 |     28.054 |     2.0
   17 |   0.7130 |     21.360 |   0.9314 |     28.392 |     2.2
   18 |   0.6859 |     20.515 |   0.9385 |     28.453 |     2.3
   19 |   0.6628 |     19.874 |   0.9135 |     27.041 |     2.4
   20 |   0.6321 |     18.745 |   0.9149 |     28.177 |     2.5
   21 |   0.6044 |     17.971 |   0.9011 |     27.471 |     2.7
   22 |   0.5829 |     17.281 |   0.9113 |     27.870 |     2.8
   23 |   0.5621 |     16.771 |   0.8971 |     26.826 |     2.9
   24 |   0.5426 |     16.124 |   0.9048 |     26.857 |     3.0
   25 |   0.5253 |     15.318 |   0.9071 |     28.207 |     3.2
   26 |   0.5067 |     15.011 |   0.8950 |     26.980 |     3.3
   27 |   0.4833 |     14.052 |   0.8903 |     26.857 |     3.4
   28 |   0.4655 |     13.679 |   0.9141 |     26.397 |     3.6
   29 |   0.4536 |     13.306 |   0.9001 |     26.581 |     3.7
   30 |   0.4328 |     12.917 |   0.9141 |     26.611 |     3.8
   31 |   0.4234 |     12.495 |   0.8959 |     25.752 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4840 |     45.060 |   1.2203 |     40.147 |     0.1
    2 |   1.1427 |     38.355 |   1.1456 |     38.214 |     0.2
    3 |   1.0433 |     35.263 |   1.0561 |     35.083 |     0.3
    4 |   0.9670 |     32.823 |   0.9864 |     31.707 |     0.5
    5 |   0.9038 |     30.938 |   0.9866 |     32.719 |     0.6
    6 |   0.8525 |     29.024 |   0.9507 |     31.645 |     0.7
    7 |   0.8157 |     27.823 |   0.8919 |     29.834 |     0.8
    8 |   0.7719 |     26.031 |   0.8872 |     30.172 |     0.9
    9 |   0.7338 |     25.214 |   0.8746 |     28.791 |     1.0
   10 |   0.6879 |     23.728 |   0.8622 |     28.115 |     1.2
   11 |   0.6606 |     22.314 |   0.8450 |     27.901 |     1.3
   12 |   0.6181 |     20.938 |   0.8573 |     28.054 |     1.4
   13 |   0.6040 |     20.762 |   0.8305 |     27.133 |     1.5
   14 |   0.5651 |     19.496 |   0.8313 |     27.747 |     1.6
   15 |   0.5374 |     18.076 |   0.8785 |     27.409 |     1.7
   16 |   0.5161 |     17.719 |   0.8316 |     25.783 |     1.8
   17 |   0.4907 |     16.897 |   0.8503 |     26.642 |     2.0
   18 |   0.4766 |     16.310 |   0.8145 |     24.800 |     2.1
   19 |   0.4448 |     15.274 |   0.8237 |     25.322 |     2.2
   20 |   0.4365 |     14.929 |   0.8653 |     25.629 |     2.3
   21 |   0.4261 |     14.841 |   0.8587 |     25.783 |     2.4
   22 |   0.4000 |     13.794 |   0.8373 |     23.941 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,341,474

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5604 |     46.930 |   1.2629 |     42.419 |     0.1
    2 |   1.2103 |     41.009 |   1.1738 |     39.503 |     0.3
    3 |   1.1244 |     38.015 |   1.1239 |     37.815 |     0.4
    4 |   1.0510 |     35.883 |   1.0671 |     36.004 |     0.6
    5 |   0.9959 |     33.684 |   1.0736 |     36.126 |     0.7
    6 |   0.9591 |     32.917 |   1.0040 |     34.408 |     0.9
    7 |   0.9073 |     31.212 |   0.9819 |     34.070 |     1.0
    8 |   0.8691 |     29.890 |   0.9658 |     32.842 |     1.2
    9 |   0.8377 |     28.706 |   0.9482 |     31.522 |     1.3
   10 |   0.7899 |     27.423 |   0.9297 |     30.755 |     1.5
   11 |   0.7651 |     26.431 |   0.9011 |     29.804 |     1.6
   12 |   0.7567 |     25.943 |   0.9183 |     30.786 |     1.8
   13 |   0.7395 |     25.680 |   0.8850 |     29.681 |     1.9
   14 |   0.7058 |     24.232 |   0.8716 |     28.913 |     2.1
   15 |   0.6712 |     22.955 |   0.8532 |     27.624 |     2.2
   16 |   0.6396 |     22.012 |   0.8870 |     28.422 |     2.4
   17 |   0.6345 |     21.935 |   0.8470 |     27.379 |     2.5
   18 |   0.6090 |     21.091 |   0.8454 |     27.256 |     2.7
   19 |   0.5839 |     20.258 |   0.8563 |     27.563 |     2.8
   20 |   0.5738 |     19.890 |   0.8566 |     27.072 |     3.0
   21 |   0.5540 |     19.172 |   0.8680 |     26.796 |     3.1
   22 |   0.5351 |     18.580 |   0.8620 |     26.489 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 386,850

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7064 |     66.239 |   2.0813 |     48.742 |     0.1
    2 |   1.9232 |     47.314 |   1.6216 |     44.444 |     0.2
    3 |   1.6331 |     44.550 |   1.4828 |     43.769 |     0.3
    4 |   1.5020 |     43.558 |   1.3971 |     42.572 |     0.4
    5 |   1.4198 |     42.401 |   1.3448 |     40.700 |     0.5
    6 |   1.3533 |     41.020 |   1.2932 |     39.779 |     0.6
    7 |   1.2977 |     39.677 |   1.2634 |     39.012 |     0.7
    8 |   1.2530 |     38.306 |   1.2296 |     38.398 |     0.8
    9 |   1.2106 |     37.281 |   1.1982 |     37.262 |     0.8
   10 |   1.1680 |     35.959 |   1.1724 |     37.017 |     0.9
   11 |   1.1334 |     34.863 |   1.1543 |     36.126 |     1.0
   12 |   1.0974 |     33.607 |   1.1306 |     36.096 |     1.1
   13 |   1.0701 |     33.366 |   1.1009 |     34.285 |     1.2
   14 |   1.0350 |     32.182 |   1.0928 |     33.702 |     1.3
   15 |   1.0058 |     30.981 |   1.0633 |     33.456 |     1.4
   16 |   0.9816 |     30.384 |   1.0582 |     33.149 |     1.5
   17 |   0.9587 |     29.485 |   1.0441 |     32.290 |     1.6
   18 |   0.9259 |     28.865 |   1.0455 |     32.689 |     1.7
   19 |   0.9054 |     28.032 |   1.0311 |     31.921 |     1.8
   20 |   0.8838 |     27.610 |   1.0205 |     30.847 |     1.9
   21 |   0.8588 |     26.864 |   1.0246 |     31.308 |     2.0
   22 |   0.8447 |     26.360 |   1.0084 |     30.724 |     2.1
   23 |   0.8192 |     25.219 |   0.9914 |     30.602 |     2.2
   24 |   0.8032 |     25.033 |   1.0004 |     31.001 |     2.3
   25 |   0.7824 |     23.969 |   0.9951 |     30.755 |     2.4
   26 |   0.7733 |     24.052 |   0.9938 |     29.711 |     2.5
   27 |   0.7536 |     23.465 |   0.9961 |     29.896 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5350 |     46.782 |   1.2740 |     43.247 |     0.2
    2 |   1.2321 |     41.234 |   1.1819 |     40.516 |     0.4
    3 |   1.1491 |     38.777 |   1.1148 |     38.735 |     0.6
    4 |   1.0926 |     37.621 |   1.0824 |     37.078 |     0.8
    5 |   1.0440 |     35.916 |   1.0565 |     36.433 |     1.0
    6 |   1.0053 |     34.189 |   1.0102 |     33.702 |     1.2
    7 |   0.9672 |     33.257 |   1.0066 |     34.653 |     1.4
    8 |   0.9358 |     32.105 |   0.9656 |     32.351 |     1.6
    9 |   0.9007 |     30.833 |   0.9510 |     31.645 |     1.7
   10 |   0.8721 |     29.923 |   0.9276 |     31.492 |     1.9
   11 |   0.8404 |     29.172 |   0.8944 |     30.018 |     2.1
   12 |   0.8106 |     27.955 |   0.8922 |     30.632 |     2.3
   13 |   0.7758 |     26.683 |   0.8700 |     29.251 |     2.5
   14 |   0.7595 |     26.195 |   0.8647 |     28.023 |     2.7
   15 |   0.7202 |     24.463 |   0.8501 |     27.901 |     2.9
   16 |   0.6988 |     24.320 |   0.8420 |     28.177 |     3.1
   17 |   0.6765 |     23.224 |   0.8360 |     27.164 |     3.3
   18 |   0.6481 |     22.215 |   0.8402 |     27.379 |     3.5
   19 |   0.6301 |     21.771 |   0.8297 |     26.458 |     3.7
   20 |   0.5897 |     20.082 |   0.8587 |     27.563 |     3.9
   21 |   0.5725 |     19.819 |   0.8382 |     25.967 |     4.1
   22 |   0.5426 |     18.893 |   0.8191 |     25.844 |     4.3
   23 |   0.5320 |     18.147 |   0.8201 |     26.090 |     4.5
   24 |   0.5088 |     17.610 |   0.8195 |     24.647 |     4.7
   25 |   0.4796 |     16.519 |   0.8337 |     25.537 |     4.9
   26 |   0.4781 |     16.650 |   0.8404 |     24.371 |     5.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9697 |     50.850 |   1.4284 |     43.339 |     0.1
    2 |   1.3106 |     39.814 |   1.2604 |     38.889 |     0.3
    3 |   1.1701 |     36.409 |   1.1658 |     36.157 |     0.4
    4 |   1.0633 |     32.867 |   1.1060 |     34.530 |     0.6
    5 |   0.9789 |     30.493 |   1.0561 |     33.395 |     0.7
    6 |   0.9051 |     28.246 |   1.0080 |     31.614 |     0.9
    7 |   0.8301 |     25.888 |   0.9643 |     30.878 |     1.0
    8 |   0.7644 |     23.777 |   0.9314 |     29.589 |     1.2
    9 |   0.7046 |     21.831 |   0.9317 |     29.865 |     1.3
   10 |   0.6548 |     20.126 |   0.8880 |     27.716 |     1.5
   11 |   0.6093 |     18.542 |   0.8978 |     28.054 |     1.6
   12 |   0.5606 |     17.050 |   0.8757 |     27.440 |     1.8
   13 |   0.5148 |     15.702 |   0.8902 |     27.348 |     1.9
   14 |   0.4880 |     14.770 |   0.8769 |     26.703 |     2.1
   15 |   0.4442 |     13.235 |   0.8922 |     26.949 |     2.2
   16 |   0.4064 |     11.996 |   0.9020 |     26.366 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 485,922

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6425 |     47.138 |   1.2987 |     42.541 |     0.1
    2 |   1.2418 |     40.504 |   1.1766 |     40.147 |     0.3
    3 |   1.1392 |     37.961 |   1.0956 |     37.385 |     0.4
    4 |   1.0698 |     35.992 |   1.0583 |     34.837 |     0.5
    5 |   1.0127 |     33.580 |   1.0004 |     33.395 |     0.7
    6 |   0.9549 |     31.848 |   0.9685 |     32.535 |     0.8
    7 |   0.9077 |     30.548 |   0.9536 |     31.400 |     0.9
    8 |   0.8651 |     28.843 |   0.9301 |     30.663 |     1.1
    9 |   0.8246 |     27.692 |   0.9194 |     29.896 |     1.2
   10 |   0.7882 |     26.541 |   0.8951 |     29.098 |     1.3
   11 |   0.7516 |     25.148 |   0.8715 |     28.975 |     1.5
   12 |   0.7153 |     24.287 |   0.8335 |     27.594 |     1.6
   13 |   0.6890 |     23.235 |   0.8649 |     27.164 |     1.7
   14 |   0.6643 |     22.478 |   0.8357 |     26.980 |     1.9
   15 |   0.6292 |     21.354 |   0.8370 |     26.796 |     2.0
   16 |   0.5963 |     20.351 |   0.8545 |     26.366 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6150 |     61.897 |   1.8285 |     45.212 |     0.2
    2 |   1.7288 |     44.956 |   1.5257 |     43.554 |     0.3
    3 |   1.5313 |     43.542 |   1.4262 |     42.449 |     0.5
    4 |   1.4353 |     42.374 |   1.3509 |     40.700 |     0.7
    5 |   1.3572 |     40.718 |   1.2921 |     39.718 |     0.8
    6 |   1.2944 |     39.145 |   1.2502 |     38.306 |     1.0
    7 |   1.2382 |     37.697 |   1.1998 |     37.078 |     1.1
    8 |   1.1929 |     36.491 |   1.1673 |     36.188 |     1.3
    9 |   1.1431 |     35.444 |   1.1438 |     35.727 |     1.5
   10 |   1.1021 |     34.117 |   1.1051 |     33.732 |     1.6
   11 |   1.0599 |     32.456 |   1.0834 |     33.548 |     1.8
   12 |   1.0242 |     31.261 |   1.0686 |     32.904 |     2.0
   13 |   0.9944 |     30.570 |   1.0490 |     31.891 |     2.1
   14 |   0.9606 |     29.348 |   1.0233 |     31.492 |     2.3
   15 |   0.9238 |     28.416 |   1.0288 |     31.215 |     2.5
   16 |   0.9007 |     27.500 |   1.0027 |     31.031 |     2.6
   17 |   0.8685 |     26.672 |   1.0024 |     31.031 |     2.8
   18 |   0.8455 |     26.162 |   0.9867 |     30.018 |     2.9
   19 |   0.8176 |     25.373 |   0.9870 |     30.602 |     3.1
   20 |   0.7972 |     24.452 |   0.9832 |     29.896 |     3.3
   21 |   0.7738 |     23.860 |   0.9863 |     29.926 |     3.4
   22 |   0.7480 |     23.147 |   0.9751 |     29.681 |     3.6
   23 |   0.7255 |     22.220 |   0.9846 |     29.497 |     3.8
   24 |   0.7109 |     22.039 |   0.9748 |     29.711 |     3.9
   25 |   0.6907 |     21.343 |   0.9799 |     29.006 |     4.1
   26 |   0.6701 |     20.532 |   0.9674 |     29.159 |     4.3
   27 |   0.6512 |     20.082 |   0.9761 |     29.067 |     4.4
   28 |   0.6345 |     19.386 |   0.9875 |     29.343 |     4.6
   29 |   0.6167 |     19.062 |   0.9725 |     28.238 |     4.8
   30 |   0.6024 |     18.459 |   0.9800 |     27.808 |     4.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6109 |     64.205 |   1.9112 |     47.974 |     0.1
    2 |   1.7784 |     46.091 |   1.5556 |     44.322 |     0.2
    3 |   1.5537 |     44.238 |   1.4378 |     42.971 |     0.3
    4 |   1.4423 |     42.440 |   1.3661 |     41.007 |     0.5
    5 |   1.3659 |     40.746 |   1.3025 |     39.227 |     0.6
    6 |   1.3002 |     39.172 |   1.2551 |     39.134 |     0.7
    7 |   1.2453 |     37.867 |   1.2233 |     38.643 |     0.8
    8 |   1.1961 |     36.321 |   1.1794 |     37.569 |     0.9
    9 |   1.1499 |     35.132 |   1.1512 |     36.280 |     1.1
   10 |   1.1046 |     34.106 |   1.1244 |     35.328 |     1.2
   11 |   1.0695 |     32.648 |   1.1064 |     35.328 |     1.3
   12 |   1.0305 |     31.667 |   1.0888 |     34.285 |     1.4
   13 |   0.9991 |     30.789 |   1.0635 |     34.438 |     1.5
   14 |   0.9645 |     29.677 |   1.0480 |     33.241 |     1.6
   15 |   0.9365 |     29.013 |   1.0294 |     32.904 |     1.8
   16 |   0.9035 |     27.928 |   1.0135 |     31.921 |     1.9
   17 |   0.8735 |     27.226 |   1.0076 |     31.522 |     2.0
   18 |   0.8482 |     26.414 |   1.0217 |     32.044 |     2.1
   19 |   0.8170 |     25.356 |   1.0031 |     31.400 |     2.2
   20 |   0.7924 |     24.600 |   0.9855 |     31.277 |     2.3
   21 |   0.7707 |     23.882 |   0.9785 |     30.571 |     2.5
   22 |   0.7519 |     23.427 |   0.9756 |     30.141 |     2.6
   23 |   0.7277 |     22.566 |   0.9670 |     29.589 |     2.7
   24 |   0.7113 |     21.974 |   0.9739 |     29.558 |     2.8
   25 |   0.6890 |     21.102 |   0.9885 |     29.006 |     2.9
   26 |   0.6720 |     20.888 |   0.9766 |     29.742 |     3.1
   27 |   0.6530 |     20.027 |   0.9847 |     29.190 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 552,674

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5629 |     62.736 |   1.8197 |     44.659 |     0.1
    2 |   1.6282 |     43.459 |   1.5071 |     41.498 |     0.2
    3 |   1.4351 |     40.154 |   1.3825 |     39.319 |     0.3
    4 |   1.3129 |     37.566 |   1.2888 |     37.416 |     0.4
    5 |   1.2163 |     35.186 |   1.2128 |     35.697 |     0.5
    6 |   1.1351 |     33.443 |   1.1587 |     34.776 |     0.6
    7 |   1.0634 |     31.672 |   1.1270 |     34.039 |     0.7
    8 |   1.0013 |     29.693 |   1.0720 |     32.627 |     0.8
    9 |   0.9439 |     28.279 |   1.0561 |     32.167 |     0.9
   10 |   0.9056 |     27.275 |   1.0094 |     31.584 |     1.0
   11 |   0.8449 |     25.099 |   0.9900 |     30.939 |     1.1
   12 |   0.8010 |     23.629 |   0.9690 |     29.650 |     1.2
   13 |   0.7637 |     22.785 |   0.9623 |     29.558 |     1.3
   14 |   0.7304 |     21.546 |   0.9423 |     28.054 |     1.4
   15 |   0.6895 |     20.406 |   0.9497 |     29.251 |     1.5
   16 |   0.6591 |     19.512 |   0.9412 |     28.852 |     1.6
   17 |   0.6333 |     18.925 |   0.9109 |     27.594 |     1.7
   18 |   0.5977 |     17.516 |   0.8954 |     26.826 |     1.8
   19 |   0.5776 |     16.782 |   0.8922 |     26.458 |     1.9
   20 |   0.5485 |     16.239 |   0.8880 |     25.875 |     2.0
   21 |   0.5273 |     15.647 |   0.9004 |     26.090 |     2.1
   22 |   0.5058 |     15.049 |   0.8984 |     25.660 |     2.2
   23 |   0.4836 |     14.106 |   0.9014 |     26.243 |     2.3
   24 |   0.4597 |     13.207 |   0.8953 |     25.506 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9984 |     51.941 |   1.4592 |     41.835 |     0.2
    2 |   1.3391 |     40.219 |   1.2885 |     39.012 |     0.4
    3 |   1.1920 |     36.519 |   1.1927 |     36.924 |     0.5
    4 |   1.0911 |     33.887 |   1.1099 |     34.653 |     0.7
    5 |   0.9988 |     30.724 |   1.0526 |     32.873 |     0.9
    6 |   0.9256 |     28.542 |   1.0517 |     33.886 |     1.1
    7 |   0.8548 |     26.453 |   0.9829 |     31.308 |     1.3
    8 |   0.7934 |     24.539 |   0.9466 |     29.558 |     1.4
    9 |   0.7307 |     22.582 |   0.9221 |     28.944 |     1.6
   10 |   0.6729 |     20.367 |   0.8967 |     27.532 |     1.8
   11 |   0.6261 |     19.479 |   0.8906 |     26.857 |     2.0
   12 |   0.5818 |     17.626 |   0.8887 |     27.103 |     2.2
   13 |   0.5424 |     16.595 |   0.8730 |     26.519 |     2.3
   14 |   0.5006 |     14.940 |   0.8650 |     26.243 |     2.5
   15 |   0.4593 |     13.673 |   0.8903 |     25.752 |     2.7
   16 |   0.4331 |     13.015 |   0.8562 |     25.200 |     2.9
   17 |   0.3923 |     11.924 |   0.8688 |     24.463 |     3.1
   18 |   0.3678 |     10.938 |   0.8942 |     24.923 |     3.2
   19 |   0.3358 |      9.951 |   0.9062 |     24.862 |     3.4
   20 |   0.3155 |      9.468 |   0.9183 |     24.985 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 535,906

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3129 |     56.107 |   1.7036 |     44.813 |     0.1
    2 |   1.5639 |     43.657 |   1.4693 |     41.559 |     0.2
    3 |   1.4081 |     41.266 |   1.3678 |     41.314 |     0.3
    4 |   1.3009 |     38.904 |   1.2835 |     38.889 |     0.4
    5 |   1.2113 |     36.645 |   1.2191 |     37.630 |     0.5
    6 |   1.1381 |     34.304 |   1.1823 |     35.881 |     0.7
    7 |   1.0803 |     32.659 |   1.1327 |     35.451 |     0.8
    8 |   1.0214 |     31.025 |   1.1101 |     34.408 |     0.9
    9 |   0.9702 |     29.561 |   1.0618 |     33.088 |     1.0
   10 |   0.9228 |     27.961 |   1.0280 |     32.228 |     1.1
   11 |   0.8821 |     26.848 |   1.0148 |     31.093 |     1.2
   12 |   0.8374 |     25.296 |   0.9908 |     30.417 |     1.3
   13 |   0.8003 |     24.106 |   0.9650 |     29.527 |     1.4
   14 |   0.7654 |     23.103 |   0.9450 |     28.484 |     1.5
   15 |   0.7221 |     21.360 |   0.9538 |     28.637 |     1.6
   16 |   0.6927 |     20.833 |   0.9389 |     28.699 |     1.7
   17 |   0.6634 |     19.836 |   0.9236 |     28.699 |     1.9
   18 |   0.6347 |     18.799 |   0.9216 |     28.821 |     2.0
   19 |   0.6039 |     18.043 |   0.9172 |     28.361 |     2.1
   20 |   0.5822 |     17.396 |   0.9144 |     27.839 |     2.2
   21 |   0.5573 |     16.700 |   0.9256 |     27.287 |     2.3
   22 |   0.5255 |     15.614 |   0.9256 |     27.778 |     2.4
   23 |   0.5075 |     15.291 |   0.9396 |     28.023 |     2.5
   24 |   0.4865 |     14.402 |   0.9330 |     27.348 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 552,674

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6327 |     47.538 |   1.2669 |     41.559 |     0.1
    2 |   1.1763 |     38.794 |   1.1558 |     37.201 |     0.3
    3 |   1.0492 |     34.764 |   1.0518 |     35.083 |     0.4
    4 |   0.9542 |     32.023 |   0.9896 |     33.364 |     0.5
    5 |   0.8907 |     29.731 |   0.9661 |     33.149 |     0.6
    6 |   0.8235 |     27.829 |   0.9395 |     31.891 |     0.8
    7 |   0.7711 |     26.014 |   0.8985 |     30.110 |     0.9
    8 |   0.7211 |     24.084 |   0.8603 |     27.901 |     1.0
    9 |   0.6782 |     22.840 |   0.8390 |     27.317 |     1.2
   10 |   0.6350 |     21.431 |   0.8497 |     28.023 |     1.3
   11 |   0.6004 |     20.236 |   0.8026 |     25.261 |     1.4
   12 |   0.5585 |     19.211 |   0.8080 |     26.397 |     1.6
   13 |   0.5246 |     17.785 |   0.8202 |     25.353 |     1.7
   14 |   0.4870 |     16.541 |   0.8276 |     25.445 |     1.8
   15 |   0.4766 |     16.223 |   0.7817 |     24.678 |     1.9
   16 |   0.4361 |     14.792 |   0.8231 |     24.033 |     2.1
   17 |   0.4206 |     14.627 |   0.8564 |     24.893 |     2.2
   18 |   0.3920 |     13.448 |   0.8246 |     23.327 |     2.3
   19 |   0.3749 |     12.862 |   0.8257 |     23.082 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 602,658

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7124 |     48.953 |   1.3293 |     43.462 |     0.2
    2 |   1.2789 |     42.133 |   1.2148 |     40.546 |     0.3
    3 |   1.1828 |     39.424 |   1.1660 |     38.643 |     0.5
    4 |   1.1104 |     37.725 |   1.1116 |     37.784 |     0.7
    5 |   1.0573 |     35.806 |   1.0647 |     36.188 |     0.9
    6 |   1.0135 |     34.748 |   1.0152 |     34.592 |     1.0
    7 |   0.9770 |     33.169 |   0.9932 |     33.364 |     1.2
    8 |   0.9304 |     31.864 |   0.9933 |     34.346 |     1.4
    9 |   0.9080 |     31.102 |   0.9515 |     32.781 |     1.6
   10 |   0.8706 |     29.583 |   0.9264 |     32.044 |     1.7
   11 |   0.8377 |     28.734 |   0.8936 |     29.558 |     1.9
   12 |   0.8112 |     27.922 |   0.9063 |     30.264 |     2.1
   13 |   0.7737 |     26.157 |   0.8742 |     29.681 |     2.2
   14 |   0.7522 |     25.548 |   0.8781 |     28.975 |     2.4
   15 |   0.7367 |     25.121 |   0.8647 |     29.006 |     2.6
   16 |   0.7047 |     23.986 |   0.8558 |     27.778 |     2.8
   17 |   0.6689 |     22.884 |   0.8709 |     28.852 |     2.9
   18 |   0.6521 |     22.259 |   0.8437 |     27.747 |     3.1
   19 |   0.6269 |     21.316 |   0.8188 |     26.212 |     3.3
   20 |   0.6046 |     20.795 |   0.8447 |     27.072 |     3.5
   21 |   0.5869 |     20.280 |   0.8412 |     25.967 |     3.6
   22 |   0.5703 |     19.693 |   0.8298 |     25.476 |     3.8
   23 |   0.5465 |     18.739 |   0.8447 |     25.599 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 437,090

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6483 |     47.511 |   1.2640 |     41.743 |     0.1
    2 |   1.1788 |     38.624 |   1.1550 |     38.336 |     0.3
    3 |   1.0659 |     35.548 |   1.0646 |     34.377 |     0.4
    4 |   0.9834 |     32.950 |   1.0175 |     33.026 |     0.5
    5 |   0.8989 |     29.984 |   0.9787 |     32.382 |     0.6
    6 |   0.8450 |     28.514 |   0.9443 |     31.461 |     0.8
    7 |   0.7936 |     26.798 |   0.9165 |     29.834 |     0.9
    8 |   0.7327 |     24.430 |   0.8756 |     29.036 |     1.0
    9 |   0.7022 |     23.651 |   0.8627 |     28.177 |     1.1
   10 |   0.6643 |     22.434 |   0.8898 |     28.300 |     1.3
   11 |   0.6200 |     20.916 |   0.8724 |     27.839 |     1.4
   12 |   0.5881 |     19.550 |   0.8218 |     25.783 |     1.5
   13 |   0.5491 |     18.695 |   0.8341 |     26.304 |     1.6
   14 |   0.5169 |     17.352 |   0.8439 |     25.721 |     1.8
   15 |   0.4975 |     16.820 |   0.8284 |     26.335 |     1.9
   16 |   0.4678 |     15.894 |   0.8105 |     24.708 |     2.0
   17 |   0.4337 |     14.693 |   0.8380 |     24.586 |     2.1
   18 |   0.4244 |     14.523 |   0.8467 |     24.985 |     2.3
   19 |   0.4058 |     13.717 |   0.8366 |     23.818 |     2.4
   20 |   0.3801 |     13.246 |   0.8714 |     24.494 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 485,922

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6705 |     47.719 |   1.2795 |     41.160 |     0.1
    2 |   1.2554 |     41.404 |   1.1655 |     39.288 |     0.2
    3 |   1.1401 |     38.207 |   1.1070 |     37.109 |     0.3
    4 |   1.0595 |     35.532 |   1.0717 |     35.513 |     0.4
    5 |   1.0067 |     33.876 |   1.0153 |     33.149 |     0.5
    6 |   0.9450 |     31.837 |   0.9831 |     31.921 |     0.6
    7 |   0.9071 |     30.258 |   0.9413 |     30.847 |     0.7
    8 |   0.8632 |     28.871 |   0.9276 |     31.645 |     0.8
    9 |   0.8263 |     27.911 |   0.8849 |     29.466 |     0.9
   10 |   0.7805 |     26.464 |   0.9089 |     30.141 |     1.0
   11 |   0.7576 |     25.444 |   0.8804 |     28.484 |     1.1
   12 |   0.7142 |     24.271 |   0.8865 |     28.238 |     1.2
   13 |   0.6878 |     23.372 |   0.8770 |     28.146 |     1.3
   14 |   0.6633 |     22.654 |   0.8390 |     26.734 |     1.4
   15 |   0.6282 |     21.118 |   0.8476 |     27.010 |     1.5
   16 |   0.5973 |     20.181 |   0.8506 |     27.010 |     1.6
   17 |   0.5753 |     19.200 |   0.8385 |     25.077 |     1.7
   18 |   0.5553 |     18.777 |   0.8568 |     26.611 |     1.7
   19 |   0.5272 |     17.933 |   0.8533 |     26.182 |     1.8
   20 |   0.5071 |     17.149 |   0.8401 |     25.629 |     1.9
   21 |   0.4918 |     16.760 |   0.8545 |     25.292 |     2.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0250 |     52.418 |   1.4462 |     43.892 |     0.2
    2 |   1.4211 |     42.982 |   1.2947 |     40.485 |     0.3
    3 |   1.2904 |     39.836 |   1.2174 |     38.674 |     0.5
    4 |   1.1991 |     37.500 |   1.1531 |     36.924 |     0.6
    5 |   1.1300 |     35.609 |   1.1014 |     35.114 |     0.8
    6 |   1.0633 |     33.618 |   1.0700 |     34.622 |     0.9
    7 |   1.0062 |     31.705 |   1.0185 |     33.303 |     1.1
    8 |   0.9525 |     29.611 |   1.0039 |     31.308 |     1.3
    9 |   0.8997 |     28.054 |   0.9737 |     31.031 |     1.4
   10 |   0.8511 |     26.760 |   0.9470 |     30.448 |     1.6
   11 |   0.8139 |     25.208 |   0.9432 |     29.619 |     1.7
   12 |   0.7745 |     24.545 |   0.9282 |     29.742 |     1.9
   13 |   0.7370 |     23.207 |   0.9183 |     29.036 |     2.0
   14 |   0.6988 |     21.749 |   0.9229 |     28.330 |     2.2
   15 |   0.6731 |     21.053 |   0.9015 |     27.624 |     2.4
   16 |   0.6360 |     19.901 |   0.9031 |     28.177 |     2.5
   17 |   0.6207 |     19.660 |   0.9056 |     27.747 |     2.7
   18 |   0.5908 |     18.635 |   0.8980 |     27.747 |     2.8
   19 |   0.5573 |     17.516 |   0.9083 |     26.918 |     3.0
   20 |   0.5337 |     16.656 |   0.9126 |     26.581 |     3.1
   21 |   0.5138 |     16.069 |   0.9153 |     26.304 |     3.3
   22 |   0.4970 |     15.707 |   0.9218 |     27.256 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,890

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3255 |     59.211 |   1.5246 |     45.365 |     0.2
    2 |   1.5133 |     44.518 |   1.3467 |     41.958 |     0.3
    3 |   1.3666 |     42.072 |   1.2564 |     39.288 |     0.5
    4 |   1.2718 |     39.380 |   1.1954 |     38.244 |     0.6
    5 |   1.1975 |     37.445 |   1.1533 |     37.201 |     0.8
    6 |   1.1387 |     35.762 |   1.1148 |     36.433 |     1.0
    7 |   1.0847 |     34.090 |   1.0774 |     34.039 |     1.1
    8 |   1.0355 |     32.604 |   1.0476 |     33.640 |     1.3
    9 |   0.9813 |     30.921 |   1.0220 |     32.228 |     1.5
   10 |   0.9469 |     29.764 |   0.9912 |     31.522 |     1.6
   11 |   0.9023 |     28.251 |   0.9705 |     30.816 |     1.8
   12 |   0.8604 |     27.045 |   0.9465 |     30.141 |     1.9
   13 |   0.8270 |     25.839 |   0.9457 |     29.834 |     2.1
   14 |   0.7906 |     24.901 |   0.9285 |     29.619 |     2.3
   15 |   0.7627 |     23.695 |   0.9208 |     28.607 |     2.4
   16 |   0.7324 |     23.065 |   0.9114 |     27.502 |     2.6
   17 |   0.6984 |     21.727 |   0.9047 |     27.624 |     2.8
   18 |   0.6779 |     21.354 |   0.8968 |     28.300 |     2.9
   19 |   0.6504 |     20.609 |   0.8979 |     27.072 |     3.1
   20 |   0.6313 |     19.770 |   0.8911 |     27.133 |     3.2
   21 |   0.6004 |     19.117 |   0.8976 |     25.998 |     3.4
   22 |   0.5792 |     18.185 |   0.9076 |     26.857 |     3.6
   23 |   0.5634 |     17.818 |   0.9047 |     27.103 |     3.7
   24 |   0.5437 |     17.418 |   0.8899 |     25.783 |     3.9
   25 |   0.5210 |     16.442 |   0.9273 |     26.151 |     4.1
   26 |   0.5076 |     16.009 |   0.9129 |     26.212 |     4.2
   27 |   0.4901 |     15.521 |   0.9152 |     25.752 |     4.4
   28 |   0.4751 |     15.225 |   0.9238 |     26.059 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2010 |     56.667 |   1.5036 |     43.677 |     0.1
    2 |   1.3649 |     41.420 |   1.2796 |     39.411 |     0.3
    3 |   1.2042 |     37.050 |   1.1846 |     37.416 |     0.4
    4 |   1.1073 |     34.359 |   1.1155 |     34.929 |     0.6
    5 |   1.0207 |     31.464 |   1.0672 |     33.364 |     0.7
    6 |   0.9538 |     29.479 |   1.0231 |     32.996 |     0.8
    7 |   0.8935 |     27.643 |   0.9859 |     31.308 |     1.0
    8 |   0.8369 |     25.899 |   0.9749 |     31.461 |     1.1
    9 |   0.7797 |     23.755 |   0.9381 |     29.282 |     1.3
   10 |   0.7299 |     22.242 |   0.9150 |     28.699 |     1.4
   11 |   0.6846 |     21.064 |   0.8914 |     27.870 |     1.6
   12 |   0.6422 |     19.666 |   0.8673 |     26.826 |     1.7
   13 |   0.6011 |     17.966 |   0.8781 |     27.348 |     1.8
   14 |   0.5687 |     17.166 |   0.8463 |     26.274 |     2.0
   15 |   0.5296 |     16.173 |   0.8548 |     26.581 |     2.1
   16 |   0.5040 |     15.450 |   0.8355 |     25.384 |     2.3
   17 |   0.4718 |     14.117 |   0.8596 |     25.629 |     2.4
   18 |   0.4509 |     13.706 |   0.8674 |     25.936 |     2.6
   19 |   0.4198 |     12.736 |   0.8629 |     25.107 |     2.7
   20 |   0.3916 |     11.826 |   0.8405 |     24.555 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 552,674

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5370 |     59.989 |   1.7683 |     46.071 |     0.1
    2 |   1.7084 |     45.285 |   1.5179 |     44.444 |     0.2
    3 |   1.5281 |     44.013 |   1.4192 |     42.910 |     0.3
    4 |   1.4252 |     42.341 |   1.3424 |     41.283 |     0.4
    5 |   1.3505 |     40.729 |   1.2823 |     39.533 |     0.5
    6 |   1.2796 |     38.860 |   1.2332 |     37.876 |     0.6
    7 |   1.2326 |     37.747 |   1.1942 |     36.525 |     0.7
    8 |   1.1848 |     36.118 |   1.1630 |     36.004 |     0.8
    9 |   1.1428 |     35.274 |   1.1491 |     36.034 |     1.0
   10 |   1.1007 |     33.799 |   1.1131 |     34.285 |     1.1
   11 |   1.0649 |     32.950 |   1.0873 |     33.732 |     1.2
   12 |   1.0241 |     31.634 |   1.0649 |     33.149 |     1.3
   13 |   0.9921 |     30.740 |   1.0488 |     32.474 |     1.4
   14 |   0.9574 |     29.627 |   1.0306 |     32.259 |     1.5
   15 |   0.9300 |     29.145 |   1.0168 |     31.492 |     1.6
   16 |   0.9009 |     28.180 |   1.0001 |     31.369 |     1.7
   17 |   0.8757 |     27.259 |   0.9891 |     31.584 |     1.8
   18 |   0.8507 |     26.338 |   0.9816 |     30.417 |     1.9
   19 |   0.8272 |     25.899 |   0.9834 |     30.602 |     2.0
   20 |   0.8046 |     24.907 |   0.9649 |     29.466 |     2.1
   21 |   0.7822 |     24.194 |   0.9586 |     29.711 |     2.2
   22 |   0.7651 |     23.887 |   0.9616 |     29.405 |     2.3
   23 |   0.7407 |     23.087 |   0.9518 |     28.821 |     2.4
   24 |   0.7178 |     22.560 |   0.9529 |     29.190 |     2.6
   25 |   0.6950 |     21.502 |   0.9417 |     28.545 |     2.7
   26 |   0.6790 |     21.113 |   0.9690 |     29.466 |     2.8
   27 |   0.6600 |     20.400 |   0.9371 |     28.269 |     2.9
   28 |   0.6494 |     20.197 |   0.9435 |     28.115 |     3.0
   29 |   0.6308 |     19.638 |   0.9615 |     28.729 |     3.1
   30 |   0.6105 |     18.909 |   0.9538 |     27.901 |     3.2
   31 |   0.5991 |     18.958 |   0.9625 |     28.514 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 47 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,076,002

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 295])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3007 |     58.092 |   1.5479 |     45.611 |     0.1
    2 |   1.5106 |     44.167 |   1.3458 |     41.805 |     0.2
    3 |   1.3581 |     41.447 |   1.2649 |     40.209 |     0.4
    4 |   1.2652 |     39.353 |   1.1942 |     38.428 |     0.5
    5 |   1.1926 |     37.188 |   1.1518 |     36.771 |     0.6
    6 |   1.1311 |     35.203 |   1.1167 |     35.973 |     0.7
    7 |   1.0831 |     34.041 |   1.0870 |     34.929 |     0.9
    8 |   1.0375 |     32.429 |   1.0585 |     33.487 |     1.0
    9 |   0.9926 |     31.135 |   1.0407 |     33.794 |     1.1
   10 |   0.9507 |     29.857 |   1.0174 |     32.382 |     1.2
   11 |   0.9115 |     28.591 |   1.0065 |     33.026 |     1.3
   12 |   0.8754 |     27.489 |   0.9914 |     31.799 |     1.5
   13 |   0.8416 |     26.354 |   0.9673 |     30.939 |     1.6
   14 |   0.8067 |     25.241 |   0.9640 |     31.154 |     1.7
   15 |   0.7809 |     24.479 |   0.9479 |     30.203 |     1.8
   16 |   0.7475 |     23.470 |   0.9530 |     29.681 |     2.0
   17 |   0.7195 |     22.434 |   0.9551 |     29.067 |     2.1
   18 |   0.6961 |     21.919 |   0.9395 |     28.760 |     2.2
   19 |   0.6679 |     21.234 |   0.9404 |     29.159 |     2.3
   20 |   0.6518 |     20.285 |   0.9352 |     29.159 |     2.5
   21 |   0.6286 |     19.896 |   0.9320 |     28.023 |     2.6
   22 |   0.6020 |     18.777 |   0.9483 |     28.146 |     2.7
   23 |   0.5872 |     18.591 |   0.9329 |     27.041 |     2.8
   24 |   0.5660 |     17.714 |   0.9383 |     27.379 |     2.9
   25 |   0.5446 |     17.078 |   0.9356 |     27.041 |     3.1
Early stopping

