Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,602

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1137 |     54.358 |   1.4626 |     42.950 |     0.2
    2 |   1.4271 |     42.718 |   1.2903 |     40.012 |     0.4
    3 |   1.2916 |     39.854 |   1.2136 |     38.219 |     0.6
    4 |   1.1974 |     37.538 |   1.1384 |     36.024 |     0.8
    5 |   1.1186 |     34.932 |   1.0873 |     35.003 |     1.0
    6 |   1.0568 |     33.355 |   1.0404 |     33.426 |     1.1
    7 |   0.9968 |     31.581 |   1.0032 |     31.818 |     1.3
    8 |   0.9463 |     29.544 |   0.9718 |     31.385 |     1.5
    9 |   0.9040 |     27.907 |   0.9606 |     31.540 |     1.7
   10 |   0.8592 |     26.615 |   0.9384 |     30.303 |     1.9
   11 |   0.8173 |     25.624 |   0.9139 |     29.623 |     2.1
   12 |   0.7713 |     24.140 |   0.9077 |     29.963 |     2.3
   13 |   0.7396 |     23.078 |   0.8810 |     28.541 |     2.5
   14 |   0.7101 |     22.082 |   0.8986 |     27.798 |     2.7
   15 |   0.6677 |     21.140 |   0.8751 |     28.355 |     2.9
   16 |   0.6425 |     19.760 |   0.8743 |     27.211 |     3.1
   17 |   0.6123 |     19.027 |   0.8712 |     26.840 |     3.3
   18 |   0.5935 |     18.512 |   0.8694 |     27.087 |     3.5
   19 |   0.5636 |     17.537 |   0.8559 |     26.221 |     3.7
   20 |   0.5463 |     16.634 |   0.8630 |     25.665 |     3.9
   21 |   0.5220 |     16.585 |   0.8577 |     26.160 |     4.1
   22 |   0.4969 |     15.418 |   0.8513 |     26.190 |     4.3
   23 |   0.4711 |     14.789 |   0.8571 |     24.985 |     4.4
   24 |   0.4542 |     14.203 |   0.8689 |     25.015 |     4.6
   25 |   0.4415 |     13.929 |   0.8765 |     25.015 |     4.8
   26 |   0.4209 |     12.889 |   0.8620 |     24.119 |     5.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 436,962

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5392 |     63.721 |   1.8817 |     44.682 |     0.1
    2 |   1.6409 |     43.517 |   1.5230 |     42.053 |     0.2
    3 |   1.4322 |     40.802 |   1.3934 |     40.414 |     0.4
    4 |   1.3259 |     39.192 |   1.3031 |     38.528 |     0.5
    5 |   1.2405 |     37.407 |   1.2371 |     36.797 |     0.6
    6 |   1.1766 |     35.595 |   1.1943 |     36.364 |     0.8
    7 |   1.1246 |     34.242 |   1.1429 |     34.508 |     0.9
    8 |   1.0693 |     32.698 |   1.1141 |     35.003 |     1.0
    9 |   1.0220 |     31.094 |   1.0904 |     33.921 |     1.1
   10 |   0.9810 |     30.076 |   1.0499 |     33.055 |     1.3
   11 |   0.9355 |     28.499 |   1.0238 |     32.004 |     1.4
   12 |   0.8949 |     27.272 |   1.0168 |     31.571 |     1.5
   13 |   0.8648 |     26.232 |   0.9714 |     30.767 |     1.6
   14 |   0.8245 |     25.066 |   0.9665 |     30.489 |     1.8
   15 |   0.7877 |     23.949 |   0.9476 |     30.025 |     1.9
   16 |   0.7583 |     23.051 |   0.9268 |     29.994 |     2.0
   17 |   0.7252 |     21.934 |   0.9072 |     28.633 |     2.1
   18 |   0.7022 |     21.381 |   0.9002 |     28.942 |     2.3
   19 |   0.6720 |     20.401 |   0.9073 |     28.293 |     2.4
   20 |   0.6540 |     19.985 |   0.8838 |     27.798 |     2.5
   21 |   0.6345 |     19.251 |   0.8770 |     28.046 |     2.7
   22 |   0.6077 |     18.457 |   0.8697 |     27.149 |     2.8
   23 |   0.5814 |     17.707 |   0.8521 |     26.902 |     2.9
   24 |   0.5537 |     16.705 |   0.8537 |     26.036 |     3.0
   25 |   0.5380 |     16.021 |   0.8497 |     26.685 |     3.2
   26 |   0.5201 |     15.692 |   0.8671 |     26.190 |     3.3
   27 |   0.4965 |     14.975 |   0.8866 |     26.902 |     3.4
   28 |   0.4838 |     14.504 |   0.8521 |     25.541 |     3.5
   29 |   0.4645 |     13.978 |   0.8495 |     26.252 |     3.7
   30 |   0.4556 |     13.716 |   0.8584 |     25.634 |     3.8
   31 |   0.4370 |     12.867 |   0.8384 |     25.294 |     3.9
   32 |   0.4270 |     12.796 |   0.8367 |     24.552 |     4.0
   33 |   0.4102 |     12.177 |   0.8696 |     25.696 |     4.2
   34 |   0.3936 |     11.624 |   0.8565 |     25.603 |     4.3
   35 |   0.3844 |     11.323 |   0.8624 |     24.892 |     4.4
   36 |   0.3736 |     11.350 |   0.8740 |     24.830 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,434

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6517 |     68.172 |   1.8885 |     48.237 |     0.2
    2 |   1.7983 |     46.277 |   1.5499 |     45.083 |     0.3
    3 |   1.5638 |     44.738 |   1.4451 |     43.352 |     0.5
    4 |   1.4618 |     43.282 |   1.3734 |     41.806 |     0.7
    5 |   1.3856 |     41.754 |   1.3194 |     40.940 |     0.8
    6 |   1.3270 |     40.150 |   1.2778 |     40.383 |     1.0
    7 |   1.2727 |     39.274 |   1.2289 |     38.930 |     1.2
    8 |   1.2235 |     37.949 |   1.1958 |     37.508 |     1.3
    9 |   1.1855 |     36.750 |   1.1698 |     36.889 |     1.5
   10 |   1.1493 |     35.792 |   1.1363 |     36.116 |     1.7
   11 |   1.1123 |     34.368 |   1.1212 |     35.312 |     1.8
   12 |   1.0782 |     33.328 |   1.0979 |     34.477 |     2.0
   13 |   1.0469 |     32.424 |   1.0792 |     34.230 |     2.2
   14 |   1.0212 |     31.800 |   1.0554 |     33.271 |     2.3
   15 |   0.9965 |     31.061 |   1.0375 |     32.962 |     2.5
   16 |   0.9652 |     30.021 |   1.0353 |     33.550 |     2.7
   17 |   0.9415 |     29.238 |   1.0149 |     32.344 |     2.9
   18 |   0.9146 |     28.389 |   0.9920 |     31.478 |     3.0
   19 |   0.8980 |     28.028 |   0.9796 |     31.354 |     3.2
   20 |   0.8750 |     26.993 |   0.9800 |     31.014 |     3.4
   21 |   0.8490 |     26.445 |   0.9661 |     30.581 |     3.5
   22 |   0.8304 |     25.734 |   0.9548 |     30.025 |     3.7
   23 |   0.8135 |     25.334 |   0.9515 |     29.654 |     3.9
   24 |   0.7861 |     24.228 |   0.9446 |     29.654 |     4.0
   25 |   0.7710 |     23.971 |   0.9563 |     29.375 |     4.2
   26 |   0.7476 |     23.226 |   0.9332 |     28.448 |     4.4
   27 |   0.7297 |     22.783 |   0.9363 |     28.695 |     4.5
   28 |   0.7289 |     22.465 |   0.9217 |     28.108 |     4.7
   29 |   0.6994 |     21.775 |   0.9220 |     28.695 |     4.9
   30 |   0.6905 |     21.178 |   0.9197 |     28.355 |     5.0
   31 |   0.6840 |     21.403 |   0.9235 |     28.417 |     5.2
   32 |   0.6619 |     20.466 |   0.9268 |     28.324 |     5.4
   33 |   0.6462 |     20.083 |   0.9196 |     28.046 |     5.5
   34 |   0.6335 |     19.892 |   0.9360 |     28.015 |     5.7
   35 |   0.6195 |     19.141 |   0.9257 |     27.706 |     5.9
   36 |   0.6150 |     19.295 |   0.9155 |     27.242 |     6.0
   37 |   0.5981 |     18.561 |   0.9405 |     27.675 |     6.2
   38 |   0.5870 |     18.413 |   0.9302 |     27.242 |     6.4
   39 |   0.5711 |     17.729 |   0.9288 |     27.767 |     6.6
   40 |   0.5642 |     17.740 |   0.9454 |     28.139 |     6.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,330

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5407 |     47.153 |   1.2324 |     40.569 |     0.2
    2 |   1.2245 |     41.125 |   1.1577 |     39.116 |     0.4
    3 |   1.1418 |     38.869 |   1.0893 |     37.322 |     0.6
    4 |   1.0857 |     36.996 |   1.0304 |     34.756 |     0.7
    5 |   1.0353 |     35.425 |   1.0303 |     35.189 |     0.9
    6 |   1.0141 |     34.910 |   1.0238 |     34.756 |     1.1
    7 |   0.9662 |     32.934 |   0.9756 |     33.302 |     1.3
    8 |   0.9356 |     32.194 |   0.9505 |     33.024 |     1.5
    9 |   0.9227 |     31.570 |   0.9465 |     32.282 |     1.7
   10 |   0.8817 |     30.180 |   0.9141 |     31.818 |     1.9
   11 |   0.8480 |     29.139 |   0.9138 |     31.416 |     2.1
   12 |   0.8315 |     28.559 |   0.9065 |     31.602 |     2.2
   13 |   0.8189 |     27.913 |   0.8741 |     29.283 |     2.4
   14 |   0.7837 |     26.938 |   0.8691 |     28.912 |     2.6
   15 |   0.7661 |     26.161 |   0.9075 |     30.396 |     2.8
   16 |   0.7398 |     25.504 |   0.8637 |     28.757 |     3.0
   17 |   0.7185 |     24.704 |   0.8806 |     30.303 |     3.2
   18 |   0.7161 |     24.436 |   0.9085 |     30.891 |     3.4
   19 |   0.6988 |     24.025 |   0.8392 |     28.850 |     3.6
   20 |   0.6673 |     23.018 |   0.8701 |     29.561 |     3.7
   21 |   0.6503 |     22.739 |   0.8573 |     28.633 |     3.9
   22 |   0.6380 |     21.808 |   0.8626 |     28.664 |     4.1
   23 |   0.6216 |     21.381 |   0.8469 |     29.097 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 552,546

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7102 |     48.779 |   1.3288 |     43.630 |     0.1
    2 |   1.2917 |     42.280 |   1.2123 |     40.167 |     0.3
    3 |   1.1829 |     39.104 |   1.1460 |     37.848 |     0.4
    4 |   1.0965 |     36.520 |   1.0975 |     36.302 |     0.6
    5 |   1.0456 |     34.916 |   1.0283 |     34.972 |     0.7
    6 |   0.9969 |     33.415 |   0.9865 |     33.395 |     0.9
    7 |   0.9435 |     31.609 |   0.9416 |     32.004 |     1.0
    8 |   0.9098 |     30.333 |   0.9269 |     31.602 |     1.2
    9 |   0.8578 |     28.860 |   0.8820 |     29.190 |     1.3
   10 |   0.8202 |     27.672 |   0.8831 |     30.087 |     1.5
   11 |   0.7988 |     26.840 |   0.8446 |     28.541 |     1.6
   12 |   0.7622 |     25.307 |   0.8335 |     28.046 |     1.7
   13 |   0.7515 |     25.487 |   0.8147 |     27.087 |     1.9
   14 |   0.7046 |     23.856 |   0.8095 |     27.211 |     2.0
   15 |   0.6732 |     22.881 |   0.8070 |     25.479 |     2.2
   16 |   0.6568 |     22.531 |   0.7930 |     25.572 |     2.3
   17 |   0.6199 |     20.937 |   0.7672 |     25.015 |     2.5
   18 |   0.5935 |     20.056 |   0.7985 |     26.098 |     2.6
   19 |   0.5922 |     20.143 |   0.7827 |     25.170 |     2.8
   20 |   0.5422 |     18.359 |   0.7635 |     25.015 |     2.9
   21 |   0.5403 |     18.041 |   0.7861 |     24.026 |     3.1
   22 |   0.5090 |     17.050 |   0.7421 |     23.377 |     3.2
   23 |   0.4865 |     16.240 |   0.7840 |     24.181 |     3.3
   24 |   0.4773 |     16.240 |   0.7524 |     23.160 |     3.5
   25 |   0.4472 |     15.413 |   0.7816 |     23.748 |     3.6
   26 |   0.4303 |     14.860 |   0.7769 |     22.542 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 535,778

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6566 |     47.657 |   1.2986 |     42.270 |     0.1
    2 |   1.2591 |     41.459 |   1.1666 |     38.776 |     0.2
    3 |   1.1613 |     39.093 |   1.1232 |     38.899 |     0.4
    4 |   1.1008 |     37.380 |   1.0651 |     36.580 |     0.5
    5 |   1.0446 |     35.195 |   1.0466 |     35.993 |     0.6
    6 |   1.0112 |     34.363 |   0.9993 |     33.766 |     0.7
    7 |   0.9659 |     33.049 |   0.9570 |     33.024 |     0.8
    8 |   0.9384 |     31.828 |   0.9589 |     33.024 |     1.0
    9 |   0.8941 |     30.546 |   0.9089 |     31.509 |     1.1
   10 |   0.8587 |     29.457 |   0.8784 |     30.210 |     1.2
   11 |   0.8243 |     27.973 |   0.8453 |     28.819 |     1.3
   12 |   0.8035 |     27.453 |   0.8634 |     29.004 |     1.4
   13 |   0.7718 |     26.298 |   0.8567 |     28.293 |     1.6
   14 |   0.7398 |     25.110 |   0.8237 |     27.798 |     1.7
   15 |   0.7260 |     24.699 |   0.8501 |     28.231 |     1.8
   16 |   0.7105 |     24.151 |   0.8357 |     28.077 |     1.9
   17 |   0.6816 |     23.084 |   0.8116 |     27.767 |     2.0
   18 |   0.6601 |     22.553 |   0.7875 |     25.170 |     2.2
   19 |   0.6207 |     20.822 |   0.7729 |     25.417 |     2.3
   20 |   0.6002 |     20.510 |   0.8044 |     25.510 |     2.4
   21 |   0.5759 |     19.530 |   0.7857 |     24.985 |     2.5
   22 |   0.5689 |     18.895 |   0.7921 |     25.541 |     2.7
   23 |   0.5519 |     18.753 |   0.7666 |     25.479 |     2.8
   24 |   0.5219 |     17.740 |   0.7877 |     24.304 |     2.9
   25 |   0.5066 |     17.127 |   0.7768 |     24.428 |     3.0
   26 |   0.4920 |     16.776 |   0.7805 |     24.490 |     3.1
   27 |   0.4612 |     15.599 |   0.7987 |     23.377 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 470,434

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7861 |     50.449 |   1.3579 |     43.414 |     0.1
    2 |   1.2969 |     42.526 |   1.2215 |     40.816 |     0.2
    3 |   1.1975 |     39.641 |   1.1271 |     38.126 |     0.4
    4 |   1.1198 |     37.352 |   1.0930 |     36.858 |     0.5
    5 |   1.0677 |     35.677 |   1.0501 |     35.003 |     0.6
    6 |   1.0267 |     34.352 |   0.9943 |     33.488 |     0.7
    7 |   0.9731 |     32.572 |   0.9729 |     32.653 |     0.9
    8 |   0.9548 |     31.707 |   0.9383 |     31.756 |     1.0
    9 |   0.9083 |     30.333 |   0.9441 |     32.529 |     1.1
   10 |   0.8871 |     29.906 |   0.9228 |     31.787 |     1.2
   11 |   0.8499 |     28.274 |   0.9021 |     30.983 |     1.4
   12 |   0.8256 |     27.781 |   0.8698 |     29.839 |     1.5
   13 |   0.7992 |     26.889 |   0.8628 |     29.561 |     1.6
   14 |   0.7561 |     25.252 |   0.8684 |     29.654 |     1.7
   15 |   0.7357 |     25.016 |   0.8474 |     28.479 |     1.9
   16 |   0.7074 |     23.998 |   0.8031 |     27.860 |     2.0
   17 |   0.6900 |     23.336 |   0.8120 |     27.644 |     2.1
   18 |   0.6705 |     23.095 |   0.8164 |     27.706 |     2.2
   19 |   0.6375 |     21.896 |   0.7835 |     26.283 |     2.4
   20 |   0.6280 |     21.102 |   0.7724 |     25.634 |     2.5
   21 |   0.6038 |     20.428 |   0.7837 |     25.572 |     2.6
   22 |   0.5796 |     19.738 |   0.7860 |     25.788 |     2.7
   23 |   0.5676 |     19.059 |   0.7612 |     23.995 |     2.9
   24 |   0.5388 |     18.233 |   0.8080 |     25.788 |     3.0
   25 |   0.5351 |     18.583 |   0.7751 |     23.995 |     3.1
   26 |   0.5186 |     17.893 |   0.7814 |     24.768 |     3.2
   27 |   0.4861 |     16.557 |   0.7594 |     24.212 |     3.4
   28 |   0.4783 |     16.541 |   0.7826 |     23.593 |     3.5
   29 |   0.4748 |     16.459 |   0.7611 |     23.717 |     3.6
   30 |   0.4390 |     15.106 |   0.7918 |     23.593 |     3.7
   31 |   0.4329 |     15.199 |   0.7672 |     23.222 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,122

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4815 |     45.412 |   1.2791 |     42.610 |     0.1
    2 |   1.2099 |     40.566 |   1.1430 |     37.044 |     0.3
    3 |   1.1125 |     37.374 |   1.0663 |     36.240 |     0.5
    4 |   1.0447 |     35.173 |   1.0353 |     34.477 |     0.6
    5 |   0.9945 |     33.832 |   0.9585 |     32.344 |     0.8
    6 |   0.9507 |     31.943 |   0.9527 |     32.684 |     0.9
    7 |   0.9213 |     31.368 |   0.9244 |     31.014 |     1.1
    8 |   0.8774 |     29.829 |   0.9120 |     30.829 |     1.2
    9 |   0.8466 |     28.783 |   0.8882 |     30.550 |     1.4
   10 |   0.8224 |     28.159 |   0.8621 |     28.602 |     1.6
   11 |   0.7798 |     26.287 |   0.8424 |     28.510 |     1.7
   12 |   0.7669 |     26.429 |   0.8199 |     28.324 |     1.9
   13 |   0.7221 |     24.907 |   0.8094 |     26.840 |     2.0
   14 |   0.6996 |     24.014 |   0.7878 |     26.036 |     2.2
   15 |   0.6686 |     22.804 |   0.7714 |     24.923 |     2.3
   16 |   0.6573 |     22.492 |   0.7784 |     25.758 |     2.5
   17 |   0.6078 |     20.883 |   0.7725 |     25.479 |     2.7
   18 |   0.6066 |     20.554 |   0.7793 |     25.387 |     2.8
   19 |   0.5830 |     19.859 |   0.7464 |     23.562 |     3.0
   20 |   0.5678 |     19.536 |   0.7676 |     24.428 |     3.1
   21 |   0.5294 |     18.101 |   0.7403 |     23.995 |     3.3
   22 |   0.5072 |     17.357 |   0.7585 |     24.552 |     3.4
   23 |   0.5116 |     17.745 |   0.7625 |     23.840 |     3.6
   24 |   0.5099 |     17.499 |   0.7564 |     23.840 |     3.7
   25 |   0.5045 |     17.762 |   0.7433 |     22.913 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,746

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2086 |     56.855 |   1.5016 |     43.043 |     0.1
    2 |   1.3722 |     41.814 |   1.3063 |     40.260 |     0.2
    3 |   1.2311 |     38.223 |   1.2279 |     38.559 |     0.3
    4 |   1.1355 |     35.436 |   1.1426 |     35.405 |     0.5
    5 |   1.0611 |     32.852 |   1.0847 |     34.261 |     0.6
    6 |   0.9817 |     30.431 |   1.0481 |     33.457 |     0.7
    7 |   0.9163 |     28.433 |   1.0057 |     32.066 |     0.8
    8 |   0.8577 |     26.226 |   0.9609 |     30.056 |     0.9
    9 |   0.8103 |     25.005 |   0.9225 |     29.406 |     1.0
   10 |   0.7599 |     23.259 |   0.9021 |     28.881 |     1.1
   11 |   0.7110 |     21.928 |   0.8926 |     28.293 |     1.3
   12 |   0.6670 |     20.560 |   0.8751 |     27.335 |     1.4
   13 |   0.6280 |     19.355 |   0.8588 |     26.994 |     1.5
   14 |   0.5907 |     17.899 |   0.8485 |     26.654 |     1.6
   15 |   0.5586 |     17.203 |   0.8388 |     25.603 |     1.7
   16 |   0.5219 |     15.928 |   0.8421 |     26.190 |     1.8
   17 |   0.5003 |     14.838 |   0.8210 |     25.479 |     1.9
   18 |   0.4623 |     13.869 |   0.8426 |     25.232 |     2.1
   19 |   0.4418 |     13.403 |   0.8128 |     25.479 |     2.2
   20 |   0.4150 |     12.358 |   0.8153 |     24.366 |     2.3
   21 |   0.3949 |     12.100 |   0.8036 |     23.222 |     2.4
   22 |   0.3680 |     10.978 |   0.8153 |     24.644 |     2.5
   23 |   0.3453 |     10.414 |   0.8038 |     23.500 |     2.6
   24 |   0.3282 |      9.949 |   0.8173 |     23.933 |     2.8
   25 |   0.3117 |      9.483 |   0.7994 |     22.325 |     2.9
   26 |   0.2955 |      9.111 |   0.8151 |     23.253 |     3.0
   27 |   0.2732 |      8.098 |   0.8574 |     23.871 |     3.1
   28 |   0.2755 |      8.377 |   0.8110 |     22.480 |     3.2
   29 |   0.2582 |      7.693 |   0.8594 |     23.933 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 535,778

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5377 |     61.317 |   1.8166 |     45.980 |     0.2
    2 |   1.7406 |     45.795 |   1.5387 |     43.847 |     0.3
    3 |   1.5373 |     43.665 |   1.4238 |     42.146 |     0.5
    4 |   1.4253 |     41.661 |   1.3424 |     40.012 |     0.7
    5 |   1.3458 |     39.898 |   1.2773 |     38.497 |     0.8
    6 |   1.2809 |     38.436 |   1.2253 |     37.755 |     1.0
    7 |   1.2228 |     37.232 |   1.1931 |     36.827 |     1.2
    8 |   1.1707 |     35.715 |   1.1539 |     36.487 |     1.3
    9 |   1.1258 |     34.565 |   1.1254 |     35.962 |     1.5
   10 |   1.0953 |     33.881 |   1.1051 |     34.972 |     1.6
   11 |   1.0552 |     32.501 |   1.0775 |     34.106 |     1.8
   12 |   1.0197 |     31.477 |   1.0532 |     33.673 |     2.0
   13 |   0.9866 |     30.273 |   1.0218 |     32.993 |     2.1
   14 |   0.9535 |     29.282 |   1.0122 |     32.066 |     2.3
   15 |   0.9257 |     28.685 |   1.0032 |     31.385 |     2.5
   16 |   0.8965 |     27.212 |   0.9744 |     30.921 |     2.7
   17 |   0.8736 |     26.955 |   0.9706 |     31.478 |     2.8
   18 |   0.8386 |     25.794 |   0.9564 |     30.458 |     3.0
   19 |   0.8143 |     25.027 |   0.9493 |     29.963 |     3.2
   20 |   0.7966 |     24.403 |   0.9430 |     30.643 |     3.3
   21 |   0.7754 |     23.839 |   0.9276 |     28.881 |     3.5
   22 |   0.7462 |     23.084 |   0.9270 |     28.819 |     3.7
   23 |   0.7199 |     22.147 |   0.9267 |     29.190 |     3.8
   24 |   0.7023 |     21.545 |   0.9230 |     28.417 |     4.0
   25 |   0.6882 |     21.206 |   0.9448 |     29.314 |     4.2
   26 |   0.6706 |     20.341 |   0.9338 |     28.664 |     4.3
   27 |   0.6527 |     20.231 |   0.9167 |     28.231 |     4.5
   28 |   0.6292 |     19.749 |   0.9201 |     28.324 |     4.7
   29 |   0.6124 |     19.021 |   0.9284 |     27.798 |     4.8
   30 |   0.6021 |     18.643 |   0.9183 |     27.953 |     5.0
   31 |   0.5883 |     18.265 |   0.9124 |     27.427 |     5.2
   32 |   0.5752 |     18.085 |   0.9279 |     27.551 |     5.3
   33 |   0.5579 |     17.395 |   0.9323 |     28.046 |     5.5
   34 |   0.5467 |     16.891 |   0.9336 |     26.685 |     5.7
   35 |   0.5322 |     16.349 |   0.9464 |     27.211 |     5.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,602

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1344 |     53.460 |   1.4890 |     43.847 |     0.2
    2 |   1.4518 |     43.238 |   1.3124 |     40.631 |     0.4
    3 |   1.3076 |     40.205 |   1.2286 |     39.239 |     0.6
    4 |   1.2217 |     37.878 |   1.1629 |     36.395 |     0.8
    5 |   1.1439 |     35.846 |   1.1085 |     34.972 |     1.0
    6 |   1.0773 |     33.580 |   1.0487 |     34.106 |     1.2
    7 |   1.0205 |     31.614 |   1.0287 |     33.271 |     1.4
    8 |   0.9629 |     30.229 |   0.9832 |     31.818 |     1.6
    9 |   0.9192 |     29.106 |   0.9651 |     30.674 |     1.7
   10 |   0.8667 |     27.097 |   0.9276 |     29.994 |     1.9
   11 |   0.8329 |     25.964 |   0.9196 |     28.819 |     2.1
   12 |   0.7880 |     24.589 |   0.9112 |     29.159 |     2.3
   13 |   0.7489 |     23.538 |   0.8990 |     28.231 |     2.5
   14 |   0.7118 |     22.153 |   0.8848 |     27.706 |     2.7
   15 |   0.6840 |     20.998 |   0.8713 |     27.211 |     2.9
   16 |   0.6550 |     20.549 |   0.8790 |     27.180 |     3.1
   17 |   0.6227 |     19.547 |   0.8648 |     26.592 |     3.3
   18 |   0.5971 |     18.605 |   0.8727 |     26.654 |     3.5
   19 |   0.5726 |     17.767 |   0.8696 |     25.974 |     3.7
   20 |   0.5500 |     16.902 |   0.8631 |     25.417 |     3.9
   21 |   0.5140 |     15.906 |   0.8791 |     25.788 |     4.1
   22 |   0.4950 |     15.517 |   0.8625 |     24.768 |     4.3
   23 |   0.4839 |     15.243 |   0.8932 |     25.603 |     4.5
   24 |   0.4671 |     14.712 |   0.8795 |     25.170 |     4.7
   25 |   0.4368 |     13.666 |   0.8754 |     24.521 |     4.9
   26 |   0.4174 |     13.146 |   0.9003 |     25.325 |     5.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,386

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0773 |     53.734 |   1.4466 |     43.445 |     0.2
    2 |   1.4267 |     42.964 |   1.2873 |     39.394 |     0.3
    3 |   1.2951 |     39.515 |   1.2070 |     37.786 |     0.5
    4 |   1.2045 |     37.571 |   1.1466 |     36.147 |     0.7
    5 |   1.1308 |     35.359 |   1.0981 |     35.189 |     0.8
    6 |   1.0732 |     33.377 |   1.0511 |     33.364 |     1.0
    7 |   1.0101 |     31.368 |   1.0183 |     32.344 |     1.1
    8 |   0.9648 |     30.393 |   0.9779 |     31.138 |     1.3
    9 |   0.9101 |     28.559 |   0.9555 |     31.169 |     1.5
   10 |   0.8652 |     26.982 |   0.9358 |     30.118 |     1.6
   11 |   0.8275 |     25.996 |   0.9179 |     29.839 |     1.8
   12 |   0.7829 |     24.337 |   0.9050 |     28.139 |     2.0
   13 |   0.7496 |     23.401 |   0.8908 |     28.169 |     2.1
   14 |   0.7163 |     22.235 |   0.8785 |     27.675 |     2.3
   15 |   0.6895 |     21.551 |   0.8758 |     27.304 |     2.5
   16 |   0.6478 |     20.647 |   0.8471 |     26.469 |     2.6
   17 |   0.6158 |     19.169 |   0.8489 |     26.221 |     2.8
   18 |   0.5890 |     18.528 |   0.8435 |     26.036 |     3.0
   19 |   0.5664 |     17.680 |   0.8469 |     25.974 |     3.1
   20 |   0.5439 |     17.044 |   0.8432 |     25.015 |     3.3
   21 |   0.5266 |     16.426 |   0.8312 |     25.077 |     3.4
   22 |   0.5016 |     15.966 |   0.8465 |     25.758 |     3.6
   23 |   0.4947 |     15.626 |   0.8430 |     24.273 |     3.8
   24 |   0.4587 |     14.597 |   0.8395 |     23.562 |     3.9
   25 |   0.4433 |     13.902 |   0.8350 |     23.748 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,075,746

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2488 |     56.800 |   1.5195 |     44.249 |     0.1
    2 |   1.4862 |     43.901 |   1.3374 |     41.837 |     0.2
    3 |   1.3398 |     41.420 |   1.2378 |     38.714 |     0.4
    4 |   1.2541 |     38.967 |   1.1734 |     36.982 |     0.5
    5 |   1.1791 |     36.914 |   1.1216 |     35.622 |     0.6
    6 |   1.1189 |     35.124 |   1.0863 |     34.725 |     0.7
    7 |   1.0645 |     33.246 |   1.0445 |     33.488 |     0.8
    8 |   1.0252 |     31.910 |   1.0094 |     32.344 |     1.0
    9 |   0.9802 |     30.924 |   1.0029 |     31.818 |     1.1
   10 |   0.9453 |     29.703 |   0.9647 |     31.509 |     1.2
   11 |   0.9071 |     28.444 |   0.9543 |     30.798 |     1.3
   12 |   0.8705 |     27.551 |   0.9184 |     30.118 |     1.5
   13 |   0.8357 |     26.588 |   0.9125 |     29.066 |     1.6
   14 |   0.8089 |     25.422 |   0.8975 |     28.231 |     1.7
   15 |   0.7775 |     24.463 |   0.8883 |     28.231 |     1.8
   16 |   0.7569 |     23.850 |   0.9027 |     29.283 |     2.0
   17 |   0.7234 |     22.881 |   0.8602 |     27.396 |     2.1
   18 |   0.7020 |     22.016 |   0.8519 |     27.242 |     2.2
   19 |   0.6763 |     21.019 |   0.8457 |     26.809 |     2.3
   20 |   0.6501 |     20.746 |   0.8554 |     26.221 |     2.4
   21 |   0.6341 |     19.974 |   0.8430 |     25.974 |     2.6
   22 |   0.6129 |     19.629 |   0.8405 |     25.850 |     2.7
   23 |   0.5921 |     18.786 |   0.8545 |     26.036 |     2.8
   24 |   0.5714 |     17.986 |   0.8419 |     25.294 |     2.9
   25 |   0.5566 |     17.504 |   0.8303 |     25.603 |     3.1
   26 |   0.5437 |     17.061 |   0.8322 |     25.232 |     3.2
   27 |   0.5250 |     16.431 |   0.8300 |     24.830 |     3.3
   28 |   0.5087 |     16.190 |   0.8387 |     25.139 |     3.4
   29 |   0.4891 |     15.550 |   0.8382 |     24.737 |     3.5
   30 |   0.4748 |     15.391 |   0.8497 |     24.985 |     3.7
   31 |   0.4561 |     14.334 |   0.8509 |     25.046 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,434

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7561 |     50.192 |   1.3180 |     42.764 |     0.2
    2 |   1.2807 |     41.935 |   1.1953 |     39.208 |     0.3
    3 |   1.1856 |     39.394 |   1.1573 |     38.559 |     0.5
    4 |   1.1151 |     37.369 |   1.0618 |     36.209 |     0.7
    5 |   1.0604 |     35.595 |   1.0279 |     35.220 |     0.8
    6 |   1.0159 |     34.357 |   0.9845 |     33.364 |     1.0
    7 |   0.9774 |     32.446 |   0.9425 |     32.066 |     1.2
    8 |   0.9348 |     31.641 |   0.9170 |     30.891 |     1.3
    9 |   0.9057 |     30.470 |   0.9165 |     31.385 |     1.5
   10 |   0.8769 |     29.659 |   0.8795 |     30.705 |     1.7
   11 |   0.8380 |     28.389 |   0.8535 |     28.881 |     1.9
   12 |   0.8248 |     27.705 |   0.8498 |     28.942 |     2.0
   13 |   0.7872 |     26.949 |   0.8277 |     28.850 |     2.2
   14 |   0.7600 |     25.816 |   0.8364 |     28.139 |     2.4
   15 |   0.7428 |     25.318 |   0.8248 |     28.602 |     2.5
   16 |   0.7183 |     24.299 |   0.8306 |     27.180 |     2.7
   17 |   0.7099 |     24.118 |   0.8016 |     27.149 |     2.9
   18 |   0.6688 |     22.887 |   0.8152 |     26.314 |     3.0
   19 |   0.6519 |     21.737 |   0.7845 |     25.603 |     3.2
   20 |   0.6223 |     21.671 |   0.7947 |     26.747 |     3.4
   21 |   0.6118 |     20.877 |   0.7879 |     25.974 |     3.6
   22 |   0.5882 |     20.028 |   0.7736 |     24.675 |     3.7
   23 |   0.5714 |     19.273 |   0.7912 |     24.490 |     3.9
   24 |   0.5543 |     19.136 |   0.7683 |     24.583 |     4.1
   25 |   0.5210 |     17.915 |   0.7682 |     24.459 |     4.2
   26 |   0.5190 |     17.597 |   0.7871 |     25.015 |     4.4
   27 |   0.5151 |     17.855 |   0.8147 |     24.892 |     4.6
   28 |   0.4978 |     16.995 |   0.8069 |     25.510 |     4.7
   29 |   0.4822 |     16.426 |   0.7798 |     24.397 |     4.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 552,546

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5723 |     45.937 |   1.2611 |     41.651 |     0.1
    2 |   1.1809 |     38.787 |   1.1443 |     37.972 |     0.3
    3 |   1.0703 |     36.186 |   1.0400 |     34.725 |     0.4
    4 |   0.9912 |     33.651 |   0.9642 |     32.715 |     0.5
    5 |   0.9135 |     30.765 |   0.9381 |     31.416 |     0.6
    6 |   0.8536 |     28.575 |   0.9210 |     30.458 |     0.8
    7 |   0.8015 |     27.097 |   0.8626 |     29.283 |     0.9
    8 |   0.7296 |     24.535 |   0.8776 |     29.716 |     1.0
    9 |   0.7029 |     23.746 |   0.8264 |     27.458 |     1.2
   10 |   0.6565 |     22.054 |   0.7896 |     26.871 |     1.3
   11 |   0.6012 |     20.237 |   0.8083 |     26.531 |     1.4
   12 |   0.5829 |     19.514 |   0.7487 |     23.346 |     1.6
   13 |   0.5701 |     19.202 |   0.7666 |     24.830 |     1.7
   14 |   0.5198 |     17.455 |   0.7512 |     23.779 |     1.8
   15 |   0.4859 |     16.398 |   0.7507 |     23.810 |     1.9
   16 |   0.4674 |     15.955 |   0.7312 |     22.851 |     2.1
   17 |   0.4344 |     14.602 |   0.7709 |     23.902 |     2.2
   18 |   0.4314 |     14.466 |   0.7420 |     22.727 |     2.3
   19 |   0.3787 |     13.048 |   0.7496 |     22.387 |     2.5
   20 |   0.3701 |     12.484 |   0.7371 |     21.336 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 436,962

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7918 |     50.115 |   1.3241 |     41.837 |     0.1
    2 |   1.2714 |     41.196 |   1.1786 |     39.641 |     0.3
    3 |   1.1697 |     38.732 |   1.1050 |     36.456 |     0.4
    4 |   1.0871 |     36.137 |   1.0439 |     36.054 |     0.5
    5 |   1.0385 |     34.554 |   1.0129 |     33.766 |     0.7
    6 |   0.9870 |     33.207 |   0.9723 |     33.426 |     0.8
    7 |   0.9209 |     30.694 |   0.9348 |     30.767 |     1.0
    8 |   0.8840 |     29.731 |   0.9119 |     30.921 |     1.1
    9 |   0.8473 |     28.323 |   0.8877 |     29.654 |     1.2
   10 |   0.8174 |     27.163 |   0.8812 |     29.963 |     1.4
   11 |   0.7839 |     26.221 |   0.8449 |     28.633 |     1.5
   12 |   0.7515 |     25.515 |   0.8251 |     27.273 |     1.7
   13 |   0.7236 |     24.414 |   0.8334 |     27.706 |     1.8
   14 |   0.6917 |     23.089 |   0.8039 |     26.871 |     1.9
   15 |   0.6737 |     22.596 |   0.7942 |     26.283 |     2.1
   16 |   0.6542 |     22.087 |   0.7778 |     25.510 |     2.2
   17 |   0.6267 |     21.217 |   0.7847 |     25.325 |     2.3
   18 |   0.6025 |     20.187 |   0.7898 |     25.417 |     2.5
   19 |   0.5855 |     19.897 |   0.7584 |     24.521 |     2.6
   20 |   0.5510 |     18.457 |   0.7804 |     24.026 |     2.8
   21 |   0.5345 |     17.734 |   0.7641 |     23.593 |     2.9
   22 |   0.5237 |     17.652 |   0.7679 |     24.057 |     3.0
   23 |   0.4958 |     16.831 |   0.7793 |     23.655 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 552,546

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4227 |     59.888 |   1.7918 |     44.527 |     0.1
    2 |   1.6256 |     44.645 |   1.5288 |     43.970 |     0.2
    3 |   1.4385 |     42.121 |   1.4010 |     41.311 |     0.3
    4 |   1.3175 |     38.765 |   1.3020 |     38.126 |     0.4
    5 |   1.2208 |     36.016 |   1.2219 |     36.209 |     0.5
    6 |   1.1423 |     33.815 |   1.1523 |     35.281 |     0.6
    7 |   1.0802 |     31.997 |   1.1179 |     33.179 |     0.7
    8 |   1.0165 |     30.590 |   1.0662 |     32.777 |     0.8
    9 |   0.9649 |     28.641 |   1.0417 |     32.344 |     0.9
   10 |   0.9123 |     27.617 |   0.9973 |     30.179 |     1.0
   11 |   0.8651 |     25.871 |   0.9790 |     30.396 |     1.1
   12 |   0.8256 |     24.748 |   0.9374 |     29.592 |     1.2
   13 |   0.7852 |     23.735 |   0.9268 |     29.066 |     1.3
   14 |   0.7507 |     22.574 |   0.9073 |     28.108 |     1.4
   15 |   0.7142 |     21.299 |   0.8937 |     28.417 |     1.5
   16 |   0.6831 |     20.237 |   0.8763 |     27.829 |     1.6
   17 |   0.6644 |     19.804 |   0.8548 |     26.036 |     1.7
   18 |   0.6267 |     18.846 |   0.8376 |     25.541 |     1.8
   19 |   0.5965 |     17.526 |   0.8332 |     25.077 |     1.9
   20 |   0.5751 |     17.061 |   0.8342 |     25.603 |     2.0
   21 |   0.5477 |     16.114 |   0.8185 |     24.459 |     2.1
   22 |   0.5249 |     15.511 |   0.8473 |     25.479 |     2.2
   23 |   0.4986 |     14.236 |   0.8119 |     24.613 |     2.3
   24 |   0.4806 |     14.011 |   0.8338 |     25.201 |     2.4
   25 |   0.4687 |     14.115 |   0.8178 |     24.026 |     2.5
   26 |   0.4425 |     12.894 |   0.8181 |     24.119 |     2.6
   27 |   0.4285 |     12.681 |   0.8054 |     23.438 |     2.7
   28 |   0.4084 |     11.898 |   0.8304 |     24.830 |     2.8
   29 |   0.3963 |     11.547 |   0.8234 |     23.655 |     2.9
   30 |   0.3764 |     11.044 |   0.8365 |     24.583 |     3.0
   31 |   0.3616 |     10.688 |   0.8403 |     23.933 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,218

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5744 |     47.876 |   1.2920 |     43.105 |     0.2
    2 |   1.2416 |     41.300 |   1.1689 |     40.012 |     0.3
    3 |   1.1589 |     38.962 |   1.1206 |     36.735 |     0.5
    4 |   1.1077 |     37.889 |   1.0780 |     36.240 |     0.6
    5 |   1.0675 |     36.137 |   1.0639 |     36.116 |     0.8
    6 |   1.0296 |     34.877 |   1.0153 |     34.694 |     1.0
    7 |   0.9897 |     33.771 |   0.9882 |     33.581 |     1.1
    8 |   0.9572 |     32.687 |   0.9712 |     33.179 |     1.3
    9 |   0.9393 |     31.921 |   0.9727 |     33.302 |     1.4
   10 |   0.9085 |     30.919 |   0.9377 |     32.158 |     1.6
   11 |   0.8741 |     30.169 |   0.8957 |     29.716 |     1.8
   12 |   0.8574 |     29.353 |   0.9242 |     30.674 |     1.9
   13 |   0.8293 |     28.433 |   0.8678 |     29.283 |     2.1
   14 |   0.7927 |     27.174 |   0.8820 |     29.839 |     2.2
   15 |   0.7741 |     26.758 |   0.8671 |     29.592 |     2.4
   16 |   0.7519 |     25.701 |   0.8467 |     28.108 |     2.6
   17 |   0.7289 |     24.819 |   0.8493 |     29.190 |     2.7
   18 |   0.6983 |     23.774 |   0.8079 |     26.747 |     2.9
   19 |   0.6823 |     23.248 |   0.8201 |     27.273 |     3.1
   20 |   0.6593 |     22.717 |   0.8342 |     27.829 |     3.2
   21 |   0.6477 |     22.164 |   0.8101 |     26.747 |     3.4
   22 |   0.6215 |     21.266 |   0.7894 |     25.665 |     3.5
   23 |   0.6123 |     20.817 |   0.7886 |     25.603 |     3.7
   24 |   0.5876 |     20.466 |   0.7916 |     25.603 |     3.9
   25 |   0.5586 |     18.753 |   0.7898 |     25.417 |     4.0
   26 |   0.5457 |     18.599 |   0.8013 |     25.696 |     4.2
   27 |   0.5346 |     18.479 |   0.7895 |     24.706 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 485,794

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5610 |     45.549 |   1.2785 |     41.682 |     0.1
    2 |   1.1881 |     39.258 |   1.1468 |     37.879 |     0.2
    3 |   1.0705 |     35.540 |   1.0684 |     35.714 |     0.4
    4 |   0.9889 |     32.879 |   0.9951 |     34.199 |     0.5
    5 |   0.9102 |     30.289 |   0.9246 |     30.860 |     0.6
    6 |   0.8556 |     28.789 |   0.9159 |     30.891 |     0.7
    7 |   0.7907 |     26.549 |   0.8496 |     28.417 |     0.9
    8 |   0.7450 |     25.115 |   0.8299 |     27.365 |     1.0
    9 |   0.7038 |     23.281 |   0.8365 |     27.520 |     1.1
   10 |   0.6695 |     22.405 |   0.7646 |     25.417 |     1.2
   11 |   0.6178 |     20.669 |   0.7992 |     26.160 |     1.4
   12 |   0.5905 |     20.198 |   0.7828 |     25.758 |     1.5
   13 |   0.5533 |     19.037 |   0.7616 |     24.706 |     1.6
   14 |   0.5198 |     17.636 |   0.7726 |     24.273 |     1.7
   15 |   0.4908 |     16.667 |   0.7516 |     24.026 |     1.9
   16 |   0.4553 |     15.555 |   0.7613 |     23.686 |     2.0
   17 |   0.4347 |     14.871 |   0.7480 |     22.542 |     2.1
   18 |   0.4230 |     14.301 |   0.7038 |     21.614 |     2.2
   19 |   0.4092 |     13.650 |   0.7464 |     23.315 |     2.4
   20 |   0.3784 |     12.993 |   0.7877 |     23.500 |     2.5
   21 |   0.3574 |     12.177 |   0.7284 |     21.707 |     2.6
   22 |   0.3530 |     11.936 |   0.7234 |     20.965 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,634

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6220 |     48.861 |   1.3035 |     41.280 |     0.1
    2 |   1.2388 |     41.420 |   1.1902 |     39.579 |     0.3
    3 |   1.1582 |     39.225 |   1.0983 |     37.168 |     0.4
    4 |   1.0919 |     36.706 |   1.0687 |     36.209 |     0.5
    5 |   1.0454 |     35.458 |   1.0498 |     36.456 |     0.7
    6 |   0.9897 |     33.530 |   0.9768 |     33.179 |     0.8
    7 |   0.9464 |     32.167 |   0.9670 |     33.333 |     0.9
    8 |   0.9109 |     31.368 |   0.9348 |     31.571 |     1.1
    9 |   0.8772 |     29.747 |   0.8941 |     30.241 |     1.2
   10 |   0.8437 |     28.740 |   0.8755 |     29.870 |     1.3
   11 |   0.8053 |     27.092 |   0.8735 |     28.664 |     1.5
   12 |   0.7804 |     26.779 |   0.8690 |     29.530 |     1.6
   13 |   0.7453 |     25.296 |   0.8424 |     28.479 |     1.7
   14 |   0.7250 |     24.699 |   0.8364 |     27.829 |     1.9
   15 |   0.6919 |     23.461 |   0.8253 |     28.355 |     2.0
   16 |   0.6779 |     22.848 |   0.8599 |     29.283 |     2.1
   17 |   0.6513 |     22.104 |   0.8136 |     26.654 |     2.3
   18 |   0.6312 |     21.425 |   0.8056 |     26.407 |     2.4
   19 |   0.6017 |     20.625 |   0.7740 |     25.665 |     2.6
   20 |   0.5769 |     19.623 |   0.7943 |     25.139 |     2.7
   21 |   0.5699 |     19.360 |   0.7606 |     24.737 |     2.8
   22 |   0.5524 |     18.539 |   0.7647 |     25.108 |     3.0
   23 |   0.5272 |     18.107 |   0.7647 |     24.706 |     3.1
   24 |   0.4869 |     16.497 |   0.7605 |     24.088 |     3.2
   25 |   0.4789 |     16.426 |   0.8189 |     25.479 |     3.4
   26 |   0.4679 |     15.938 |   0.7852 |     24.397 |     3.5
   27 |   0.4553 |     15.955 |   0.7685 |     23.655 |     3.6
   28 |   0.4336 |     14.805 |   0.7549 |     22.913 |     3.8
   29 |   0.4205 |     14.460 |   0.7666 |     23.377 |     3.9
   30 |   0.4131 |     14.066 |   0.7893 |     23.686 |     4.0
   31 |   0.4054 |     14.126 |   0.8029 |     23.748 |     4.2
   32 |   0.3803 |     13.447 |   0.7832 |     23.160 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,386

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1567 |     55.891 |   1.4595 |     44.001 |     0.2
    2 |   1.4424 |     43.298 |   1.3173 |     41.466 |     0.3
    3 |   1.3178 |     40.944 |   1.2429 |     39.208 |     0.5
    4 |   1.2302 |     38.360 |   1.1656 |     37.229 |     0.7
    5 |   1.1603 |     36.263 |   1.1215 |     35.467 |     0.8
    6 |   1.0914 |     34.078 |   1.0819 |     35.281 |     1.0
    7 |   1.0501 |     32.879 |   1.0437 |     33.364 |     1.2
    8 |   0.9998 |     31.067 |   1.0126 |     32.282 |     1.3
    9 |   0.9389 |     29.309 |   0.9843 |     32.066 |     1.5
   10 |   0.8960 |     28.083 |   0.9525 |     30.303 |     1.7
   11 |   0.8541 |     27.059 |   0.9246 |     29.777 |     1.8
   12 |   0.8134 |     25.564 |   0.9201 |     29.777 |     2.0
   13 |   0.7667 |     24.086 |   0.8950 |     29.375 |     2.2
   14 |   0.7391 |     22.870 |   0.8972 |     28.602 |     2.3
   15 |   0.7019 |     22.219 |   0.8782 |     27.829 |     2.5
   16 |   0.6614 |     20.598 |   0.8623 |     27.335 |     2.7
   17 |   0.6391 |     19.946 |   0.8676 |     26.994 |     2.9
   18 |   0.6185 |     19.158 |   0.8686 |     26.407 |     3.0
   19 |   0.5838 |     17.838 |   0.8358 |     25.634 |     3.2
   20 |   0.5681 |     17.592 |   0.8283 |     24.954 |     3.4
   21 |   0.5370 |     16.814 |   0.8311 |     25.294 |     3.5
   22 |   0.5133 |     15.615 |   0.8241 |     24.892 |     3.7
   23 |   0.4892 |     15.364 |   0.8362 |     24.892 |     3.9
   24 |   0.4680 |     14.860 |   0.8536 |     24.242 |     4.0
   25 |   0.4504 |     14.214 |   0.8444 |     24.799 |     4.2
   26 |   0.4407 |     13.759 |   0.8587 |     24.985 |     4.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,194

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4702 |     59.083 |   1.8700 |     44.341 |     0.1
    2 |   1.6643 |     44.092 |   1.5284 |     42.795 |     0.3
    3 |   1.4465 |     41.557 |   1.3944 |     40.816 |     0.4
    4 |   1.3375 |     39.564 |   1.3152 |     38.776 |     0.6
    5 |   1.2569 |     37.779 |   1.2569 |     37.910 |     0.7
    6 |   1.1883 |     35.929 |   1.2002 |     36.642 |     0.9
    7 |   1.1349 |     34.560 |   1.1476 |     34.323 |     1.0
    8 |   1.0755 |     32.594 |   1.1066 |     34.539 |     1.2
    9 |   1.0285 |     31.105 |   1.0809 |     33.983 |     1.3
   10 |   0.9780 |     29.386 |   1.0519 |     32.498 |     1.5
   11 |   0.9355 |     27.962 |   1.0081 |     31.942 |     1.6
   12 |   0.8950 |     26.938 |   0.9835 |     30.118 |     1.8
   13 |   0.8468 |     25.230 |   0.9746 |     30.427 |     1.9
   14 |   0.8139 |     24.376 |   0.9597 |     30.087 |     2.1
   15 |   0.7786 |     23.210 |   0.9178 |     28.169 |     2.2
   16 |   0.7444 |     22.388 |   0.9104 |     28.912 |     2.4
   17 |   0.7172 |     21.556 |   0.9002 |     28.077 |     2.5
   18 |   0.6882 |     20.647 |   0.8805 |     27.706 |     2.7
   19 |   0.6641 |     19.640 |   0.8801 |     27.829 |     2.8
   20 |   0.6378 |     19.289 |   0.8917 |     27.396 |     3.0
   21 |   0.6172 |     18.621 |   0.8707 |     27.211 |     3.1
   22 |   0.5896 |     17.625 |   0.8636 |     27.087 |     3.3
   23 |   0.5655 |     16.957 |   0.8609 |     27.365 |     3.4
   24 |   0.5475 |     16.557 |   0.8781 |     27.180 |     3.6
   25 |   0.5316 |     15.840 |   0.8588 |     26.160 |     3.7
   26 |   0.5109 |     15.260 |   0.8477 |     26.592 |     3.9
   27 |   0.4946 |     14.832 |   0.8579 |     26.098 |     4.0
   28 |   0.4821 |     14.586 |   0.8578 |     26.531 |     4.2
   29 |   0.4615 |     13.705 |   0.8514 |     26.345 |     4.3
   30 |   0.4542 |     13.507 |   0.8634 |     26.067 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 485,794

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6727 |     47.421 |   1.2879 |     41.682 |     0.1
    2 |   1.2464 |     40.884 |   1.1755 |     39.116 |     0.3
    3 |   1.1460 |     38.190 |   1.0981 |     36.797 |     0.4
    4 |   1.0620 |     35.529 |   1.0270 |     34.137 |     0.5
    5 |   1.0018 |     33.547 |   0.9971 |     33.581 |     0.7
    6 |   0.9681 |     32.457 |   0.9530 |     32.004 |     0.8
    7 |   0.9190 |     30.771 |   0.9432 |     32.498 |     0.9
    8 |   0.8888 |     29.873 |   0.8952 |     30.334 |     1.1
    9 |   0.8386 |     28.006 |   0.8977 |     29.716 |     1.2
   10 |   0.8194 |     27.546 |   0.8620 |     30.087 |     1.4
   11 |   0.7714 |     25.816 |   0.8613 |     28.541 |     1.5
   12 |   0.7427 |     24.973 |   0.8107 |     26.778 |     1.6
   13 |   0.7106 |     23.938 |   0.8088 |     26.531 |     1.8
   14 |   0.6839 |     22.980 |   0.7817 |     26.500 |     1.9
   15 |   0.6627 |     22.695 |   0.7944 |     26.994 |     2.0
   16 |   0.6229 |     21.063 |   0.7997 |     25.603 |     2.2
   17 |   0.5981 |     20.111 |   0.7872 |     24.737 |     2.3
   18 |   0.5791 |     19.656 |   0.7736 |     25.170 |     2.4
   19 |   0.5527 |     18.671 |   0.7681 |     24.861 |     2.6
   20 |   0.5279 |     17.844 |   0.7449 |     24.181 |     2.7
   21 |   0.5262 |     17.773 |   0.7788 |     23.655 |     2.9
   22 |   0.5034 |     16.897 |   0.7282 |     23.191 |     3.0
   23 |   0.4702 |     15.769 |   0.7809 |     23.902 |     3.1
   24 |   0.4569 |     15.166 |   0.7334 |     22.449 |     3.3
   25 |   0.4459 |     15.117 |   0.7845 |     23.593 |     3.4
   26 |   0.4258 |     14.394 |   0.7979 |     23.624 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,746

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0567 |     51.883 |   1.4836 |     42.579 |     0.1
    2 |   1.3747 |     41.694 |   1.2991 |     38.621 |     0.2
    3 |   1.2343 |     38.113 |   1.1890 |     36.456 |     0.3
    4 |   1.1283 |     35.518 |   1.1205 |     36.085 |     0.5
    5 |   1.0436 |     32.413 |   1.0819 |     34.694 |     0.6
    6 |   0.9754 |     30.108 |   1.0114 |     32.529 |     0.7
    7 |   0.9094 |     28.269 |   0.9684 |     30.396 |     0.8
    8 |   0.8516 |     26.533 |   0.9290 |     29.685 |     0.9
    9 |   0.7973 |     24.310 |   0.8899 |     28.881 |     1.0
   10 |   0.7528 |     22.941 |   0.8805 |     28.324 |     1.2
   11 |   0.7002 |     21.162 |   0.8545 |     27.087 |     1.3
   12 |   0.6683 |     20.122 |   0.8511 |     27.551 |     1.4
   13 |   0.6265 |     18.922 |   0.8340 |     26.283 |     1.5
   14 |   0.5943 |     17.893 |   0.8218 |     26.190 |     1.6
   15 |   0.5679 |     17.017 |   0.7983 |     25.696 |     1.8
   16 |   0.5356 |     16.322 |   0.8045 |     25.139 |     1.9
   17 |   0.5021 |     15.062 |   0.7937 |     24.459 |     2.0
   18 |   0.4726 |     14.301 |   0.7837 |     23.995 |     2.1
   19 |   0.4474 |     13.425 |   0.7743 |     23.129 |     2.2
   20 |   0.4194 |     12.527 |   0.7986 |     23.810 |     2.3
   21 |   0.4067 |     12.303 |   0.7670 |     23.779 |     2.5
   22 |   0.3848 |     11.465 |   0.7739 |     22.851 |     2.6
   23 |   0.3554 |     10.682 |   0.7819 |     22.975 |     2.7
   24 |   0.3380 |     10.200 |   0.7794 |     23.067 |     2.8
   25 |   0.3220 |      9.970 |   0.7902 |     23.315 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,471,906

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5055 |     46.567 |   1.2620 |     42.393 |     0.1
    2 |   1.1814 |     39.915 |   1.1648 |     38.312 |     0.3
    3 |   1.0679 |     35.929 |   1.1086 |     38.095 |     0.5
    4 |   0.9982 |     34.160 |   1.0034 |     34.632 |     0.6
    5 |   0.9312 |     31.899 |   0.9312 |     31.973 |     0.8
    6 |   0.8775 |     30.004 |   0.9262 |     30.983 |     0.9
    7 |   0.8299 |     28.225 |   0.8885 |     30.643 |     1.1
    8 |   0.8150 |     27.612 |   0.8697 |     28.633 |     1.2
    9 |   0.7547 |     25.816 |   0.8374 |     28.108 |     1.4
   10 |   0.7217 |     24.595 |   0.8600 |     28.448 |     1.5
   11 |   0.6839 |     23.100 |   0.7942 |     26.685 |     1.7
   12 |   0.6689 |     22.744 |   0.7594 |     25.325 |     1.8
   13 |   0.6184 |     20.915 |   0.7775 |     26.190 |     2.0
   14 |   0.5980 |     20.516 |   0.7931 |     26.345 |     2.1
   15 |   0.5592 |     19.246 |   0.7248 |     24.088 |     2.3
   16 |   0.5312 |     17.762 |   0.7690 |     24.366 |     2.5
   17 |   0.5201 |     17.472 |   0.7404 |     23.717 |     2.6
   18 |   0.4870 |     16.415 |   0.7222 |     22.696 |     2.8
   19 |   0.4809 |     16.393 |   0.7229 |     22.820 |     2.9
   20 |   0.4347 |     14.739 |   0.7511 |     23.686 |     3.1
   21 |   0.4247 |     14.143 |   0.7484 |     23.222 |     3.2
   22 |   0.4269 |     14.663 |   0.7307 |     22.202 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,341,218

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0314 |     51.385 |   1.4721 |     43.383 |     0.2
    2 |   1.3538 |     41.103 |   1.2934 |     39.889 |     0.4
    3 |   1.2131 |     37.790 |   1.1950 |     38.157 |     0.5
    4 |   1.1130 |     34.390 |   1.1286 |     35.436 |     0.7
    5 |   1.0313 |     31.981 |   1.0533 |     33.179 |     0.9
    6 |   0.9499 |     29.610 |   1.0140 |     32.189 |     1.1
    7 |   0.8857 |     27.354 |   0.9585 |     30.334 |     1.3
    8 |   0.8218 |     25.520 |   0.9272 |     29.561 |     1.5
    9 |   0.7698 |     23.511 |   0.9226 |     29.499 |     1.7
   10 |   0.7228 |     22.197 |   0.8656 |     27.675 |     1.9
   11 |   0.6644 |     20.143 |   0.8834 |     27.644 |     2.1
   12 |   0.6217 |     19.098 |   0.8361 |     26.840 |     2.3
   13 |   0.5764 |     17.482 |   0.8177 |     25.850 |     2.5
   14 |   0.5410 |     16.453 |   0.8046 |     24.768 |     2.7
   15 |   0.5122 |     15.714 |   0.8472 |     26.067 |     2.9
   16 |   0.4847 |     14.679 |   0.7832 |     23.871 |     3.1
   17 |   0.4425 |     13.130 |   0.7872 |     24.459 |     3.3
   18 |   0.4088 |     12.292 |   0.7818 |     22.882 |     3.5
   19 |   0.3939 |     11.985 |   0.7870 |     23.686 |     3.7
   20 |   0.3682 |     11.027 |   0.7910 |     22.789 |     3.8
   21 |   0.3432 |     10.419 |   0.8517 |     25.170 |     4.0
   22 |   0.3264 |      9.910 |   0.7788 |     22.418 |     4.2
   23 |   0.3017 |      9.248 |   0.8069 |     22.604 |     4.4
   24 |   0.2938 |      8.985 |   0.7915 |     22.975 |     4.6
   25 |   0.2687 |      7.786 |   0.8110 |     22.202 |     4.8
   26 |   0.2589 |      7.923 |   0.8320 |     22.789 |     5.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,273,122

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9686 |     50.509 |   1.4307 |     41.991 |     0.1
    2 |   1.3262 |     40.155 |   1.2714 |     39.239 |     0.3
    3 |   1.1943 |     37.182 |   1.1798 |     36.395 |     0.4
    4 |   1.0902 |     33.826 |   1.1002 |     35.281 |     0.6
    5 |   0.9975 |     31.138 |   1.0353 |     33.612 |     0.7
    6 |   0.9307 |     29.200 |   0.9742 |     31.231 |     0.9
    7 |   0.8635 |     26.812 |   0.9651 |     31.416 |     1.0
    8 |   0.7947 |     24.540 |   0.9135 |     29.777 |     1.2
    9 |   0.7457 |     23.155 |   0.8848 |     29.128 |     1.3
   10 |   0.6938 |     21.687 |   0.8731 |     28.726 |     1.5
   11 |   0.6555 |     20.368 |   0.8525 |     26.964 |     1.6
   12 |   0.6120 |     18.599 |   0.8265 |     26.345 |     1.8
   13 |   0.5631 |     17.203 |   0.8174 |     25.974 |     1.9
   14 |   0.5304 |     16.174 |   0.8088 |     25.387 |     2.1
   15 |   0.4926 |     14.920 |   0.8236 |     25.788 |     2.2
   16 |   0.4731 |     14.613 |   0.7803 |     24.459 |     2.4
   17 |   0.4268 |     12.943 |   0.7684 |     23.902 |     2.5
   18 |   0.4012 |     12.182 |   0.7818 |     23.964 |     2.7
   19 |   0.3821 |     11.608 |   0.7795 |     23.655 |     2.8
   20 |   0.3591 |     10.890 |   0.7890 |     24.242 |     3.0
   21 |   0.3428 |     10.381 |   0.7795 |     23.748 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,075,746

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5403 |     46.748 |   1.2819 |     41.775 |     0.1
    2 |   1.2365 |     41.409 |   1.1567 |     38.652 |     0.2
    3 |   1.1486 |     38.354 |   1.0786 |     35.838 |     0.4
    4 |   1.0797 |     36.525 |   1.0204 |     34.787 |     0.5
    5 |   1.0117 |     34.270 |   0.9846 |     34.199 |     0.6
    6 |   0.9722 |     33.158 |   0.9701 |     34.075 |     0.7
    7 |   0.9236 |     31.105 |   0.9285 |     32.127 |     0.9
    8 |   0.8863 |     29.714 |   0.8962 |     30.983 |     1.0
    9 |   0.8490 |     28.718 |   0.9027 |     30.643 |     1.1
   10 |   0.8209 |     27.322 |   0.8569 |     30.179 |     1.2
   11 |   0.7904 |     26.747 |   0.8704 |     29.159 |     1.4
   12 |   0.7636 |     25.931 |   0.8379 |     28.417 |     1.5
   13 |   0.7278 |     24.880 |   0.8307 |     28.077 |     1.6
   14 |   0.7064 |     24.020 |   0.8758 |     29.344 |     1.7
   15 |   0.6824 |     22.881 |   0.8470 |     27.551 |     1.9
   16 |   0.6602 |     22.361 |   0.8313 |     26.840 |     2.0
   17 |   0.6544 |     22.213 |   0.8651 |     28.015 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 535,778

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5946 |     46.479 |   1.2769 |     41.744 |     0.1
    2 |   1.2017 |     40.041 |   1.1453 |     37.013 |     0.2
    3 |   1.0918 |     36.640 |   1.0860 |     36.735 |     0.3
    4 |   1.0139 |     34.204 |   1.0074 |     33.859 |     0.4
    5 |   0.9511 |     31.784 |   0.9720 |     33.364 |     0.6
    6 |   0.8905 |     30.004 |   0.9010 |     29.654 |     0.7
    7 |   0.8354 |     28.537 |   0.8835 |     30.519 |     0.8
    8 |   0.7975 |     27.092 |   0.8468 |     28.695 |     0.9
    9 |   0.7495 |     25.224 |   0.8438 |     28.479 |     1.0
   10 |   0.7092 |     24.179 |   0.8054 |     26.623 |     1.1
   11 |   0.6744 |     22.887 |   0.7931 |     27.242 |     1.2
   12 |   0.6342 |     21.633 |   0.8191 |     27.551 |     1.3
   13 |   0.6128 |     20.762 |   0.7542 |     25.263 |     1.5
   14 |   0.5926 |     20.056 |   0.7425 |     24.830 |     1.6
   15 |   0.5639 |     19.333 |   0.7201 |     23.500 |     1.7
   16 |   0.5289 |     17.882 |   0.7375 |     24.057 |     1.8
   17 |   0.5072 |     17.532 |   0.7205 |     23.315 |     1.9
   18 |   0.4784 |     16.278 |   0.7343 |     23.098 |     2.0
   19 |   0.4729 |     16.283 |   0.7286 |     23.438 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 470,434

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4403 |     58.596 |   1.7655 |     44.465 |     0.2
    2 |   1.5867 |     43.939 |   1.5032 |     43.506 |     0.3
    3 |   1.4181 |     41.393 |   1.3934 |     40.909 |     0.5
    4 |   1.3205 |     39.608 |   1.3037 |     38.776 |     0.6
    5 |   1.2418 |     37.380 |   1.2493 |     36.673 |     0.8
    6 |   1.1695 |     35.288 |   1.1933 |     35.869 |     0.9
    7 |   1.1071 |     33.333 |   1.1456 |     35.096 |     1.1
    8 |   1.0488 |     31.735 |   1.1100 |     34.045 |     1.3
    9 |   0.9940 |     29.889 |   1.0653 |     33.148 |     1.4
   10 |   0.9436 |     28.280 |   1.0280 |     32.313 |     1.6
   11 |   0.8969 |     27.092 |   1.0093 |     31.478 |     1.8
   12 |   0.8509 |     25.542 |   1.0199 |     32.158 |     1.9
   13 |   0.8127 |     24.359 |   0.9941 |     31.385 |     2.1
   14 |   0.7834 |     23.927 |   0.9386 |     29.716 |     2.2
   15 |   0.7432 |     22.175 |   0.9469 |     29.994 |     2.4
   16 |   0.7091 |     21.288 |   0.9265 |     29.654 |     2.5
   17 |   0.6785 |     20.434 |   0.9149 |     28.664 |     2.7
   18 |   0.6615 |     19.968 |   0.9030 |     28.355 |     2.8
   19 |   0.6308 |     18.939 |   0.8907 |     27.706 |     3.0
   20 |   0.6077 |     18.238 |   0.8944 |     28.200 |     3.2
   21 |   0.5792 |     17.499 |   0.8963 |     27.798 |     3.3
   22 |   0.5573 |     16.645 |   0.9030 |     28.046 |     3.5
   23 |   0.5384 |     16.316 |   0.9106 |     27.458 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,602

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5252 |     46.934 |   1.2876 |     43.445 |     0.2
    2 |   1.2374 |     41.453 |   1.1832 |     39.672 |     0.3
    3 |   1.1572 |     38.907 |   1.1100 |     37.044 |     0.5
    4 |   1.1019 |     37.850 |   1.0580 |     35.962 |     0.6
    5 |   1.0656 |     36.514 |   1.0086 |     34.632 |     0.8
    6 |   1.0190 |     34.910 |   1.0400 |     34.910 |     1.0
    7 |   0.9786 |     33.487 |   0.9502 |     32.282 |     1.1
    8 |   0.9491 |     32.627 |   0.9792 |     33.210 |     1.3
    9 |   0.9221 |     31.789 |   0.9537 |     31.447 |     1.5
   10 |   0.9053 |     31.045 |   0.9332 |     32.096 |     1.6
   11 |   0.8825 |     30.295 |   0.9207 |     31.818 |     1.8
   12 |   0.8505 |     29.194 |   0.8972 |     31.540 |     1.9
   13 |   0.8324 |     28.466 |   0.8972 |     30.643 |     2.1
   14 |   0.8086 |     27.820 |   0.8749 |     29.097 |     2.3
   15 |   0.8024 |     27.486 |   0.8948 |     30.241 |     2.4
   16 |   0.7725 |     26.840 |   0.8581 |     28.726 |     2.6
   17 |   0.7391 |     25.093 |   0.8768 |     29.716 |     2.7
   18 |   0.7531 |     26.007 |   0.8552 |     29.004 |     2.9
   19 |   0.7192 |     24.606 |   0.8693 |     28.912 |     3.1
   20 |   0.6958 |     23.954 |   0.8466 |     27.798 |     3.2
   21 |   0.6784 |     23.117 |   0.8544 |     28.015 |     3.4
   22 |   0.6631 |     22.717 |   0.8666 |     27.737 |     3.5
   23 |   0.6477 |     22.509 |   0.8441 |     26.994 |     3.7
   24 |   0.6356 |     21.857 |   0.8886 |     28.633 |     3.8
   25 |   0.6126 |     21.069 |   0.9097 |     29.870 |     4.0
   26 |   0.5915 |     20.384 |   0.8987 |     28.757 |     4.2
   27 |   0.5874 |     20.461 |   0.8682 |     27.087 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,746

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4820 |     45.603 |   1.2299 |     40.724 |     0.1
    2 |   1.1462 |     38.502 |   1.1345 |     38.219 |     0.2
    3 |   1.0450 |     35.025 |   1.0350 |     35.312 |     0.3
    4 |   0.9686 |     32.649 |   0.9856 |     32.931 |     0.5
    5 |   0.9128 |     30.782 |   0.9249 |     31.942 |     0.6
    6 |   0.8614 |     29.221 |   0.9030 |     30.087 |     0.7
    7 |   0.8112 |     27.469 |   0.8919 |     30.179 |     0.8
    8 |   0.7800 |     26.259 |   0.8409 |     28.324 |     0.9
    9 |   0.7559 |     25.613 |   0.8225 |     27.304 |     1.0
   10 |   0.7191 |     24.332 |   0.8330 |     27.675 |     1.2
   11 |   0.6766 |     22.711 |   0.7964 |     27.582 |     1.3
   12 |   0.6344 |     21.655 |   0.8091 |     26.685 |     1.4
   13 |   0.6236 |     21.118 |   0.7738 |     25.417 |     1.5
   14 |   0.6103 |     20.806 |   0.7831 |     26.129 |     1.6
   15 |   0.5818 |     19.585 |   0.7656 |     24.985 |     1.7
   16 |   0.5374 |     18.156 |   0.7614 |     25.170 |     1.8
   17 |   0.5297 |     18.090 |   0.7667 |     24.335 |     2.0
   18 |   0.5109 |     17.543 |   0.7426 |     23.531 |     2.1
   19 |   0.4632 |     15.900 |   0.7940 |     25.634 |     2.2
   20 |   0.4640 |     15.922 |   0.7688 |     24.026 |     2.3
   21 |   0.4424 |     15.221 |   0.7653 |     23.098 |     2.4
   22 |   0.4293 |     14.750 |   0.7480 |     23.160 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,634

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0594 |     54.397 |   1.4406 |     43.290 |     0.1
    2 |   1.3363 |     40.955 |   1.2697 |     38.188 |     0.2
    3 |   1.2023 |     37.193 |   1.2042 |     38.590 |     0.4
    4 |   1.1084 |     34.669 |   1.1101 |     35.622 |     0.5
    5 |   1.0188 |     31.537 |   1.0355 |     32.870 |     0.6
    6 |   0.9571 |     29.605 |   0.9942 |     31.540 |     0.7
    7 |   0.8857 |     27.124 |   0.9665 |     31.540 |     0.9
    8 |   0.8236 |     25.246 |   0.9086 |     28.973 |     1.0
    9 |   0.7730 |     23.637 |   0.9138 |     29.468 |     1.1
   10 |   0.7294 |     22.366 |   0.8667 |     27.118 |     1.2
   11 |   0.6740 |     20.554 |   0.8555 |     27.644 |     1.4
   12 |   0.6350 |     19.174 |   0.8404 |     25.974 |     1.5
   13 |   0.5924 |     17.762 |   0.8304 |     25.943 |     1.6
   14 |   0.5698 |     17.548 |   0.8069 |     25.108 |     1.7
   15 |   0.5184 |     15.610 |   0.8105 |     25.077 |     1.9
   16 |   0.4958 |     15.030 |   0.7908 |     23.933 |     2.0
   17 |   0.4621 |     13.896 |   0.7885 |     23.995 |     2.1
   18 |   0.4379 |     13.447 |   0.7824 |     23.500 |     2.2
   19 |   0.4084 |     12.347 |   0.7854 |     23.006 |     2.4
   20 |   0.3821 |     11.427 |   0.7820 |     22.480 |     2.5
   21 |   0.3512 |     10.326 |   0.7836 |     22.294 |     2.6
   22 |   0.3418 |     10.310 |   0.7881 |     22.233 |     2.7
   23 |   0.3234 |      9.883 |   0.7899 |     21.954 |     2.9
   24 |   0.2982 |      8.733 |   0.7911 |     22.047 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,602

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9336 |     51.396 |   1.4177 |     42.177 |     0.2
    2 |   1.3141 |     39.904 |   1.2644 |     39.301 |     0.4
    3 |   1.1763 |     36.471 |   1.1540 |     36.487 |     0.5
    4 |   1.0786 |     33.437 |   1.0780 |     34.570 |     0.7
    5 |   0.9912 |     30.815 |   1.0088 |     32.313 |     0.9
    6 |   0.9143 |     28.499 |   0.9786 |     30.891 |     1.1
    7 |   0.8480 |     26.402 |   0.9117 |     29.344 |     1.3
    8 |   0.7784 |     23.976 |   0.8980 |     28.850 |     1.4
    9 |   0.7322 |     22.284 |   0.8513 |     27.180 |     1.6
   10 |   0.6772 |     20.483 |   0.8459 |     26.747 |     1.8
   11 |   0.6254 |     18.901 |   0.8138 |     26.036 |     2.0
   12 |   0.5813 |     17.696 |   0.8032 |     25.170 |     2.2
   13 |   0.5419 |     16.070 |   0.8333 |     26.438 |     2.3
   14 |   0.5152 |     15.873 |   0.7894 |     24.737 |     2.5
   15 |   0.4710 |     14.438 |   0.7895 |     24.923 |     2.7
   16 |   0.4401 |     13.217 |   0.7964 |     24.181 |     2.9
   17 |   0.4090 |     11.925 |   0.7882 |     23.377 |     3.1
   18 |   0.3816 |     11.553 |   0.7749 |     22.727 |     3.2
   19 |   0.3483 |     10.288 |   0.7893 |     23.160 |     3.4
   20 |   0.3256 |      9.708 |   0.7715 |     22.140 |     3.6
   21 |   0.3035 |      8.968 |   0.7744 |     22.758 |     3.8
   22 |   0.2678 |      7.813 |   0.7971 |     22.635 |     4.0
   23 |   0.2584 |      7.638 |   0.8009 |     22.109 |     4.1
   24 |   0.2475 |      7.304 |   0.7813 |     21.429 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,386

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5520 |     46.994 |   1.2963 |     45.826 |     0.2
    2 |   1.2527 |     41.628 |   1.2214 |     41.558 |     0.3
    3 |   1.1790 |     39.624 |   1.1420 |     37.693 |     0.5
    4 |   1.1256 |     38.507 |   1.0869 |     36.611 |     0.7
    5 |   1.0768 |     36.723 |   1.0411 |     36.209 |     0.8
    6 |   1.0420 |     35.370 |   1.0104 |     35.869 |     1.0
    7 |   1.0230 |     34.593 |   1.0156 |     35.189 |     1.2
    8 |   0.9936 |     33.799 |   0.9952 |     34.539 |     1.3
    9 |   0.9708 |     33.426 |   0.9831 |     33.395 |     1.5
   10 |   0.9344 |     32.058 |   0.9710 |     33.643 |     1.6
   11 |   0.9023 |     30.886 |   0.9721 |     33.241 |     1.8
   12 |   0.9009 |     31.516 |   0.9309 |     32.591 |     2.0
   13 |   0.8779 |     30.284 |   0.9450 |     33.024 |     2.1
   14 |   0.8509 |     28.997 |   0.9080 |     31.818 |     2.3
   15 |   0.8385 |     28.931 |   0.8844 |     30.025 |     2.5
   16 |   0.8016 |     27.502 |   0.9006 |     31.138 |     2.6
   17 |   0.7954 |     27.502 |   0.9032 |     31.169 |     2.8
   18 |   0.7595 |     26.040 |   0.8573 |     29.375 |     3.0
   19 |   0.7479 |     25.991 |   0.8564 |     29.716 |     3.1
   20 |   0.7478 |     25.383 |   0.8581 |     29.375 |     3.3
   21 |   0.7178 |     24.682 |   0.8685 |     30.581 |     3.5
   22 |   0.7170 |     24.759 |   0.8654 |     30.798 |     3.6
   23 |   0.6961 |     24.359 |   0.8799 |     30.303 |     3.8
   24 |   0.6748 |     23.522 |   0.8441 |     28.695 |     4.0
   25 |   0.6557 |     22.295 |   0.8436 |     28.819 |     4.1
   26 |   0.6350 |     21.901 |   0.8522 |     28.262 |     4.3
   27 |   0.6184 |     21.337 |   0.8662 |     29.066 |     4.5
   28 |   0.6216 |     21.348 |   0.8854 |     28.912 |     4.6
   29 |   0.6034 |     20.576 |   0.8488 |     28.262 |     4.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,122

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5272 |     46.638 |   1.2408 |     41.404 |     0.1
    2 |   1.2252 |     40.982 |   1.1493 |     39.054 |     0.2
    3 |   1.1232 |     37.516 |   1.0612 |     34.818 |     0.4
    4 |   1.0635 |     36.016 |   1.0454 |     35.065 |     0.5
    5 |   1.0084 |     33.968 |   0.9994 |     33.797 |     0.6
    6 |   0.9745 |     33.098 |   0.9325 |     31.633 |     0.8
    7 |   0.9323 |     31.494 |   0.9220 |     31.354 |     0.9
    8 |   0.8901 |     30.229 |   0.8868 |     30.829 |     1.0
    9 |   0.8534 |     28.866 |   0.8706 |     29.901 |     1.1
   10 |   0.8230 |     28.340 |   0.8497 |     28.757 |     1.3
   11 |   0.8007 |     27.108 |   0.8648 |     29.344 |     1.4
   12 |   0.7754 |     26.736 |   0.8290 |     28.479 |     1.5
   13 |   0.7188 |     24.885 |   0.7923 |     26.129 |     1.7
   14 |   0.6975 |     23.664 |   0.7859 |     26.221 |     1.8
   15 |   0.6815 |     23.500 |   0.7715 |     26.005 |     1.9
   16 |   0.6444 |     21.912 |   0.7552 |     25.139 |     2.0
   17 |   0.6245 |     21.315 |   0.7581 |     25.232 |     2.2
   18 |   0.6002 |     20.341 |   0.7450 |     24.459 |     2.3
   19 |   0.5987 |     20.510 |   0.7726 |     26.190 |     2.4
   20 |   0.5559 |     18.818 |   0.7386 |     25.201 |     2.5
   21 |   0.5325 |     18.025 |   0.7439 |     24.397 |     2.7
   22 |   0.4973 |     17.077 |   0.7289 |     23.717 |     2.8
   23 |   0.4851 |     16.656 |   0.7446 |     23.006 |     2.9
   24 |   0.4846 |     16.338 |   0.7354 |     24.150 |     3.1
   25 |   0.4645 |     15.955 |   0.7475 |     23.995 |     3.2
   26 |   0.4220 |     14.696 |   0.7742 |     23.655 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 436,962

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5794 |     64.778 |   1.8505 |     44.805 |     0.1
    2 |   1.6383 |     44.333 |   1.5202 |     42.362 |     0.2
    3 |   1.4411 |     41.667 |   1.3920 |     40.507 |     0.3
    4 |   1.3387 |     39.515 |   1.3110 |     38.806 |     0.4
    5 |   1.2491 |     37.440 |   1.2461 |     37.291 |     0.5
    6 |   1.1801 |     35.359 |   1.1849 |     36.797 |     0.6
    7 |   1.1215 |     34.062 |   1.1398 |     35.591 |     0.7
    8 |   1.0641 |     32.216 |   1.1040 |     34.570 |     0.8
    9 |   1.0197 |     30.623 |   1.0615 |     33.395 |     0.9
   10 |   0.9661 |     29.249 |   1.0329 |     32.251 |     1.0
   11 |   0.9206 |     27.541 |   1.0066 |     31.416 |     1.1
   12 |   0.8827 |     26.243 |   0.9769 |     30.118 |     1.2
   13 |   0.8463 |     25.591 |   0.9489 |     30.025 |     1.3
   14 |   0.8074 |     24.381 |   0.9395 |     29.035 |     1.3
   15 |   0.7776 |     23.396 |   0.9136 |     28.448 |     1.4
   16 |   0.7466 |     22.251 |   0.9245 |     28.850 |     1.5
   17 |   0.7215 |     21.742 |   0.9006 |     28.510 |     1.6
   18 |   0.6852 |     20.450 |   0.8965 |     28.046 |     1.7
   19 |   0.6603 |     19.651 |   0.8812 |     28.448 |     1.8
   20 |   0.6364 |     19.273 |   0.8723 |     26.902 |     1.9
   21 |   0.6081 |     18.167 |   0.8721 |     26.747 |     2.0
   22 |   0.5890 |     17.658 |   0.8588 |     27.056 |     2.1
   23 |   0.5641 |     17.012 |   0.8551 |     26.716 |     2.2
   24 |   0.5440 |     16.081 |   0.8573 |     26.531 |     2.3
   25 |   0.5186 |     15.303 |   0.8537 |     25.448 |     2.4
   26 |   0.4972 |     14.553 |   0.8449 |     25.294 |     2.5
   27 |   0.4899 |     14.592 |   0.8428 |     25.634 |     2.6
   28 |   0.4603 |     13.644 |   0.8455 |     25.696 |     2.7
   29 |   0.4481 |     13.163 |   0.8514 |     25.788 |     2.8
   30 |   0.4366 |     13.075 |   0.8606 |     26.592 |     2.9
   31 |   0.4137 |     12.232 |   0.8462 |     25.108 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,386

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8877 |     50.400 |   1.3964 |     42.146 |     0.1
    2 |   1.2897 |     39.652 |   1.2243 |     38.126 |     0.3
    3 |   1.1545 |     35.934 |   1.1395 |     36.085 |     0.5
    4 |   1.0517 |     33.054 |   1.0741 |     33.581 |     0.6
    5 |   0.9640 |     30.267 |   1.0113 |     32.715 |     0.8
    6 |   0.8902 |     27.803 |   0.9549 |     29.901 |     0.9
    7 |   0.8272 |     25.777 |   0.9193 |     29.592 |     1.1
    8 |   0.7644 |     23.555 |   0.8929 |     28.973 |     1.2
    9 |   0.7032 |     21.512 |   0.8497 |     26.809 |     1.4
   10 |   0.6483 |     19.985 |   0.8575 |     27.706 |     1.5
   11 |   0.5974 |     18.298 |   0.7966 |     25.603 |     1.7
   12 |   0.5482 |     16.754 |   0.7988 |     24.985 |     1.8
   13 |   0.5161 |     15.807 |   0.7793 |     24.830 |     2.0
   14 |   0.4659 |     14.269 |   0.7918 |     24.861 |     2.2
   15 |   0.4386 |     13.201 |   0.7789 |     23.624 |     2.3
   16 |   0.4270 |     13.102 |   0.7635 |     22.944 |     2.5
   17 |   0.3746 |     11.076 |   0.7931 |     23.408 |     2.6
   18 |   0.3618 |     10.584 |   0.7514 |     21.985 |     2.8
   19 |   0.3298 |      9.998 |   0.7793 |     22.356 |     2.9
   20 |   0.2948 |      8.799 |   0.7953 |     22.758 |     3.1
   21 |   0.2796 |      8.394 |   0.7984 |     22.604 |     3.2
   22 |   0.2741 |      8.240 |   0.7902 |     22.263 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,386

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1548 |     55.563 |   1.4873 |     44.280 |     0.2
    2 |   1.4476 |     42.893 |   1.3222 |     41.682 |     0.4
    3 |   1.3084 |     40.320 |   1.2330 |     39.518 |     0.6
    4 |   1.2211 |     38.294 |   1.1494 |     36.456 |     0.8
    5 |   1.1439 |     35.836 |   1.1005 |     34.879 |     1.0
    6 |   1.0821 |     33.541 |   1.0527 |     33.364 |     1.2
    7 |   1.0328 |     32.255 |   1.0363 |     33.271 |     1.4
    8 |   0.9794 |     30.234 |   0.9876 |     31.880 |     1.6
    9 |   0.9246 |     28.844 |   0.9673 |     31.664 |     1.8
   10 |   0.8753 |     27.261 |   0.9417 |     30.519 |     2.1
   11 |   0.8343 |     25.860 |   0.9114 |     29.375 |     2.3
   12 |   0.7953 |     24.666 |   0.8933 |     28.850 |     2.5
   13 |   0.7559 |     23.609 |   0.8910 |     28.571 |     2.7
   14 |   0.7142 |     22.323 |   0.8793 |     27.829 |     2.9
   15 |   0.6839 |     21.299 |   0.9057 |     28.231 |     3.1
   16 |   0.6486 |     20.357 |   0.8816 |     26.809 |     3.3
   17 |   0.6262 |     19.366 |   0.8871 |     27.149 |     3.5
   18 |   0.6000 |     18.747 |   0.8644 |     26.438 |     3.7
   19 |   0.5703 |     17.778 |   0.8559 |     25.912 |     3.9
   20 |   0.5396 |     17.094 |   0.8721 |     26.036 |     4.1
   21 |   0.5212 |     16.371 |   0.8703 |     25.881 |     4.3
   22 |   0.4948 |     15.500 |   0.8582 |     24.675 |     4.5
   23 |   0.4819 |     15.035 |   0.8587 |     25.046 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 436,962

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8119 |     68.452 |   1.9727 |     48.825 |     0.1
    2 |   1.8747 |     47.147 |   1.5860 |     44.341 |     0.2
    3 |   1.6141 |     44.760 |   1.4676 |     43.383 |     0.3
    4 |   1.4941 |     43.594 |   1.3897 |     41.589 |     0.4
    5 |   1.4154 |     42.050 |   1.3242 |     39.920 |     0.5
    6 |   1.3536 |     40.774 |   1.2794 |     39.270 |     0.6
    7 |   1.3012 |     39.548 |   1.2431 |     38.404 |     0.7
    8 |   1.2529 |     38.392 |   1.2120 |     37.817 |     0.8
    9 |   1.2138 |     37.336 |   1.1776 |     36.827 |     0.9
   10 |   1.1776 |     36.131 |   1.1519 |     36.240 |     1.0
   11 |   1.1444 |     35.337 |   1.1245 |     35.096 |     1.1
   12 |   1.1178 |     34.319 |   1.1070 |     35.158 |     1.2
   13 |   1.0852 |     33.372 |   1.0821 |     34.045 |     1.3
   14 |   1.0533 |     32.474 |   1.0894 |     35.250 |     1.4
   15 |   1.0277 |     31.740 |   1.0640 |     33.952 |     1.5
   16 |   1.0019 |     30.661 |   1.0456 |     33.148 |     1.7
   17 |   0.9774 |     30.207 |   1.0149 |     32.035 |     1.8
   18 |   0.9507 |     29.473 |   1.0124 |     31.756 |     1.9
   19 |   0.9305 |     29.041 |   0.9958 |     31.849 |     2.0
   20 |   0.9063 |     28.515 |   0.9944 |     31.200 |     2.1
   21 |   0.8869 |     27.557 |   0.9882 |     30.983 |     2.2
   22 |   0.8692 |     27.168 |   0.9802 |     30.581 |     2.3
   23 |   0.8444 |     26.259 |   0.9640 |     30.519 |     2.4
   24 |   0.8341 |     26.035 |   0.9558 |     29.716 |     2.5
   25 |   0.8109 |     25.181 |   0.9566 |     30.025 |     2.6
   26 |   0.7972 |     24.885 |   0.9367 |     29.004 |     2.7
   27 |   0.7787 |     23.938 |   0.9444 |     29.468 |     2.8
   28 |   0.7656 |     24.080 |   0.9364 |     29.066 |     2.9
   29 |   0.7397 |     22.969 |   0.9355 |     29.375 |     3.0
   30 |   0.7371 |     23.281 |   0.9273 |     28.571 |     3.1
   31 |   0.7155 |     22.202 |   0.9171 |     28.293 |     3.2
   32 |   0.6964 |     21.885 |   0.9201 |     27.767 |     3.3
   33 |   0.6883 |     21.485 |   0.9278 |     28.108 |     3.4
   34 |   0.6792 |     21.562 |   0.9230 |     28.200 |     3.5
   35 |   0.6683 |     20.811 |   0.9128 |     27.551 |     3.6
   36 |   0.6544 |     20.116 |   0.9110 |     27.798 |     3.7
   37 |   0.6479 |     20.384 |   0.9205 |     27.273 |     3.8
   38 |   0.6251 |     19.443 |   0.9064 |     26.994 |     3.9
   39 |   0.6120 |     19.048 |   0.9106 |     26.964 |     4.0
   40 |   0.6106 |     19.229 |   0.9014 |     27.118 |     4.1
   41 |   0.5998 |     19.005 |   0.9287 |     27.025 |     4.2
   42 |   0.5864 |     18.682 |   0.9242 |     26.840 |     4.3
   43 |   0.5776 |     18.326 |   0.9252 |     26.778 |     4.4
   44 |   0.5773 |     18.145 |   0.9346 |     26.562 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,778

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6290 |     46.906 |   1.2846 |     41.806 |     0.1
    2 |   1.2121 |     40.336 |   1.1845 |     40.662 |     0.3
    3 |   1.1159 |     38.130 |   1.0837 |     35.776 |     0.4
    4 |   1.0288 |     35.085 |   1.0238 |     34.694 |     0.6
    5 |   0.9648 |     32.802 |   0.9503 |     33.550 |     0.7
    6 |   0.9081 |     30.984 |   0.9214 |     31.694 |     0.9
    7 |   0.8578 |     29.128 |   0.8967 |     29.932 |     1.0
    8 |   0.8206 |     27.946 |   0.8790 |     30.427 |     1.2
    9 |   0.7838 |     26.511 |   0.8618 |     30.179 |     1.4
   10 |   0.7368 |     25.203 |   0.8013 |     27.767 |     1.5
   11 |   0.6965 |     23.976 |   0.8022 |     27.489 |     1.7
   12 |   0.6607 |     22.689 |   0.8074 |     27.118 |     1.8
   13 |   0.6358 |     21.666 |   0.7656 |     26.160 |     2.0
   14 |   0.6061 |     20.565 |   0.7887 |     25.727 |     2.1
   15 |   0.5805 |     19.799 |   0.7602 |     24.521 |     2.3
   16 |   0.5604 |     19.098 |   0.7469 |     24.799 |     2.4
   17 |   0.5387 |     18.413 |   0.7239 |     23.408 |     2.6
   18 |   0.4971 |     16.727 |   0.7182 |     23.995 |     2.7
   19 |   0.4728 |     16.141 |   0.7358 |     23.129 |     2.9
   20 |   0.4629 |     15.867 |   0.7255 |     23.408 |     3.0
   21 |   0.4306 |     14.696 |   0.7163 |     22.665 |     3.2
   22 |   0.4403 |     15.177 |   0.7356 |     22.727 |     3.3
   23 |   0.3970 |     13.644 |   0.7101 |     21.552 |     3.5
   24 |   0.3673 |     12.615 |   0.7239 |     20.810 |     3.6
   25 |   0.3692 |     12.681 |   0.7393 |     22.294 |     3.8
   26 |   0.3710 |     12.796 |   0.7436 |     21.305 |     3.9
   27 |   0.3246 |     11.016 |   0.7446 |     20.810 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,122

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0653 |     53.208 |   1.4390 |     43.939 |     0.2
    2 |   1.4187 |     42.712 |   1.2943 |     41.156 |     0.3
    3 |   1.2970 |     39.931 |   1.2181 |     38.621 |     0.5
    4 |   1.2135 |     37.976 |   1.1619 |     37.353 |     0.6
    5 |   1.1408 |     36.000 |   1.1062 |     35.560 |     0.8
    6 |   1.0869 |     34.363 |   1.0615 |     34.508 |     0.9
    7 |   1.0340 |     32.288 |   1.0351 |     33.241 |     1.1
    8 |   0.9836 |     31.357 |   0.9974 |     32.808 |     1.3
    9 |   0.9322 |     29.512 |   0.9745 |     32.437 |     1.4
   10 |   0.8888 |     28.126 |   0.9499 |     31.076 |     1.6
   11 |   0.8496 |     26.621 |   0.9415 |     30.179 |     1.7
   12 |   0.8156 |     25.761 |   0.9223 |     30.365 |     1.9
   13 |   0.7823 |     24.814 |   0.8817 |     27.798 |     2.0
   14 |   0.7458 |     23.440 |   0.8883 |     28.479 |     2.2
   15 |   0.7091 |     22.449 |   0.8847 |     27.891 |     2.4
   16 |   0.6796 |     21.293 |   0.8665 |     27.737 |     2.5
   17 |   0.6514 |     20.406 |   0.8410 |     26.345 |     2.7
   18 |   0.6273 |     19.645 |   0.8614 |     27.273 |     2.8
   19 |   0.6026 |     19.098 |   0.8551 |     26.685 |     3.0
   20 |   0.5780 |     18.123 |   0.8373 |     26.469 |     3.2
   21 |   0.5492 |     17.121 |   0.8561 |     25.356 |     3.3
   22 |   0.5300 |     16.858 |   0.8468 |     26.623 |     3.5
   23 |   0.5068 |     15.933 |   0.8496 |     26.221 |     3.6
   24 |   0.4870 |     15.325 |   0.8445 |     25.387 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,122

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0882 |     53.548 |   1.4514 |     43.785 |     0.1
    2 |   1.4272 |     43.085 |   1.3001 |     40.569 |     0.2
    3 |   1.3033 |     40.183 |   1.2180 |     38.126 |     0.4
    4 |   1.2158 |     38.058 |   1.1502 |     36.271 |     0.5
    5 |   1.1511 |     36.055 |   1.1106 |     35.436 |     0.6
    6 |   1.0862 |     33.853 |   1.0695 |     34.323 |     0.8
    7 |   1.0420 |     32.665 |   1.0304 |     33.117 |     0.9
    8 |   0.9876 |     31.236 |   0.9899 |     32.313 |     1.0
    9 |   0.9392 |     29.774 |   0.9661 |     31.076 |     1.1
   10 |   0.9038 |     28.428 |   0.9458 |     30.952 |     1.3
   11 |   0.8702 |     27.447 |   0.9162 |     29.499 |     1.4
   12 |   0.8215 |     25.991 |   0.9104 |     29.716 |     1.5
   13 |   0.8015 |     25.531 |   0.9047 |     28.973 |     1.7
   14 |   0.7536 |     24.080 |   0.8714 |     27.582 |     1.8
   15 |   0.7306 |     22.936 |   0.8810 |     28.602 |     1.9
   16 |   0.6981 |     22.279 |   0.8646 |     27.489 |     2.0
   17 |   0.6654 |     21.217 |   0.8573 |     26.902 |     2.2
   18 |   0.6440 |     20.154 |   0.8304 |     26.407 |     2.3
   19 |   0.6154 |     19.503 |   0.8377 |     25.665 |     2.4
   20 |   0.5927 |     18.490 |   0.8403 |     25.665 |     2.5
   21 |   0.5726 |     18.019 |   0.8390 |     25.788 |     2.7
   22 |   0.5449 |     17.116 |   0.8397 |     25.046 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 470,434

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6699 |     48.073 |   1.2972 |     41.280 |     0.1
    2 |   1.2003 |     39.427 |   1.1620 |     38.745 |     0.3
    3 |   1.0867 |     36.011 |   1.0454 |     34.570 |     0.5
    4 |   0.9885 |     32.791 |   0.9915 |     33.890 |     0.6
    5 |   0.9290 |     31.121 |   0.9387 |     32.313 |     0.8
    6 |   0.8746 |     29.117 |   0.8991 |     30.705 |     0.9
    7 |   0.8296 |     28.050 |   0.9069 |     29.901 |     1.1
    8 |   0.7820 |     25.942 |   0.8703 |     28.819 |     1.2
    9 |   0.7510 |     25.476 |   0.8149 |     27.582 |     1.4
   10 |   0.7060 |     23.883 |   0.7997 |     27.025 |     1.5
   11 |   0.6822 |     22.952 |   0.7777 |     26.562 |     1.7
   12 |   0.6397 |     21.753 |   0.7962 |     26.438 |     1.9
   13 |   0.6090 |     20.171 |   0.7979 |     26.221 |     2.0
   14 |   0.6088 |     20.516 |   0.7611 |     25.356 |     2.2
   15 |   0.5669 |     19.284 |   0.7561 |     25.015 |     2.3
   16 |   0.5305 |     17.948 |   0.7623 |     23.531 |     2.5
   17 |   0.5120 |     17.378 |   0.7669 |     24.119 |     2.6
   18 |   0.4800 |     16.349 |   0.7485 |     23.500 |     2.8
   19 |   0.4757 |     16.223 |   0.7558 |     23.253 |     2.9
   20 |   0.4500 |     15.391 |   0.7702 |     23.191 |     3.1
   21 |   0.4250 |     14.422 |   0.7713 |     23.593 |     3.3
   22 |   0.4170 |     14.477 |   0.7755 |     23.006 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 386,722

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7411 |     49.113 |   1.2799 |     42.393 |     0.1
    2 |   1.2552 |     40.714 |   1.1915 |     39.147 |     0.2
    3 |   1.1570 |     38.080 |   1.0953 |     36.116 |     0.3
    4 |   1.0967 |     36.454 |   1.0420 |     35.714 |     0.4
    5 |   1.0405 |     34.669 |   1.0179 |     33.766 |     0.5
    6 |   0.9796 |     33.235 |   0.9636 |     32.870 |     0.6
    7 |   0.9397 |     31.691 |   0.9246 |     31.571 |     0.7
    8 |   0.8999 |     29.939 |   0.9008 |     31.107 |     0.8
    9 |   0.8609 |     28.701 |   0.8726 |     29.685 |     0.8
   10 |   0.8382 |     28.521 |   0.8501 |     29.004 |     0.9
   11 |   0.7976 |     26.747 |   0.8829 |     30.458 |     1.0
   12 |   0.7791 |     25.887 |   0.8361 |     27.984 |     1.1
   13 |   0.7319 |     24.847 |   0.8338 |     28.139 |     1.2
   14 |   0.7113 |     24.239 |   0.8080 |     26.469 |     1.3
   15 |   0.6809 |     22.958 |   0.8343 |     27.118 |     1.4
   16 |   0.6624 |     22.492 |   0.8221 |     26.747 |     1.5
   17 |   0.6347 |     21.288 |   0.8134 |     26.129 |     1.6
   18 |   0.6171 |     20.844 |   0.8034 |     26.098 |     1.7
   19 |   0.5855 |     20.034 |   0.7755 |     24.675 |     1.8
   20 |   0.5634 |     19.289 |   0.7643 |     24.985 |     1.9
   21 |   0.5493 |     18.528 |   0.7828 |     24.335 |     2.0
   22 |   0.5497 |     18.703 |   0.7481 |     23.408 |     2.1
   23 |   0.5154 |     17.499 |   0.7573 |     23.840 |     2.2
   24 |   0.5075 |     17.132 |   0.7605 |     23.284 |     2.3
   25 |   0.4736 |     16.251 |   0.7916 |     24.150 |     2.4
   26 |   0.4603 |     15.725 |   0.7859 |     23.902 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,778

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3457 |     58.273 |   1.7049 |     45.671 |     0.1
    2 |   1.5534 |     43.320 |   1.4631 |     41.960 |     0.3
    3 |   1.3895 |     40.949 |   1.3451 |     39.332 |     0.4
    4 |   1.2890 |     38.491 |   1.2762 |     38.652 |     0.6
    5 |   1.2166 |     36.810 |   1.2162 |     37.446 |     0.7
    6 |   1.1437 |     34.905 |   1.1697 |     35.714 |     0.9
    7 |   1.0868 |     33.103 |   1.1175 |     34.354 |     1.0
    8 |   1.0287 |     31.384 |   1.0659 |     32.962 |     1.2
    9 |   0.9811 |     29.714 |   1.0329 |     31.664 |     1.4
   10 |   0.9305 |     28.351 |   1.0064 |     31.756 |     1.5
   11 |   0.8878 |     26.960 |   0.9814 |     30.643 |     1.7
   12 |   0.8380 |     25.307 |   0.9592 |     29.994 |     1.8
   13 |   0.8005 |     24.190 |   0.9399 |     29.468 |     2.0
   14 |   0.7629 |     22.881 |   0.9343 |     29.004 |     2.1
   15 |   0.7335 |     22.257 |   0.9226 |     29.128 |     2.3
   16 |   0.6976 |     21.030 |   0.8901 |     27.644 |     2.4
   17 |   0.6633 |     19.842 |   0.8785 |     27.211 |     2.6
   18 |   0.6448 |     19.317 |   0.8879 |     27.644 |     2.7
   19 |   0.6084 |     18.183 |   0.8728 |     26.778 |     2.9
   20 |   0.5768 |     17.099 |   0.8765 |     27.613 |     3.0
   21 |   0.5603 |     16.727 |   0.8691 |     26.809 |     3.2
   22 |   0.5324 |     15.736 |   0.8689 |     26.531 |     3.3
   23 |   0.5106 |     15.205 |   0.8696 |     26.964 |     3.5
   24 |   0.4969 |     15.024 |   0.8544 |     25.850 |     3.6
   25 |   0.4709 |     13.809 |   0.8437 |     25.850 |     3.8
   26 |   0.4439 |     13.135 |   0.8383 |     25.541 |     3.9
   27 |   0.4321 |     12.774 |   0.8466 |     25.077 |     4.1
   28 |   0.4166 |     12.155 |   0.8633 |     25.417 |     4.2
   29 |   0.4005 |     11.821 |   0.8701 |     25.046 |     4.4
   30 |   0.3866 |     11.350 |   0.8657 |     24.737 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 420,194

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8054 |     69.295 |   2.1025 |     48.330 |     0.2
    2 |   1.9156 |     46.917 |   1.6049 |     45.393 |     0.3
    3 |   1.6136 |     44.497 |   1.4737 |     42.981 |     0.5
    4 |   1.4930 |     43.035 |   1.3965 |     41.744 |     0.6
    5 |   1.4118 |     41.672 |   1.3373 |     40.445 |     0.8
    6 |   1.3506 |     40.375 |   1.2897 |     39.765 |     1.0
    7 |   1.2969 |     39.493 |   1.2460 |     38.466 |     1.1
    8 |   1.2447 |     37.697 |   1.2200 |     37.972 |     1.3
    9 |   1.2033 |     36.848 |   1.1830 |     36.920 |     1.4
   10 |   1.1697 |     36.224 |   1.1624 |     36.487 |     1.6
   11 |   1.1335 |     34.779 |   1.1382 |     35.529 |     1.8
   12 |   1.1019 |     34.155 |   1.1146 |     35.096 |     1.9
   13 |   1.0677 |     33.142 |   1.1096 |     35.900 |     2.1
   14 |   1.0428 |     32.249 |   1.0866 |     35.220 |     2.3
   15 |   1.0190 |     31.302 |   1.0610 |     33.179 |     2.4
   16 |   0.9859 |     30.453 |   1.0584 |     33.952 |     2.6
   17 |   0.9703 |     29.950 |   1.0393 |     32.406 |     2.7
   18 |   0.9408 |     29.134 |   1.0355 |     32.715 |     2.9
   19 |   0.9209 |     28.241 |   1.0147 |     32.127 |     3.1
   20 |   0.8957 |     27.486 |   1.0084 |     31.725 |     3.2
   21 |   0.8723 |     26.900 |   0.9975 |     31.818 |     3.4
   22 |   0.8602 |     26.769 |   0.9957 |     31.385 |     3.5
   23 |   0.8350 |     25.591 |   0.9908 |     30.860 |     3.7
   24 |   0.8220 |     25.307 |   0.9690 |     30.550 |     3.9
   25 |   0.8041 |     24.929 |   0.9742 |     30.860 |     4.0
   26 |   0.7768 |     23.757 |   0.9804 |     31.200 |     4.2
   27 |   0.7637 |     23.631 |   0.9780 |     30.674 |     4.3
   28 |   0.7462 |     23.029 |   0.9742 |     30.581 |     4.5
   29 |   0.7252 |     22.372 |   0.9654 |     30.241 |     4.7
   30 |   0.7137 |     22.202 |   0.9626 |     30.148 |     4.8
   31 |   0.7011 |     21.792 |   0.9745 |     29.159 |     5.0
   32 |   0.6949 |     21.742 |   0.9560 |     29.592 |     5.2
   33 |   0.6735 |     20.861 |   0.9774 |     29.314 |     5.3
   34 |   0.6614 |     20.472 |   0.9638 |     28.973 |     5.5
   35 |   0.6406 |     19.935 |   0.9676 |     28.355 |     5.6
   36 |   0.6282 |     19.541 |   0.9742 |     28.850 |     5.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,075,746

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5404 |     46.748 |   1.2572 |     42.022 |     0.1
    2 |   1.2126 |     40.325 |   1.1289 |     37.199 |     0.3
    3 |   1.1198 |     37.653 |   1.0641 |     35.374 |     0.5
    4 |   1.0512 |     35.178 |   1.0169 |     33.890 |     0.6
    5 |   1.0040 |     34.100 |   1.0051 |     34.106 |     0.8
    6 |   0.9527 |     32.184 |   0.9843 |     33.333 |     0.9
    7 |   0.9145 |     30.678 |   0.9276 |     31.602 |     1.1
    8 |   0.8911 |     30.180 |   0.8951 |     30.519 |     1.2
    9 |   0.8576 |     29.128 |   0.8898 |     30.612 |     1.4
   10 |   0.8175 |     27.732 |   0.8712 |     29.901 |     1.5
   11 |   0.7938 |     27.163 |   0.8518 |     28.664 |     1.7
   12 |   0.7520 |     25.389 |   0.8657 |     29.499 |     1.8
   13 |   0.7310 |     24.984 |   0.8287 |     28.169 |     2.0
   14 |   0.7150 |     24.365 |   0.8728 |     28.448 |     2.1
   15 |   0.7123 |     24.097 |   0.8178 |     27.304 |     2.3
   16 |   0.6752 |     23.089 |   0.8222 |     27.675 |     2.4
   17 |   0.6465 |     22.191 |   0.8404 |     27.706 |     2.6
   18 |   0.6379 |     21.479 |   0.8202 |     25.850 |     2.7
   19 |   0.6044 |     20.751 |   0.8044 |     26.809 |     2.9
   20 |   0.5934 |     20.094 |   0.8414 |     27.427 |     3.0
   21 |   0.5646 |     18.988 |   0.7708 |     25.294 |     3.2
   22 |   0.5500 |     18.922 |   0.8116 |     25.974 |     3.4
   23 |   0.5286 |     17.844 |   0.7734 |     24.923 |     3.5
   24 |   0.5079 |     17.827 |   0.7916 |     25.232 |     3.7
   25 |   0.4884 |     16.710 |   0.8022 |     25.850 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 552,546

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6752 |     48.226 |   1.3091 |     41.991 |     0.1
    2 |   1.2650 |     41.218 |   1.1742 |     39.147 |     0.3
    3 |   1.1636 |     38.633 |   1.1089 |     36.735 |     0.4
    4 |   1.0884 |     36.076 |   1.0547 |     35.343 |     0.6
    5 |   1.0259 |     34.379 |   1.0230 |     33.766 |     0.7
    6 |   0.9803 |     32.928 |   0.9669 |     32.437 |     0.9
    7 |   0.9256 |     30.705 |   0.9269 |     31.664 |     1.0
    8 |   0.8931 |     30.070 |   0.9037 |     31.385 |     1.1
    9 |   0.8558 |     28.345 |   0.8956 |     30.025 |     1.3
   10 |   0.8138 |     27.272 |   0.8757 |     29.901 |     1.4
   11 |   0.7842 |     26.484 |   0.8787 |     28.510 |     1.6
   12 |   0.7596 |     25.526 |   0.8482 |     27.767 |     1.7
   13 |   0.7274 |     24.606 |   0.8141 |     27.304 |     1.9
   14 |   0.6937 |     23.565 |   0.7785 |     25.603 |     2.0
   15 |   0.6668 |     22.213 |   0.7736 |     25.108 |     2.1
   16 |   0.6422 |     21.698 |   0.7961 |     26.376 |     2.3
   17 |   0.6206 |     20.888 |   0.7877 |     26.283 |     2.4
   18 |   0.5858 |     19.864 |   0.7648 |     24.335 |     2.6
   19 |   0.5649 |     19.196 |   0.7593 |     23.995 |     2.7
   20 |   0.5340 |     17.680 |   0.7657 |     23.964 |     2.9
   21 |   0.5122 |     17.406 |   0.7658 |     24.459 |     3.0
   22 |   0.4967 |     17.055 |   0.7686 |     24.304 |     3.1
   23 |   0.4780 |     16.245 |   0.7605 |     23.593 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,218

Training started
X_train.shape: torch.Size([3044, 649])
Y_train.shape: torch.Size([3044, 7])
X_dev.shape: torch.Size([539, 702])
Y_dev.shape: torch.Size([539, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6155 |     48.549 |   1.2872 |     41.899 |     0.2
    2 |   1.2607 |     41.902 |   1.1989 |     39.579 |     0.4
    3 |   1.1743 |     39.592 |   1.1415 |     38.374 |     0.6
    4 |   1.1170 |     38.075 |   1.1183 |     37.786 |     0.8
    5 |   1.0747 |     36.432 |   1.0912 |     36.920 |     1.0
    6 |   1.0338 |     35.458 |   1.0073 |     34.818 |     1.2
    7 |   0.9985 |     33.892 |   0.9784 |     33.457 |     1.4
    8 |   0.9523 |     32.413 |   0.9718 |     32.777 |     1.6
    9 |   0.9290 |     31.450 |   0.9509 |     32.962 |     1.8
   10 |   0.9071 |     31.056 |   0.9307 |     32.498 |     2.0
   11 |   0.8705 |     29.659 |   0.9196 |     31.354 |     2.2
   12 |   0.8505 |     29.221 |   0.8755 |     29.901 |     2.4
   13 |   0.8268 |     28.296 |   0.8872 |     29.808 |     2.6
   14 |   0.7944 |     27.316 |   0.8692 |     29.808 |     2.8
   15 |   0.7678 |     25.953 |   0.8433 |     29.097 |     3.0
   16 |   0.7585 |     25.986 |   0.8458 |     28.386 |     3.2
   17 |   0.7341 |     24.759 |   0.8239 |     28.324 |     3.4
   18 |   0.7039 |     24.009 |   0.8099 |     28.046 |     3.6
   19 |   0.6864 |     23.472 |   0.7810 |     25.696 |     3.8
   20 |   0.6725 |     22.969 |   0.7886 |     27.273 |     4.0
   21 |   0.6529 |     22.328 |   0.7791 |     26.345 |     4.2
   22 |   0.6179 |     21.069 |   0.7828 |     26.036 |     4.4
   23 |   0.6075 |     20.839 |   0.7635 |     25.294 |     4.6
   24 |   0.5835 |     19.919 |   0.7397 |     24.923 |     4.8
   25 |   0.5773 |     19.815 |   0.7570 |     24.923 |     5.0
   26 |   0.5513 |     18.802 |   0.7756 |     24.954 |     5.2
   27 |   0.5351 |     18.380 |   0.7465 |     24.181 |     5.4
   28 |   0.5221 |     17.926 |   0.7576 |     24.397 |     5.6
Early stopping

