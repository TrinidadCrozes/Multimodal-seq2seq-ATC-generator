Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,762

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6088 |     47.966 |   1.2668 |     41.160 |     0.1
    2 |   1.2526 |     40.981 |   1.1533 |     39.165 |     0.3
    3 |   1.1516 |     38.361 |   1.0955 |     38.275 |     0.4
    4 |   1.0864 |     36.771 |   1.0577 |     35.697 |     0.5
    5 |   1.0443 |     35.433 |   1.0073 |     34.469 |     0.7
    6 |   0.9885 |     33.542 |   0.9815 |     33.640 |     0.8
    7 |   0.9435 |     31.787 |   0.9860 |     34.193 |     0.9
    8 |   0.9124 |     30.620 |   0.9525 |     32.167 |     1.1
    9 |   0.8781 |     29.693 |   0.9335 |     31.215 |     1.2
   10 |   0.8423 |     28.684 |   0.9031 |     30.939 |     1.3
   11 |   0.8033 |     27.341 |   0.9219 |     31.001 |     1.5
   12 |   0.7937 |     26.853 |   0.9171 |     30.847 |     1.6
   13 |   0.7502 |     25.773 |   0.8883 |     29.405 |     1.7
   14 |   0.7298 |     24.874 |   0.8765 |     28.760 |     1.9
   15 |   0.6986 |     23.564 |   0.8939 |     29.773 |     2.0
   16 |   0.6867 |     23.432 |   0.9313 |     30.387 |     2.1
   17 |   0.6581 |     22.363 |   0.8938 |     28.729 |     2.3
   18 |   0.6342 |     21.804 |   0.8694 |     28.269 |     2.4
   19 |   0.6289 |     21.678 |   0.8695 |     28.453 |     2.5
   20 |   0.5984 |     20.422 |   0.8963 |     28.392 |     2.7
   21 |   0.6131 |     20.822 |   0.9194 |     29.619 |     2.8
   22 |   0.5674 |     19.490 |   0.8852 |     27.747 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 437,026

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7338 |     67.917 |   1.9100 |     45.427 |     0.1
    2 |   1.8312 |     46.316 |   1.5504 |     44.107 |     0.2
    3 |   1.5928 |     44.967 |   1.4316 |     42.541 |     0.3
    4 |   1.4798 |     43.465 |   1.3543 |     41.037 |     0.4
    5 |   1.4008 |     41.738 |   1.2974 |     39.932 |     0.5
    6 |   1.3413 |     40.614 |   1.2525 |     38.428 |     0.6
    7 |   1.2857 |     38.942 |   1.2158 |     37.446 |     0.7
    8 |   1.2428 |     38.109 |   1.1849 |     36.587 |     0.8
    9 |   1.2030 |     36.738 |   1.1507 |     35.727 |     0.9
   10 |   1.1645 |     35.713 |   1.1391 |     35.758 |     1.0
   11 |   1.1334 |     35.077 |   1.1188 |     35.052 |     1.1
   12 |   1.1019 |     34.013 |   1.0956 |     34.500 |     1.2
   13 |   1.0736 |     33.098 |   1.0859 |     33.794 |     1.4
   14 |   1.0431 |     32.264 |   1.0710 |     33.241 |     1.5
   15 |   1.0245 |     32.072 |   1.0591 |     33.548 |     1.6
   16 |   0.9871 |     30.236 |   1.0294 |     32.044 |     1.7
   17 |   0.9669 |     29.890 |   1.0265 |     31.676 |     1.8
   18 |   0.9394 |     28.876 |   1.0263 |     32.014 |     1.9
   19 |   0.9219 |     28.651 |   1.0198 |     31.737 |     2.0
   20 |   0.8950 |     27.511 |   1.0151 |     31.553 |     2.1
   21 |   0.8783 |     27.259 |   1.0162 |     31.584 |     2.2
   22 |   0.8599 |     26.924 |   1.0003 |     30.663 |     2.3
   23 |   0.8397 |     26.190 |   0.9851 |     30.018 |     2.4
   24 |   0.8200 |     25.625 |   0.9935 |     30.632 |     2.5
   25 |   0.8056 |     25.143 |   0.9807 |     30.141 |     2.6
   26 |   0.7877 |     24.545 |   0.9820 |     30.264 |     2.7
   27 |   0.7702 |     23.980 |   0.9767 |     28.944 |     2.8
   28 |   0.7538 |     23.843 |   0.9782 |     29.190 |     2.9
   29 |   0.7374 |     23.109 |   0.9782 |     28.791 |     3.0
   30 |   0.7265 |     22.632 |   0.9719 |     29.343 |     3.1
   31 |   0.7043 |     22.303 |   0.9842 |     29.711 |     3.2
   32 |   0.6965 |     21.667 |   0.9755 |     29.220 |     3.3
   33 |   0.6850 |     21.343 |   0.9650 |     27.624 |     3.4
   34 |   0.6674 |     20.899 |   0.9845 |     29.067 |     3.6
   35 |   0.6595 |     20.746 |   0.9868 |     28.484 |     3.7
   36 |   0.6451 |     20.269 |   0.9884 |     28.238 |     3.8
   37 |   0.6320 |     19.704 |   0.9956 |     28.668 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 535,842

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5759 |     46.579 |   1.2582 |     41.989 |     0.1
    2 |   1.1977 |     39.984 |   1.1603 |     39.104 |     0.2
    3 |   1.0932 |     36.952 |   1.0574 |     36.034 |     0.3
    4 |   1.0085 |     33.936 |   1.0330 |     34.346 |     0.4
    5 |   0.9342 |     31.584 |   0.9484 |     32.689 |     0.6
    6 |   0.8717 |     29.227 |   0.9189 |     32.413 |     0.7
    7 |   0.8266 |     28.141 |   0.8995 |     29.711 |     0.8
    8 |   0.7885 |     26.886 |   0.8773 |     29.865 |     0.9
    9 |   0.7362 |     25.208 |   0.8420 |     28.729 |     1.0
   10 |   0.6931 |     23.273 |   0.8294 |     27.655 |     1.1
   11 |   0.6590 |     22.473 |   0.8134 |     27.041 |     1.2
   12 |   0.6264 |     21.464 |   0.8029 |     26.028 |     1.3
   13 |   0.5941 |     20.104 |   0.8072 |     26.120 |     1.4
   14 |   0.5665 |     19.402 |   0.8037 |     25.568 |     1.6
   15 |   0.5381 |     18.492 |   0.7823 |     25.506 |     1.7
   16 |   0.5213 |     17.977 |   0.7699 |     23.910 |     1.8
   17 |   0.4940 |     17.078 |   0.7534 |     23.542 |     1.9
   18 |   0.4655 |     16.107 |   0.7721 |     23.450 |     2.0
   19 |   0.4485 |     15.444 |   0.7848 |     24.494 |     2.1
   20 |   0.4146 |     14.342 |   0.7699 |     22.652 |     2.2
   21 |   0.4051 |     14.265 |   0.7532 |     22.621 |     2.3
   22 |   0.3894 |     13.575 |   0.8061 |     23.481 |     2.4
   23 |   0.3760 |     13.004 |   0.8043 |     23.235 |     2.5
   24 |   0.3600 |     12.286 |   0.7975 |     23.450 |     2.7
   25 |   0.3429 |     11.815 |   0.7940 |     22.192 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 535,842

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5420 |     61.195 |   1.8362 |     44.322 |     0.2
    2 |   1.7597 |     45.384 |   1.5305 |     42.419 |     0.3
    3 |   1.5480 |     43.383 |   1.4146 |     41.344 |     0.5
    4 |   1.4330 |     41.661 |   1.3376 |     40.638 |     0.7
    5 |   1.3464 |     39.923 |   1.2712 |     38.735 |     0.8
    6 |   1.2858 |     38.750 |   1.2136 |     37.385 |     1.0
    7 |   1.2257 |     36.968 |   1.1837 |     35.973 |     1.2
    8 |   1.1773 |     35.894 |   1.1413 |     35.175 |     1.3
    9 |   1.1325 |     34.578 |   1.1165 |     34.408 |     1.5
   10 |   1.0899 |     32.933 |   1.0947 |     34.408 |     1.7
   11 |   1.0518 |     32.050 |   1.0824 |     33.395 |     1.8
   12 |   1.0168 |     31.064 |   1.0583 |     33.211 |     2.0
   13 |   0.9830 |     30.093 |   1.0366 |     32.167 |     2.2
   14 |   0.9504 |     28.975 |   1.0355 |     32.259 |     2.3
   15 |   0.9197 |     27.917 |   1.0117 |     31.093 |     2.5
   16 |   0.8933 |     27.418 |   0.9997 |     30.479 |     2.7
   17 |   0.8686 |     26.562 |   0.9906 |     30.694 |     2.8
   18 |   0.8432 |     25.718 |   0.9783 |     29.619 |     3.0
   19 |   0.8147 |     24.781 |   0.9915 |     30.233 |     3.2
   20 |   0.7895 |     24.128 |   0.9676 |     29.650 |     3.3
   21 |   0.7708 |     23.750 |   0.9716 |     29.466 |     3.5
   22 |   0.7451 |     22.758 |   0.9702 |     29.374 |     3.7
   23 |   0.7223 |     22.346 |   0.9799 |     29.435 |     3.8
   24 |   0.7055 |     21.700 |   0.9662 |     29.128 |     4.0
   25 |   0.6797 |     20.740 |   0.9695 |     28.913 |     4.2
   26 |   0.6628 |     20.636 |   0.9630 |     28.115 |     4.3
   27 |   0.6472 |     20.219 |   0.9740 |     28.944 |     4.5
   28 |   0.6313 |     19.282 |   0.9590 |     27.808 |     4.6
   29 |   0.6137 |     19.035 |   0.9680 |     28.607 |     4.8
   30 |   0.5957 |     18.564 |   0.9547 |     27.471 |     5.0
   31 |   0.5831 |     17.944 |   0.9651 |     27.870 |     5.1
   32 |   0.5711 |     17.692 |   0.9599 |     28.115 |     5.3
   33 |   0.5524 |     17.270 |   0.9821 |     27.256 |     5.5
   34 |   0.5412 |     16.694 |   0.9875 |     27.440 |     5.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,514

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0249 |     53.218 |   1.4138 |     41.713 |     0.2
    2 |   1.3259 |     40.071 |   1.2353 |     37.815 |     0.3
    3 |   1.1802 |     36.469 |   1.1334 |     35.390 |     0.5
    4 |   1.0678 |     32.911 |   1.0778 |     33.917 |     0.6
    5 |   0.9836 |     30.362 |   1.0188 |     31.921 |     0.8
    6 |   0.9000 |     27.643 |   0.9609 |     29.405 |     0.9
    7 |   0.8329 |     25.630 |   0.9228 |     28.913 |     1.1
    8 |   0.7650 |     23.553 |   0.8862 |     26.888 |     1.3
    9 |   0.7037 |     21.179 |   0.8705 |     27.041 |     1.4
   10 |   0.6474 |     19.622 |   0.8435 |     26.397 |     1.6
   11 |   0.5966 |     18.054 |   0.8203 |     25.445 |     1.7
   12 |   0.5547 |     16.732 |   0.8221 |     25.721 |     1.9
   13 |   0.5142 |     15.439 |   0.8082 |     24.770 |     2.0
   14 |   0.4679 |     14.232 |   0.8015 |     24.340 |     2.2
   15 |   0.4313 |     12.780 |   0.7911 |     23.082 |     2.4
   16 |   0.4119 |     12.752 |   0.8062 |     24.524 |     2.5
   17 |   0.3654 |     11.146 |   0.7988 |     23.419 |     2.7
   18 |   0.3491 |     10.647 |   0.8215 |     23.788 |     2.8
   19 |   0.3176 |      9.298 |   0.8186 |     24.432 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 470,498

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5400 |     62.802 |   1.8501 |     44.751 |     0.1
    2 |   1.6657 |     44.359 |   1.5231 |     42.879 |     0.2
    3 |   1.4577 |     41.349 |   1.3865 |     40.086 |     0.3
    4 |   1.3369 |     38.997 |   1.2978 |     38.152 |     0.5
    5 |   1.2471 |     36.908 |   1.2397 |     36.955 |     0.6
    6 |   1.1735 |     34.868 |   1.1854 |     34.715 |     0.7
    7 |   1.1117 |     33.438 |   1.1366 |     34.039 |     0.8
    8 |   1.0556 |     31.848 |   1.0948 |     32.842 |     0.9
    9 |   1.0072 |     30.302 |   1.0659 |     32.505 |     1.0
   10 |   0.9598 |     28.898 |   1.0297 |     31.860 |     1.1
   11 |   0.9211 |     27.988 |   1.0146 |     30.847 |     1.3
   12 |   0.8747 |     26.502 |   0.9960 |     30.510 |     1.4
   13 |   0.8370 |     25.181 |   0.9772 |     30.694 |     1.5
   14 |   0.8043 |     24.359 |   0.9644 |     29.497 |     1.6
   15 |   0.7655 |     22.977 |   0.9509 |     29.466 |     1.7
   16 |   0.7322 |     22.297 |   0.9438 |     28.883 |     1.8
   17 |   0.7106 |     21.453 |   0.9226 |     28.821 |     1.9
   18 |   0.6796 |     20.658 |   0.9070 |     27.317 |     2.1
   19 |   0.6511 |     19.633 |   0.9037 |     27.563 |     2.2
   20 |   0.6272 |     18.914 |   0.8972 |     27.686 |     2.3
   21 |   0.6061 |     18.344 |   0.8876 |     26.366 |     2.4
   22 |   0.5706 |     17.116 |   0.8841 |     26.857 |     2.5
   23 |   0.5560 |     16.848 |   0.8890 |     26.458 |     2.6
   24 |   0.5337 |     16.332 |   0.8929 |     25.998 |     2.7
   25 |   0.5158 |     15.471 |   0.8727 |     25.936 |     2.9
   26 |   0.4941 |     14.715 |   0.8949 |     25.660 |     3.0
   27 |   0.4812 |     14.370 |   0.8626 |     25.292 |     3.1
   28 |   0.4565 |     13.438 |   0.8801 |     25.568 |     3.2
   29 |   0.4462 |     13.224 |   0.8744 |     25.015 |     3.3
   30 |   0.4270 |     12.692 |   0.8838 |     24.985 |     3.4
   31 |   0.4059 |     12.122 |   0.8888 |     24.862 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 386,786

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6345 |     47.462 |   1.2713 |     42.020 |     0.1
    2 |   1.2035 |     39.638 |   1.1465 |     37.815 |     0.2
    3 |   1.0793 |     36.009 |   1.0701 |     35.206 |     0.3
    4 |   0.9855 |     32.549 |   0.9899 |     32.904 |     0.4
    5 |   0.9078 |     30.422 |   0.9677 |     32.505 |     0.4
    6 |   0.8392 |     28.070 |   0.9041 |     30.018 |     0.5
    7 |   0.7742 |     26.075 |   0.8803 |     29.374 |     0.6
    8 |   0.7228 |     24.764 |   0.8538 |     28.115 |     0.7
    9 |   0.6820 |     22.895 |   0.8241 |     27.041 |     0.8
   10 |   0.6420 |     21.908 |   0.8235 |     25.936 |     0.9
   11 |   0.5996 |     20.154 |   0.8150 |     26.120 |     1.0
   12 |   0.5649 |     19.041 |   0.8016 |     24.770 |     1.1
   13 |   0.5319 |     18.125 |   0.8125 |     25.599 |     1.1
   14 |   0.4989 |     16.897 |   0.8018 |     24.002 |     1.2
   15 |   0.4683 |     15.784 |   0.8079 |     24.831 |     1.3
   16 |   0.4624 |     15.784 |   0.8178 |     24.463 |     1.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 437,026

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7267 |     68.580 |   1.9826 |     47.360 |     0.1
    2 |   1.8653 |     46.212 |   1.5682 |     42.296 |     0.3
    3 |   1.6002 |     44.112 |   1.4414 |     41.559 |     0.4
    4 |   1.4810 |     42.791 |   1.3585 |     40.945 |     0.6
    5 |   1.4000 |     41.552 |   1.3048 |     40.086 |     0.7
    6 |   1.3389 |     40.471 |   1.2461 |     38.920 |     0.8
    7 |   1.2852 |     39.304 |   1.2029 |     37.569 |     1.0
    8 |   1.2381 |     37.791 |   1.1686 |     37.201 |     1.1
    9 |   1.1907 |     36.689 |   1.1336 |     35.390 |     1.2
   10 |   1.1511 |     35.537 |   1.1170 |     34.377 |     1.4
   11 |   1.1168 |     34.457 |   1.1045 |     34.899 |     1.5
   12 |   1.0856 |     33.668 |   1.0658 |     33.211 |     1.7
   13 |   1.0560 |     32.791 |   1.0479 |     32.689 |     1.8
   14 |   1.0183 |     31.639 |   1.0392 |     32.996 |     1.9
   15 |   0.9911 |     30.768 |   1.0148 |     32.044 |     2.1
   16 |   0.9686 |     30.214 |   1.0001 |     31.246 |     2.2
   17 |   0.9409 |     29.507 |   0.9908 |     31.277 |     2.4
   18 |   0.9138 |     28.542 |   0.9832 |     30.602 |     2.5
   19 |   0.8942 |     27.966 |   0.9862 |     31.246 |     2.6
   20 |   0.8724 |     27.423 |   0.9594 |     29.773 |     2.8
   21 |   0.8478 |     26.398 |   0.9647 |     29.988 |     2.9
   22 |   0.8293 |     25.680 |   0.9465 |     29.343 |     3.1
   23 |   0.8099 |     25.307 |   0.9486 |     29.343 |     3.2
   24 |   0.7940 |     24.742 |   0.9566 |     29.312 |     3.3
   25 |   0.7797 |     24.117 |   0.9419 |     28.975 |     3.5
   26 |   0.7651 |     23.964 |   0.9306 |     28.576 |     3.6
   27 |   0.7450 |     23.399 |   0.9499 |     28.392 |     3.7
   28 |   0.7272 |     23.141 |   0.9341 |     29.220 |     3.9
   29 |   0.7160 |     22.418 |   0.9486 |     28.975 |     4.0
   30 |   0.6979 |     21.880 |   0.9181 |     27.716 |     4.2
   31 |   0.6826 |     21.497 |   0.9193 |     27.379 |     4.3
   32 |   0.6685 |     21.102 |   0.9334 |     27.993 |     4.4
   33 |   0.6574 |     20.905 |   0.9362 |     28.023 |     4.6
   34 |   0.6480 |     20.526 |   0.9307 |     27.808 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6303 |     47.368 |   1.2836 |     42.204 |     0.1
    2 |   1.2090 |     40.038 |   1.1571 |     39.012 |     0.2
    3 |   1.1021 |     36.864 |   1.0711 |     36.618 |     0.3
    4 |   1.0050 |     33.355 |   1.0165 |     34.469 |     0.4
    5 |   0.9322 |     31.190 |   0.9536 |     31.645 |     0.5
    6 |   0.8658 |     28.849 |   0.9385 |     31.952 |     0.6
    7 |   0.8231 |     27.664 |   0.8876 |     29.619 |     0.7
    8 |   0.7742 |     25.932 |   0.8418 |     28.913 |     0.8
    9 |   0.7273 |     24.468 |   0.8442 |     27.440 |     0.9
   10 |   0.6817 |     22.681 |   0.8110 |     26.550 |     1.1
   11 |   0.6533 |     22.018 |   0.8186 |     27.225 |     1.2
   12 |   0.6138 |     20.938 |   0.8332 |     27.041 |     1.3
   13 |   0.5946 |     20.159 |   0.8044 |     26.182 |     1.4
   14 |   0.5648 |     19.068 |   0.8130 |     25.967 |     1.5
   15 |   0.5313 |     17.752 |   0.7891 |     24.647 |     1.6
   16 |   0.5075 |     17.089 |   0.7901 |     24.156 |     1.7
   17 |   0.4802 |     16.387 |   0.8041 |     23.880 |     1.8
   18 |   0.4487 |     15.208 |   0.8043 |     24.187 |     1.9
   19 |   0.4428 |     15.307 |   0.7960 |     24.800 |     2.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,730

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9665 |     51.217 |   1.4271 |     41.866 |     0.1
    2 |   1.3401 |     40.647 |   1.2568 |     38.244 |     0.3
    3 |   1.2012 |     37.248 |   1.1714 |     35.820 |     0.4
    4 |   1.0976 |     34.062 |   1.1011 |     34.837 |     0.6
    5 |   1.0076 |     31.080 |   1.0442 |     31.921 |     0.7
    6 |   0.9338 |     28.865 |   0.9905 |     31.001 |     0.9
    7 |   0.8670 |     26.639 |   0.9566 |     29.773 |     1.0
    8 |   0.8081 |     24.797 |   0.9264 |     29.374 |     1.2
    9 |   0.7457 |     22.697 |   0.9016 |     28.085 |     1.3
   10 |   0.6982 |     21.086 |   0.8818 |     27.808 |     1.5
   11 |   0.6416 |     19.227 |   0.8588 |     25.967 |     1.6
   12 |   0.5958 |     17.922 |   0.8499 |     25.998 |     1.8
   13 |   0.5569 |     16.760 |   0.8568 |     26.550 |     1.9
   14 |   0.5109 |     15.208 |   0.8456 |     24.831 |     2.1
   15 |   0.4691 |     14.260 |   0.8279 |     24.125 |     2.2
   16 |   0.4497 |     13.498 |   0.8353 |     24.401 |     2.4
   17 |   0.4102 |     12.105 |   0.8457 |     24.923 |     2.5
   18 |   0.3778 |     11.332 |   0.8842 |     25.015 |     2.7
   19 |   0.3603 |     10.833 |   0.8394 |     24.309 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 535,842

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6762 |     48.284 |   1.2895 |     41.651 |     0.2
    2 |   1.2623 |     41.376 |   1.1771 |     39.441 |     0.3
    3 |   1.1709 |     39.112 |   1.1009 |     36.894 |     0.5
    4 |   1.1008 |     36.891 |   1.0570 |     35.328 |     0.7
    5 |   1.0470 |     35.181 |   1.0272 |     35.236 |     0.8
    6 |   0.9893 |     33.487 |   0.9652 |     32.136 |     1.0
    7 |   0.9432 |     31.913 |   0.9405 |     32.228 |     1.2
    8 |   0.9081 |     30.806 |   0.9260 |     31.400 |     1.3
    9 |   0.8728 |     29.616 |   0.8865 |     28.944 |     1.5
   10 |   0.8295 |     28.125 |   0.8734 |     30.018 |     1.6
   11 |   0.7983 |     26.919 |   0.8499 |     29.098 |     1.8
   12 |   0.7759 |     26.102 |   0.8356 |     27.502 |     2.0
   13 |   0.7441 |     24.956 |   0.8526 |     28.729 |     2.1
   14 |   0.7168 |     24.139 |   0.8254 |     27.287 |     2.3
   15 |   0.6862 |     23.355 |   0.8000 |     26.550 |     2.5
   16 |   0.6661 |     22.654 |   0.7825 |     26.151 |     2.6
   17 |   0.6372 |     21.853 |   0.7918 |     25.752 |     2.8
   18 |   0.6110 |     20.789 |   0.8003 |     25.292 |     3.0
   19 |   0.5932 |     20.214 |   0.7774 |     24.555 |     3.1
   20 |   0.5595 |     19.211 |   0.7861 |     24.279 |     3.3
   21 |   0.5531 |     18.964 |   0.7745 |     24.616 |     3.5
   22 |   0.5241 |     17.593 |   0.8109 |     24.800 |     3.6
   23 |   0.4923 |     16.754 |   0.7845 |     23.511 |     3.8
   24 |   0.4809 |     16.365 |   0.7840 |     23.665 |     4.0
   25 |   0.4679 |     15.773 |   0.7896 |     24.371 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,458

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5020 |     46.458 |   1.2153 |     40.823 |     0.2
    2 |   1.1517 |     39.030 |   1.1002 |     37.477 |     0.3
    3 |   1.0603 |     36.206 |   1.0756 |     36.832 |     0.5
    4 |   0.9878 |     33.476 |   1.0254 |     35.328 |     0.7
    5 |   0.9303 |     31.738 |   0.9392 |     31.983 |     0.9
    6 |   0.8713 |     29.770 |   0.9173 |     30.847 |     1.1
    7 |   0.8373 |     28.470 |   0.9084 |     30.448 |     1.2
    8 |   0.7921 |     27.083 |   0.8809 |     29.190 |     1.4
    9 |   0.7700 |     26.513 |   0.8766 |     29.067 |     1.6
   10 |   0.7339 |     25.356 |   0.8359 |     28.085 |     1.8
   11 |   0.7076 |     24.671 |   0.8433 |     27.716 |     1.9
   12 |   0.6743 |     23.284 |   0.8133 |     26.796 |     2.1
   13 |   0.6461 |     22.264 |   0.7978 |     26.611 |     2.3
   14 |   0.6235 |     21.776 |   0.8079 |     26.581 |     2.5
   15 |   0.6073 |     20.833 |   0.8383 |     28.300 |     2.6
   16 |   0.5900 |     20.707 |   0.7710 |     25.322 |     2.8
   17 |   0.5728 |     19.852 |   0.7917 |     25.414 |     3.0
   18 |   0.5568 |     19.008 |   0.8014 |     24.893 |     3.2
   19 |   0.5274 |     17.971 |   0.7982 |     25.721 |     3.3
   20 |   0.5146 |     17.933 |   0.7685 |     24.279 |     3.5
   21 |   0.4956 |     17.259 |   0.7868 |     24.800 |     3.7
   22 |   0.4922 |     17.001 |   0.8036 |     25.476 |     3.9
   23 |   0.4729 |     16.393 |   0.8005 |     24.432 |     4.1
   24 |   0.4560 |     15.641 |   0.8037 |     24.156 |     4.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 602,594

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6803 |     48.257 |   1.2845 |     41.191 |     0.1
    2 |   1.2708 |     41.530 |   1.1815 |     39.288 |     0.3
    3 |   1.1722 |     39.254 |   1.1137 |     37.416 |     0.4
    4 |   1.1074 |     37.533 |   1.0618 |     35.973 |     0.5
    5 |   1.0610 |     36.107 |   1.0288 |     34.807 |     0.6
    6 |   1.0097 |     34.550 |   1.0251 |     35.175 |     0.8
    7 |   0.9732 |     33.405 |   0.9903 |     34.592 |     0.9
    8 |   0.9324 |     31.502 |   0.9588 |     33.395 |     1.0
    9 |   0.8990 |     30.329 |   0.9276 |     32.198 |     1.1
   10 |   0.8731 |     29.885 |   0.9102 |     31.093 |     1.3
   11 |   0.8278 |     28.207 |   0.8709 |     29.558 |     1.4
   12 |   0.8023 |     27.138 |   0.8675 |     29.312 |     1.5
   13 |   0.7714 |     26.414 |   0.8760 |     29.711 |     1.7
   14 |   0.7378 |     25.000 |   0.8503 |     27.931 |     1.8
   15 |   0.7127 |     24.342 |   0.8521 |     27.532 |     1.9
   16 |   0.6899 |     23.564 |   0.8094 |     26.581 |     2.0
   17 |   0.6589 |     22.248 |   0.8154 |     25.568 |     2.2
   18 |   0.6373 |     22.007 |   0.8187 |     25.629 |     2.3
   19 |   0.6036 |     20.395 |   0.8100 |     25.783 |     2.4
   20 |   0.5899 |     20.132 |   0.7940 |     25.322 |     2.5
   21 |   0.5717 |     19.567 |   0.7948 |     25.292 |     2.7
   22 |   0.5379 |     18.366 |   0.8329 |     25.169 |     2.8
   23 |   0.5330 |     18.152 |   0.8009 |     25.721 |     2.9
   24 |   0.5069 |     17.237 |   0.8174 |     24.770 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,874

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1005 |     54.342 |   1.4431 |     42.449 |     0.1
    2 |   1.3529 |     40.976 |   1.2616 |     39.319 |     0.2
    3 |   1.2068 |     37.368 |   1.1579 |     35.359 |     0.3
    4 |   1.1090 |     34.589 |   1.0993 |     34.592 |     0.5
    5 |   1.0210 |     31.404 |   1.0430 |     32.505 |     0.6
    6 |   0.9533 |     29.781 |   0.9977 |     31.308 |     0.7
    7 |   0.8866 |     27.692 |   0.9727 |     30.878 |     0.8
    8 |   0.8293 |     25.581 |   0.9475 |     29.804 |     0.9
    9 |   0.7806 |     24.156 |   0.9395 |     30.264 |     1.0
   10 |   0.7308 |     22.533 |   0.8911 |     28.453 |     1.2
   11 |   0.6812 |     20.707 |   0.8861 |     27.808 |     1.3
   12 |   0.6386 |     19.644 |   0.8607 |     26.581 |     1.4
   13 |   0.6038 |     18.427 |   0.8476 |     26.581 |     1.5
   14 |   0.5639 |     17.116 |   0.8298 |     24.893 |     1.6
   15 |   0.5286 |     16.124 |   0.8417 |     25.905 |     1.7
   16 |   0.4891 |     14.726 |   0.8398 |     25.844 |     1.9
   17 |   0.4613 |     13.646 |   0.8328 |     24.678 |     2.0
   18 |   0.4372 |     13.240 |   0.8487 |     24.800 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 535,842

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3942 |     57.873 |   1.7013 |     43.554 |     0.1
    2 |   1.5648 |     43.394 |   1.4476 |     41.774 |     0.2
    3 |   1.4027 |     41.223 |   1.3424 |     40.301 |     0.3
    4 |   1.3035 |     39.041 |   1.2686 |     38.766 |     0.4
    5 |   1.2273 |     37.166 |   1.2139 |     37.078 |     0.5
    6 |   1.1574 |     35.312 |   1.1685 |     34.899 |     0.7
    7 |   1.0952 |     33.465 |   1.1230 |     34.438 |     0.8
    8 |   1.0391 |     31.924 |   1.0795 |     33.456 |     0.9
    9 |   0.9823 |     29.901 |   1.0481 |     32.320 |     1.0
   10 |   0.9378 |     28.531 |   1.0242 |     31.768 |     1.1
   11 |   0.8862 |     26.815 |   1.0037 |     31.707 |     1.2
   12 |   0.8431 |     25.406 |   0.9693 |     29.711 |     1.3
   13 |   0.8042 |     24.364 |   0.9630 |     29.435 |     1.4
   14 |   0.7686 |     23.333 |   0.9444 |     29.374 |     1.5
   15 |   0.7299 |     21.957 |   0.9356 |     28.607 |     1.6
   16 |   0.7003 |     21.173 |   0.9314 |     29.312 |     1.8
   17 |   0.6688 |     20.208 |   0.9205 |     29.006 |     1.9
   18 |   0.6310 |     18.958 |   0.8925 |     27.440 |     2.0
   19 |   0.6031 |     18.130 |   0.9014 |     27.287 |     2.1
   20 |   0.5781 |     17.401 |   0.9038 |     27.133 |     2.2
   21 |   0.5545 |     16.738 |   0.8938 |     26.642 |     2.3
   22 |   0.5284 |     15.800 |   0.8862 |     26.243 |     2.4
   23 |   0.5030 |     14.973 |   0.8856 |     26.581 |     2.5
   24 |   0.4786 |     14.200 |   0.9008 |     26.796 |     2.6
   25 |   0.4619 |     13.832 |   0.9039 |     26.980 |     2.7
   26 |   0.4445 |     13.311 |   0.8896 |     25.752 |     2.8
   27 |   0.4179 |     12.292 |   0.9004 |     25.998 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,498

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8017 |     50.987 |   1.3194 |     42.296 |     0.2
    2 |   1.2950 |     42.242 |   1.1981 |     40.608 |     0.3
    3 |   1.1892 |     39.567 |   1.1289 |     38.428 |     0.5
    4 |   1.1183 |     37.264 |   1.0820 |     35.912 |     0.7
    5 |   1.0596 |     35.636 |   1.0487 |     35.236 |     0.8
    6 |   1.0089 |     33.553 |   0.9960 |     34.377 |     1.0
    7 |   0.9746 |     33.152 |   0.9875 |     32.627 |     1.2
    8 |   0.9287 |     31.179 |   0.9667 |     32.842 |     1.3
    9 |   0.8906 |     29.803 |   0.9223 |     31.737 |     1.5
   10 |   0.8616 |     28.893 |   0.9363 |     31.614 |     1.7
   11 |   0.8174 |     27.336 |   0.8962 |     30.663 |     1.8
   12 |   0.7928 |     26.776 |   0.8556 |     28.207 |     2.0
   13 |   0.7624 |     25.362 |   0.8655 |     29.497 |     2.2
   14 |   0.7370 |     24.868 |   0.8240 |     27.624 |     2.3
   15 |   0.7066 |     23.410 |   0.8366 |     27.379 |     2.5
   16 |   0.6828 |     23.218 |   0.8046 |     26.335 |     2.7
   17 |   0.6511 |     21.689 |   0.8162 |     25.905 |     2.8
   18 |   0.6382 |     21.584 |   0.8160 |     25.322 |     3.0
   19 |   0.6155 |     21.140 |   0.7900 |     25.476 |     3.2
   20 |   0.5802 |     19.611 |   0.8093 |     25.353 |     3.3
   21 |   0.5683 |     19.304 |   0.7951 |     23.788 |     3.5
   22 |   0.5466 |     18.394 |   0.8013 |     24.770 |     3.7
   23 |   0.5244 |     18.004 |   0.7784 |     23.112 |     3.9
   24 |   0.5094 |     17.231 |   0.8177 |     24.770 |     4.0
   25 |   0.4959 |     16.875 |   0.8147 |     24.279 |     4.2
   26 |   0.4695 |     15.954 |   0.8264 |     24.862 |     4.4
   27 |   0.4488 |     15.499 |   0.8289 |     24.217 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7012 |     65.395 |   2.0054 |     45.150 |     0.1
    2 |   1.7472 |     44.819 |   1.5596 |     42.050 |     0.3
    3 |   1.4939 |     41.689 |   1.4224 |     39.871 |     0.4
    4 |   1.3727 |     39.616 |   1.3320 |     39.288 |     0.6
    5 |   1.2804 |     37.593 |   1.2676 |     37.538 |     0.7
    6 |   1.2045 |     35.751 |   1.2148 |     36.863 |     0.9
    7 |   1.1372 |     33.646 |   1.1597 |     34.622 |     1.0
    8 |   1.0814 |     32.061 |   1.1240 |     33.671 |     1.2
    9 |   1.0283 |     30.406 |   1.0847 |     32.443 |     1.3
   10 |   0.9776 |     29.221 |   1.0572 |     32.014 |     1.5
   11 |   0.9380 |     28.152 |   1.0380 |     31.522 |     1.6
   12 |   0.8921 |     26.749 |   1.0168 |     30.724 |     1.8
   13 |   0.8540 |     25.757 |   0.9904 |     30.448 |     1.9
   14 |   0.8159 |     24.660 |   0.9626 |     29.190 |     2.0
   15 |   0.7843 |     23.438 |   0.9673 |     29.128 |     2.2
   16 |   0.7534 |     22.516 |   0.9579 |     29.466 |     2.3
   17 |   0.7210 |     21.667 |   0.9346 |     28.054 |     2.5
   18 |   0.6915 |     20.581 |   0.9394 |     28.361 |     2.6
   19 |   0.6615 |     19.726 |   0.9221 |     27.164 |     2.8
   20 |   0.6452 |     19.529 |   0.9044 |     27.225 |     2.9
   21 |   0.6080 |     17.955 |   0.9222 |     26.918 |     3.1
   22 |   0.5900 |     17.571 |   0.9254 |     27.287 |     3.2
   23 |   0.5720 |     17.253 |   0.9147 |     26.581 |     3.4
   24 |   0.5423 |     16.250 |   0.8965 |     26.366 |     3.5
   25 |   0.5241 |     15.603 |   0.8925 |     25.629 |     3.7
   26 |   0.5094 |     15.192 |   0.8942 |     25.967 |     3.8
   27 |   0.4875 |     14.457 |   0.8916 |     25.721 |     3.9
   28 |   0.4665 |     14.002 |   0.9183 |     26.581 |     4.1
   29 |   0.4467 |     13.383 |   0.8967 |     25.445 |     4.2
   30 |   0.4336 |     12.829 |   0.9113 |     25.844 |     4.4
   31 |   0.4097 |     12.198 |   0.9179 |     25.107 |     4.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5490 |     61.672 |   1.8646 |     44.751 |     0.1
    2 |   1.6703 |     44.320 |   1.5190 |     42.818 |     0.2
    3 |   1.4700 |     42.319 |   1.3970 |     40.884 |     0.3
    4 |   1.3594 |     40.411 |   1.3042 |     38.490 |     0.4
    5 |   1.2709 |     37.878 |   1.2434 |     37.017 |     0.5
    6 |   1.1989 |     35.981 |   1.1896 |     35.697 |     0.6
    7 |   1.1411 |     34.578 |   1.1447 |     33.640 |     0.7
    8 |   1.0847 |     32.325 |   1.1217 |     34.285 |     0.8
    9 |   1.0382 |     31.036 |   1.0829 |     31.921 |     0.9
   10 |   0.9931 |     30.137 |   1.0684 |     32.014 |     1.0
   11 |   0.9484 |     28.416 |   1.0311 |     31.983 |     1.2
   12 |   0.9081 |     27.500 |   1.0165 |     31.093 |     1.3
   13 |   0.8704 |     26.195 |   0.9895 |     30.724 |     1.4
   14 |   0.8416 |     25.367 |   0.9831 |     30.110 |     1.5
   15 |   0.8087 |     24.468 |   0.9716 |     30.233 |     1.6
   16 |   0.7756 |     23.701 |   0.9697 |     29.742 |     1.7
   17 |   0.7501 |     22.911 |   0.9494 |     30.141 |     1.8
   18 |   0.7168 |     21.513 |   0.9399 |     28.484 |     1.9
   19 |   0.6891 |     20.811 |   0.9227 |     28.791 |     2.0
   20 |   0.6629 |     19.890 |   0.9285 |     27.931 |     2.1
   21 |   0.6431 |     19.452 |   0.9138 |     27.471 |     2.2
   22 |   0.6153 |     18.547 |   0.9118 |     26.918 |     2.3
   23 |   0.5960 |     18.081 |   0.9098 |     27.072 |     2.4
   24 |   0.5729 |     17.111 |   0.8975 |     26.980 |     2.5
   25 |   0.5546 |     16.667 |   0.8901 |     26.366 |     2.6
   26 |   0.5339 |     16.162 |   0.9102 |     26.949 |     2.7
   27 |   0.5188 |     15.570 |   0.8950 |     26.519 |     2.9
   28 |   0.4951 |     14.726 |   0.8880 |     26.028 |     3.0
   29 |   0.4830 |     14.627 |   0.8963 |     25.752 |     3.1
   30 |   0.4589 |     13.607 |   0.8889 |     25.015 |     3.2
   31 |   0.4473 |     13.481 |   0.9276 |     26.243 |     3.3
   32 |   0.4337 |     13.136 |   0.9018 |     25.107 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 386,786

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4857 |     60.839 |   1.7922 |     43.800 |     0.1
    2 |   1.6202 |     43.673 |   1.4916 |     41.774 |     0.2
    3 |   1.4349 |     41.754 |   1.3770 |     40.117 |     0.3
    4 |   1.3305 |     39.402 |   1.2944 |     38.766 |     0.3
    5 |   1.2516 |     37.719 |   1.2491 |     38.459 |     0.4
    6 |   1.1832 |     36.003 |   1.1920 |     36.157 |     0.5
    7 |   1.1250 |     34.189 |   1.1525 |     34.868 |     0.6
    8 |   1.0706 |     32.171 |   1.1026 |     33.917 |     0.7
    9 |   1.0236 |     31.053 |   1.0724 |     33.180 |     0.8
   10 |   0.9770 |     29.501 |   1.0430 |     31.891 |     0.9
   11 |   0.9337 |     28.295 |   1.0194 |     31.277 |     1.0
   12 |   0.8989 |     27.451 |   0.9951 |     29.988 |     1.0
   13 |   0.8575 |     25.970 |   0.9761 |     29.619 |     1.1
   14 |   0.8261 |     24.682 |   0.9553 |     29.190 |     1.2
   15 |   0.7940 |     23.953 |   0.9339 |     29.036 |     1.3
   16 |   0.7610 |     22.845 |   0.9283 |     29.006 |     1.4
   17 |   0.7301 |     22.122 |   0.9055 |     27.532 |     1.5
   18 |   0.7088 |     21.217 |   0.8969 |     28.023 |     1.6
   19 |   0.6783 |     20.274 |   0.8848 |     27.256 |     1.7
   20 |   0.6579 |     19.808 |   0.8754 |     27.133 |     1.8
   21 |   0.6312 |     19.189 |   0.8735 |     27.225 |     1.8
   22 |   0.6146 |     18.344 |   0.8745 |     26.489 |     1.9
   23 |   0.5879 |     17.719 |   0.8607 |     25.905 |     2.0
   24 |   0.5645 |     16.957 |   0.8565 |     25.905 |     2.1
   25 |   0.5533 |     16.562 |   0.8578 |     25.998 |     2.2
   26 |   0.5254 |     15.647 |   0.8667 |     25.599 |     2.3
   27 |   0.5105 |     15.038 |   0.8503 |     25.537 |     2.4
   28 |   0.4996 |     14.912 |   0.8680 |     25.353 |     2.5
   29 |   0.4765 |     14.397 |   0.8666 |     24.371 |     2.5
   30 |   0.4622 |     13.925 |   0.8522 |     24.831 |     2.6
   31 |   0.4487 |     13.383 |   0.8771 |     25.783 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,874

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4748 |     45.521 |   1.2035 |     40.055 |     0.1
    2 |   1.1731 |     39.090 |   1.1413 |     38.674 |     0.2
    3 |   1.0792 |     36.102 |   1.0423 |     35.021 |     0.3
    4 |   0.9929 |     33.569 |   0.9989 |     34.592 |     0.5
    5 |   0.9266 |     31.184 |   0.9488 |     31.614 |     0.6
    6 |   0.8646 |     29.485 |   0.9372 |     31.277 |     0.7
    7 |   0.8256 |     28.284 |   0.9007 |     30.970 |     0.8
    8 |   0.7879 |     26.853 |   0.8871 |     29.527 |     0.9
    9 |   0.7395 |     25.543 |   0.8678 |     28.729 |     1.0
   10 |   0.7205 |     24.408 |   0.8542 |     27.655 |     1.2
   11 |   0.6767 |     23.010 |   0.8249 |     27.440 |     1.3
   12 |   0.6477 |     22.330 |   0.8035 |     25.691 |     1.4
   13 |   0.6215 |     21.436 |   0.7951 |     25.752 |     1.5
   14 |   0.5951 |     20.351 |   0.7964 |     26.519 |     1.6
   15 |   0.5672 |     19.534 |   0.8283 |     26.734 |     1.7
   16 |   0.5402 |     18.257 |   0.8126 |     26.397 |     1.8
   17 |   0.5159 |     17.582 |   0.7761 |     24.125 |     2.0
   18 |   0.4915 |     16.711 |   0.7869 |     25.414 |     2.1
   19 |   0.4735 |     16.343 |   0.8048 |     24.401 |     2.2
   20 |   0.4540 |     15.740 |   0.7574 |     23.788 |     2.3
   21 |   0.4335 |     14.797 |   0.7882 |     23.910 |     2.4
   22 |   0.4259 |     14.819 |   0.8064 |     23.788 |     2.5
   23 |   0.3981 |     13.712 |   0.7892 |     23.051 |     2.7
   24 |   0.3846 |     13.202 |   0.7999 |     23.726 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6142 |     46.721 |   1.2726 |     41.866 |     0.1
    2 |   1.1987 |     39.682 |   1.1261 |     37.569 |     0.3
    3 |   1.0802 |     36.036 |   1.0519 |     35.021 |     0.4
    4 |   0.9851 |     32.719 |   0.9927 |     33.794 |     0.6
    5 |   0.9147 |     30.855 |   0.9638 |     32.320 |     0.7
    6 |   0.8634 |     28.728 |   0.9240 |     31.185 |     0.9
    7 |   0.8014 |     27.001 |   0.9126 |     30.018 |     1.0
    8 |   0.7561 |     25.197 |   0.8697 |     28.944 |     1.2
    9 |   0.7218 |     24.123 |   0.8818 |     28.422 |     1.3
   10 |   0.6800 |     22.829 |   0.8332 |     28.085 |     1.5
   11 |   0.6371 |     21.546 |   0.8102 |     25.599 |     1.6
   12 |   0.6102 |     20.713 |   0.8066 |     25.568 |     1.8
   13 |   0.5811 |     19.792 |   0.8146 |     25.721 |     1.9
   14 |   0.5561 |     19.030 |   0.7926 |     24.954 |     2.1
   15 |   0.5216 |     17.791 |   0.7767 |     24.033 |     2.2
   16 |   0.4965 |     16.891 |   0.8021 |     25.230 |     2.3
   17 |   0.4729 |     15.894 |   0.8120 |     24.432 |     2.5
   18 |   0.4658 |     15.817 |   0.8020 |     23.818 |     2.6
   19 |   0.4488 |     15.493 |   0.7776 |     23.542 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 535,842

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6637 |     48.026 |   1.3051 |     43.217 |     0.1
    2 |   1.2692 |     41.595 |   1.1784 |     39.533 |     0.2
    3 |   1.1669 |     39.221 |   1.0973 |     36.924 |     0.4
    4 |   1.0973 |     36.913 |   1.0367 |     35.666 |     0.5
    5 |   1.0419 |     35.252 |   1.0267 |     34.622 |     0.6
    6 |   0.9875 |     33.147 |   0.9901 |     35.236 |     0.7
    7 |   0.9560 |     32.094 |   0.9545 |     31.829 |     0.8
    8 |   0.9158 |     31.075 |   0.9436 |     31.891 |     0.9
    9 |   0.8770 |     30.022 |   0.9041 |     30.325 |     1.1
   10 |   0.8515 |     29.293 |   0.8991 |     29.650 |     1.2
   11 |   0.8162 |     27.774 |   0.8685 |     29.006 |     1.3
   12 |   0.7855 |     26.595 |   0.8560 |     29.128 |     1.4
   13 |   0.7654 |     26.162 |   0.8372 |     27.379 |     1.5
   14 |   0.7302 |     24.918 |   0.8614 |     28.913 |     1.6
   15 |   0.7109 |     24.156 |   0.8498 |     28.269 |     1.8
   16 |   0.6805 |     23.163 |   0.8266 |     27.287 |     1.9
   17 |   0.6604 |     22.445 |   0.8266 |     26.703 |     2.0
   18 |   0.6343 |     21.683 |   0.8112 |     26.796 |     2.1
   19 |   0.6122 |     21.118 |   0.8018 |     26.519 |     2.2
   20 |   0.5805 |     19.918 |   0.8052 |     25.568 |     2.4
   21 |   0.5627 |     19.518 |   0.8071 |     26.151 |     2.5
   22 |   0.5400 |     18.503 |   0.8098 |     25.138 |     2.6
   23 |   0.5288 |     18.443 |   0.7710 |     24.432 |     2.7
   24 |   0.5067 |     17.599 |   0.7981 |     23.818 |     2.8
   25 |   0.4854 |     16.672 |   0.7880 |     23.880 |     2.9
   26 |   0.4612 |     15.751 |   0.8237 |     24.555 |     3.1
   27 |   0.4505 |     15.466 |   0.8488 |     24.494 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 485,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6290 |     64.298 |   1.8614 |     48.066 |     0.1
    2 |   1.7717 |     46.754 |   1.5284 |     42.327 |     0.3
    3 |   1.5531 |     43.821 |   1.4061 |     41.314 |     0.4
    4 |   1.4376 |     41.738 |   1.3250 |     40.669 |     0.5
    5 |   1.3523 |     40.154 |   1.2566 |     38.029 |     0.7
    6 |   1.2830 |     38.640 |   1.2051 |     37.630 |     0.8
    7 |   1.2268 |     37.412 |   1.1644 |     36.065 |     0.9
    8 |   1.1760 |     36.058 |   1.1320 |     35.513 |     1.1
    9 |   1.1299 |     34.622 |   1.0973 |     33.824 |     1.2
   10 |   1.0912 |     33.448 |   1.0712 |     33.303 |     1.3
   11 |   1.0580 |     32.522 |   1.0485 |     32.781 |     1.5
   12 |   1.0164 |     31.113 |   1.0339 |     32.965 |     1.6
   13 |   0.9895 |     30.729 |   1.0176 |     31.768 |     1.7
   14 |   0.9540 |     29.890 |   1.0023 |     31.461 |     1.9
   15 |   0.9293 |     28.635 |   0.9901 |     31.891 |     2.0
   16 |   0.8983 |     27.840 |   0.9743 |     30.663 |     2.1
   17 |   0.8733 |     27.286 |   0.9746 |     30.479 |     2.3
   18 |   0.8487 |     26.376 |   0.9511 |     29.711 |     2.4
   19 |   0.8207 |     25.488 |   0.9543 |     29.681 |     2.5
   20 |   0.7976 |     24.890 |   0.9298 |     29.128 |     2.6
   21 |   0.7715 |     24.161 |   0.9410 |     29.190 |     2.8
   22 |   0.7575 |     23.668 |   0.9400 |     28.821 |     2.9
   23 |   0.7346 |     23.043 |   0.9228 |     28.791 |     3.0
   24 |   0.7168 |     22.259 |   0.9312 |     28.944 |     3.2
   25 |   0.6971 |     21.804 |   0.9146 |     28.269 |     3.3
   26 |   0.6750 |     21.020 |   0.9253 |     28.023 |     3.4
   27 |   0.6676 |     21.014 |   0.9008 |     27.778 |     3.6
   28 |   0.6407 |     20.225 |   0.9165 |     28.115 |     3.7
   29 |   0.6299 |     19.600 |   0.9071 |     27.594 |     3.8
   30 |   0.6066 |     18.810 |   0.9112 |     27.716 |     4.0
   31 |   0.5992 |     18.624 |   0.9166 |     26.980 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,273,250

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9780 |     51.513 |   1.4151 |     42.081 |     0.1
    2 |   1.3151 |     39.940 |   1.2375 |     38.735 |     0.3
    3 |   1.1723 |     35.965 |   1.1493 |     35.421 |     0.4
    4 |   1.0696 |     32.966 |   1.0909 |     34.561 |     0.6
    5 |   0.9856 |     30.367 |   1.0205 |     31.553 |     0.7
    6 |   0.9094 |     28.191 |   0.9684 |     30.724 |     0.9
    7 |   0.8455 |     26.113 |   0.9275 |     28.392 |     1.0
    8 |   0.7774 |     23.991 |   0.9092 |     27.655 |     1.2
    9 |   0.7261 |     22.467 |   0.8837 |     27.225 |     1.3
   10 |   0.6737 |     20.515 |   0.8377 |     25.875 |     1.5
   11 |   0.6306 |     19.271 |   0.8419 |     25.844 |     1.6
   12 |   0.5863 |     17.643 |   0.8445 |     26.059 |     1.7
   13 |   0.5454 |     16.787 |   0.8213 |     24.923 |     1.9
   14 |   0.5064 |     15.504 |   0.8016 |     24.033 |     2.0
   15 |   0.4714 |     14.304 |   0.8184 |     24.432 |     2.2
   16 |   0.4329 |     13.180 |   0.8164 |     24.187 |     2.3
   17 |   0.4116 |     12.500 |   0.8028 |     23.450 |     2.5
   18 |   0.3837 |     11.782 |   0.8088 |     23.603 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 386,786

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7083 |     48.766 |   1.2782 |     41.590 |     0.1
    2 |   1.2657 |     41.573 |   1.1944 |     40.485 |     0.3
    3 |   1.1632 |     38.432 |   1.1042 |     36.832 |     0.4
    4 |   1.0869 |     36.162 |   1.0367 |     35.144 |     0.5
    5 |   1.0190 |     34.413 |   1.0037 |     33.732 |     0.6
    6 |   0.9682 |     32.489 |   0.9663 |     32.597 |     0.8
    7 |   0.9161 |     31.086 |   0.9210 |     31.215 |     0.9
    8 |   0.8762 |     29.649 |   0.9040 |     29.405 |     1.0
    9 |   0.8395 |     27.900 |   0.8848 |     29.773 |     1.2
   10 |   0.7962 |     26.606 |   0.8648 |     28.453 |     1.3
   11 |   0.7769 |     25.998 |   0.8613 |     28.392 |     1.4
   12 |   0.7392 |     24.764 |   0.8546 |     28.668 |     1.5
   13 |   0.7101 |     23.832 |   0.8316 |     28.146 |     1.7
   14 |   0.6778 |     22.895 |   0.8255 |     27.041 |     1.8
   15 |   0.6424 |     22.050 |   0.8083 |     25.261 |     1.9
   16 |   0.6375 |     21.530 |   0.8327 |     27.133 |     2.1
   17 |   0.6001 |     20.291 |   0.7989 |     25.322 |     2.2
   18 |   0.5767 |     19.518 |   0.8105 |     25.752 |     2.3
   19 |   0.5531 |     18.980 |   0.7996 |     24.954 |     2.4
   20 |   0.5397 |     18.448 |   0.8540 |     25.660 |     2.6
   21 |   0.5174 |     17.538 |   0.8251 |     25.046 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,472,034

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0099 |     52.703 |   1.4041 |     40.424 |     0.2
    2 |   1.3071 |     39.572 |   1.2327 |     38.091 |     0.3
    3 |   1.1635 |     36.173 |   1.1406 |     35.513 |     0.5
    4 |   1.0568 |     32.993 |   1.0596 |     33.026 |     0.6
    5 |   0.9661 |     30.164 |   0.9990 |     31.983 |     0.8
    6 |   0.8908 |     28.059 |   0.9536 |     29.742 |     0.9
    7 |   0.8215 |     25.340 |   0.9238 |     28.821 |     1.1
    8 |   0.7598 |     23.580 |   0.8882 |     27.778 |     1.2
    9 |   0.7004 |     21.732 |   0.8568 |     26.888 |     1.4
   10 |   0.6484 |     20.016 |   0.8453 |     25.660 |     1.5
   11 |   0.6048 |     18.750 |   0.8300 |     25.292 |     1.7
   12 |   0.5574 |     17.105 |   0.8082 |     24.616 |     1.9
   13 |   0.5138 |     15.537 |   0.8161 |     24.217 |     2.0
   14 |   0.4811 |     14.819 |   0.7972 |     23.788 |     2.2
   15 |   0.4446 |     13.388 |   0.8037 |     24.401 |     2.3
   16 |   0.4093 |     12.379 |   0.8051 |     23.634 |     2.5
   17 |   0.3825 |     11.760 |   0.7902 |     23.389 |     2.6
   18 |   0.3543 |     10.625 |   0.8144 |     23.726 |     2.8
   19 |   0.3265 |      9.764 |   0.7987 |     22.959 |     2.9
   20 |   0.3050 |      9.167 |   0.7944 |     22.192 |     3.1
   21 |   0.2934 |      9.008 |   0.8309 |     22.560 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 485,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5625 |     46.382 |   1.2464 |     40.853 |     0.1
    2 |   1.1856 |     38.969 |   1.1597 |     39.165 |     0.2
    3 |   1.0632 |     35.181 |   1.0284 |     34.316 |     0.3
    4 |   0.9810 |     32.845 |   0.9825 |     33.241 |     0.4
    5 |   0.9049 |     30.510 |   0.9673 |     33.395 |     0.5
    6 |   0.8444 |     28.295 |   0.9007 |     29.957 |     0.5
    7 |   0.7856 |     26.261 |   0.8799 |     29.251 |     0.6
    8 |   0.7364 |     24.655 |   0.8703 |     28.392 |     0.7
    9 |   0.6869 |     23.240 |   0.8372 |     27.901 |     0.8
   10 |   0.6376 |     21.272 |   0.8144 |     26.796 |     0.9
   11 |   0.6004 |     20.049 |   0.7885 |     25.292 |     1.0
   12 |   0.5664 |     19.315 |   0.8079 |     25.445 |     1.1
   13 |   0.5330 |     18.103 |   0.8008 |     24.708 |     1.2
   14 |   0.5006 |     17.182 |   0.7751 |     24.678 |     1.3
   15 |   0.4700 |     15.921 |   0.7642 |     23.696 |     1.4
   16 |   0.4394 |     14.940 |   0.7771 |     23.481 |     1.4
   17 |   0.4151 |     14.178 |   0.7854 |     23.603 |     1.5
   18 |   0.3886 |     13.339 |   0.8229 |     25.322 |     1.6
   19 |   0.3708 |     12.741 |   0.8389 |     24.463 |     1.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,346

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5953 |     48.010 |   1.2950 |     42.879 |     0.2
    2 |   1.2777 |     42.484 |   1.1934 |     40.025 |     0.3
    3 |   1.2000 |     40.186 |   1.1502 |     39.042 |     0.5
    4 |   1.1438 |     38.706 |   1.1092 |     37.416 |     0.6
    5 |   1.0972 |     37.045 |   1.1020 |     36.372 |     0.8
    6 |   1.0459 |     35.499 |   1.0446 |     35.666 |     0.9
    7 |   1.0138 |     34.287 |   1.0211 |     34.438 |     1.1
    8 |   0.9721 |     32.988 |   0.9797 |     33.517 |     1.3
    9 |   0.9295 |     31.414 |   0.9857 |     33.241 |     1.4
   10 |   0.9027 |     30.312 |   0.9578 |     32.167 |     1.6
   11 |   0.8755 |     29.836 |   0.9349 |     31.277 |     1.7
   12 |   0.8587 |     29.276 |   0.9634 |     33.088 |     1.9
   13 |   0.8358 |     28.586 |   0.9085 |     31.338 |     2.1
   14 |   0.8027 |     27.451 |   0.9021 |     30.663 |     2.2
   15 |   0.7815 |     26.798 |   0.9268 |     31.707 |     2.4
   16 |   0.7653 |     25.746 |   0.8929 |     30.233 |     2.5
   17 |   0.7364 |     25.132 |   0.8980 |     30.080 |     2.7
   18 |   0.7172 |     24.770 |   0.8895 |     28.821 |     2.9
   19 |   0.6967 |     24.331 |   0.9373 |     30.417 |     3.0
   20 |   0.6871 |     23.728 |   0.8626 |     28.883 |     3.2
   21 |   0.6618 |     22.796 |   0.9199 |     29.988 |     3.3
   22 |   0.6262 |     21.524 |   0.8833 |     28.821 |     3.5
   23 |   0.6268 |     21.672 |   0.9043 |     28.637 |     3.6
   24 |   0.6102 |     21.146 |   0.9546 |     29.681 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,458

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2115 |     56.409 |   1.5100 |     43.984 |     0.2
    2 |   1.4874 |     43.893 |   1.3262 |     41.160 |     0.4
    3 |   1.3477 |     41.683 |   1.2283 |     39.042 |     0.6
    4 |   1.2520 |     38.986 |   1.1725 |     37.078 |     0.7
    5 |   1.1741 |     36.530 |   1.1218 |     36.403 |     0.9
    6 |   1.1094 |     34.797 |   1.0754 |     33.794 |     1.1
    7 |   1.0509 |     32.966 |   1.0476 |     33.517 |     1.3
    8 |   1.0003 |     31.595 |   1.0125 |     32.505 |     1.5
    9 |   0.9548 |     30.038 |   0.9868 |     31.430 |     1.7
   10 |   0.9122 |     28.646 |   0.9707 |     30.786 |     1.9
   11 |   0.8679 |     27.303 |   0.9507 |     29.006 |     2.1
   12 |   0.8293 |     26.042 |   0.9488 |     29.435 |     2.3
   13 |   0.7973 |     25.395 |   0.9309 |     29.312 |     2.4
   14 |   0.7642 |     24.304 |   0.9296 |     29.006 |     2.6
   15 |   0.7308 |     22.917 |   0.9175 |     27.655 |     2.8
   16 |   0.7006 |     21.875 |   0.9211 |     28.699 |     3.0
   17 |   0.6746 |     21.266 |   0.9032 |     26.888 |     3.2
   18 |   0.6463 |     20.504 |   0.8944 |     27.256 |     3.4
   19 |   0.6194 |     19.545 |   0.8950 |     27.133 |     3.6
   20 |   0.5882 |     18.629 |   0.9117 |     26.796 |     3.8
   21 |   0.5761 |     18.136 |   0.8956 |     26.765 |     4.0
   22 |   0.5503 |     17.226 |   0.9038 |     26.090 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7461 |     49.227 |   1.2901 |     41.314 |     0.1
    2 |   1.2743 |     41.601 |   1.1844 |     38.920 |     0.2
    3 |   1.1727 |     39.265 |   1.1058 |     36.863 |     0.3
    4 |   1.0974 |     36.935 |   1.0465 |     35.267 |     0.4
    5 |   1.0429 |     35.236 |   1.0063 |     34.223 |     0.6
    6 |   0.9922 |     33.624 |   1.0041 |     34.131 |     0.7
    7 |   0.9539 |     32.264 |   0.9497 |     31.983 |     0.8
    8 |   0.9127 |     30.795 |   0.9247 |     32.014 |     0.9
    9 |   0.8799 |     29.709 |   0.9099 |     30.172 |     1.0
   10 |   0.8405 |     28.257 |   0.9043 |     30.602 |     1.1
   11 |   0.8135 |     27.429 |   0.8646 |     29.190 |     1.3
   12 |   0.7806 |     26.118 |   0.8635 |     29.282 |     1.4
   13 |   0.7610 |     25.779 |   0.8357 |     27.962 |     1.5
   14 |   0.7194 |     24.578 |   0.8315 |     27.931 |     1.6
   15 |   0.6966 |     23.514 |   0.8321 |     27.072 |     1.7
   16 |   0.6635 |     22.330 |   0.8262 |     26.642 |     1.8
   17 |   0.6529 |     22.018 |   0.8248 |     26.796 |     1.9
   18 |   0.6256 |     20.948 |   0.8001 |     25.998 |     2.0
   19 |   0.5990 |     19.951 |   0.8023 |     24.616 |     2.2
   20 |   0.5788 |     19.331 |   0.8179 |     25.414 |     2.3
   21 |   0.5676 |     19.320 |   0.7994 |     24.555 |     2.4
   22 |   0.5415 |     18.624 |   0.7852 |     25.138 |     2.5
   23 |   0.5213 |     17.632 |   0.7875 |     23.726 |     2.6
   24 |   0.5088 |     17.478 |   0.8439 |     25.445 |     2.7
   25 |   0.4892 |     16.475 |   0.8135 |     25.660 |     2.8
   26 |   0.4739 |     16.140 |   0.8160 |     23.389 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4137 |     58.832 |   1.7964 |     43.984 |     0.1
    2 |   1.6447 |     43.904 |   1.5156 |     42.296 |     0.2
    3 |   1.4554 |     41.606 |   1.3878 |     40.147 |     0.3
    4 |   1.3440 |     39.539 |   1.3088 |     38.551 |     0.4
    5 |   1.2590 |     37.719 |   1.2413 |     37.201 |     0.5
    6 |   1.1923 |     36.014 |   1.1860 |     35.820 |     0.6
    7 |   1.1333 |     34.594 |   1.1451 |     34.715 |     0.7
    8 |   1.0781 |     32.681 |   1.1083 |     33.763 |     0.8
    9 |   1.0301 |     31.217 |   1.0803 |     33.057 |     0.9
   10 |   0.9833 |     29.830 |   1.0567 |     32.320 |     1.1
   11 |   0.9441 |     29.041 |   1.0284 |     31.614 |     1.2
   12 |   0.8992 |     27.418 |   1.0165 |     31.338 |     1.3
   13 |   0.8634 |     26.179 |   1.0072 |     30.909 |     1.4
   14 |   0.8243 |     24.945 |   0.9852 |     29.589 |     1.5
   15 |   0.7896 |     23.893 |   0.9640 |     29.804 |     1.6
   16 |   0.7543 |     22.538 |   0.9669 |     29.681 |     1.7
   17 |   0.7242 |     22.209 |   0.9545 |     29.497 |     1.8
   18 |   0.6974 |     21.140 |   0.9437 |     28.361 |     1.9
   19 |   0.6648 |     20.329 |   0.9303 |     28.422 |     2.0
   20 |   0.6427 |     19.227 |   0.9269 |     27.317 |     2.1
   21 |   0.6157 |     18.476 |   0.9366 |     28.146 |     2.2
   22 |   0.6018 |     18.350 |   0.9287 |     27.471 |     2.3
   23 |   0.5702 |     16.946 |   0.9154 |     27.716 |     2.4
   24 |   0.5485 |     16.393 |   0.9319 |     27.010 |     2.5
   25 |   0.5350 |     15.883 |   0.9342 |     26.980 |     2.6
   26 |   0.5173 |     15.548 |   0.9279 |     26.550 |     2.7
   27 |   0.4941 |     14.984 |   0.9239 |     27.164 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,250

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1597 |     55.724 |   1.4686 |     43.646 |     0.1
    2 |   1.4675 |     44.139 |   1.3147 |     41.436 |     0.3
    3 |   1.3303 |     41.184 |   1.2181 |     37.876 |     0.4
    4 |   1.2328 |     38.032 |   1.1442 |     36.556 |     0.5
    5 |   1.1490 |     35.828 |   1.0918 |     34.899 |     0.6
    6 |   1.0850 |     33.953 |   1.0517 |     34.131 |     0.8
    7 |   1.0266 |     32.050 |   1.0270 |     32.904 |     0.9
    8 |   0.9755 |     30.609 |   0.9838 |     31.031 |     1.0
    9 |   0.9252 |     29.106 |   0.9564 |     29.896 |     1.1
   10 |   0.8887 |     27.851 |   0.9360 |     30.510 |     1.3
   11 |   0.8399 |     26.480 |   0.9316 |     28.913 |     1.4
   12 |   0.8064 |     25.510 |   0.8970 |     27.870 |     1.5
   13 |   0.7674 |     24.304 |   0.8804 |     27.624 |     1.7
   14 |   0.7385 |     23.465 |   0.8826 |     27.901 |     1.8
   15 |   0.7011 |     22.122 |   0.8796 |     27.440 |     1.9
   16 |   0.6721 |     21.299 |   0.8801 |     26.765 |     2.0
   17 |   0.6440 |     20.548 |   0.8607 |     25.752 |     2.2
   18 |   0.6141 |     19.298 |   0.8799 |     25.967 |     2.3
   19 |   0.5904 |     18.629 |   0.8680 |     25.691 |     2.4
   20 |   0.5613 |     17.856 |   0.8614 |     25.783 |     2.6
   21 |   0.5394 |     17.105 |   0.8815 |     26.028 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,842

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5926 |     47.111 |   1.2667 |     41.590 |     0.1
    2 |   1.2093 |     40.230 |   1.1548 |     39.012 |     0.3
    3 |   1.0913 |     36.223 |   1.0688 |     35.850 |     0.4
    4 |   1.0135 |     33.904 |   0.9967 |     33.517 |     0.6
    5 |   0.9463 |     32.061 |   0.9932 |     33.794 |     0.8
    6 |   0.8900 |     30.378 |   0.9121 |     30.632 |     0.9
    7 |   0.8343 |     28.459 |   0.9066 |     29.650 |     1.1
    8 |   0.7937 |     26.875 |   0.8682 |     28.422 |     1.2
    9 |   0.7469 |     25.110 |   0.8301 |     27.655 |     1.4
   10 |   0.7060 |     23.920 |   0.8128 |     27.471 |     1.5
   11 |   0.6756 |     22.878 |   0.8175 |     27.103 |     1.7
   12 |   0.6453 |     21.875 |   0.7822 |     26.151 |     1.8
   13 |   0.6111 |     20.718 |   0.7648 |     24.800 |     2.0
   14 |   0.5764 |     19.715 |   0.7716 |     25.353 |     2.1
   15 |   0.5520 |     19.035 |   0.7760 |     24.279 |     2.3
   16 |   0.5245 |     17.911 |   0.7456 |     23.910 |     2.4
   17 |   0.4948 |     16.787 |   0.7811 |     24.893 |     2.6
   18 |   0.4698 |     15.932 |   0.7613 |     23.788 |     2.7
   19 |   0.4569 |     15.762 |   0.7780 |     23.419 |     2.9
   20 |   0.4309 |     15.022 |   0.7607 |     21.915 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,458

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0184 |     52.489 |   1.4720 |     42.848 |     0.1
    2 |   1.3712 |     41.266 |   1.2706 |     38.582 |     0.3
    3 |   1.2257 |     37.928 |   1.1827 |     36.464 |     0.4
    4 |   1.1225 |     34.775 |   1.1078 |     35.083 |     0.6
    5 |   1.0422 |     32.248 |   1.0587 |     33.487 |     0.7
    6 |   0.9675 |     29.967 |   1.0162 |     32.689 |     0.8
    7 |   0.9065 |     28.081 |   0.9632 |     29.988 |     1.0
    8 |   0.8377 |     25.877 |   0.9350 |     29.466 |     1.1
    9 |   0.7835 |     24.211 |   0.9004 |     27.901 |     1.3
   10 |   0.7267 |     22.555 |   0.9004 |     28.054 |     1.4
   11 |   0.6918 |     21.332 |   0.8893 |     27.471 |     1.6
   12 |   0.6452 |     19.704 |   0.8555 |     25.967 |     1.7
   13 |   0.6083 |     18.596 |   0.8453 |     25.629 |     1.8
   14 |   0.5556 |     16.787 |   0.8505 |     25.752 |     2.0
   15 |   0.5270 |     15.921 |   0.8337 |     25.261 |     2.1
   16 |   0.4979 |     15.082 |   0.8281 |     24.862 |     2.3
   17 |   0.4675 |     14.287 |   0.8172 |     24.309 |     2.4
   18 |   0.4361 |     13.185 |   0.8320 |     24.555 |     2.5
   19 |   0.4127 |     12.385 |   0.8392 |     24.033 |     2.7
   20 |   0.3912 |     11.853 |   0.8557 |     24.401 |     2.8
   21 |   0.3644 |     10.663 |   0.8352 |     23.941 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,472,034

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5027 |     46.245 |   1.2251 |     39.288 |     0.2
    2 |   1.1486 |     38.635 |   1.0996 |     37.293 |     0.3
    3 |   1.0435 |     35.241 |   1.0472 |     36.587 |     0.5
    4 |   0.9717 |     32.697 |   0.9743 |     33.088 |     0.6
    5 |   0.8948 |     30.356 |   0.9344 |     31.308 |     0.8
    6 |   0.8459 |     28.646 |   0.9026 |     30.448 |     0.9
    7 |   0.8097 |     27.467 |   0.8638 |     28.791 |     1.1
    8 |   0.7565 |     25.641 |   0.8621 |     28.729 |     1.2
    9 |   0.7258 |     24.600 |   0.8639 |     29.282 |     1.4
   10 |   0.6901 |     23.169 |   0.8289 |     26.826 |     1.6
   11 |   0.6533 |     22.204 |   0.8290 |     27.655 |     1.7
   12 |   0.6242 |     21.239 |   0.8242 |     26.304 |     1.9
   13 |   0.6045 |     20.948 |   0.7950 |     26.458 |     2.0
   14 |   0.5770 |     19.715 |   0.8036 |     25.936 |     2.2
   15 |   0.5432 |     18.558 |   0.8239 |     25.322 |     2.3
   16 |   0.5239 |     18.279 |   0.7655 |     23.665 |     2.5
   17 |   0.4870 |     16.859 |   0.7912 |     23.696 |     2.6
   18 |   0.4754 |     16.310 |   0.7839 |     24.340 |     2.8
   19 |   0.4626 |     16.113 |   0.7712 |     23.573 |     3.0
   20 |   0.4223 |     14.507 |   0.8028 |     23.910 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 602,594

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6259 |     47.149 |   1.2628 |     41.375 |     0.1
    2 |   1.2110 |     39.463 |   1.1435 |     38.981 |     0.2
    3 |   1.0988 |     36.683 |   1.0634 |     36.433 |     0.3
    4 |   1.0100 |     33.772 |   1.0132 |     33.702 |     0.5
    5 |   0.9502 |     31.749 |   0.9518 |     32.719 |     0.6
    6 |   0.8897 |     29.962 |   0.9261 |     31.308 |     0.7
    7 |   0.8469 |     28.536 |   0.9128 |     30.909 |     0.8
    8 |   0.8088 |     27.281 |   0.8826 |     29.374 |     0.9
    9 |   0.7550 |     25.751 |   0.8852 |     29.405 |     1.0
   10 |   0.7228 |     24.814 |   0.8560 |     27.931 |     1.2
   11 |   0.6900 |     23.635 |   0.8280 |     26.182 |     1.3
   12 |   0.6542 |     21.771 |   0.8175 |     27.962 |     1.4
   13 |   0.6316 |     21.332 |   0.8031 |     26.734 |     1.5
   14 |   0.5954 |     20.143 |   0.7948 |     26.212 |     1.6
   15 |   0.5771 |     19.775 |   0.7736 |     24.586 |     1.7
   16 |   0.5380 |     18.470 |   0.7630 |     24.309 |     1.9
   17 |   0.5044 |     17.166 |   0.7995 |     24.862 |     2.0
   18 |   0.5011 |     17.094 |   0.7959 |     23.665 |     2.1
   19 |   0.4626 |     15.735 |   0.7671 |     24.064 |     2.2
   20 |   0.4471 |     15.285 |   0.7736 |     23.174 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7510 |     49.490 |   1.3087 |     42.664 |     0.1
    2 |   1.2734 |     41.798 |   1.1557 |     38.582 |     0.2
    3 |   1.1661 |     38.728 |   1.1008 |     37.661 |     0.3
    4 |   1.0961 |     36.579 |   1.0712 |     35.421 |     0.4
    5 |   1.0453 |     34.660 |   1.0261 |     35.942 |     0.6
    6 |   1.0008 |     33.300 |   1.0009 |     34.162 |     0.7
    7 |   0.9505 |     31.776 |   0.9950 |     33.364 |     0.8
    8 |   0.9151 |     30.630 |   0.9460 |     32.351 |     0.9
    9 |   0.8818 |     29.753 |   0.9108 |     30.755 |     1.0
   10 |   0.8470 |     28.772 |   0.8976 |     29.619 |     1.1
   11 |   0.8161 |     27.407 |   0.9102 |     30.172 |     1.2
   12 |   0.7892 |     26.826 |   0.8892 |     30.110 |     1.4
   13 |   0.7513 |     25.439 |   0.8691 |     28.115 |     1.5
   14 |   0.7395 |     25.011 |   0.8920 |     29.865 |     1.6
   15 |   0.7047 |     23.723 |   0.8807 |     28.699 |     1.7
   16 |   0.6829 |     23.147 |   0.8635 |     27.502 |     1.8
   17 |   0.6650 |     22.719 |   0.8344 |     26.703 |     1.9
   18 |   0.6279 |     21.080 |   0.8490 |     27.164 |     2.0
   19 |   0.6094 |     20.482 |   0.8335 |     25.476 |     2.2
   20 |   0.5801 |     19.386 |   0.8443 |     25.813 |     2.3
   21 |   0.5733 |     19.572 |   0.8551 |     26.151 |     2.4
   22 |   0.5540 |     18.832 |   0.8373 |     25.537 |     2.5
   23 |   0.5394 |     18.443 |   0.8382 |     24.432 |     2.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5804 |     62.961 |   1.8913 |     45.549 |     0.1
    2 |   1.6899 |     44.073 |   1.5477 |     41.559 |     0.3
    3 |   1.4825 |     41.875 |   1.4141 |     40.546 |     0.4
    4 |   1.3625 |     39.622 |   1.3178 |     38.674 |     0.6
    5 |   1.2717 |     37.708 |   1.2518 |     37.446 |     0.7
    6 |   1.1980 |     36.086 |   1.1961 |     36.311 |     0.9
    7 |   1.1325 |     34.386 |   1.1612 |     34.960 |     1.0
    8 |   1.0696 |     32.555 |   1.1176 |     34.070 |     1.2
    9 |   1.0223 |     31.272 |   1.0873 |     32.996 |     1.3
   10 |   0.9725 |     29.496 |   1.0450 |     32.136 |     1.5
   11 |   0.9266 |     28.048 |   1.0230 |     31.645 |     1.6
   12 |   0.8843 |     26.908 |   1.0018 |     30.816 |     1.8
   13 |   0.8417 |     25.263 |   0.9899 |     30.571 |     1.9
   14 |   0.8085 |     24.117 |   0.9747 |     30.018 |     2.0
   15 |   0.7715 |     23.174 |   0.9716 |     28.913 |     2.2
   16 |   0.7448 |     22.379 |   0.9517 |     29.282 |     2.3
   17 |   0.7142 |     21.458 |   0.9324 |     28.484 |     2.5
   18 |   0.6823 |     20.291 |   0.9148 |     27.655 |     2.6
   19 |   0.6548 |     19.693 |   0.9244 |     27.471 |     2.8
   20 |   0.6301 |     18.810 |   0.9136 |     27.256 |     2.9
   21 |   0.5968 |     18.065 |   0.8971 |     26.427 |     3.1
   22 |   0.5814 |     17.484 |   0.8849 |     25.905 |     3.2
   23 |   0.5567 |     16.628 |   0.8978 |     26.703 |     3.4
   24 |   0.5372 |     16.360 |   0.8887 |     25.875 |     3.5
   25 |   0.5165 |     15.691 |   0.9229 |     26.489 |     3.7
   26 |   0.5053 |     15.318 |   0.8899 |     25.107 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,514

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1916 |     56.919 |   1.4590 |     43.247 |     0.2
    2 |   1.4533 |     43.536 |   1.2933 |     39.902 |     0.3
    3 |   1.3074 |     40.323 |   1.1889 |     37.569 |     0.5
    4 |   1.2118 |     37.730 |   1.1184 |     35.574 |     0.7
    5 |   1.1341 |     35.691 |   1.0716 |     33.671 |     0.8
    6 |   1.0668 |     33.361 |   1.0206 |     31.983 |     1.0
    7 |   1.0055 |     31.519 |   1.0040 |     31.154 |     1.2
    8 |   0.9566 |     30.016 |   0.9720 |     30.602 |     1.3
    9 |   0.9033 |     28.087 |   0.9565 |     30.049 |     1.5
   10 |   0.8584 |     27.116 |   0.9311 |     29.220 |     1.7
   11 |   0.8063 |     25.367 |   0.9125 |     28.760 |     1.8
   12 |   0.7741 |     24.276 |   0.9151 |     28.422 |     2.0
   13 |   0.7277 |     22.862 |   0.8957 |     27.287 |     2.2
   14 |   0.6938 |     21.689 |   0.8938 |     27.993 |     2.3
   15 |   0.6657 |     20.740 |   0.9008 |     27.317 |     2.5
   16 |   0.6350 |     20.197 |   0.9018 |     27.440 |     2.7
   17 |   0.6037 |     19.276 |   0.8943 |     26.335 |     2.8
   18 |   0.5719 |     18.054 |   0.8802 |     25.844 |     3.0
   19 |   0.5506 |     17.456 |   0.9097 |     26.980 |     3.1
   20 |   0.5186 |     16.140 |   0.8998 |     26.366 |     3.3
   21 |   0.4981 |     15.959 |   0.9078 |     26.212 |     3.5
   22 |   0.4834 |     15.800 |   0.9292 |     26.120 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,762

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5291 |     46.398 |   1.2340 |     41.222 |     0.1
    2 |   1.1513 |     38.443 |   1.0927 |     37.017 |     0.3
    3 |   1.0397 |     34.693 |   1.0217 |     35.144 |     0.5
    4 |   0.9632 |     32.341 |   1.0034 |     34.561 |     0.6
    5 |   0.9056 |     30.329 |   0.9651 |     32.904 |     0.8
    6 |   0.8487 |     28.629 |   0.9181 |     30.909 |     0.9
    7 |   0.8020 |     27.072 |   0.9133 |     30.632 |     1.1
    8 |   0.7626 |     25.866 |   0.8513 |     28.545 |     1.2
    9 |   0.7248 |     24.929 |   0.8332 |     27.287 |     1.4
   10 |   0.6762 |     22.862 |   0.8372 |     27.716 |     1.5
   11 |   0.6591 |     22.357 |   0.8253 |     28.330 |     1.7
   12 |   0.6101 |     20.696 |   0.8304 |     26.765 |     1.8
   13 |   0.5955 |     20.367 |   0.8064 |     26.212 |     2.0
   14 |   0.5743 |     19.693 |   0.7737 |     24.708 |     2.1
   15 |   0.5601 |     18.909 |   0.7875 |     25.691 |     2.3
   16 |   0.5252 |     18.043 |   0.7842 |     24.770 |     2.4
   17 |   0.4938 |     16.831 |   0.7748 |     23.696 |     2.6
   18 |   0.4819 |     16.634 |   0.7912 |     25.046 |     2.7
   19 |   0.4563 |     15.669 |   0.7512 |     22.437 |     2.9
   20 |   0.4334 |     15.115 |   0.7883 |     22.284 |     3.0
   21 |   0.4199 |     14.485 |   0.7984 |     23.143 |     3.2
   22 |   0.4161 |     14.375 |   0.8279 |     24.432 |     3.3
   23 |   0.4128 |     14.413 |   0.7727 |     22.805 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,341,346

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5354 |     47.094 |   1.2571 |     42.480 |     0.1
    2 |   1.1977 |     40.395 |   1.1446 |     38.889 |     0.3
    3 |   1.1019 |     37.330 |   1.0761 |     35.513 |     0.4
    4 |   1.0294 |     35.060 |   1.0221 |     33.548 |     0.6
    5 |   0.9679 |     33.191 |   0.9974 |     34.715 |     0.7
    6 |   0.9140 |     31.047 |   0.9322 |     31.952 |     0.9
    7 |   0.8669 |     29.868 |   0.9310 |     32.198 |     1.0
    8 |   0.8320 |     28.651 |   0.8953 |     30.417 |     1.2
    9 |   0.7882 |     27.133 |   0.8911 |     29.865 |     1.3
   10 |   0.7596 |     25.970 |   0.8547 |     28.760 |     1.5
   11 |   0.7434 |     25.543 |   0.8547 |     29.098 |     1.6
   12 |   0.7064 |     24.342 |   0.8385 |     27.287 |     1.8
   13 |   0.6853 |     23.772 |   0.7933 |     26.212 |     1.9
   14 |   0.6463 |     22.522 |   0.8218 |     26.918 |     2.1
   15 |   0.6170 |     21.272 |   0.8156 |     26.734 |     2.2
   16 |   0.5953 |     20.581 |   0.7833 |     25.506 |     2.4
   17 |   0.5653 |     19.474 |   0.7838 |     25.077 |     2.5
   18 |   0.5609 |     19.304 |   0.7948 |     25.506 |     2.7
   19 |   0.5286 |     18.355 |   0.8056 |     24.954 |     2.8
   20 |   0.5090 |     17.429 |   0.7718 |     24.923 |     3.0
   21 |   0.4882 |     16.809 |   0.8121 |     24.678 |     3.1
   22 |   0.4754 |     16.469 |   0.7583 |     23.818 |     3.3
   23 |   0.4606 |     15.938 |   0.8121 |     24.831 |     3.4
   24 |   0.4447 |     15.208 |   0.8001 |     23.174 |     3.6
   25 |   0.4110 |     14.183 |   0.8188 |     24.279 |     3.7
   26 |   0.4056 |     14.167 |   0.7835 |     22.775 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,762

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0845 |     54.468 |   1.4376 |     42.910 |     0.1
    2 |   1.3542 |     41.398 |   1.2710 |     39.288 |     0.2
    3 |   1.2199 |     37.878 |   1.1742 |     35.605 |     0.4
    4 |   1.1229 |     35.302 |   1.0968 |     33.978 |     0.5
    5 |   1.0322 |     32.001 |   1.0468 |     32.750 |     0.6
    6 |   0.9513 |     29.518 |   1.0243 |     32.535 |     0.7
    7 |   0.8852 |     27.286 |   0.9755 |     30.540 |     0.9
    8 |   0.8203 |     25.461 |   0.9173 |     28.269 |     1.0
    9 |   0.7621 |     23.443 |   0.9104 |     28.453 |     1.1
   10 |   0.7179 |     22.007 |   0.8727 |     27.440 |     1.2
   11 |   0.6655 |     20.444 |   0.8622 |     26.642 |     1.4
   12 |   0.6192 |     18.717 |   0.8369 |     25.691 |     1.5
   13 |   0.5792 |     17.840 |   0.8605 |     25.721 |     1.6
   14 |   0.5496 |     16.754 |   0.8287 |     25.261 |     1.7
   15 |   0.5170 |     15.828 |   0.8101 |     23.849 |     1.9
   16 |   0.4748 |     14.545 |   0.8329 |     24.831 |     2.0
   17 |   0.4516 |     13.843 |   0.8112 |     23.849 |     2.1
   18 |   0.4197 |     12.654 |   0.8212 |     23.972 |     2.2
   19 |   0.3893 |     11.683 |   0.8274 |     23.665 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,514

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5651 |     47.489 |   1.2581 |     41.191 |     0.2
    2 |   1.2468 |     41.902 |   1.1644 |     40.823 |     0.3
    3 |   1.1549 |     39.408 |   1.1059 |     37.661 |     0.5
    4 |   1.1036 |     37.774 |   1.0667 |     37.937 |     0.7
    5 |   1.0647 |     36.864 |   1.0374 |     35.482 |     0.8
    6 |   1.0089 |     34.693 |   0.9940 |     34.285 |     1.0
    7 |   0.9777 |     33.640 |   0.9967 |     33.947 |     1.2
    8 |   0.9386 |     31.957 |   0.9797 |     32.934 |     1.3
    9 |   0.9145 |     31.623 |   0.9240 |     31.676 |     1.5
   10 |   0.8820 |     30.285 |   0.9394 |     31.799 |     1.7
   11 |   0.8496 |     29.282 |   0.9029 |     31.522 |     1.8
   12 |   0.8298 |     28.662 |   0.8669 |     29.435 |     2.0
   13 |   0.7901 |     26.957 |   0.8641 |     29.067 |     2.2
   14 |   0.7652 |     26.272 |   0.8553 |     28.023 |     2.3
   15 |   0.7355 |     25.296 |   0.8558 |     27.379 |     2.5
   16 |   0.7196 |     24.940 |   0.8314 |     27.870 |     2.6
   17 |   0.6794 |     23.333 |   0.8641 |     28.115 |     2.8
   18 |   0.6667 |     22.560 |   0.8387 |     27.256 |     3.0
   19 |   0.6336 |     21.776 |   0.8059 |     26.090 |     3.1
   20 |   0.6111 |     20.883 |   0.7977 |     26.243 |     3.3
   21 |   0.6004 |     20.795 |   0.7750 |     24.432 |     3.5
   22 |   0.5727 |     19.518 |   0.7999 |     24.739 |     3.6
   23 |   0.5507 |     18.827 |   0.8307 |     25.599 |     3.8
   24 |   0.5141 |     17.615 |   0.8064 |     24.555 |     4.0
   25 |   0.5112 |     17.390 |   0.7947 |     23.910 |     4.1
   26 |   0.4957 |     16.809 |   0.7746 |     24.248 |     4.3
   27 |   0.4640 |     16.058 |   0.8503 |     23.941 |     4.5
   28 |   0.4424 |     15.302 |   0.8311 |     24.309 |     4.6
   29 |   0.4320 |     14.896 |   0.7977 |     23.757 |     4.8
   30 |   0.4094 |     14.200 |   0.8375 |     24.248 |     5.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,472,034

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4837 |     46.283 |   1.2477 |     40.792 |     0.1
    2 |   1.1664 |     39.232 |   1.0962 |     37.170 |     0.3
    3 |   1.0634 |     35.959 |   1.0416 |     35.328 |     0.4
    4 |   0.9901 |     33.383 |   1.0083 |     34.500 |     0.5
    5 |   0.9216 |     31.217 |   0.9385 |     32.382 |     0.6
    6 |   0.8687 |     29.446 |   0.8983 |     30.909 |     0.8
    7 |   0.8161 |     27.933 |   0.9147 |     30.632 |     0.9
    8 |   0.7861 |     26.732 |   0.8681 |     29.312 |     1.0
    9 |   0.7453 |     25.307 |   0.8465 |     29.067 |     1.2
   10 |   0.7122 |     24.342 |   0.8320 |     27.502 |     1.3
   11 |   0.6715 |     23.004 |   0.8349 |     27.409 |     1.4
   12 |   0.6336 |     21.705 |   0.8327 |     27.440 |     1.5
   13 |   0.6056 |     20.510 |   0.8044 |     26.397 |     1.7
   14 |   0.5735 |     19.348 |   0.8010 |     25.384 |     1.8
   15 |   0.5517 |     19.062 |   0.8158 |     26.182 |     1.9
   16 |   0.5271 |     17.988 |   0.7847 |     24.893 |     2.1
   17 |   0.4895 |     16.519 |   0.8041 |     24.401 |     2.2
   18 |   0.4767 |     16.393 |   0.7630 |     24.125 |     2.3
   19 |   0.4546 |     15.905 |   0.8062 |     24.156 |     2.4
   20 |   0.4169 |     14.254 |   0.7498 |     21.946 |     2.6
   21 |   0.4008 |     13.805 |   0.7902 |     22.284 |     2.7
   22 |   0.3879 |     13.564 |   0.7878 |     22.437 |     2.8
   23 |   0.3554 |     12.149 |   0.7986 |     21.915 |     3.0
   24 |   0.3526 |     12.297 |   0.8071 |     21.946 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,458

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5629 |     47.418 |   1.2482 |     42.419 |     0.2
    2 |   1.2183 |     40.663 |   1.1612 |     39.411 |     0.4
    3 |   1.1288 |     38.098 |   1.1119 |     38.551 |     0.6
    4 |   1.0709 |     36.086 |   1.0369 |     35.789 |     0.8
    5 |   1.0267 |     34.912 |   1.0058 |     33.640 |     0.9
    6 |   0.9856 |     33.268 |   0.9690 |     33.118 |     1.1
    7 |   0.9490 |     32.303 |   0.9269 |     31.921 |     1.3
    8 |   0.9021 |     30.817 |   0.9053 |     30.816 |     1.5
    9 |   0.8748 |     29.753 |   0.9160 |     30.448 |     1.7
   10 |   0.8490 |     28.914 |   0.8972 |     30.110 |     1.9
   11 |   0.8129 |     27.697 |   0.8832 |     29.527 |     2.1
   12 |   0.7887 |     26.946 |   0.9024 |     30.356 |     2.3
   13 |   0.7617 |     26.343 |   0.8436 |     28.300 |     2.4
   14 |   0.7341 |     24.989 |   0.8584 |     27.839 |     2.6
   15 |   0.7063 |     24.145 |   0.8187 |     27.655 |     2.8
   16 |   0.6939 |     23.849 |   0.8319 |     26.765 |     3.0
   17 |   0.6706 |     22.944 |   0.8137 |     28.023 |     3.2
   18 |   0.6435 |     21.963 |   0.8234 |     25.721 |     3.4
   19 |   0.6237 |     21.168 |   0.7932 |     26.028 |     3.6
   20 |   0.6070 |     20.537 |   0.7867 |     25.261 |     3.8
   21 |   0.5828 |     19.885 |   0.8085 |     25.230 |     4.0
   22 |   0.5655 |     19.435 |   0.8109 |     25.077 |     4.1
   23 |   0.5412 |     18.684 |   0.7864 |     23.910 |     4.3
   24 |   0.5184 |     17.840 |   0.8086 |     24.555 |     4.5
   25 |   0.5140 |     17.703 |   0.7902 |     23.788 |     4.7
   26 |   0.4922 |     16.820 |   0.8045 |     23.297 |     4.9
   27 |   0.4790 |     16.431 |   0.8052 |     23.266 |     5.1
   28 |   0.4549 |     15.581 |   0.7675 |     22.990 |     5.3
   29 |   0.4353 |     15.214 |   0.7927 |     22.836 |     5.5
   30 |   0.4256 |     14.830 |   0.8024 |     23.297 |     5.6
   31 |   0.4140 |     14.232 |   0.8210 |     23.051 |     5.8
   32 |   0.4014 |     13.964 |   0.8482 |     23.542 |     6.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 485,858

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6402 |     47.061 |   1.2632 |     41.375 |     0.1
    2 |   1.2522 |     41.102 |   1.1526 |     38.735 |     0.3
    3 |   1.1335 |     37.632 |   1.0757 |     36.249 |     0.4
    4 |   1.0643 |     35.356 |   1.0417 |     34.684 |     0.5
    5 |   1.0066 |     33.438 |   0.9804 |     32.535 |     0.7
    6 |   0.9514 |     31.727 |   0.9569 |     32.382 |     0.8
    7 |   0.9142 |     30.970 |   0.9300 |     31.461 |     0.9
    8 |   0.8661 |     28.887 |   0.9178 |     31.154 |     1.1
    9 |   0.8161 |     27.533 |   0.8534 |     28.453 |     1.2
   10 |   0.7819 |     26.102 |   0.8851 |     29.036 |     1.3
   11 |   0.7497 |     25.395 |   0.8613 |     28.422 |     1.5
   12 |   0.7159 |     24.529 |   0.8511 |     27.962 |     1.6
   13 |   0.6891 |     23.339 |   0.8084 |     26.519 |     1.7
   14 |   0.6452 |     22.171 |   0.8106 |     25.783 |     1.9
   15 |   0.6311 |     21.255 |   0.8085 |     26.090 |     2.0
   16 |   0.6051 |     20.559 |   0.8016 |     25.599 |     2.1
   17 |   0.5855 |     19.879 |   0.7980 |     24.678 |     2.3
   18 |   0.5562 |     19.112 |   0.7971 |     24.678 |     2.4
   19 |   0.5258 |     18.065 |   0.8069 |     25.138 |     2.5
   20 |   0.5053 |     17.379 |   0.7969 |     24.064 |     2.7
   21 |   0.4938 |     16.804 |   0.7929 |     24.401 |     2.8
   22 |   0.4616 |     16.075 |   0.8031 |     23.020 |     2.9
   23 |   0.4395 |     14.978 |   0.7998 |     23.143 |     3.1
   24 |   0.4282 |     14.808 |   0.8548 |     23.941 |     3.2
   25 |   0.4121 |     14.172 |   0.8471 |     23.941 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,273,250

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0347 |     52.473 |   1.4322 |     41.007 |     0.1
    2 |   1.3300 |     40.247 |   1.2364 |     37.845 |     0.3
    3 |   1.1820 |     36.546 |   1.1465 |     35.144 |     0.4
    4 |   1.0828 |     33.218 |   1.0776 |     33.702 |     0.6
    5 |   1.0015 |     31.031 |   1.0452 |     32.689 |     0.7
    6 |   0.9298 |     29.194 |   0.9934 |     30.724 |     0.9
    7 |   0.8573 |     26.513 |   0.9363 |     29.128 |     1.0
    8 |   0.7928 |     24.156 |   0.9073 |     27.808 |     1.2
    9 |   0.7363 |     22.725 |   0.8732 |     27.103 |     1.3
   10 |   0.6859 |     21.140 |   0.8547 |     26.796 |     1.5
   11 |   0.6359 |     19.402 |   0.8478 |     26.397 |     1.6
   12 |   0.5903 |     18.021 |   0.8286 |     25.384 |     1.8
   13 |   0.5430 |     16.431 |   0.8355 |     25.721 |     1.9
   14 |   0.5075 |     15.230 |   0.8101 |     24.309 |     2.0
   15 |   0.4698 |     14.353 |   0.8063 |     23.818 |     2.2
   16 |   0.4376 |     13.213 |   0.8045 |     24.739 |     2.3
   17 |   0.4078 |     12.330 |   0.8112 |     23.297 |     2.5
   18 |   0.3745 |     11.365 |   0.8354 |     23.481 |     2.6
   19 |   0.3567 |     10.685 |   0.8194 |     23.818 |     2.8
   20 |   0.3274 |      9.808 |   0.8270 |     23.327 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 470,498

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7604 |     50.543 |   1.3110 |     43.616 |     0.2
    2 |   1.2942 |     42.050 |   1.2072 |     40.270 |     0.3
    3 |   1.1901 |     39.156 |   1.1270 |     37.538 |     0.5
    4 |   1.1208 |     37.566 |   1.1038 |     38.183 |     0.7
    5 |   1.0600 |     35.641 |   1.0309 |     34.837 |     0.8
    6 |   1.0123 |     34.243 |   0.9990 |     33.671 |     1.0
    7 |   0.9614 |     32.166 |   0.9486 |     31.614 |     1.2
    8 |   0.9172 |     30.883 |   0.9392 |     31.645 |     1.3
    9 |   0.8741 |     29.627 |   0.9037 |     30.387 |     1.5
   10 |   0.8521 |     28.717 |   0.8931 |     29.957 |     1.7
   11 |   0.8104 |     27.034 |   0.8915 |     29.804 |     1.8
   12 |   0.7751 |     26.025 |   0.8643 |     28.269 |     2.0
   13 |   0.7606 |     25.811 |   0.8502 |     28.269 |     2.2
   14 |   0.7186 |     24.359 |   0.8293 |     26.888 |     2.3
   15 |   0.6934 |     23.454 |   0.8408 |     27.440 |     2.5
   16 |   0.6766 |     22.812 |   0.7934 |     25.691 |     2.7
   17 |   0.6428 |     21.820 |   0.8205 |     26.611 |     2.9
   18 |   0.6242 |     20.965 |   0.8065 |     26.059 |     3.0
   19 |   0.5975 |     20.296 |   0.8316 |     25.721 |     3.2
   20 |   0.5890 |     20.154 |   0.8112 |     25.506 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 437,026

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6827 |     65.011 |   1.9364 |     44.936 |     0.1
    2 |   1.8535 |     46.086 |   1.5706 |     43.738 |     0.3
    3 |   1.6030 |     44.912 |   1.4506 |     42.511 |     0.4
    4 |   1.4839 |     43.257 |   1.3693 |     40.853 |     0.5
    5 |   1.4039 |     41.628 |   1.3090 |     39.687 |     0.7
    6 |   1.3352 |     40.060 |   1.2529 |     38.797 |     0.8
    7 |   1.2860 |     38.958 |   1.2098 |     38.244 |     1.0
    8 |   1.2363 |     37.725 |   1.1736 |     37.324 |     1.1
    9 |   1.1933 |     36.667 |   1.1418 |     35.881 |     1.2
   10 |   1.1517 |     35.680 |   1.1058 |     34.592 |     1.4
   11 |   1.1181 |     34.748 |   1.0881 |     34.346 |     1.5
   12 |   1.0828 |     33.339 |   1.0733 |     33.118 |     1.7
   13 |   1.0520 |     32.473 |   1.0565 |     32.965 |     1.8
   14 |   1.0228 |     31.321 |   1.0460 |     33.118 |     1.9
   15 |   0.9990 |     30.888 |   1.0176 |     31.338 |     2.1
   16 |   0.9677 |     29.666 |   1.0200 |     32.413 |     2.2
   17 |   0.9434 |     29.413 |   1.0005 |     31.215 |     2.3
   18 |   0.9207 |     28.657 |   0.9736 |     30.233 |     2.5
   19 |   0.8967 |     27.664 |   0.9611 |     29.374 |     2.6
   20 |   0.8773 |     27.094 |   0.9643 |     30.110 |     2.8
   21 |   0.8558 |     26.716 |   0.9576 |     30.203 |     2.9
   22 |   0.8306 |     25.609 |   0.9412 |     29.220 |     3.0
   23 |   0.8102 |     25.115 |   0.9518 |     29.681 |     3.2
   24 |   0.7939 |     24.836 |   0.9361 |     28.975 |     3.3
   25 |   0.7772 |     24.057 |   0.9408 |     28.944 |     3.4
   26 |   0.7563 |     23.383 |   0.9221 |     28.576 |     3.6
   27 |   0.7411 |     23.240 |   0.9228 |     28.238 |     3.7
   28 |   0.7257 |     22.456 |   0.9119 |     28.207 |     3.9
   29 |   0.7221 |     22.566 |   0.9211 |     27.993 |     4.0
   30 |   0.7004 |     22.029 |   0.9010 |     27.686 |     4.1
   31 |   0.6862 |     21.689 |   0.9184 |     27.655 |     4.3
   32 |   0.6727 |     21.168 |   0.9164 |     27.993 |     4.4
   33 |   0.6526 |     20.340 |   0.9243 |     27.901 |     4.5
   34 |   0.6410 |     20.340 |   0.9173 |     27.317 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 602,594

Training started
X_train.shape: torch.Size([3040, 702])
Y_train.shape: torch.Size([3040, 7])
X_dev.shape: torch.Size([543, 294])
Y_dev.shape: torch.Size([543, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5871 |     63.459 |   1.7757 |     44.598 |     0.1
    2 |   1.7244 |     44.841 |   1.5063 |     42.572 |     0.2
    3 |   1.5409 |     43.317 |   1.4013 |     41.344 |     0.4
    4 |   1.4342 |     41.584 |   1.3223 |     39.564 |     0.5
    5 |   1.3578 |     40.241 |   1.2614 |     38.244 |     0.6
    6 |   1.2952 |     39.221 |   1.2108 |     37.661 |     0.8
    7 |   1.2379 |     37.675 |   1.1726 |     36.219 |     0.9
    8 |   1.1897 |     36.475 |   1.1389 |     35.328 |     1.0
    9 |   1.1467 |     35.148 |   1.1108 |     35.052 |     1.1
   10 |   1.1100 |     34.238 |   1.0790 |     33.425 |     1.3
   11 |   1.0689 |     32.599 |   1.0641 |     33.548 |     1.4
   12 |   1.0261 |     31.502 |   1.0471 |     32.290 |     1.5
   13 |   0.9952 |     30.609 |   1.0158 |     31.553 |     1.6
   14 |   0.9595 |     29.611 |   1.0052 |     31.246 |     1.8
   15 |   0.9321 |     28.810 |   1.0129 |     32.505 |     1.9
   16 |   0.9012 |     27.911 |   0.9831 |     31.461 |     2.0
   17 |   0.8755 |     27.363 |   0.9700 |     30.847 |     2.1
   18 |   0.8482 |     26.014 |   0.9629 |     30.049 |     2.3
   19 |   0.8188 |     25.148 |   0.9564 |     30.172 |     2.4
   20 |   0.7989 |     24.775 |   0.9513 |     30.172 |     2.5
   21 |   0.7732 |     23.920 |   0.9593 |     29.282 |     2.7
   22 |   0.7572 |     23.416 |   0.9444 |     29.558 |     2.8
   23 |   0.7313 |     22.544 |   0.9383 |     28.207 |     2.9
   24 |   0.7147 |     22.346 |   0.9391 |     28.361 |     3.0
   25 |   0.6970 |     21.579 |   0.9576 |     29.098 |     3.2
   26 |   0.6787 |     21.223 |   0.9376 |     28.207 |     3.3
   27 |   0.6593 |     20.570 |   0.9383 |     28.545 |     3.4
   28 |   0.6444 |     20.066 |   0.9409 |     27.471 |     3.5
   29 |   0.6267 |     19.501 |   0.9387 |     27.103 |     3.7
   30 |   0.6108 |     18.788 |   0.9450 |     27.655 |     3.8
Early stopping

