{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a67c3-3164-402b-9c3d-ed5f98d41c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))\n",
    "from seq2seq import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multimodaltransformer_hyp import hyperparametersselection\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566324b4-cf15-44bc-9f49-c6c019367e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa18d3e-cd26-4b6a-85c0-cc550fb60feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string that simulates a list to a real list\n",
    "def convert_string_list(element):\n",
    "    # Delete [] of the string\n",
    "    element = element[0:len(element)]\n",
    "    # Create a list that contains each code as e.g. 'A'\n",
    "    ATC_list = list(element.split('; '))\n",
    "    for index, code in enumerate(ATC_list):\n",
    "        # Delete '' of the code\n",
    "        ATC_list[index] = code[0:len(code)]\n",
    "    return ATC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e165f52-d611-4847-a003-d336dd9fe491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicate_rows(df):\n",
    "    # Duplicate each compound the number of ATC codes associated to it, copying its SMILES in new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        atc_codes = row['ATC Codes']\n",
    "        atc_codes_list = convert_string_list(atc_codes)\n",
    "        \n",
    "        if len(atc_codes_list) > 1:\n",
    "            for code in atc_codes_list:\n",
    "                if len(code) == 5:\n",
    "                    new_row = row.copy()\n",
    "                    new_row['ATC Codes'] = code\n",
    "                    new_rows.append(new_row)\n",
    "        else:\n",
    "            if len(atc_codes_list[0]) == 5:\n",
    "                new_rows.append(row)\n",
    "    \n",
    "    new_set = pd.DataFrame(new_rows)\n",
    "    new_set = new_set.reset_index(drop=True)\n",
    "\n",
    "    return new_set\n",
    "\n",
    "def extract_descriptors(df):\n",
    "    \"\"\"\n",
    "    Extract molecular descriptors from your dataset.\n",
    "    You'll need to implement this based on your descriptor source.\n",
    "    \n",
    "    Returns FloatTensor of shape (n_molecules, descriptor_dimension)\n",
    "    \"\"\"\n",
    "    descriptors = df.iloc[:, 2:-5].values\n",
    "    # Convert to numpy for easier handling\n",
    "    if isinstance(descriptors, torch.Tensor):\n",
    "        desc_array = descriptors.numpy()\n",
    "    else:\n",
    "        desc_array = np.array(descriptors)\n",
    "    \n",
    "    # Replace infinite values with NaN first\n",
    "    desc_array[np.isinf(desc_array)] = np.nan\n",
    "    \n",
    "    # Calculate median for each feature (column-wise)\n",
    "    medians = np.nanmedian(desc_array, axis=0)\n",
    "    \n",
    "    # Replace NaN values with corresponding median\n",
    "    for i in range(desc_array.shape[1]):\n",
    "        mask = np.isnan(desc_array[:, i])\n",
    "        desc_array[mask, i] = medians[i]\n",
    "    return torch.tensor(desc_array, dtype=torch.float32)\n",
    "    \n",
    "# Create vocabularies\n",
    "# Tokenize the data\n",
    "def source(df):\n",
    "    source = []\n",
    "    for compound in df['Neutralized SMILES']:\n",
    "        # A list containing each SMILES character separated\n",
    "        source.append(list(compound))\n",
    "    return source\n",
    "def target(df):\n",
    "    target = []\n",
    "    for codes in df['ATC Codes']:  \n",
    "        code = convert_string_list(codes) \n",
    "        # A list of lists, each one containing each ATC code character separated \n",
    "        for c in code:\n",
    "            list_c = list(c)\n",
    "            target.append(list_c)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3256e6-ad40-454b-80a0-e415b76ab19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 3\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,273,250\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3024, 702])\n",
      "Y_train.shape: torch.Size([3024, 7])\n",
      "X_dev.shape: torch.Size([538, 295])\n",
      "Y_dev.shape: torch.Size([538, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.2404 |     58.151 |   1.4612 |     44.517 |     0.2\n",
      "    2 |   1.4325 |     42.846 |   1.3039 |     41.543 |     0.3\n",
      "    3 |   1.2989 |     39.953 |   1.2260 |     39.374 |     0.5\n",
      "    4 |   1.2068 |     37.599 |   1.1717 |     38.135 |     0.6\n",
      "    5 |   1.1410 |     35.797 |   1.1174 |     35.998 |     0.8\n",
      "    6 |   1.0782 |     33.581 |   1.0834 |     35.316 |     1.0\n",
      "    7 |   1.0225 |     31.961 |   1.0339 |     33.147 |     1.1\n",
      "    8 |   0.9684 |     30.748 |   1.0064 |     32.807 |     1.3\n",
      "    9 |   0.9242 |     28.803 |   0.9876 |     31.475 |     1.4\n",
      "   10 |   0.8758 |     27.315 |   0.9691 |     30.390 |     1.6\n",
      "   11 |   0.8328 |     26.301 |   0.9328 |     28.903 |     1.8\n",
      "   12 |   0.7900 |     24.884 |   0.9203 |     28.191 |     1.9\n",
      "   13 |   0.7545 |     23.534 |   0.9135 |     28.222 |     2.1\n",
      "   14 |   0.7220 |     22.321 |   0.9004 |     27.138 |     2.3\n",
      "   15 |   0.6895 |     21.401 |   0.9132 |     27.323 |     2.4\n",
      "   16 |   0.6575 |     20.971 |   0.8744 |     26.146 |     2.6\n",
      "   17 |   0.6289 |     19.428 |   0.8680 |     25.558 |     2.8\n",
      "   18 |   0.6029 |     18.888 |   0.8930 |     25.867 |     2.9\n",
      "   19 |   0.5706 |     17.918 |   0.8888 |     25.929 |     3.1\n",
      "   20 |   0.5461 |     17.278 |   0.8902 |     25.310 |     3.3\n",
      "   21 |   0.5242 |     16.435 |   0.8933 |     25.310 |     3.4\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Temp\\ipykernel_20440\\1958673972.py:194: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n",
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 4\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,604,386\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3028, 649])\n",
      "Y_train.shape: torch.Size([3028, 7])\n",
      "X_dev.shape: torch.Size([534, 702])\n",
      "Y_dev.shape: torch.Size([534, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.5818 |     48.228 |   1.2829 |     42.572 |     0.2\n",
      "    2 |   1.2431 |     41.524 |   1.1803 |     39.700 |     0.4\n",
      "    3 |   1.1628 |     39.790 |   1.1010 |     36.767 |     0.6\n",
      "    4 |   1.0995 |     37.324 |   1.0535 |     36.236 |     0.8\n",
      "    5 |   1.0432 |     35.304 |   1.0011 |     33.365 |     1.0\n",
      "    6 |   1.0104 |     34.429 |   1.0033 |     34.270 |     1.3\n",
      "    7 |   0.9628 |     32.965 |   0.9728 |     32.054 |     1.5\n",
      "    8 |   0.9381 |     32.056 |   0.9479 |     32.085 |     1.7\n",
      "    9 |   0.9048 |     30.961 |   0.9175 |     30.743 |     1.9\n",
      "   10 |   0.8805 |     30.174 |   0.8886 |     29.869 |     2.1\n",
      "   11 |   0.8387 |     28.776 |   0.8907 |     30.087 |     2.3\n",
      "   12 |   0.8129 |     27.587 |   0.8952 |     29.619 |     2.5\n",
      "   13 |   0.7928 |     27.229 |   0.8604 |     27.591 |     2.8\n",
      "   14 |   0.7633 |     25.798 |   0.8337 |     28.059 |     3.0\n",
      "   15 |   0.7281 |     24.923 |   0.8692 |     29.744 |     3.2\n",
      "   16 |   0.7090 |     24.406 |   0.8320 |     27.684 |     3.4\n",
      "   17 |   0.6754 |     23.178 |   0.7907 |     26.155 |     3.6\n",
      "   18 |   0.6462 |     22.204 |   0.7884 |     26.155 |     3.8\n",
      "   19 |   0.6339 |     21.940 |   0.7705 |     24.282 |     4.0\n",
      "   20 |   0.6000 |     20.393 |   0.7690 |     24.563 |     4.3\n",
      "   21 |   0.5762 |     19.578 |   0.8011 |     25.031 |     4.5\n",
      "   22 |   0.5652 |     19.430 |   0.7821 |     23.876 |     4.7\n",
      "   23 |   0.5269 |     18.356 |   0.8049 |     24.719 |     4.9\n",
      "   24 |   0.5084 |     17.459 |   0.7778 |     24.594 |     5.1\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 44 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 3\n",
      "Decoder layers: 3\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,272,994\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3021, 702])\n",
      "Y_train.shape: torch.Size([3021, 7])\n",
      "X_dev.shape: torch.Size([541, 250])\n",
      "Y_dev.shape: torch.Size([541, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.1523 |     54.634 |   1.4698 |     43.561 |     0.1\n",
      "    2 |   1.4477 |     43.567 |   1.3067 |     41.282 |     0.3\n",
      "    3 |   1.3095 |     40.130 |   1.2203 |     38.139 |     0.4\n",
      "    4 |   1.2221 |     37.730 |   1.1715 |     36.722 |     0.5\n",
      "    5 |   1.1484 |     35.739 |   1.1253 |     35.490 |     0.6\n",
      "    6 |   1.0835 |     33.769 |   1.0969 |     34.535 |     0.8\n",
      "    7 |   1.0313 |     32.373 |   1.0568 |     33.179 |     0.9\n",
      "    8 |   0.9754 |     30.608 |   1.0205 |     32.039 |     1.0\n",
      "    9 |   0.9287 |     29.218 |   0.9994 |     31.485 |     1.2\n",
      "   10 |   0.8810 |     27.844 |   0.9844 |     31.115 |     1.3\n",
      "   11 |   0.8412 |     26.487 |   0.9906 |     30.715 |     1.5\n",
      "   12 |   0.8019 |     25.229 |   0.9589 |     30.407 |     1.6\n",
      "   13 |   0.7661 |     24.120 |   0.9377 |     29.205 |     1.7\n",
      "   14 |   0.7320 |     22.984 |   0.9397 |     28.712 |     1.9\n",
      "   15 |   0.6940 |     21.698 |   0.9345 |     28.219 |     2.0\n",
      "   16 |   0.6602 |     20.777 |   0.9335 |     28.404 |     2.1\n",
      "   17 |   0.6313 |     19.712 |   0.9201 |     27.788 |     2.3\n",
      "   18 |   0.6072 |     19.260 |   0.9372 |     28.497 |     2.4\n",
      "   19 |   0.5814 |     18.537 |   0.9356 |     26.802 |     2.5\n",
      "   20 |   0.5597 |     17.400 |   0.9442 |     26.710 |     2.7\n",
      "   21 |   0.5325 |     17.014 |   0.9206 |     26.433 |     2.8\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 43 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 4\n",
      "Decoder layers: 4\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,604,130\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3042, 702])\n",
      "Y_train.shape: torch.Size([3042, 7])\n",
      "X_dev.shape: torch.Size([520, 467])\n",
      "Y_dev.shape: torch.Size([520, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.1314 |     55.150 |   1.4562 |     45.032 |     0.2\n",
      "    2 |   1.4442 |     43.798 |   1.3184 |     40.962 |     0.3\n",
      "    3 |   1.3254 |     41.365 |   1.2354 |     39.872 |     0.5\n",
      "    4 |   1.2431 |     39.289 |   1.1594 |     36.987 |     0.7\n",
      "    5 |   1.1715 |     36.664 |   1.1252 |     36.154 |     0.9\n",
      "    6 |   1.1064 |     35.180 |   1.0636 |     33.846 |     1.0\n",
      "    7 |   1.0555 |     33.142 |   1.0325 |     33.365 |     1.2\n",
      "    8 |   1.0122 |     32.243 |   1.0051 |     32.468 |     1.4\n",
      "    9 |   0.9515 |     30.188 |   0.9896 |     31.603 |     1.6\n",
      "   10 |   0.9190 |     28.972 |   0.9584 |     30.545 |     1.7\n",
      "   11 |   0.8749 |     27.394 |   0.9471 |     29.872 |     1.9\n",
      "   12 |   0.8361 |     26.320 |   0.9205 |     29.551 |     2.1\n",
      "   13 |   0.7891 |     24.770 |   0.9177 |     28.974 |     2.3\n",
      "   14 |   0.7532 |     23.482 |   0.8934 |     27.981 |     2.4\n",
      "   15 |   0.7262 |     23.006 |   0.8936 |     27.115 |     2.6\n",
      "   16 |   0.6993 |     21.751 |   0.8897 |     27.019 |     2.8\n",
      "   17 |   0.6754 |     21.011 |   0.8745 |     26.603 |     3.0\n",
      "   18 |   0.6397 |     20.277 |   0.8832 |     26.731 |     3.2\n",
      "   19 |   0.6087 |     19.105 |   0.8566 |     25.609 |     3.3\n",
      "   20 |   0.5849 |     18.206 |   0.8699 |     26.731 |     3.5\n",
      "   21 |   0.5653 |     17.877 |   0.8859 |     26.154 |     3.7\n",
      "   22 |   0.5428 |     17.127 |   0.8692 |     25.224 |     3.9\n",
      "   23 |   0.5077 |     16.048 |   0.8786 |     25.449 |     4.0\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 3\n",
      "Decoder layers: 4\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,472,034\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3027, 702])\n",
      "Y_train.shape: torch.Size([3027, 7])\n",
      "X_dev.shape: torch.Size([535, 258])\n",
      "Y_dev.shape: torch.Size([535, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.2150 |     57.846 |   1.4942 |     44.766 |     0.2\n",
      "    2 |   1.4444 |     43.283 |   1.3268 |     41.059 |     0.3\n",
      "    3 |   1.3035 |     40.304 |   1.2216 |     38.224 |     0.5\n",
      "    4 |   1.2061 |     37.452 |   1.1490 |     36.293 |     0.7\n",
      "    5 |   1.1290 |     35.216 |   1.0911 |     34.860 |     0.8\n",
      "    6 |   1.0667 |     33.642 |   1.0633 |     33.209 |     1.0\n",
      "    7 |   1.0099 |     31.814 |   1.0207 |     33.022 |     1.2\n",
      "    8 |   0.9547 |     29.826 |   0.9992 |     32.056 |     1.3\n",
      "    9 |   0.9096 |     28.857 |   0.9633 |     30.467 |     1.5\n",
      "   10 |   0.8666 |     26.963 |   0.9430 |     30.187 |     1.7\n",
      "   11 |   0.8231 |     25.559 |   0.9395 |     29.408 |     1.9\n",
      "   12 |   0.7905 |     24.898 |   0.9261 |     29.283 |     2.0\n",
      "   13 |   0.7492 |     23.345 |   0.9251 |     28.287 |     2.2\n",
      "   14 |   0.7180 |     22.420 |   0.9211 |     28.536 |     2.4\n",
      "   15 |   0.6899 |     21.556 |   0.8996 |     26.604 |     2.5\n",
      "   16 |   0.6518 |     20.416 |   0.8919 |     27.196 |     2.7\n",
      "   17 |   0.6311 |     19.844 |   0.8832 |     26.324 |     2.9\n",
      "   18 |   0.5956 |     18.654 |   0.9007 |     26.012 |     3.0\n",
      "   19 |   0.5717 |     17.718 |   0.9016 |     26.075 |     3.2\n",
      "   20 |   0.5499 |     17.217 |   0.8839 |     25.296 |     3.4\n",
      "   21 |   0.5318 |     16.898 |   0.8942 |     25.607 |     3.6\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 3\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,273,122\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3025, 702])\n",
      "Y_train.shape: torch.Size([3025, 7])\n",
      "X_dev.shape: torch.Size([537, 467])\n",
      "Y_dev.shape: torch.Size([537, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.1448 |     54.430 |   1.4718 |     44.382 |     0.2\n",
      "    2 |   1.4478 |     43.218 |   1.3075 |     41.403 |     0.3\n",
      "    3 |   1.3051 |     40.204 |   1.2299 |     39.168 |     0.5\n",
      "    4 |   1.2131 |     37.499 |   1.1604 |     37.151 |     0.6\n",
      "    5 |   1.1397 |     35.427 |   1.1215 |     36.096 |     0.8\n",
      "    6 |   1.0771 |     33.388 |   1.0792 |     34.513 |     1.0\n",
      "    7 |   1.0247 |     31.758 |   1.0706 |     34.575 |     1.1\n",
      "    8 |   0.9659 |     30.121 |   1.0323 |     32.775 |     1.3\n",
      "    9 |   0.9158 |     28.424 |   1.0079 |     32.030 |     1.4\n",
      "   10 |   0.8684 |     27.047 |   0.9884 |     31.440 |     1.6\n",
      "   11 |   0.8255 |     25.355 |   0.9679 |     31.626 |     1.8\n",
      "   12 |   0.7827 |     24.033 |   0.9537 |     29.795 |     1.9\n",
      "   13 |   0.7494 |     23.113 |   0.9527 |     29.174 |     2.1\n",
      "   14 |   0.7121 |     21.956 |   0.9394 |     29.268 |     2.2\n",
      "   15 |   0.6840 |     21.455 |   0.9308 |     28.212 |     2.4\n",
      "   16 |   0.6515 |     20.050 |   0.9314 |     28.709 |     2.6\n",
      "   17 |   0.6255 |     19.691 |   0.9265 |     27.592 |     2.7\n",
      "   18 |   0.5944 |     18.452 |   0.9371 |     27.405 |     2.9\n",
      "   19 |   0.5657 |     17.609 |   0.9340 |     27.436 |     3.0\n",
      "   20 |   0.5409 |     17.102 |   0.9431 |     27.343 |     3.2\n",
      "   21 |   0.5237 |     16.259 |   0.9651 |     27.188 |     3.4\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 3\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,273,122\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3038, 702])\n",
      "Y_train.shape: torch.Size([3038, 7])\n",
      "X_dev.shape: torch.Size([524, 221])\n",
      "Y_dev.shape: torch.Size([524, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   1.9748 |     51.745 |   1.4348 |     43.162 |     0.1\n",
      "    2 |   1.3398 |     41.354 |   1.2505 |     37.691 |     0.3\n",
      "    3 |   1.1944 |     37.080 |   1.1597 |     35.878 |     0.4\n",
      "    4 |   1.0911 |     33.915 |   1.0863 |     33.333 |     0.6\n",
      "    5 |   1.0037 |     31.303 |   1.0480 |     31.711 |     0.7\n",
      "    6 |   0.9315 |     29.263 |   0.9990 |     30.821 |     0.9\n",
      "    7 |   0.8636 |     26.871 |   0.9444 |     28.912 |     1.0\n",
      "    8 |   0.7932 |     24.781 |   0.9400 |     28.562 |     1.2\n",
      "    9 |   0.7357 |     22.817 |   0.8997 |     27.354 |     1.3\n",
      "   10 |   0.6843 |     21.006 |   0.8787 |     26.336 |     1.5\n",
      "   11 |   0.6346 |     19.360 |   0.8746 |     26.304 |     1.6\n",
      "   12 |   0.5884 |     18.170 |   0.8742 |     26.654 |     1.8\n",
      "   13 |   0.5479 |     16.617 |   0.8644 |     25.668 |     1.9\n",
      "   14 |   0.5016 |     15.125 |   0.8591 |     24.841 |     2.0\n",
      "   15 |   0.4623 |     14.099 |   0.8800 |     25.445 |     2.2\n",
      "   16 |   0.4320 |     12.876 |   0.8901 |     24.905 |     2.3\n",
      "   17 |   0.4034 |     12.267 |   0.8575 |     24.300 |     2.5\n",
      "   18 |   0.3739 |     11.301 |   0.8739 |     24.587 |     2.6\n",
      "   19 |   0.3536 |     10.698 |   0.8667 |     23.346 |     2.8\n",
      "   20 |   0.3230 |      9.551 |   0.8563 |     23.569 |     2.9\n",
      "   21 |   0.2971 |      8.613 |   0.9021 |     23.887 |     3.1\n",
      "   22 |   0.2807 |      8.339 |   0.8939 |     23.728 |     3.2\n",
      "   23 |   0.2654 |      7.955 |   0.9212 |     23.473 |     3.4\n",
      "   24 |   0.2477 |      7.445 |   0.9235 |     23.601 |     3.5\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 33 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 3\n",
      "Decoder layers: 4\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,471,777\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3025, 702])\n",
      "Y_train.shape: torch.Size([3025, 7])\n",
      "X_dev.shape: torch.Size([537, 337])\n",
      "Y_dev.shape: torch.Size([537, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.1490 |     55.950 |   1.4615 |     45.562 |     0.2\n",
      "    2 |   1.4380 |     43.339 |   1.3002 |     41.651 |     0.3\n",
      "    3 |   1.3103 |     40.749 |   1.2076 |     38.796 |     0.5\n",
      "    4 |   1.2234 |     38.259 |   1.1534 |     37.089 |     0.7\n",
      "    5 |   1.1545 |     36.314 |   1.1058 |     35.847 |     0.8\n",
      "    6 |   1.0950 |     34.127 |   1.0585 |     34.264 |     1.0\n",
      "    7 |   1.0401 |     32.727 |   1.0191 |     33.085 |     1.2\n",
      "    8 |   0.9839 |     30.926 |   0.9916 |     32.216 |     1.3\n",
      "    9 |   0.9386 |     29.587 |   0.9727 |     30.975 |     1.5\n",
      "   10 |   0.8916 |     28.556 |   0.9355 |     29.826 |     1.7\n",
      "   11 |   0.8514 |     27.102 |   0.9243 |     29.950 |     1.8\n",
      "   12 |   0.8105 |     25.686 |   0.9051 |     29.268 |     2.0\n",
      "   13 |   0.7676 |     24.248 |   0.8825 |     27.126 |     2.2\n",
      "   14 |   0.7328 |     23.003 |   0.8764 |     26.940 |     2.3\n",
      "   15 |   0.6980 |     22.187 |   0.8712 |     26.971 |     2.5\n",
      "   16 |   0.6711 |     21.421 |   0.8563 |     26.226 |     2.7\n",
      "   17 |   0.6411 |     20.044 |   0.8623 |     26.226 |     2.8\n",
      "   18 |   0.6064 |     19.163 |   0.8532 |     25.854 |     3.0\n",
      "   19 |   0.5850 |     18.138 |   0.8512 |     25.791 |     3.2\n",
      "   20 |   0.5540 |     17.504 |   0.8737 |     26.102 |     3.3\n",
      "   21 |   0.5330 |     16.860 |   0.8978 |     26.350 |     3.5\n",
      "   22 |   0.5096 |     16.138 |   0.8556 |     24.860 |     3.7\n",
      "   23 |   0.4977 |     15.752 |   0.8714 |     25.295 |     3.9\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 33 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 64\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 128\n",
      "Encoder layers: 4\n",
      "Decoder layers: 3\n",
      "Attention heads: 2\n",
      "Activation: relu\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 420,065\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3033, 702])\n",
      "Y_train.shape: torch.Size([3033, 7])\n",
      "X_dev.shape: torch.Size([529, 267])\n",
      "Y_dev.shape: torch.Size([529, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.4897 |     60.754 |   1.8273 |     44.675 |     0.1\n",
      "    2 |   1.6321 |     43.510 |   1.5212 |     42.313 |     0.2\n",
      "    3 |   1.4433 |     41.329 |   1.4041 |     40.706 |     0.3\n",
      "    4 |   1.3332 |     39.230 |   1.3289 |     39.319 |     0.4\n",
      "    5 |   1.2579 |     37.757 |   1.2676 |     37.083 |     0.5\n",
      "    6 |   1.1949 |     35.922 |   1.2271 |     37.303 |     0.6\n",
      "    7 |   1.1385 |     34.147 |   1.1870 |     35.507 |     0.7\n",
      "    8 |   1.0795 |     32.405 |   1.1457 |     34.184 |     0.8\n",
      "    9 |   1.0333 |     30.987 |   1.1220 |     33.680 |     0.9\n",
      "   10 |   0.9929 |     29.822 |   1.1027 |     33.522 |     1.0\n",
      "   11 |   0.9476 |     28.750 |   1.0659 |     32.420 |     1.1\n",
      "   12 |   0.9043 |     27.311 |   1.0681 |     32.136 |     1.2\n",
      "   13 |   0.8718 |     26.706 |   1.0345 |     31.474 |     1.3\n",
      "   14 |   0.8320 |     25.157 |   1.0351 |     31.317 |     1.4\n",
      "   15 |   0.7987 |     24.310 |   1.0061 |     30.372 |     1.5\n",
      "   16 |   0.7651 |     23.145 |   1.0063 |     30.529 |     1.6\n",
      "   17 |   0.7351 |     21.871 |   0.9746 |     29.458 |     1.8\n",
      "   18 |   0.7028 |     21.002 |   0.9702 |     29.647 |     1.9\n",
      "   19 |   0.6774 |     20.409 |   0.9675 |     29.112 |     2.0\n",
      "   20 |   0.6512 |     19.530 |   0.9676 |     29.112 |     2.1\n",
      "   21 |   0.6298 |     18.892 |   0.9779 |     28.986 |     2.2\n",
      "   22 |   0.6080 |     18.249 |   0.9687 |     28.670 |     2.3\n",
      "   23 |   0.5872 |     17.562 |   0.9757 |     29.395 |     2.4\n",
      "   24 |   0.5679 |     16.870 |   0.9541 |     28.103 |     2.5\n",
      "   25 |   0.5404 |     15.974 |   0.9586 |     27.568 |     2.6\n",
      "   26 |   0.5241 |     15.787 |   0.9473 |     27.316 |     2.7\n",
      "   27 |   0.4979 |     14.771 |   0.9576 |     27.694 |     2.8\n",
      "   28 |   0.4894 |     14.573 |   0.9830 |     27.883 |     2.9\n",
      "   29 |   0.4659 |     13.672 |   0.9644 |     26.465 |     3.0\n",
      "   30 |   0.4487 |     13.194 |   0.9618 |     26.906 |     3.1\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Transformer\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Max sequence length: 800\n",
      "Embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Feedforward dimension: 256\n",
      "Encoder layers: 3\n",
      "Decoder layers: 3\n",
      "Attention heads: 4\n",
      "Activation: relu\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,273,250\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3017, 702])\n",
      "Y_train.shape: torch.Size([3017, 7])\n",
      "X_dev.shape: torch.Size([545, 323])\n",
      "Y_dev.shape: torch.Size([545, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.1872 |     55.966 |   1.4831 |     43.945 |     0.2\n",
      "    2 |   1.4397 |     43.084 |   1.3216 |     42.232 |     0.3\n",
      "    3 |   1.3005 |     39.874 |   1.2380 |     39.266 |     0.5\n",
      "    4 |   1.2093 |     37.686 |   1.1776 |     37.401 |     0.6\n",
      "    5 |   1.1284 |     35.145 |   1.1263 |     35.505 |     0.8\n",
      "    6 |   1.0710 |     33.637 |   1.1074 |     35.168 |     0.9\n",
      "    7 |   1.0105 |     31.831 |   1.0730 |     33.089 |     1.1\n",
      "    8 |   0.9613 |     30.328 |   1.0541 |     32.538 |     1.2\n",
      "    9 |   0.9089 |     28.676 |   1.0332 |     31.376 |     1.4\n",
      "   10 |   0.8630 |     27.201 |   1.0155 |     30.765 |     1.6\n",
      "   11 |   0.8257 |     25.936 |   0.9955 |     30.122 |     1.7\n",
      "   12 |   0.7823 |     24.677 |   0.9620 |     29.205 |     1.9\n",
      "   13 |   0.7463 |     23.130 |   0.9679 |     29.388 |     2.0\n",
      "   14 |   0.7149 |     22.495 |   0.9480 |     27.645 |     2.2\n",
      "   15 |   0.6792 |     21.318 |   0.9533 |     27.920 |     2.3\n",
      "   16 |   0.6542 |     20.445 |   0.9659 |     28.012 |     2.5\n",
      "   17 |   0.6283 |     19.788 |   0.9527 |     27.951 |     2.7\n",
      "   18 |   0.5955 |     18.644 |   0.9296 |     26.575 |     2.8\n",
      "   19 |   0.5752 |     18.048 |   0.9546 |     26.789 |     3.0\n",
      "   20 |   0.5388 |     16.915 |   0.9465 |     26.544 |     3.1\n",
      "   21 |   0.5242 |     16.385 |   0.9562 |     26.789 |     3.3\n",
      "   22 |   0.4986 |     15.777 |   0.9504 |     27.095 |     3.4\n",
      "Early stopping\n",
      "\n",
      "Mean: Precision            0.107403\n",
      "Recall               0.283777\n",
      "F1                   0.151967\n",
      "Precision_level3     0.198204\n",
      "Recall_level3        0.499308\n",
      "F1_level3            0.275588\n",
      "Precision_level2     0.297153\n",
      "Recall_level2        0.627399\n",
      "F1_level2            0.382957\n",
      "Precision level 1    0.553395\n",
      "Precision level 2    0.771255\n",
      "Precision level 3    0.668488\n",
      "Precision level 4    0.457785\n",
      "Recall level 1       0.674569\n",
      "Recall level 2       0.843365\n",
      "Recall level 3       0.782099\n",
      "Recall level 4       0.629881\n",
      "dtype: float64\n",
      "Std: Precision            0.006367\n",
      "Recall               0.016613\n",
      "F1                   0.009036\n",
      "Precision_level3     0.011475\n",
      "Recall_level3        0.024290\n",
      "F1_level3            0.014775\n",
      "Precision_level2     0.019241\n",
      "Recall_level2        0.024292\n",
      "F1_level2            0.019269\n",
      "Precision level 1    0.022420\n",
      "Precision level 2    0.015881\n",
      "Precision level 3    0.022445\n",
      "Precision level 4    0.019160\n",
      "Recall level 1       0.017263\n",
      "Recall level 2       0.020906\n",
      "Recall level 3       0.016027\n",
      "Recall level 4       0.015273\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 47899, 2025, 1, 20, 99, 1020, 345, 78] \n",
    "columns = [\n",
    "    'Seed', \n",
    "    'Precision', 'Recall', 'F1',\n",
    "    'Precision_level3', 'Recall_level3', 'F1_level3',\n",
    "    'Precision_level2', 'Recall_level2', 'F1_level2',\n",
    "    'Precision level 1', 'Precision level 2', 'Precision level 3', 'Precision level 4',\n",
    "    'Recall level 1', 'Recall level 2', 'Recall level 3', 'Recall level 4',\n",
    "    '#Compounds that have at least one match'\n",
    "]\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seeds(seed)\n",
    "\n",
    "    train_set = pd.read_csv(f'../Datasets/Rep_train_set{seed}.csv')\n",
    "    test_set = pd.read_csv(f'../Datasets/Rep_test_set{seed}.csv')\n",
    "    val_set = pd.read_csv(f'../Datasets/Rep_val_set{seed}.csv')\n",
    "    \n",
    "    new_train_set = multiplicate_rows(train_set)\n",
    "    new_val_set = multiplicate_rows(val_set)\n",
    "    new_test_set = multiplicate_rows(test_set)\n",
    "    \n",
    "    train_descriptors = extract_descriptors(new_train_set)\n",
    "    test_descriptors = extract_descriptors(new_test_set)\n",
    "    test_descriptors2 = extract_descriptors(test_set)\n",
    "    val_descriptors = extract_descriptors(new_val_set)\n",
    "    val_descriptors2 = extract_descriptors(val_set)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_descriptors = torch.tensor(scaler.fit_transform(train_descriptors.numpy()), dtype=torch.float32)\n",
    "    val_descriptors = torch.tensor(scaler.transform(val_descriptors.numpy()), dtype=torch.float32)\n",
    "    test_descriptors = torch.tensor(scaler.transform(test_descriptors.numpy()), dtype=torch.float32)\n",
    "    val_descriptors2 = torch.tensor(scaler.transform(val_descriptors2.numpy()), dtype=torch.float32)\n",
    "    test_descriptors2 = torch.tensor(scaler.transform(test_descriptors2.numpy()), dtype=torch.float32)\n",
    "    \n",
    "    source_train = source(new_train_set)\n",
    "    source_test = source(new_test_set)\n",
    "    # Test set without duplicated compounds\n",
    "    source_test2 = source(test_set)\n",
    "    source_val = source(new_val_set)\n",
    "    # Val set without duplicated compounds\n",
    "    source_val2 = source(val_set)\n",
    "    \n",
    "    target_train = target(new_train_set)\n",
    "    target_test = target(new_test_set)\n",
    "    target_val = target(new_val_set)\n",
    "    \n",
    "    # An Index object represents a mapping from the vocabulary to integers (indices) to feed into the models\n",
    "    source_index = index.Index(source_train)\n",
    "    target_index = index.Index(target_train)\n",
    "    \n",
    "    # Create tensors\n",
    "    X_train = source_index.text2tensor(source_train)\n",
    "    y_train = target_index.text2tensor(target_train)\n",
    "    X_val = source_index.text2tensor(source_val)\n",
    "    X_val2 = source_index.text2tensor(source_val2)\n",
    "    y_val = target_index.text2tensor(target_val)     \n",
    "    X_test = source_index.text2tensor(source_test)\n",
    "    X_test2 = source_index.text2tensor(source_test2)\n",
    "    y_test = target_index.text2tensor(target_test)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        X_train = X_train.to(\"cuda\")\n",
    "        y_train = y_train.to(\"cuda\")\n",
    "        train_descriptors = train_descriptors.to(\"cuda\") \n",
    "        test_descriptors = test_descriptors.to(\"cuda\")\n",
    "        test_descriptors2 = test_descriptors2.to(\"cuda\")\n",
    "        val_descriptors = val_descriptors.to(\"cuda\")\n",
    "        val_descriptors2 = val_descriptors2.to(\"cuda\")\n",
    "        X_val = X_val.to(\"cuda\")\n",
    "        X_val2 = X_val2.to(\"cuda\")\n",
    "        y_val = y_val.to(\"cuda\")\n",
    "        X_test= X_test.to(\"cuda\")\n",
    "        y_test = y_test.to(\"cuda\")\n",
    "        X_test2 = X_test2.to(\"cuda\")\n",
    "\n",
    "    if os.path.exists(f\"s_mmtransformer_results{seed}.csv\"):\n",
    "        best_hyperparameters = (pd.read_csv(f\"s_mmtransformer_results{seed}.csv\")).loc[0]\n",
    "    else:\n",
    "        best_hyperparameters = hyperparametersselection(seed, source_index, target_index, X_train, X_val, X_val2, train_descriptors, val_descriptors, val_descriptors2, y_train, y_val)\n",
    "\n",
    "    model = multimodal_models.MultimodalTransformer(\n",
    "                source_index, \n",
    "                target_index,\n",
    "                max_sequence_length = 800,\n",
    "                embedding_dimension = best_hyperparameters['embedding_dim'],\n",
    "                descriptors_dimension=train_descriptors.shape[1],\n",
    "                feedforward_dimension = best_hyperparameters['feedforward_dim'],\n",
    "                encoder_layers = best_hyperparameters['enc_layers'],\n",
    "                decoder_layers = best_hyperparameters['dec_layers'],\n",
    "                attention_heads = best_hyperparameters['attention_heads'],\n",
    "                activation = \"relu\",\n",
    "                dropout = best_hyperparameters['dropout'])   \n",
    "    model.to(\"cuda\")\n",
    "    q = model.fit(X_train, \n",
    "            train_descriptors,\n",
    "            y_train,\n",
    "            X_val, \n",
    "            val_descriptors,\n",
    "            y_val, \n",
    "            batch_size = 32, \n",
    "            epochs = 150, \n",
    "            learning_rate = best_hyperparameters['learning_rate'], \n",
    "            weight_decay = best_hyperparameters['weight_decay'],\n",
    "            progress_bar = 0, \n",
    "            save_path = None)\n",
    "    model.load_state_dict(torch.load(\"best_multimodalmodel.pth\", weights_only=True))\n",
    "    loss, error_rate = model.evaluate(X_test, test_descriptors, y_test, batch_size = 32) \n",
    "\n",
    "    predictions, log_probabilities = search_algorithms.multimodal_beam_search(\n",
    "        model, \n",
    "        X_test2, # Make predictions with test set \n",
    "        test_descriptors2,\n",
    "        predictions = 6, # max length of the predicted sequence\n",
    "        beam_width = 10,\n",
    "        batch_size = 32, \n",
    "        progress_bar = 0\n",
    "    )\n",
    "    output_beam = [target_index.tensor2text(p) for p in predictions]\n",
    "\n",
    "    predictions_clean = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            if len(clean_pred) == 5:\n",
    "                interm.append(clean_pred)\n",
    "            if len(interm) == 3:\n",
    "                break\n",
    "        predictions_clean.append(interm)\n",
    "    predictions_clean_level3 = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            pred_3 = clean_pred[0:4]\n",
    "            if len(pred_3) == 4 and pred_3 not in interm:\n",
    "                interm.append(pred_3)\n",
    "        predictions_clean_level3.append(interm[0:3])\n",
    "    predictions_clean_level2 = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            pred_2 = clean_pred[0:3]\n",
    "            if len(pred_2) == 3 and pred_2 not in interm:\n",
    "                interm.append(pred_2)\n",
    "        predictions_clean_level2.append(interm[0:3])\n",
    "    precision_1, precision_2, precision_3, precision_4 = defined_metrics.precision(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes')\n",
    "    recall_1, recall_2, recall_3, recall_4, counter_compound_match = defined_metrics.recall(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes')\n",
    "    precisions, recalls, f1s = defined_metrics.complete_metrics(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_level3, recalls_level3, f1s_level3 = defined_metrics.complete_metrics_level3(predictions_clean_level3, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_level2, recalls_level2, f1s_level2 = defined_metrics.complete_metrics_level2(predictions_clean_level2, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_average = sum(precisions)/len(precisions)\n",
    "    recalls_average = sum(recalls)/len(recalls)\n",
    "    f1s_average = sum(f1s)/len(f1s)\n",
    "\n",
    "    precisions_average_level3 = sum(precisions_level3)/len(precisions_level3)\n",
    "    recalls_average_level3 = sum(recalls_level3)/len(recalls_level3)\n",
    "    f1s_average_level3 = sum(f1s_level3)/len(f1s_level3)\n",
    "\n",
    "    precisions_average_level2 = sum(precisions_level2)/len(precisions_level2)\n",
    "    recalls_average_level2 = sum(recalls_level2)/len(recalls_level2)\n",
    "    f1s_average_level2 = sum(f1s_level2)/len(f1s_level2)\n",
    "    \n",
    "    metrics = {\n",
    "        'Precision': precisions_average, \n",
    "        'Recall': recalls_average,\n",
    "        'F1': f1s_average,\n",
    "        'Precision_level3': precisions_average_level3, \n",
    "        'Recall_level3': recalls_average_level3,\n",
    "        'F1_level3': f1s_average_level3,\n",
    "        'Precision_level2': precisions_average_level2, \n",
    "        'Recall_level2': recalls_average_level2,\n",
    "        'F1_level2': f1s_average_level2,\n",
    "        'Precision level 1': precision_1,\n",
    "        'Precision level 2': precision_2,\n",
    "        'Precision level 3': precision_3,\n",
    "        'Precision level 4': precision_4,\n",
    "        'Recall level 1': recall_1,\n",
    "        'Recall level 2': recall_2,\n",
    "        'Recall level 3': recall_3,\n",
    "        'Recall level 4': recall_4,\n",
    "        '#Compounds that have at least one match': counter_compound_match\n",
    "    }\n",
    "    \n",
    "    # Build the row\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "metrics_df.to_csv(\"multimodaltransformer_metrics.csv\", index=False)\n",
    "print(\"Mean:\", metrics_df.mean(numeric_only=True))\n",
    "print(\"Std:\", metrics_df.std(numeric_only=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
