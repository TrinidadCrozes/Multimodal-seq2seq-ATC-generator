Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 485,730

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4438 |     59.690 |   1.7756 |     45.633 |     0.1
    2 |   1.5944 |     43.558 |   1.4827 |     43.523 |     0.2
    3 |   1.4173 |     41.534 |   1.3682 |     40.404 |     0.4
    4 |   1.3128 |     38.986 |   1.2863 |     38.146 |     0.5
    5 |   1.2274 |     37.067 |   1.2253 |     36.869 |     0.6
    6 |   1.1611 |     35.313 |   1.1674 |     36.067 |     0.7
    7 |   1.0983 |     33.355 |   1.1185 |     34.106 |     0.8
    8 |   1.0423 |     32.026 |   1.0884 |     33.333 |     1.0
    9 |   0.9892 |     29.997 |   1.0536 |     32.234 |     1.1
   10 |   0.9394 |     28.651 |   1.0315 |     32.115 |     1.2
   11 |   0.8952 |     26.969 |   0.9993 |     31.016 |     1.3
   12 |   0.8572 |     26.169 |   0.9869 |     31.105 |     1.4
   13 |   0.8155 |     24.338 |   0.9643 |     30.333 |     1.6
   14 |   0.7741 |     23.230 |   0.9519 |     29.501 |     1.7
   15 |   0.7479 |     22.518 |   0.9582 |     30.630 |     1.8
   16 |   0.7177 |     21.741 |   0.9407 |     29.441 |     1.9
   17 |   0.6735 |     20.042 |   0.9041 |     28.520 |     2.1
   18 |   0.6462 |     19.303 |   0.9224 |     28.580 |     2.2
   19 |   0.6235 |     18.652 |   0.9031 |     27.392 |     2.3
   20 |   0.5942 |     17.494 |   0.9092 |     27.570 |     2.4
   21 |   0.5695 |     17.141 |   0.9064 |     27.867 |     2.5
   22 |   0.5412 |     15.928 |   0.8994 |     27.481 |     2.7
   23 |   0.5187 |     15.371 |   0.8907 |     27.362 |     2.8
   24 |   0.5007 |     14.725 |   0.8996 |     26.322 |     2.9
   25 |   0.4828 |     14.378 |   0.8876 |     26.441 |     3.0
   26 |   0.4589 |     13.529 |   0.9082 |     26.441 |     3.2
   27 |   0.4374 |     12.878 |   0.8840 |     25.966 |     3.3
   28 |   0.4190 |     12.464 |   0.8897 |     24.985 |     3.4
   29 |   0.4048 |     12.001 |   0.9113 |     25.817 |     3.5
   30 |   0.3914 |     11.543 |   0.8901 |     25.312 |     3.6
   31 |   0.3668 |     10.732 |   0.9192 |     25.431 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 420,130

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6873 |     65.415 |   2.0027 |     49.198 |     0.2
    2 |   1.8817 |     46.492 |   1.6089 |     45.247 |     0.3
    3 |   1.6157 |     44.700 |   1.4708 |     43.583 |     0.5
    4 |   1.4902 |     43.161 |   1.3920 |     42.246 |     0.6
    5 |   1.4049 |     41.700 |   1.3263 |     40.671 |     0.8
    6 |   1.3405 |     40.018 |   1.2728 |     38.265 |     1.0
    7 |   1.2861 |     38.937 |   1.2419 |     37.611 |     1.1
    8 |   1.2407 |     37.872 |   1.2049 |     36.809 |     1.3
    9 |   1.1916 |     36.593 |   1.1763 |     36.185 |     1.4
   10 |   1.1516 |     35.368 |   1.1428 |     34.878 |     1.6
   11 |   1.1147 |     34.525 |   1.1303 |     34.343 |     1.7
   12 |   1.0867 |     33.416 |   1.1153 |     34.254 |     1.9
   13 |   1.0468 |     32.236 |   1.0921 |     33.779 |     2.1
   14 |   1.0220 |     31.800 |   1.0799 |     33.630 |     2.2
   15 |   0.9940 |     30.692 |   1.0588 |     33.007 |     2.4
   16 |   0.9619 |     29.677 |   1.0504 |     32.353 |     2.5
   17 |   0.9357 |     28.877 |   1.0524 |     32.383 |     2.7
   18 |   0.9103 |     28.304 |   1.0400 |     32.264 |     2.9
   19 |   0.8887 |     27.416 |   1.0393 |     32.501 |     3.0
   20 |   0.8612 |     26.952 |   1.0408 |     32.204 |     3.2
   21 |   0.8397 |     26.169 |   1.0170 |     31.640 |     3.3
   22 |   0.8213 |     25.596 |   1.0204 |     31.729 |     3.5
   23 |   0.7965 |     24.840 |   1.0090 |     30.570 |     3.7
   24 |   0.7797 |     24.349 |   1.0096 |     31.521 |     3.8
   25 |   0.7550 |     23.599 |   1.0304 |     31.313 |     4.0
   26 |   0.7452 |     22.860 |   1.0165 |     31.135 |     4.1
   27 |   0.7235 |     22.336 |   1.0224 |     31.194 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,474

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8853 |     49.824 |   1.4297 |     44.088 |     0.2
    2 |   1.3301 |     40.884 |   1.2783 |     39.483 |     0.4
    3 |   1.1889 |     36.973 |   1.1604 |     35.651 |     0.5
    4 |   1.0780 |     33.758 |   1.0865 |     34.076 |     0.7
    5 |   0.9865 |     30.421 |   1.0357 |     32.264 |     0.9
    6 |   0.9069 |     27.868 |   0.9713 |     30.719 |     1.1
    7 |   0.8401 |     25.546 |   0.9336 |     29.590 |     1.3
    8 |   0.7658 |     23.224 |   0.9070 |     29.204 |     1.4
    9 |   0.7156 |     21.851 |   0.8760 |     27.718 |     1.6
   10 |   0.6662 |     20.285 |   0.8838 |     28.223 |     1.8
   11 |   0.6105 |     18.200 |   0.8626 |     26.708 |     2.0
   12 |   0.5627 |     17.069 |   0.8216 |     25.550 |     2.2
   13 |   0.5156 |     15.602 |   0.8304 |     25.401 |     2.3
   14 |   0.4806 |     14.422 |   0.8451 |     26.173 |     2.5
   15 |   0.4432 |     13.027 |   0.8185 |     24.213 |     2.7
   16 |   0.4166 |     12.497 |   0.8278 |     25.163 |     2.9
   17 |   0.3806 |     11.311 |   0.8407 |     24.034 |     3.1
   18 |   0.3508 |     10.324 |   0.8368 |     24.094 |     3.2
   19 |   0.3252 |      9.530 |   0.8530 |     25.163 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 535,714

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4895 |     60.015 |   1.8416 |     45.722 |     0.1
    2 |   1.6480 |     44.314 |   1.5395 |     44.623 |     0.3
    3 |   1.4557 |     41.849 |   1.4056 |     41.028 |     0.4
    4 |   1.3367 |     39.758 |   1.3098 |     39.632 |     0.6
    5 |   1.2453 |     37.574 |   1.2487 |     37.493 |     0.7
    6 |   1.1662 |     35.087 |   1.1876 |     35.829 |     0.9
    7 |   1.0973 |     32.798 |   1.1314 |     34.611 |     1.0
    8 |   1.0339 |     30.719 |   1.0907 |     34.165 |     1.2
    9 |   0.9775 |     29.291 |   1.0441 |     32.145 |     1.3
   10 |   0.9236 |     27.702 |   1.0087 |     31.105 |     1.5
   11 |   0.8748 |     26.406 |   1.0191 |     31.788 |     1.6
   12 |   0.8339 |     25.165 |   0.9808 |     30.541 |     1.8
   13 |   0.7898 |     23.434 |   0.9543 |     29.382 |     1.9
   14 |   0.7487 |     22.452 |   0.9267 |     27.926 |     2.1
   15 |   0.7181 |     21.901 |   0.9208 |     27.778 |     2.2
   16 |   0.6789 |     20.069 |   0.9203 |     27.778 |     2.4
   17 |   0.6500 |     19.507 |   0.8955 |     27.659 |     2.6
   18 |   0.6202 |     18.509 |   0.9051 |     27.510 |     2.7
   19 |   0.5924 |     17.621 |   0.8937 |     27.184 |     2.9
   20 |   0.5643 |     16.766 |   0.8804 |     26.946 |     3.0
   21 |   0.5400 |     16.137 |   0.8889 |     26.679 |     3.2
   22 |   0.5158 |     15.293 |   0.9096 |     26.471 |     3.3
   23 |   0.4935 |     14.235 |   0.8990 |     27.302 |     3.5
   24 |   0.4640 |     13.369 |   0.8840 |     25.728 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,506

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0901 |     53.226 |   1.5066 |     44.058 |     0.1
    2 |   1.3773 |     41.043 |   1.2886 |     39.513 |     0.2
    3 |   1.2124 |     37.194 |   1.1780 |     35.769 |     0.4
    4 |   1.0998 |     33.499 |   1.1203 |     35.918 |     0.5
    5 |   1.0208 |     31.359 |   1.0407 |     32.383 |     0.6
    6 |   0.9383 |     28.728 |   1.0076 |     31.402 |     0.7
    7 |   0.8748 |     26.837 |   1.0124 |     32.561 |     0.9
    8 |   0.8153 |     24.983 |   0.9706 |     31.313 |     1.0
    9 |   0.7639 |     23.285 |   0.9016 |     27.778 |     1.1
   10 |   0.7082 |     21.603 |   0.8799 |     27.748 |     1.2
   11 |   0.6633 |     20.136 |   0.8707 |     26.708 |     1.4
   12 |   0.6279 |     18.768 |   0.8805 |     27.035 |     1.5
   13 |   0.5818 |     17.544 |   0.8652 |     26.114 |     1.6
   14 |   0.5459 |     16.336 |   0.8433 |     25.995 |     1.7
   15 |   0.5135 |     15.315 |   0.8287 |     25.520 |     1.9
   16 |   0.4831 |     14.648 |   0.8556 |     25.995 |     2.0
   17 |   0.4555 |     13.595 |   0.8583 |     25.817 |     2.1
   18 |   0.4231 |     12.503 |   0.8413 |     24.540 |     2.2
   19 |   0.4008 |     11.896 |   0.8679 |     25.490 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,471,778

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4669 |     45.456 |   1.2088 |     39.721 |     0.1
    2 |   1.1567 |     38.788 |   1.1349 |     37.760 |     0.3
    3 |   1.0690 |     36.620 |   1.0594 |     36.928 |     0.4
    4 |   0.9900 |     33.229 |   0.9977 |     33.393 |     0.5
    5 |   0.9374 |     31.502 |   0.9457 |     32.709 |     0.6
    6 |   0.8777 |     29.826 |   0.9100 |     30.660 |     0.8
    7 |   0.8313 |     27.691 |   0.9106 |     30.244 |     0.9
    8 |   0.7823 |     26.511 |   0.8951 |     29.828 |     1.0
    9 |   0.7469 |     25.403 |   0.8605 |     28.907 |     1.2
   10 |   0.7089 |     23.842 |   0.8474 |     28.402 |     1.3
   11 |   0.6719 |     22.590 |   0.8486 |     28.105 |     1.4
   12 |   0.6458 |     22.033 |   0.8149 |     27.094 |     1.5
   13 |   0.6121 |     20.996 |   0.8176 |     27.302 |     1.7
   14 |   0.5985 |     20.500 |   0.8196 |     26.144 |     1.8
   15 |   0.5634 |     19.187 |   0.8071 |     26.055 |     1.9
   16 |   0.5415 |     18.652 |   0.7990 |     25.074 |     2.1
   17 |   0.5001 |     17.146 |   0.8002 |     25.193 |     2.2
   18 |   0.4801 |     16.385 |   0.7788 |     23.381 |     2.3
   19 |   0.4621 |     15.801 |   0.8070 |     25.550 |     2.4
   20 |   0.4568 |     15.718 |   0.8148 |     24.866 |     2.6
   21 |   0.4198 |     14.521 |   0.8128 |     24.183 |     2.7
   22 |   0.3904 |     13.534 |   0.8313 |     24.837 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,202

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0699 |     53.072 |   1.4774 |     44.415 |     0.2
    2 |   1.3575 |     40.966 |   1.2942 |     39.572 |     0.3
    3 |   1.2156 |     37.872 |   1.1953 |     36.958 |     0.5
    4 |   1.1143 |     34.850 |   1.1186 |     34.967 |     0.7
    5 |   1.0372 |     32.313 |   1.0590 |     33.928 |     0.9
    6 |   0.9566 |     29.572 |   1.0142 |     31.729 |     1.0
    7 |   0.8915 |     27.542 |   0.9727 |     31.610 |     1.2
    8 |   0.8274 |     25.347 |   0.9540 |     30.392 |     1.4
    9 |   0.7747 |     23.880 |   0.9219 |     29.441 |     1.6
   10 |   0.7186 |     21.807 |   0.9090 |     28.758 |     1.7
   11 |   0.6744 |     20.433 |   0.8871 |     27.867 |     1.9
   12 |   0.6262 |     19.137 |   0.8715 |     26.768 |     2.1
   13 |   0.5843 |     17.742 |   0.8921 |     27.124 |     2.3
   14 |   0.5530 |     16.849 |   0.8834 |     26.560 |     2.4
   15 |   0.5246 |     15.922 |   0.8483 |     26.055 |     2.6
   16 |   0.4802 |     14.339 |   0.8565 |     26.322 |     2.8
   17 |   0.4524 |     13.777 |   0.8473 |     25.045 |     3.0
   18 |   0.4245 |     12.630 |   0.8767 |     25.371 |     3.1
   19 |   0.3967 |     11.951 |   0.8613 |     25.163 |     3.3
   20 |   0.3780 |     11.058 |   0.8720 |     25.045 |     3.5
   21 |   0.3573 |     10.600 |   0.8990 |     25.906 |     3.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,202

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4884 |     45.979 |   1.2619 |     43.167 |     0.2
    2 |   1.1636 |     39.157 |   1.1389 |     38.562 |     0.3
    3 |   1.0586 |     35.705 |   1.0242 |     34.581 |     0.5
    4 |   0.9894 |     33.736 |   0.9853 |     32.947 |     0.7
    5 |   0.9291 |     31.304 |   0.9497 |     32.620 |     0.9
    6 |   0.8869 |     30.118 |   0.9588 |     32.680 |     1.0
    7 |   0.8566 |     29.208 |   0.9045 |     30.808 |     1.2
    8 |   0.8084 |     27.735 |   0.8995 |     30.957 |     1.4
    9 |   0.7682 |     26.379 |   0.8642 |     30.392 |     1.6
   10 |   0.7424 |     25.447 |   0.8744 |     28.818 |     1.7
   11 |   0.7250 |     24.989 |   0.8484 |     28.639 |     1.9
   12 |   0.6894 |     23.704 |   0.8525 |     28.342 |     2.1
   13 |   0.6692 |     22.733 |   0.8479 |     27.451 |     2.3
   14 |   0.6494 |     22.116 |   0.8463 |     28.194 |     2.4
   15 |   0.6273 |     21.895 |   0.8276 |     27.124 |     2.6
   16 |   0.5998 |     20.748 |   0.8422 |     27.362 |     2.8
   17 |   0.5851 |     20.158 |   0.8253 |     26.381 |     3.0
   18 |   0.5652 |     19.584 |   0.8228 |     25.966 |     3.1
   19 |   0.5583 |     19.198 |   0.8290 |     26.381 |     3.3
   20 |   0.5281 |     18.233 |   0.8044 |     25.045 |     3.5
   21 |   0.5077 |     17.378 |   0.8041 |     25.074 |     3.7
   22 |   0.4897 |     16.904 |   0.8287 |     25.282 |     3.8
   23 |   0.4764 |     16.595 |   0.7909 |     24.480 |     4.0
   24 |   0.4625 |     15.928 |   0.8308 |     25.847 |     4.2
   25 |   0.4486 |     15.652 |   0.8378 |     25.550 |     4.3
   26 |   0.4308 |     14.935 |   0.8059 |     24.183 |     4.5
   27 |   0.4199 |     14.637 |   0.8509 |     25.104 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 485,730

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4235 |     58.857 |   1.7989 |     46.227 |     0.1
    2 |   1.6273 |     43.658 |   1.5215 |     41.830 |     0.2
    3 |   1.4468 |     41.242 |   1.3934 |     39.037 |     0.4
    4 |   1.3295 |     38.975 |   1.3046 |     37.077 |     0.5
    5 |   1.2393 |     36.670 |   1.2316 |     36.334 |     0.6
    6 |   1.1719 |     35.446 |   1.1888 |     34.997 |     0.7
    7 |   1.1031 |     33.284 |   1.1428 |     33.809 |     0.9
    8 |   1.0455 |     31.442 |   1.1098 |     33.244 |     1.0
    9 |   0.9905 |     29.776 |   1.0744 |     32.204 |     1.1
   10 |   0.9422 |     28.342 |   1.0276 |     31.075 |     1.2
   11 |   0.8917 |     26.864 |   1.0194 |     31.224 |     1.3
   12 |   0.8498 |     25.292 |   1.0009 |     30.154 |     1.5
   13 |   0.8044 |     24.024 |   0.9699 |     29.085 |     1.6
   14 |   0.7669 |     22.926 |   0.9482 |     29.204 |     1.7
   15 |   0.7382 |     21.696 |   0.9476 |     28.520 |     1.8
   16 |   0.7011 |     20.538 |   0.9393 |     27.926 |     2.0
   17 |   0.6686 |     19.799 |   0.9346 |     27.807 |     2.1
   18 |   0.6404 |     19.022 |   0.9197 |     27.481 |     2.2
   19 |   0.6198 |     18.266 |   0.9125 |     27.659 |     2.3
   20 |   0.5892 |     17.461 |   0.9205 |     27.005 |     2.4
   21 |   0.5683 |     16.501 |   0.9055 |     26.976 |     2.6
   22 |   0.5416 |     15.724 |   0.9123 |     27.659 |     2.7
   23 |   0.5197 |     15.040 |   0.9091 |     26.263 |     2.8
   24 |   0.5032 |     14.786 |   0.8988 |     26.827 |     2.9
   25 |   0.4761 |     13.975 |   0.9103 |     26.173 |     3.1
   26 |   0.4596 |     13.413 |   0.9351 |     26.560 |     3.2
   27 |   0.4372 |     12.795 |   0.9100 |     26.203 |     3.3
   28 |   0.4161 |     11.962 |   0.9246 |     26.619 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 436,898

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7335 |     66.595 |   1.9960 |     46.851 |     0.1
    2 |   1.8799 |     46.222 |   1.6092 |     44.534 |     0.2
    3 |   1.6185 |     44.308 |   1.4723 |     43.613 |     0.3
    4 |   1.4959 |     42.963 |   1.3873 |     42.365 |     0.4
    5 |   1.4106 |     41.485 |   1.3243 |     40.226 |     0.5
    6 |   1.3459 |     40.122 |   1.2733 |     38.770 |     0.6
    7 |   1.2940 |     39.372 |   1.2345 |     37.879 |     0.7
    8 |   1.2473 |     38.258 |   1.2025 |     36.869 |     0.8
    9 |   1.2073 |     36.935 |   1.1708 |     35.354 |     0.9
   10 |   1.1706 |     35.925 |   1.1381 |     34.700 |     1.0
   11 |   1.1323 |     35.076 |   1.1219 |     34.225 |     1.1
   12 |   1.1034 |     34.028 |   1.1001 |     34.165 |     1.2
   13 |   1.0656 |     32.914 |   1.0819 |     33.571 |     1.3
   14 |   1.0400 |     32.467 |   1.0741 |     33.601 |     1.4
   15 |   1.0135 |     31.381 |   1.0587 |     33.512 |     1.5
   16 |   0.9870 |     30.719 |   1.0500 |     33.304 |     1.6
   17 |   0.9558 |     29.853 |   1.0343 |     32.917 |     1.7
   18 |   0.9318 |     28.822 |   1.0203 |     32.323 |     1.8
   19 |   0.9109 |     28.359 |   1.0123 |     31.462 |     1.9
   20 |   0.8885 |     27.581 |   1.0018 |     31.996 |     2.0
   21 |   0.8653 |     27.140 |   0.9811 |     30.511 |     2.2
   22 |   0.8503 |     26.655 |   0.9762 |     31.462 |     2.3
   23 |   0.8247 |     25.722 |   0.9798 |     30.749 |     2.4
   24 |   0.8071 |     25.226 |   0.9703 |     30.214 |     2.5
   25 |   0.7830 |     24.669 |   0.9761 |     29.679 |     2.6
   26 |   0.7695 |     24.002 |   0.9685 |     30.333 |     2.7
   27 |   0.7566 |     23.345 |   0.9786 |     30.749 |     2.8
   28 |   0.7395 |     23.345 |   0.9629 |     29.798 |     2.9
   29 |   0.7206 |     22.447 |   0.9640 |     30.481 |     3.0
   30 |   0.7056 |     22.309 |   0.9768 |     29.590 |     3.1
   31 |   0.6920 |     21.757 |   0.9778 |     30.481 |     3.2
   32 |   0.6744 |     21.024 |   0.9661 |     29.649 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 602,466

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7030 |     49.195 |   1.3201 |     42.751 |     0.2
    2 |   1.2851 |     42.389 |   1.2279 |     41.176 |     0.3
    3 |   1.1825 |     39.792 |   1.1078 |     37.136 |     0.5
    4 |   1.1097 |     37.497 |   1.0895 |     37.017 |     0.7
    5 |   1.0625 |     35.484 |   1.0309 |     34.789 |     0.9
    6 |   1.0166 |     34.607 |   1.0138 |     34.551 |     1.0
    7 |   0.9765 |     32.649 |   0.9595 |     33.007 |     1.2
    8 |   0.9376 |     31.646 |   0.9338 |     30.867 |     1.4
    9 |   0.9088 |     30.874 |   0.9484 |     32.115 |     1.5
   10 |   0.8804 |     29.726 |   0.9141 |     31.878 |     1.7
   11 |   0.8366 |     28.430 |   0.9057 |     31.046 |     1.9
   12 |   0.8126 |     27.570 |   0.8833 |     29.709 |     2.1
   13 |   0.7910 |     26.991 |   0.8800 |     29.471 |     2.2
   14 |   0.7547 |     25.756 |   0.8540 |     28.728 |     2.4
   15 |   0.7268 |     24.680 |   0.8355 |     27.421 |     2.6
   16 |   0.6940 |     23.500 |   0.8437 |     28.045 |     2.8
   17 |   0.6726 |     22.617 |   0.8203 |     27.065 |     2.9
   18 |   0.6513 |     21.823 |   0.8615 |     27.035 |     3.1
   19 |   0.6310 |     21.299 |   0.8435 |     26.233 |     3.3
   20 |   0.6139 |     20.880 |   0.8236 |     26.471 |     3.4
   21 |   0.5891 |     20.136 |   0.8172 |     26.708 |     3.6
   22 |   0.5584 |     18.878 |   0.8227 |     26.025 |     3.8
   23 |   0.5380 |     18.238 |   0.8079 |     25.401 |     4.0
   24 |   0.5254 |     18.360 |   0.8479 |     25.431 |     4.1
   25 |   0.5043 |     17.169 |   0.8338 |     25.906 |     4.3
   26 |   0.4874 |     16.529 |   0.8572 |     24.837 |     4.5
   27 |   0.4655 |     15.988 |   0.8746 |     24.213 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 485,730

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6526 |     47.447 |   1.2791 |     42.395 |     0.1
    2 |   1.2139 |     40.100 |   1.1365 |     38.027 |     0.2
    3 |   1.0784 |     35.975 |   1.0462 |     34.641 |     0.3
    4 |   0.9910 |     33.129 |   0.9868 |     33.422 |     0.4
    5 |   0.9083 |     30.488 |   0.9548 |     31.818 |     0.4
    6 |   0.8543 |     28.563 |   0.9027 |     30.184 |     0.5
    7 |   0.7933 |     26.324 |   0.8757 |     29.293 |     0.6
    8 |   0.7355 |     24.377 |   0.8544 |     28.461 |     0.7
    9 |   0.7014 |     23.219 |   0.8486 |     28.639 |     0.8
   10 |   0.6502 |     21.862 |   0.8598 |     28.194 |     0.9
   11 |   0.6177 |     20.489 |   0.8196 |     25.966 |     1.0
   12 |   0.5728 |     19.259 |   0.8291 |     26.203 |     1.1
   13 |   0.5403 |     18.172 |   0.8160 |     25.728 |     1.2
   14 |   0.5182 |     17.676 |   0.7927 |     25.490 |     1.3
   15 |   0.4903 |     16.600 |   0.8096 |     24.807 |     1.3
   16 |   0.4544 |     15.343 |   0.8199 |     24.718 |     1.4
   17 |   0.4432 |     15.012 |   0.8434 |     25.223 |     1.5
   18 |   0.4127 |     14.113 |   0.8123 |     23.767 |     1.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,202

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2255 |     56.695 |   1.5516 |     45.276 |     0.2
    2 |   1.5088 |     44.165 |   1.3541 |     41.979 |     0.4
    3 |   1.3585 |     41.595 |   1.2702 |     40.463 |     0.6
    4 |   1.2681 |     39.400 |   1.1967 |     37.433 |     0.7
    5 |   1.1875 |     36.957 |   1.1260 |     35.829 |     0.9
    6 |   1.1185 |     35.137 |   1.0945 |     35.532 |     1.1
    7 |   1.0582 |     33.394 |   1.0471 |     33.571 |     1.3
    8 |   1.0067 |     31.331 |   1.0228 |     32.680 |     1.5
    9 |   0.9587 |     30.300 |   0.9989 |     32.115 |     1.7
   10 |   0.9135 |     28.855 |   1.0034 |     31.818 |     1.9
   11 |   0.8732 |     27.283 |   0.9549 |     30.927 |     2.1
   12 |   0.8287 |     25.783 |   0.9386 |     29.531 |     2.3
   13 |   0.7984 |     25.154 |   0.9375 |     29.947 |     2.4
   14 |   0.7612 |     23.439 |   0.9148 |     28.847 |     2.6
   15 |   0.7289 |     23.092 |   0.9131 |     28.520 |     2.8
   16 |   0.6913 |     21.674 |   0.9083 |     28.105 |     3.0
   17 |   0.6642 |     20.715 |   0.9167 |     27.807 |     3.2
   18 |   0.6455 |     20.152 |   0.9150 |     28.015 |     3.4
   19 |   0.6119 |     18.856 |   0.9047 |     27.659 |     3.6
   20 |   0.5976 |     18.784 |   0.8990 |     26.471 |     3.8
   21 |   0.5622 |     17.648 |   0.9152 |     27.421 |     3.9
   22 |   0.5439 |     16.810 |   0.8956 |     26.144 |     4.1
   23 |   0.5279 |     16.369 |   0.9082 |     27.005 |     4.3
   24 |   0.4968 |     15.315 |   0.9200 |     27.035 |     4.5
   25 |   0.4843 |     14.946 |   0.9183 |     26.619 |     4.7
   26 |   0.4611 |     14.494 |   0.9528 |     26.381 |     4.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 436,898

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7391 |     49.388 |   1.3252 |     43.494 |     0.1
    2 |   1.2846 |     42.488 |   1.2049 |     39.721 |     0.2
    3 |   1.1839 |     39.157 |   1.1301 |     37.611 |     0.3
    4 |   1.1181 |     36.896 |   1.0612 |     35.680 |     0.4
    5 |   1.0555 |     35.093 |   1.0558 |     34.462 |     0.5
    6 |   1.0044 |     33.317 |   1.0111 |     35.027 |     0.6
    7 |   0.9583 |     31.872 |   0.9641 |     32.531 |     0.7
    8 |   0.9166 |     30.482 |   0.9343 |     31.313 |     0.8
    9 |   0.8739 |     29.440 |   0.9198 |     30.273 |     0.9
   10 |   0.8324 |     27.509 |   0.9056 |     31.046 |     1.0
   11 |   0.7994 |     26.445 |   0.8894 |     29.263 |     1.1
   12 |   0.7669 |     25.678 |   0.8794 |     28.788 |     1.2
   13 |   0.7507 |     25.028 |   0.8576 |     28.015 |     1.3
   14 |   0.6988 |     23.235 |   0.8743 |     28.610 |     1.4
   15 |   0.6731 |     22.452 |   0.8686 |     27.302 |     1.5
   16 |   0.6493 |     21.470 |   0.8569 |     26.619 |     1.6
   17 |   0.6294 |     21.117 |   0.8511 |     27.065 |     1.7
   18 |   0.6068 |     20.489 |   0.8418 |     26.500 |     1.8
   19 |   0.5819 |     19.634 |   0.8473 |     25.936 |     1.9
   20 |   0.5576 |     18.795 |   0.8809 |     27.035 |     2.0
   21 |   0.5331 |     18.073 |   0.8788 |     26.738 |     2.1
   22 |   0.5113 |     17.086 |   0.9081 |     26.203 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 470,370

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6011 |     63.677 |   1.8755 |     46.316 |     0.1
    2 |   1.6664 |     43.994 |   1.5498 |     43.256 |     0.2
    3 |   1.4644 |     41.485 |   1.4159 |     41.087 |     0.3
    4 |   1.3500 |     39.554 |   1.3274 |     38.681 |     0.4
    5 |   1.2613 |     37.415 |   1.2642 |     37.077 |     0.6
    6 |   1.1919 |     35.777 |   1.2115 |     35.086 |     0.7
    7 |   1.1264 |     33.929 |   1.1768 |     35.859 |     0.8
    8 |   1.0717 |     32.004 |   1.1361 |     34.225 |     0.9
    9 |   1.0210 |     30.885 |   1.1027 |     33.541 |     1.0
   10 |   0.9711 |     29.318 |   1.0845 |     32.917 |     1.1
   11 |   0.9291 |     27.614 |   1.0501 |     31.818 |     1.2
   12 |   0.8856 |     26.737 |   1.0205 |     31.402 |     1.3
   13 |   0.8474 |     25.436 |   1.0157 |     31.699 |     1.5
   14 |   0.8117 |     24.360 |   0.9920 |     30.957 |     1.6
   15 |   0.7759 |     23.368 |   0.9809 |     30.778 |     1.7
   16 |   0.7432 |     22.127 |   0.9584 |     29.798 |     1.8
   17 |   0.7147 |     21.266 |   0.9679 |     28.818 |     1.9
   18 |   0.6839 |     20.411 |   0.9514 |     28.877 |     2.0
   19 |   0.6561 |     19.496 |   0.9488 |     28.669 |     2.1
   20 |   0.6324 |     18.994 |   0.9406 |     28.313 |     2.3
   21 |   0.6038 |     18.062 |   0.9260 |     28.223 |     2.4
   22 |   0.5810 |     17.367 |   0.9390 |     28.105 |     2.5
   23 |   0.5545 |     16.352 |   0.9321 |     27.421 |     2.6
   24 |   0.5374 |     15.713 |   0.9189 |     26.768 |     2.7
   25 |   0.5235 |     15.371 |   0.9108 |     26.471 |     2.8
   26 |   0.4960 |     14.439 |   0.9182 |     26.946 |     2.9
   27 |   0.4782 |     14.141 |   0.9354 |     26.708 |     3.0
   28 |   0.4574 |     13.242 |   0.9475 |     26.797 |     3.2
   29 |   0.4450 |     12.779 |   0.9520 |     26.857 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 602,466

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7542 |     49.509 |   1.3167 |     44.147 |     0.2
    2 |   1.2831 |     41.805 |   1.1977 |     39.602 |     0.3
    3 |   1.1854 |     39.450 |   1.1352 |     37.552 |     0.5
    4 |   1.1128 |     37.420 |   1.0664 |     35.740 |     0.7
    5 |   1.0566 |     35.479 |   1.0282 |     34.641 |     0.9
    6 |   1.0077 |     33.918 |   1.0060 |     33.838 |     1.0
    7 |   0.9709 |     32.633 |   0.9634 |     32.650 |     1.2
    8 |   0.9307 |     31.276 |   0.9377 |     31.848 |     1.4
    9 |   0.8810 |     29.605 |   0.8862 |     30.273 |     1.5
   10 |   0.8522 |     28.861 |   0.8873 |     30.511 |     1.7
   11 |   0.8177 |     27.553 |   0.8800 |     28.936 |     1.9
   12 |   0.7755 |     25.982 |   0.8624 |     29.382 |     2.1
   13 |   0.7496 |     25.132 |   0.8473 |     28.223 |     2.2
   14 |   0.7207 |     24.437 |   0.8573 |     28.253 |     2.4
   15 |   0.7008 |     23.737 |   0.8375 |     28.015 |     2.6
   16 |   0.6745 |     22.733 |   0.8059 |     25.995 |     2.7
   17 |   0.6394 |     21.421 |   0.8307 |     26.055 |     2.9
   18 |   0.6275 |     20.974 |   0.8275 |     25.936 |     3.1
   19 |   0.5960 |     20.356 |   0.8410 |     25.966 |     3.3
   20 |   0.5742 |     19.341 |   0.8274 |     26.144 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,075,618

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5561 |     47.248 |   1.2661 |     42.632 |     0.1
    2 |   1.2436 |     41.214 |   1.1782 |     39.988 |     0.2
    3 |   1.1492 |     38.815 |   1.0881 |     36.275 |     0.4
    4 |   1.0947 |     37.034 |   1.0669 |     34.730 |     0.5
    5 |   1.0328 |     35.164 |   0.9895 |     34.076 |     0.6
    6 |   0.9799 |     32.550 |   1.0152 |     34.551 |     0.7
    7 |   0.9412 |     31.524 |   0.9557 |     32.115 |     0.9
    8 |   0.8981 |     29.997 |   0.9812 |     32.561 |     1.0
    9 |   0.8675 |     28.850 |   0.9235 |     31.551 |     1.1
   10 |   0.8243 |     27.967 |   0.9101 |     30.422 |     1.2
   11 |   0.7940 |     26.919 |   0.9261 |     31.135 |     1.3
   12 |   0.7800 |     25.987 |   0.9334 |     30.511 |     1.5
   13 |   0.7292 |     24.426 |   0.8883 |     28.996 |     1.6
   14 |   0.6959 |     23.312 |   0.8960 |     29.323 |     1.7
   15 |   0.6861 |     23.042 |   0.8768 |     29.055 |     1.8
   16 |   0.6604 |     22.435 |   0.9113 |     29.026 |     2.0
   17 |   0.6272 |     21.189 |   0.9261 |     30.036 |     2.1
   18 |   0.6083 |     20.638 |   0.9349 |     30.422 |     2.2
   19 |   0.5812 |     19.672 |   0.9251 |     29.144 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,202

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2735 |     57.953 |   1.5274 |     45.484 |     0.1
    2 |   1.4912 |     43.597 |   1.3387 |     42.395 |     0.3
    3 |   1.3433 |     41.545 |   1.2415 |     38.532 |     0.4
    4 |   1.2541 |     39.367 |   1.1755 |     36.839 |     0.6
    5 |   1.1827 |     36.924 |   1.1238 |     35.086 |     0.7
    6 |   1.1152 |     34.662 |   1.0851 |     33.541 |     0.9
    7 |   1.0594 |     33.168 |   1.0417 |     33.304 |     1.0
    8 |   1.0069 |     31.844 |   1.0316 |     33.452 |     1.2
    9 |   0.9653 |     29.914 |   0.9994 |     32.175 |     1.4
   10 |   0.9177 |     28.629 |   0.9776 |     31.313 |     1.5
   11 |   0.8794 |     27.134 |   0.9586 |     30.511 |     1.7
   12 |   0.8403 |     25.927 |   0.9573 |     29.768 |     1.8
   13 |   0.8125 |     25.353 |   0.9308 |     29.204 |     2.0
   14 |   0.7774 |     24.349 |   0.9164 |     28.520 |     2.1
   15 |   0.7457 |     23.141 |   0.9234 |     29.055 |     2.3
   16 |   0.7150 |     22.237 |   0.9283 |     28.818 |     2.4
   17 |   0.6895 |     20.946 |   0.9232 |     28.728 |     2.6
   18 |   0.6687 |     20.671 |   0.9182 |     27.540 |     2.7
   19 |   0.6386 |     19.998 |   0.9009 |     27.005 |     2.9
   20 |   0.6148 |     18.939 |   0.9144 |     27.392 |     3.0
   21 |   0.5924 |     18.167 |   0.9108 |     27.867 |     3.2
   22 |   0.5653 |     17.262 |   0.9266 |     27.540 |     3.3
   23 |   0.5494 |     16.942 |   0.9218 |     27.213 |     3.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 470,370

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7853 |     50.529 |   1.3411 |     43.494 |     0.1
    2 |   1.3087 |     42.952 |   1.2202 |     40.790 |     0.2
    3 |   1.2066 |     40.293 |   1.1392 |     38.681 |     0.4
    4 |   1.1422 |     38.010 |   1.0999 |     36.482 |     0.5
    5 |   1.0853 |     36.571 |   1.0696 |     35.443 |     0.6
    6 |   1.0443 |     35.385 |   1.0211 |     34.284 |     0.7
    7 |   0.9925 |     33.471 |   0.9779 |     33.185 |     0.8
    8 |   0.9647 |     32.164 |   0.9595 |     32.561 |     1.0
    9 |   0.9224 |     30.736 |   0.9509 |     32.264 |     1.1
   10 |   0.8860 |     29.522 |   0.9244 |     30.600 |     1.2
   11 |   0.8472 |     28.497 |   0.9289 |     31.462 |     1.3
   12 |   0.8110 |     27.019 |   0.9097 |     30.778 |     1.5
   13 |   0.7942 |     26.644 |   0.8881 |     29.144 |     1.6
   14 |   0.7685 |     25.662 |   0.8592 |     28.699 |     1.7
   15 |   0.7280 |     24.399 |   0.8525 |     28.283 |     1.8
   16 |   0.6993 |     23.197 |   0.8527 |     27.124 |     1.9
   17 |   0.6851 |     23.268 |   0.8598 |     27.362 |     2.1
   18 |   0.6464 |     21.652 |   0.8303 |     26.857 |     2.2
   19 |   0.6308 |     21.222 |   0.8408 |     26.827 |     2.3
   20 |   0.6133 |     20.472 |   0.8555 |     26.352 |     2.4
   21 |   0.5842 |     19.584 |   0.8713 |     26.619 |     2.6
   22 |   0.5677 |     18.795 |   0.8339 |     26.055 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,272,994

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5195 |     46.663 |   1.2510 |     41.771 |     0.1
    2 |   1.2278 |     41.589 |   1.1758 |     39.958 |     0.3
    3 |   1.1421 |     38.915 |   1.1426 |     38.116 |     0.4
    4 |   1.0816 |     36.604 |   1.0770 |     36.096 |     0.5
    5 |   1.0267 |     34.806 |   1.0187 |     34.611 |     0.6
    6 |   0.9823 |     33.466 |   0.9630 |     32.799 |     0.8
    7 |   0.9299 |     31.596 |   0.9722 |     33.541 |     0.9
    8 |   0.8935 |     30.135 |   0.9182 |     31.254 |     1.0
    9 |   0.8583 |     29.191 |   0.8802 |     30.006 |     1.1
   10 |   0.8140 |     27.565 |   0.8823 |     29.679 |     1.3
   11 |   0.7864 |     26.577 |   0.8570 |     28.758 |     1.4
   12 |   0.7512 |     25.480 |   0.8727 |     28.936 |     1.5
   13 |   0.7242 |     24.266 |   0.8392 |     27.184 |     1.7
   14 |   0.6909 |     23.268 |   0.8397 |     26.827 |     1.8
   15 |   0.6671 |     22.673 |   0.8374 |     27.600 |     1.9
   16 |   0.6335 |     21.305 |   0.8263 |     26.352 |     2.0
   17 |   0.6065 |     20.627 |   0.8159 |     25.698 |     2.2
   18 |   0.5797 |     19.843 |   0.8418 |     26.352 |     2.3
   19 |   0.5603 |     18.944 |   0.8515 |     25.579 |     2.4
   20 |   0.5303 |     18.023 |   0.8168 |     25.104 |     2.6
   21 |   0.5139 |     17.444 |   0.8374 |     25.015 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 420,130

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7381 |     49.415 |   1.3296 |     44.831 |     0.1
    2 |   1.3020 |     43.117 |   1.2274 |     40.493 |     0.2
    3 |   1.2043 |     40.122 |   1.1591 |     38.740 |     0.3
    4 |   1.1340 |     38.181 |   1.0953 |     37.611 |     0.5
    5 |   1.0777 |     35.986 |   1.0530 |     36.245 |     0.6
    6 |   1.0214 |     33.879 |   1.0303 |     35.294 |     0.7
    7 |   0.9837 |     32.666 |   1.0084 |     34.700 |     0.8
    8 |   0.9423 |     31.811 |   0.9330 |     32.115 |     0.9
    9 |   0.9098 |     30.355 |   0.9261 |     31.075 |     1.0
   10 |   0.8667 |     28.701 |   0.9035 |     31.224 |     1.1
   11 |   0.8359 |     28.006 |   0.9115 |     30.570 |     1.2
   12 |   0.8077 |     27.145 |   0.8881 |     29.174 |     1.4
   13 |   0.7820 |     26.120 |   0.8572 |     28.431 |     1.5
   14 |   0.7539 |     25.287 |   0.8429 |     28.431 |     1.6
   15 |   0.7308 |     24.322 |   0.8493 |     28.105 |     1.7
   16 |   0.6977 |     23.301 |   0.8410 |     28.223 |     1.8
   17 |   0.6786 |     22.744 |   0.8171 |     25.817 |     1.9
   18 |   0.6425 |     21.801 |   0.8331 |     27.065 |     2.0
   19 |   0.6230 |     20.908 |   0.8252 |     26.560 |     2.2
   20 |   0.6072 |     20.384 |   0.8288 |     27.213 |     2.3
   21 |   0.5880 |     19.959 |   0.8203 |     26.203 |     2.4
   22 |   0.5705 |     19.623 |   0.8094 |     25.520 |     2.5
   23 |   0.5411 |     18.255 |   0.8183 |     25.163 |     2.6
   24 |   0.5223 |     17.687 |   0.8583 |     26.471 |     2.7
   25 |   0.5175 |     17.466 |   0.8359 |     25.223 |     2.8
   26 |   0.4902 |     16.512 |   0.8281 |     25.045 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 485,730

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5755 |     45.897 |   1.2362 |     40.582 |     0.1
    2 |   1.1758 |     38.931 |   1.0971 |     36.334 |     0.2
    3 |   1.0484 |     34.960 |   1.0662 |     35.948 |     0.3
    4 |   0.9596 |     31.789 |   0.9718 |     32.204 |     0.4
    5 |   0.8857 |     29.396 |   0.9450 |     31.640 |     0.5
    6 |   0.8248 |     27.598 |   0.9219 |     31.105 |     0.5
    7 |   0.7723 |     26.131 |   0.8647 |     28.580 |     0.6
    8 |   0.7192 |     23.991 |   0.8732 |     28.372 |     0.7
    9 |   0.6751 |     22.485 |   0.8564 |     28.610 |     0.8
   10 |   0.6438 |     21.503 |   0.7999 |     25.847 |     0.9
   11 |   0.5885 |     19.805 |   0.8001 |     25.074 |     1.0
   12 |   0.5539 |     18.454 |   0.8031 |     25.906 |     1.1
   13 |   0.5280 |     18.034 |   0.8160 |     25.193 |     1.2
   14 |   0.4981 |     16.689 |   0.8278 |     24.985 |     1.3
   15 |   0.4719 |     15.861 |   0.7984 |     24.926 |     1.4
   16 |   0.4514 |     15.194 |   0.7888 |     24.540 |     1.5
   17 |   0.4140 |     13.986 |   0.8291 |     24.153 |     1.5
   18 |   0.3940 |     13.402 |   0.8151 |     23.321 |     1.6
   19 |   0.3634 |     12.459 |   0.8506 |     24.302 |     1.7
   20 |   0.3572 |     12.084 |   0.8256 |     23.351 |     1.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,618

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4879 |     45.935 |   1.2352 |     39.721 |     0.1
    2 |   1.1577 |     39.025 |   1.1053 |     36.928 |     0.2
    3 |   1.0522 |     35.606 |   1.0376 |     34.195 |     0.3
    4 |   0.9683 |     32.473 |   0.9897 |     32.858 |     0.5
    5 |   0.9121 |     30.399 |   0.9661 |     33.066 |     0.6
    6 |   0.8595 |     28.916 |   0.9262 |     31.699 |     0.7
    7 |   0.8039 |     27.267 |   0.8920 |     30.006 |     0.8
    8 |   0.7664 |     25.899 |   0.8840 |     29.560 |     0.9
    9 |   0.7204 |     24.785 |   0.8478 |     28.461 |     1.0
   10 |   0.6895 |     23.274 |   0.8553 |     28.520 |     1.2
   11 |   0.6509 |     21.939 |   0.8364 |     27.332 |     1.3
   12 |   0.6119 |     20.842 |   0.8434 |     26.203 |     1.4
   13 |   0.5966 |     20.240 |   0.8032 |     26.144 |     1.5
   14 |   0.5569 |     19.132 |   0.8108 |     25.728 |     1.6
   15 |   0.5272 |     17.946 |   0.7894 |     25.460 |     1.7
   16 |   0.4993 |     16.832 |   0.8293 |     25.460 |     1.9
   17 |   0.4972 |     16.931 |   0.7982 |     24.896 |     2.0
   18 |   0.4738 |     16.104 |   0.8026 |     24.985 |     2.1
   19 |   0.4370 |     14.979 |   0.8132 |     25.104 |     2.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 436,898

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6661 |     47.551 |   1.2982 |     43.048 |     0.1
    2 |   1.2056 |     39.792 |   1.1386 |     37.671 |     0.2
    3 |   1.0752 |     35.517 |   1.0574 |     34.641 |     0.3
    4 |   0.9772 |     32.010 |   0.9869 |     32.917 |     0.4
    5 |   0.9086 |     30.427 |   0.9382 |     31.016 |     0.5
    6 |   0.8504 |     27.945 |   0.9388 |     30.838 |     0.6
    7 |   0.7973 |     26.588 |   0.8947 |     29.412 |     0.7
    8 |   0.7472 |     24.763 |   0.8894 |     29.501 |     0.8
    9 |   0.7042 |     23.125 |   0.8445 |     27.600 |     0.9
   10 |   0.6541 |     21.608 |   0.8228 |     26.946 |     1.0
   11 |   0.6186 |     20.400 |   0.8342 |     26.233 |     1.1
   12 |   0.5964 |     19.921 |   0.8195 |     25.579 |     1.1
   13 |   0.5600 |     18.735 |   0.8052 |     25.787 |     1.2
   14 |   0.5269 |     17.615 |   0.7790 |     24.510 |     1.3
   15 |   0.4948 |     16.600 |   0.8132 |     25.193 |     1.4
   16 |   0.4739 |     15.834 |   0.7936 |     24.332 |     1.5
   17 |   0.4545 |     15.260 |   0.8173 |     25.074 |     1.6
   18 |   0.4306 |     14.312 |   0.8159 |     24.153 |     1.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 420,130

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6383 |     63.076 |   1.9414 |     46.376 |     0.1
    2 |   1.8374 |     46.437 |   1.5886 |     45.009 |     0.2
    3 |   1.6032 |     44.546 |   1.4595 |     43.316 |     0.3
    4 |   1.4853 |     43.205 |   1.3764 |     41.949 |     0.4
    5 |   1.4021 |     41.628 |   1.3247 |     40.582 |     0.6
    6 |   1.3348 |     40.326 |   1.2705 |     39.364 |     0.7
    7 |   1.2839 |     38.948 |   1.2297 |     38.414 |     0.8
    8 |   1.2291 |     37.729 |   1.2030 |     37.433 |     0.9
    9 |   1.1887 |     36.758 |   1.1782 |     37.255 |     1.0
   10 |   1.1512 |     35.462 |   1.1557 |     36.423 |     1.1
   11 |   1.1118 |     34.370 |   1.1342 |     35.799 |     1.2
   12 |   1.0807 |     33.284 |   1.1076 |     34.551 |     1.4
   13 |   1.0487 |     32.490 |   1.0923 |     33.957 |     1.5
   14 |   1.0174 |     31.574 |   1.0751 |     33.333 |     1.6
   15 |   0.9958 |     30.962 |   1.0635 |     33.779 |     1.7
   16 |   0.9670 |     29.997 |   1.0443 |     32.145 |     1.8
   17 |   0.9395 |     29.555 |   1.0389 |     32.204 |     1.9
   18 |   0.9178 |     28.270 |   1.0478 |     32.294 |     2.0
   19 |   0.8993 |     27.967 |   1.0335 |     32.175 |     2.1
   20 |   0.8699 |     27.162 |   1.0281 |     31.907 |     2.3
   21 |   0.8525 |     26.699 |   1.0234 |     31.402 |     2.4
   22 |   0.8336 |     26.114 |   1.0126 |     30.630 |     2.5
   23 |   0.8172 |     25.695 |   1.0057 |     30.541 |     2.6
   24 |   0.8020 |     25.154 |   1.0081 |     30.392 |     2.7
   25 |   0.7789 |     24.278 |   1.0333 |     30.897 |     2.8
   26 |   0.7651 |     24.101 |   0.9986 |     30.065 |     2.9
   27 |   0.7438 |     23.103 |   1.0240 |     30.689 |     3.0
   28 |   0.7348 |     22.910 |   1.0021 |     30.065 |     3.2
   29 |   0.7139 |     22.413 |   1.0144 |     29.709 |     3.3
   30 |   0.6997 |     21.647 |   1.0213 |     29.976 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 602,466

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4735 |     61.278 |   1.7571 |     46.613 |     0.1
    2 |   1.7015 |     45.511 |   1.5015 |     44.088 |     0.2
    3 |   1.5206 |     43.790 |   1.4004 |     42.781 |     0.4
    4 |   1.4202 |     41.948 |   1.3278 |     41.147 |     0.5
    5 |   1.3464 |     40.018 |   1.2683 |     38.354 |     0.6
    6 |   1.2799 |     38.424 |   1.2149 |     37.314 |     0.8
    7 |   1.2246 |     36.929 |   1.1734 |     36.393 |     0.9
    8 |   1.1797 |     36.014 |   1.1400 |     35.205 |     1.0
    9 |   1.1366 |     34.856 |   1.1111 |     34.462 |     1.1
   10 |   1.0958 |     33.615 |   1.0897 |     34.165 |     1.3
   11 |   1.0551 |     32.335 |   1.0736 |     33.987 |     1.4
   12 |   1.0190 |     31.298 |   1.0422 |     32.620 |     1.5
   13 |   0.9848 |     30.306 |   1.0349 |     32.591 |     1.6
   14 |   0.9613 |     29.688 |   1.0209 |     32.828 |     1.8
   15 |   0.9260 |     28.447 |   1.0113 |     31.402 |     1.9
   16 |   0.8922 |     27.592 |   1.0004 |     31.521 |     2.0
   17 |   0.8624 |     26.710 |   0.9972 |     31.105 |     2.1
   18 |   0.8384 |     26.042 |   0.9757 |     30.422 |     2.3
   19 |   0.8113 |     25.072 |   0.9704 |     29.887 |     2.4
   20 |   0.7940 |     24.515 |   0.9704 |     30.897 |     2.5
   21 |   0.7653 |     23.776 |   0.9562 |     29.828 |     2.7
   22 |   0.7494 |     23.037 |   0.9559 |     29.293 |     2.8
   23 |   0.7270 |     22.452 |   0.9514 |     29.857 |     2.9
   24 |   0.7081 |     22.160 |   0.9544 |     29.144 |     3.0
   25 |   0.6842 |     21.002 |   0.9534 |     29.441 |     3.2
   26 |   0.6641 |     20.627 |   0.9675 |     29.144 |     3.3
   27 |   0.6509 |     20.081 |   0.9808 |     29.620 |     3.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,474

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1158 |     54.561 |   1.4579 |     44.593 |     0.2
    2 |   1.4404 |     43.354 |   1.2985 |     40.166 |     0.4
    3 |   1.3101 |     40.100 |   1.2098 |     37.344 |     0.6
    4 |   1.2158 |     37.955 |   1.1584 |     37.077 |     0.8
    5 |   1.1486 |     35.914 |   1.1093 |     35.146 |     1.0
    6 |   1.0822 |     33.609 |   1.0640 |     33.571 |     1.2
    7 |   1.0203 |     31.668 |   1.0371 |     32.472 |     1.4
    8 |   0.9598 |     29.743 |   1.0022 |     31.907 |     1.6
    9 |   0.9065 |     27.951 |   0.9866 |     30.986 |     1.7
   10 |   0.8569 |     26.500 |   0.9580 |     29.531 |     1.9
   11 |   0.8110 |     24.978 |   0.9473 |     29.947 |     2.1
   12 |   0.7763 |     24.007 |   0.9413 |     29.234 |     2.3
   13 |   0.7414 |     23.119 |   0.9481 |     29.115 |     2.5
   14 |   0.6970 |     21.404 |   0.9279 |     28.253 |     2.7
   15 |   0.6649 |     20.886 |   0.9233 |     28.728 |     2.9
   16 |   0.6341 |     20.235 |   0.9196 |     28.342 |     3.1
   17 |   0.6045 |     18.542 |   0.9172 |     27.451 |     3.3
   18 |   0.5813 |     17.886 |   0.9195 |     27.600 |     3.5
   19 |   0.5488 |     16.964 |   0.9205 |     27.600 |     3.7
   20 |   0.5232 |     16.016 |   0.9294 |     26.976 |     3.9
   21 |   0.5004 |     15.371 |   0.9507 |     26.797 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,341,090

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0456 |     53.370 |   1.4458 |     43.167 |     0.2
    2 |   1.3294 |     40.437 |   1.2653 |     39.216 |     0.4
    3 |   1.1902 |     36.830 |   1.1717 |     35.710 |     0.5
    4 |   1.0884 |     34.177 |   1.1221 |     35.175 |     0.7
    5 |   1.0104 |     31.370 |   1.0674 |     34.195 |     0.9
    6 |   0.9308 |     29.043 |   1.0043 |     31.699 |     1.1
    7 |   0.8698 |     27.134 |   0.9767 |     30.689 |     1.3
    8 |   0.8138 |     24.994 |   0.9538 |     31.194 |     1.5
    9 |   0.7624 |     23.368 |   0.9211 |     28.669 |     1.7
   10 |   0.6984 |     21.327 |   0.8845 |     27.273 |     1.8
   11 |   0.6659 |     20.439 |   0.8856 |     27.332 |     2.0
   12 |   0.6086 |     18.492 |   0.8905 |     27.600 |     2.2
   13 |   0.5677 |     17.053 |   0.8571 |     26.352 |     2.4
   14 |   0.5333 |     16.165 |   0.8783 |     26.589 |     2.6
   15 |   0.5044 |     15.349 |   0.8600 |     26.441 |     2.8
   16 |   0.4630 |     13.771 |   0.8387 |     25.015 |     2.9
   17 |   0.4335 |     13.016 |   0.8476 |     25.193 |     3.1
   18 |   0.4076 |     12.304 |   0.8461 |     24.985 |     3.3
   19 |   0.3807 |     11.295 |   0.8566 |     25.193 |     3.5
   20 |   0.3555 |     10.666 |   0.8806 |     25.550 |     3.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,474

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9709 |     52.123 |   1.4329 |     44.236 |     0.1
    2 |   1.3293 |     41.049 |   1.2647 |     38.800 |     0.3
    3 |   1.1938 |     36.841 |   1.1648 |     35.651 |     0.4
    4 |   1.0999 |     34.276 |   1.1088 |     35.056 |     0.6
    5 |   1.0171 |     31.861 |   1.0499 |     33.898 |     0.7
    6 |   0.9372 |     29.203 |   1.0127 |     31.818 |     0.9
    7 |   0.8592 |     27.019 |   0.9759 |     30.481 |     1.0
    8 |   0.7899 |     24.266 |   0.9386 |     29.739 |     1.2
    9 |   0.7264 |     22.380 |   0.9157 |     29.204 |     1.3
   10 |   0.6782 |     20.853 |   0.8915 |     27.689 |     1.5
   11 |   0.6214 |     18.878 |   0.8848 |     27.807 |     1.6
   12 |   0.5746 |     17.643 |   0.8716 |     26.738 |     1.8
   13 |   0.5255 |     15.817 |   0.8812 |     27.273 |     1.9
   14 |   0.4926 |     14.687 |   0.8809 |     26.708 |     2.1
   15 |   0.4591 |     13.782 |   0.8414 |     25.401 |     2.2
   16 |   0.4167 |     12.514 |   0.8616 |     25.966 |     2.4
   17 |   0.3854 |     11.284 |   0.8868 |     25.668 |     2.5
   18 |   0.3650 |     11.129 |   0.8822 |     25.728 |     2.6
   19 |   0.3328 |     10.159 |   0.8818 |     26.263 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 535,714

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6773 |     48.169 |   1.3228 |     43.969 |     0.2
    2 |   1.2887 |     42.395 |   1.2406 |     41.741 |     0.3
    3 |   1.1932 |     40.051 |   1.1305 |     38.027 |     0.5
    4 |   1.1208 |     37.988 |   1.1006 |     37.017 |     0.7
    5 |   1.0569 |     35.710 |   1.0311 |     34.433 |     0.8
    6 |   1.0011 |     33.830 |   0.9763 |     33.630 |     1.0
    7 |   0.9619 |     32.208 |   0.9423 |     32.264 |     1.1
    8 |   0.9173 |     31.089 |   0.9384 |     31.670 |     1.3
    9 |   0.8804 |     29.467 |   0.9069 |     31.402 |     1.5
   10 |   0.8436 |     28.155 |   0.9037 |     30.689 |     1.6
   11 |   0.8165 |     27.498 |   0.8892 |     30.214 |     1.8
   12 |   0.7799 |     26.489 |   0.8696 |     28.966 |     2.0
   13 |   0.7562 |     25.684 |   0.8423 |     29.412 |     2.1
   14 |   0.7236 |     24.278 |   0.8292 |     27.897 |     2.3
   15 |   0.6898 |     23.186 |   0.8573 |     27.689 |     2.5
   16 |   0.6700 |     22.160 |   0.8193 |     27.510 |     2.6
   17 |   0.6387 |     21.768 |   0.8351 |     26.649 |     2.8
   18 |   0.6135 |     20.649 |   0.8251 |     26.708 |     3.0
   19 |   0.6044 |     20.516 |   0.8083 |     26.352 |     3.1
   20 |   0.5642 |     19.137 |   0.8409 |     26.857 |     3.3
   21 |   0.5534 |     18.812 |   0.8159 |     26.173 |     3.5
   22 |   0.5308 |     18.211 |   0.8058 |     25.550 |     3.6
   23 |   0.5105 |     17.599 |   0.8271 |     26.173 |     3.8
   24 |   0.4837 |     16.623 |   0.8174 |     25.371 |     3.9
   25 |   0.4698 |     16.016 |   0.8327 |     25.134 |     4.1
   26 |   0.4542 |     15.376 |   0.8210 |     25.045 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,471,778

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4772 |     45.968 |   1.2684 |     43.167 |     0.1
    2 |   1.1771 |     39.521 |   1.1405 |     38.295 |     0.3
    3 |   1.0773 |     36.372 |   1.0653 |     35.472 |     0.4
    4 |   0.9951 |     33.620 |   0.9922 |     33.096 |     0.5
    5 |   0.9371 |     31.287 |   0.9555 |     32.739 |     0.6
    6 |   0.8781 |     29.677 |   0.9360 |     31.610 |     0.8
    7 |   0.8315 |     28.188 |   0.9084 |     30.570 |     0.9
    8 |   0.7874 |     26.941 |   0.8830 |     29.382 |     1.0
    9 |   0.7350 |     24.785 |   0.8507 |     28.194 |     1.2
   10 |   0.6980 |     23.638 |   0.8639 |     29.115 |     1.3
   11 |   0.6728 |     22.888 |   0.8526 |     28.045 |     1.4
   12 |   0.6310 |     21.404 |   0.8261 |     27.392 |     1.5
   13 |   0.6029 |     20.031 |   0.8054 |     26.589 |     1.7
   14 |   0.5549 |     18.812 |   0.8002 |     25.401 |     1.8
   15 |   0.5274 |     17.968 |   0.7796 |     25.401 |     1.9
   16 |   0.5054 |     17.169 |   0.7746 |     23.767 |     2.1
   17 |   0.4862 |     16.711 |   0.8263 |     25.876 |     2.2
   18 |   0.4576 |     15.542 |   0.7912 |     24.599 |     2.3
   19 |   0.4309 |     14.803 |   0.7489 |     23.500 |     2.4
   20 |   0.4248 |     14.560 |   0.8169 |     23.797 |     2.6
   21 |   0.3938 |     13.661 |   0.8094 |     24.272 |     2.7
   22 |   0.3797 |     12.916 |   0.8016 |     23.856 |     2.8
   23 |   0.3481 |     12.023 |   0.8526 |     24.540 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,258

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8832 |     50.827 |   1.3670 |     41.622 |     0.2
    2 |   1.2820 |     39.841 |   1.2233 |     38.116 |     0.4
    3 |   1.1590 |     36.400 |   1.1458 |     35.977 |     0.6
    4 |   1.0584 |     33.234 |   1.0758 |     34.373 |     0.8
    5 |   0.9714 |     30.493 |   1.0153 |     32.056 |     0.9
    6 |   0.8787 |     27.245 |   0.9715 |     30.689 |     1.1
    7 |   0.8125 |     25.370 |   0.9273 |     28.669 |     1.3
    8 |   0.7458 |     22.695 |   0.8869 |     27.897 |     1.5
    9 |   0.6856 |     20.704 |   0.9064 |     28.818 |     1.7
   10 |   0.6353 |     18.818 |   0.8746 |     27.451 |     1.9
   11 |   0.5864 |     17.935 |   0.8408 |     25.906 |     2.1
   12 |   0.5324 |     16.165 |   0.8615 |     27.213 |     2.3
   13 |   0.5029 |     15.304 |   0.8226 |     25.104 |     2.5
   14 |   0.4549 |     13.380 |   0.8270 |     24.629 |     2.7
   15 |   0.4298 |     12.988 |   0.8560 |     25.074 |     2.8
   16 |   0.3882 |     11.758 |   0.8351 |     24.421 |     3.0
   17 |   0.3538 |     10.319 |   0.8354 |     23.500 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 420,130

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7024 |     48.627 |   1.3172 |     43.316 |     0.1
    2 |   1.2858 |     42.146 |   1.2110 |     40.404 |     0.2
    3 |   1.1963 |     39.736 |   1.1325 |     37.552 |     0.3
    4 |   1.1284 |     37.734 |   1.0763 |     36.423 |     0.4
    5 |   1.0720 |     36.229 |   1.0220 |     33.838 |     0.6
    6 |   1.0158 |     34.332 |   0.9908 |     33.571 |     0.7
    7 |   0.9659 |     32.341 |   0.9920 |     33.155 |     0.8
    8 |   0.9261 |     31.039 |   0.9305 |     31.283 |     0.9
    9 |   0.8899 |     29.710 |   0.9195 |     31.194 |     1.0
   10 |   0.8559 |     28.645 |   0.8968 |     30.422 |     1.1
   11 |   0.8222 |     27.289 |   0.8877 |     29.887 |     1.2
   12 |   0.8018 |     26.996 |   0.8676 |     29.144 |     1.4
   13 |   0.7638 |     25.507 |   0.8670 |     28.936 |     1.5
   14 |   0.7389 |     25.193 |   0.8337 |     27.243 |     1.6
   15 |   0.7056 |     23.908 |   0.8625 |     27.837 |     1.7
   16 |   0.6828 |     22.965 |   0.8372 |     27.005 |     1.8
   17 |   0.6525 |     22.127 |   0.8544 |     27.986 |     1.9
   18 |   0.6497 |     21.834 |   0.8598 |     28.134 |     2.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,341,090

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5325 |     47.099 |   1.2537 |     41.830 |     0.1
    2 |   1.1960 |     40.387 |   1.1351 |     39.305 |     0.3
    3 |   1.1016 |     37.271 |   1.0684 |     36.453 |     0.4
    4 |   1.0397 |     35.633 |   1.0649 |     35.235 |     0.6
    5 |   0.9986 |     33.582 |   1.0182 |     34.254 |     0.7
    6 |   0.9676 |     33.063 |   1.0201 |     34.789 |     0.9
    7 |   0.9245 |     31.447 |   0.9724 |     32.739 |     1.0
    8 |   0.8608 |     29.269 |   0.9651 |     32.828 |     1.2
    9 |   0.8364 |     28.530 |   0.9124 |     31.135 |     1.3
   10 |   0.8015 |     27.427 |   0.8938 |     30.095 |     1.5
   11 |   0.7692 |     26.120 |   0.8582 |     28.936 |     1.6
   12 |   0.7423 |     25.441 |   0.8567 |     29.263 |     1.8
   13 |   0.7191 |     24.426 |   0.8674 |     29.263 |     1.9
   14 |   0.6949 |     23.665 |   0.8398 |     27.867 |     2.1
   15 |   0.6711 |     22.805 |   0.8222 |     27.332 |     2.2
   16 |   0.6614 |     22.662 |   0.8303 |     27.629 |     2.4
   17 |   0.6538 |     22.314 |   0.8379 |     27.540 |     2.5
   18 |   0.6408 |     22.016 |   0.8262 |     26.589 |     2.7
   19 |   0.5852 |     20.125 |   0.7977 |     25.995 |     2.8
   20 |   0.5684 |     19.551 |   0.8257 |     27.184 |     3.0
   21 |   0.5594 |     19.198 |   0.7913 |     25.876 |     3.1
   22 |   0.5443 |     18.718 |   0.8479 |     26.530 |     3.3
   23 |   0.5182 |     17.919 |   0.8098 |     25.401 |     3.4
   24 |   0.5087 |     17.246 |   0.8115 |     24.629 |     3.6
   25 |   0.4831 |     16.496 |   0.8152 |     24.896 |     3.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,258

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4792 |     45.665 |   1.2316 |     42.276 |     0.2
    2 |   1.1703 |     39.030 |   1.1628 |     38.503 |     0.4
    3 |   1.0803 |     36.593 |   1.0625 |     36.156 |     0.6
    4 |   1.0049 |     34.100 |   1.0342 |     35.146 |     0.8
    5 |   0.9472 |     32.258 |   0.9859 |     33.214 |     0.9
    6 |   0.9019 |     30.460 |   0.9538 |     33.155 |     1.1
    7 |   0.8611 |     29.274 |   0.9135 |     31.046 |     1.3
    8 |   0.8188 |     28.000 |   0.8582 |     30.006 |     1.5
    9 |   0.7740 |     26.770 |   0.8613 |     29.976 |     1.7
   10 |   0.7479 |     25.640 |   0.8368 |     28.342 |     1.9
   11 |   0.7042 |     23.858 |   0.8533 |     28.728 |     2.1
   12 |   0.6904 |     23.345 |   0.8276 |     29.026 |     2.3
   13 |   0.6640 |     22.662 |   0.8550 |     28.699 |     2.5
   14 |   0.6297 |     21.310 |   0.8076 |     26.411 |     2.6
   15 |   0.6043 |     20.505 |   0.8484 |     27.332 |     2.8
   16 |   0.5810 |     19.871 |   0.8286 |     26.173 |     3.0
   17 |   0.5562 |     18.977 |   0.8281 |     25.728 |     3.2
   18 |   0.5313 |     18.244 |   0.7749 |     24.837 |     3.4
   19 |   0.5101 |     17.759 |   0.8304 |     25.817 |     3.6
   20 |   0.4748 |     16.066 |   0.8020 |     26.055 |     3.8
   21 |   0.4584 |     15.757 |   0.8139 |     25.253 |     4.0
   22 |   0.4501 |     16.054 |   0.7787 |     23.173 |     4.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,618

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4834 |     45.549 |   1.2110 |     40.582 |     0.1
    2 |   1.1565 |     38.700 |   1.1263 |     37.641 |     0.3
    3 |   1.0502 |     34.850 |   1.0215 |     33.868 |     0.4
    4 |   0.9563 |     31.767 |   0.9975 |     32.917 |     0.6
    5 |   0.8929 |     30.107 |   0.9601 |     32.561 |     0.7
    6 |   0.8320 |     27.835 |   0.9106 |     30.749 |     0.8
    7 |   0.7825 |     26.809 |   0.9127 |     29.441 |     1.0
    8 |   0.7412 |     25.050 |   0.8782 |     29.739 |     1.1
    9 |   0.7046 |     23.704 |   0.8423 |     28.194 |     1.3
   10 |   0.6597 |     22.441 |   0.8647 |     28.699 |     1.4
   11 |   0.6167 |     20.924 |   0.8352 |     27.362 |     1.6
   12 |   0.6021 |     20.582 |   0.8383 |     26.946 |     1.7
   13 |   0.5597 |     19.088 |   0.8247 |     26.560 |     1.8
   14 |   0.5452 |     18.614 |   0.8216 |     26.352 |     2.0
   15 |   0.5095 |     17.334 |   0.8117 |     24.926 |     2.1
   16 |   0.4936 |     16.821 |   0.7878 |     25.936 |     2.3
   17 |   0.4767 |     16.303 |   0.8121 |     24.955 |     2.4
   18 |   0.4470 |     15.349 |   0.7970 |     24.688 |     2.5
   19 |   0.4257 |     14.516 |   0.8356 |     24.480 |     2.7
   20 |   0.4045 |     13.815 |   0.8458 |     24.837 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,272,994

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9911 |     52.283 |   1.4168 |     42.187 |     0.1
    2 |   1.3202 |     40.023 |   1.2634 |     38.146 |     0.3
    3 |   1.1844 |     36.924 |   1.1532 |     35.264 |     0.4
    4 |   1.0806 |     33.344 |   1.0867 |     33.393 |     0.6
    5 |   1.0013 |     31.232 |   1.0346 |     32.472 |     0.7
    6 |   0.9210 |     28.800 |   0.9886 |     30.570 |     0.9
    7 |   0.8564 |     26.610 |   0.9536 |     30.333 |     1.0
    8 |   0.7893 |     24.096 |   0.9144 |     28.461 |     1.2
    9 |   0.7305 |     22.094 |   0.9012 |     28.223 |     1.3
   10 |   0.6849 |     20.825 |   0.8761 |     27.213 |     1.5
   11 |   0.6265 |     19.005 |   0.8646 |     26.916 |     1.6
   12 |   0.5829 |     17.676 |   0.8442 |     25.639 |     1.7
   13 |   0.5434 |     16.071 |   0.8371 |     25.936 |     1.9
   14 |   0.5016 |     14.957 |   0.8473 |     25.639 |     2.0
   15 |   0.4710 |     14.168 |   0.8800 |     26.381 |     2.2
   16 |   0.4427 |     13.330 |   0.8293 |     24.688 |     2.3
   17 |   0.4048 |     12.006 |   0.8279 |     24.985 |     2.5
   18 |   0.3760 |     11.289 |   0.8288 |     24.985 |     2.6
   19 |   0.3433 |      9.933 |   0.8292 |     24.837 |     2.8
   20 |   0.3211 |      9.409 |   0.8381 |     24.302 |     2.9
   21 |   0.3097 |      8.951 |   0.8344 |     23.827 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,202

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4909 |     45.643 |   1.2101 |     41.384 |     0.2
    2 |   1.1524 |     39.185 |   1.1033 |     37.641 |     0.3
    3 |   1.0595 |     35.970 |   1.0511 |     36.601 |     0.5
    4 |   0.9819 |     33.146 |   0.9939 |     33.720 |     0.7
    5 |   0.9226 |     31.122 |   0.9618 |     32.709 |     0.9
    6 |   0.8650 |     29.462 |   0.9170 |     30.422 |     1.0
    7 |   0.8278 |     28.193 |   0.8948 |     30.333 |     1.2
    8 |   0.7781 |     26.528 |   0.8725 |     29.174 |     1.4
    9 |   0.7549 |     25.954 |   0.8335 |     28.461 |     1.6
   10 |   0.7236 |     24.917 |   0.8382 |     28.461 |     1.7
   11 |   0.6806 |     23.450 |   0.8372 |     28.223 |     1.9
   12 |   0.6594 |     22.546 |   0.8421 |     27.600 |     2.1
   13 |   0.6214 |     21.349 |   0.8312 |     27.778 |     2.3
   14 |   0.6083 |     20.935 |   0.8220 |     26.857 |     2.4
   15 |   0.5808 |     20.097 |   0.8218 |     26.976 |     2.6
   16 |   0.5529 |     19.110 |   0.8125 |     26.055 |     2.8
   17 |   0.5378 |     18.542 |   0.7868 |     25.847 |     3.0
   18 |   0.5210 |     17.411 |   0.7634 |     23.203 |     3.1
   19 |   0.4868 |     16.843 |   0.8171 |     25.609 |     3.3
   20 |   0.4698 |     16.159 |   0.8296 |     25.639 |     3.5
   21 |   0.4466 |     15.293 |   0.8346 |     24.569 |     3.6
   22 |   0.4388 |     14.940 |   0.8097 |     24.747 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 485,730

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5826 |     46.702 |   1.2644 |     41.206 |     0.1
    2 |   1.1837 |     39.091 |   1.1453 |     37.701 |     0.2
    3 |   1.0588 |     35.247 |   1.0513 |     35.413 |     0.4
    4 |   0.9648 |     32.225 |   0.9820 |     33.066 |     0.5
    5 |   0.8845 |     29.423 |   0.9565 |     31.937 |     0.6
    6 |   0.8284 |     27.840 |   0.8742 |     29.115 |     0.7
    7 |   0.7755 |     25.938 |   0.8707 |     28.758 |     0.8
    8 |   0.7153 |     23.693 |   0.8864 |     29.590 |     1.0
    9 |   0.6817 |     22.601 |   0.8296 |     26.887 |     1.1
   10 |   0.6306 |     21.233 |   0.7911 |     25.787 |     1.2
   11 |   0.5968 |     20.075 |   0.8026 |     26.055 |     1.3
   12 |   0.5582 |     18.658 |   0.8335 |     26.025 |     1.5
   13 |   0.5322 |     17.974 |   0.8082 |     25.134 |     1.6
   14 |   0.4937 |     16.358 |   0.7939 |     23.529 |     1.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 485,730

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5430 |     60.975 |   1.8734 |     45.544 |     0.1
    2 |   1.7631 |     45.103 |   1.5402 |     43.791 |     0.3
    3 |   1.5393 |     43.156 |   1.4225 |     41.860 |     0.4
    4 |   1.4303 |     41.573 |   1.3438 |     40.523 |     0.5
    5 |   1.3547 |     40.056 |   1.2852 |     38.681 |     0.7
    6 |   1.2922 |     39.008 |   1.2329 |     36.720 |     0.8
    7 |   1.2369 |     37.266 |   1.1951 |     36.334 |     0.9
    8 |   1.1946 |     36.571 |   1.1690 |     35.651 |     1.1
    9 |   1.1474 |     35.352 |   1.1451 |     34.611 |     1.2
   10 |   1.1104 |     34.028 |   1.1095 |     34.046 |     1.3
   11 |   1.0720 |     32.727 |   1.0820 |     33.779 |     1.5
   12 |   1.0388 |     31.888 |   1.0628 |     33.541 |     1.6
   13 |   1.0063 |     30.973 |   1.0438 |     31.759 |     1.7
   14 |   0.9770 |     30.096 |   1.0408 |     32.234 |     1.9
   15 |   0.9500 |     29.263 |   1.0282 |     32.115 |     2.0
   16 |   0.9197 |     28.138 |   1.0134 |     31.818 |     2.1
   17 |   0.8952 |     27.371 |   1.0033 |     31.699 |     2.3
   18 |   0.8729 |     26.864 |   0.9939 |     31.759 |     2.4
   19 |   0.8434 |     25.882 |   0.9862 |     31.135 |     2.5
   20 |   0.8275 |     25.154 |   0.9805 |     30.422 |     2.7
   21 |   0.7998 |     24.829 |   0.9810 |     30.630 |     2.8
   22 |   0.7847 |     24.068 |   0.9595 |     30.125 |     2.9
   23 |   0.7596 |     23.230 |   0.9556 |     29.976 |     3.1
   24 |   0.7454 |     23.042 |   0.9547 |     29.768 |     3.2
   25 |   0.7207 |     22.397 |   0.9543 |     29.560 |     3.3
   26 |   0.7003 |     21.525 |   0.9503 |     29.026 |     3.5
   27 |   0.6863 |     21.239 |   0.9496 |     29.144 |     3.6
   28 |   0.6684 |     20.312 |   0.9440 |     28.461 |     3.7
   29 |   0.6574 |     20.257 |   0.9454 |     28.431 |     3.9
   30 |   0.6357 |     19.529 |   0.9555 |     28.313 |     4.0
   31 |   0.6217 |     19.297 |   0.9416 |     27.837 |     4.1
   32 |   0.6049 |     18.503 |   0.9477 |     28.313 |     4.3
   33 |   0.5960 |     18.305 |   0.9533 |     28.550 |     4.4
   34 |   0.5816 |     17.996 |   0.9494 |     27.986 |     4.5
   35 |   0.5678 |     17.825 |   0.9556 |     27.392 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,604,258

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2035 |     56.580 |   1.5106 |     44.979 |     0.2
    2 |   1.4686 |     43.393 |   1.3235 |     40.553 |     0.3
    3 |   1.3278 |     40.801 |   1.2191 |     37.849 |     0.5
    4 |   1.2293 |     38.418 |   1.1621 |     36.126 |     0.7
    5 |   1.1550 |     36.234 |   1.1004 |     35.056 |     0.8
    6 |   1.0868 |     34.409 |   1.0665 |     33.185 |     1.0
    7 |   1.0288 |     32.523 |   1.0299 |     33.452 |     1.2
    8 |   0.9693 |     30.454 |   0.9874 |     31.996 |     1.3
    9 |   0.9188 |     28.805 |   0.9565 |     30.689 |     1.5
   10 |   0.8690 |     27.305 |   0.9322 |     29.501 |     1.7
   11 |   0.8280 |     25.827 |   0.9238 |     29.471 |     1.8
   12 |   0.7909 |     24.846 |   0.9194 |     28.342 |     2.0
   13 |   0.7445 |     23.169 |   0.9103 |     28.461 |     2.1
   14 |   0.7016 |     21.774 |   0.9064 |     27.926 |     2.3
   15 |   0.6720 |     20.886 |   0.8737 |     27.094 |     2.5
   16 |   0.6371 |     19.816 |   0.8907 |     27.243 |     2.6
   17 |   0.6102 |     19.126 |   0.8962 |     26.768 |     2.8
   18 |   0.5753 |     17.753 |   0.9137 |     27.273 |     3.0
   19 |   0.5512 |     17.174 |   0.9082 |     26.263 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,258

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5152 |     46.862 |   1.2758 |     42.989 |     0.2
    2 |   1.2093 |     40.939 |   1.1654 |     39.037 |     0.3
    3 |   1.1138 |     37.856 |   1.0753 |     37.522 |     0.5
    4 |   1.0417 |     35.468 |   1.0674 |     35.472 |     0.6
    5 |   0.9924 |     33.890 |   1.0179 |     34.938 |     0.8
    6 |   0.9407 |     32.368 |   0.9746 |     33.096 |     0.9
    7 |   0.8898 |     30.306 |   0.9716 |     33.393 |     1.1
    8 |   0.8586 |     29.655 |   0.9180 |     31.521 |     1.2
    9 |   0.8227 |     27.951 |   0.8978 |     30.244 |     1.4
   10 |   0.7903 |     27.090 |   0.8787 |     30.362 |     1.6
   11 |   0.7690 |     26.164 |   0.9041 |     30.184 |     1.7
   12 |   0.7325 |     25.314 |   0.8619 |     29.234 |     1.9
   13 |   0.6984 |     24.057 |   0.8452 |     28.520 |     2.0
   14 |   0.6782 |     23.180 |   0.8169 |     27.897 |     2.2
   15 |   0.6448 |     22.231 |   0.8185 |     27.540 |     2.3
   16 |   0.6181 |     21.321 |   0.7958 |     25.728 |     2.5
   17 |   0.5882 |     20.108 |   0.8005 |     26.084 |     2.6
   18 |   0.5585 |     19.259 |   0.8108 |     25.817 |     2.8
   19 |   0.5446 |     18.746 |   0.8196 |     25.876 |     3.0
   20 |   0.5282 |     18.156 |   0.7897 |     25.193 |     3.1
   21 |   0.4862 |     16.766 |   0.7840 |     25.074 |     3.3
   22 |   0.4675 |     16.121 |   0.8382 |     25.698 |     3.4
   23 |   0.4691 |     16.049 |   0.7879 |     24.094 |     3.6
   24 |   0.4380 |     15.194 |   0.8017 |     24.480 |     3.7
   25 |   0.4080 |     14.152 |   0.8101 |     24.153 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,471,778

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5164 |     46.741 |   1.2778 |     42.573 |     0.2
    2 |   1.1712 |     39.328 |   1.1125 |     37.671 |     0.3
    3 |   1.0703 |     36.124 |   1.0574 |     37.047 |     0.5
    4 |   0.9845 |     33.322 |   0.9787 |     33.393 |     0.6
    5 |   0.9114 |     30.647 |   0.9593 |     31.996 |     0.8
    6 |   0.8767 |     29.622 |   0.9398 |     31.046 |     0.9
    7 |   0.8298 |     28.386 |   0.9040 |     31.016 |     1.1
    8 |   0.7803 |     26.478 |   0.8760 |     29.412 |     1.2
    9 |   0.7431 |     25.403 |   0.8767 |     29.709 |     1.4
   10 |   0.7068 |     24.178 |   0.8504 |     28.461 |     1.6
   11 |   0.6660 |     22.910 |   0.8291 |     27.392 |     1.7
   12 |   0.6305 |     21.520 |   0.8237 |     27.332 |     1.9
   13 |   0.6089 |     20.880 |   0.9217 |     27.986 |     2.0
   14 |   0.5798 |     19.794 |   0.8281 |     26.381 |     2.2
   15 |   0.5574 |     19.077 |   0.7993 |     25.490 |     2.3
   16 |   0.5315 |     18.299 |   0.7947 |     24.955 |     2.5
   17 |   0.5040 |     17.273 |   0.8079 |     25.490 |     2.6
   18 |   0.4879 |     16.623 |   0.8258 |     25.282 |     2.8
   19 |   0.4571 |     15.889 |   0.8184 |     24.658 |     3.0
   20 |   0.4426 |     15.062 |   0.8717 |     25.223 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,202

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3767 |     59.949 |   1.5866 |     45.217 |     0.2
    2 |   1.5182 |     43.878 |   1.3243 |     41.860 |     0.4
    3 |   1.3409 |     41.347 |   1.2316 |     39.364 |     0.6
    4 |   1.2412 |     38.705 |   1.1669 |     37.285 |     0.7
    5 |   1.1718 |     36.797 |   1.1190 |     35.472 |     0.9
    6 |   1.1086 |     34.679 |   1.0875 |     34.759 |     1.1
    7 |   1.0480 |     33.102 |   1.0562 |     33.957 |     1.3
    8 |   1.0021 |     31.381 |   1.0078 |     32.650 |     1.5
    9 |   0.9541 |     29.820 |   0.9960 |     32.383 |     1.7
   10 |   0.9080 |     28.265 |   0.9808 |     32.026 |     1.9
   11 |   0.8645 |     26.919 |   0.9679 |     31.907 |     2.1
   12 |   0.8294 |     25.745 |   0.9663 |     31.194 |     2.2
   13 |   0.7927 |     24.763 |   0.9414 |     29.976 |     2.4
   14 |   0.7519 |     23.219 |   0.9278 |     29.234 |     2.6
   15 |   0.7259 |     22.601 |   0.9064 |     29.263 |     2.8
   16 |   0.6980 |     21.945 |   0.9155 |     29.055 |     3.0
   17 |   0.6664 |     20.814 |   0.9202 |     28.491 |     3.2
   18 |   0.6348 |     19.535 |   0.9167 |     28.847 |     3.4
   19 |   0.6134 |     18.944 |   0.9119 |     27.956 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 535,714

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5487 |     60.225 |   1.8504 |     46.821 |     0.1
    2 |   1.7617 |     45.555 |   1.5589 |     44.623 |     0.2
    3 |   1.5588 |     44.253 |   1.4388 |     43.761 |     0.3
    4 |   1.4506 |     42.648 |   1.3582 |     40.463 |     0.5
    5 |   1.3709 |     40.735 |   1.2891 |     39.037 |     0.6
    6 |   1.3069 |     39.097 |   1.2390 |     38.057 |     0.7
    7 |   1.2470 |     37.795 |   1.2079 |     36.928 |     0.8
    8 |   1.1987 |     36.499 |   1.1588 |     35.591 |     0.9
    9 |   1.1548 |     35.550 |   1.1394 |     34.967 |     1.1
   10 |   1.1089 |     33.923 |   1.1128 |     34.730 |     1.2
   11 |   1.0673 |     32.556 |   1.0824 |     33.779 |     1.3
   12 |   1.0313 |     31.205 |   1.0555 |     33.214 |     1.4
   13 |   0.9984 |     30.697 |   1.0409 |     33.422 |     1.5
   14 |   0.9648 |     29.660 |   1.0254 |     32.650 |     1.6
   15 |   0.9323 |     28.502 |   1.0193 |     31.313 |     1.8
   16 |   0.9032 |     28.000 |   1.0056 |     31.670 |     1.9
   17 |   0.8770 |     27.030 |   1.0122 |     32.145 |     2.0
   18 |   0.8479 |     26.241 |   0.9906 |     31.105 |     2.1
   19 |   0.8173 |     25.188 |   0.9803 |     30.986 |     2.2
   20 |   0.7975 |     24.735 |   0.9681 |     30.006 |     2.4
   21 |   0.7761 |     24.178 |   0.9735 |     30.541 |     2.5
   22 |   0.7513 |     22.799 |   0.9749 |     30.065 |     2.6
   23 |   0.7270 |     22.463 |   0.9569 |     30.214 |     2.7
   24 |   0.7142 |     22.143 |   0.9763 |     30.184 |     2.8
   25 |   0.6945 |     21.553 |   0.9628 |     29.026 |     2.9
   26 |   0.6749 |     20.842 |   0.9673 |     30.006 |     3.1
   27 |   0.6568 |     20.218 |   0.9614 |     28.877 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 470,370

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8313 |     51.506 |   1.3430 |     44.058 |     0.1
    2 |   1.3110 |     42.957 |   1.2268 |     40.582 |     0.2
    3 |   1.2132 |     40.299 |   1.1390 |     37.908 |     0.4
    4 |   1.1473 |     38.655 |   1.0942 |     36.542 |     0.5
    5 |   1.0880 |     36.323 |   1.0621 |     35.710 |     0.6
    6 |   1.0399 |     34.922 |   1.0041 |     33.333 |     0.7
    7 |   0.9912 |     33.118 |   0.9749 |     34.135 |     0.8
    8 |   0.9489 |     31.927 |   0.9628 |     31.699 |     1.0
    9 |   0.9050 |     30.311 |   0.9343 |     31.996 |     1.1
   10 |   0.8706 |     29.368 |   0.9059 |     30.362 |     1.2
   11 |   0.8382 |     28.232 |   0.9009 |     30.303 |     1.3
   12 |   0.8163 |     27.636 |   0.8807 |     29.263 |     1.5
   13 |   0.7744 |     26.042 |   0.8727 |     28.788 |     1.6
   14 |   0.7433 |     24.879 |   0.8476 |     28.728 |     1.7
   15 |   0.7244 |     24.432 |   0.8361 |     27.302 |     1.8
   16 |   0.6933 |     23.605 |   0.8579 |     28.075 |     1.9
   17 |   0.6700 |     22.546 |   0.8482 |     27.243 |     2.1
   18 |   0.6477 |     21.945 |   0.8388 |     26.976 |     2.2
   19 |   0.6306 |     21.206 |   0.8239 |     25.342 |     2.3
   20 |   0.5938 |     19.970 |   0.8461 |     26.946 |     2.4
   21 |   0.5942 |     20.103 |   0.8552 |     27.689 |     2.5
   22 |   0.5594 |     18.933 |   0.8243 |     26.144 |     2.7
   23 |   0.5537 |     18.641 |   0.8494 |     27.184 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,241,506

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3373 |     58.670 |   1.5791 |     45.157 |     0.1
    2 |   1.5303 |     44.126 |   1.3666 |     43.375 |     0.3
    3 |   1.3701 |     42.036 |   1.2658 |     40.137 |     0.4
    4 |   1.2760 |     40.034 |   1.2114 |     38.711 |     0.5
    5 |   1.2138 |     38.225 |   1.1532 |     37.047 |     0.7
    6 |   1.1512 |     36.455 |   1.1101 |     34.848 |     0.8
    7 |   1.0993 |     34.740 |   1.0790 |     34.670 |     0.9
    8 |   1.0470 |     33.041 |   1.0473 |     33.868 |     1.0
    9 |   1.0053 |     31.899 |   1.0140 |     32.175 |     1.2
   10 |   0.9588 |     30.151 |   0.9797 |     31.402 |     1.3
   11 |   0.9204 |     28.965 |   0.9625 |     31.462 |     1.4
   12 |   0.8827 |     27.890 |   0.9534 |     30.422 |     1.6
   13 |   0.8497 |     26.677 |   0.9326 |     30.273 |     1.7
   14 |   0.8189 |     25.513 |   0.9135 |     29.234 |     1.8
   15 |   0.7843 |     24.471 |   0.9219 |     28.669 |     2.0
   16 |   0.7504 |     23.522 |   0.8935 |     27.510 |     2.1
   17 |   0.7230 |     22.606 |   0.8879 |     27.807 |     2.2
   18 |   0.6865 |     21.503 |   0.8801 |     27.600 |     2.4
   19 |   0.6681 |     21.018 |   0.8972 |     27.332 |     2.5
   20 |   0.6418 |     19.821 |   0.8834 |     27.332 |     2.6
   21 |   0.6197 |     19.270 |   0.8894 |     26.649 |     2.8
   22 |   0.6000 |     18.630 |   0.8970 |     26.441 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 602,466

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6907 |     48.875 |   1.3413 |     45.841 |     0.1
    2 |   1.2954 |     42.356 |   1.2066 |     39.394 |     0.2
    3 |   1.1783 |     39.113 |   1.1081 |     37.195 |     0.4
    4 |   1.1137 |     37.403 |   1.0739 |     36.096 |     0.5
    5 |   1.0544 |     35.606 |   1.0340 |     35.056 |     0.6
    6 |   1.0085 |     34.243 |   1.0217 |     35.235 |     0.8
    7 |   0.9714 |     32.445 |   0.9478 |     32.709 |     0.9
    8 |   0.9346 |     31.546 |   0.9367 |     31.432 |     1.0
    9 |   0.9003 |     29.991 |   0.9505 |     32.412 |     1.1
   10 |   0.8616 |     28.745 |   0.8922 |     29.887 |     1.3
   11 |   0.8273 |     27.791 |   0.8718 |     29.026 |     1.4
   12 |   0.7948 |     26.539 |   0.8535 |     29.412 |     1.5
   13 |   0.7703 |     25.965 |   0.8605 |     29.709 |     1.6
   14 |   0.7402 |     24.956 |   0.8631 |     28.134 |     1.8
   15 |   0.7139 |     23.952 |   0.8387 |     28.461 |     1.9
   16 |   0.6799 |     22.992 |   0.8324 |     28.342 |     2.0
   17 |   0.6574 |     22.281 |   0.8302 |     26.827 |     2.1
   18 |   0.6512 |     21.707 |   0.8306 |     26.946 |     2.3
   19 |   0.6160 |     20.654 |   0.8536 |     26.738 |     2.4
   20 |   0.5884 |     19.683 |   0.7992 |     25.906 |     2.5
   21 |   0.5720 |     19.154 |   0.7971 |     25.520 |     2.6
   22 |   0.5502 |     18.658 |   0.8380 |     26.352 |     2.8
   23 |   0.5250 |     17.698 |   0.8207 |     25.520 |     2.9
   24 |   0.5084 |     17.141 |   0.8589 |     25.966 |     3.0
   25 |   0.4905 |     16.358 |   0.8540 |     26.114 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,471,778

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0412 |     53.794 |   1.4053 |     41.919 |     0.2
    2 |   1.3052 |     39.825 |   1.2413 |     38.087 |     0.3
    3 |   1.1648 |     35.925 |   1.1387 |     34.759 |     0.5
    4 |   1.0524 |     32.677 |   1.0494 |     32.947 |     0.6
    5 |   0.9588 |     29.710 |   0.9930 |     31.432 |     0.8
    6 |   0.8834 |     27.294 |   0.9554 |     30.214 |     0.9
    7 |   0.8101 |     24.796 |   0.9129 |     28.966 |     1.1
    8 |   0.7405 |     22.546 |   0.8904 |     27.778 |     1.2
    9 |   0.6879 |     20.930 |   0.8901 |     27.689 |     1.4
   10 |   0.6363 |     19.446 |   0.8538 |     26.471 |     1.6
   11 |   0.5874 |     17.941 |   0.8519 |     26.649 |     1.7
   12 |   0.5458 |     16.430 |   0.8101 |     25.253 |     1.9
   13 |   0.5053 |     15.266 |   0.8127 |     25.015 |     2.0
   14 |   0.4602 |     13.722 |   0.8225 |     25.134 |     2.2
   15 |   0.4276 |     12.817 |   0.8193 |     24.213 |     2.3
   16 |   0.3949 |     11.736 |   0.8265 |     24.480 |     2.5
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,341,090

Training started
X_train.shape: torch.Size([3022, 702])
Y_train.shape: torch.Size([3022, 7])
X_dev.shape: torch.Size([561, 294])
Y_dev.shape: torch.Size([561, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0330 |     53.353 |   1.4507 |     44.355 |     0.1
    2 |   1.3499 |     41.683 |   1.2728 |     38.859 |     0.3
    3 |   1.2050 |     37.547 |   1.1793 |     36.958 |     0.4
    4 |   1.1028 |     34.420 |   1.1067 |     35.056 |     0.6
    5 |   1.0195 |     31.982 |   1.0544 |     33.690 |     0.7
    6 |   0.9455 |     29.296 |   1.0001 |     31.046 |     0.9
    7 |   0.8748 |     26.985 |   0.9701 |     30.422 |     1.0
    8 |   0.8246 |     25.276 |   0.9638 |     30.749 |     1.2
    9 |   0.7653 |     23.456 |   0.9401 |     29.739 |     1.3
   10 |   0.7132 |     21.564 |   0.8943 |     27.897 |     1.5
   11 |   0.6689 |     20.174 |   0.9061 |     28.491 |     1.6
   12 |   0.6244 |     18.851 |   0.8803 |     27.005 |     1.8
   13 |   0.5849 |     17.406 |   0.8641 |     26.263 |     1.9
   14 |   0.5416 |     16.225 |   0.8575 |     27.243 |     2.1
   15 |   0.5101 |     15.106 |   0.8613 |     25.520 |     2.2
   16 |   0.4751 |     14.086 |   0.8687 |     25.966 |     2.4
   17 |   0.4438 |     13.286 |   0.8743 |     25.371 |     2.5
   18 |   0.4174 |     12.365 |   0.8726 |     25.520 |     2.7
Early stopping

