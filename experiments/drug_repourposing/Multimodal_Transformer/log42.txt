Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 437,026

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6494 |     47.299 |   1.3003 |     42.782 |     0.1
    2 |   1.2039 |     39.043 |   1.1580 |     39.467 |     0.2
    3 |   1.0780 |     35.240 |   1.0744 |     35.595 |     0.3
    4 |   0.9847 |     32.490 |   1.0059 |     33.116 |     0.4
    5 |   0.9138 |     30.142 |   0.9552 |     32.280 |     0.4
    6 |   0.8343 |     27.783 |   0.9350 |     31.475 |     0.5
    7 |   0.7871 |     26.339 |   0.9194 |     30.421 |     0.6
    8 |   0.7290 |     24.157 |   0.9035 |     29.182 |     0.7
    9 |   0.6959 |     23.556 |   0.8365 |     27.416 |     0.8
   10 |   0.6477 |     21.952 |   0.8419 |     26.704 |     0.9
   11 |   0.6132 |     20.425 |   0.8598 |     27.664 |     1.0
   12 |   0.5766 |     19.428 |   0.8384 |     25.589 |     1.1
   13 |   0.5510 |     18.353 |   0.8296 |     26.208 |     1.2
   14 |   0.5199 |     17.471 |   0.8335 |     25.620 |     1.3
   15 |   0.4788 |     15.983 |   0.8295 |     24.690 |     1.3
   16 |   0.4590 |     15.421 |   0.8526 |     25.310 |     1.4
   17 |   0.4389 |     15.162 |   0.8329 |     24.164 |     1.5
   18 |   0.4114 |     13.773 |   0.8493 |     24.287 |     1.6
   19 |   0.3894 |     13.233 |   0.8070 |     22.553 |     1.7
   20 |   0.3683 |     12.572 |   0.8639 |     23.792 |     1.8
   21 |   0.3617 |     12.224 |   0.8499 |     23.730 |     1.9
   22 |   0.3478 |     11.938 |   0.8747 |     23.358 |     2.0
   23 |   0.3348 |     11.486 |   0.8630 |     22.553 |     2.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 602,594

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6081 |     47.024 |   1.3064 |     43.123 |     0.1
    2 |   1.1887 |     39.308 |   1.1431 |     37.608 |     0.2
    3 |   1.0586 |     35.213 |   1.0623 |     35.781 |     0.3
    4 |   0.9770 |     32.766 |   1.0066 |     34.046 |     0.5
    5 |   0.9104 |     30.704 |   0.9753 |     32.373 |     0.6
    6 |   0.8521 |     28.654 |   0.9420 |     31.722 |     0.7
    7 |   0.8108 |     27.585 |   0.9005 |     30.824 |     0.8
    8 |   0.7635 |     25.810 |   0.8943 |     30.390 |     0.9
    9 |   0.7222 |     24.460 |   0.8979 |     29.616 |     1.0
   10 |   0.6990 |     23.402 |   0.8436 |     27.107 |     1.2
   11 |   0.6532 |     22.112 |   0.8375 |     27.726 |     1.3
   12 |   0.6192 |     20.944 |   0.8374 |     27.045 |     1.4
   13 |   0.5992 |     20.547 |   0.8354 |     26.549 |     1.5
   14 |   0.5675 |     19.433 |   0.8388 |     26.239 |     1.6
   15 |   0.5383 |     18.199 |   0.8185 |     24.969 |     1.7
   16 |   0.5197 |     17.675 |   0.8301 |     25.898 |     1.9
   17 |   0.4947 |     16.986 |   0.8020 |     24.257 |     2.0
   18 |   0.4653 |     15.950 |   0.8277 |     24.814 |     2.1
   19 |   0.4443 |     15.162 |   0.8259 |     23.637 |     2.2
   20 |   0.4201 |     14.523 |   0.8478 |     23.978 |     2.3
   21 |   0.4071 |     14.005 |   0.8455 |     23.358 |     2.4
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,874

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1013 |     52.403 |   1.4874 |     44.052 |     0.1
    2 |   1.3543 |     40.757 |   1.2915 |     39.653 |     0.2
    3 |   1.2076 |     36.739 |   1.2108 |     38.538 |     0.4
    4 |   1.1078 |     34.083 |   1.1289 |     35.998 |     0.5
    5 |   1.0318 |     31.823 |   1.0914 |     34.944 |     0.6
    6 |   0.9658 |     30.241 |   1.0418 |     33.953 |     0.7
    7 |   0.9014 |     28.241 |   1.0217 |     32.869 |     0.8
    8 |   0.8402 |     26.196 |   0.9975 |     31.753 |     0.9
    9 |   0.7910 |     24.581 |   0.9375 |     29.988 |     1.1
   10 |   0.7413 |     22.884 |   0.9203 |     29.275 |     1.2
   11 |   0.6928 |     21.159 |   0.8805 |     27.261 |     1.3
   12 |   0.6496 |     19.858 |   0.8861 |     27.912 |     1.4
   13 |   0.6123 |     18.519 |   0.9044 |     27.509 |     1.5
   14 |   0.5744 |     17.378 |   0.8391 |     25.310 |     1.6
   15 |   0.5413 |     16.567 |   0.8505 |     25.403 |     1.8
   16 |   0.5017 |     15.057 |   0.8416 |     24.845 |     1.9
   17 |   0.4737 |     14.170 |   0.8412 |     24.876 |     2.0
   18 |   0.4473 |     13.415 |   0.8392 |     24.380 |     2.1
   19 |   0.4258 |     12.842 |   0.8285 |     23.792 |     2.2
   20 |   0.3945 |     11.916 |   0.8309 |     23.637 |     2.4
   21 |   0.3743 |     11.050 |   0.8223 |     22.924 |     2.5
   22 |   0.3452 |     10.114 |   0.8592 |     23.606 |     2.6
   23 |   0.3228 |      9.711 |   0.8651 |     23.854 |     2.7
   24 |   0.3094 |      9.138 |   0.8455 |     23.296 |     2.8
   25 |   0.2950 |      8.840 |   0.8929 |     23.575 |     3.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,730

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5222 |     46.511 |   1.2947 |     44.145 |     0.2
    2 |   1.2368 |     41.253 |   1.1874 |     41.295 |     0.3
    3 |   1.1706 |     39.495 |   1.1244 |     40.025 |     0.5
    4 |   1.1087 |     37.737 |   1.0822 |     37.887 |     0.6
    5 |   1.0656 |     36.585 |   1.0547 |     37.237 |     0.8
    6 |   1.0185 |     35.108 |   1.0226 |     36.369 |     1.0
    7 |   0.9913 |     34.667 |   1.0122 |     35.099 |     1.1
    8 |   0.9458 |     32.391 |   0.9680 |     33.364 |     1.3
    9 |   0.9201 |     31.592 |   0.9696 |     33.086 |     1.5
   10 |   0.8999 |     31.101 |   0.9432 |     32.993 |     1.6
   11 |   0.8712 |     30.374 |   0.9247 |     31.134 |     1.8
   12 |   0.8372 |     29.183 |   0.8989 |     30.576 |     2.0
   13 |   0.8172 |     28.279 |   0.9098 |     32.311 |     2.1
   14 |   0.7909 |     27.238 |   0.9149 |     30.081 |     2.3
   15 |   0.7818 |     26.879 |   0.8983 |     29.368 |     2.4
   16 |   0.7561 |     26.521 |   0.9114 |     30.483 |     2.6
   17 |   0.7269 |     25.127 |   0.8908 |     29.399 |     2.8
   18 |   0.7028 |     24.239 |   0.8609 |     28.903 |     2.9
   19 |   0.7044 |     24.355 |   0.8787 |     28.439 |     3.1
   20 |   0.6724 |     23.297 |   0.8752 |     28.594 |     3.3
   21 |   0.6608 |     22.840 |   0.8915 |     28.532 |     3.4
   22 |   0.6454 |     22.266 |   0.9241 |     29.275 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,346

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3257 |     59.970 |   1.5416 |     45.291 |     0.2
    2 |   1.5141 |     44.301 |   1.3491 |     42.503 |     0.3
    3 |   1.3600 |     41.595 |   1.2697 |     40.211 |     0.5
    4 |   1.2688 |     38.950 |   1.2059 |     39.064 |     0.6
    5 |   1.1917 |     37.092 |   1.1576 |     37.763 |     0.8
    6 |   1.1302 |     35.367 |   1.1071 |     35.812 |     1.0
    7 |   1.0712 |     33.477 |   1.0572 |     34.015 |     1.1
    8 |   1.0208 |     31.884 |   1.0350 |     33.922 |     1.3
    9 |   0.9707 |     29.889 |   1.0126 |     32.776 |     1.5
   10 |   0.9280 |     28.952 |   0.9970 |     32.249 |     1.7
   11 |   0.8856 |     27.646 |   0.9575 |     30.235 |     1.8
   12 |   0.8412 |     26.108 |   0.9432 |     29.213 |     2.0
   13 |   0.8125 |     25.193 |   0.9471 |     30.235 |     2.1
   14 |   0.7713 |     23.760 |   0.9080 |     28.191 |     2.3
   15 |   0.7388 |     23.082 |   0.9169 |     28.810 |     2.5
   16 |   0.7132 |     22.228 |   0.9179 |     28.067 |     2.6
   17 |   0.6816 |     21.159 |   0.9102 |     27.385 |     2.8
   18 |   0.6583 |     20.552 |   0.8905 |     26.704 |     3.0
   19 |   0.6334 |     19.626 |   0.8865 |     26.673 |     3.1
   20 |   0.6062 |     18.921 |   0.9107 |     26.022 |     3.3
   21 |   0.5777 |     17.791 |   0.9058 |     26.363 |     3.5
   22 |   0.5630 |     17.383 |   0.8960 |     25.434 |     3.6
   23 |   0.5324 |     16.854 |   0.9090 |     25.898 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 485,858

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5816 |     61.607 |   1.8175 |     45.880 |     0.1
    2 |   1.7385 |     45.277 |   1.5402 |     44.424 |     0.3
    3 |   1.5388 |     44.086 |   1.4266 |     43.742 |     0.4
    4 |   1.4337 |     42.086 |   1.3518 |     42.131 |     0.6
    5 |   1.3517 |     40.179 |   1.2951 |     40.582 |     0.7
    6 |   1.2901 |     38.856 |   1.2448 |     38.848 |     0.8
    7 |   1.2366 |     37.368 |   1.2078 |     38.724 |     1.0
    8 |   1.1853 |     35.968 |   1.1659 |     37.670 |     1.1
    9 |   1.1418 |     34.976 |   1.1361 |     36.152 |     1.3
   10 |   1.1032 |     33.807 |   1.1165 |     35.409 |     1.4
   11 |   1.0640 |     32.804 |   1.0857 |     34.294 |     1.5
   12 |   1.0276 |     31.559 |   1.0699 |     34.046 |     1.7
   13 |   0.9979 |     30.627 |   1.0437 |     33.147 |     1.8
   14 |   0.9641 |     29.591 |   1.0256 |     32.094 |     2.0
   15 |   0.9367 |     28.687 |   1.0291 |     32.621 |     2.1
   16 |   0.9106 |     27.750 |   1.0037 |     31.537 |     2.2
   17 |   0.8804 |     27.309 |   1.0080 |     31.537 |     2.4
   18 |   0.8580 |     26.543 |   0.9946 |     31.072 |     2.5
   19 |   0.8344 |     25.529 |   0.9854 |     30.514 |     2.7
   20 |   0.8128 |     25.254 |   0.9805 |     30.545 |     2.8
   21 |   0.7861 |     24.135 |   0.9831 |     30.390 |     2.9
   22 |   0.7690 |     23.804 |   0.9761 |     29.709 |     3.1
   23 |   0.7534 |     23.407 |   0.9561 |     29.616 |     3.2
   24 |   0.7292 |     22.399 |   0.9578 |     29.554 |     3.4
   25 |   0.7135 |     22.151 |   0.9548 |     28.996 |     3.5
   26 |   0.6963 |     21.506 |   0.9622 |     28.996 |     3.7
   27 |   0.6717 |     20.674 |   0.9322 |     28.036 |     3.8
   28 |   0.6589 |     20.161 |   0.9436 |     28.810 |     3.9
   29 |   0.6426 |     20.067 |   0.9462 |     28.315 |     4.1
   30 |   0.6239 |     19.307 |   0.9454 |     28.377 |     4.2
   31 |   0.6118 |     18.932 |   0.9549 |     28.346 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,730

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9486 |     50.055 |   1.4278 |     42.658 |     0.2
    2 |   1.3289 |     40.146 |   1.2798 |     39.281 |     0.4
    3 |   1.1908 |     36.750 |   1.1859 |     36.493 |     0.5
    4 |   1.0903 |     33.769 |   1.1090 |     35.657 |     0.7
    5 |   0.9950 |     30.677 |   1.0519 |     33.271 |     0.9
    6 |   0.9161 |     28.268 |   1.0125 |     31.568 |     1.1
    7 |   0.8430 |     25.750 |   0.9629 |     30.204 |     1.3
    8 |   0.7767 |     23.804 |   0.9196 |     28.222 |     1.5
    9 |   0.7220 |     21.980 |   0.9175 |     28.717 |     1.7
   10 |   0.6713 |     20.409 |   0.8791 |     27.138 |     1.9
   11 |   0.6162 |     18.860 |   0.8754 |     26.859 |     2.1
   12 |   0.5643 |     16.821 |   0.8617 |     26.549 |     2.3
   13 |   0.5271 |     15.658 |   0.8413 |     24.690 |     2.5
   14 |   0.4858 |     14.324 |   0.8746 |     26.239 |     2.7
   15 |   0.4547 |     13.564 |   0.8446 |     24.257 |     2.9
   16 |   0.4210 |     12.588 |   0.8525 |     24.845 |     3.1
   17 |   0.3965 |     11.657 |   0.8435 |     24.040 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,273,250

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9462 |     50.524 |   1.4266 |     43.247 |     0.1
    2 |   1.3201 |     39.804 |   1.2685 |     39.715 |     0.2
    3 |   1.1740 |     35.924 |   1.1631 |     37.020 |     0.4
    4 |   1.0717 |     33.058 |   1.0975 |     34.758 |     0.5
    5 |   0.9838 |     30.671 |   1.0269 |     32.652 |     0.6
    6 |   0.9067 |     28.114 |   0.9849 |     30.917 |     0.8
    7 |   0.8419 |     26.064 |   0.9424 |     29.678 |     0.9
    8 |   0.7761 |     23.644 |   0.9214 |     29.399 |     1.0
    9 |   0.7246 |     22.189 |   0.9147 |     29.709 |     1.1
   10 |   0.6743 |     20.580 |   0.8690 |     27.385 |     1.3
   11 |   0.6267 |     19.312 |   0.8467 |     25.774 |     1.4
   12 |   0.5748 |     17.394 |   0.8380 |     25.743 |     1.5
   13 |   0.5401 |     16.369 |   0.8388 |     25.620 |     1.6
   14 |   0.4944 |     14.820 |   0.8597 |     25.960 |     1.8
   15 |   0.4671 |     13.850 |   0.8363 |     24.938 |     1.9
   16 |   0.4300 |     13.057 |   0.8315 |     24.349 |     2.0
   17 |   0.4022 |     11.861 |   0.8278 |     24.071 |     2.2
   18 |   0.3738 |     11.084 |   0.8451 |     24.287 |     2.3
   19 |   0.3557 |     10.439 |   0.8301 |     23.048 |     2.4
   20 |   0.3234 |      9.518 |   0.8170 |     23.296 |     2.5
   21 |   0.2987 |      8.730 |   0.8534 |     23.482 |     2.7
   22 |   0.2848 |      8.383 |   0.8494 |     23.482 |     2.8
   23 |   0.2623 |      7.622 |   0.8426 |     23.606 |     2.9
   24 |   0.2455 |      7.297 |   0.8515 |     22.615 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,241,762

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5100 |     45.718 |   1.2218 |     41.047 |     0.1
    2 |   1.1490 |     38.641 |   1.1390 |     38.042 |     0.3
    3 |   1.0470 |     35.180 |   1.0327 |     34.294 |     0.4
    4 |   0.9721 |     32.711 |   0.9728 |     32.776 |     0.5
    5 |   0.9059 |     30.688 |   0.9873 |     32.838 |     0.7
    6 |   0.8557 |     28.555 |   0.9372 |     31.939 |     0.8
    7 |   0.8072 |     27.221 |   0.9373 |     31.629 |     0.9
    8 |   0.7737 |     26.455 |   0.9056 |     29.554 |     1.1
    9 |   0.7382 |     24.829 |   0.8870 |     29.709 |     1.2
   10 |   0.6983 |     23.666 |   0.8613 |     28.594 |     1.3
   11 |   0.6567 |     22.266 |   0.8393 |     27.726 |     1.5
   12 |   0.6125 |     20.899 |   0.8477 |     27.850 |     1.6
   13 |   0.6066 |     20.591 |   0.8330 |     26.828 |     1.7
   14 |   0.5782 |     19.571 |   0.8179 |     25.960 |     1.9
   15 |   0.5503 |     18.552 |   0.8135 |     24.566 |     2.0
   16 |   0.5297 |     18.342 |   0.8375 |     25.372 |     2.1
   17 |   0.4908 |     16.838 |   0.8029 |     24.752 |     2.3
   18 |   0.4856 |     16.722 |   0.8183 |     24.504 |     2.4
   19 |   0.4650 |     15.994 |   0.8062 |     24.535 |     2.5
   20 |   0.4305 |     14.594 |   0.8573 |     24.535 |     2.7
   21 |   0.4162 |     14.308 |   0.8250 |     24.690 |     2.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,730

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5140 |     46.621 |   1.2586 |     41.760 |     0.2
    2 |   1.2150 |     40.366 |   1.1534 |     39.591 |     0.4
    3 |   1.1310 |     38.321 |   1.0989 |     37.051 |     0.6
    4 |   1.0799 |     36.866 |   1.0612 |     37.515 |     0.8
    5 |   1.0320 |     35.152 |   1.0365 |     35.533 |     1.0
    6 |   0.9905 |     33.962 |   0.9992 |     34.170 |     1.2
    7 |   0.9605 |     32.722 |   0.9559 |     32.745 |     1.4
    8 |   0.9169 |     31.531 |   0.9700 |     34.046 |     1.6
    9 |   0.8900 |     30.374 |   0.9533 |     33.922 |     1.8
   10 |   0.8673 |     29.922 |   0.9272 |     31.382 |     2.0
   11 |   0.8254 |     28.390 |   0.9018 |     30.173 |     2.3
   12 |   0.8066 |     28.015 |   0.9241 |     30.452 |     2.5
   13 |   0.7827 |     27.100 |   0.8834 |     28.594 |     2.7
   14 |   0.7599 |     26.190 |   0.8978 |     28.717 |     2.9
   15 |   0.7331 |     25.176 |   0.8622 |     27.850 |     3.1
   16 |   0.7024 |     24.151 |   0.8304 |     26.518 |     3.3
   17 |   0.6761 |     23.148 |   0.8581 |     27.726 |     3.5
   18 |   0.6591 |     22.586 |   0.8444 |     25.867 |     3.7
   19 |   0.6286 |     21.996 |   0.8046 |     25.496 |     3.9
   20 |   0.6002 |     20.442 |   0.8249 |     25.805 |     4.1
   21 |   0.5849 |     20.034 |   0.8048 |     25.279 |     4.3
   22 |   0.5711 |     19.577 |   0.8462 |     25.651 |     4.5
   23 |   0.5404 |     18.480 |   0.8545 |     24.938 |     4.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 602,594

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6938 |     65.834 |   1.8715 |     46.995 |     0.2
    2 |   1.7651 |     45.861 |   1.5434 |     45.012 |     0.4
    3 |   1.5427 |     43.855 |   1.4358 |     42.441 |     0.5
    4 |   1.4341 |     41.523 |   1.3491 |     41.016 |     0.7
    5 |   1.3476 |     39.760 |   1.2890 |     40.428 |     0.9
    6 |   1.2798 |     38.167 |   1.2454 |     39.188 |     1.1
    7 |   1.2222 |     36.464 |   1.1992 |     37.794 |     1.3
    8 |   1.1743 |     35.488 |   1.1649 |     37.051 |     1.4
    9 |   1.1326 |     34.298 |   1.1368 |     35.657 |     1.6
   10 |   1.0903 |     33.019 |   1.1052 |     35.161 |     1.8
   11 |   1.0540 |     32.148 |   1.0864 |     34.542 |     2.0
   12 |   1.0178 |     31.233 |   1.0644 |     34.232 |     2.2
   13 |   0.9893 |     30.363 |   1.0490 |     32.621 |     2.4
   14 |   0.9571 |     29.508 |   1.0350 |     31.784 |     2.5
   15 |   0.9259 |     28.312 |   1.0144 |     32.373 |     2.7
   16 |   0.8959 |     27.651 |   1.0191 |     31.908 |     2.9
   17 |   0.8710 |     27.001 |   0.9875 |     30.545 |     3.1
   18 |   0.8417 |     26.047 |   0.9827 |     30.824 |     3.3
   19 |   0.8138 |     25.248 |   0.9787 |     30.112 |     3.5
   20 |   0.7954 |     24.669 |   0.9735 |     31.072 |     3.7
   21 |   0.7709 |     23.854 |   0.9743 |     30.824 |     3.8
   22 |   0.7520 |     23.341 |   0.9558 |     29.616 |     4.0
   23 |   0.7280 |     22.498 |   0.9551 |     29.895 |     4.2
   24 |   0.7115 |     22.211 |   0.9504 |     28.748 |     4.4
   25 |   0.6872 |     21.384 |   0.9559 |     28.872 |     4.6
   26 |   0.6814 |     21.451 |   0.9582 |     28.408 |     4.8
   27 |   0.6600 |     20.723 |   0.9598 |     28.284 |     4.9
   28 |   0.6389 |     19.737 |   0.9542 |     27.943 |     5.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,175,458

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4833 |     45.211 |   1.2338 |     41.605 |     0.2
    2 |   1.1654 |     39.153 |   1.1576 |     41.047 |     0.4
    3 |   1.0584 |     36.056 |   1.0648 |     35.905 |     0.6
    4 |   0.9958 |     34.099 |   1.0191 |     35.564 |     0.7
    5 |   0.9312 |     31.966 |   0.9921 |     34.727 |     0.9
    6 |   0.8912 |     30.561 |   0.9622 |     32.807 |     1.1
    7 |   0.8358 |     28.759 |   0.9414 |     32.032 |     1.3
    8 |   0.8063 |     27.381 |   0.9289 |     30.886 |     1.5
    9 |   0.7801 |     27.094 |   0.8902 |     30.019 |     1.7
   10 |   0.7403 |     25.617 |   0.8690 |     28.748 |     1.9
   11 |   0.7112 |     24.658 |   0.8786 |     28.563 |     2.0
   12 |   0.6894 |     23.738 |   0.8929 |     29.306 |     2.2
   13 |   0.6605 |     22.784 |   0.8693 |     27.695 |     2.4
   14 |   0.6411 |     22.013 |   0.8552 |     27.261 |     2.6
   15 |   0.6016 |     20.591 |   0.8282 |     27.323 |     2.8
   16 |   0.5973 |     20.613 |   0.8161 |     25.527 |     3.0
   17 |   0.5682 |     19.703 |   0.8006 |     25.991 |     3.2
   18 |   0.5494 |     18.987 |   0.8357 |     25.713 |     3.4
   19 |   0.5296 |     18.199 |   0.8282 |     24.814 |     3.5
   20 |   0.5117 |     17.813 |   0.8406 |     25.836 |     3.7
   21 |   0.5043 |     17.378 |   0.8504 |     25.620 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,405,730

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5255 |     46.985 |   1.2797 |     43.401 |     0.2
    2 |   1.2447 |     41.402 |   1.1676 |     40.087 |     0.4
    3 |   1.1576 |     38.784 |   1.1130 |     37.980 |     0.5
    4 |   1.0947 |     37.357 |   1.0500 |     36.927 |     0.7
    5 |   1.0521 |     36.006 |   1.0270 |     36.152 |     0.9
    6 |   1.0017 |     34.320 |   1.0030 |     35.223 |     1.0
    7 |   0.9662 |     33.223 |   0.9952 |     34.882 |     1.2
    8 |   0.9359 |     32.016 |   0.9589 |     32.590 |     1.4
    9 |   0.9015 |     30.842 |   0.9361 |     31.784 |     1.5
   10 |   0.8762 |     30.324 |   0.9104 |     30.948 |     1.7
   11 |   0.8400 |     28.560 |   0.9048 |     30.483 |     1.9
   12 |   0.8106 |     27.811 |   0.9090 |     30.948 |     2.0
   13 |   0.7946 |     27.491 |   0.8768 |     29.368 |     2.2
   14 |   0.7566 |     25.998 |   0.8725 |     28.996 |     2.4
   15 |   0.7328 |     25.121 |   0.8463 |     28.098 |     2.6
   16 |   0.7061 |     24.598 |   0.8505 |     28.036 |     2.7
   17 |   0.6830 |     23.330 |   0.8459 |     27.323 |     2.9
   18 |   0.6542 |     22.399 |   0.8219 |     27.014 |     3.1
   19 |   0.6471 |     22.310 |   0.8000 |     24.907 |     3.2
   20 |   0.6100 |     21.175 |   0.8120 |     24.473 |     3.4
   21 |   0.5876 |     20.255 |   0.8028 |     25.589 |     3.6
   22 |   0.5633 |     19.549 |   0.8005 |     24.628 |     3.7
   23 |   0.5333 |     18.507 |   0.7792 |     24.133 |     3.9
   24 |   0.5141 |     17.615 |   0.8085 |     25.093 |     4.1
   25 |   0.5060 |     17.411 |   0.8016 |     23.575 |     4.2
   26 |   0.4811 |     16.347 |   0.8051 |     23.854 |     4.4
   27 |   0.4515 |     15.460 |   0.8045 |     23.296 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5354 |     63.933 |   1.8907 |     45.136 |     0.2
    2 |   1.6691 |     43.519 |   1.5474 |     43.494 |     0.3
    3 |   1.4616 |     41.821 |   1.4228 |     41.698 |     0.5
    4 |   1.3467 |     39.390 |   1.3373 |     41.388 |     0.6
    5 |   1.2598 |     37.599 |   1.2694 |     39.033 |     0.8
    6 |   1.1954 |     35.946 |   1.2288 |     38.693 |     1.0
    7 |   1.1392 |     34.535 |   1.1810 |     36.896 |     1.1
    8 |   1.0873 |     32.931 |   1.1504 |     36.245 |     1.3
    9 |   1.0418 |     31.741 |   1.1188 |     35.843 |     1.4
   10 |   0.9993 |     30.567 |   1.0859 |     33.984 |     1.6
   11 |   0.9531 |     29.211 |   1.0639 |     33.829 |     1.7
   12 |   0.9136 |     28.131 |   1.0452 |     33.519 |     1.9
   13 |   0.8760 |     26.935 |   1.0260 |     32.094 |     2.1
   14 |   0.8404 |     25.716 |   1.0063 |     31.939 |     2.2
   15 |   0.8039 |     24.708 |   0.9876 |     31.041 |     2.4
   16 |   0.7769 |     23.644 |   0.9741 |     30.143 |     2.5
   17 |   0.7431 |     22.917 |   0.9597 |     29.554 |     2.7
   18 |   0.7187 |     22.024 |   0.9679 |     30.421 |     2.9
   19 |   0.6920 |     20.833 |   0.9649 |     29.554 |     3.0
   20 |   0.6683 |     20.464 |   0.9527 |     28.686 |     3.2
   21 |   0.6389 |     19.461 |   0.9528 |     28.563 |     3.3
   22 |   0.6313 |     19.296 |   0.9428 |     28.625 |     3.5
   23 |   0.6028 |     18.326 |   0.9210 |     27.695 |     3.6
   24 |   0.5760 |     17.648 |   0.9239 |     27.045 |     3.8
   25 |   0.5528 |     16.849 |   0.9356 |     27.571 |     4.0
   26 |   0.5353 |     16.292 |   0.9374 |     27.292 |     4.1
   27 |   0.5270 |     15.785 |   0.9279 |     27.354 |     4.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6582 |     63.762 |   1.9684 |     49.071 |     0.1
    2 |   1.8558 |     46.373 |   1.6017 |     44.238 |     0.2
    3 |   1.6017 |     44.009 |   1.4659 |     43.587 |     0.4
    4 |   1.4730 |     42.394 |   1.3834 |     42.689 |     0.5
    5 |   1.3861 |     41.286 |   1.3199 |     41.171 |     0.6
    6 |   1.3139 |     39.616 |   1.2662 |     40.273 |     0.7
    7 |   1.2554 |     37.941 |   1.2288 |     38.817 |     0.9
    8 |   1.2070 |     37.015 |   1.2047 |     37.732 |     1.0
    9 |   1.1679 |     35.753 |   1.1670 |     37.113 |     1.1
   10 |   1.1323 |     34.695 |   1.1364 |     36.462 |     1.2
   11 |   1.0919 |     33.433 |   1.1235 |     35.874 |     1.3
   12 |   1.0620 |     32.474 |   1.1022 |     35.037 |     1.5
   13 |   1.0283 |     31.443 |   1.0833 |     34.170 |     1.6
   14 |   1.0033 |     30.732 |   1.0608 |     33.953 |     1.7
   15 |   0.9747 |     29.756 |   1.0519 |     33.798 |     1.8
   16 |   0.9477 |     29.178 |   1.0422 |     32.497 |     2.0
   17 |   0.9258 |     28.450 |   1.0318 |     32.962 |     2.1
   18 |   0.8972 |     27.723 |   1.0194 |     32.218 |     2.2
   19 |   0.8692 |     26.802 |   1.0206 |     32.342 |     2.3
   20 |   0.8592 |     26.775 |   1.0141 |     31.629 |     2.4
   21 |   0.8330 |     25.865 |   0.9961 |     30.700 |     2.6
   22 |   0.8110 |     25.143 |   1.0029 |     31.165 |     2.7
   23 |   0.7970 |     24.686 |   0.9862 |     30.390 |     2.8
   24 |   0.7739 |     24.019 |   0.9749 |     30.204 |     2.9
   25 |   0.7595 |     24.019 |   0.9782 |     30.514 |     3.0
   26 |   0.7425 |     23.165 |   0.9758 |     29.461 |     3.1
   27 |   0.7308 |     22.647 |   0.9745 |     29.399 |     3.3
   28 |   0.7133 |     22.603 |   0.9653 |     28.810 |     3.4
   29 |   0.6973 |     21.528 |   0.9682 |     29.244 |     3.5
   30 |   0.6800 |     21.219 |   0.9686 |     29.182 |     3.6
   31 |   0.6657 |     20.778 |   0.9706 |     28.625 |     3.7
   32 |   0.6466 |     20.337 |   0.9795 |     28.625 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,472,034

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2240 |     57.628 |   1.5033 |     44.548 |     0.1
    2 |   1.4613 |     42.797 |   1.3311 |     41.543 |     0.3
    3 |   1.3209 |     40.267 |   1.2472 |     38.817 |     0.4
    4 |   1.2303 |     37.985 |   1.1958 |     38.228 |     0.6
    5 |   1.1575 |     35.907 |   1.1291 |     36.989 |     0.7
    6 |   1.0956 |     34.695 |   1.0953 |     36.369 |     0.9
    7 |   1.0442 |     33.140 |   1.0699 |     34.789 |     1.0
    8 |   1.0004 |     32.226 |   1.0403 |     34.356 |     1.2
    9 |   0.9582 |     30.489 |   1.0023 |     33.271 |     1.3
   10 |   0.9097 |     29.001 |   0.9742 |     32.063 |     1.4
   11 |   0.8735 |     28.131 |   0.9647 |     31.784 |     1.6
   12 |   0.8297 |     26.279 |   0.9360 |     29.771 |     1.7
   13 |   0.7857 |     24.923 |   0.9169 |     29.585 |     1.9
   14 |   0.7592 |     24.228 |   0.8962 |     28.965 |     2.0
   15 |   0.7280 |     22.906 |   0.9078 |     28.191 |     2.2
   16 |   0.6938 |     22.250 |   0.8923 |     27.602 |     2.3
   17 |   0.6611 |     20.745 |   0.8912 |     27.045 |     2.5
   18 |   0.6373 |     19.996 |   0.8684 |     26.363 |     2.6
   19 |   0.6134 |     19.538 |   0.8879 |     26.363 |     2.7
   20 |   0.5770 |     18.370 |   0.8790 |     26.053 |     2.9
   21 |   0.5619 |     17.824 |   0.8932 |     25.124 |     3.0
   22 |   0.5382 |     17.256 |   0.8722 |     25.434 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 470,498

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5164 |     62.048 |   1.8005 |     45.136 |     0.1
    2 |   1.6054 |     43.221 |   1.5143 |     43.278 |     0.2
    3 |   1.4234 |     40.294 |   1.4000 |     40.985 |     0.4
    4 |   1.3179 |     38.194 |   1.3328 |     40.118 |     0.5
    5 |   1.2377 |     36.491 |   1.2631 |     38.197 |     0.6
    6 |   1.1673 |     34.882 |   1.2038 |     37.423 |     0.7
    7 |   1.1122 |     33.245 |   1.1859 |     36.865 |     0.8
    8 |   1.0572 |     31.713 |   1.1402 |     36.400 |     0.9
    9 |   1.0058 |     30.214 |   1.1145 |     35.440 |     1.1
   10 |   0.9661 |     29.150 |   1.0793 |     33.953 |     1.2
   11 |   0.9216 |     27.905 |   1.0521 |     32.993 |     1.3
   12 |   0.8792 |     26.593 |   1.0214 |     32.001 |     1.4
   13 |   0.8379 |     25.061 |   0.9992 |     30.979 |     1.5
   14 |   0.8044 |     24.366 |   0.9818 |     30.019 |     1.7
   15 |   0.7693 |     23.264 |   0.9730 |     29.802 |     1.8
   16 |   0.7385 |     22.156 |   0.9601 |     29.461 |     1.9
   17 |   0.7094 |     21.616 |   0.9632 |     29.616 |     2.0
   18 |   0.6757 |     20.448 |   0.9461 |     28.346 |     2.1
   19 |   0.6482 |     19.544 |   0.9236 |     27.726 |     2.2
   20 |   0.6184 |     18.381 |   0.9205 |     28.129 |     2.4
   21 |   0.5916 |     17.543 |   0.9251 |     27.385 |     2.5
   22 |   0.5720 |     17.080 |   0.9399 |     26.890 |     2.6
   23 |   0.5534 |     16.623 |   0.9247 |     27.292 |     2.7
   24 |   0.5333 |     15.906 |   0.9131 |     25.929 |     2.8
   25 |   0.5055 |     15.195 |   0.9364 |     26.704 |     2.9
   26 |   0.4901 |     14.396 |   0.9176 |     27.292 |     3.1
   27 |   0.4728 |     14.131 |   0.9281 |     26.208 |     3.2
   28 |   0.4582 |     13.718 |   0.9431 |     26.642 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,346

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3256 |     58.151 |   1.5897 |     44.888 |     0.2
    2 |   1.5236 |     43.430 |   1.3617 |     42.286 |     0.4
    3 |   1.3601 |     40.851 |   1.2624 |     40.087 |     0.6
    4 |   1.2567 |     38.051 |   1.2012 |     38.538 |     0.8
    5 |   1.1821 |     36.651 |   1.1593 |     37.392 |     1.0
    6 |   1.1226 |     34.981 |   1.1147 |     36.090 |     1.2
    7 |   1.0682 |     33.670 |   1.0979 |     36.431 |     1.4
    8 |   1.0189 |     32.209 |   1.0516 |     34.634 |     1.7
    9 |   0.9705 |     30.743 |   1.0223 |     33.116 |     1.9
   10 |   0.9281 |     28.952 |   0.9940 |     31.846 |     2.1
   11 |   0.8887 |     27.541 |   1.0067 |     31.506 |     2.3
   12 |   0.8544 |     26.538 |   0.9873 |     30.917 |     2.5
   13 |   0.8186 |     25.893 |   0.9481 |     30.266 |     2.7
   14 |   0.7807 |     24.399 |   0.9477 |     30.019 |     2.9
   15 |   0.7462 |     23.413 |   0.9183 |     28.253 |     3.1
   16 |   0.7233 |     22.878 |   0.9281 |     28.253 |     3.3
   17 |   0.6865 |     21.671 |   0.9197 |     27.726 |     3.5
   18 |   0.6635 |     20.778 |   0.9091 |     28.036 |     3.7
   19 |   0.6345 |     19.880 |   0.8909 |     26.487 |     3.9
   20 |   0.6156 |     19.229 |   0.8913 |     26.642 |     4.1
   21 |   0.5836 |     18.452 |   0.9114 |     27.292 |     4.4
   22 |   0.5681 |     18.022 |   0.9073 |     26.735 |     4.6
   23 |   0.5384 |     17.025 |   0.9258 |     26.735 |     4.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,514

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9418 |     51.868 |   1.4198 |     43.494 |     0.2
    2 |   1.3059 |     40.008 |   1.2584 |     39.777 |     0.4
    3 |   1.1574 |     36.023 |   1.1604 |     36.679 |     0.6
    4 |   1.0535 |     32.914 |   1.1008 |     35.781 |     0.8
    5 |   0.9699 |     30.539 |   1.0378 |     32.900 |     1.0
    6 |   0.8881 |     27.486 |   0.9788 |     31.041 |     1.2
    7 |   0.8198 |     25.358 |   0.9622 |     30.731 |     1.4
    8 |   0.7533 |     23.187 |   0.9379 |     29.554 |     1.6
    9 |   0.6952 |     21.346 |   0.8738 |     27.292 |     1.8
   10 |   0.6423 |     19.985 |   0.8564 |     26.828 |     2.0
   11 |   0.5894 |     17.984 |   0.8577 |     25.867 |     2.2
   12 |   0.5414 |     16.435 |   0.8497 |     25.774 |     2.4
   13 |   0.5038 |     15.179 |   0.8418 |     25.217 |     2.6
   14 |   0.4599 |     13.900 |   0.8428 |     25.186 |     2.8
   15 |   0.4271 |     12.991 |   0.8138 |     23.978 |     3.0
   16 |   0.3921 |     11.750 |   0.8028 |     23.234 |     3.2
   17 |   0.3590 |     10.797 |   0.8102 |     22.677 |     3.4
   18 |   0.3310 |      9.888 |   0.8208 |     23.606 |     3.6
   19 |   0.3152 |      9.485 |   0.8369 |     23.637 |     3.8
   20 |   0.2906 |      8.664 |   0.8246 |     22.398 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 420,258

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6783 |     47.851 |   1.3066 |     43.061 |     0.1
    2 |   1.2035 |     39.627 |   1.1473 |     38.971 |     0.2
    3 |   1.0954 |     36.359 |   1.0834 |     37.918 |     0.3
    4 |   1.0133 |     34.298 |   1.0452 |     36.059 |     0.4
    5 |   0.9476 |     31.652 |   0.9948 |     33.860 |     0.5
    6 |   0.8844 |     29.823 |   0.9527 |     32.497 |     0.7
    7 |   0.8267 |     27.943 |   0.9392 |     30.824 |     0.8
    8 |   0.7934 |     26.631 |   0.8987 |     29.554 |     0.9
    9 |   0.7507 |     25.276 |   0.8862 |     29.926 |     1.0
   10 |   0.6976 |     23.617 |   0.8420 |     27.200 |     1.1
   11 |   0.6689 |     22.636 |   0.8614 |     28.253 |     1.2
   12 |   0.6484 |     22.079 |   0.8377 |     27.912 |     1.3
   13 |   0.6098 |     20.475 |   0.8268 |     26.394 |     1.4
   14 |   0.5697 |     19.444 |   0.8401 |     26.890 |     1.5
   15 |   0.5594 |     18.981 |   0.8255 |     25.898 |     1.6
   16 |   0.5264 |     17.692 |   0.8418 |     27.014 |     1.7
   17 |   0.5086 |     17.190 |   0.8209 |     25.434 |     1.8
   18 |   0.4777 |     16.303 |   0.8319 |     24.535 |     2.0
   19 |   0.4634 |     15.653 |   0.8149 |     24.195 |     2.1
   20 |   0.4478 |     15.261 |   0.8102 |     23.761 |     2.2
   21 |   0.4175 |     14.264 |   0.8354 |     24.783 |     2.3
   22 |   0.4009 |     13.646 |   0.8219 |     24.566 |     2.4
   23 |   0.3783 |     12.731 |   0.8032 |     22.831 |     2.5
   24 |   0.3700 |     12.820 |   0.8467 |     23.730 |     2.6
   25 |   0.3432 |     11.767 |   0.8712 |     23.699 |     2.7
   26 |   0.3500 |     12.324 |   0.8925 |     23.854 |     2.8
   27 |   0.3335 |     11.491 |   0.8704 |     23.513 |     2.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 386,786

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7645 |     49.757 |   1.3286 |     44.393 |     0.1
    2 |   1.2658 |     41.038 |   1.1819 |     39.808 |     0.2
    3 |   1.1572 |     38.117 |   1.1372 |     37.454 |     0.3
    4 |   1.0885 |     36.039 |   1.0611 |     35.688 |     0.4
    5 |   1.0245 |     34.149 |   1.0359 |     35.905 |     0.5
    6 |   0.9709 |     32.644 |   0.9759 |     33.240 |     0.6
    7 |   0.9247 |     31.079 |   0.9437 |     31.784 |     0.7
    8 |   0.8782 |     29.387 |   0.9600 |     32.094 |     0.8
    9 |   0.8489 |     28.483 |   0.8929 |     29.678 |     0.9
   10 |   0.8031 |     26.935 |   0.8905 |     29.895 |     1.0
   11 |   0.7612 |     25.584 |   0.8815 |     28.810 |     1.1
   12 |   0.7324 |     24.928 |   0.8750 |     28.903 |     1.2
   13 |   0.7138 |     23.991 |   0.8515 |     27.695 |     1.3
   14 |   0.6795 |     22.845 |   0.8376 |     26.456 |     1.4
   15 |   0.6491 |     22.018 |   0.8541 |     27.447 |     1.5
   16 |   0.6351 |     21.368 |   0.8451 |     26.487 |     1.5
   17 |   0.5972 |     20.282 |   0.8338 |     25.743 |     1.6
   18 |   0.5825 |     19.560 |   0.8391 |     25.682 |     1.7
   19 |   0.5642 |     18.987 |   0.8289 |     25.372 |     1.8
   20 |   0.5485 |     18.474 |   0.8537 |     25.434 |     1.9
   21 |   0.5274 |     17.703 |   0.8580 |     25.465 |     2.0
   22 |   0.5019 |     16.799 |   0.8537 |     25.031 |     2.1
   23 |   0.4877 |     16.408 |   0.8420 |     24.628 |     2.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,075,874

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4691 |     45.200 |   1.2300 |     41.171 |     0.1
    2 |   1.1545 |     38.465 |   1.0964 |     37.918 |     0.2
    3 |   1.0416 |     34.954 |   1.0349 |     35.843 |     0.4
    4 |   0.9591 |     32.534 |   0.9833 |     33.271 |     0.5
    5 |   0.8828 |     30.065 |   0.9679 |     33.705 |     0.6
    6 |   0.8331 |     28.175 |   0.9188 |     30.266 |     0.7
    7 |   0.7979 |     26.725 |   0.9050 |     30.359 |     0.8
    8 |   0.7404 |     24.945 |   0.8878 |     28.160 |     1.0
    9 |   0.7111 |     24.030 |   0.8819 |     29.275 |     1.1
   10 |   0.6695 |     23.038 |   0.8558 |     28.036 |     1.2
   11 |   0.6455 |     21.842 |   0.8460 |     27.138 |     1.3
   12 |   0.6068 |     20.354 |   0.8279 |     26.797 |     1.5
   13 |   0.5861 |     19.968 |   0.8145 |     25.341 |     1.6
   14 |   0.5503 |     18.877 |   0.8195 |     26.022 |     1.7
   15 |   0.5213 |     18.011 |   0.7877 |     24.411 |     1.8
   16 |   0.5064 |     17.438 |   0.8104 |     24.287 |     1.9
   17 |   0.4839 |     16.567 |   0.8218 |     25.341 |     2.1
   18 |   0.4685 |     15.967 |   0.7966 |     24.040 |     2.2
   19 |   0.4388 |     14.782 |   0.8127 |     23.761 |     2.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,604,514

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9818 |     53.009 |   1.4050 |     43.494 |     0.2
    2 |   1.3011 |     39.848 |   1.2485 |     38.941 |     0.3
    3 |   1.1711 |     36.524 |   1.1710 |     37.237 |     0.5
    4 |   1.0706 |     33.229 |   1.0752 |     34.727 |     0.7
    5 |   0.9887 |     31.052 |   1.0195 |     32.838 |     0.8
    6 |   0.9054 |     28.224 |   0.9966 |     32.249 |     1.0
    7 |   0.8301 |     25.612 |   0.9463 |     31.041 |     1.1
    8 |   0.7693 |     23.727 |   0.9132 |     29.120 |     1.3
    9 |   0.7050 |     21.346 |   0.8656 |     26.859 |     1.5
   10 |   0.6581 |     20.023 |   0.8574 |     26.921 |     1.6
   11 |   0.5971 |     18.017 |   0.8449 |     26.115 |     1.8
   12 |   0.5619 |     17.058 |   0.8301 |     25.341 |     2.0
   13 |   0.5107 |     15.272 |   0.8378 |     25.558 |     2.1
   14 |   0.4688 |     14.142 |   0.8138 |     25.062 |     2.3
   15 |   0.4403 |     13.161 |   0.7932 |     23.730 |     2.5
   16 |   0.4029 |     11.921 |   0.8353 |     24.473 |     2.6
   17 |   0.3773 |     11.381 |   0.8361 |     24.133 |     2.8
   18 |   0.3380 |      9.843 |   0.8014 |     23.575 |     3.0
   19 |   0.3248 |      9.601 |   0.8235 |     23.482 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,250

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1286 |     55.269 |   1.4650 |     44.331 |     0.2
    2 |   1.4441 |     43.149 |   1.3223 |     41.729 |     0.3
    3 |   1.3059 |     40.311 |   1.2352 |     40.056 |     0.5
    4 |   1.2125 |     37.506 |   1.1760 |     38.910 |     0.7
    5 |   1.1389 |     35.494 |   1.1211 |     36.803 |     0.8
    6 |   1.0715 |     33.725 |   1.0760 |     35.316 |     1.0
    7 |   1.0134 |     31.658 |   1.0259 |     34.170 |     1.2
    8 |   0.9622 |     30.682 |   1.0103 |     32.218 |     1.3
    9 |   0.9187 |     29.161 |   0.9906 |     32.125 |     1.5
   10 |   0.8723 |     27.541 |   0.9582 |     31.506 |     1.7
   11 |   0.8325 |     26.003 |   0.9482 |     30.173 |     1.8
   12 |   0.7905 |     24.631 |   0.9308 |     30.019 |     2.0
   13 |   0.7582 |     23.776 |   0.9280 |     28.656 |     2.2
   14 |   0.7271 |     23.076 |   0.9041 |     28.656 |     2.3
   15 |   0.6935 |     21.809 |   0.8888 |     27.292 |     2.5
   16 |   0.6623 |     20.784 |   0.8629 |     25.991 |     2.7
   17 |   0.6345 |     20.051 |   0.8705 |     27.076 |     2.8
   18 |   0.6018 |     19.020 |   0.8714 |     26.115 |     3.0
   19 |   0.5798 |     18.282 |   0.8777 |     26.549 |     3.2
   20 |   0.5536 |     17.571 |   0.8632 |     25.279 |     3.3
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 485,858

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6913 |     69.373 |   1.9950 |     49.690 |     0.1
    2 |   1.8111 |     45.519 |   1.5554 |     44.145 |     0.2
    3 |   1.5534 |     43.563 |   1.4345 |     43.030 |     0.3
    4 |   1.4411 |     41.942 |   1.3584 |     41.945 |     0.4
    5 |   1.3609 |     40.697 |   1.2944 |     40.799 |     0.5
    6 |   1.2938 |     38.972 |   1.2457 |     39.064 |     0.6
    7 |   1.2348 |     37.197 |   1.2125 |     38.445 |     0.7
    8 |   1.1867 |     35.863 |   1.1780 |     36.989 |     0.8
    9 |   1.1446 |     34.722 |   1.1392 |     35.967 |     1.0
   10 |   1.1059 |     33.857 |   1.1177 |     35.254 |     1.1
   11 |   1.0690 |     32.485 |   1.0931 |     34.603 |     1.2
   12 |   1.0343 |     31.702 |   1.0779 |     34.201 |     1.3
   13 |   1.0050 |     30.699 |   1.0586 |     33.395 |     1.4
   14 |   0.9727 |     29.773 |   1.0409 |     32.466 |     1.5
   15 |   0.9414 |     28.731 |   1.0276 |     32.652 |     1.7
   16 |   0.9128 |     28.048 |   1.0186 |     31.753 |     1.8
   17 |   0.8900 |     27.442 |   1.0123 |     31.753 |     1.9
   18 |   0.8673 |     26.687 |   0.9998 |     31.320 |     2.0
   19 |   0.8446 |     26.003 |   0.9832 |     30.669 |     2.1
   20 |   0.8167 |     25.270 |   0.9727 |     30.979 |     2.2
   21 |   0.7951 |     24.581 |   0.9579 |     29.895 |     2.3
   22 |   0.7750 |     23.870 |   0.9563 |     29.833 |     2.4
   23 |   0.7570 |     23.765 |   0.9413 |     28.903 |     2.5
   24 |   0.7385 |     23.038 |   0.9413 |     28.934 |     2.7
   25 |   0.7186 |     22.481 |   0.9520 |     29.647 |     2.8
   26 |   0.7013 |     21.787 |   0.9436 |     28.717 |     2.9
   27 |   0.6849 |     21.511 |   0.9411 |     29.399 |     3.0
   28 |   0.6636 |     20.365 |   0.9585 |     28.717 |     3.1
   29 |   0.6521 |     20.211 |   0.9462 |     28.005 |     3.2
   30 |   0.6372 |     19.814 |   0.9568 |     28.625 |     3.3
   31 |   0.6201 |     19.207 |   0.9499 |     27.540 |     3.4
   32 |   0.6008 |     18.910 |   0.9374 |     26.983 |     3.5
   33 |   0.5941 |     18.474 |   0.9395 |     27.138 |     3.6
   34 |   0.5754 |     17.907 |   0.9470 |     27.912 |     3.7
   35 |   0.5628 |     17.499 |   0.9464 |     26.797 |     3.8
   36 |   0.5507 |     17.394 |   0.9536 |     26.363 |     3.9
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 3
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,273,250

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5294 |     46.710 |   1.2264 |     41.388 |     0.1
    2 |   1.2105 |     40.184 |   1.1345 |     38.786 |     0.3
    3 |   1.1187 |     37.494 |   1.0738 |     36.462 |     0.4
    4 |   1.0530 |     35.053 |   1.0394 |     35.161 |     0.6
    5 |   0.9996 |     33.609 |   1.0194 |     34.913 |     0.7
    6 |   0.9464 |     31.939 |   0.9806 |     33.612 |     0.8
    7 |   0.9100 |     30.622 |   0.9547 |     32.280 |     1.0
    8 |   0.8669 |     28.985 |   0.9208 |     31.165 |     1.1
    9 |   0.8297 |     27.993 |   0.8968 |     29.926 |     1.3
   10 |   0.7929 |     26.802 |   0.8819 |     29.461 |     1.4
   11 |   0.7572 |     25.468 |   0.8733 |     28.315 |     1.6
   12 |   0.7322 |     24.763 |   0.8681 |     27.138 |     1.7
   13 |   0.6957 |     23.931 |   0.8594 |     26.952 |     1.8
   14 |   0.6752 |     22.966 |   0.8514 |     27.881 |     2.0
   15 |   0.6365 |     21.677 |   0.8223 |     25.867 |     2.1
   16 |   0.6156 |     20.833 |   0.8528 |     27.200 |     2.3
   17 |   0.5944 |     20.425 |   0.8355 |     26.022 |     2.4
   18 |   0.5619 |     19.042 |   0.8153 |     25.248 |     2.5
   19 |   0.5396 |     18.480 |   0.8241 |     23.761 |     2.7
   20 |   0.5167 |     17.620 |   0.8234 |     24.257 |     2.8
   21 |   0.4845 |     16.463 |   0.8560 |     24.814 |     3.0
   22 |   0.4649 |     16.044 |   0.8190 |     24.442 |     3.1
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,405,730

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4713 |     45.370 |   1.2564 |     42.286 |     0.2
    2 |   1.1559 |     38.927 |   1.1324 |     38.166 |     0.4
    3 |   1.0584 |     35.852 |   1.0306 |     35.626 |     0.6
    4 |   0.9790 |     33.052 |   1.0014 |     33.984 |     0.8
    5 |   0.9188 |     31.250 |   0.9727 |     33.581 |     1.0
    6 |   0.8849 |     30.308 |   0.9392 |     32.311 |     1.2
    7 |   0.8290 |     28.191 |   0.9259 |     31.846 |     1.4
    8 |   0.7942 |     27.072 |   0.9005 |     30.297 |     1.6
    9 |   0.7554 |     25.551 |   0.8774 |     29.027 |     1.8
   10 |   0.7162 |     24.250 |   0.9010 |     29.554 |     2.0
   11 |   0.6943 |     23.754 |   0.8649 |     28.501 |     2.2
   12 |   0.6584 |     22.580 |   0.8289 |     26.518 |     2.4
   13 |   0.6446 |     22.118 |   0.8243 |     27.385 |     2.6
   14 |   0.6168 |     20.894 |   0.8057 |     25.589 |     2.8
   15 |   0.5771 |     19.593 |   0.8097 |     25.031 |     3.0
   16 |   0.5713 |     19.218 |   0.8221 |     26.394 |     3.2
   17 |   0.5364 |     18.199 |   0.8390 |     26.518 |     3.4
   18 |   0.5066 |     17.323 |   0.8035 |     24.566 |     3.6
   19 |   0.4897 |     16.843 |   0.7770 |     24.411 |     3.8
   20 |   0.4740 |     16.667 |   0.7910 |     23.637 |     4.0
   21 |   0.4432 |     15.283 |   0.8112 |     23.141 |     4.2
   22 |   0.4243 |     14.401 |   0.7883 |     23.172 |     4.4
   23 |   0.4167 |     14.396 |   0.8099 |     23.792 |     4.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 437,026

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5025 |     60.632 |   1.7829 |     45.012 |     0.1
    2 |   1.6044 |     43.590 |   1.5075 |     43.278 |     0.2
    3 |   1.4199 |     41.077 |   1.3884 |     40.954 |     0.3
    4 |   1.3136 |     38.950 |   1.3155 |     39.281 |     0.4
    5 |   1.2326 |     36.684 |   1.2588 |     37.608 |     0.5
    6 |   1.1633 |     34.645 |   1.2012 |     36.183 |     0.6
    7 |   1.1042 |     33.091 |   1.1554 |     36.090 |     0.7
    8 |   1.0542 |     31.796 |   1.1259 |     34.944 |     0.8
    9 |   1.0027 |     30.280 |   1.0880 |     33.860 |     0.9
   10 |   0.9573 |     28.698 |   1.0609 |     32.807 |     1.1
   11 |   0.9156 |     27.717 |   1.0382 |     31.846 |     1.2
   12 |   0.8716 |     26.345 |   1.0141 |     31.103 |     1.3
   13 |   0.8337 |     25.066 |   1.0019 |     30.669 |     1.4
   14 |   0.7984 |     24.096 |   0.9765 |     30.514 |     1.5
   15 |   0.7628 |     22.878 |   0.9571 |     28.996 |     1.6
   16 |   0.7322 |     21.825 |   0.9368 |     28.656 |     1.7
   17 |   0.6992 |     20.927 |   0.9361 |     28.656 |     1.8
   18 |   0.6836 |     20.497 |   0.9201 |     28.315 |     1.9
   19 |   0.6550 |     19.836 |   0.9098 |     27.076 |     2.0
   20 |   0.6237 |     18.678 |   0.9000 |     27.943 |     2.1
   21 |   0.6031 |     18.326 |   0.8928 |     26.704 |     2.2
   22 |   0.5740 |     17.124 |   0.8886 |     26.890 |     2.3
   23 |   0.5535 |     16.540 |   0.8840 |     25.867 |     2.4
   24 |   0.5332 |     15.879 |   0.8872 |     26.301 |     2.5
   25 |   0.5187 |     15.636 |   0.8889 |     26.332 |     2.6
   26 |   0.5004 |     15.068 |   0.8756 |     25.310 |     2.7
   27 |   0.4795 |     14.131 |   0.8838 |     25.960 |     2.9
   28 |   0.4583 |     13.272 |   0.8895 |     25.434 |     3.0
   29 |   0.4472 |     13.178 |   0.8984 |     25.000 |     3.1
   30 |   0.4371 |     12.935 |   0.8818 |     25.186 |     3.2
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,175,458

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2962 |     59.044 |   1.5221 |     44.703 |     0.2
    2 |   1.4890 |     43.700 |   1.3438 |     42.813 |     0.3
    3 |   1.3447 |     41.325 |   1.2568 |     39.994 |     0.5
    4 |   1.2506 |     38.476 |   1.1994 |     39.033 |     0.7
    5 |   1.1905 |     37.180 |   1.1677 |     37.546 |     0.8
    6 |   1.1288 |     35.119 |   1.1132 |     36.152 |     1.0
    7 |   1.0767 |     33.559 |   1.0990 |     35.967 |     1.2
    8 |   1.0287 |     32.187 |   1.0535 |     34.851 |     1.3
    9 |   0.9797 |     30.550 |   1.0268 |     33.240 |     1.5
   10 |   0.9396 |     29.315 |   0.9956 |     32.993 |     1.7
   11 |   0.8989 |     28.059 |   1.0039 |     32.249 |     1.9
   12 |   0.8630 |     27.436 |   0.9812 |     31.877 |     2.0
   13 |   0.8265 |     26.091 |   0.9652 |     32.001 |     2.2
   14 |   0.7958 |     25.220 |   0.9626 |     31.134 |     2.4
   15 |   0.7601 |     24.217 |   0.9640 |     31.258 |     2.5
   16 |   0.7382 |     23.297 |   0.9420 |     29.771 |     2.7
   17 |   0.7005 |     22.272 |   0.9188 |     28.656 |     2.8
   18 |   0.6817 |     21.666 |   0.9218 |     29.089 |     3.0
   19 |   0.6536 |     20.993 |   0.9131 |     28.625 |     3.2
   20 |   0.6275 |     19.968 |   0.9228 |     28.315 |     3.3
   21 |   0.6001 |     18.981 |   0.9174 |     28.284 |     3.5
   22 |   0.5773 |     18.452 |   0.9241 |     27.385 |     3.6
   23 |   0.5566 |     17.449 |   0.9238 |     27.292 |     3.8
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 470,498

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4375 |     59.915 |   1.7785 |     45.880 |     0.1
    2 |   1.6022 |     43.673 |   1.4955 |     42.937 |     0.2
    3 |   1.4191 |     40.460 |   1.3814 |     40.644 |     0.4
    4 |   1.3102 |     38.128 |   1.3110 |     40.118 |     0.5
    5 |   1.2264 |     36.673 |   1.2472 |     38.879 |     0.6
    6 |   1.1637 |     35.047 |   1.1874 |     37.454 |     0.7
    7 |   1.1013 |     33.218 |   1.1480 |     35.967 |     0.9
    8 |   1.0458 |     31.779 |   1.1440 |     35.874 |     1.0
    9 |   0.9979 |     30.269 |   1.0826 |     33.612 |     1.1
   10 |   0.9522 |     28.847 |   1.0634 |     33.147 |     1.2
   11 |   0.9070 |     27.149 |   1.0235 |     32.311 |     1.4
   12 |   0.8633 |     25.761 |   1.0044 |     31.010 |     1.5
   13 |   0.8283 |     24.713 |   0.9905 |     31.072 |     1.6
   14 |   0.7965 |     23.837 |   0.9861 |     31.320 |     1.7
   15 |   0.7592 |     22.437 |   0.9671 |     29.988 |     1.8
   16 |   0.7263 |     21.798 |   0.9597 |     29.678 |     2.0
   17 |   0.7027 |     20.938 |   0.9496 |     28.810 |     2.1
   18 |   0.6732 |     20.084 |   0.9259 |     28.005 |     2.2
   19 |   0.6411 |     19.367 |   0.9380 |     28.315 |     2.3
   20 |   0.6199 |     18.706 |   0.9482 |     29.120 |     2.4
   21 |   0.6000 |     17.962 |   0.9189 |     27.540 |     2.6
   22 |   0.5692 |     17.008 |   0.9331 |     27.788 |     2.7
   23 |   0.5453 |     16.193 |   0.9416 |     28.191 |     2.8
   24 |   0.5331 |     15.873 |   0.9182 |     27.509 |     2.9
   25 |   0.5086 |     15.289 |   0.9121 |     26.890 |     3.0
   26 |   0.4889 |     14.440 |   0.9163 |     26.580 |     3.2
   27 |   0.4694 |     13.861 |   0.9095 |     26.859 |     3.3
   28 |   0.4528 |     13.283 |   0.9275 |     26.394 |     3.4
   29 |   0.4304 |     12.627 |   0.9080 |     25.867 |     3.5
   30 |   0.4184 |     12.357 |   0.9287 |     25.898 |     3.6
   31 |   0.4067 |     11.949 |   0.9451 |     26.363 |     3.8
   32 |   0.3870 |     11.398 |   0.9193 |     25.031 |     3.9
   33 |   0.3765 |     11.194 |   0.9182 |     24.938 |     4.0
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 602,594

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6407 |     65.482 |   1.9087 |     47.862 |     0.1
    2 |   1.7624 |     45.767 |   1.5373 |     44.548 |     0.3
    3 |   1.5377 |     43.684 |   1.4259 |     43.463 |     0.4
    4 |   1.4331 |     41.948 |   1.3522 |     40.892 |     0.5
    5 |   1.3462 |     40.024 |   1.2887 |     40.242 |     0.7
    6 |   1.2794 |     38.453 |   1.2440 |     39.343 |     0.8
    7 |   1.2271 |     37.197 |   1.1957 |     38.073 |     0.9
    8 |   1.1749 |     35.769 |   1.1645 |     37.206 |     1.1
    9 |   1.1287 |     34.540 |   1.1380 |     36.772 |     1.2
   10 |   1.0847 |     33.135 |   1.1162 |     36.029 |     1.3
   11 |   1.0501 |     32.159 |   1.0781 |     34.789 |     1.5
   12 |   1.0166 |     31.399 |   1.0549 |     33.674 |     1.6
   13 |   0.9806 |     30.076 |   1.0460 |     32.931 |     1.7
   14 |   0.9465 |     29.001 |   1.0314 |     32.807 |     1.9
   15 |   0.9226 |     28.186 |   1.0076 |     31.506 |     2.0
   16 |   0.8961 |     27.524 |   0.9923 |     30.669 |     2.1
   17 |   0.8608 |     26.262 |   0.9758 |     30.421 |     2.3
   18 |   0.8473 |     26.113 |   0.9730 |     29.337 |     2.4
   19 |   0.8176 |     25.061 |   0.9653 |     29.678 |     2.5
   20 |   0.7936 |     24.487 |   0.9626 |     29.368 |     2.7
   21 |   0.7675 |     23.622 |   0.9463 |     28.810 |     2.8
   22 |   0.7497 |     23.076 |   0.9645 |     29.120 |     2.9
   23 |   0.7260 |     22.360 |   0.9379 |     28.377 |     3.1
   24 |   0.7128 |     22.046 |   0.9424 |     28.625 |     3.2
   25 |   0.6877 |     20.971 |   0.9422 |     28.810 |     3.3
   26 |   0.6706 |     20.635 |   0.9412 |     27.726 |     3.5
   27 |   0.6530 |     20.238 |   0.9425 |     28.748 |     3.6
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 3
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 437,026

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6029 |     61.927 |   1.9056 |     45.880 |     0.1
    2 |   1.6864 |     43.491 |   1.5698 |     44.517 |     0.2
    3 |   1.4762 |     41.446 |   1.4235 |     41.233 |     0.3
    4 |   1.3555 |     39.302 |   1.3297 |     39.746 |     0.4
    5 |   1.2630 |     37.346 |   1.2779 |     38.538 |     0.5
    6 |   1.1912 |     35.731 |   1.2113 |     37.020 |     0.6
    7 |   1.1263 |     33.978 |   1.1758 |     36.307 |     0.7
    8 |   1.0704 |     32.077 |   1.1418 |     34.913 |     0.8
    9 |   1.0210 |     30.660 |   1.1022 |     33.271 |     0.9
   10 |   0.9753 |     29.095 |   1.0624 |     32.838 |     1.0
   11 |   0.9308 |     27.993 |   1.0456 |     32.342 |     1.1
   12 |   0.8936 |     26.780 |   1.0286 |     32.156 |     1.2
   13 |   0.8547 |     25.617 |   1.0019 |     31.134 |     1.3
   14 |   0.8179 |     24.686 |   0.9920 |     29.988 |     1.4
   15 |   0.7889 |     23.468 |   0.9629 |     30.050 |     1.5
   16 |   0.7566 |     22.658 |   0.9441 |     28.996 |     1.6
   17 |   0.7227 |     21.577 |   0.9279 |     28.191 |     1.7
   18 |   0.6965 |     20.855 |   0.9348 |     29.058 |     1.8
   19 |   0.6710 |     19.885 |   0.9520 |     29.492 |     1.9
   20 |   0.6432 |     19.417 |   0.9190 |     28.470 |     2.0
   21 |   0.6216 |     18.546 |   0.9130 |     28.129 |     2.1
   22 |   0.5937 |     17.637 |   0.9002 |     27.200 |     2.2
   23 |   0.5680 |     16.992 |   0.8832 |     26.177 |     2.3
   24 |   0.5504 |     16.391 |   0.9049 |     26.425 |     2.4
   25 |   0.5351 |     16.132 |   0.8877 |     25.867 |     2.5
   26 |   0.5080 |     15.234 |   0.8937 |     26.332 |     2.6
   27 |   0.4896 |     14.418 |   0.9024 |     26.363 |     2.7
Early stopping

Model: Seq2Seq Multimodal Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Descriptors dimension: 1136
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,341,346

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5998 |     48.291 |   1.2729 |     42.937 |     0.2
    2 |   1.2579 |     41.584 |   1.1980 |     40.706 |     0.3
    3 |   1.1687 |     39.220 |   1.1149 |     39.188 |     0.5
    4 |   1.1078 |     37.649 |   1.0874 |     38.135 |     0.7
    5 |   1.0560 |     35.709 |   1.0623 |     36.648 |     0.8
    6 |   1.0151 |     34.496 |   1.0068 |     34.325 |     1.0
