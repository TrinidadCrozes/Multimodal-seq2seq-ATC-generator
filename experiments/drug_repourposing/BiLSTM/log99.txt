Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,069,218

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0382 |     56.216 |   1.4777 |     45.420 |     0.0
    2 |   1.4092 |     45.633 |   1.3539 |     45.261 |     0.1
    3 |   1.3282 |     44.646 |   1.2937 |     44.656 |     0.1
    4 |   1.2862 |     43.867 |   1.2546 |     43.670 |     0.2
    5 |   1.2510 |     43.395 |   1.2249 |     42.939 |     0.2
    6 |   1.2186 |     42.720 |   1.2007 |     42.048 |     0.2
    7 |   1.1894 |     41.804 |   1.1734 |     41.571 |     0.3
    8 |   1.1541 |     40.493 |   1.1493 |     40.108 |     0.3
    9 |   1.1140 |     38.446 |   1.1193 |     38.804 |     0.4
   10 |   1.0789 |     37.470 |   1.0730 |     37.214 |     0.4
   11 |   1.0312 |     35.182 |   1.0515 |     35.751 |     0.4
   12 |   0.9893 |     33.520 |   1.0265 |     34.637 |     0.5
   13 |   0.9407 |     31.715 |   0.9881 |     32.952 |     0.5
   14 |   0.8888 |     29.822 |   0.9739 |     32.316 |     0.6
   15 |   0.8439 |     27.754 |   0.9273 |     30.630 |     0.6
   16 |   0.7906 |     25.817 |   0.9182 |     30.121 |     0.6
   17 |   0.7406 |     24.199 |   0.9157 |     29.039 |     0.7
   18 |   0.6995 |     22.498 |   0.9059 |     28.181 |     0.7
   19 |   0.6593 |     21.198 |   0.9103 |     29.135 |     0.8
   20 |   0.6181 |     19.843 |   0.8948 |     27.545 |     0.8
   21 |   0.5785 |     18.559 |   0.8980 |     27.704 |     0.8
   22 |   0.5383 |     17.138 |   0.8995 |     27.226 |     0.9
   23 |   0.5142 |     16.519 |   0.8985 |     26.368 |     0.9
   24 |   0.4758 |     15.026 |   0.8995 |     26.018 |     0.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 442,402

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3841 |     64.236 |   1.8360 |     48.696 |     0.0
    2 |   1.6196 |     46.703 |   1.4669 |     45.642 |     0.1
    3 |   1.4228 |     45.809 |   1.3750 |     45.992 |     0.1
    4 |   1.3598 |     45.101 |   1.3330 |     44.338 |     0.1
    5 |   1.3270 |     44.574 |   1.3098 |     44.211 |     0.1
    6 |   1.3042 |     44.240 |   1.2871 |     43.607 |     0.2
    7 |   1.2796 |     43.515 |   1.2689 |     43.543 |     0.2
    8 |   1.2598 |     43.060 |   1.2509 |     42.494 |     0.2
    9 |   1.2394 |     42.819 |   1.2294 |     41.953 |     0.2
   10 |   1.2162 |     42.248 |   1.2148 |     42.080 |     0.3
   11 |   1.1954 |     41.491 |   1.2000 |     41.794 |     0.3
   12 |   1.1733 |     40.937 |   1.1843 |     40.840 |     0.3
   13 |   1.1488 |     39.895 |   1.1632 |     40.744 |     0.3
   14 |   1.1251 |     38.649 |   1.1456 |     39.122 |     0.4
   15 |   1.0992 |     37.596 |   1.1342 |     38.709 |     0.4
   16 |   1.0704 |     36.400 |   1.1145 |     37.882 |     0.4
   17 |   1.0417 |     35.484 |   1.0951 |     37.055 |     0.4
   18 |   1.0136 |     34.557 |   1.0808 |     36.101 |     0.5
   19 |   0.9826 |     33.202 |   1.0688 |     35.464 |     0.5
   20 |   0.9503 |     31.901 |   1.0557 |     35.146 |     0.5
   21 |   0.9165 |     30.771 |   1.0446 |     34.637 |     0.5
   22 |   0.8834 |     29.169 |   1.0238 |     33.365 |     0.6
   23 |   0.8464 |     27.633 |   1.0082 |     32.729 |     0.6
   24 |   0.8130 |     26.339 |   0.9912 |     32.125 |     0.6
   25 |   0.7769 |     24.868 |   0.9987 |     32.220 |     0.6
   26 |   0.7434 |     23.859 |   0.9844 |     31.202 |     0.7
   27 |   0.7079 |     22.553 |   0.9817 |     30.725 |     0.7
   28 |   0.6813 |     21.708 |   0.9655 |     30.884 |     0.7
   29 |   0.6445 |     20.200 |   0.9652 |     30.280 |     0.8
   30 |   0.6096 |     18.932 |   0.9634 |     29.676 |     0.8
   31 |   0.5839 |     18.159 |   0.9668 |     29.421 |     0.8
   32 |   0.5600 |     17.270 |   0.9623 |     29.580 |     0.8
   33 |   0.5372 |     16.425 |   0.9498 |     28.499 |     0.9
   34 |   0.5056 |     15.476 |   0.9505 |     28.244 |     0.9
   35 |   0.4777 |     14.302 |   0.9682 |     28.244 |     0.9
   36 |   0.4620 |     14.121 |   0.9963 |     28.467 |     0.9
   37 |   0.4458 |     13.386 |   0.9860 |     27.831 |     1.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 2,054,498

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1712 |     59.019 |   1.5686 |     45.802 |     0.1
    2 |   1.4668 |     46.302 |   1.4118 |     45.802 |     0.2
    3 |   1.3998 |     46.198 |   1.3706 |     45.611 |     0.2
    4 |   1.3705 |     46.012 |   1.3467 |     45.547 |     0.3
    5 |   1.3406 |     45.809 |   1.3237 |     45.102 |     0.4
    6 |   1.3154 |     45.353 |   1.2986 |     45.324 |     0.5
    7 |   1.2930 |     44.914 |   1.2813 |     44.784 |     0.6
    8 |   1.2701 |     44.234 |   1.2552 |     43.861 |     0.6
    9 |   1.2498 |     43.960 |   1.2388 |     43.607 |     0.7
   10 |   1.2330 |     43.362 |   1.2217 |     43.193 |     0.8
   11 |   1.2162 |     42.896 |   1.2135 |     43.352 |     0.9
   12 |   1.1970 |     42.363 |   1.1942 |     42.207 |     1.0
   13 |   1.1778 |     41.935 |   1.1702 |     41.349 |     1.0
   14 |   1.1530 |     40.893 |   1.1586 |     40.744 |     1.1
   15 |   1.1350 |     40.334 |   1.1365 |     39.249 |     1.2
   16 |   1.1140 |     39.686 |   1.1257 |     39.377 |     1.3
   17 |   1.1018 |     39.160 |   1.1083 |     38.868 |     1.4
   18 |   1.0744 |     37.843 |   1.1026 |     39.345 |     1.4
   19 |   1.0591 |     37.580 |   1.1067 |     38.613 |     1.5
   20 |   1.0519 |     37.596 |   1.0766 |     37.786 |     1.6
   21 |   1.0322 |     36.674 |   1.0629 |     37.373 |     1.7
   22 |   1.0054 |     35.665 |   1.0475 |     36.228 |     1.8
   23 |   0.9903 |     34.919 |   1.0335 |     36.164 |     1.8
   24 |   0.9667 |     34.003 |   1.0258 |     35.178 |     1.9
   25 |   0.9466 |     33.043 |   1.0097 |     34.128 |     2.0
   26 |   0.9228 |     32.022 |   0.9941 |     34.224 |     2.1
   27 |   0.8999 |     31.402 |   0.9792 |     34.383 |     2.2
   28 |   0.8779 |     30.278 |   0.9619 |     32.856 |     2.2
   29 |   0.8504 |     29.312 |   0.9590 |     33.047 |     2.3
   30 |   0.8221 |     28.242 |   0.9614 |     31.934 |     2.4
   31 |   0.8006 |     27.304 |   0.9473 |     31.393 |     2.5
   32 |   0.7706 |     26.059 |   0.9289 |     30.789 |     2.6
   33 |   0.7862 |     26.843 |   0.9213 |     30.121 |     2.6
   34 |   0.7395 |     24.896 |   0.9411 |     30.280 |     2.7
   35 |   0.7246 |     24.594 |   0.9298 |     30.439 |     2.8
   36 |   0.6987 |     22.954 |   0.9099 |     29.198 |     2.9
   37 |   0.6648 |     22.268 |   0.9134 |     28.626 |     3.0
   38 |   0.6329 |     20.803 |   0.9236 |     29.230 |     3.0
   39 |   0.6242 |     20.600 |   0.9193 |     29.453 |     3.1
   40 |   0.6040 |     19.849 |   0.8958 |     27.863 |     3.2
   41 |   0.5737 |     18.697 |   0.9030 |     27.767 |     3.3
   42 |   0.5465 |     18.055 |   0.8895 |     26.908 |     3.4
   43 |   0.5237 |     17.100 |   0.9160 |     27.576 |     3.4
   44 |   0.5039 |     16.458 |   0.9143 |     27.195 |     3.5
   45 |   0.4854 |     15.860 |   0.9296 |     26.877 |     3.6
   46 |   0.4916 |     16.184 |   0.9298 |     26.304 |     3.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,426,658

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0931 |     57.664 |   1.5451 |     45.802 |     0.1
    2 |   1.4491 |     46.319 |   1.3891 |     46.533 |     0.1
    3 |   1.3631 |     45.864 |   1.3269 |     45.038 |     0.2
    4 |   1.3202 |     44.920 |   1.2958 |     44.338 |     0.2
    5 |   1.2906 |     44.196 |   1.2711 |     44.275 |     0.3
    6 |   1.2639 |     43.631 |   1.2464 |     44.593 |     0.4
    7 |   1.2415 |     43.461 |   1.2336 |     44.052 |     0.4
    8 |   1.2219 |     43.110 |   1.2207 |     42.939 |     0.5
    9 |   1.2030 |     42.413 |   1.1879 |     41.508 |     0.5
   10 |   1.1857 |     41.661 |   1.1787 |     41.094 |     0.6
   11 |   1.1700 |     41.365 |   1.1640 |     41.190 |     0.7
   12 |   1.1526 |     40.904 |   1.1480 |     40.840 |     0.7
   13 |   1.1344 |     40.048 |   1.1356 |     39.567 |     0.8
   14 |   1.1146 |     39.467 |   1.1294 |     39.631 |     0.8
   15 |   1.0978 |     38.968 |   1.1123 |     38.995 |     0.9
   16 |   1.0792 |     37.958 |   1.0861 |     37.691 |     1.0
   17 |   1.0675 |     37.448 |   1.0839 |     39.408 |     1.0
   18 |   1.0469 |     37.168 |   1.0686 |     37.436 |     1.1
   19 |   1.0249 |     36.203 |   1.0532 |     36.323 |     1.1
   20 |   1.0085 |     35.637 |   1.0407 |     35.719 |     1.2
   21 |   0.9911 |     34.957 |   1.0336 |     35.814 |     1.3
   22 |   0.9729 |     34.277 |   1.0351 |     35.210 |     1.3
   23 |   0.9603 |     33.624 |   1.0184 |     34.860 |     1.4
   24 |   0.9423 |     32.905 |   1.0038 |     34.288 |     1.4
   25 |   0.9200 |     32.181 |   1.0032 |     34.606 |     1.5
   26 |   0.9009 |     31.062 |   0.9835 |     33.429 |     1.6
   27 |   0.8807 |     30.574 |   0.9831 |     33.174 |     1.6
   28 |   0.8661 |     30.108 |   0.9662 |     31.934 |     1.7
   29 |   0.8492 |     29.471 |   0.9589 |     32.475 |     1.7
   30 |   0.8297 |     28.665 |   0.9513 |     31.552 |     1.8
   31 |   0.8171 |     28.072 |   0.9524 |     32.888 |     1.8
   32 |   0.7866 |     26.723 |   0.9382 |     31.043 |     1.9
   33 |   0.7654 |     25.828 |   0.9386 |     31.075 |     2.0
   34 |   0.7480 |     25.269 |   0.9119 |     30.439 |     2.0
   35 |   0.7248 |     24.402 |   0.9139 |     29.676 |     2.1
   36 |   0.7083 |     23.716 |   0.9173 |     29.962 |     2.1
   37 |   0.6896 |     22.849 |   0.9134 |     29.707 |     2.2
   38 |   0.6672 |     22.038 |   0.9063 |     29.739 |     2.3
   39 |   0.6369 |     21.138 |   0.9035 |     29.071 |     2.3
   40 |   0.6192 |     20.474 |   0.9184 |     28.976 |     2.4
   41 |   0.6027 |     19.772 |   0.9024 |     28.022 |     2.4
   42 |   0.5883 |     19.591 |   0.9071 |     28.244 |     2.5
   43 |   0.5623 |     18.263 |   0.8822 |     26.845 |     2.6
   44 |   0.5401 |     17.654 |   0.8992 |     27.163 |     2.6
   45 |   0.5184 |     16.974 |   0.9036 |     27.513 |     2.7
   46 |   0.5014 |     16.359 |   0.9110 |     27.799 |     2.7
   47 |   0.4838 |     16.019 |   0.9050 |     26.908 |     2.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,063,746

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2073 |     60.572 |   1.5870 |     45.802 |     0.0
    2 |   1.4705 |     46.171 |   1.4097 |     45.802 |     0.1
    3 |   1.4015 |     46.259 |   1.3811 |     45.802 |     0.1
    4 |   1.3739 |     46.182 |   1.3500 |     45.006 |     0.2
    5 |   1.3385 |     45.567 |   1.3167 |     45.229 |     0.2
    6 |   1.3110 |     45.375 |   1.2982 |     44.911 |     0.2
    7 |   1.2914 |     44.613 |   1.2881 |     45.579 |     0.3
    8 |   1.2770 |     44.525 |   1.2602 |     44.084 |     0.3
    9 |   1.2618 |     44.179 |   1.2606 |     44.084 |     0.3
   10 |   1.2520 |     43.954 |   1.2436 |     44.211 |     0.4
   11 |   1.2403 |     43.971 |   1.2318 |     44.561 |     0.4
   12 |   1.2296 |     43.620 |   1.2291 |     44.020 |     0.5
   13 |   1.2208 |     43.570 |   1.2183 |     43.034 |     0.5
   14 |   1.2104 |     42.835 |   1.2068 |     43.925 |     0.5
   15 |   1.2023 |     42.945 |   1.1934 |     42.080 |     0.6
   16 |   1.1920 |     42.594 |   1.1929 |     42.462 |     0.6
   17 |   1.1816 |     42.045 |   1.1806 |     42.048 |     0.6
   18 |   1.1719 |     42.133 |   1.1771 |     42.494 |     0.7
   19 |   1.1653 |     41.892 |   1.1686 |     41.349 |     0.7
   20 |   1.1560 |     41.453 |   1.1598 |     41.667 |     0.8
   21 |   1.1496 |     41.316 |   1.1587 |     41.794 |     0.8
   22 |   1.1417 |     41.107 |   1.1626 |     41.412 |     0.8
   23 |   1.1375 |     41.178 |   1.1538 |     40.872 |     0.9
   24 |   1.1278 |     40.548 |   1.1376 |     40.999 |     0.9
   25 |   1.1192 |     40.394 |   1.1424 |     41.031 |     1.0
   26 |   1.1177 |     40.246 |   1.1309 |     41.190 |     1.0
   27 |   1.1077 |     40.235 |   1.1319 |     40.840 |     1.0
   28 |   1.0996 |     39.982 |   1.1276 |     40.235 |     1.1
   29 |   1.0925 |     39.659 |   1.1293 |     39.917 |     1.1
   30 |   1.0871 |     39.297 |   1.1174 |     39.536 |     1.1
   31 |   1.0830 |     39.538 |   1.1087 |     39.536 |     1.2
   32 |   1.0763 |     39.154 |   1.1085 |     39.536 |     1.2
   33 |   1.0718 |     39.154 |   1.1037 |     39.313 |     1.3
   34 |   1.0661 |     39.121 |   1.1030 |     39.981 |     1.3
   35 |   1.0648 |     39.209 |   1.0900 |     38.963 |     1.3
   36 |   1.0579 |     38.951 |   1.0904 |     38.804 |     1.4
   37 |   1.0553 |     38.754 |   1.0950 |     38.963 |     1.4
   38 |   1.0511 |     38.457 |   1.0973 |     39.758 |     1.5
   39 |   1.0479 |     38.644 |   1.0895 |     38.613 |     1.5
   40 |   1.0387 |     37.953 |   1.0877 |     39.059 |     1.5
   41 |   1.0390 |     38.413 |   1.0740 |     38.772 |     1.6
   42 |   1.0324 |     37.810 |   1.0699 |     38.454 |     1.6
   43 |   1.0291 |     37.887 |   1.0761 |     37.977 |     1.6
   44 |   1.0230 |     37.530 |   1.0669 |     38.581 |     1.7
   45 |   1.0196 |     37.234 |   1.0739 |     38.104 |     1.7
   46 |   1.0196 |     37.503 |   1.0698 |     39.027 |     1.8
   47 |   1.0132 |     37.250 |   1.0741 |     37.882 |     1.8
   48 |   1.0087 |     37.196 |   1.0629 |     38.709 |     1.8
   49 |   1.0032 |     36.894 |   1.0494 |     37.564 |     1.9
   50 |   1.0005 |     36.510 |   1.0585 |     37.723 |     1.9
   51 |   0.9971 |     36.658 |   1.0515 |     38.200 |     1.9
   52 |   0.9906 |     36.290 |   1.0460 |     37.532 |     2.0
   53 |   0.9874 |     36.148 |   1.0526 |     38.009 |     2.0
   54 |   0.9816 |     35.879 |   1.0448 |     37.436 |     2.1
   55 |   0.9730 |     35.418 |   1.0359 |     36.482 |     2.1
   56 |   0.9732 |     35.528 |   1.0337 |     37.150 |     2.1
   57 |   0.9660 |     35.105 |   1.0403 |     36.101 |     2.2
   58 |   0.9581 |     34.562 |   1.0381 |     36.800 |     2.2
   59 |   0.9570 |     34.897 |   1.0376 |     37.150 |     2.3
   60 |   0.9489 |     34.057 |   1.0291 |     36.005 |     2.3
   61 |   0.9412 |     34.222 |   1.0229 |     35.814 |     2.3
   62 |   0.9359 |     33.514 |   1.0219 |     35.751 |     2.4
   63 |   0.9313 |     33.344 |   1.0214 |     36.482 |     2.4
   64 |   0.9244 |     33.037 |   1.0189 |     35.528 |     2.4
   65 |   0.9191 |     33.114 |   1.0054 |     35.019 |     2.5
   66 |   0.9095 |     32.494 |   1.0132 |     35.560 |     2.5
   67 |   0.9033 |     32.258 |   1.0050 |     35.083 |     2.6
   68 |   0.8967 |     32.039 |   1.0005 |     34.478 |     2.6
   69 |   0.8906 |     31.693 |   1.0065 |     34.924 |     2.6
   70 |   0.8848 |     31.534 |   0.9902 |     34.288 |     2.7
   71 |   0.8761 |     31.254 |   1.0010 |     34.765 |     2.7
   72 |   0.8695 |     30.859 |   1.0021 |     34.574 |     2.8
   73 |   0.8597 |     30.486 |   0.9918 |     33.556 |     2.8
   74 |   0.8530 |     30.289 |   0.9919 |     34.256 |     2.8
   75 |   0.8452 |     29.948 |   0.9750 |     33.270 |     2.9
   76 |   0.8372 |     29.630 |   0.9783 |     33.238 |     2.9
   77 |   0.8310 |     29.477 |   0.9769 |     33.397 |     3.0
   78 |   0.8295 |     29.180 |   0.9861 |     33.938 |     3.0
   79 |   0.8207 |     28.796 |   0.9729 |     32.856 |     3.0
   80 |   0.8165 |     28.851 |   0.9890 |     32.888 |     3.1
   81 |   0.8061 |     28.506 |   0.9798 |     33.111 |     3.1
   82 |   0.8016 |     28.187 |   0.9722 |     32.284 |     3.1
   83 |   0.7902 |     27.622 |   0.9732 |     32.506 |     3.2
   84 |   0.7912 |     27.743 |   0.9687 |     32.252 |     3.2
   85 |   0.7784 |     27.068 |   0.9764 |     32.411 |     3.3
   86 |   0.7736 |     27.046 |   0.9618 |     31.997 |     3.3
   87 |   0.7651 |     26.607 |   0.9648 |     31.934 |     3.3
   88 |   0.7563 |     26.158 |   0.9601 |     31.075 |     3.4
   89 |   0.7513 |     25.785 |   0.9516 |     31.170 |     3.4
   90 |   0.7366 |     25.329 |   0.9561 |     31.870 |     3.5
   91 |   0.7337 |     25.335 |   0.9525 |     31.361 |     3.5
   92 |   0.7271 |     25.154 |   0.9452 |     31.202 |     3.5
   93 |   0.7253 |     25.104 |   0.9442 |     31.170 |     3.6
   94 |   0.7138 |     24.528 |   0.9626 |     31.711 |     3.6
   95 |   0.7031 |     24.095 |   0.9604 |     30.630 |     3.6
   96 |   0.6937 |     23.837 |   0.9368 |     30.725 |     3.7
   97 |   0.6879 |     23.760 |   0.9480 |     31.011 |     3.7
   98 |   0.6764 |     23.321 |   0.9328 |     30.439 |     3.8
   99 |   0.6785 |     23.480 |   0.9492 |     30.852 |     3.8
  100 |   0.6688 |     22.806 |   0.9283 |     30.439 |     3.8
  101 |   0.6547 |     22.345 |   0.9372 |     30.534 |     3.9
  102 |   0.6514 |     22.454 |   0.9501 |     30.471 |     3.9
  103 |   0.6445 |     21.988 |   0.9418 |     29.930 |     4.0
  104 |   0.6395 |     21.840 |   0.9367 |     30.057 |     4.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,495,074

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0442 |     56.024 |   1.5098 |     45.802 |     0.1
    2 |   1.4350 |     46.154 |   1.3737 |     45.802 |     0.1
    3 |   1.3580 |     45.644 |   1.3243 |     44.211 |     0.2
    4 |   1.3134 |     44.476 |   1.2890 |     45.197 |     0.2
    5 |   1.2805 |     43.965 |   1.2595 |     43.225 |     0.3
    6 |   1.2519 |     43.636 |   1.2383 |     43.257 |     0.4
    7 |   1.2334 |     43.208 |   1.2251 |     43.034 |     0.4
    8 |   1.2117 |     42.577 |   1.2059 |     41.889 |     0.5
    9 |   1.1919 |     41.842 |   1.1822 |     42.207 |     0.5
   10 |   1.1730 |     41.327 |   1.1678 |     40.840 |     0.6
   11 |   1.1534 |     40.569 |   1.1539 |     39.790 |     0.7
   12 |   1.1332 |     39.697 |   1.1419 |     40.522 |     0.7
   13 |   1.1160 |     39.192 |   1.1221 |     39.186 |     0.8
   14 |   1.0967 |     38.616 |   1.1033 |     37.945 |     0.9
   15 |   1.0761 |     37.601 |   1.1017 |     38.359 |     0.9
   16 |   1.0599 |     36.982 |   1.0796 |     37.055 |     1.0
   17 |   1.0337 |     35.840 |   1.0640 |     36.641 |     1.0
   18 |   1.0164 |     35.319 |   1.0606 |     36.641 |     1.1
   19 |   0.9961 |     34.705 |   1.0412 |     35.878 |     1.2
   20 |   0.9748 |     33.865 |   1.0306 |     34.796 |     1.2
   21 |   0.9571 |     32.873 |   1.0124 |     34.033 |     1.3
   22 |   0.9320 |     31.847 |   0.9996 |     33.333 |     1.3
   23 |   0.9174 |     31.342 |   0.9946 |     33.620 |     1.4
   24 |   0.8929 |     30.678 |   0.9736 |     33.079 |     1.5
   25 |   0.8701 |     29.416 |   0.9681 |     32.665 |     1.5
   26 |   0.8476 |     29.049 |   0.9522 |     32.347 |     1.6
   27 |   0.8249 |     28.072 |   0.9450 |     31.425 |     1.6
   28 |   0.8042 |     27.244 |   0.9435 |     31.489 |     1.7
   29 |   0.7856 |     26.487 |   0.9518 |     31.711 |     1.8
   30 |   0.7573 |     25.560 |   0.9351 |     30.503 |     1.8
   31 |   0.7390 |     24.759 |   0.9327 |     30.216 |     1.9
   32 |   0.7188 |     23.947 |   0.9277 |     30.153 |     1.9
   33 |   0.6950 |     22.948 |   0.9377 |     30.757 |     2.0
   34 |   0.6733 |     22.498 |   0.9216 |     29.739 |     2.1
   35 |   0.6544 |     21.922 |   0.9169 |     29.644 |     2.1
   36 |   0.6298 |     20.891 |   0.9301 |     29.517 |     2.2
   37 |   0.6161 |     20.392 |   0.9245 |     28.690 |     2.2
   38 |   0.5893 |     19.448 |   0.9122 |     27.894 |     2.3
   39 |   0.5676 |     18.773 |   0.9423 |     28.690 |     2.4
   40 |   0.5579 |     18.159 |   0.9432 |     28.435 |     2.4
   41 |   0.5545 |     18.181 |   0.9442 |     28.531 |     2.5
   42 |   0.5265 |     17.380 |   0.9430 |     28.721 |     2.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 850,754

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2185 |     61.005 |   1.6218 |     48.919 |     0.0
    2 |   1.4864 |     46.297 |   1.4134 |     45.802 |     0.1
    3 |   1.3975 |     46.138 |   1.3675 |     45.770 |     0.1
    4 |   1.3628 |     45.820 |   1.3425 |     45.483 |     0.1
    5 |   1.3344 |     45.611 |   1.3232 |     45.547 |     0.2
    6 |   1.3126 |     45.337 |   1.3083 |     45.070 |     0.2
    7 |   1.2944 |     44.585 |   1.2819 |     44.911 |     0.2
    8 |   1.2775 |     44.366 |   1.2670 |     44.784 |     0.3
    9 |   1.2652 |     44.377 |   1.2709 |     44.275 |     0.3
   10 |   1.2514 |     43.938 |   1.2447 |     43.861 |     0.3
   11 |   1.2324 |     43.713 |   1.2240 |     43.416 |     0.4
   12 |   1.2149 |     43.170 |   1.2018 |     42.684 |     0.4
   13 |   1.1978 |     42.786 |   1.1895 |     42.525 |     0.4
   14 |   1.1818 |     42.007 |   1.1782 |     41.031 |     0.4
   15 |   1.1677 |     41.864 |   1.1724 |     41.667 |     0.5
   16 |   1.1502 |     41.283 |   1.1552 |     41.317 |     0.5
   17 |   1.1278 |     40.279 |   1.1358 |     40.076 |     0.5
   18 |   1.1096 |     39.719 |   1.1251 |     40.267 |     0.6
   19 |   1.0867 |     38.929 |   1.1104 |     39.377 |     0.6
   20 |   1.0606 |     38.035 |   1.1077 |     39.313 |     0.6
   21 |   1.0429 |     37.382 |   1.0907 |     38.327 |     0.7
   22 |   1.0149 |     35.895 |   1.0819 |     38.486 |     0.7
   23 |   0.9979 |     35.226 |   1.0510 |     37.246 |     0.7
   24 |   0.9680 |     33.569 |   1.0509 |     35.941 |     0.8
   25 |   0.9398 |     32.659 |   1.0513 |     36.991 |     0.8
   26 |   0.9156 |     31.622 |   1.0277 |     34.733 |     0.8
   27 |   0.8853 |     30.118 |   1.0154 |     34.128 |     0.9
   28 |   0.8619 |     29.488 |   1.0082 |     34.510 |     0.9
   29 |   0.8345 |     27.902 |   1.0024 |     32.824 |     0.9
   30 |   0.8088 |     27.315 |   0.9997 |     32.793 |     1.0
   31 |   0.7776 |     25.955 |   0.9989 |     32.665 |     1.0
   32 |   0.7476 |     24.868 |   0.9832 |     31.966 |     1.0
   33 |   0.7194 |     23.947 |   0.9837 |     31.330 |     1.0
   34 |   0.6938 |     22.734 |   1.0042 |     31.425 |     1.1
   35 |   0.6676 |     21.878 |   0.9834 |     29.962 |     1.1
   36 |   0.6357 |     20.518 |   0.9813 |     29.485 |     1.1
   37 |   0.6059 |     19.481 |   0.9782 |     29.676 |     1.2
   38 |   0.5791 |     18.488 |   0.9765 |     28.944 |     1.2
   39 |   0.5618 |     18.011 |   0.9957 |     29.198 |     1.2
   40 |   0.5374 |     17.149 |   0.9761 |     27.735 |     1.3
   41 |   0.5078 |     16.228 |   0.9989 |     28.308 |     1.3
   42 |   0.4839 |     15.405 |   1.0034 |     28.372 |     1.3
   43 |   0.4558 |     14.275 |   1.0030 |     27.926 |     1.4
   44 |   0.4300 |     13.633 |   1.0211 |     28.499 |     1.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 931,650

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1061 |     57.423 |   1.5198 |     45.642 |     0.0
    2 |   1.4212 |     45.973 |   1.3529 |     45.897 |     0.1
    3 |   1.3339 |     45.117 |   1.3098 |     45.102 |     0.1
    4 |   1.2990 |     44.344 |   1.2790 |     44.052 |     0.2
    5 |   1.2737 |     44.157 |   1.2538 |     43.702 |     0.2
    6 |   1.2473 |     43.647 |   1.2431 |     43.352 |     0.2
    7 |   1.2244 |     43.192 |   1.2150 |     42.557 |     0.3
    8 |   1.1990 |     42.539 |   1.2015 |     43.034 |     0.3
    9 |   1.1782 |     41.705 |   1.1747 |     40.840 |     0.3
   10 |   1.1571 |     41.200 |   1.1596 |     40.458 |     0.4
   11 |   1.1421 |     40.213 |   1.1445 |     40.553 |     0.4
   12 |   1.1200 |     39.598 |   1.1235 |     39.567 |     0.5
   13 |   1.1013 |     38.869 |   1.1157 |     38.995 |     0.5
   14 |   1.0815 |     38.370 |   1.1001 |     38.200 |     0.5
   15 |   1.0695 |     37.980 |   1.0905 |     39.313 |     0.6
   16 |   1.0474 |     36.987 |   1.0827 |     38.359 |     0.6
   17 |   1.0297 |     36.208 |   1.0533 |     36.673 |     0.6
   18 |   1.0112 |     35.221 |   1.0509 |     36.959 |     0.7
   19 |   0.9956 |     35.029 |   1.0496 |     35.401 |     0.7
   20 |   0.9747 |     34.184 |   1.0302 |     35.401 |     0.8
   21 |   0.9693 |     34.173 |   1.0272 |     35.814 |     0.8
   22 |   0.9450 |     33.065 |   1.0191 |     34.733 |     0.8
   23 |   0.9298 |     32.631 |   1.0028 |     34.319 |     0.9
   24 |   0.9146 |     32.061 |   0.9918 |     33.779 |     0.9
   25 |   0.8965 |     31.397 |   0.9844 |     33.779 |     1.0
   26 |   0.8710 |     30.190 |   0.9822 |     33.492 |     1.0
   27 |   0.8519 |     29.652 |   0.9694 |     32.856 |     1.0
   28 |   0.8410 |     29.049 |   0.9585 |     32.570 |     1.1
   29 |   0.8115 |     27.644 |   0.9557 |     31.298 |     1.1
   30 |   0.7928 |     26.832 |   0.9421 |     30.852 |     1.1
   31 |   0.7678 |     26.141 |   0.9293 |     30.821 |     1.2
   32 |   0.7504 |     25.461 |   0.9227 |     29.835 |     1.2
   33 |   0.7204 |     24.369 |   0.9168 |     31.043 |     1.3
   34 |   0.7121 |     24.259 |   0.9197 |     29.485 |     1.3
   35 |   0.7012 |     23.645 |   0.9079 |     29.389 |     1.3
   36 |   0.6608 |     21.911 |   0.9107 |     29.135 |     1.4
   37 |   0.6330 |     20.853 |   0.9251 |     29.039 |     1.4
   38 |   0.6134 |     20.233 |   0.9029 |     28.149 |     1.5
   39 |   0.5818 |     18.943 |   0.9149 |     28.181 |     1.5
   40 |   0.5657 |     18.494 |   0.9180 |     28.658 |     1.5
   41 |   0.5410 |     17.736 |   0.9167 |     27.481 |     1.6
   42 |   0.5130 |     16.464 |   0.9250 |     27.831 |     1.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 785,122

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4517 |     64.511 |   1.9108 |     50.191 |     0.0
    2 |   1.7167 |     49.402 |   1.5383 |     45.802 |     0.1
    3 |   1.4847 |     46.121 |   1.4285 |     45.802 |     0.1
    4 |   1.4211 |     46.072 |   1.3915 |     45.802 |     0.2
    5 |   1.3919 |     45.990 |   1.3628 |     45.674 |     0.2
    6 |   1.3602 |     45.885 |   1.3326 |     45.070 |     0.2
    7 |   1.3376 |     45.611 |   1.3133 |     44.307 |     0.3
    8 |   1.3191 |     45.024 |   1.3035 |     44.307 |     0.3
    9 |   1.3030 |     44.607 |   1.2898 |     44.370 |     0.4
   10 |   1.2921 |     44.717 |   1.2720 |     44.148 |     0.4
   11 |   1.2744 |     44.179 |   1.2599 |     44.275 |     0.4
   12 |   1.2564 |     43.839 |   1.2544 |     43.861 |     0.5
   13 |   1.2412 |     43.384 |   1.2317 |     43.257 |     0.5
   14 |   1.2278 |     43.269 |   1.2261 |     43.193 |     0.6
   15 |   1.2154 |     42.786 |   1.2080 |     43.066 |     0.6
   16 |   1.1969 |     42.095 |   1.1931 |     41.921 |     0.6
   17 |   1.1805 |     41.420 |   1.1863 |     41.031 |     0.7
   18 |   1.1695 |     41.135 |   1.1640 |     40.522 |     0.7
   19 |   1.1515 |     40.602 |   1.1572 |     40.267 |     0.8
   20 |   1.1381 |     39.758 |   1.1488 |     39.599 |     0.8
   21 |   1.1236 |     39.461 |   1.1403 |     40.140 |     0.8
   22 |   1.1104 |     38.995 |   1.1238 |     38.868 |     0.9
   23 |   1.0918 |     38.260 |   1.1102 |     38.486 |     0.9
   24 |   1.0730 |     37.404 |   1.1020 |     38.740 |     1.0
   25 |   1.0585 |     36.927 |   1.0895 |     37.882 |     1.0
   26 |   1.0414 |     36.427 |   1.0852 |     37.214 |     1.0
   27 |   1.0209 |     35.495 |   1.0814 |     37.468 |     1.1
   28 |   1.0080 |     35.347 |   1.0634 |     36.768 |     1.1
   29 |   0.9820 |     34.255 |   1.0533 |     36.005 |     1.2
   30 |   0.9729 |     33.964 |   1.0423 |     35.305 |     1.2
   31 |   0.9499 |     33.086 |   1.0341 |     34.669 |     1.2
   32 |   0.9339 |     32.521 |   1.0253 |     34.733 |     1.3
   33 |   0.9158 |     31.512 |   1.0268 |     34.160 |     1.3
   34 |   0.9007 |     31.309 |   1.0237 |     34.256 |     1.4
   35 |   0.8896 |     30.733 |   1.0244 |     34.319 |     1.4
   36 |   0.8715 |     30.058 |   1.0093 |     33.874 |     1.4
   37 |   0.8673 |     30.179 |   1.0187 |     34.383 |     1.5
   38 |   0.8433 |     29.186 |   1.0067 |     33.333 |     1.5
   39 |   0.8158 |     28.204 |   1.0139 |     33.238 |     1.6
   40 |   0.8064 |     27.705 |   1.0027 |     32.697 |     1.6
   41 |   0.7863 |     26.794 |   0.9990 |     31.838 |     1.6
   42 |   0.7709 |     26.339 |   0.9974 |     31.489 |     1.7
   43 |   0.7488 |     25.532 |   0.9964 |     31.234 |     1.7
   44 |   0.7357 |     24.709 |   0.9892 |     31.075 |     1.8
   45 |   0.7242 |     24.380 |   1.0124 |     30.916 |     1.8
   46 |   0.7060 |     23.683 |   0.9994 |     30.280 |     1.8
   47 |   0.6964 |     23.694 |   1.0125 |     30.630 |     1.9
   48 |   0.6912 |     23.294 |   1.0051 |     30.312 |     1.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 853,538

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5231 |     67.808 |   1.9621 |     55.121 |     0.0
    2 |   1.7503 |     49.358 |   1.5639 |     45.802 |     0.1
    3 |   1.4971 |     46.143 |   1.4463 |     45.802 |     0.1
    4 |   1.4337 |     46.226 |   1.4088 |     45.802 |     0.2
    5 |   1.4077 |     46.132 |   1.3860 |     45.802 |     0.2
    6 |   1.3891 |     46.105 |   1.3667 |     45.802 |     0.2
    7 |   1.3686 |     46.050 |   1.3524 |     45.802 |     0.3
    8 |   1.3483 |     45.748 |   1.3342 |     45.770 |     0.3
    9 |   1.3278 |     45.298 |   1.3123 |     45.897 |     0.3
   10 |   1.3069 |     44.909 |   1.2960 |     44.179 |     0.4
   11 |   1.2913 |     44.157 |   1.2757 |     44.020 |     0.4
   12 |   1.2717 |     43.746 |   1.2602 |     43.575 |     0.5
   13 |   1.2532 |     43.483 |   1.2417 |     43.130 |     0.5
   14 |   1.2348 |     42.709 |   1.2203 |     42.398 |     0.5
   15 |   1.2169 |     42.347 |   1.2107 |     41.762 |     0.6
   16 |   1.1988 |     41.584 |   1.1982 |     41.571 |     0.6
   17 |   1.1784 |     40.959 |   1.1728 |     40.999 |     0.7
   18 |   1.1586 |     40.334 |   1.1627 |     40.681 |     0.7
   19 |   1.1376 |     39.582 |   1.1480 |     39.854 |     0.7
   20 |   1.1163 |     38.830 |   1.1371 |     39.440 |     0.8
   21 |   1.0929 |     37.991 |   1.1286 |     39.059 |     0.8
   22 |   1.0722 |     37.322 |   1.1035 |     37.754 |     0.9
   23 |   1.0484 |     36.285 |   1.1124 |     38.168 |     0.9
   24 |   1.0248 |     35.473 |   1.0973 |     38.295 |     0.9
   25 |   1.0020 |     34.617 |   1.0849 |     37.309 |     1.0
   26 |   0.9733 |     33.224 |   1.0770 |     37.087 |     1.0
   27 |   0.9513 |     32.373 |   1.0776 |     35.623 |     1.1
   28 |   0.9231 |     31.298 |   1.0765 |     37.214 |     1.1
   29 |   0.9031 |     30.437 |   1.0703 |     35.878 |     1.1
   30 |   0.8735 |     29.290 |   1.0850 |     34.955 |     1.2
   31 |   0.8467 |     27.897 |   1.0730 |     35.051 |     1.2
   32 |   0.8236 |     27.321 |   1.0814 |     34.765 |     1.2
   33 |   0.8006 |     26.273 |   1.0895 |     34.574 |     1.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,662,114

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2108 |     60.522 |   1.6151 |     45.802 |     0.1
    2 |   1.4865 |     46.237 |   1.4147 |     45.802 |     0.1
    3 |   1.4088 |     46.259 |   1.3880 |     46.533 |     0.2
    4 |   1.3778 |     45.940 |   1.3502 |     45.770 |     0.2
    5 |   1.3467 |     45.628 |   1.3182 |     44.879 |     0.3
    6 |   1.3151 |     45.485 |   1.2977 |     45.388 |     0.4
    7 |   1.2893 |     45.095 |   1.2695 |     44.434 |     0.4
    8 |   1.2618 |     44.135 |   1.2409 |     43.257 |     0.5
    9 |   1.2368 |     43.417 |   1.2230 |     43.511 |     0.6
   10 |   1.2117 |     42.731 |   1.2036 |     42.430 |     0.6
   11 |   1.1868 |     41.601 |   1.1848 |     41.539 |     0.7
   12 |   1.1580 |     40.827 |   1.1570 |     41.094 |     0.7
   13 |   1.1292 |     39.873 |   1.1457 |     40.108 |     0.8
   14 |   1.1087 |     38.978 |   1.1291 |     39.377 |     0.9
   15 |   1.0822 |     37.892 |   1.1113 |     37.659 |     0.9
   16 |   1.0590 |     37.316 |   1.0904 |     37.500 |     1.0
   17 |   1.0304 |     36.131 |   1.0779 |     37.564 |     1.0
   18 |   1.0055 |     35.253 |   1.0653 |     37.214 |     1.1
   19 |   0.9842 |     34.551 |   1.0422 |     35.464 |     1.2
   20 |   0.9557 |     33.097 |   1.0250 |     35.274 |     1.2
   21 |   0.9256 |     31.934 |   1.0113 |     33.333 |     1.3
   22 |   0.8964 |     30.903 |   0.9998 |     33.047 |     1.4
   23 |   0.8742 |     30.151 |   1.0138 |     33.969 |     1.4
   24 |   0.8408 |     28.604 |   0.9872 |     32.538 |     1.5
   25 |   0.8185 |     27.474 |   0.9854 |     32.093 |     1.5
   26 |   0.7787 |     25.944 |   0.9884 |     31.870 |     1.6
   27 |   0.7575 |     25.049 |   0.9625 |     30.375 |     1.7
   28 |   0.7210 |     23.618 |   0.9625 |     30.630 |     1.7
   29 |   0.6939 |     22.838 |   0.9567 |     29.962 |     1.8
   30 |   0.6570 |     21.374 |   0.9561 |     29.485 |     1.8
   31 |   0.6382 |     20.765 |   0.9511 |     28.976 |     1.9
   32 |   0.6079 |     19.700 |   0.9516 |     28.976 |     2.0
   33 |   0.5777 |     18.439 |   0.9670 |     28.499 |     2.0
   34 |   0.5477 |     17.687 |   0.9837 |     28.244 |     2.1
   35 |   0.5187 |     16.398 |   0.9731 |     27.608 |     2.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,588,418

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5166 |     67.682 |   1.9855 |     54.230 |     0.1
    2 |   1.7552 |     49.698 |   1.5511 |     45.802 |     0.2
    3 |   1.4903 |     46.143 |   1.4409 |     45.802 |     0.2
    4 |   1.4315 |     46.160 |   1.4058 |     45.802 |     0.3
    5 |   1.4056 |     46.242 |   1.3860 |     45.802 |     0.4
    6 |   1.3890 |     46.045 |   1.3686 |     45.642 |     0.5
    7 |   1.3700 |     46.017 |   1.3512 |     44.720 |     0.6
    8 |   1.3469 |     45.737 |   1.3264 |     45.579 |     0.6
    9 |   1.3248 |     45.458 |   1.3118 |     45.452 |     0.7
   10 |   1.3098 |     45.255 |   1.2998 |     45.197 |     0.8
   11 |   1.2998 |     45.101 |   1.2853 |     44.720 |     0.9
   12 |   1.2882 |     44.755 |   1.2787 |     44.816 |     1.0
   13 |   1.2726 |     44.333 |   1.2616 |     44.879 |     1.0
   14 |   1.2548 |     44.070 |   1.2456 |     43.861 |     1.1
   15 |   1.2399 |     43.362 |   1.2261 |     42.494 |     1.2
   16 |   1.2223 |     42.841 |   1.2162 |     42.398 |     1.3
   17 |   1.2070 |     42.566 |   1.2042 |     41.794 |     1.4
   18 |   1.1932 |     41.732 |   1.1934 |     42.144 |     1.4
   19 |   1.1778 |     41.288 |   1.1858 |     40.808 |     1.5
   20 |   1.1659 |     40.822 |   1.1723 |     40.394 |     1.6
   21 |   1.1515 |     40.284 |   1.1587 |     40.363 |     1.7
   22 |   1.1396 |     39.966 |   1.1504 |     39.949 |     1.8
   23 |   1.1241 |     39.472 |   1.1555 |     40.458 |     1.8
   24 |   1.1119 |     39.028 |   1.1437 |     39.663 |     1.9
   25 |   1.1003 |     38.682 |   1.1310 |     39.504 |     2.0
   26 |   1.0882 |     38.600 |   1.1156 |     38.836 |     2.1
   27 |   1.0735 |     37.645 |   1.1095 |     38.359 |     2.2
   28 |   1.0599 |     37.201 |   1.1054 |     38.327 |     2.2
   29 |   1.0477 |     36.603 |   1.1018 |     38.581 |     2.3
   30 |   1.0386 |     36.312 |   1.0960 |     37.532 |     2.4
   31 |   1.0284 |     35.714 |   1.1000 |     37.691 |     2.5
   32 |   1.0130 |     35.391 |   1.0794 |     37.246 |     2.5
   33 |   0.9949 |     34.650 |   1.0847 |     37.246 |     2.6
   34 |   0.9815 |     33.975 |   1.0728 |     37.023 |     2.7
   35 |   0.9692 |     33.520 |   1.0709 |     37.214 |     2.8
   36 |   0.9523 |     32.702 |   1.0507 |     35.687 |     2.9
   37 |   0.9354 |     32.099 |   1.0568 |     36.005 |     2.9
   38 |   0.9352 |     32.083 |   1.0399 |     35.719 |     3.0
   39 |   0.9082 |     30.941 |   1.0264 |     34.001 |     3.1
   40 |   0.8824 |     29.773 |   1.0307 |     34.796 |     3.2
   41 |   0.8631 |     28.999 |   1.0205 |     34.097 |     3.3
   42 |   0.8505 |     28.621 |   1.0272 |     33.302 |     3.3
   43 |   0.8340 |     27.858 |   1.0056 |     31.934 |     3.4
   44 |   0.8049 |     26.750 |   1.0015 |     33.015 |     3.5
   45 |   0.7909 |     26.196 |   1.0128 |     33.047 |     3.6
   46 |   0.7646 |     25.296 |   0.9937 |     31.457 |     3.7
   47 |   0.7440 |     24.287 |   0.9907 |     30.916 |     3.7
   48 |   0.7297 |     23.853 |   0.9901 |     31.139 |     3.8
   49 |   0.7054 |     22.987 |   0.9929 |     30.725 |     3.9
   50 |   0.6904 |     22.679 |   0.9947 |     30.344 |     4.0
   51 |   0.6653 |     21.434 |   1.0105 |     30.693 |     4.1
   52 |   0.6465 |     20.814 |   0.9942 |     29.676 |     4.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 406,754

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3435 |     61.329 |   1.7899 |     48.601 |     0.0
    2 |   1.5985 |     47.103 |   1.4633 |     45.420 |     0.1
    3 |   1.4247 |     45.847 |   1.3820 |     45.420 |     0.1
    4 |   1.3611 |     45.282 |   1.3328 |     44.370 |     0.1
    5 |   1.3173 |     44.481 |   1.2869 |     44.148 |     0.1
    6 |   1.2867 |     44.031 |   1.2631 |     43.861 |     0.2
    7 |   1.2633 |     43.735 |   1.2447 |     43.543 |     0.2
    8 |   1.2430 |     43.285 |   1.2232 |     42.812 |     0.2
    9 |   1.2239 |     42.687 |   1.2073 |     42.462 |     0.2
   10 |   1.2085 |     42.182 |   1.1889 |     42.207 |     0.3
   11 |   1.1911 |     41.628 |   1.1830 |     41.349 |     0.3
   12 |   1.1763 |     41.052 |   1.1702 |     40.681 |     0.3
   13 |   1.1614 |     40.734 |   1.1565 |     40.299 |     0.3
   14 |   1.1476 |     40.103 |   1.1448 |     39.917 |     0.4
   15 |   1.1310 |     39.620 |   1.1421 |     40.522 |     0.4
   16 |   1.1180 |     39.127 |   1.1265 |     39.122 |     0.4
   17 |   1.1018 |     38.402 |   1.1171 |     38.709 |     0.4
   18 |   1.0895 |     37.876 |   1.1079 |     38.645 |     0.5
   19 |   1.0752 |     37.388 |   1.1071 |     39.059 |     0.5
   20 |   1.0666 |     36.987 |   1.0945 |     38.422 |     0.5
   21 |   1.0518 |     36.663 |   1.0849 |     37.246 |     0.5
   22 |   1.0370 |     36.011 |   1.0791 |     37.277 |     0.6
   23 |   1.0202 |     35.018 |   1.0692 |     36.578 |     0.6
   24 |   1.0058 |     35.007 |   1.0704 |     36.896 |     0.6
   25 |   0.9927 |     34.030 |   1.0493 |     35.655 |     0.6
   26 |   0.9734 |     33.339 |   1.0445 |     35.115 |     0.7
   27 |   0.9537 |     32.395 |   1.0344 |     34.733 |     0.7
   28 |   0.9380 |     31.841 |   1.0208 |     34.478 |     0.7
   29 |   0.9231 |     31.402 |   1.0057 |     33.333 |     0.7
   30 |   0.9028 |     30.475 |   1.0023 |     32.602 |     0.8
   31 |   0.8892 |     30.239 |   0.9874 |     32.093 |     0.8
   32 |   0.8675 |     29.301 |   0.9883 |     32.983 |     0.8
   33 |   0.8565 |     28.912 |   0.9773 |     31.838 |     0.8
   34 |   0.8360 |     27.864 |   0.9751 |     32.188 |     0.9
   35 |   0.8215 |     27.425 |   0.9683 |     31.330 |     0.9
   36 |   0.8002 |     26.580 |   0.9671 |     31.107 |     0.9
   37 |   0.7861 |     26.196 |   0.9672 |     31.202 |     0.9
   38 |   0.7670 |     25.154 |   0.9495 |     30.153 |     1.0
   39 |   0.7521 |     24.835 |   0.9538 |     30.662 |     1.0
   40 |   0.7358 |     24.034 |   0.9567 |     30.439 |     1.0
   41 |   0.7192 |     23.469 |   0.9487 |     29.994 |     1.0
   42 |   0.7027 |     22.828 |   0.9582 |     30.121 |     1.1
   43 |   0.7024 |     22.657 |   0.9449 |     29.771 |     1.1
   44 |   0.6738 |     21.988 |   0.9522 |     29.580 |     1.1
   45 |   0.6555 |     21.379 |   0.9532 |     29.071 |     1.1
   46 |   0.6364 |     20.633 |   0.9685 |     29.135 |     1.2
   47 |   0.6252 |     20.106 |   0.9819 |     29.835 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 885,698

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2136 |     60.605 |   1.6162 |     48.919 |     0.0
    2 |   1.4820 |     46.215 |   1.4036 |     45.802 |     0.1
    3 |   1.3861 |     45.957 |   1.3576 |     45.770 |     0.1
    4 |   1.3492 |     45.545 |   1.3338 |     45.579 |     0.1
    5 |   1.3205 |     45.260 |   1.2991 |     44.466 |     0.2
    6 |   1.2970 |     44.975 |   1.2790 |     44.148 |     0.2
    7 |   1.2775 |     44.635 |   1.2607 |     43.734 |     0.2
    8 |   1.2553 |     44.135 |   1.2353 |     44.179 |     0.3
    9 |   1.2348 |     43.856 |   1.2141 |     42.303 |     0.3
   10 |   1.2196 |     43.192 |   1.2037 |     42.176 |     0.3
   11 |   1.2025 |     42.440 |   1.1924 |     42.748 |     0.4
   12 |   1.1876 |     41.935 |   1.1835 |     41.730 |     0.4
   13 |   1.1760 |     41.689 |   1.1787 |     41.794 |     0.4
   14 |   1.1665 |     41.387 |   1.1676 |     41.285 |     0.5
   15 |   1.1546 |     41.014 |   1.1544 |     41.794 |     0.5
   16 |   1.1454 |     40.959 |   1.1486 |     40.840 |     0.5
   17 |   1.1356 |     40.471 |   1.1521 |     41.762 |     0.6
   18 |   1.1262 |     40.246 |   1.1366 |     39.949 |     0.6
   19 |   1.1163 |     40.120 |   1.1377 |     40.585 |     0.6
   20 |   1.1115 |     40.109 |   1.1230 |     39.695 |     0.7
   21 |   1.1013 |     39.533 |   1.1208 |     39.567 |     0.7
   22 |   1.0912 |     39.291 |   1.1128 |     39.154 |     0.7
   23 |   1.0857 |     39.286 |   1.1063 |     38.931 |     0.8
   24 |   1.0774 |     38.781 |   1.1028 |     38.613 |     0.8
   25 |   1.0651 |     38.490 |   1.0899 |     39.122 |     0.8
   26 |   1.0608 |     37.996 |   1.1032 |     38.263 |     0.9
   27 |   1.0520 |     37.722 |   1.0861 |     38.391 |     0.9
   28 |   1.0508 |     38.035 |   1.0837 |     38.327 |     0.9
   29 |   1.0413 |     37.761 |   1.0742 |     38.073 |     1.0
   30 |   1.0317 |     37.201 |   1.0710 |     37.945 |     1.0
   31 |   1.0300 |     37.256 |   1.0627 |     37.373 |     1.0
   32 |   1.0221 |     37.020 |   1.0511 |     37.150 |     1.1
   33 |   1.0149 |     36.433 |   1.0495 |     36.387 |     1.1
   34 |   1.0125 |     36.850 |   1.0528 |     37.341 |     1.1
   35 |   1.0015 |     36.362 |   1.0446 |     37.087 |     1.2
   36 |   0.9928 |     35.928 |   1.0389 |     36.514 |     1.2
   37 |   0.9870 |     35.632 |   1.0340 |     36.673 |     1.2
   38 |   0.9811 |     35.347 |   1.0229 |     35.655 |     1.3
   39 |   0.9690 |     35.111 |   1.0131 |     35.878 |     1.3
   40 |   0.9640 |     34.634 |   1.0110 |     34.955 |     1.3
   41 |   0.9562 |     34.118 |   1.0136 |     34.637 |     1.4
   42 |   0.9522 |     34.326 |   1.0116 |     34.892 |     1.4
   43 |   0.9354 |     33.492 |   1.0063 |     34.510 |     1.4
   44 |   0.9341 |     33.503 |   0.9991 |     34.288 |     1.5
   45 |   0.9260 |     33.229 |   0.9952 |     34.192 |     1.5
   46 |   0.9133 |     32.505 |   0.9967 |     34.097 |     1.5
   47 |   0.9102 |     32.554 |   0.9901 |     34.128 |     1.6
   48 |   0.9046 |     32.187 |   0.9816 |     34.351 |     1.6
   49 |   0.8991 |     32.006 |   0.9739 |     32.697 |     1.6
   50 |   0.8837 |     31.353 |   0.9785 |     33.620 |     1.7
   51 |   0.8738 |     30.629 |   0.9671 |     32.952 |     1.7
   52 |   0.8686 |     30.426 |   0.9710 |     33.302 |     1.7
   53 |   0.8655 |     30.398 |   0.9585 |     32.316 |     1.8
   54 |   0.8471 |     29.586 |   0.9547 |     32.602 |     1.8
   55 |   0.8418 |     29.504 |   0.9577 |     32.952 |     1.8
   56 |   0.8335 |     29.334 |   0.9551 |     31.934 |     1.9
   57 |   0.8273 |     28.939 |   0.9556 |     31.711 |     1.9
   58 |   0.8186 |     28.308 |   0.9459 |     31.584 |     1.9
   59 |   0.8052 |     27.814 |   0.9647 |     32.379 |     2.0
   60 |   0.7997 |     27.502 |   0.9598 |     31.489 |     2.0
   61 |   0.7892 |     27.655 |   0.9317 |     30.248 |     2.0
   62 |   0.7768 |     26.575 |   0.9500 |     31.234 |     2.1
   63 |   0.7672 |     26.328 |   0.9447 |     31.043 |     2.1
   64 |   0.7616 |     26.114 |   0.9404 |     31.202 |     2.1
   65 |   0.7659 |     26.048 |   0.9394 |     30.662 |     2.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 621,506

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1804 |     59.145 |   1.5755 |     45.802 |     0.0
    2 |   1.4639 |     46.253 |   1.3892 |     45.833 |     0.0
    3 |   1.3759 |     46.066 |   1.3464 |     45.770 |     0.1
    4 |   1.3412 |     45.902 |   1.3225 |     44.975 |     0.1
    5 |   1.3175 |     45.556 |   1.3074 |     46.374 |     0.1
    6 |   1.3003 |     45.578 |   1.2850 |     44.975 |     0.1
    7 |   1.2812 |     45.024 |   1.2630 |     44.561 |     0.1
    8 |   1.2609 |     44.673 |   1.2363 |     44.020 |     0.1
    9 |   1.2383 |     43.899 |   1.2184 |     43.766 |     0.2
   10 |   1.2215 |     43.548 |   1.2026 |     42.430 |     0.2
   11 |   1.2036 |     42.994 |   1.1907 |     43.003 |     0.2
   12 |   1.1869 |     42.062 |   1.1766 |     42.398 |     0.2
   13 |   1.1783 |     42.007 |   1.1678 |     41.031 |     0.2
   14 |   1.1623 |     41.217 |   1.1557 |     41.190 |     0.2
   15 |   1.1521 |     40.707 |   1.1472 |     40.903 |     0.3
   16 |   1.1366 |     40.410 |   1.1394 |     40.458 |     0.3
   17 |   1.1342 |     40.526 |   1.1328 |     40.045 |     0.3
   18 |   1.1217 |     40.032 |   1.1223 |     39.472 |     0.3
   19 |   1.1106 |     39.686 |   1.1265 |     40.204 |     0.3
   20 |   1.1026 |     39.302 |   1.1214 |     39.663 |     0.4
   21 |   1.0931 |     38.935 |   1.1016 |     38.740 |     0.4
   22 |   1.0835 |     38.677 |   1.1117 |     40.045 |     0.4
   23 |   1.0773 |     38.304 |   1.0980 |     39.536 |     0.4
   24 |   1.0683 |     38.199 |   1.0982 |     39.090 |     0.4
   25 |   1.0570 |     37.898 |   1.0806 |     38.899 |     0.4
   26 |   1.0505 |     37.662 |   1.0740 |     37.882 |     0.5
   27 |   1.0435 |     37.415 |   1.0672 |     37.532 |     0.5
   28 |   1.0376 |     37.399 |   1.0706 |     38.518 |     0.5
   29 |   1.0317 |     37.223 |   1.0647 |     38.104 |     0.5
   30 |   1.0251 |     36.861 |   1.0498 |     37.277 |     0.5
   31 |   1.0161 |     36.806 |   1.0540 |     37.087 |     0.5
   32 |   1.0081 |     36.329 |   1.0457 |     36.896 |     0.6
   33 |   0.9969 |     36.214 |   1.0350 |     37.373 |     0.6
   34 |   0.9955 |     35.895 |   1.0482 |     37.023 |     0.6
   35 |   0.9850 |     35.396 |   1.0245 |     36.132 |     0.6
   36 |   0.9775 |     35.374 |   1.0099 |     34.955 |     0.6
   37 |   0.9703 |     34.826 |   1.0180 |     34.924 |     0.7
   38 |   0.9607 |     34.206 |   1.0026 |     34.987 |     0.7
   39 |   0.9500 |     33.783 |   0.9980 |     34.383 |     0.7
   40 |   0.9517 |     33.931 |   1.0286 |     36.419 |     0.7
   41 |   0.9443 |     33.800 |   1.0001 |     35.019 |     0.7
   42 |   0.9287 |     33.240 |   0.9903 |     34.701 |     0.7
   43 |   0.9206 |     32.713 |   0.9894 |     34.033 |     0.8
   44 |   0.9138 |     32.532 |   0.9875 |     33.906 |     0.8
   45 |   0.9011 |     31.901 |   0.9817 |     34.478 |     0.8
   46 |   0.8929 |     31.731 |   0.9671 |     33.302 |     0.8
   47 |   0.8873 |     31.408 |   0.9690 |     32.824 |     0.8
   48 |   0.8850 |     31.347 |   0.9610 |     32.156 |     0.9
   49 |   0.8713 |     30.535 |   0.9579 |     32.602 |     0.9
   50 |   0.8856 |     31.496 |   0.9692 |     33.206 |     0.9
   51 |   0.8684 |     30.799 |   0.9628 |     32.920 |     0.9
   52 |   0.8488 |     29.872 |   0.9531 |     32.156 |     0.9
   53 |   0.8481 |     29.822 |   0.9529 |     32.475 |     0.9
   54 |   0.8394 |     29.850 |   0.9465 |     32.125 |     1.0
   55 |   0.8255 |     28.988 |   0.9416 |     31.902 |     1.0
   56 |   0.8184 |     28.846 |   0.9479 |     31.393 |     1.0
   57 |   0.8118 |     28.445 |   0.9420 |     32.029 |     1.0
   58 |   0.8005 |     28.083 |   0.9471 |     31.489 |     1.0
   59 |   0.8093 |     28.412 |   0.9348 |     31.043 |     1.1
   60 |   0.7866 |     27.441 |   0.9360 |     30.884 |     1.1
   61 |   0.7816 |     27.496 |   0.9291 |     30.025 |     1.1
   62 |   0.7740 |     26.871 |   0.9456 |     30.884 |     1.1
   63 |   0.7686 |     27.156 |   0.9254 |     30.089 |     1.1
   64 |   0.7524 |     26.053 |   0.9356 |     30.184 |     1.1
   65 |   0.7507 |     26.273 |   0.9299 |     30.312 |     1.2
   66 |   0.7431 |     25.603 |   0.9241 |     29.835 |     1.2
   67 |   0.7345 |     25.713 |   0.9410 |     30.025 |     1.2
   68 |   0.7304 |     25.241 |   0.9502 |     29.962 |     1.2
   69 |   0.7289 |     25.390 |   0.9365 |     30.439 |     1.2
   70 |   0.7168 |     24.545 |   0.9370 |     29.835 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 966,594

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9931 |     54.691 |   1.4701 |     45.293 |     0.0
    2 |   1.3923 |     45.688 |   1.3356 |     44.338 |     0.1
    3 |   1.3131 |     44.541 |   1.2771 |     43.830 |     0.1
    4 |   1.2693 |     43.697 |   1.2397 |     42.939 |     0.2
    5 |   1.2352 |     42.857 |   1.2187 |     42.080 |     0.2
    6 |   1.2023 |     42.155 |   1.1864 |     41.190 |     0.2
    7 |   1.1682 |     41.074 |   1.1644 |     40.267 |     0.3
    8 |   1.1405 |     40.180 |   1.1426 |     40.394 |     0.3
    9 |   1.1133 |     39.160 |   1.1284 |     39.981 |     0.4
   10 |   1.0793 |     38.101 |   1.0943 |     38.263 |     0.4
   11 |   1.0454 |     36.576 |   1.0770 |     37.659 |     0.4
   12 |   1.0114 |     35.237 |   1.0629 |     37.373 |     0.5
   13 |   0.9751 |     33.739 |   1.0310 |     35.369 |     0.5
   14 |   0.9365 |     32.011 |   1.0296 |     35.719 |     0.6
   15 |   0.8968 |     30.651 |   0.9837 |     32.729 |     0.6
   16 |   0.8567 |     29.334 |   0.9708 |     33.015 |     0.6
   17 |   0.8217 |     28.028 |   0.9716 |     32.602 |     0.7
   18 |   0.7805 |     26.399 |   0.9333 |     30.057 |     0.7
   19 |   0.7364 |     24.868 |   0.9257 |     30.598 |     0.8
   20 |   0.6968 |     23.546 |   0.9021 |     29.071 |     0.8
   21 |   0.6691 |     21.884 |   0.9091 |     28.690 |     0.8
   22 |   0.6260 |     20.540 |   0.9041 |     28.690 |     0.9
   23 |   0.5894 |     19.322 |   0.9041 |     27.926 |     0.9
   24 |   0.5582 |     17.896 |   0.9057 |     28.085 |     1.0
   25 |   0.5240 |     16.881 |   0.8975 |     26.622 |     1.0
   26 |   0.4903 |     15.849 |   0.9085 |     27.576 |     1.0
   27 |   0.4754 |     15.284 |   0.9024 |     27.640 |     1.1
   28 |   0.4345 |     14.022 |   0.9148 |     26.177 |     1.1
   29 |   0.4080 |     13.112 |   0.9395 |     26.559 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 753,602

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0392 |     55.815 |   1.4681 |     45.642 |     0.0
    2 |   1.3905 |     45.677 |   1.3293 |     46.374 |     0.1
    3 |   1.3089 |     44.624 |   1.2798 |     44.879 |     0.1
    4 |   1.2733 |     44.168 |   1.2518 |     43.639 |     0.1
    5 |   1.2423 |     43.444 |   1.2216 |     42.971 |     0.2
    6 |   1.2165 |     42.912 |   1.2006 |     42.335 |     0.2
    7 |   1.1915 |     42.188 |   1.1741 |     41.985 |     0.2
    8 |   1.1719 |     41.815 |   1.1616 |     41.126 |     0.3
    9 |   1.1497 |     40.910 |   1.1531 |     41.730 |     0.3
   10 |   1.1305 |     40.218 |   1.1290 |     40.045 |     0.3
   11 |   1.1146 |     39.867 |   1.1196 |     40.331 |     0.4
   12 |   1.1010 |     39.236 |   1.1109 |     39.567 |     0.4
   13 |   1.0825 |     38.715 |   1.0959 |     38.104 |     0.4
   14 |   1.0713 |     38.331 |   1.0842 |     38.295 |     0.5
   15 |   1.0562 |     37.777 |   1.0736 |     37.405 |     0.5
   16 |   1.0420 |     37.371 |   1.0740 |     37.882 |     0.5
   17 |   1.0374 |     37.157 |   1.0696 |     38.295 |     0.6
   18 |   1.0263 |     36.713 |   1.0538 |     36.419 |     0.6
   19 |   1.0133 |     36.170 |   1.0451 |     35.941 |     0.6
   20 |   1.0034 |     35.868 |   1.0383 |     36.387 |     0.7
   21 |   0.9878 |     35.155 |   1.0250 |     35.751 |     0.7
   22 |   0.9798 |     35.029 |   1.0256 |     36.101 |     0.7
   23 |   0.9647 |     34.348 |   1.0163 |     34.796 |     0.8
   24 |   0.9513 |     33.531 |   1.0133 |     34.796 |     0.8
   25 |   0.9385 |     33.196 |   1.0036 |     33.969 |     0.8
   26 |   0.9240 |     32.560 |   1.0102 |     34.542 |     0.9
   27 |   0.9150 |     32.318 |   0.9871 |     33.651 |     0.9
   28 |   0.8953 |     31.627 |   0.9805 |     33.174 |     0.9
   29 |   0.8782 |     30.519 |   0.9715 |     32.284 |     1.0
   30 |   0.8701 |     30.503 |   0.9677 |     32.729 |     1.0
   31 |   0.8528 |     29.504 |   0.9476 |     32.443 |     1.0
   32 |   0.8410 |     28.884 |   0.9543 |     31.584 |     1.1
   33 |   0.8275 |     28.462 |   0.9484 |     31.679 |     1.1
   34 |   0.8167 |     27.979 |   0.9364 |     31.234 |     1.1
   35 |   0.8001 |     27.452 |   0.9359 |     31.075 |     1.2
   36 |   0.7871 |     27.041 |   0.9337 |     31.266 |     1.2
   37 |   0.7741 |     26.607 |   0.9289 |     31.107 |     1.2
   38 |   0.7529 |     25.571 |   0.9221 |     30.153 |     1.3
   39 |   0.7369 |     25.104 |   0.9183 |     30.153 |     1.3
   40 |   0.7257 |     24.649 |   0.9215 |     30.089 |     1.3
   41 |   0.7125 |     24.177 |   0.9169 |     30.407 |     1.4
   42 |   0.7012 |     23.864 |   0.9148 |     30.184 |     1.4
   43 |   0.6909 |     23.650 |   0.9081 |     29.230 |     1.4
   44 |   0.6741 |     22.838 |   0.9020 |     29.676 |     1.5
   45 |   0.6638 |     22.701 |   0.8977 |     29.485 |     1.5
   46 |   0.6526 |     22.098 |   0.8902 |     28.753 |     1.5
   47 |   0.6367 |     21.451 |   0.9109 |     28.976 |     1.6
   48 |   0.6379 |     21.467 |   0.9039 |     28.753 |     1.6
   49 |   0.6156 |     20.677 |   0.8918 |     28.022 |     1.6
   50 |   0.5964 |     20.013 |   0.9205 |     28.849 |     1.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,281,570

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4770 |     66.414 |   1.9073 |     54.230 |     0.1
    2 |   1.7079 |     48.930 |   1.5324 |     45.802 |     0.1
    3 |   1.4740 |     46.154 |   1.4223 |     46.533 |     0.2
    4 |   1.4124 |     46.061 |   1.3927 |     45.547 |     0.2
    5 |   1.3890 |     46.066 |   1.3661 |     45.611 |     0.3
    6 |   1.3721 |     45.929 |   1.3498 |     45.388 |     0.4
    7 |   1.3562 |     45.661 |   1.3352 |     44.943 |     0.4
    8 |   1.3414 |     45.216 |   1.3245 |     44.943 |     0.5
    9 |   1.3204 |     45.101 |   1.2973 |     44.752 |     0.6
   10 |   1.2950 |     44.465 |   1.2787 |     43.989 |     0.6
   11 |   1.2730 |     44.245 |   1.2542 |     43.352 |     0.7
   12 |   1.2465 |     43.521 |   1.2338 |     42.812 |     0.7
   13 |   1.2242 |     42.972 |   1.2137 |     43.321 |     0.8
   14 |   1.2027 |     42.226 |   1.1993 |     41.921 |     0.9
   15 |   1.1814 |     41.469 |   1.1785 |     41.730 |     0.9
   16 |   1.1613 |     40.855 |   1.1696 |     40.776 |     1.0
   17 |   1.1411 |     39.971 |   1.1412 |     39.631 |     1.1
   18 |   1.1197 |     39.192 |   1.1304 |     39.599 |     1.1
   19 |   1.0998 |     38.386 |   1.1258 |     38.263 |     1.2
   20 |   1.0810 |     37.503 |   1.1052 |     37.468 |     1.2
   21 |   1.0602 |     36.537 |   1.0926 |     37.373 |     1.3
   22 |   1.0385 |     35.983 |   1.0869 |     36.991 |     1.4
   23 |   1.0192 |     35.292 |   1.0809 |     37.023 |     1.4
   24 |   0.9982 |     34.623 |   1.0722 |     36.291 |     1.5
   25 |   0.9776 |     33.476 |   1.0588 |     35.274 |     1.5
   26 |   0.9612 |     32.648 |   1.0537 |     34.828 |     1.6
   27 |   0.9371 |     31.589 |   1.0505 |     35.019 |     1.7
   28 |   0.9103 |     30.733 |   1.0296 |     34.224 |     1.7
   29 |   0.8897 |     29.641 |   1.0392 |     34.478 |     1.8
   30 |   0.8678 |     28.994 |   1.0232 |     33.651 |     1.9
   31 |   0.8451 |     27.973 |   1.0138 |     32.506 |     1.9
   32 |   0.8160 |     26.591 |   1.0128 |     32.570 |     2.0
   33 |   0.7911 |     25.944 |   1.0090 |     31.679 |     2.0
   34 |   0.7679 |     25.219 |   1.0056 |     30.948 |     2.1
   35 |   0.7428 |     24.106 |   0.9962 |     31.298 |     2.2
   36 |   0.7201 |     23.393 |   1.0010 |     30.630 |     2.2
   37 |   0.6888 |     22.059 |   0.9982 |     30.407 |     2.3
   38 |   0.6703 |     21.917 |   0.9988 |     29.898 |     2.4
   39 |   0.6404 |     20.776 |   0.9943 |     29.771 |     2.4
   40 |   0.6153 |     20.002 |   0.9993 |     30.439 |     2.5
   41 |   0.5997 |     19.585 |   1.0059 |     29.230 |     2.5
   42 |   0.5813 |     19.031 |   1.0066 |     29.039 |     2.6
   43 |   0.5672 |     18.488 |   1.0082 |     30.121 |     2.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 904,226

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1961 |     59.480 |   1.5894 |     45.802 |     0.0
    2 |   1.4738 |     46.143 |   1.4069 |     45.802 |     0.1
    3 |   1.3984 |     46.143 |   1.3652 |     45.833 |     0.1
    4 |   1.3591 |     45.820 |   1.3381 |     45.038 |     0.1
    5 |   1.3340 |     45.825 |   1.3133 |     44.752 |     0.2
    6 |   1.3112 |     45.496 |   1.2949 |     44.720 |     0.2
    7 |   1.2917 |     44.816 |   1.2751 |     44.052 |     0.3
    8 |   1.2744 |     44.750 |   1.2589 |     44.211 |     0.3
    9 |   1.2583 |     44.015 |   1.2574 |     44.816 |     0.3
   10 |   1.2454 |     43.532 |   1.2273 |     43.861 |     0.4
   11 |   1.2250 |     42.939 |   1.2114 |     42.716 |     0.4
   12 |   1.2067 |     42.193 |   1.2035 |     42.462 |     0.4
   13 |   1.1857 |     41.381 |   1.1825 |     41.794 |     0.5
   14 |   1.1652 |     40.844 |   1.1703 |     40.522 |     0.5
   15 |   1.1428 |     39.801 |   1.1458 |     39.854 |     0.6
   16 |   1.1174 |     38.869 |   1.1289 |     38.899 |     0.6
   17 |   1.0961 |     38.265 |   1.1070 |     37.977 |     0.6
   18 |   1.0735 |     37.316 |   1.0979 |     37.882 |     0.7
   19 |   1.0494 |     36.515 |   1.0846 |     37.277 |     0.7
   20 |   1.0191 |     35.347 |   1.0816 |     36.609 |     0.7
   21 |   0.9970 |     34.524 |   1.0569 |     35.846 |     0.8
   22 |   0.9708 |     33.152 |   1.0455 |     34.765 |     0.8
   23 |   0.9458 |     32.318 |   1.0193 |     34.351 |     0.9
   24 |   0.9158 |     31.347 |   1.0110 |     33.270 |     0.9
   25 |   0.8910 |     30.217 |   1.0097 |     32.538 |     0.9
   26 |   0.8632 |     29.147 |   0.9946 |     32.316 |     1.0
   27 |   0.8369 |     28.368 |   0.9978 |     31.489 |     1.0
   28 |   0.8096 |     27.386 |   0.9805 |     31.393 |     1.0
   29 |   0.7797 |     26.256 |   0.9834 |     31.266 |     1.1
   30 |   0.7592 |     25.867 |   1.0085 |     31.997 |     1.1
   31 |   0.7522 |     25.033 |   0.9740 |     30.439 |     1.1
   32 |   0.7190 |     23.969 |   0.9624 |     30.439 |     1.2
   33 |   0.6879 |     22.811 |   0.9598 |     30.057 |     1.2
   34 |   0.6636 |     21.966 |   0.9703 |     30.598 |     1.3
   35 |   0.6473 |     21.461 |   0.9634 |     29.389 |     1.3
   36 |   0.6303 |     20.814 |   0.9606 |     29.326 |     1.3
   37 |   0.6175 |     20.534 |   0.9746 |     28.753 |     1.4
   38 |   0.5980 |     19.415 |   0.9570 |     28.340 |     1.4
   39 |   0.5694 |     18.625 |   0.9588 |     28.022 |     1.4
   40 |   0.5547 |     18.203 |   0.9911 |     28.817 |     1.5
   41 |   0.5537 |     18.170 |   0.9824 |     27.385 |     1.5
   42 |   0.5320 |     17.583 |   0.9638 |     27.863 |     1.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 965,858

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0888 |     56.934 |   1.4993 |     45.674 |     0.0
    2 |   1.4242 |     46.160 |   1.3694 |     45.515 |     0.1
    3 |   1.3524 |     45.715 |   1.3266 |     44.975 |     0.1
    4 |   1.3101 |     44.876 |   1.2881 |     45.324 |     0.2
    5 |   1.2844 |     44.092 |   1.2598 |     43.352 |     0.2
    6 |   1.2556 |     43.570 |   1.2437 |     43.416 |     0.2
    7 |   1.2320 |     42.939 |   1.2210 |     42.207 |     0.3
    8 |   1.2045 |     42.276 |   1.1968 |     41.508 |     0.3
    9 |   1.1810 |     41.113 |   1.1717 |     40.553 |     0.4
   10 |   1.1502 |     40.054 |   1.1507 |     40.235 |     0.4
   11 |   1.1158 |     38.688 |   1.1208 |     38.613 |     0.4
   12 |   1.0790 |     37.196 |   1.0942 |     38.073 |     0.5
   13 |   1.0415 |     36.241 |   1.0683 |     37.246 |     0.5
   14 |   0.9943 |     34.315 |   1.0299 |     34.987 |     0.6
   15 |   0.9498 |     32.148 |   0.9983 |     33.524 |     0.6
   16 |   0.9020 |     30.294 |   0.9784 |     33.015 |     0.6
   17 |   0.8526 |     28.226 |   0.9660 |     32.443 |     0.7
   18 |   0.8102 |     26.618 |   0.9472 |     31.775 |     0.7
   19 |   0.7702 |     25.077 |   0.9217 |     30.725 |     0.8
   20 |   0.7137 |     22.976 |   0.9111 |     28.785 |     0.8
   21 |   0.6809 |     22.038 |   0.9053 |     28.817 |     0.8
   22 |   0.6399 |     20.847 |   0.8982 |     28.403 |     0.9
   23 |   0.5934 |     18.910 |   0.8938 |     27.449 |     0.9
   24 |   0.5518 |     17.358 |   0.8873 |     27.417 |     1.0
   25 |   0.5172 |     16.184 |   0.8960 |     26.240 |     1.0
   26 |   0.4810 |     15.251 |   0.9021 |     26.304 |     1.0
   27 |   0.4538 |     14.247 |   0.9139 |     26.240 |     1.1
   28 |   0.4263 |     13.523 |   0.9475 |     27.067 |     1.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,524,546

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2321 |     60.226 |   1.5936 |     45.802 |     0.1
    2 |   1.4774 |     46.204 |   1.4203 |     46.533 |     0.1
    3 |   1.4007 |     46.248 |   1.3643 |     45.802 |     0.2
    4 |   1.3628 |     45.809 |   1.3436 |     45.642 |     0.2
    5 |   1.3329 |     45.682 |   1.3255 |     44.688 |     0.3
    6 |   1.3152 |     45.397 |   1.2972 |     45.388 |     0.4
    7 |   1.2996 |     44.986 |   1.2871 |     44.752 |     0.4
    8 |   1.2878 |     44.733 |   1.2802 |     44.466 |     0.5
    9 |   1.2749 |     44.519 |   1.2616 |     44.338 |     0.5
   10 |   1.2628 |     44.382 |   1.2529 |     44.529 |     0.6
   11 |   1.2510 |     44.393 |   1.2416 |     44.656 |     0.7
   12 |   1.2320 |     43.960 |   1.2196 |     44.020 |     0.7
   13 |   1.2207 |     43.691 |   1.2149 |     43.034 |     0.8
   14 |   1.2114 |     43.252 |   1.2085 |     43.130 |     0.8
   15 |   1.2016 |     43.318 |   1.1967 |     42.971 |     0.9
   16 |   1.1930 |     42.577 |   1.1850 |     42.494 |     1.0
   17 |   1.1822 |     42.237 |   1.1797 |     41.508 |     1.0
   18 |   1.1760 |     41.831 |   1.1771 |     42.494 |     1.1
   19 |   1.1670 |     41.776 |   1.1629 |     41.412 |     1.1
   20 |   1.1586 |     41.562 |   1.1534 |     41.221 |     1.2
   21 |   1.1520 |     41.348 |   1.1478 |     40.776 |     1.3
   22 |   1.1452 |     41.299 |   1.1444 |     41.031 |     1.3
   23 |   1.1329 |     40.849 |   1.1440 |     40.935 |     1.4
   24 |   1.1244 |     40.668 |   1.1341 |     40.522 |     1.4
   25 |   1.1152 |     40.377 |   1.1258 |     39.917 |     1.5
   26 |   1.1094 |     39.977 |   1.1185 |     40.808 |     1.5
   27 |   1.0999 |     39.659 |   1.1123 |     39.154 |     1.6
   28 |   1.0915 |     39.401 |   1.1158 |     39.377 |     1.7
   29 |   1.0853 |     39.670 |   1.1027 |     39.599 |     1.7
   30 |   1.0798 |     39.308 |   1.0962 |     39.027 |     1.8
   31 |   1.0720 |     38.874 |   1.1010 |     39.186 |     1.8
   32 |   1.0667 |     38.616 |   1.0826 |     38.550 |     1.9
   33 |   1.0637 |     38.583 |   1.0768 |     38.232 |     2.0
   34 |   1.0546 |     38.348 |   1.0848 |     38.073 |     2.0
   35 |   1.0496 |     38.084 |   1.0734 |     38.963 |     2.1
   36 |   1.0450 |     38.227 |   1.0687 |     37.850 |     2.1
   37 |   1.0398 |     37.996 |   1.0675 |     37.532 |     2.2
   38 |   1.0347 |     37.497 |   1.0616 |     37.850 |     2.3
   39 |   1.0262 |     37.333 |   1.0640 |     38.009 |     2.3
   40 |   1.0205 |     36.839 |   1.0529 |     38.295 |     2.4
   41 |   1.0115 |     36.828 |   1.0517 |     37.532 |     2.4
   42 |   1.0104 |     36.537 |   1.0432 |     36.737 |     2.5
   43 |   0.9995 |     36.334 |   1.0475 |     37.627 |     2.6
   44 |   0.9939 |     36.005 |   1.0404 |     36.959 |     2.6
   45 |   0.9880 |     35.517 |   1.0355 |     36.609 |     2.7
   46 |   0.9816 |     35.594 |   1.0210 |     35.719 |     2.7
   47 |   0.9740 |     35.434 |   1.0215 |     35.846 |     2.8
   48 |   0.9701 |     34.875 |   1.0126 |     35.083 |     2.9
   49 |   0.9614 |     34.705 |   1.0309 |     35.782 |     2.9
   50 |   0.9640 |     34.908 |   1.0134 |     34.987 |     3.0
   51 |   0.9488 |     34.129 |   1.0033 |     34.796 |     3.0
   52 |   0.9645 |     34.968 |   1.0739 |     37.818 |     3.1
   53 |   0.9640 |     34.666 |   1.0066 |     34.383 |     3.2
   54 |   0.9500 |     34.348 |   0.9980 |     35.560 |     3.2
   55 |   0.9355 |     33.761 |   0.9905 |     34.319 |     3.3
   56 |   0.9235 |     33.043 |   0.9962 |     33.779 |     3.3
   57 |   0.9254 |     33.059 |   1.0096 |     35.464 |     3.4
   58 |   0.9149 |     32.960 |   0.9939 |     34.256 |     3.5
   59 |   0.9155 |     32.571 |   0.9799 |     34.065 |     3.5
   60 |   0.9080 |     32.549 |   0.9874 |     34.192 |     3.6
   61 |   0.8973 |     32.072 |   0.9673 |     33.556 |     3.6
   62 |   0.8850 |     31.260 |   0.9799 |     33.270 |     3.7
   63 |   0.8822 |     31.249 |   0.9776 |     32.824 |     3.8
   64 |   0.8766 |     31.205 |   0.9791 |     33.079 |     3.8
   65 |   0.8671 |     30.733 |   0.9629 |     32.634 |     3.9
   66 |   0.8676 |     30.727 |   0.9672 |     32.347 |     3.9
   67 |   0.8534 |     30.195 |   0.9588 |     32.347 |     4.0
   68 |   0.8458 |     29.669 |   0.9750 |     33.206 |     4.1
   69 |   0.8467 |     29.937 |   0.9593 |     32.156 |     4.1
   70 |   0.8339 |     29.394 |   0.9555 |     31.711 |     4.2
   71 |   0.8361 |     29.296 |   0.9434 |     31.457 |     4.2
   72 |   0.8269 |     28.884 |   0.9562 |     31.679 |     4.3
   73 |   0.8164 |     28.791 |   0.9666 |     32.284 |     4.4
   74 |   0.8163 |     28.654 |   0.9523 |     31.393 |     4.4
   75 |   0.8070 |     28.418 |   0.9510 |     31.043 |     4.5
   76 |   0.8000 |     28.083 |   0.9411 |     30.471 |     4.5
   77 |   0.7991 |     28.001 |   0.9390 |     30.916 |     4.6
   78 |   0.7937 |     27.683 |   0.9643 |     32.252 |     4.7
   79 |   0.7848 |     27.386 |   0.9581 |     31.170 |     4.7
   80 |   0.7791 |     27.140 |   0.9516 |     31.202 |     4.8
   81 |   0.7731 |     26.821 |   0.9352 |     31.139 |     4.8
   82 |   0.7671 |     26.854 |   0.9392 |     30.725 |     4.9
   83 |   0.7623 |     26.739 |   0.9376 |     30.534 |     5.0
   84 |   0.7617 |     26.558 |   0.9450 |     30.662 |     5.0
   85 |   0.7504 |     25.922 |   0.9235 |     29.453 |     5.1
   86 |   0.7416 |     25.741 |   0.9530 |     30.852 |     5.1
   87 |   0.7411 |     25.669 |   0.9277 |     29.866 |     5.2
   88 |   0.7312 |     25.406 |   0.9349 |     29.548 |     5.3
   89 |   0.7237 |     25.313 |   0.9313 |     29.135 |     5.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 388,194

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3963 |     62.431 |   1.8327 |     48.696 |     0.0
    2 |   1.6284 |     47.663 |   1.4654 |     45.642 |     0.1
    3 |   1.4309 |     45.902 |   1.3863 |     45.642 |     0.1
    4 |   1.3785 |     45.737 |   1.3463 |     46.215 |     0.1
    5 |   1.3449 |     45.540 |   1.3241 |     45.229 |     0.1
    6 |   1.3187 |     44.953 |   1.3078 |     44.816 |     0.2
    7 |   1.3003 |     44.338 |   1.2844 |     44.148 |     0.2
    8 |   1.2848 |     43.976 |   1.2693 |     43.798 |     0.2
    9 |   1.2663 |     43.598 |   1.2601 |     43.575 |     0.2
   10 |   1.2494 |     43.400 |   1.2394 |     42.844 |     0.3
   11 |   1.2353 |     43.027 |   1.2282 |     43.034 |     0.3
   12 |   1.2208 |     42.725 |   1.2108 |     42.780 |     0.3
   13 |   1.2033 |     42.221 |   1.2020 |     42.144 |     0.3
   14 |   1.1912 |     41.694 |   1.1880 |     41.444 |     0.4
   15 |   1.1786 |     41.348 |   1.1713 |     40.553 |     0.4
   16 |   1.1663 |     40.992 |   1.1603 |     40.585 |     0.4
   17 |   1.1530 |     40.394 |   1.1517 |     40.585 |     0.4
   18 |   1.1453 |     40.032 |   1.1514 |     40.522 |     0.5
   19 |   1.1330 |     39.406 |   1.1432 |     39.567 |     0.5
   20 |   1.1258 |     39.346 |   1.1305 |     39.440 |     0.5
   21 |   1.1113 |     39.033 |   1.1269 |     39.027 |     0.5
   22 |   1.1005 |     38.490 |   1.1144 |     37.882 |     0.6
   23 |   1.0908 |     38.128 |   1.1154 |     39.504 |     0.6
   24 |   1.0803 |     37.618 |   1.1019 |     38.709 |     0.6
   25 |   1.0692 |     37.272 |   1.0863 |     37.977 |     0.6
   26 |   1.0571 |     37.185 |   1.0855 |     37.754 |     0.7
   27 |   1.0456 |     36.663 |   1.0706 |     36.450 |     0.7
   28 |   1.0319 |     36.109 |   1.0614 |     36.578 |     0.7
   29 |   1.0252 |     35.873 |   1.0597 |     36.641 |     0.7
   30 |   1.0118 |     35.034 |   1.0472 |     35.878 |     0.8
   31 |   0.9990 |     34.732 |   1.0410 |     35.910 |     0.8
   32 |   0.9912 |     35.007 |   1.0235 |     35.146 |     0.8
   33 |   0.9721 |     33.855 |   1.0166 |     35.146 |     0.8
   34 |   0.9598 |     33.207 |   1.0183 |     34.097 |     0.9
   35 |   0.9494 |     32.648 |   1.0126 |     34.606 |     0.9
   36 |   0.9418 |     32.275 |   0.9983 |     33.779 |     0.9
   37 |   0.9244 |     31.649 |   0.9959 |     33.302 |     0.9
   38 |   0.9134 |     31.539 |   0.9975 |     33.238 |     1.0
   39 |   0.9002 |     30.771 |   0.9862 |     32.475 |     1.0
   40 |   0.8897 |     29.998 |   0.9898 |     33.270 |     1.0
   41 |   0.8775 |     29.740 |   0.9769 |     32.475 |     1.0
   42 |   0.8608 |     28.747 |   0.9678 |     32.156 |     1.1
   43 |   0.8483 |     28.626 |   0.9601 |     31.361 |     1.1
   44 |   0.8385 |     28.133 |   0.9816 |     32.061 |     1.1
   45 |   0.8323 |     27.962 |   0.9586 |     31.902 |     1.1
   46 |   0.8079 |     27.008 |   0.9570 |     31.902 |     1.2
   47 |   0.7957 |     26.723 |   0.9376 |     30.725 |     1.2
   48 |   0.7833 |     26.141 |   0.9487 |     30.852 |     1.2
   49 |   0.7795 |     26.020 |   0.9382 |     31.298 |     1.2
   50 |   0.7670 |     25.444 |   0.9412 |     30.662 |     1.3
   51 |   0.7514 |     25.060 |   0.9375 |     30.789 |     1.3
   52 |   0.7318 |     24.073 |   0.9205 |     30.153 |     1.3
   53 |   0.7161 |     23.683 |   0.9373 |     30.089 |     1.3
   54 |   0.7189 |     23.667 |   0.9266 |     30.121 |     1.4
   55 |   0.7035 |     23.168 |   0.9397 |     29.930 |     1.4
   56 |   0.6828 |     22.394 |   0.9219 |     29.930 |     1.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 422,210

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5288 |     68.428 |   1.9138 |     54.230 |     0.0
    2 |   1.6885 |     48.195 |   1.5208 |     45.802 |     0.0
    3 |   1.4736 |     46.253 |   1.4277 |     45.802 |     0.1
    4 |   1.4159 |     46.094 |   1.3870 |     45.802 |     0.1
    5 |   1.3853 |     46.176 |   1.3663 |     46.533 |     0.1
    6 |   1.3649 |     45.979 |   1.3564 |     45.770 |     0.1
    7 |   1.3467 |     45.606 |   1.3293 |     45.261 |     0.2
    8 |   1.3218 |     44.997 |   1.3025 |     44.561 |     0.2
    9 |   1.2976 |     44.410 |   1.2782 |     44.243 |     0.2
   10 |   1.2760 |     44.349 |   1.2583 |     44.148 |     0.2
   11 |   1.2597 |     43.976 |   1.2476 |     44.370 |     0.3
   12 |   1.2445 |     43.625 |   1.2331 |     43.893 |     0.3
   13 |   1.2328 |     43.537 |   1.2236 |     43.416 |     0.3
   14 |   1.2203 |     43.159 |   1.2187 |     43.003 |     0.3
   15 |   1.2090 |     42.731 |   1.2062 |     43.607 |     0.3
   16 |   1.1978 |     42.341 |   1.1946 |     42.494 |     0.4
   17 |   1.1888 |     41.974 |   1.1841 |     41.858 |     0.4
   18 |   1.1764 |     41.425 |   1.1798 |     41.349 |     0.4
   19 |   1.1669 |     41.381 |   1.1719 |     40.903 |     0.4
   20 |   1.1585 |     41.277 |   1.1671 |     41.508 |     0.5
   21 |   1.1508 |     41.217 |   1.1576 |     40.872 |     0.5
   22 |   1.1433 |     40.822 |   1.1579 |     41.158 |     0.5
   23 |   1.1370 |     40.591 |   1.1507 |     41.508 |     0.5
   24 |   1.1304 |     40.460 |   1.1413 |     40.045 |     0.6
   25 |   1.1220 |     40.399 |   1.1369 |     40.394 |     0.6
   26 |   1.1163 |     39.917 |   1.1267 |     39.599 |     0.6
   27 |   1.1093 |     39.522 |   1.1350 |     40.045 |     0.6
   28 |   1.1048 |     39.697 |   1.1193 |     40.204 |     0.6
   29 |   1.0946 |     39.143 |   1.1199 |     39.154 |     0.7
   30 |   1.0886 |     38.929 |   1.1105 |     39.186 |     0.7
   31 |   1.0803 |     38.825 |   1.1028 |     39.504 |     0.7
   32 |   1.0746 |     38.452 |   1.1035 |     39.949 |     0.7
   33 |   1.0732 |     38.605 |   1.1024 |     39.345 |     0.8
   34 |   1.0669 |     38.282 |   1.0967 |     38.645 |     0.8
   35 |   1.0602 |     38.139 |   1.0983 |     38.391 |     0.8
   36 |   1.0564 |     37.843 |   1.0968 |     38.613 |     0.8
   37 |   1.0497 |     37.788 |   1.0847 |     39.090 |     0.9
   38 |   1.0431 |     37.503 |   1.0788 |     37.977 |     0.9
   39 |   1.0387 |     37.250 |   1.0795 |     37.945 |     0.9
   40 |   1.0373 |     37.333 |   1.0791 |     37.246 |     0.9
   41 |   1.0305 |     36.735 |   1.0787 |     37.945 |     0.9
   42 |   1.0247 |     36.674 |   1.0712 |     38.073 |     1.0
   43 |   1.0193 |     36.581 |   1.0737 |     37.118 |     1.0
   44 |   1.0155 |     36.565 |   1.0714 |     37.691 |     1.0
   45 |   1.0099 |     36.268 |   1.0671 |     37.341 |     1.0
   46 |   1.0036 |     36.005 |   1.0619 |     36.768 |     1.1
   47 |   0.9986 |     35.632 |   1.0645 |     37.182 |     1.1
   48 |   0.9966 |     35.857 |   1.0582 |     37.087 |     1.1
   49 |   0.9899 |     35.259 |   1.0446 |     37.118 |     1.1
   50 |   0.9824 |     35.138 |   1.0534 |     36.927 |     1.2
   51 |   0.9805 |     35.061 |   1.0425 |     36.800 |     1.2
   52 |   0.9762 |     34.727 |   1.0435 |     36.387 |     1.2
   53 |   0.9672 |     34.436 |   1.0359 |     36.164 |     1.2
   54 |   0.9585 |     34.079 |   1.0359 |     35.782 |     1.2
   55 |   0.9533 |     33.805 |   1.0304 |     35.846 |     1.3
   56 |   0.9417 |     33.191 |   1.0227 |     35.051 |     1.3
   57 |   0.9381 |     33.158 |   1.0268 |     35.687 |     1.3
   58 |   0.9259 |     32.823 |   1.0123 |     34.319 |     1.3
   59 |   0.9199 |     32.264 |   1.0249 |     35.019 |     1.4
   60 |   0.9176 |     32.126 |   1.0089 |     33.461 |     1.4
   61 |   0.9044 |     31.748 |   1.0074 |     33.524 |     1.4
   62 |   0.8969 |     31.397 |   1.0185 |     33.938 |     1.4
   63 |   0.8979 |     31.457 |   1.0021 |     34.447 |     1.5
   64 |   0.8895 |     30.991 |   0.9988 |     33.365 |     1.5
   65 |   0.8768 |     30.519 |   0.9943 |     33.015 |     1.5
   66 |   0.8683 |     30.173 |   1.0015 |     32.920 |     1.5
   67 |   0.8604 |     29.833 |   0.9982 |     32.538 |     1.5
   68 |   0.8522 |     29.394 |   0.9899 |     32.443 |     1.6
   69 |   0.8437 |     29.038 |   0.9870 |     33.174 |     1.6
   70 |   0.8368 |     28.714 |   0.9883 |     31.648 |     1.6
   71 |   0.8289 |     28.456 |   0.9890 |     32.475 |     1.6
   72 |   0.8213 |     28.286 |   0.9799 |     31.489 |     1.7
   73 |   0.8164 |     27.973 |   0.9827 |     32.411 |     1.7
   74 |   0.8042 |     27.496 |   0.9905 |     32.443 |     1.7
   75 |   0.8006 |     27.310 |   0.9715 |     31.902 |     1.7
   76 |   0.7897 |     26.745 |   0.9739 |     31.043 |     1.8
   77 |   0.7817 |     26.531 |   0.9684 |     31.743 |     1.8
   78 |   0.7704 |     26.042 |   0.9613 |     31.234 |     1.8
   79 |   0.7652 |     25.752 |   0.9760 |     31.743 |     1.8
   80 |   0.7656 |     25.812 |   0.9697 |     31.457 |     1.9
   81 |   0.7485 |     25.033 |   0.9651 |     30.630 |     1.9
   82 |   0.7403 |     24.786 |   0.9537 |     30.248 |     1.9
   83 |   0.7300 |     24.314 |   0.9626 |     30.630 |     1.9
   84 |   0.7251 |     24.243 |   0.9423 |     29.962 |     1.9
   85 |   0.7174 |     24.013 |   0.9629 |     30.693 |     2.0
   86 |   0.7086 |     23.744 |   0.9433 |     30.534 |     2.0
   87 |   0.6946 |     22.921 |   0.9384 |     29.676 |     2.0
   88 |   0.6868 |     22.636 |   0.9417 |     28.944 |     2.0
   89 |   0.6833 |     22.405 |   0.9498 |     29.358 |     2.1
   90 |   0.6735 |     22.114 |   0.9350 |     28.944 |     2.1
   91 |   0.6637 |     21.588 |   0.9419 |     29.358 |     2.1
   92 |   0.6535 |     21.275 |   0.9370 |     29.803 |     2.1
   93 |   0.6595 |     21.714 |   0.9403 |     29.994 |     2.2
   94 |   0.6375 |     20.842 |   0.9367 |     28.372 |     2.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 639,330

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0356 |     54.093 |   1.4769 |     45.356 |     0.0
    2 |   1.4023 |     45.671 |   1.3306 |     44.338 |     0.1
    3 |   1.3180 |     44.563 |   1.2836 |     43.798 |     0.1
    4 |   1.2737 |     43.828 |   1.2526 |     43.670 |     0.1
    5 |   1.2419 |     43.175 |   1.2187 |     42.748 |     0.1
    6 |   1.2135 |     42.704 |   1.2019 |     42.271 |     0.2
    7 |   1.1848 |     41.798 |   1.1719 |     42.080 |     0.2
    8 |   1.1604 |     41.233 |   1.1457 |     40.108 |     0.2
    9 |   1.1283 |     39.747 |   1.1303 |     40.235 |     0.2
   10 |   1.1053 |     39.132 |   1.1055 |     39.027 |     0.3
   11 |   1.0756 |     37.591 |   1.0868 |     38.327 |     0.3
   12 |   1.0469 |     36.532 |   1.0681 |     37.214 |     0.3
   13 |   1.0150 |     35.511 |   1.0470 |     36.419 |     0.3
   14 |   0.9856 |     34.502 |   1.0283 |     35.115 |     0.4
   15 |   0.9563 |     33.026 |   1.0019 |     34.097 |     0.4
   16 |   0.9234 |     31.677 |   0.9836 |     33.620 |     0.4
   17 |   0.8945 |     30.892 |   0.9660 |     32.793 |     0.4
   18 |   0.8568 |     29.246 |   0.9470 |     31.043 |     0.5
   19 |   0.8266 |     27.611 |   0.9254 |     30.884 |     0.5
   20 |   0.7939 |     26.492 |   0.9224 |     30.153 |     0.5
   21 |   0.7661 |     25.390 |   0.9140 |     29.707 |     0.5
   22 |   0.7332 |     24.155 |   0.8904 |     29.167 |     0.6
   23 |   0.7072 |     23.447 |   0.8920 |     29.135 |     0.6
   24 |   0.6787 |     22.328 |   0.9032 |     29.008 |     0.6
   25 |   0.6497 |     21.363 |   0.8972 |     27.990 |     0.7
   26 |   0.6270 |     20.721 |   0.8882 |     27.322 |     0.7
   27 |   0.5999 |     19.838 |   0.9005 |     28.022 |     0.7
   28 |   0.5794 |     18.899 |   0.8791 |     27.099 |     0.7
   29 |   0.5547 |     18.455 |   0.8793 |     26.972 |     0.8
   30 |   0.5368 |     17.709 |   0.8970 |     26.527 |     0.8
   31 |   0.5142 |     16.864 |   0.8785 |     27.163 |     0.8
   32 |   0.4959 |     16.200 |   0.8897 |     26.209 |     0.8
   33 |   0.4705 |     15.460 |   0.8934 |     26.336 |     0.9
   34 |   0.4639 |     15.180 |   0.9144 |     26.113 |     0.9
   35 |   0.4491 |     14.736 |   0.9231 |     26.431 |     0.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,622,626

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5346 |     67.199 |   1.9960 |     58.810 |     0.1
    2 |   1.7712 |     50.647 |   1.5742 |     45.802 |     0.2
    3 |   1.5079 |     46.143 |   1.4444 |     45.802 |     0.2
    4 |   1.4343 |     46.226 |   1.4050 |     45.802 |     0.3
    5 |   1.4079 |     46.149 |   1.3872 |     45.802 |     0.4
    6 |   1.3921 |     46.143 |   1.3769 |     45.802 |     0.5
    7 |   1.3736 |     46.110 |   1.3469 |     45.802 |     0.6
    8 |   1.3508 |     45.869 |   1.3295 |     46.056 |     0.6
    9 |   1.3307 |     45.584 |   1.3118 |     45.388 |     0.7
   10 |   1.3143 |     45.408 |   1.3012 |     45.611 |     0.8
   11 |   1.3025 |     45.194 |   1.2924 |     44.847 |     0.9
   12 |   1.2917 |     45.046 |   1.2785 |     44.434 |     1.0
   13 |   1.2809 |     44.646 |   1.2677 |     44.911 |     1.0
   14 |   1.2671 |     44.267 |   1.2521 |     44.052 |     1.1
   15 |   1.2510 |     43.773 |   1.2429 |     43.670 |     1.2
   16 |   1.2369 |     43.406 |   1.2246 |     42.366 |     1.3
   17 |   1.2238 |     42.742 |   1.2148 |     43.003 |     1.4
   18 |   1.2118 |     42.528 |   1.2014 |     41.794 |     1.4
   19 |   1.1951 |     42.089 |   1.1893 |     41.476 |     1.5
   20 |   1.1833 |     41.864 |   1.1809 |     41.571 |     1.6
   21 |   1.1723 |     41.711 |   1.1730 |     40.967 |     1.7
   22 |   1.1593 |     41.244 |   1.1697 |     40.967 |     1.8
   23 |   1.1481 |     40.729 |   1.1606 |     40.363 |     1.8
   24 |   1.1341 |     40.158 |   1.1500 |     40.744 |     1.9
   25 |   1.1197 |     39.686 |   1.1424 |     41.094 |     2.0
   26 |   1.1065 |     39.077 |   1.1369 |     39.949 |     2.1
   27 |   1.0965 |     38.589 |   1.1306 |     39.885 |     2.2
   28 |   1.0794 |     37.777 |   1.1217 |     39.122 |     2.2
   29 |   1.0672 |     37.783 |   1.1178 |     38.740 |     2.3
   30 |   1.0571 |     37.206 |   1.1160 |     38.836 |     2.4
   31 |   1.0446 |     36.652 |   1.1050 |     38.518 |     2.5
   32 |   1.0296 |     36.301 |   1.0999 |     38.136 |     2.6
   33 |   1.0148 |     35.550 |   1.1002 |     37.977 |     2.6
   34 |   1.0035 |     35.308 |   1.0864 |     37.913 |     2.7
   35 |   0.9914 |     34.255 |   1.0849 |     37.246 |     2.8
   36 |   0.9712 |     33.564 |   1.0853 |     37.405 |     2.9
   37 |   0.9620 |     33.037 |   1.0775 |     36.673 |     2.9
   38 |   0.9450 |     32.730 |   1.0645 |     35.846 |     3.0
   39 |   0.9294 |     31.830 |   1.0744 |     36.323 |     3.1
   40 |   0.9150 |     31.271 |   1.0720 |     36.482 |     3.2
   41 |   0.8971 |     30.492 |   1.0750 |     35.846 |     3.3
   42 |   0.8880 |     30.426 |   1.0697 |     35.973 |     3.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 785,122

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4900 |     66.041 |   1.9443 |     55.216 |     0.0
    2 |   1.7199 |     49.084 |   1.5342 |     45.802 |     0.1
    3 |   1.4774 |     46.105 |   1.4303 |     45.802 |     0.1
    4 |   1.4182 |     46.105 |   1.3946 |     45.802 |     0.2
    5 |   1.3843 |     45.885 |   1.3639 |     45.515 |     0.2
    6 |   1.3622 |     45.798 |   1.3493 |     46.628 |     0.2
    7 |   1.3465 |     45.858 |   1.3338 |     44.879 |     0.3
    8 |   1.3311 |     45.189 |   1.3203 |     44.879 |     0.3
    9 |   1.3160 |     44.673 |   1.3058 |     44.688 |     0.3
   10 |   1.3045 |     44.503 |   1.2960 |     43.957 |     0.4
   11 |   1.2959 |     44.185 |   1.2900 |     45.356 |     0.4
   12 |   1.2853 |     44.503 |   1.2763 |     44.148 |     0.5
   13 |   1.2724 |     44.349 |   1.2665 |     44.466 |     0.5
   14 |   1.2597 |     44.004 |   1.2503 |     44.243 |     0.5
   15 |   1.2492 |     43.938 |   1.2414 |     43.130 |     0.6
   16 |   1.2342 |     43.483 |   1.2224 |     42.716 |     0.6
   17 |   1.2205 |     43.142 |   1.2185 |     43.543 |     0.7
   18 |   1.2096 |     42.841 |   1.2061 |     42.748 |     0.7
   19 |   1.1967 |     42.281 |   1.1943 |     42.525 |     0.7
   20 |   1.1836 |     41.903 |   1.1832 |     41.635 |     0.8
   21 |   1.1718 |     41.442 |   1.1791 |     41.667 |     0.8
   22 |   1.1599 |     40.871 |   1.1653 |     41.953 |     0.8
   23 |   1.1455 |     40.602 |   1.1545 |     40.458 |     0.9
   24 |   1.1310 |     40.142 |   1.1416 |     39.885 |     0.9
   25 |   1.1141 |     39.368 |   1.1394 |     40.490 |     1.0
   26 |   1.1000 |     38.743 |   1.1388 |     39.726 |     1.0
   27 |   1.0825 |     38.194 |   1.1304 |     39.218 |     1.0
   28 |   1.0669 |     37.300 |   1.1187 |     38.804 |     1.1
   29 |   1.0464 |     36.537 |   1.1102 |     39.504 |     1.1
   30 |   1.0319 |     36.076 |   1.0952 |     38.041 |     1.2
   31 |   1.0105 |     35.133 |   1.0971 |     37.564 |     1.2
   32 |   0.9931 |     34.420 |   1.0799 |     37.309 |     1.2
   33 |   0.9726 |     33.229 |   1.0883 |     37.627 |     1.3
   34 |   0.9553 |     32.697 |   1.0734 |     35.814 |     1.3
   35 |   0.9313 |     31.633 |   1.0674 |     35.146 |     1.4
   36 |   0.9086 |     30.557 |   1.0585 |     35.973 |     1.4
   37 |   0.8863 |     29.729 |   1.0385 |     34.288 |     1.4
   38 |   0.8583 |     28.714 |   1.0539 |     34.447 |     1.5
   39 |   0.8371 |     27.502 |   1.0400 |     33.365 |     1.5
   40 |   0.8167 |     26.854 |   1.0371 |     32.570 |     1.5
   41 |   0.7940 |     25.960 |   1.0501 |     33.302 |     1.6
   42 |   0.7647 |     24.945 |   1.0286 |     32.475 |     1.6
   43 |   0.7409 |     23.820 |   1.0306 |     31.997 |     1.7
   44 |   0.7203 |     23.151 |   1.0308 |     31.775 |     1.7
   45 |   0.6974 |     22.460 |   1.0343 |     31.298 |     1.7
   46 |   0.6801 |     21.566 |   1.0288 |     31.266 |     1.8
   47 |   0.6541 |     20.825 |   1.0256 |     30.503 |     1.8
   48 |   0.6285 |     19.679 |   1.0191 |     30.121 |     1.9
   49 |   0.6070 |     18.982 |   1.0361 |     30.089 |     1.9
   50 |   0.5881 |     18.291 |   1.0376 |     30.471 |     1.9
   51 |   0.5698 |     17.841 |   1.0518 |     30.439 |     2.0
   52 |   0.5499 |     17.281 |   1.0484 |     29.739 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 486,082

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4643 |     65.262 |   1.9008 |     54.803 |     0.0
    2 |   1.6516 |     47.789 |   1.4912 |     45.674 |     0.1
    3 |   1.4468 |     45.798 |   1.4078 |     46.151 |     0.1
    4 |   1.3973 |     45.781 |   1.3720 |     45.165 |     0.1
    5 |   1.3664 |     45.578 |   1.3391 |     45.165 |     0.2
    6 |   1.3352 |     45.271 |   1.3136 |     44.497 |     0.2
    7 |   1.3116 |     44.514 |   1.2957 |     44.275 |     0.2
    8 |   1.2964 |     44.218 |   1.2813 |     43.639 |     0.2
    9 |   1.2792 |     43.845 |   1.2647 |     43.734 |     0.3
   10 |   1.2612 |     43.488 |   1.2570 |     43.225 |     0.3
   11 |   1.2440 |     43.214 |   1.2443 |     42.971 |     0.3
   12 |   1.2325 |     42.956 |   1.2297 |     42.844 |     0.4
   13 |   1.2189 |     42.544 |   1.2144 |     41.730 |     0.4
   14 |   1.2055 |     42.171 |   1.2070 |     41.571 |     0.4
   15 |   1.1909 |     41.722 |   1.1947 |     41.476 |     0.5
   16 |   1.1780 |     41.639 |   1.1881 |     41.889 |     0.5
   17 |   1.1650 |     41.069 |   1.1721 |     40.808 |     0.5
   18 |   1.1507 |     40.509 |   1.1598 |     41.031 |     0.6
   19 |   1.1344 |     40.103 |   1.1519 |     41.349 |     0.6
   20 |   1.1250 |     39.829 |   1.1508 |     39.885 |     0.6
   21 |   1.1103 |     39.291 |   1.1307 |     39.090 |     0.6
   22 |   1.0966 |     38.540 |   1.1191 |     39.695 |     0.7
   23 |   1.0851 |     38.254 |   1.1120 |     38.518 |     0.7
   24 |   1.0731 |     37.596 |   1.0999 |     38.263 |     0.7
   25 |   1.0578 |     37.036 |   1.0966 |     37.405 |     0.8
   26 |   1.0478 |     36.691 |   1.0852 |     36.832 |     0.8
   27 |   1.0374 |     36.504 |   1.0781 |     36.005 |     0.8
   28 |   1.0228 |     35.851 |   1.0678 |     36.132 |     0.9
   29 |   1.0100 |     35.105 |   1.0608 |     35.878 |     0.9
   30 |   0.9973 |     34.562 |   1.0436 |     34.860 |     0.9
   31 |   0.9876 |     34.140 |   1.0515 |     35.464 |     1.0
   32 |   0.9793 |     34.085 |   1.0505 |     36.228 |     1.0
   33 |   0.9656 |     33.322 |   1.0377 |     35.019 |     1.0
   34 |   0.9512 |     32.543 |   1.0306 |     35.242 |     1.0
   35 |   0.9368 |     32.110 |   1.0193 |     34.256 |     1.1
   36 |   0.9244 |     31.545 |   1.0169 |     34.097 |     1.1
   37 |   0.9169 |     31.325 |   1.0099 |     33.779 |     1.1
   38 |   0.8994 |     30.634 |   1.0018 |     33.747 |     1.2
   39 |   0.8925 |     30.162 |   0.9987 |     32.983 |     1.2
   40 |   0.8819 |     30.042 |   1.0052 |     33.779 |     1.2
   41 |   0.8615 |     29.065 |   0.9866 |     32.570 |     1.3
   42 |   0.8511 |     28.632 |   0.9899 |     33.461 |     1.3
   43 |   0.8374 |     28.220 |   0.9720 |     32.475 |     1.3
   44 |   0.8196 |     27.853 |   0.9754 |     32.443 |     1.4
   45 |   0.8075 |     27.145 |   0.9747 |     31.966 |     1.4
   46 |   0.7965 |     26.750 |   0.9630 |     31.361 |     1.4
   47 |   0.7764 |     25.680 |   0.9586 |     31.457 |     1.4
   48 |   0.7615 |     25.313 |   0.9736 |     31.934 |     1.5
   49 |   0.7600 |     25.192 |   0.9562 |     31.393 |     1.5
   50 |   0.7440 |     24.539 |   0.9623 |     31.330 |     1.5
   51 |   0.7210 |     23.519 |   0.9619 |     31.170 |     1.6
   52 |   0.7048 |     23.036 |   0.9551 |     30.725 |     1.6
   53 |   0.6879 |     22.120 |   0.9445 |     30.089 |     1.6
   54 |   0.6699 |     21.769 |   0.9844 |     30.852 |     1.7
   55 |   0.6712 |     21.840 |   0.9456 |     29.644 |     1.7
   56 |   0.6461 |     20.809 |   0.9654 |     29.994 |     1.7
   57 |   0.6473 |     21.006 |   0.9546 |     29.866 |     1.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,213,154

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5215 |     67.550 |   2.0009 |     56.997 |     0.1
    2 |   1.7619 |     49.457 |   1.5613 |     45.802 |     0.1
    3 |   1.4943 |     46.187 |   1.4364 |     45.802 |     0.2
    4 |   1.4245 |     46.105 |   1.3931 |     45.802 |     0.2
    5 |   1.3907 |     45.940 |   1.3609 |     45.642 |     0.3
    6 |   1.3574 |     45.661 |   1.3301 |     44.911 |     0.3
    7 |   1.3323 |     45.364 |   1.3178 |     45.165 |     0.4
    8 |   1.3134 |     45.052 |   1.2974 |     44.307 |     0.4
    9 |   1.2966 |     44.294 |   1.2870 |     44.211 |     0.5
   10 |   1.2811 |     44.015 |   1.2684 |     43.575 |     0.6
   11 |   1.2648 |     43.834 |   1.2545 |     43.798 |     0.6
   12 |   1.2508 |     43.625 |   1.2446 |     43.098 |     0.7
   13 |   1.2344 |     43.038 |   1.2232 |     43.511 |     0.7
   14 |   1.2188 |     42.528 |   1.2119 |     41.985 |     0.8
   15 |   1.2038 |     42.073 |   1.2034 |     42.239 |     0.8
   16 |   1.1896 |     41.398 |   1.1923 |     42.048 |     0.9
   17 |   1.1771 |     41.217 |   1.1795 |     41.858 |     1.0
   18 |   1.1653 |     40.750 |   1.1707 |     42.335 |     1.0
   19 |   1.1548 |     40.696 |   1.1550 |     40.490 |     1.1
   20 |   1.1448 |     40.087 |   1.1519 |     40.712 |     1.1
   21 |   1.1369 |     40.207 |   1.1505 |     40.553 |     1.2
   22 |   1.1270 |     39.851 |   1.1515 |     40.744 |     1.2
   23 |   1.1221 |     39.615 |   1.1427 |     40.522 |     1.3
   24 |   1.1122 |     39.352 |   1.1293 |     39.631 |     1.3
   25 |   1.1032 |     39.269 |   1.1230 |     39.726 |     1.4
   26 |   1.0959 |     38.693 |   1.1213 |     39.504 |     1.5
   27 |   1.0926 |     38.743 |   1.1196 |     39.281 |     1.5
   28 |   1.0870 |     38.638 |   1.1125 |     38.804 |     1.6
   29 |   1.0783 |     38.221 |   1.1074 |     40.331 |     1.6
   30 |   1.0710 |     37.975 |   1.0989 |     38.868 |     1.7
   31 |   1.0636 |     37.794 |   1.0954 |     38.486 |     1.7
   32 |   1.0553 |     37.442 |   1.0947 |     38.677 |     1.8
   33 |   1.0514 |     37.377 |   1.0898 |     39.059 |     1.8
   34 |   1.0422 |     36.899 |   1.0938 |     38.868 |     1.9
   35 |   1.0375 |     36.905 |   1.0786 |     38.931 |     2.0
   36 |   1.0279 |     36.296 |   1.0760 |     38.359 |     2.0
   37 |   1.0195 |     35.972 |   1.0768 |     38.486 |     2.1
   38 |   1.0136 |     35.692 |   1.0631 |     36.832 |     2.1
   39 |   1.0045 |     35.193 |   1.0608 |     36.927 |     2.2
   40 |   0.9985 |     35.226 |   1.0631 |     36.609 |     2.2
   41 |   0.9929 |     34.979 |   1.0575 |     36.737 |     2.3
   42 |   0.9853 |     34.606 |   1.0536 |     36.323 |     2.3
   43 |   0.9734 |     34.079 |   1.0463 |     35.814 |     2.4
   44 |   0.9690 |     33.811 |   1.0551 |     35.941 |     2.5
   45 |   0.9607 |     33.630 |   1.0324 |     34.924 |     2.5
   46 |   0.9501 |     33.130 |   1.0263 |     34.478 |     2.6
   47 |   0.9420 |     32.927 |   1.0228 |     35.178 |     2.6
   48 |   0.9359 |     32.494 |   1.0194 |     34.256 |     2.7
   49 |   0.9277 |     32.340 |   1.0286 |     34.669 |     2.7
   50 |   0.9212 |     31.907 |   1.0274 |     34.192 |     2.8
   51 |   0.9127 |     31.644 |   1.0268 |     34.860 |     2.8
   52 |   0.9026 |     31.314 |   1.0155 |     34.924 |     2.9
   53 |   0.8895 |     30.799 |   1.0180 |     33.683 |     3.0
   54 |   0.8825 |     30.376 |   1.0068 |     33.524 |     3.0
   55 |   0.8710 |     29.866 |   0.9982 |     33.111 |     3.1
   56 |   0.8621 |     29.521 |   1.0048 |     33.397 |     3.1
   57 |   0.8597 |     29.449 |   1.0061 |     33.683 |     3.2
   58 |   0.8431 |     28.835 |   0.9857 |     32.952 |     3.2
   59 |   0.8324 |     28.330 |   0.9941 |     32.920 |     3.3
   60 |   0.8229 |     27.738 |   0.9845 |     32.379 |     3.4
   61 |   0.8090 |     27.375 |   0.9963 |     31.870 |     3.4
   62 |   0.7975 |     26.750 |   0.9891 |     32.316 |     3.5
   63 |   0.7843 |     26.481 |   0.9913 |     31.520 |     3.5
   64 |   0.7713 |     25.933 |   0.9962 |     31.139 |     3.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,063,746

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2364 |     61.367 |   1.6166 |     45.802 |     0.0
    2 |   1.4886 |     46.160 |   1.4115 |     45.802 |     0.1
    3 |   1.4077 |     46.313 |   1.3793 |     45.802 |     0.1
    4 |   1.3759 |     45.979 |   1.3502 |     45.770 |     0.2
    5 |   1.3430 |     45.567 |   1.3246 |     46.088 |     0.2
    6 |   1.3176 |     45.447 |   1.2990 |     45.293 |     0.2
    7 |   1.3007 |     45.309 |   1.2933 |     45.547 |     0.3
    8 |   1.2901 |     44.887 |   1.2831 |     44.847 |     0.3
    9 |   1.2778 |     44.838 |   1.2769 |     45.102 |     0.4
   10 |   1.2668 |     44.415 |   1.2620 |     44.243 |     0.4
   11 |   1.2609 |     44.519 |   1.2587 |     44.243 |     0.4
   12 |   1.2518 |     44.294 |   1.2396 |     43.480 |     0.5
   13 |   1.2344 |     43.631 |   1.2255 |     43.543 |     0.5
   14 |   1.2192 |     43.142 |   1.2110 |     42.430 |     0.6
   15 |   1.2029 |     42.824 |   1.1975 |     42.303 |     0.6
   16 |   1.1890 |     42.281 |   1.1788 |     41.889 |     0.6
   17 |   1.1715 |     41.881 |   1.1717 |     41.412 |     0.7
   18 |   1.1565 |     41.392 |   1.1661 |     41.698 |     0.7
   19 |   1.1477 |     41.392 |   1.1486 |     40.840 |     0.8
   20 |   1.1255 |     40.531 |   1.1344 |     40.999 |     0.8
   21 |   1.1201 |     40.328 |   1.1237 |     40.140 |     0.8
   22 |   1.1023 |     39.308 |   1.1114 |     39.854 |     0.9
   23 |   1.0846 |     39.198 |   1.1034 |     38.486 |     0.9
   24 |   1.0667 |     38.287 |   1.0888 |     38.709 |     1.0
   25 |   1.0508 |     37.848 |   1.0762 |     37.246 |     1.0
   26 |   1.0323 |     36.680 |   1.0627 |     37.277 |     1.0
   27 |   1.0097 |     35.945 |   1.0464 |     35.846 |     1.1
   28 |   0.9933 |     35.259 |   1.0442 |     36.005 |     1.1
   29 |   0.9791 |     34.869 |   1.0537 |     36.228 |     1.2
   30 |   0.9632 |     33.778 |   1.0283 |     35.528 |     1.2
   31 |   0.9414 |     33.004 |   1.0158 |     34.001 |     1.2
   32 |   0.9201 |     32.154 |   1.0098 |     33.969 |     1.3
   33 |   0.8996 |     31.298 |   1.0023 |     33.238 |     1.3
   34 |   0.8827 |     30.678 |   0.9851 |     33.111 |     1.4
   35 |   0.8606 |     29.811 |   0.9872 |     32.602 |     1.4
   36 |   0.8422 |     29.147 |   0.9697 |     32.634 |     1.4
   37 |   0.8198 |     28.072 |   0.9715 |     31.934 |     1.5
   38 |   0.8031 |     27.622 |   0.9580 |     31.520 |     1.5
   39 |   0.7841 |     26.750 |   0.9537 |     31.011 |     1.6
   40 |   0.7603 |     25.735 |   0.9479 |     30.821 |     1.6
   41 |   0.7469 |     25.307 |   0.9466 |     30.693 |     1.7
   42 |   0.7282 |     24.627 |   0.9569 |     30.852 |     1.7
   43 |   0.7053 |     23.420 |   0.9403 |     29.803 |     1.7
   44 |   0.6809 |     22.701 |   0.9314 |     29.294 |     1.8
   45 |   0.6599 |     21.846 |   0.9375 |     29.262 |     1.8
   46 |   0.6382 |     21.056 |   0.9298 |     28.817 |     1.9
   47 |   0.6197 |     20.545 |   0.9399 |     29.135 |     1.9
   48 |   0.6046 |     19.876 |   0.9578 |     29.548 |     1.9
   49 |   0.5915 |     19.382 |   0.9342 |     28.690 |     2.0
   50 |   0.5668 |     18.691 |   0.9333 |     28.085 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,248,290

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4165 |     65.657 |   1.8835 |     53.053 |     0.1
    2 |   1.6585 |     48.025 |   1.4984 |     45.802 |     0.1
    3 |   1.4471 |     46.006 |   1.3937 |     46.374 |     0.2
    4 |   1.3761 |     45.639 |   1.3430 |     44.593 |     0.2
    5 |   1.3356 |     44.700 |   1.3156 |     44.975 |     0.3
    6 |   1.3108 |     44.399 |   1.2930 |     43.639 |     0.3
    7 |   1.2882 |     43.856 |   1.2697 |     43.289 |     0.4
    8 |   1.2681 |     43.433 |   1.2593 |     43.480 |     0.5
    9 |   1.2462 |     43.000 |   1.2337 |     43.130 |     0.5
   10 |   1.2218 |     42.501 |   1.2170 |     42.239 |     0.6
   11 |   1.2008 |     41.667 |   1.1981 |     41.253 |     0.6
   12 |   1.1809 |     41.047 |   1.1797 |     40.967 |     0.7
   13 |   1.1574 |     40.098 |   1.1710 |     40.299 |     0.8
   14 |   1.1307 |     39.011 |   1.1537 |     39.726 |     0.8
   15 |   1.1066 |     37.931 |   1.1380 |     39.377 |     0.9
   16 |   1.0768 |     36.833 |   1.1223 |     38.295 |     0.9
   17 |   1.0460 |     35.456 |   1.1120 |     38.168 |     1.0
   18 |   1.0148 |     34.584 |   1.0906 |     37.214 |     1.0
   19 |   0.9785 |     32.993 |   1.0682 |     36.514 |     1.1
   20 |   0.9390 |     31.463 |   1.0482 |     34.860 |     1.2
   21 |   0.9052 |     30.042 |   1.0330 |     33.429 |     1.2
   22 |   0.8644 |     28.643 |   1.0312 |     34.033 |     1.3
   23 |   0.8218 |     27.046 |   1.0201 |     32.793 |     1.3
   24 |   0.7821 |     25.368 |   1.0079 |     31.902 |     1.4
   25 |   0.7409 |     23.738 |   1.0139 |     31.520 |     1.5
   26 |   0.7026 |     22.284 |   1.0147 |     31.075 |     1.5
   27 |   0.6609 |     20.842 |   1.0102 |     31.170 |     1.6
   28 |   0.6204 |     19.668 |   1.0003 |     30.153 |     1.6
   29 |   0.5812 |     17.939 |   1.0055 |     29.962 |     1.7
   30 |   0.5409 |     16.508 |   0.9889 |     28.976 |     1.7
   31 |   0.5031 |     15.328 |   1.0327 |     29.135 |     1.8
   32 |   0.4751 |     14.319 |   1.0311 |     28.849 |     1.9
   33 |   0.4401 |     13.134 |   1.0262 |     28.435 |     1.9
   34 |   0.4121 |     12.278 |   1.0457 |     28.912 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,955,874

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0852 |     56.512 |   1.5523 |     45.802 |     0.1
    2 |   1.4543 |     46.176 |   1.3866 |     45.802 |     0.2
    3 |   1.3677 |     45.770 |   1.3345 |     45.388 |     0.2
    4 |   1.3288 |     45.002 |   1.3103 |     44.656 |     0.3
    5 |   1.2993 |     44.585 |   1.2891 |     44.656 |     0.4
    6 |   1.2764 |     44.168 |   1.2646 |     43.989 |     0.5
    7 |   1.2520 |     43.740 |   1.2396 |     43.321 |     0.5
    8 |   1.2258 |     42.923 |   1.2208 |     43.989 |     0.6
    9 |   1.2007 |     42.149 |   1.1982 |     42.017 |     0.7
   10 |   1.1816 |     41.749 |   1.1820 |     42.366 |     0.8
   11 |   1.1647 |     41.288 |   1.1632 |     41.285 |     0.8
   12 |   1.1441 |     40.427 |   1.1488 |     41.062 |     0.9
   13 |   1.1254 |     39.626 |   1.1325 |     39.758 |     1.0
   14 |   1.1049 |     39.000 |   1.1206 |     39.631 |     1.1
   15 |   1.0851 |     38.040 |   1.1046 |     39.090 |     1.1
   16 |   1.0690 |     37.667 |   1.0903 |     38.486 |     1.2
   17 |   1.0496 |     36.647 |   1.0884 |     38.518 |     1.3
   18 |   1.0279 |     35.698 |   1.0755 |     37.659 |     1.4
   19 |   1.0049 |     34.721 |   1.0505 |     36.260 |     1.4
   20 |   0.9833 |     33.778 |   1.0410 |     35.655 |     1.5
   21 |   0.9559 |     32.494 |   1.0149 |     34.478 |     1.6
   22 |   0.9274 |     31.413 |   0.9973 |     33.524 |     1.7
   23 |   0.8974 |     30.673 |   0.9881 |     33.492 |     1.7
   24 |   0.8711 |     29.680 |   0.9753 |     33.174 |     1.8
   25 |   0.8383 |     28.401 |   0.9694 |     31.902 |     1.9
   26 |   0.8154 |     27.414 |   0.9554 |     32.475 |     2.0
   27 |   0.7826 |     26.377 |   0.9412 |     31.139 |     2.0
   28 |   0.7443 |     24.781 |   0.9437 |     31.234 |     2.1
   29 |   0.7168 |     23.952 |   0.9267 |     30.693 |     2.2
   30 |   0.6872 |     22.718 |   0.9249 |     30.025 |     2.3
   31 |   0.6581 |     21.851 |   0.9057 |     28.340 |     2.3
   32 |   0.6316 |     20.814 |   0.9134 |     29.262 |     2.4
   33 |   0.6052 |     19.986 |   0.9205 |     29.167 |     2.5
   34 |   0.5722 |     18.724 |   0.9176 |     28.244 |     2.6
   35 |   0.5479 |     17.786 |   0.9322 |     28.276 |     2.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 287,938

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5359 |     67.599 |   1.9883 |     55.280 |     0.0
    2 |   1.7552 |     49.484 |   1.5570 |     45.802 |     0.0
    3 |   1.4922 |     46.105 |   1.4422 |     45.802 |     0.0
    4 |   1.4309 |     46.061 |   1.4123 |     46.533 |     0.1
    5 |   1.4073 |     46.077 |   1.3913 |     45.802 |     0.1
    6 |   1.3876 |     46.061 |   1.3656 |     45.802 |     0.1
    7 |   1.3682 |     45.639 |   1.3508 |     45.802 |     0.1
    8 |   1.3488 |     45.474 |   1.3312 |     45.102 |     0.1
    9 |   1.3300 |     45.030 |   1.3152 |     45.420 |     0.1
   10 |   1.3108 |     44.755 |   1.2991 |     44.370 |     0.2
   11 |   1.2928 |     44.393 |   1.2797 |     44.720 |     0.2
   12 |   1.2774 |     43.954 |   1.2637 |     44.338 |     0.2
   13 |   1.2632 |     43.691 |   1.2544 |     44.211 |     0.2
   14 |   1.2490 |     43.022 |   1.2409 |     43.734 |     0.2
   15 |   1.2360 |     42.978 |   1.2213 |     42.494 |     0.2
   16 |   1.2193 |     42.396 |   1.2114 |     41.730 |     0.3
   17 |   1.2065 |     42.100 |   1.2011 |     41.412 |     0.3
   18 |   1.1916 |     41.359 |   1.1914 |     41.667 |     0.3
   19 |   1.1766 |     40.926 |   1.1823 |     41.253 |     0.3
   20 |   1.1592 |     40.169 |   1.1648 |     40.903 |     0.3
   21 |   1.1438 |     39.725 |   1.1560 |     40.394 |     0.3
   22 |   1.1261 |     38.907 |   1.1531 |     40.013 |     0.4
   23 |   1.1104 |     38.331 |   1.1410 |     39.599 |     0.4
   24 |   1.0919 |     37.810 |   1.1312 |     39.472 |     0.4
   25 |   1.0754 |     37.437 |   1.1283 |     39.631 |     0.4
   26 |   1.0564 |     36.707 |   1.1081 |     37.691 |     0.4
   27 |   1.0388 |     35.862 |   1.0966 |     38.518 |     0.4
   28 |   1.0163 |     34.716 |   1.0939 |     36.641 |     0.5
   29 |   0.9967 |     33.871 |   1.0747 |     35.814 |     0.5
   30 |   0.9768 |     33.262 |   1.0713 |     36.005 |     0.5
   31 |   0.9577 |     32.220 |   1.0667 |     35.401 |     0.5
   32 |   0.9307 |     31.457 |   1.0630 |     35.496 |     0.5
   33 |   0.9111 |     30.727 |   1.0475 |     34.892 |     0.5
   34 |   0.9003 |     30.289 |   1.0440 |     34.606 |     0.6
   35 |   0.8704 |     28.983 |   1.0311 |     33.874 |     0.6
   36 |   0.8465 |     28.144 |   1.0343 |     33.747 |     0.6
   37 |   0.8293 |     27.397 |   1.0315 |     34.033 |     0.6
   38 |   0.8045 |     26.531 |   1.0280 |     33.365 |     0.6
   39 |   0.7924 |     26.322 |   1.0412 |     33.683 |     0.6
   40 |   0.7728 |     25.483 |   1.0262 |     32.952 |     0.7
   41 |   0.7512 |     24.556 |   1.0394 |     33.047 |     0.7
   42 |   0.7317 |     23.930 |   1.0239 |     31.711 |     0.7
   43 |   0.7276 |     23.694 |   1.0546 |     33.079 |     0.7
   44 |   0.7030 |     23.025 |   1.0306 |     31.711 |     0.7
   45 |   0.6817 |     22.087 |   1.0261 |     31.425 |     0.7
   46 |   0.6634 |     21.352 |   1.0485 |     31.298 |     0.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,955,874

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0595 |     55.700 |   1.5262 |     45.802 |     0.1
    2 |   1.4303 |     45.951 |   1.3738 |     46.183 |     0.2
    3 |   1.3502 |     45.359 |   1.3212 |     46.088 |     0.2
    4 |   1.3115 |     44.624 |   1.2854 |     43.639 |     0.3
    5 |   1.2832 |     44.163 |   1.2608 |     43.575 |     0.4
    6 |   1.2544 |     43.537 |   1.2431 |     43.066 |     0.5
    7 |   1.2303 |     42.912 |   1.2265 |     42.557 |     0.5
    8 |   1.2035 |     42.330 |   1.1938 |     42.239 |     0.6
    9 |   1.1721 |     41.025 |   1.1745 |     40.872 |     0.7
   10 |   1.1467 |     40.021 |   1.1473 |     38.963 |     0.8
   11 |   1.1049 |     38.062 |   1.1318 |     38.518 |     0.8
   12 |   1.0596 |     36.268 |   1.0788 |     36.291 |     0.9
   13 |   1.0097 |     34.206 |   1.0437 |     34.542 |     1.0
   14 |   0.9624 |     32.351 |   1.0194 |     34.128 |     1.1
   15 |   0.9089 |     30.113 |   1.0144 |     34.001 |     1.2
   16 |   0.8583 |     28.456 |   0.9869 |     33.047 |     1.2
   17 |   0.8000 |     26.048 |   0.9610 |     31.552 |     1.3
   18 |   0.7434 |     23.870 |   0.9547 |     30.439 |     1.4
   19 |   0.7004 |     22.531 |   0.9452 |     30.184 |     1.5
   20 |   0.6395 |     20.183 |   0.9380 |     29.358 |     1.5
   21 |   0.5983 |     19.360 |   0.9399 |     29.071 |     1.6
   22 |   0.5406 |     16.820 |   0.9428 |     28.531 |     1.7
   23 |   0.4936 |     15.207 |   0.9699 |     28.372 |     1.8
   24 |   0.4368 |     13.370 |   0.9532 |     27.481 |     1.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 388,930

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3622 |     61.795 |   1.7947 |     49.841 |     0.0
    2 |   1.6073 |     47.690 |   1.4694 |     45.420 |     0.1
    3 |   1.4267 |     45.787 |   1.3737 |     45.547 |     0.1
    4 |   1.3578 |     45.732 |   1.3216 |     44.816 |     0.1
    5 |   1.3145 |     44.777 |   1.2886 |     44.529 |     0.1
    6 |   1.2817 |     44.004 |   1.2634 |     44.052 |     0.2
    7 |   1.2551 |     43.389 |   1.2354 |     42.971 |     0.2
    8 |   1.2296 |     42.780 |   1.2152 |     42.239 |     0.2
    9 |   1.2069 |     42.330 |   1.1955 |     41.508 |     0.2
   10 |   1.1890 |     41.546 |   1.1824 |     41.508 |     0.3
   11 |   1.1724 |     41.244 |   1.1668 |     41.730 |     0.3
   12 |   1.1572 |     40.663 |   1.1584 |     40.553 |     0.3
   13 |   1.1447 |     40.273 |   1.1513 |     40.585 |     0.3
   14 |   1.1332 |     40.142 |   1.1376 |     39.949 |     0.3
   15 |   1.1228 |     39.555 |   1.1338 |     40.935 |     0.4
   16 |   1.1118 |     39.105 |   1.1336 |     39.917 |     0.4
   17 |   1.1037 |     38.968 |   1.1226 |     40.140 |     0.4
   18 |   1.0912 |     38.381 |   1.1110 |     39.027 |     0.4
   19 |   1.0836 |     38.578 |   1.1017 |     38.327 |     0.5
   20 |   1.0746 |     37.920 |   1.1005 |     38.327 |     0.5
   21 |   1.0664 |     37.953 |   1.0921 |     38.645 |     0.5
   22 |   1.0574 |     37.552 |   1.0849 |     37.532 |     0.5
   23 |   1.0465 |     37.097 |   1.0861 |     37.627 |     0.6
   24 |   1.0431 |     37.141 |   1.0785 |     38.550 |     0.6
   25 |   1.0312 |     36.537 |   1.0715 |     37.214 |     0.6
   26 |   1.0188 |     35.654 |   1.0625 |     37.500 |     0.6
   27 |   1.0130 |     35.802 |   1.0586 |     36.705 |     0.7
   28 |   1.0029 |     35.319 |   1.0497 |     36.578 |     0.7
   29 |   0.9935 |     34.837 |   1.0504 |     36.355 |     0.7
   30 |   0.9837 |     34.601 |   1.0393 |     35.973 |     0.7
   31 |   0.9713 |     34.057 |   1.0365 |     36.260 |     0.8
   32 |   0.9631 |     33.767 |   1.0299 |     35.878 |     0.8
   33 |   0.9514 |     33.586 |   1.0328 |     35.242 |     0.8
   34 |   0.9442 |     32.911 |   1.0226 |     35.464 |     0.8
   35 |   0.9314 |     32.505 |   1.0181 |     35.719 |     0.9
   36 |   0.9244 |     32.467 |   1.0162 |     35.146 |     0.9
   37 |   0.9117 |     31.709 |   0.9999 |     33.556 |     0.9
   38 |   0.8996 |     31.282 |   0.9928 |     34.097 |     0.9
   39 |   0.8886 |     30.645 |   0.9985 |     34.256 |     1.0
   40 |   0.8788 |     30.338 |   0.9900 |     34.160 |     1.0
   41 |   0.8639 |     29.674 |   0.9821 |     32.888 |     1.0
   42 |   0.8521 |     29.488 |   0.9836 |     33.715 |     1.0
   43 |   0.8400 |     28.862 |   0.9774 |     33.333 |     1.1
   44 |   0.8270 |     28.050 |   0.9789 |     33.047 |     1.1
   45 |   0.8208 |     28.182 |   0.9741 |     32.506 |     1.1
   46 |   0.8077 |     27.589 |   0.9847 |     32.570 |     1.1
   47 |   0.8112 |     27.655 |   0.9687 |     32.538 |     1.2
   48 |   0.7872 |     26.684 |   0.9585 |     31.711 |     1.2
   49 |   0.7726 |     26.037 |   0.9523 |     31.202 |     1.2
   50 |   0.7558 |     25.614 |   0.9475 |     31.011 |     1.2
   51 |   0.7453 |     24.907 |   0.9455 |     30.789 |     1.3
   52 |   0.7347 |     24.600 |   0.9424 |     30.916 |     1.3
   53 |   0.7248 |     24.649 |   0.9653 |     30.916 |     1.3
   54 |   0.7110 |     23.820 |   0.9436 |     30.503 |     1.3
   55 |   0.7009 |     23.546 |   0.9430 |     30.216 |     1.4
   56 |   0.6861 |     22.866 |   0.9306 |     29.930 |     1.4
   57 |   0.6704 |     22.734 |   0.9430 |     30.057 |     1.4
   58 |   0.6698 |     22.471 |   0.9390 |     29.167 |     1.4
   59 |   0.6488 |     21.643 |   0.9342 |     28.912 |     1.5
   60 |   0.6421 |     21.259 |   0.9502 |     29.898 |     1.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,606,978

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4844 |     66.881 |   1.9505 |     54.230 |     0.1
    2 |   1.7567 |     49.868 |   1.5790 |     45.802 |     0.1
    3 |   1.5012 |     46.198 |   1.4466 |     45.802 |     0.2
    4 |   1.4293 |     46.105 |   1.4023 |     45.802 |     0.3
    5 |   1.3954 |     46.110 |   1.3661 |     45.802 |     0.4
    6 |   1.3613 |     45.940 |   1.3410 |     46.788 |     0.4
    7 |   1.3345 |     45.710 |   1.3131 |     45.515 |     0.5
    8 |   1.3125 |     44.854 |   1.2912 |     43.989 |     0.6
    9 |   1.2902 |     44.305 |   1.2735 |     43.575 |     0.7
   10 |   1.2674 |     43.587 |   1.2562 |     42.780 |     0.7
   11 |   1.2482 |     43.016 |   1.2371 |     43.003 |     0.8
   12 |   1.2308 |     42.522 |   1.2217 |     42.176 |     0.9
   13 |   1.2140 |     42.001 |   1.2068 |     42.017 |     1.0
   14 |   1.2014 |     41.601 |   1.1991 |     42.017 |     1.0
   15 |   1.1864 |     40.992 |   1.1891 |     42.017 |     1.1
   16 |   1.1696 |     40.350 |   1.1725 |     41.190 |     1.2
   17 |   1.1522 |     39.933 |   1.1618 |     40.172 |     1.3
   18 |   1.1350 |     39.341 |   1.1476 |     39.822 |     1.3
   19 |   1.1166 |     38.869 |   1.1363 |     39.790 |     1.4
   20 |   1.1014 |     38.282 |   1.1311 |     38.613 |     1.5
   21 |   1.0830 |     37.645 |   1.1284 |     38.327 |     1.6
   22 |   1.0661 |     36.828 |   1.1206 |     38.486 |     1.6
   23 |   1.0479 |     36.417 |   1.1012 |     37.436 |     1.7
   24 |   1.0299 |     35.237 |   1.0977 |     37.055 |     1.8
   25 |   1.0127 |     34.727 |   1.0895 |     36.959 |     1.9
   26 |   0.9929 |     33.849 |   1.0756 |     36.228 |     1.9
   27 |   0.9722 |     33.257 |   1.0616 |     35.973 |     2.0
   28 |   0.9519 |     32.587 |   1.0637 |     35.687 |     2.1
   29 |   0.9269 |     31.166 |   1.0582 |     35.560 |     2.2
   30 |   0.9107 |     30.766 |   1.0551 |     35.401 |     2.2
   31 |   0.8900 |     29.806 |   1.0537 |     34.701 |     2.3
   32 |   0.8626 |     28.659 |   1.0580 |     34.288 |     2.4
   33 |   0.8380 |     27.639 |   1.0519 |     34.319 |     2.5
   34 |   0.8130 |     26.986 |   1.0624 |     34.383 |     2.5
   35 |   0.8009 |     26.289 |   1.0511 |     33.906 |     2.6
   36 |   0.7800 |     25.417 |   1.0442 |     33.302 |     2.7
   37 |   0.7477 |     24.292 |   1.0544 |     32.856 |     2.8
   38 |   0.7236 |     23.277 |   1.0446 |     32.634 |     2.8
   39 |   0.6958 |     22.273 |   1.0562 |     33.015 |     2.9
   40 |   0.6718 |     21.242 |   1.0428 |     31.679 |     3.0
   41 |   0.6479 |     20.458 |   1.0423 |     31.139 |     3.1
   42 |   0.6170 |     19.327 |   1.0639 |     31.934 |     3.1
   43 |   0.5928 |     18.515 |   1.0455 |     31.425 |     3.2
   44 |   0.5724 |     17.797 |   1.0593 |     30.598 |     3.3
   45 |   0.5462 |     17.100 |   1.0991 |     31.457 |     3.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 604,386

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1073 |     57.790 |   1.5126 |     45.420 |     0.0
    2 |   1.4186 |     45.726 |   1.3510 |     44.688 |     0.1
    3 |   1.3327 |     44.849 |   1.3017 |     44.625 |     0.1
    4 |   1.2962 |     44.393 |   1.2718 |     44.179 |     0.1
    5 |   1.2663 |     43.790 |   1.2405 |     43.702 |     0.1
    6 |   1.2353 |     43.164 |   1.2211 |     42.207 |     0.2
    7 |   1.2075 |     42.177 |   1.1949 |     41.476 |     0.2
    8 |   1.1762 |     41.469 |   1.1684 |     40.903 |     0.2
    9 |   1.1471 |     39.966 |   1.1464 |     39.790 |     0.2
   10 |   1.1180 |     39.198 |   1.1248 |     39.663 |     0.3
   11 |   1.0879 |     38.013 |   1.0879 |     38.200 |     0.3
   12 |   1.0521 |     36.493 |   1.0587 |     36.291 |     0.3
   13 |   1.0242 |     35.374 |   1.0579 |     36.037 |     0.3
   14 |   0.9923 |     34.502 |   1.0346 |     33.715 |     0.4
   15 |   0.9617 |     32.845 |   1.0006 |     33.779 |     0.4
   16 |   0.9263 |     31.666 |   0.9811 |     32.793 |     0.4
   17 |   0.8923 |     30.047 |   0.9559 |     31.457 |     0.4
   18 |   0.8611 |     29.504 |   0.9436 |     31.361 |     0.5
   19 |   0.8285 |     27.990 |   0.9350 |     31.616 |     0.5
   20 |   0.7951 |     26.767 |   0.9311 |     30.693 |     0.5
   21 |   0.7695 |     25.790 |   0.9039 |     29.930 |     0.5
   22 |   0.7335 |     24.468 |   0.9029 |     29.866 |     0.6
   23 |   0.7067 |     23.585 |   0.8968 |     29.135 |     0.6
   24 |   0.6680 |     21.939 |   0.8913 |     28.435 |     0.6
   25 |   0.6450 |     21.242 |   0.8726 |     27.258 |     0.7
   26 |   0.6228 |     20.556 |   0.8816 |     27.990 |     0.7
   27 |   0.5916 |     19.558 |   0.8820 |     26.877 |     0.7
   28 |   0.5678 |     18.702 |   0.8740 |     27.608 |     0.7
   29 |   0.5441 |     17.950 |   0.8750 |     26.431 |     0.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 834,978

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4889 |     66.096 |   1.9693 |     58.810 |     0.0
    2 |   1.7551 |     49.989 |   1.5680 |     45.802 |     0.1
    3 |   1.5076 |     46.138 |   1.4513 |     46.533 |     0.1
    4 |   1.4371 |     46.204 |   1.4117 |     45.802 |     0.2
    5 |   1.4103 |     46.083 |   1.3919 |     45.802 |     0.2
    6 |   1.3921 |     46.099 |   1.3770 |     45.802 |     0.2
    7 |   1.3737 |     45.924 |   1.3537 |     44.784 |     0.3
    8 |   1.3535 |     45.622 |   1.3484 |     46.056 |     0.3
    9 |   1.3345 |     45.353 |   1.3178 |     44.943 |     0.4
   10 |   1.3178 |     44.953 |   1.2985 |     44.243 |     0.4
   11 |   1.2992 |     44.349 |   1.2817 |     44.688 |     0.4
   12 |   1.2812 |     44.355 |   1.2648 |     43.639 |     0.5
   13 |   1.2619 |     43.587 |   1.2479 |     43.225 |     0.5
   14 |   1.2436 |     42.950 |   1.2368 |     43.702 |     0.6
   15 |   1.2296 |     42.292 |   1.2280 |     42.939 |     0.6
   16 |   1.2141 |     41.881 |   1.2072 |     42.080 |     0.6
   17 |   1.1972 |     41.568 |   1.1960 |     41.508 |     0.7
   18 |   1.1830 |     40.959 |   1.1908 |     41.826 |     0.7
   19 |   1.1721 |     40.674 |   1.1799 |     41.126 |     0.8
   20 |   1.1530 |     40.279 |   1.1673 |     42.017 |     0.8
   21 |   1.1378 |     39.719 |   1.1520 |     40.331 |     0.8
   22 |   1.1217 |     39.324 |   1.1461 |     40.108 |     0.9
   23 |   1.1054 |     38.754 |   1.1363 |     40.458 |     0.9
   24 |   1.0910 |     37.980 |   1.1324 |     40.013 |     1.0
   25 |   1.0716 |     37.475 |   1.1153 |     38.550 |     1.0
   26 |   1.0558 |     36.943 |   1.1242 |     39.249 |     1.0
   27 |   1.0378 |     36.148 |   1.1077 |     38.899 |     1.1
   28 |   1.0202 |     35.462 |   1.1020 |     38.041 |     1.1
   29 |   0.9996 |     34.359 |   1.0864 |     37.468 |     1.2
   30 |   0.9808 |     33.849 |   1.0828 |     37.055 |     1.2
   31 |   0.9602 |     32.823 |   1.0809 |     37.087 |     1.3
   32 |   0.9396 |     32.055 |   1.0718 |     36.832 |     1.3
   33 |   0.9244 |     31.479 |   1.0674 |     35.751 |     1.3
   34 |   0.9141 |     31.166 |   1.0544 |     35.687 |     1.4
   35 |   0.8866 |     30.135 |   1.0613 |     35.592 |     1.4
   36 |   0.8627 |     29.471 |   1.0571 |     35.337 |     1.5
   37 |   0.8390 |     28.544 |   1.0483 |     34.701 |     1.5
   38 |   0.8263 |     27.913 |   1.0613 |     34.160 |     1.5
   39 |   0.8035 |     27.068 |   1.0573 |     34.033 |     1.6
   40 |   0.7793 |     26.136 |   1.0488 |     33.270 |     1.6
   41 |   0.7582 |     25.000 |   1.0544 |     33.047 |     1.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 868,578

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1900 |     59.924 |   1.5830 |     45.802 |     0.0
    2 |   1.4703 |     46.165 |   1.4056 |     46.533 |     0.1
    3 |   1.3840 |     46.242 |   1.3560 |     45.261 |     0.1
    4 |   1.3530 |     45.699 |   1.3381 |     45.452 |     0.1
    5 |   1.3320 |     45.842 |   1.3188 |     45.452 |     0.2
    6 |   1.3071 |     45.353 |   1.3026 |     45.197 |     0.2
    7 |   1.2894 |     45.030 |   1.2819 |     45.452 |     0.2
    8 |   1.2762 |     44.514 |   1.2657 |     45.706 |     0.3
    9 |   1.2615 |     44.377 |   1.2550 |     44.020 |     0.3
   10 |   1.2424 |     43.697 |   1.2412 |     43.480 |     0.3
   11 |   1.2290 |     43.526 |   1.2149 |     42.907 |     0.4
   12 |   1.2095 |     42.605 |   1.2004 |     43.098 |     0.4
   13 |   1.1917 |     42.215 |   1.1910 |     42.684 |     0.5
   14 |   1.1734 |     41.573 |   1.1714 |     41.126 |     0.5
   15 |   1.1514 |     40.986 |   1.1633 |     40.712 |     0.5
   16 |   1.1313 |     40.120 |   1.1396 |     40.776 |     0.6
   17 |   1.1097 |     39.692 |   1.1306 |     39.981 |     0.6
   18 |   1.0860 |     38.715 |   1.1096 |     39.122 |     0.6
   19 |   1.0627 |     37.645 |   1.0911 |     38.581 |     0.7
   20 |   1.0395 |     37.014 |   1.0827 |     38.041 |     0.7
   21 |   1.0171 |     36.153 |   1.0580 |     36.037 |     0.7
   22 |   0.9897 |     34.941 |   1.0518 |     36.355 |     0.8
   23 |   0.9648 |     33.575 |   1.0431 |     35.242 |     0.8
   24 |   0.9423 |     33.163 |   1.0210 |     34.669 |     0.8
   25 |   0.9159 |     31.611 |   1.0085 |     34.351 |     0.9
   26 |   0.8859 |     30.311 |   0.9972 |     33.429 |     0.9
   27 |   0.8583 |     29.153 |   0.9898 |     31.775 |     0.9
   28 |   0.8348 |     28.308 |   0.9901 |     32.443 |     1.0
   29 |   0.8043 |     26.695 |   0.9762 |     32.093 |     1.0
   30 |   0.7812 |     26.180 |   0.9731 |     31.298 |     1.0
   31 |   0.7566 |     25.000 |   0.9639 |     31.139 |     1.1
   32 |   0.7324 |     24.002 |   0.9690 |     30.598 |     1.1
   33 |   0.7075 |     23.162 |   0.9627 |     30.248 |     1.1
   34 |   0.6861 |     22.411 |   0.9546 |     29.230 |     1.2
   35 |   0.6626 |     21.472 |   0.9570 |     29.612 |     1.2
   36 |   0.6411 |     21.083 |   0.9630 |     29.198 |     1.2
   37 |   0.6183 |     20.342 |   0.9567 |     28.785 |     1.3
   38 |   0.5974 |     19.284 |   0.9488 |     28.594 |     1.3
   39 |   0.5696 |     18.466 |   0.9627 |     28.658 |     1.3
   40 |   0.5546 |     18.088 |   0.9349 |     28.149 |     1.4
   41 |   0.5280 |     16.974 |   0.9425 |     27.640 |     1.4
   42 |   0.5119 |     16.497 |   0.9613 |     27.704 |     1.4
   43 |   0.5020 |     16.156 |   0.9774 |     27.926 |     1.5
   44 |   0.4851 |     15.635 |   0.9724 |     27.576 |     1.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 291,042

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3556 |     61.230 |   1.7184 |     48.537 |     0.0
    2 |   1.5574 |     46.791 |   1.4339 |     45.420 |     0.0
    3 |   1.3973 |     45.606 |   1.3452 |     44.975 |     0.1
    4 |   1.3370 |     44.569 |   1.3086 |     43.734 |     0.1
    5 |   1.3029 |     44.031 |   1.2803 |     43.670 |     0.1
    6 |   1.2795 |     43.746 |   1.2591 |     43.448 |     0.1
    7 |   1.2591 |     43.653 |   1.2418 |     43.607 |     0.1
    8 |   1.2391 |     43.225 |   1.2274 |     42.812 |     0.1
    9 |   1.2228 |     42.654 |   1.2077 |     41.603 |     0.2
   10 |   1.2076 |     42.210 |   1.1928 |     41.826 |     0.2
   11 |   1.1904 |     41.903 |   1.1813 |     42.207 |     0.2
   12 |   1.1761 |     41.480 |   1.1711 |     41.190 |     0.2
   13 |   1.1588 |     40.685 |   1.1562 |     41.190 |     0.2
   14 |   1.1438 |     40.224 |   1.1443 |     40.267 |     0.2
   15 |   1.1304 |     39.829 |   1.1370 |     39.917 |     0.3
   16 |   1.1189 |     39.368 |   1.1242 |     39.663 |     0.3
   17 |   1.1036 |     38.704 |   1.1101 |     39.122 |     0.3
   18 |   1.0944 |     38.216 |   1.1085 |     39.027 |     0.3
   19 |   1.0901 |     38.101 |   1.0961 |     37.945 |     0.3
   20 |   1.0704 |     37.574 |   1.0918 |     38.073 |     0.3
   21 |   1.0608 |     37.091 |   1.0756 |     37.055 |     0.4
   22 |   1.0471 |     36.510 |   1.0631 |     37.150 |     0.4
   23 |   1.0315 |     36.109 |   1.0579 |     36.419 |     0.4
   24 |   1.0235 |     35.714 |   1.0515 |     35.687 |     0.4
   25 |   1.0116 |     35.341 |   1.0418 |     35.464 |     0.4
   26 |   0.9943 |     34.321 |   1.0355 |     34.955 |     0.4
   27 |   0.9860 |     34.211 |   1.0185 |     33.969 |     0.5
   28 |   0.9746 |     33.394 |   1.0117 |     34.065 |     0.5
   29 |   0.9609 |     33.070 |   1.0017 |     33.333 |     0.5
   30 |   0.9476 |     32.807 |   0.9945 |     33.461 |     0.5
   31 |   0.9367 |     31.995 |   0.9909 |     33.206 |     0.5
   32 |   0.9223 |     30.974 |   0.9782 |     32.347 |     0.5
   33 |   0.9095 |     31.090 |   0.9755 |     32.188 |     0.6
   34 |   0.8929 |     30.332 |   0.9706 |     32.029 |     0.6
   35 |   0.8753 |     29.773 |   0.9654 |     31.457 |     0.6
   36 |   0.8684 |     29.427 |   0.9608 |     31.807 |     0.6
   37 |   0.8535 |     28.720 |   0.9476 |     31.457 |     0.6
   38 |   0.8421 |     28.341 |   0.9472 |     30.725 |     0.7
   39 |   0.8267 |     27.716 |   0.9483 |     31.107 |     0.7
   40 |   0.8154 |     27.392 |   0.9329 |     30.407 |     0.7
   41 |   0.7995 |     26.525 |   0.9323 |     30.121 |     0.7
   42 |   0.7860 |     26.075 |   0.9340 |     30.630 |     0.7
   43 |   0.7787 |     26.284 |   0.9316 |     30.312 |     0.7
   44 |   0.7665 |     25.488 |   0.9149 |     29.421 |     0.8
   45 |   0.7507 |     24.775 |   0.9132 |     29.230 |     0.8
   46 |   0.7374 |     24.259 |   0.9248 |     29.262 |     0.8
   47 |   0.7245 |     23.980 |   0.9251 |     30.153 |     0.8
   48 |   0.7145 |     23.716 |   0.9213 |     29.580 |     0.8
   49 |   0.6990 |     23.058 |   0.9236 |     29.453 |     0.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 621,506

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0361 |     55.294 |   1.4830 |     45.420 |     0.0
    2 |   1.3897 |     45.309 |   1.3205 |     44.402 |     0.1
    3 |   1.3035 |     44.119 |   1.2691 |     43.702 |     0.1
    4 |   1.2593 |     43.378 |   1.2409 |     43.321 |     0.1
    5 |   1.2274 |     42.868 |   1.2076 |     42.017 |     0.1
    6 |   1.2006 |     42.111 |   1.1864 |     40.967 |     0.2
    7 |   1.1725 |     41.338 |   1.1597 |     40.744 |     0.2
    8 |   1.1504 |     40.750 |   1.1475 |     40.204 |     0.2
    9 |   1.1224 |     39.555 |   1.1274 |     39.122 |     0.2
   10 |   1.0959 |     38.666 |   1.1076 |     38.709 |     0.3
   11 |   1.0738 |     37.953 |   1.0845 |     38.073 |     0.3
   12 |   1.0474 |     36.449 |   1.0770 |     36.578 |     0.3
   13 |   1.0255 |     36.027 |   1.0521 |     35.242 |     0.3
   14 |   1.0018 |     35.039 |   1.0509 |     36.291 |     0.4
   15 |   0.9746 |     33.783 |   1.0196 |     34.383 |     0.4
   16 |   0.9442 |     32.499 |   1.0060 |     33.747 |     0.4
   17 |   0.9220 |     31.781 |   0.9917 |     33.810 |     0.4
   18 |   0.8858 |     30.453 |   0.9766 |     32.093 |     0.5
   19 |   0.8503 |     28.818 |   0.9566 |     31.520 |     0.5
   20 |   0.8270 |     28.072 |   0.9511 |     31.266 |     0.5
   21 |   0.7945 |     26.640 |   0.9408 |     30.534 |     0.5
   22 |   0.7656 |     25.774 |   0.9346 |     30.153 |     0.6
   23 |   0.7372 |     24.726 |   0.9308 |     30.598 |     0.6
   24 |   0.7219 |     24.194 |   0.9182 |     29.644 |     0.6
   25 |   0.6805 |     22.745 |   0.9146 |     28.880 |     0.6
   26 |   0.6571 |     21.780 |   0.9125 |     28.372 |     0.7
   27 |   0.6284 |     20.902 |   0.9177 |     28.785 |     0.7
   28 |   0.6109 |     20.205 |   0.9142 |     28.149 |     0.7
   29 |   0.5842 |     19.316 |   0.9077 |     27.958 |     0.8
   30 |   0.5662 |     18.702 |   0.9102 |     27.958 |     0.8
   31 |   0.5378 |     17.440 |   0.9175 |     27.672 |     0.8
   32 |   0.5165 |     16.996 |   0.9176 |     27.513 |     0.8
   33 |   0.5019 |     16.480 |   0.9163 |     26.590 |     0.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,558,754

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1442 |     57.960 |   1.5763 |     45.802 |     0.1
    2 |   1.4690 |     46.105 |   1.4096 |     45.802 |     0.1
    3 |   1.4027 |     46.302 |   1.3784 |     45.515 |     0.2
    4 |   1.3768 |     45.924 |   1.3566 |     45.420 |     0.2
    5 |   1.3554 |     45.682 |   1.3546 |     45.515 |     0.3
    6 |   1.3370 |     45.573 |   1.3196 |     45.229 |     0.3
    7 |   1.3186 |     45.403 |   1.3042 |     45.261 |     0.4
    8 |   1.2967 |     44.788 |   1.2769 |     43.925 |     0.5
    9 |   1.2795 |     44.530 |   1.2693 |     44.529 |     0.5
   10 |   1.2676 |     44.360 |   1.2583 |     43.766 |     0.6
   11 |   1.2478 |     43.921 |   1.2395 |     43.352 |     0.6
   12 |   1.2285 |     43.274 |   1.2261 |     42.748 |     0.7
   13 |   1.2116 |     43.000 |   1.2157 |     43.384 |     0.8
   14 |   1.1906 |     42.484 |   1.1932 |     43.162 |     0.8
   15 |   1.1694 |     41.787 |   1.1809 |     41.253 |     0.9
   16 |   1.1483 |     40.761 |   1.1575 |     41.667 |     0.9
   17 |   1.1229 |     40.142 |   1.1416 |     40.140 |     1.0
   18 |   1.1013 |     38.957 |   1.1168 |     39.281 |     1.0
   19 |   1.0761 |     37.525 |   1.0970 |     38.327 |     1.1
   20 |   1.0508 |     36.811 |   1.0905 |     37.341 |     1.2
   21 |   1.0275 |     35.753 |   1.0756 |     36.609 |     1.2
   22 |   0.9972 |     34.507 |   1.0485 |     36.323 |     1.3
   23 |   0.9698 |     33.213 |   1.0510 |     36.419 |     1.3
   24 |   0.9495 |     32.626 |   1.0164 |     34.606 |     1.4
   25 |   0.9143 |     31.265 |   0.9996 |     33.620 |     1.4
   26 |   0.8828 |     29.948 |   0.9882 |     32.983 |     1.5
   27 |   0.8525 |     28.977 |   0.9871 |     32.888 |     1.6
   28 |   0.8232 |     27.562 |   0.9810 |     32.316 |     1.6
   29 |   0.7871 |     26.009 |   0.9638 |     31.934 |     1.7
   30 |   0.7441 |     24.353 |   0.9535 |     31.011 |     1.7
   31 |   0.7128 |     23.173 |   0.9460 |     30.280 |     1.8
   32 |   0.6793 |     21.846 |   0.9676 |     30.789 |     1.8
   33 |   0.6401 |     20.447 |   0.9688 |     29.898 |     1.9
   34 |   0.6014 |     19.245 |   0.9600 |     29.835 |     2.0
   35 |   0.5701 |     17.989 |   0.9595 |     28.721 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,558,754

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2126 |     60.583 |   1.6021 |     45.802 |     0.1
    2 |   1.4853 |     46.154 |   1.4130 |     46.533 |     0.1
    3 |   1.4084 |     46.121 |   1.3892 |     45.802 |     0.2
    4 |   1.3866 |     46.390 |   1.3711 |     45.802 |     0.2
    5 |   1.3593 |     45.891 |   1.3362 |     45.515 |     0.3
    6 |   1.3283 |     45.315 |   1.3135 |     44.561 |     0.4
    7 |   1.3093 |     45.167 |   1.2991 |     45.006 |     0.4
    8 |   1.2938 |     44.799 |   1.2818 |     45.134 |     0.5
    9 |   1.2759 |     44.596 |   1.2673 |     45.738 |     0.5
   10 |   1.2603 |     44.426 |   1.2508 |     43.893 |     0.6
   11 |   1.2448 |     44.135 |   1.2386 |     43.893 |     0.7
   12 |   1.2305 |     43.757 |   1.2200 |     43.098 |     0.7
   13 |   1.2124 |     43.170 |   1.2057 |     42.525 |     0.8
   14 |   1.1944 |     42.089 |   1.1861 |     41.889 |     0.9
   15 |   1.1755 |     42.012 |   1.1721 |     41.508 |     0.9
   16 |   1.1557 |     41.036 |   1.1563 |     41.126 |     1.0
   17 |   1.1331 |     40.076 |   1.1386 |     40.076 |     1.0
   18 |   1.1161 |     39.818 |   1.1212 |     39.122 |     1.1
   19 |   1.1012 |     39.050 |   1.1165 |     39.249 |     1.2
   20 |   1.0767 |     38.084 |   1.1020 |     38.677 |     1.2
   21 |   1.0640 |     37.497 |   1.0941 |     38.136 |     1.3
   22 |   1.0403 |     36.905 |   1.0772 |     37.277 |     1.3
   23 |   1.0220 |     36.076 |   1.0652 |     36.768 |     1.4
   24 |   0.9965 |     34.765 |   1.0771 |     36.864 |     1.5
   25 |   0.9765 |     34.063 |   1.0429 |     35.369 |     1.5
   26 |   0.9540 |     32.938 |   1.0235 |     34.637 |     1.6
   27 |   0.9269 |     31.825 |   1.0145 |     33.461 |     1.7
   28 |   0.9073 |     31.018 |   1.0084 |     33.429 |     1.7
   29 |   0.8831 |     30.173 |   1.0005 |     33.015 |     1.8
   30 |   0.8556 |     28.906 |   0.9861 |     32.506 |     1.8
   31 |   0.8321 |     28.105 |   0.9726 |     31.934 |     1.9
   32 |   0.8042 |     27.085 |   0.9659 |     32.125 |     2.0
   33 |   0.7834 |     26.201 |   0.9710 |     31.711 |     2.0
   34 |   0.7607 |     25.274 |   0.9568 |     30.821 |     2.1
   35 |   0.7501 |     25.110 |   0.9533 |     30.598 |     2.1
   36 |   0.7139 |     23.486 |   0.9655 |     31.075 |     2.2
   37 |   0.6858 |     22.630 |   0.9475 |     29.676 |     2.3
   38 |   0.6647 |     21.577 |   0.9504 |     29.898 |     2.3
   39 |   0.6492 |     20.935 |   0.9577 |     30.216 |     2.4
   40 |   0.6225 |     20.397 |   0.9513 |     29.262 |     2.4
   41 |   0.6247 |     20.490 |   0.9528 |     29.294 |     2.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,588,418

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5590 |     68.263 |   1.9925 |     58.111 |     0.1
    2 |   1.7692 |     50.488 |   1.5826 |     45.802 |     0.1
    3 |   1.5105 |     46.160 |   1.4514 |     45.802 |     0.2
    4 |   1.4353 |     46.204 |   1.4072 |     45.802 |     0.3
    5 |   1.4068 |     46.198 |   1.3882 |     45.770 |     0.4
    6 |   1.3901 |     46.149 |   1.3695 |     45.770 |     0.4
    7 |   1.3699 |     46.001 |   1.3529 |     45.802 |     0.5
    8 |   1.3500 |     45.529 |   1.3291 |     45.452 |     0.6
    9 |   1.3278 |     45.030 |   1.3130 |     44.370 |     0.7
   10 |   1.3110 |     44.739 |   1.3011 |     44.179 |     0.7
   11 |   1.2963 |     44.437 |   1.2867 |     44.497 |     0.8
   12 |   1.2831 |     44.174 |   1.2744 |     44.211 |     0.9
   13 |   1.2698 |     44.009 |   1.2605 |     44.052 |     1.0
   14 |   1.2582 |     43.861 |   1.2488 |     43.925 |     1.0
   15 |   1.2459 |     43.834 |   1.2419 |     44.975 |     1.1
   16 |   1.2340 |     43.718 |   1.2336 |     44.275 |     1.2
   17 |   1.2243 |     43.620 |   1.2265 |     43.225 |     1.3
   18 |   1.2157 |     43.236 |   1.2153 |     43.321 |     1.3
   19 |   1.2078 |     42.939 |   1.2085 |     43.003 |     1.4
   20 |   1.1988 |     42.758 |   1.2071 |     42.875 |     1.5
   21 |   1.1930 |     42.341 |   1.1993 |     42.112 |     1.6
   22 |   1.1828 |     42.034 |   1.1926 |     42.812 |     1.6
   23 |   1.1763 |     41.497 |   1.1827 |     42.589 |     1.7
   24 |   1.1696 |     41.266 |   1.1791 |     41.380 |     1.8
   25 |   1.1600 |     40.948 |   1.1708 |     40.967 |     1.8
   26 |   1.1558 |     40.805 |   1.1664 |     40.935 |     1.9
   27 |   1.1476 |     40.290 |   1.1584 |     40.649 |     2.0
   28 |   1.1405 |     40.345 |   1.1602 |     41.190 |     2.1
   29 |   1.1345 |     40.218 |   1.1525 |     40.808 |     2.1
   30 |   1.1279 |     39.900 |   1.1478 |     40.585 |     2.2
   31 |   1.1234 |     39.725 |   1.1436 |     39.981 |     2.3
   32 |   1.1176 |     39.675 |   1.1328 |     40.140 |     2.4
   33 |   1.1130 |     39.406 |   1.1312 |     39.663 |     2.4
   34 |   1.1084 |     39.538 |   1.1316 |     39.758 |     2.5
   35 |   1.1016 |     39.341 |   1.1263 |     40.872 |     2.6
   36 |   1.0978 |     39.417 |   1.1180 |     39.567 |     2.7
   37 |   1.0926 |     39.181 |   1.1224 |     39.440 |     2.7
   38 |   1.0880 |     38.924 |   1.1163 |     39.726 |     2.8
   39 |   1.0859 |     38.841 |   1.1092 |     39.122 |     2.9
   40 |   1.0797 |     38.946 |   1.1063 |     39.218 |     3.0
   41 |   1.0755 |     38.435 |   1.0993 |     38.804 |     3.0
   42 |   1.0689 |     38.490 |   1.1056 |     39.218 |     3.1
   43 |   1.0672 |     38.320 |   1.1016 |     38.899 |     3.2
   44 |   1.0614 |     38.271 |   1.1004 |     39.504 |     3.3
   45 |   1.0614 |     38.205 |   1.0885 |     39.599 |     3.3
   46 |   1.0554 |     38.046 |   1.0901 |     38.772 |     3.4
   47 |   1.0524 |     37.947 |   1.0945 |     38.899 |     3.5
   48 |   1.0469 |     37.859 |   1.0795 |     38.391 |     3.5
   49 |   1.0426 |     37.722 |   1.0840 |     38.804 |     3.6
   50 |   1.0394 |     37.530 |   1.0763 |     38.581 |     3.7
   51 |   1.0333 |     37.338 |   1.0788 |     38.359 |     3.8
   52 |   1.0292 |     37.135 |   1.0729 |     38.263 |     3.8
   53 |   1.0278 |     37.201 |   1.0671 |     38.104 |     3.9
   54 |   1.0218 |     37.042 |   1.0778 |     37.850 |     4.0
   55 |   1.0186 |     36.570 |   1.0611 |     37.659 |     4.1
   56 |   1.0151 |     36.373 |   1.0597 |     37.627 |     4.1
   57 |   1.0102 |     36.137 |   1.0600 |     37.436 |     4.2
   58 |   1.0064 |     36.279 |   1.0591 |     37.564 |     4.3
   59 |   1.0044 |     36.197 |   1.0612 |     37.850 |     4.4
   60 |   1.0009 |     35.906 |   1.0578 |     37.373 |     4.4
   61 |   0.9953 |     35.742 |   1.0491 |     36.991 |     4.5
   62 |   0.9938 |     35.950 |   1.0539 |     37.214 |     4.6
   63 |   0.9938 |     35.879 |   1.0588 |     37.118 |     4.7
   64 |   0.9886 |     35.533 |   1.0437 |     36.864 |     4.7
   65 |   0.9860 |     35.418 |   1.0421 |     36.991 |     4.8
   66 |   0.9817 |     35.462 |   1.0429 |     36.800 |     4.9
   67 |   0.9758 |     35.259 |   1.0391 |     36.641 |     4.9
   68 |   0.9714 |     35.188 |   1.0317 |     36.323 |     5.0
   69 |   0.9661 |     34.699 |   1.0291 |     36.323 |     5.1
   70 |   0.9672 |     34.847 |   1.0241 |     35.910 |     5.2
   71 |   0.9591 |     34.513 |   1.0316 |     36.578 |     5.2
   72 |   0.9581 |     34.694 |   1.0236 |     36.005 |     5.3
   73 |   0.9529 |     34.008 |   1.0212 |     35.910 |     5.4
   74 |   0.9514 |     34.195 |   1.0120 |     35.337 |     5.5
   75 |   0.9452 |     33.948 |   1.0211 |     35.878 |     5.5
   76 |   0.9385 |     33.613 |   1.0180 |     35.655 |     5.6
   77 |   0.9354 |     33.509 |   1.0104 |     34.574 |     5.7
   78 |   0.9314 |     33.257 |   1.0104 |     34.955 |     5.8
   79 |   0.9275 |     32.971 |   1.0149 |     35.496 |     5.8
   80 |   0.9222 |     33.059 |   1.0045 |     34.860 |     5.9
   81 |   0.9186 |     32.746 |   1.0032 |     34.701 |     6.0
   82 |   0.9170 |     32.900 |   1.0040 |     35.083 |     6.1
   83 |   0.9112 |     32.598 |   1.0045 |     34.065 |     6.1
   84 |   0.9054 |     32.368 |   1.0004 |     34.828 |     6.2
   85 |   0.9033 |     32.302 |   1.0032 |     34.987 |     6.3
   86 |   0.8960 |     31.869 |   1.0056 |     34.606 |     6.3
   87 |   0.8917 |     31.485 |   1.0083 |     35.019 |     6.4
   88 |   0.8928 |     31.742 |   1.0054 |     34.351 |     6.5
   89 |   0.8899 |     31.594 |   0.9970 |     34.415 |     6.6
   90 |   0.8805 |     31.122 |   0.9958 |     34.256 |     6.6
   91 |   0.8808 |     31.111 |   0.9890 |     34.637 |     6.7
   92 |   0.8849 |     31.249 |   1.0030 |     34.733 |     6.8
   93 |   0.8738 |     30.854 |   0.9937 |     33.969 |     6.9
   94 |   0.8697 |     30.585 |   0.9992 |     34.765 |     6.9
   95 |   0.8618 |     30.245 |   0.9886 |     33.810 |     7.0
   96 |   0.8560 |     30.179 |   0.9916 |     34.065 |     7.1
   97 |   0.8558 |     29.888 |   0.9880 |     33.715 |     7.2
   98 |   0.8467 |     29.800 |   0.9795 |     33.492 |     7.2
   99 |   0.8469 |     29.745 |   0.9879 |     32.602 |     7.3
  100 |   0.8427 |     29.542 |   0.9856 |     33.715 |     7.4
  101 |   0.8374 |     29.394 |   0.9793 |     33.079 |     7.5
  102 |   0.8290 |     29.076 |   0.9843 |     33.524 |     7.5
  103 |   0.8577 |     30.382 |   0.9872 |     33.906 |     7.6
  104 |   0.8325 |     29.219 |   0.9766 |     33.397 |     7.7
  105 |   0.8206 |     28.643 |   0.9859 |     33.111 |     7.7
  106 |   0.8238 |     29.027 |   0.9734 |     32.983 |     7.8
  107 |   0.8082 |     28.149 |   0.9868 |     33.365 |     7.9
  108 |   0.8146 |     28.418 |   0.9858 |     32.761 |     8.0
  109 |   0.8041 |     27.897 |   0.9683 |     32.188 |     8.0
  110 |   0.7988 |     27.897 |   0.9764 |     32.888 |     8.1
  111 |   0.7942 |     27.491 |   0.9820 |     32.888 |     8.2
  112 |   0.7931 |     27.557 |   0.9834 |     32.824 |     8.3
  113 |   0.7920 |     27.655 |   0.9717 |     32.284 |     8.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,132,898

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1547 |     59.244 |   1.5800 |     45.802 |     0.0
    2 |   1.4706 |     46.275 |   1.4091 |     45.802 |     0.1
    3 |   1.3964 |     46.138 |   1.3613 |     45.802 |     0.1
    4 |   1.3634 |     45.798 |   1.3414 |     45.483 |     0.2
    5 |   1.3355 |     45.364 |   1.3178 |     45.038 |     0.2
    6 |   1.3153 |     44.887 |   1.3056 |     44.529 |     0.2
    7 |   1.2983 |     44.673 |   1.2795 |     44.243 |     0.3
    8 |   1.2779 |     44.432 |   1.2634 |     43.893 |     0.3
    9 |   1.2595 |     44.371 |   1.2479 |     44.561 |     0.4
   10 |   1.2429 |     43.795 |   1.2291 |     43.639 |     0.4
   11 |   1.2298 |     43.784 |   1.2240 |     42.366 |     0.4
   12 |   1.2116 |     42.824 |   1.2022 |     42.844 |     0.5
   13 |   1.1926 |     42.193 |   1.1913 |     42.144 |     0.5
   14 |   1.1737 |     41.568 |   1.1772 |     42.525 |     0.6
   15 |   1.1596 |     41.184 |   1.1592 |     40.522 |     0.6
   16 |   1.1405 |     40.509 |   1.1520 |     41.826 |     0.6
   17 |   1.1212 |     40.180 |   1.1312 |     39.885 |     0.7
   18 |   1.1028 |     39.258 |   1.1156 |     39.122 |     0.7
   19 |   1.0832 |     38.688 |   1.1063 |     38.963 |     0.8
   20 |   1.0602 |     37.623 |   1.0869 |     37.945 |     0.8
   21 |   1.0416 |     37.212 |   1.0873 |     37.977 |     0.8
   22 |   1.0204 |     36.658 |   1.0588 |     36.768 |     0.9
   23 |   0.9984 |     35.550 |   1.0447 |     36.164 |     0.9
   24 |   0.9751 |     34.420 |   1.0300 |     35.782 |     1.0
   25 |   0.9520 |     33.432 |   1.0240 |     34.796 |     1.0
   26 |   0.9284 |     32.368 |   1.0028 |     34.351 |     1.1
   27 |   0.9055 |     31.775 |   0.9947 |     33.556 |     1.1
   28 |   0.8831 |     30.711 |   1.0092 |     33.779 |     1.1
   29 |   0.8587 |     29.811 |   0.9831 |     33.079 |     1.2
   30 |   0.8294 |     28.445 |   0.9759 |     32.411 |     1.2
   31 |   0.7991 |     27.370 |   0.9687 |     31.902 |     1.3
   32 |   0.7717 |     26.147 |   0.9602 |     31.838 |     1.3
   33 |   0.7456 |     24.973 |   0.9594 |     31.043 |     1.3
   34 |   0.7162 |     23.980 |   0.9615 |     30.439 |     1.4
   35 |   0.6904 |     22.740 |   0.9654 |     30.693 |     1.4
   36 |   0.6649 |     22.059 |   0.9765 |     31.043 |     1.5
   37 |   0.6415 |     21.138 |   0.9665 |     29.294 |     1.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 522,466

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4291 |     64.341 |   1.8485 |     49.746 |     0.0
    2 |   1.6167 |     47.493 |   1.4566 |     45.420 |     0.1
    3 |   1.4174 |     45.814 |   1.3636 |     45.197 |     0.1
    4 |   1.3578 |     45.540 |   1.3290 |     44.816 |     0.1
    5 |   1.3234 |     44.684 |   1.2997 |     43.702 |     0.2
    6 |   1.2985 |     44.437 |   1.2807 |     43.702 |     0.2
    7 |   1.2752 |     43.965 |   1.2579 |     43.670 |     0.2
    8 |   1.2529 |     43.515 |   1.2342 |     43.193 |     0.3
    9 |   1.2296 |     43.044 |   1.2260 |     43.162 |     0.3
   10 |   1.2091 |     42.287 |   1.1994 |     42.239 |     0.3
   11 |   1.1875 |     41.327 |   1.1831 |     40.617 |     0.4
   12 |   1.1632 |     40.131 |   1.1679 |     40.204 |     0.4
   13 |   1.1405 |     39.587 |   1.1485 |     39.408 |     0.4
   14 |   1.1190 |     38.792 |   1.1397 |     39.377 |     0.5
   15 |   1.0942 |     37.761 |   1.1205 |     39.059 |     0.5
   16 |   1.0721 |     36.982 |   1.0969 |     37.786 |     0.6
   17 |   1.0466 |     36.109 |   1.0842 |     37.595 |     0.6
   18 |   1.0205 |     35.155 |   1.0625 |     36.291 |     0.6
   19 |   0.9930 |     33.882 |   1.0547 |     35.528 |     0.7
   20 |   0.9669 |     32.719 |   1.0367 |     35.369 |     0.7
   21 |   0.9377 |     31.293 |   1.0158 |     34.097 |     0.7
   22 |   0.9123 |     30.492 |   1.0151 |     33.015 |     0.8
   23 |   0.8837 |     29.115 |   0.9927 |     32.443 |     0.8
   24 |   0.8558 |     28.270 |   0.9849 |     32.029 |     0.8
   25 |   0.8220 |     26.969 |   0.9796 |     32.411 |     0.9
   26 |   0.7990 |     26.114 |   0.9747 |     30.884 |     0.9
   27 |   0.7731 |     24.956 |   0.9658 |     31.361 |     0.9
   28 |   0.7464 |     24.205 |   0.9563 |     30.598 |     1.0
   29 |   0.7235 |     23.343 |   0.9572 |     30.598 |     1.0
   30 |   0.7031 |     22.438 |   0.9531 |     29.612 |     1.0
   31 |   0.6794 |     21.736 |   0.9608 |     30.503 |     1.1
   32 |   0.6489 |     20.666 |   0.9390 |     29.676 |     1.1
   33 |   0.6290 |     19.997 |   0.9498 |     29.517 |     1.1
   34 |   0.6051 |     19.201 |   0.9318 |     28.817 |     1.2
   35 |   0.5878 |     18.603 |   0.9492 |     28.817 |     1.2
   36 |   0.5623 |     17.769 |   0.9598 |     28.244 |     1.2
   37 |   0.5438 |     17.062 |   0.9458 |     28.690 |     1.3
   38 |   0.5187 |     16.222 |   0.9666 |     28.849 |     1.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,194,594

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5418 |     68.312 |   1.9631 |     54.230 |     0.1
    2 |   1.7472 |     49.556 |   1.5610 |     45.802 |     0.1
    3 |   1.4967 |     46.160 |   1.4446 |     46.533 |     0.2
    4 |   1.4341 |     46.313 |   1.4087 |     45.802 |     0.2
    5 |   1.4114 |     46.176 |   1.3950 |     45.802 |     0.3
    6 |   1.3973 |     46.066 |   1.3872 |     45.611 |     0.3
    7 |   1.3873 |     45.979 |   1.3673 |     45.293 |     0.4
    8 |   1.3747 |     45.924 |   1.3568 |     45.356 |     0.5
    9 |   1.3562 |     45.704 |   1.3507 |     45.070 |     0.5
   10 |   1.3396 |     45.222 |   1.3241 |     45.134 |     0.6
   11 |   1.3225 |     44.903 |   1.3112 |     44.052 |     0.6
   12 |   1.3086 |     44.514 |   1.3117 |     44.847 |     0.7
   13 |   1.2969 |     44.711 |   1.2859 |     43.861 |     0.7
   14 |   1.2828 |     44.174 |   1.2762 |     43.639 |     0.8
   15 |   1.2710 |     43.839 |   1.2666 |     43.702 |     0.9
   16 |   1.2583 |     43.620 |   1.2518 |     43.289 |     0.9
   17 |   1.2452 |     43.345 |   1.2395 |     43.289 |     1.0
   18 |   1.2290 |     42.896 |   1.2287 |     42.971 |     1.0
   19 |   1.2116 |     42.056 |   1.2146 |     42.335 |     1.1
   20 |   1.1953 |     41.590 |   1.2076 |     42.144 |     1.1
   21 |   1.1780 |     41.398 |   1.1904 |     41.730 |     1.2
   22 |   1.1593 |     40.893 |   1.1807 |     41.508 |     1.3
   23 |   1.1413 |     40.542 |   1.1627 |     40.999 |     1.3
   24 |   1.1223 |     39.851 |   1.1633 |     40.045 |     1.4
   25 |   1.1011 |     38.836 |   1.1467 |     40.267 |     1.4
   26 |   1.0801 |     37.717 |   1.1301 |     39.186 |     1.5
   27 |   1.0566 |     36.811 |   1.1162 |     38.073 |     1.5
   28 |   1.0335 |     35.627 |   1.1081 |     37.977 |     1.6
   29 |   1.0066 |     34.387 |   1.0943 |     37.055 |     1.7
   30 |   0.9774 |     33.059 |   1.0775 |     36.228 |     1.7
   31 |   0.9517 |     32.176 |   1.0703 |     35.814 |     1.8
   32 |   0.9205 |     30.716 |   1.0611 |     34.224 |     1.8
   33 |   0.8910 |     29.839 |   1.0398 |     33.747 |     1.9
   34 |   0.8512 |     28.144 |   1.0402 |     33.270 |     1.9
   35 |   0.8217 |     26.646 |   1.0475 |     33.810 |     2.0
   36 |   0.7882 |     25.368 |   1.0261 |     31.648 |     2.1
   37 |   0.7551 |     23.820 |   1.0168 |     31.648 |     2.1
   38 |   0.7220 |     22.504 |   1.0179 |     31.330 |     2.2
   39 |   0.6866 |     21.352 |   1.0384 |     31.298 |     2.2
   40 |   0.6532 |     20.172 |   1.0307 |     30.948 |     2.3
   41 |   0.6243 |     19.218 |   1.0286 |     30.566 |     2.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 440,034

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5007 |     66.453 |   1.9324 |     55.057 |     0.0
    2 |   1.7142 |     48.914 |   1.5319 |     45.802 |     0.0
    3 |   1.4715 |     46.099 |   1.4188 |     45.802 |     0.1
    4 |   1.4041 |     45.984 |   1.3748 |     45.833 |     0.1
    5 |   1.3643 |     45.842 |   1.3400 |     45.197 |     0.1
    6 |   1.3298 |     45.419 |   1.3060 |     44.816 |     0.1
    7 |   1.3002 |     44.459 |   1.2866 |     43.893 |     0.2
    8 |   1.2779 |     43.916 |   1.2678 |     43.670 |     0.2
    9 |   1.2593 |     43.740 |   1.2486 |     43.830 |     0.2
   10 |   1.2434 |     43.647 |   1.2368 |     43.670 |     0.2
   11 |   1.2280 |     43.307 |   1.2233 |     43.193 |     0.3
   12 |   1.2147 |     42.863 |   1.2079 |     43.193 |     0.3
   13 |   1.2035 |     42.479 |   1.2064 |     42.684 |     0.3
   14 |   1.1922 |     42.149 |   1.1958 |     42.430 |     0.3
   15 |   1.1806 |     41.897 |   1.1849 |     41.571 |     0.3
   16 |   1.1718 |     41.628 |   1.1838 |     41.444 |     0.4
   17 |   1.1615 |     41.091 |   1.1719 |     40.808 |     0.4
   18 |   1.1522 |     40.394 |   1.1635 |     40.967 |     0.4
   19 |   1.1439 |     40.443 |   1.1533 |     40.617 |     0.4
   20 |   1.1336 |     40.279 |   1.1465 |     40.490 |     0.5
   21 |   1.1250 |     39.747 |   1.1465 |     40.076 |     0.5
   22 |   1.1181 |     39.620 |   1.1301 |     39.345 |     0.5
   23 |   1.1064 |     39.044 |   1.1273 |     38.868 |     0.5
   24 |   1.1008 |     38.841 |   1.1233 |     39.059 |     0.6
   25 |   1.0907 |     38.408 |   1.1214 |     38.931 |     0.6
   26 |   1.0816 |     38.501 |   1.1132 |     38.550 |     0.6
   27 |   1.0723 |     37.903 |   1.1070 |     38.136 |     0.6
   28 |   1.0664 |     37.865 |   1.1066 |     38.645 |     0.6
   29 |   1.0591 |     37.541 |   1.1052 |     38.868 |     0.7
   30 |   1.0498 |     36.965 |   1.0931 |     37.500 |     0.7
   31 |   1.0385 |     36.724 |   1.0872 |     37.532 |     0.7
   32 |   1.0316 |     36.532 |   1.0807 |     37.882 |     0.7
   33 |   1.0228 |     35.978 |   1.0801 |     37.913 |     0.8
   34 |   1.0197 |     35.742 |   1.0772 |     37.627 |     0.8
   35 |   1.0088 |     35.599 |   1.0722 |     37.564 |     0.8
   36 |   0.9974 |     34.782 |   1.0777 |     38.136 |     0.8
   37 |   0.9884 |     34.886 |   1.0563 |     36.896 |     0.9
   38 |   0.9897 |     34.809 |   1.0581 |     36.482 |     0.9
   39 |   0.9723 |     34.222 |   1.0455 |     35.655 |     0.9
   40 |   0.9663 |     33.679 |   1.0494 |     36.800 |     0.9
   41 |   0.9544 |     33.410 |   1.0480 |     35.496 |     0.9
   42 |   0.9395 |     32.604 |   1.0394 |     36.132 |     1.0
   43 |   0.9250 |     32.088 |   1.0290 |     35.655 |     1.0
   44 |   0.9147 |     31.770 |   1.0321 |     35.051 |     1.0
   45 |   0.9067 |     31.347 |   1.0296 |     34.542 |     1.0
   46 |   0.8945 |     30.985 |   1.0392 |     34.987 |     1.1
   47 |   0.8864 |     30.749 |   1.0307 |     34.669 |     1.1
   48 |   0.8701 |     29.916 |   1.0205 |     34.256 |     1.1
   49 |   0.8584 |     29.202 |   1.0206 |     33.683 |     1.1
   50 |   0.8458 |     28.665 |   1.0264 |     33.715 |     1.2
   51 |   0.8326 |     28.237 |   1.0229 |     34.447 |     1.2
   52 |   0.8254 |     28.105 |   1.0193 |     33.620 |     1.2
   53 |   0.8095 |     27.458 |   1.0284 |     33.969 |     1.2
   54 |   0.8061 |     27.425 |   1.0199 |     32.475 |     1.3
   55 |   0.7929 |     26.854 |   1.0219 |     33.270 |     1.3
   56 |   0.7864 |     26.569 |   1.0029 |     32.125 |     1.3
   57 |   0.7690 |     25.746 |   1.0088 |     31.711 |     1.3
   58 |   0.7672 |     25.724 |   1.0067 |     32.347 |     1.3
   59 |   0.7500 |     24.824 |   1.0170 |     31.966 |     1.4
   60 |   0.7396 |     24.671 |   1.0154 |     31.870 |     1.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,593,698

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1872 |     60.029 |   1.6174 |     48.919 |     0.1
    2 |   1.4861 |     46.297 |   1.4103 |     45.802 |     0.1
    3 |   1.3942 |     46.034 |   1.3547 |     45.802 |     0.2
    4 |   1.3459 |     45.770 |   1.3197 |     45.388 |     0.2
    5 |   1.3119 |     45.134 |   1.2919 |     45.738 |     0.3
    6 |   1.2866 |     44.777 |   1.2719 |     44.784 |     0.4
    7 |   1.2707 |     44.459 |   1.2549 |     44.561 |     0.4
    8 |   1.2509 |     44.102 |   1.2385 |     43.384 |     0.5
    9 |   1.2340 |     43.450 |   1.2210 |     43.416 |     0.5
   10 |   1.2168 |     43.115 |   1.1988 |     42.271 |     0.6
   11 |   1.1989 |     41.957 |   1.1994 |     41.444 |     0.7
   12 |   1.1834 |     41.546 |   1.1888 |     42.144 |     0.7
   13 |   1.1696 |     41.354 |   1.1712 |     42.080 |     0.8
   14 |   1.1594 |     40.888 |   1.1628 |     40.426 |     0.8
   15 |   1.1475 |     40.718 |   1.1592 |     41.317 |     0.9
   16 |   1.1359 |     40.668 |   1.1509 |     40.967 |     1.0
   17 |   1.1225 |     40.026 |   1.1438 |     40.331 |     1.0
   18 |   1.1098 |     39.341 |   1.1301 |     40.267 |     1.1
   19 |   1.1007 |     39.412 |   1.1250 |     39.440 |     1.1
   20 |   1.0899 |     39.242 |   1.1096 |     39.695 |     1.2
   21 |   1.0763 |     38.364 |   1.1019 |     38.263 |     1.2
   22 |   1.0663 |     38.145 |   1.0959 |     38.550 |     1.3
   23 |   1.0521 |     37.651 |   1.0807 |     38.422 |     1.4
   24 |   1.0474 |     37.371 |   1.0760 |     37.246 |     1.4
   25 |   1.0335 |     36.822 |   1.0681 |     37.405 |     1.5
   26 |   1.0211 |     36.433 |   1.0702 |     36.864 |     1.5
   27 |   1.0128 |     35.934 |   1.0659 |     36.832 |     1.6
   28 |   1.0062 |     35.868 |   1.0611 |     37.055 |     1.7
   29 |   0.9942 |     35.039 |   1.0445 |     36.450 |     1.7
   30 |   0.9837 |     35.034 |   1.0372 |     35.560 |     1.8
   31 |   0.9697 |     34.365 |   1.0421 |     35.528 |     1.8
   32 |   0.9536 |     33.575 |   1.0202 |     34.415 |     1.9
   33 |   0.9444 |     33.416 |   1.0158 |     34.542 |     2.0
   34 |   0.9319 |     33.119 |   1.0133 |     33.715 |     2.0
   35 |   0.9178 |     32.115 |   0.9979 |     33.874 |     2.1
   36 |   0.9041 |     31.748 |   1.0027 |     34.128 |     2.1
   37 |   0.8976 |     31.380 |   0.9943 |     33.524 |     2.2
   38 |   0.8874 |     31.249 |   0.9841 |     33.461 |     2.3
   39 |   0.8727 |     30.431 |   0.9814 |     33.142 |     2.3
   40 |   0.8634 |     29.959 |   0.9722 |     32.761 |     2.4
   41 |   0.8502 |     29.696 |   0.9699 |     31.648 |     2.4
   42 |   0.8382 |     29.054 |   0.9533 |     31.043 |     2.5
   43 |   0.8234 |     28.528 |   0.9528 |     31.584 |     2.6
   44 |   0.8121 |     27.770 |   0.9635 |     31.966 |     2.6
   45 |   0.8045 |     27.776 |   0.9345 |     30.852 |     2.7
   46 |   0.7892 |     27.419 |   0.9338 |     30.821 |     2.7
   47 |   0.7741 |     26.695 |   0.9351 |     30.439 |     2.8
   48 |   0.7643 |     26.300 |   0.9304 |     30.216 |     2.9
   49 |   0.7500 |     25.713 |   0.9338 |     29.580 |     2.9
   50 |   0.7403 |     25.494 |   0.9280 |     30.789 |     3.0
   51 |   0.7304 |     25.132 |   0.9240 |     29.326 |     3.0
   52 |   0.7149 |     24.451 |   0.9205 |     29.962 |     3.1
   53 |   0.7021 |     23.749 |   0.9333 |     30.248 |     3.2
   54 |   0.6910 |     23.261 |   0.9145 |     29.485 |     3.2
   55 |   0.6786 |     22.811 |   0.9251 |     29.039 |     3.3
   56 |   0.6657 |     22.438 |   0.9078 |     28.880 |     3.3
   57 |   0.6540 |     22.202 |   0.8955 |     27.926 |     3.4
   58 |   0.6427 |     21.632 |   0.9090 |     28.244 |     3.5
   59 |   0.6266 |     21.154 |   0.9164 |     28.403 |     3.5
   60 |   0.6178 |     20.809 |   0.8969 |     27.831 |     3.6
   61 |   0.6151 |     20.776 |   0.9119 |     28.435 |     3.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 586,562

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2521 |     62.163 |   1.6271 |     45.802 |     0.0
    2 |   1.4869 |     46.165 |   1.4064 |     46.533 |     0.0
    3 |   1.3893 |     46.045 |   1.3635 |     45.802 |     0.1
    4 |   1.3528 |     45.864 |   1.3338 |     45.738 |     0.1
    5 |   1.3263 |     45.677 |   1.3136 |     45.356 |     0.1
    6 |   1.3055 |     45.331 |   1.2963 |     45.038 |     0.1
    7 |   1.2879 |     44.744 |   1.2798 |     44.275 |     0.1
    8 |   1.2733 |     44.536 |   1.2680 |     44.561 |     0.1
    9 |   1.2554 |     44.218 |   1.2413 |     43.893 |     0.2
   10 |   1.2376 |     43.883 |   1.2299 |     42.494 |     0.2
   11 |   1.2239 |     43.186 |   1.2159 |     43.257 |     0.2
   12 |   1.2092 |     42.912 |   1.2108 |     42.971 |     0.2
   13 |   1.1970 |     42.577 |   1.1974 |     43.003 |     0.2
   14 |   1.1811 |     42.106 |   1.1815 |     42.748 |     0.2
   15 |   1.1694 |     41.743 |   1.1807 |     41.985 |     0.3
   16 |   1.1516 |     41.359 |   1.1587 |     40.935 |     0.3
   17 |   1.1349 |     40.613 |   1.1469 |     40.585 |     0.3
   18 |   1.1145 |     39.906 |   1.1340 |     40.363 |     0.3
   19 |   1.0976 |     39.171 |   1.1320 |     40.363 |     0.3
   20 |   1.0778 |     38.375 |   1.1097 |     40.235 |     0.3
   21 |   1.0598 |     37.909 |   1.0972 |     38.836 |     0.4
   22 |   1.0362 |     36.850 |   1.0827 |     37.850 |     0.4
   23 |   1.0123 |     35.758 |   1.0704 |     36.705 |     0.4
   24 |   0.9902 |     34.688 |   1.0582 |     36.355 |     0.4
   25 |   0.9676 |     33.865 |   1.0538 |     35.941 |     0.4
   26 |   0.9417 |     32.713 |   1.0482 |     35.210 |     0.4
   27 |   0.9200 |     32.011 |   1.0375 |     35.687 |     0.5
   28 |   0.8907 |     30.799 |   1.0230 |     34.351 |     0.5
   29 |   0.8628 |     29.740 |   1.0143 |     33.333 |     0.5
   30 |   0.8395 |     28.643 |   1.0126 |     33.047 |     0.5
   31 |   0.8133 |     27.655 |   1.0034 |     33.238 |     0.5
   32 |   0.7879 |     26.772 |   1.0099 |     32.443 |     0.5
   33 |   0.7646 |     25.960 |   0.9975 |     31.966 |     0.6
   34 |   0.7788 |     26.404 |   0.9928 |     32.347 |     0.6
   35 |   0.7415 |     24.781 |   0.9828 |     31.584 |     0.6
   36 |   0.7063 |     23.903 |   0.9811 |     30.662 |     0.6
   37 |   0.6789 |     22.531 |   0.9825 |     30.312 |     0.6
   38 |   0.6584 |     22.120 |   0.9654 |     29.739 |     0.7
   39 |   0.6466 |     21.664 |   0.9937 |     30.439 |     0.7
   40 |   0.6758 |     22.515 |   0.9763 |     29.676 |     0.7
   41 |   0.6126 |     20.326 |   0.9883 |     29.930 |     0.7
   42 |   0.5828 |     19.196 |   1.0025 |     29.358 |     0.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,229,730

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3965 |     62.969 |   1.8505 |     48.537 |     0.1
    2 |   1.6461 |     47.844 |   1.4903 |     45.674 |     0.1
    3 |   1.4496 |     46.012 |   1.4008 |     45.611 |     0.2
    4 |   1.3878 |     45.770 |   1.3558 |     45.197 |     0.3
    5 |   1.3498 |     45.458 |   1.3223 |     44.688 |     0.3
    6 |   1.3219 |     44.865 |   1.2992 |     43.289 |     0.4
    7 |   1.3003 |     44.031 |   1.2856 |     44.084 |     0.4
    8 |   1.2831 |     43.735 |   1.2647 |     43.257 |     0.5
    9 |   1.2636 |     42.967 |   1.2550 |     42.875 |     0.6
   10 |   1.2486 |     42.912 |   1.2476 |     43.003 |     0.6
   11 |   1.2283 |     42.325 |   1.2248 |     43.448 |     0.7
   12 |   1.2109 |     41.672 |   1.2077 |     41.762 |     0.8
   13 |   1.1898 |     40.915 |   1.2056 |     41.349 |     0.8
   14 |   1.1698 |     40.191 |   1.1767 |     40.967 |     0.9
   15 |   1.1440 |     39.050 |   1.1643 |     40.140 |     1.0
   16 |   1.1231 |     38.271 |   1.1481 |     39.313 |     1.0
   17 |   1.0949 |     36.833 |   1.1256 |     38.422 |     1.1
   18 |   1.0674 |     36.032 |   1.1093 |     37.087 |     1.1
   19 |   1.0338 |     34.151 |   1.0831 |     35.623 |     1.2
   20 |   0.9979 |     32.867 |   1.0615 |     35.369 |     1.3
   21 |   0.9616 |     31.282 |   1.0494 |     35.019 |     1.3
   22 |   0.9263 |     30.261 |   1.0373 |     34.383 |     1.4
   23 |   0.8937 |     29.071 |   1.0214 |     34.288 |     1.4
   24 |   0.8524 |     27.584 |   1.0121 |     32.920 |     1.5
   25 |   0.8128 |     26.289 |   1.0016 |     32.252 |     1.6
   26 |   0.7738 |     24.868 |   0.9797 |     31.202 |     1.6
   27 |   0.7393 |     23.425 |   0.9845 |     30.916 |     1.7
   28 |   0.7105 |     22.652 |   0.9878 |     30.407 |     1.8
   29 |   0.6745 |     21.577 |   0.9763 |     30.216 |     1.8
   30 |   0.6328 |     19.684 |   0.9914 |     30.725 |     1.9
   31 |   0.5981 |     18.735 |   0.9782 |     29.676 |     1.9
   32 |   0.5718 |     17.945 |   0.9840 |     28.976 |     2.0
   33 |   0.5402 |     16.722 |   0.9890 |     29.612 |     2.1
Early stopping

