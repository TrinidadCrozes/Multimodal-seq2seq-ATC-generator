Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,069,346

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0681 |     56.294 |   1.5027 |     46.097 |     0.0
    2 |   1.4036 |     45.569 |   1.3538 |     46.004 |     0.1
    3 |   1.3164 |     44.466 |   1.2979 |     43.897 |     0.1
    4 |   1.2681 |     43.634 |   1.2587 |     43.587 |     0.2
    5 |   1.2368 |     43.094 |   1.2327 |     42.441 |     0.2
    6 |   1.2088 |     42.323 |   1.2090 |     42.937 |     0.2
    7 |   1.1762 |     41.474 |   1.1807 |     41.233 |     0.3
    8 |   1.1452 |     40.074 |   1.1455 |     39.932 |     0.3
    9 |   1.1054 |     38.106 |   1.1238 |     39.374 |     0.4
   10 |   1.0668 |     36.491 |   1.0887 |     38.011 |     0.4
   11 |   1.0223 |     34.177 |   1.0495 |     35.812 |     0.4
   12 |   0.9709 |     32.512 |   1.0288 |     36.059 |     0.5
   13 |   0.9201 |     30.379 |   1.0037 |     34.542 |     0.5
   14 |   0.8726 |     28.853 |   0.9706 |     32.931 |     0.6
   15 |   0.8232 |     26.857 |   0.9478 |     32.001 |     0.6
   16 |   0.7717 |     24.956 |   0.9356 |     30.514 |     0.6
   17 |   0.7158 |     22.928 |   0.9245 |     29.616 |     0.7
   18 |   0.6654 |     20.955 |   0.9149 |     29.926 |     0.7
   19 |   0.6226 |     19.703 |   0.9043 |     29.089 |     0.8
   20 |   0.5786 |     18.430 |   0.8937 |     28.222 |     0.8
   21 |   0.5363 |     16.970 |   0.9007 |     27.757 |     0.8
   22 |   0.4901 |     15.399 |   0.8939 |     27.292 |     0.9
   23 |   0.4522 |     13.878 |   0.9061 |     27.014 |     0.9
   24 |   0.4131 |     12.693 |   0.8938 |     25.682 |     1.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 504,674

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4214 |     64.826 |   1.8359 |     52.478 |     0.0
    2 |   1.6193 |     47.090 |   1.4887 |     46.468 |     0.1
    3 |   1.4238 |     45.740 |   1.3880 |     46.685 |     0.1
    4 |   1.3542 |     45.233 |   1.3424 |     45.043 |     0.1
    5 |   1.3174 |     44.345 |   1.3110 |     44.703 |     0.2
    6 |   1.2872 |     44.026 |   1.2830 |     44.052 |     0.2
    7 |   1.2652 |     43.623 |   1.2705 |     45.260 |     0.2
    8 |   1.2443 |     43.491 |   1.2501 |     43.587 |     0.3
    9 |   1.2228 |     43.193 |   1.2235 |     43.092 |     0.3
   10 |   1.2013 |     42.317 |   1.2113 |     42.131 |     0.3
   11 |   1.1852 |     41.551 |   1.1975 |     41.884 |     0.4
   12 |   1.1705 |     40.906 |   1.1896 |     42.410 |     0.4
   13 |   1.1546 |     40.217 |   1.1691 |     40.923 |     0.4
   14 |   1.1427 |     40.157 |   1.1636 |     40.149 |     0.4
   15 |   1.1269 |     39.605 |   1.1540 |     40.087 |     0.5
   16 |   1.1190 |     39.710 |   1.1525 |     40.799 |     0.5
   17 |   1.1042 |     38.922 |   1.1346 |     40.675 |     0.5
   18 |   1.0913 |     38.360 |   1.1266 |     39.653 |     0.6
   19 |   1.0791 |     37.731 |   1.1156 |     38.662 |     0.6
   20 |   1.0682 |     37.539 |   1.1023 |     38.104 |     0.6
   21 |   1.0549 |     36.916 |   1.0931 |     37.856 |     0.7
   22 |   1.0409 |     36.486 |   1.0849 |     38.290 |     0.7
   23 |   1.0319 |     36.243 |   1.0733 |     37.454 |     0.7
   24 |   1.0233 |     35.709 |   1.0750 |     37.887 |     0.7
   25 |   1.0090 |     35.009 |   1.0633 |     37.113 |     0.8
   26 |   0.9979 |     34.843 |   1.0514 |     37.237 |     0.8
   27 |   0.9845 |     34.485 |   1.0505 |     36.400 |     0.8
   28 |   0.9724 |     33.548 |   1.0342 |     36.648 |     0.9
   29 |   0.9609 |     33.091 |   1.0370 |     36.090 |     0.9
   30 |   0.9483 |     32.485 |   1.0186 |     35.502 |     0.9
   31 |   0.9335 |     31.878 |   1.0161 |     35.006 |     1.0
   32 |   0.9229 |     31.404 |   1.0124 |     34.727 |     1.0
   33 |   0.9072 |     30.594 |   1.0134 |     35.719 |     1.0
   34 |   0.8970 |     30.219 |   1.0077 |     34.851 |     1.1
   35 |   0.8833 |     29.602 |   0.9986 |     34.263 |     1.1
   36 |   0.8691 |     29.117 |   0.9889 |     33.860 |     1.1
   37 |   0.8575 |     28.952 |   0.9875 |     33.488 |     1.2
   38 |   0.8436 |     28.329 |   0.9702 |     32.900 |     1.2
   39 |   0.8269 |     27.480 |   0.9819 |     32.280 |     1.2
   40 |   0.8178 |     27.425 |   0.9789 |     33.333 |     1.2
   41 |   0.8010 |     26.444 |   0.9548 |     31.815 |     1.3
   42 |   0.7883 |     25.970 |   0.9459 |     31.599 |     1.3
   43 |   0.7702 |     25.468 |   0.9506 |     30.824 |     1.3
   44 |   0.7515 |     24.724 |   0.9333 |     30.514 |     1.4
   45 |   0.7474 |     24.664 |   0.9303 |     30.886 |     1.4
   46 |   0.7258 |     23.914 |   0.9371 |     30.421 |     1.4
   47 |   0.7066 |     23.005 |   0.9346 |     30.112 |     1.5
   48 |   0.6940 |     22.795 |   0.9168 |     29.709 |     1.5
   49 |   0.6794 |     22.184 |   0.9289 |     30.297 |     1.5
   50 |   0.6648 |     21.533 |   0.9152 |     28.903 |     1.6
   51 |   0.6451 |     20.662 |   0.9146 |     29.244 |     1.6
   52 |   0.6420 |     20.762 |   0.9023 |     28.377 |     1.6
   53 |   0.6169 |     19.814 |   0.9079 |     28.532 |     1.7
   54 |   0.6053 |     19.362 |   0.9224 |     29.368 |     1.7
   55 |   0.5880 |     18.430 |   0.9235 |     29.058 |     1.7
   56 |   0.5742 |     18.375 |   0.9194 |     28.656 |     1.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,524,578

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2391 |     61.343 |   1.6683 |     49.442 |     0.1
    2 |   1.5083 |     45.955 |   1.4354 |     47.150 |     0.1
    3 |   1.4127 |     45.960 |   1.3946 |     46.778 |     0.2
    4 |   1.3743 |     45.613 |   1.3633 |     45.570 |     0.2
    5 |   1.3379 |     45.585 |   1.3314 |     46.004 |     0.3
    6 |   1.3118 |     45.117 |   1.3134 |     45.229 |     0.3
    7 |   1.2926 |     44.770 |   1.2921 |     44.641 |     0.4
    8 |   1.2703 |     44.334 |   1.2774 |     44.641 |     0.5
    9 |   1.2533 |     43.998 |   1.2545 |     43.959 |     0.5
   10 |   1.2354 |     43.860 |   1.2455 |     43.835 |     0.6
   11 |   1.2210 |     43.563 |   1.2353 |     43.371 |     0.6
   12 |   1.2082 |     43.011 |   1.2184 |     42.720 |     0.7
   13 |   1.1986 |     42.697 |   1.2161 |     42.844 |     0.7
   14 |   1.1872 |     42.411 |   1.1951 |     41.822 |     0.8
   15 |   1.1764 |     41.959 |   1.1902 |     41.822 |     0.9
   16 |   1.1660 |     41.567 |   1.1811 |     41.853 |     0.9
   17 |   1.1591 |     41.242 |   1.1768 |     42.286 |     1.0
   18 |   1.1445 |     40.680 |   1.1597 |     40.551 |     1.0
   19 |   1.1351 |     40.410 |   1.1486 |     40.242 |     1.1
   20 |   1.1272 |     40.146 |   1.1479 |     39.963 |     1.1
   21 |   1.1162 |     39.804 |   1.1472 |     39.715 |     1.2
   22 |   1.1065 |     39.545 |   1.1420 |     40.644 |     1.3
   23 |   1.0974 |     39.164 |   1.1324 |     40.582 |     1.3
   24 |   1.0872 |     39.005 |   1.1247 |     39.374 |     1.4
   25 |   1.0763 |     38.371 |   1.1119 |     39.188 |     1.5
   26 |   1.0657 |     37.886 |   1.1010 |     38.600 |     1.5
   27 |   1.0578 |     38.018 |   1.0921 |     38.569 |     1.6
   28 |   1.0493 |     37.461 |   1.0850 |     38.042 |     1.6
   29 |   1.0407 |     37.357 |   1.0770 |     38.352 |     1.7
   30 |   1.0294 |     36.684 |   1.0773 |     37.980 |     1.8
   31 |   1.0161 |     36.431 |   1.0720 |     37.825 |     1.8
   32 |   1.0104 |     36.017 |   1.0497 |     37.546 |     1.9
   33 |   1.0038 |     35.951 |   1.0689 |     38.538 |     1.9
   34 |   0.9914 |     35.108 |   1.0542 |     37.237 |     2.0
   35 |   0.9860 |     35.053 |   1.0390 |     36.648 |     2.0
   36 |   0.9744 |     34.717 |   1.0617 |     37.608 |     2.1
   37 |   0.9673 |     34.055 |   1.0345 |     36.741 |     2.2
   38 |   0.9561 |     33.901 |   1.0167 |     35.936 |     2.2
   39 |   0.9397 |     33.157 |   1.0114 |     35.750 |     2.3
   40 |   0.9353 |     33.207 |   1.0138 |     35.595 |     2.3
   41 |   0.9534 |     34.281 |   1.0360 |     36.710 |     2.4
   42 |   0.9384 |     33.361 |   1.0059 |     35.843 |     2.5
   43 |   0.9116 |     32.016 |   1.0029 |     35.378 |     2.5
   44 |   0.9039 |     31.807 |   1.0069 |     35.440 |     2.6
   45 |   0.9045 |     31.801 |   0.9923 |     34.201 |     2.6
   46 |   0.8832 |     30.897 |   0.9870 |     34.696 |     2.7
   47 |   0.8708 |     30.230 |   0.9785 |     34.480 |     2.8
   48 |   0.8743 |     30.748 |   0.9762 |     34.139 |     2.8
   49 |   0.8500 |     29.415 |   0.9782 |     34.046 |     2.9
   50 |   0.8441 |     29.222 |   0.9698 |     33.953 |     3.0
   51 |   0.8300 |     28.814 |   0.9589 |     32.993 |     3.0
   52 |   0.8168 |     28.114 |   0.9752 |     32.900 |     3.1
   53 |   0.8112 |     28.119 |   0.9528 |     32.559 |     3.2
   54 |   0.7988 |     27.359 |   0.9675 |     33.395 |     3.2
   55 |   0.7875 |     27.050 |   0.9568 |     32.714 |     3.3
   56 |   0.7742 |     26.532 |   0.9509 |     31.939 |     3.4
   57 |   0.7666 |     26.505 |   0.9531 |     31.722 |     3.4
   58 |   0.7548 |     26.268 |   0.9474 |     31.753 |     3.5
   59 |   0.7393 |     25.336 |   0.9451 |     30.917 |     3.6
   60 |   0.7308 |     25.050 |   0.9618 |     30.669 |     3.6
   61 |   0.7295 |     25.006 |   0.9591 |     31.289 |     3.7
   62 |   0.7153 |     24.526 |   0.9318 |     30.452 |     3.8
   63 |   0.6956 |     23.523 |   0.9438 |     30.359 |     3.8
   64 |   0.6946 |     23.407 |   0.9441 |     30.359 |     3.9
   65 |   0.6792 |     23.110 |   0.9505 |     30.545 |     3.9
   66 |   0.6701 |     22.597 |   0.9267 |     30.204 |     4.0
   67 |   0.6562 |     22.101 |   0.9323 |     30.019 |     4.1
   68 |   0.6503 |     21.836 |   0.9519 |     29.864 |     4.1
   69 |   0.6399 |     21.522 |   0.9404 |     29.926 |     4.2
   70 |   0.6265 |     21.021 |   0.9568 |     29.585 |     4.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 360,098

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4784 |     66.556 |   1.8884 |     49.040 |     0.0
    2 |   1.6735 |     47.917 |   1.5281 |     46.344 |     0.0
    3 |   1.4730 |     45.949 |   1.4430 |     46.344 |     0.1
    4 |   1.4171 |     46.032 |   1.3967 |     46.344 |     0.1
    5 |   1.3846 |     45.850 |   1.3869 |     46.344 |     0.1
    6 |   1.3613 |     45.585 |   1.3514 |     45.229 |     0.1
    7 |   1.3453 |     45.315 |   1.3410 |     45.043 |     0.1
    8 |   1.3274 |     44.858 |   1.3259 |     44.857 |     0.2
    9 |   1.3139 |     44.389 |   1.3164 |     44.703 |     0.2
   10 |   1.3022 |     44.152 |   1.3118 |     44.579 |     0.2
   11 |   1.2911 |     43.987 |   1.2931 |     44.021 |     0.2
   12 |   1.2766 |     43.612 |   1.2798 |     43.525 |     0.3
   13 |   1.2574 |     42.984 |   1.2615 |     43.990 |     0.3
   14 |   1.2328 |     42.526 |   1.2409 |     42.844 |     0.3
   15 |   1.2099 |     41.876 |   1.2218 |     42.224 |     0.3
   16 |   1.1838 |     40.901 |   1.2005 |     41.574 |     0.3
   17 |   1.1578 |     40.201 |   1.1779 |     40.830 |     0.4
   18 |   1.1317 |     38.961 |   1.1693 |     40.242 |     0.4
   19 |   1.1103 |     38.327 |   1.1482 |     39.653 |     0.4
   20 |   1.0890 |     37.654 |   1.1427 |     38.817 |     0.4
   21 |   1.0635 |     36.728 |   1.1288 |     38.879 |     0.5
   22 |   1.0390 |     35.571 |   1.1126 |     37.825 |     0.5
   23 |   1.0158 |     34.766 |   1.1092 |     37.701 |     0.5
   24 |   0.9863 |     33.471 |   1.1115 |     37.454 |     0.5
   25 |   0.9670 |     32.655 |   1.0980 |     36.896 |     0.5
   26 |   0.9396 |     31.663 |   1.0942 |     36.648 |     0.6
   27 |   0.9116 |     30.363 |   1.0827 |     35.719 |     0.6
   28 |   0.8891 |     29.723 |   1.0879 |     35.719 |     0.6
   29 |   0.8643 |     28.974 |   1.0781 |     35.192 |     0.6
   30 |   0.8375 |     27.888 |   1.0774 |     33.984 |     0.6
   31 |   0.8198 |     27.155 |   1.0785 |     34.201 |     0.7
   32 |   0.7886 |     25.788 |   1.0767 |     34.418 |     0.7
   33 |   0.7683 |     25.044 |   1.0716 |     33.395 |     0.7
   34 |   0.7409 |     24.047 |   1.0775 |     33.147 |     0.7
   35 |   0.7226 |     23.446 |   1.0846 |     32.652 |     0.7
   36 |   0.7013 |     22.917 |   1.0971 |     32.559 |     0.8
   37 |   0.6829 |     22.090 |   1.0876 |     32.466 |     0.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 422,242

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5310 |     66.060 |   1.9709 |     56.444 |     0.0
    2 |   1.7573 |     49.532 |   1.5854 |     46.344 |     0.1
    3 |   1.5123 |     46.065 |   1.4590 |     46.344 |     0.1
    4 |   1.4318 |     45.960 |   1.4134 |     46.344 |     0.1
    5 |   1.3946 |     45.993 |   1.3764 |     46.097 |     0.1
    6 |   1.3608 |     45.387 |   1.3475 |     44.734 |     0.2
    7 |   1.3324 |     44.863 |   1.3243 |     45.043 |     0.2
    8 |   1.3096 |     44.444 |   1.3087 |     44.765 |     0.2
    9 |   1.2940 |     44.351 |   1.2896 |     44.486 |     0.2
   10 |   1.2800 |     43.937 |   1.2720 |     43.649 |     0.3
   11 |   1.2610 |     43.612 |   1.2627 |     43.680 |     0.3
   12 |   1.2446 |     43.469 |   1.2445 |     43.463 |     0.3
   13 |   1.2271 |     43.513 |   1.2310 |     43.618 |     0.4
   14 |   1.2104 |     42.879 |   1.2204 |     42.658 |     0.4
   15 |   1.1935 |     42.190 |   1.2015 |     42.007 |     0.4
   16 |   1.1776 |     41.358 |   1.1917 |     41.016 |     0.4
   17 |   1.1622 |     40.807 |   1.1809 |     40.582 |     0.5
   18 |   1.1458 |     40.085 |   1.1628 |     40.489 |     0.5
   19 |   1.1305 |     39.512 |   1.1686 |     40.118 |     0.5
   20 |   1.1160 |     38.812 |   1.1522 |     39.994 |     0.6
   21 |   1.1027 |     38.735 |   1.1355 |     39.746 |     0.6
   22 |   1.0861 |     37.814 |   1.1291 |     39.529 |     0.6
   23 |   1.0741 |     37.577 |   1.1278 |     39.405 |     0.6
   24 |   1.0577 |     36.888 |   1.1128 |     37.763 |     0.7
   25 |   1.0462 |     36.365 |   1.1082 |     38.197 |     0.7
   26 |   1.0290 |     35.703 |   1.0931 |     37.330 |     0.7
   27 |   1.0153 |     35.207 |   1.0841 |     37.546 |     0.8
   28 |   0.9999 |     34.397 |   1.0877 |     37.763 |     0.8
   29 |   0.9830 |     33.708 |   1.0668 |     36.369 |     0.8
   30 |   0.9641 |     32.992 |   1.0663 |     36.307 |     0.8
   31 |   0.9505 |     32.055 |   1.0572 |     35.316 |     0.9
   32 |   0.9288 |     31.459 |   1.0536 |     35.254 |     0.9
   33 |   0.9175 |     30.919 |   1.0371 |     34.851 |     0.9
   34 |   0.8977 |     30.087 |   1.0417 |     35.068 |     1.0
   35 |   0.8776 |     29.244 |   1.0185 |     33.860 |     1.0
   36 |   0.8562 |     28.290 |   1.0272 |     33.612 |     1.0
   37 |   0.8761 |     29.172 |   1.0233 |     33.519 |     1.0
   38 |   0.8378 |     27.723 |   0.9932 |     33.302 |     1.1
   39 |   0.8101 |     26.576 |   0.9928 |     32.404 |     1.1
   40 |   0.7924 |     26.157 |   1.0119 |     33.302 |     1.1
   41 |   0.7737 |     25.479 |   0.9920 |     32.249 |     1.2
   42 |   0.7620 |     24.978 |   1.0038 |     32.466 |     1.2
   43 |   0.7455 |     24.388 |   0.9902 |     32.094 |     1.2
   44 |   0.7331 |     23.958 |   0.9925 |     31.537 |     1.2
   45 |   0.7150 |     23.253 |   1.0149 |     31.970 |     1.3
   46 |   0.7022 |     23.021 |   0.9871 |     31.134 |     1.3
   47 |   0.6818 |     22.250 |   0.9822 |     30.762 |     1.3
   48 |   0.6722 |     21.947 |   1.0122 |     31.660 |     1.4
   49 |   0.6620 |     21.616 |   0.9919 |     30.824 |     1.4
   50 |   0.6407 |     21.125 |   1.0061 |     30.390 |     1.4
   51 |   0.6285 |     20.437 |   1.0065 |     30.545 |     1.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 507,298

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0149 |     55.627 |   1.4684 |     45.880 |     0.0
    2 |   1.3801 |     45.023 |   1.3303 |     44.548 |     0.0
    3 |   1.2974 |     44.174 |   1.2856 |     43.711 |     0.1
    4 |   1.2558 |     43.612 |   1.2563 |     43.030 |     0.1
    5 |   1.2270 |     42.989 |   1.2263 |     42.410 |     0.1
    6 |   1.2010 |     42.207 |   1.2050 |     42.069 |     0.1
    7 |   1.1800 |     41.975 |   1.1818 |     41.140 |     0.1
    8 |   1.1561 |     40.901 |   1.1728 |     41.388 |     0.1
    9 |   1.1361 |     40.410 |   1.1477 |     40.428 |     0.2
   10 |   1.1186 |     39.776 |   1.1430 |     40.830 |     0.2
   11 |   1.0991 |     39.076 |   1.1314 |     39.963 |     0.2
   12 |   1.0767 |     38.084 |   1.1022 |     38.693 |     0.2
   13 |   1.0559 |     37.131 |   1.0855 |     37.980 |     0.2
   14 |   1.0322 |     36.216 |   1.0714 |     37.485 |     0.3
   15 |   1.0125 |     35.251 |   1.0619 |     36.524 |     0.3
   16 |   0.9933 |     34.557 |   1.0500 |     36.989 |     0.3
   17 |   0.9741 |     33.857 |   1.0319 |     35.998 |     0.3
   18 |   0.9473 |     32.617 |   1.0160 |     35.688 |     0.3
   19 |   0.9290 |     32.187 |   0.9985 |     35.006 |     0.4
   20 |   0.9050 |     31.129 |   1.0058 |     35.564 |     0.4
   21 |   0.8854 |     30.473 |   0.9956 |     35.192 |     0.4
   22 |   0.8637 |     29.602 |   0.9741 |     33.581 |     0.4
   23 |   0.8427 |     29.001 |   0.9614 |     32.776 |     0.4
   24 |   0.8169 |     27.877 |   0.9420 |     32.094 |     0.4
   25 |   0.7968 |     27.205 |   0.9337 |     31.599 |     0.5
   26 |   0.7694 |     25.783 |   0.9191 |     30.917 |     0.5
   27 |   0.7464 |     24.978 |   0.9390 |     31.599 |     0.5
   28 |   0.7234 |     24.135 |   0.9180 |     30.328 |     0.5
   29 |   0.6983 |     23.506 |   0.9264 |     30.452 |     0.5
   30 |   0.6777 |     22.310 |   0.9019 |     29.306 |     0.6
   31 |   0.6518 |     21.533 |   0.8965 |     28.903 |     0.6
   32 |   0.6322 |     20.618 |   0.8955 |     28.408 |     0.6
   33 |   0.6019 |     19.466 |   0.9040 |     29.368 |     0.6
   34 |   0.5820 |     18.904 |   0.9054 |     28.656 |     0.6
   35 |   0.5626 |     18.265 |   0.9010 |     28.563 |     0.6
   36 |   0.5450 |     17.637 |   0.9147 |     28.717 |     0.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 423,970

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4762 |     66.138 |   1.9503 |     55.700 |     0.0
    2 |   1.7218 |     48.787 |   1.5407 |     46.344 |     0.1
    3 |   1.4708 |     45.861 |   1.4183 |     46.344 |     0.1
    4 |   1.3913 |     45.602 |   1.3700 |     45.291 |     0.1
    5 |   1.3495 |     45.001 |   1.3362 |     44.734 |     0.2
    6 |   1.3210 |     44.516 |   1.3198 |     45.229 |     0.2
    7 |   1.3042 |     44.340 |   1.3040 |     45.415 |     0.2
    8 |   1.2886 |     44.351 |   1.2946 |     44.300 |     0.2
    9 |   1.2719 |     43.899 |   1.2706 |     43.711 |     0.3
   10 |   1.2548 |     43.430 |   1.2600 |     43.247 |     0.3
   11 |   1.2374 |     42.780 |   1.2372 |     42.782 |     0.3
   12 |   1.2188 |     42.350 |   1.2222 |     42.255 |     0.4
   13 |   1.2041 |     41.744 |   1.2131 |     41.822 |     0.4
   14 |   1.1867 |     41.171 |   1.1996 |     41.574 |     0.4
   15 |   1.1681 |     40.405 |   1.1887 |     41.202 |     0.5
   16 |   1.1481 |     39.589 |   1.1744 |     40.613 |     0.5
   17 |   1.1285 |     39.043 |   1.1578 |     40.025 |     0.5
   18 |   1.1015 |     37.825 |   1.1453 |     39.870 |     0.5
   19 |   1.0807 |     37.087 |   1.1305 |     39.095 |     0.6
   20 |   1.0532 |     35.775 |   1.1173 |     37.949 |     0.6
   21 |   1.0287 |     34.772 |   1.1030 |     37.918 |     0.6
   22 |   1.0000 |     33.532 |   1.0841 |     37.020 |     0.7
   23 |   0.9767 |     32.755 |   1.0904 |     36.989 |     0.7
   24 |   0.9478 |     31.382 |   1.0683 |     35.874 |     0.7
   25 |   0.9232 |     30.699 |   1.0675 |     35.440 |     0.8
   26 |   0.8897 |     29.101 |   1.0499 |     34.975 |     0.8
   27 |   0.8606 |     28.406 |   1.0405 |     33.953 |     0.8
   28 |   0.8321 |     27.094 |   1.0252 |     33.550 |     0.8
   29 |   0.8064 |     26.427 |   1.0409 |     33.674 |     0.9
   30 |   0.7923 |     25.788 |   1.0165 |     32.931 |     0.9
   31 |   0.7633 |     24.746 |   1.0039 |     31.320 |     0.9
   32 |   0.7322 |     23.473 |   1.0076 |     31.320 |     1.0
   33 |   0.7127 |     22.812 |   0.9917 |     31.351 |     1.0
   34 |   0.6868 |     22.068 |   1.0038 |     30.452 |     1.0
   35 |   0.6603 |     20.883 |   1.0101 |     30.421 |     1.1
   36 |   0.6453 |     20.552 |   1.0064 |     30.328 |     1.1
   37 |   0.6254 |     19.929 |   1.0165 |     30.081 |     1.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 621,538

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9940 |     55.297 |   1.4565 |     45.911 |     0.0
    2 |   1.3842 |     45.464 |   1.3459 |     45.477 |     0.1
    3 |   1.3081 |     44.417 |   1.2893 |     45.012 |     0.1
    4 |   1.2639 |     43.634 |   1.2578 |     44.021 |     0.1
    5 |   1.2311 |     43.298 |   1.2264 |     43.061 |     0.1
    6 |   1.2004 |     41.909 |   1.2002 |     41.667 |     0.2
    7 |   1.1698 |     41.452 |   1.1771 |     41.388 |     0.2
    8 |   1.1368 |     40.449 |   1.1405 |     40.149 |     0.2
    9 |   1.1062 |     38.983 |   1.1177 |     38.817 |     0.2
   10 |   1.0733 |     37.809 |   1.1002 |     38.073 |     0.3
   11 |   1.0444 |     36.541 |   1.0663 |     37.794 |     0.3
   12 |   1.0082 |     35.180 |   1.0525 |     37.454 |     0.3
   13 |   0.9790 |     33.438 |   1.0291 |     36.059 |     0.3
   14 |   0.9582 |     33.058 |   1.0296 |     36.586 |     0.4
   15 |   0.9257 |     31.713 |   1.0012 |     34.511 |     0.4
   16 |   0.8901 |     30.445 |   0.9863 |     34.170 |     0.4
   17 |   0.8563 |     29.139 |   0.9706 |     33.829 |     0.5
   18 |   0.8318 |     28.119 |   0.9664 |     32.962 |     0.5
   19 |   0.7962 |     26.598 |   0.9517 |     32.094 |     0.5
   20 |   0.7642 |     25.634 |   0.9603 |     32.404 |     0.5
   21 |   0.7353 |     24.421 |   0.9463 |     32.094 |     0.6
   22 |   0.7018 |     23.313 |   0.9282 |     30.607 |     0.6
   23 |   0.6736 |     22.090 |   0.9179 |     30.297 |     0.6
   24 |   0.6420 |     21.120 |   0.9173 |     29.833 |     0.6
   25 |   0.6131 |     20.007 |   0.9195 |     29.895 |     0.7
   26 |   0.5887 |     19.334 |   0.9397 |     29.926 |     0.7
   27 |   0.5653 |     18.392 |   0.9188 |     28.315 |     0.7
   28 |   0.5363 |     17.284 |   0.9372 |     28.872 |     0.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 850,786

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2220 |     60.185 |   1.6099 |     46.344 |     0.0
    2 |   1.4792 |     45.977 |   1.4231 |     47.150 |     0.1
    3 |   1.3989 |     46.015 |   1.3795 |     45.446 |     0.1
    4 |   1.3633 |     45.442 |   1.3513 |     45.911 |     0.1
    5 |   1.3361 |     45.310 |   1.3317 |     45.818 |     0.2
    6 |   1.3172 |     45.282 |   1.3115 |     44.919 |     0.2
    7 |   1.2997 |     45.211 |   1.2961 |     44.641 |     0.3
    8 |   1.2813 |     44.599 |   1.2823 |     44.517 |     0.3
    9 |   1.2644 |     44.174 |   1.2631 |     44.114 |     0.3
   10 |   1.2480 |     43.761 |   1.2505 |     43.649 |     0.4
   11 |   1.2309 |     43.204 |   1.2378 |     43.990 |     0.4
   12 |   1.2153 |     42.824 |   1.2147 |     42.255 |     0.4
   13 |   1.1943 |     42.405 |   1.2050 |     42.224 |     0.5
   14 |   1.1745 |     41.832 |   1.1951 |     41.636 |     0.5
   15 |   1.1602 |     41.259 |   1.1693 |     41.357 |     0.5
   16 |   1.1384 |     40.267 |   1.1587 |     40.613 |     0.6
   17 |   1.1153 |     39.771 |   1.1460 |     40.985 |     0.6
   18 |   1.0965 |     38.735 |   1.1361 |     40.613 |     0.6
   19 |   1.0749 |     37.731 |   1.1137 |     38.971 |     0.7
   20 |   1.0523 |     36.976 |   1.0941 |     38.321 |     0.7
   21 |   1.0336 |     36.095 |   1.0895 |     38.352 |     0.7
   22 |   1.0127 |     35.499 |   1.0626 |     36.896 |     0.8
   23 |   0.9945 |     34.270 |   1.0557 |     36.462 |     0.8
   24 |   0.9702 |     33.532 |   1.0288 |     35.378 |     0.9
   25 |   0.9440 |     32.314 |   1.0191 |     34.511 |     0.9
   26 |   0.9234 |     31.581 |   1.0143 |     34.851 |     0.9
   27 |   0.9018 |     30.793 |   1.0002 |     33.395 |     1.0
   28 |   0.8774 |     29.966 |   0.9953 |     33.457 |     1.0
   29 |   0.8575 |     28.897 |   0.9914 |     32.745 |     1.0
   30 |   0.8338 |     28.197 |   0.9824 |     32.311 |     1.1
   31 |   0.8056 |     26.819 |   0.9807 |     32.838 |     1.1
   32 |   0.7829 |     25.788 |   0.9717 |     31.227 |     1.1
   33 |   0.7567 |     24.945 |   0.9558 |     31.165 |     1.2
   34 |   0.7311 |     24.002 |   0.9827 |     30.979 |     1.2
   35 |   0.7137 |     23.313 |   0.9768 |     31.258 |     1.3
   36 |   0.6922 |     22.542 |   0.9556 |     31.227 |     1.3
   37 |   0.6699 |     21.825 |   0.9445 |     29.833 |     1.3
   38 |   0.6485 |     21.153 |   0.9573 |     30.452 |     1.4
   39 |   0.6382 |     20.839 |   0.9587 |     29.337 |     1.4
   40 |   0.6150 |     19.770 |   0.9542 |     29.616 |     1.4
   41 |   0.5931 |     19.020 |   0.9488 |     29.585 |     1.5
   42 |   0.5714 |     18.226 |   0.9288 |     28.005 |     1.5
   43 |   0.5565 |     17.857 |   0.9573 |     28.532 |     1.6
   44 |   0.5373 |     16.926 |   0.9682 |     28.779 |     1.6
   45 |   0.5158 |     16.479 |   0.9690 |     27.726 |     1.6
   46 |   0.5106 |     16.308 |   0.9611 |     27.757 |     1.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 766,626

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5813 |     68.430 |   2.0155 |     59.851 |     0.0
    2 |   1.7847 |     50.529 |   1.5808 |     46.344 |     0.1
    3 |   1.5057 |     46.219 |   1.4566 |     46.344 |     0.1
    4 |   1.4356 |     45.922 |   1.4185 |     46.344 |     0.2
    5 |   1.4095 |     46.010 |   1.3978 |     46.344 |     0.2
    6 |   1.3902 |     45.944 |   1.3796 |     46.344 |     0.2
    7 |   1.3692 |     45.806 |   1.3581 |     45.446 |     0.3
    8 |   1.3428 |     45.414 |   1.3363 |     45.446 |     0.3
    9 |   1.3233 |     44.979 |   1.3184 |     44.796 |     0.4
   10 |   1.3039 |     44.593 |   1.3020 |     44.548 |     0.4
   11 |   1.2855 |     44.329 |   1.2892 |     44.919 |     0.5
   12 |   1.2691 |     44.202 |   1.2765 |     43.804 |     0.5
   13 |   1.2582 |     43.970 |   1.2661 |     43.649 |     0.5
   14 |   1.2471 |     43.563 |   1.2565 |     43.401 |     0.6
   15 |   1.2370 |     43.133 |   1.2442 |     43.494 |     0.6
   16 |   1.2264 |     42.890 |   1.2362 |     43.371 |     0.7
   17 |   1.2175 |     42.582 |   1.2258 |     42.131 |     0.7
   18 |   1.2072 |     42.323 |   1.2217 |     42.627 |     0.7
   19 |   1.1959 |     41.942 |   1.2066 |     41.760 |     0.8
   20 |   1.1853 |     41.578 |   1.2047 |     41.667 |     0.8
   21 |   1.1750 |     41.402 |   1.1871 |     41.450 |     0.9
   22 |   1.1612 |     40.686 |   1.1805 |     41.078 |     0.9
   23 |   1.1521 |     40.575 |   1.1695 |     40.613 |     1.0
   24 |   1.1411 |     40.013 |   1.1628 |     40.397 |     1.0
   25 |   1.1308 |     39.710 |   1.1560 |     40.644 |     1.0
   26 |   1.1169 |     39.159 |   1.1444 |     40.335 |     1.1
   27 |   1.1034 |     38.823 |   1.1375 |     40.149 |     1.1
   28 |   1.0926 |     38.415 |   1.1330 |     39.653 |     1.2
   29 |   1.0798 |     37.550 |   1.1262 |     38.910 |     1.2
   30 |   1.0682 |     37.246 |   1.1181 |     38.693 |     1.2
   31 |   1.0502 |     36.591 |   1.1237 |     38.073 |     1.3
   32 |   1.0392 |     36.249 |   1.1046 |     37.949 |     1.3
   33 |   1.0226 |     35.417 |   1.1095 |     37.825 |     1.4
   34 |   1.0074 |     34.733 |   1.0988 |     37.020 |     1.4
   35 |   0.9941 |     34.309 |   1.0907 |     36.648 |     1.4
   36 |   0.9789 |     33.482 |   1.0891 |     36.927 |     1.5
   37 |   0.9636 |     33.052 |   1.0807 |     36.772 |     1.5
   38 |   0.9438 |     32.474 |   1.0830 |     35.843 |     1.6
   39 |   0.9334 |     31.917 |   1.0712 |     35.533 |     1.6
   40 |   0.9104 |     30.903 |   1.0691 |     35.874 |     1.7
   41 |   0.8958 |     30.015 |   1.0706 |     35.409 |     1.7
   42 |   0.8798 |     29.558 |   1.0503 |     35.471 |     1.7
   43 |   0.8616 |     28.753 |   1.0480 |     34.882 |     1.8
   44 |   0.8400 |     27.998 |   1.0547 |     34.944 |     1.8
   45 |   0.8234 |     27.342 |   1.0512 |     34.542 |     1.9
   46 |   0.8008 |     26.488 |   1.0436 |     34.356 |     1.9
   47 |   0.7891 |     26.119 |   1.0386 |     34.015 |     1.9
   48 |   0.7695 |     25.535 |   1.0572 |     34.201 |     2.0
   49 |   0.7712 |     25.331 |   1.0516 |     34.356 |     2.0
   50 |   0.7432 |     24.565 |   1.0676 |     33.024 |     2.1
   51 |   0.7315 |     23.826 |   1.0416 |     33.086 |     2.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,559,522

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2088 |     59.513 |   1.6144 |     49.442 |     0.1
    2 |   1.4771 |     46.313 |   1.4081 |     46.344 |     0.1
    3 |   1.3904 |     45.877 |   1.3579 |     45.446 |     0.2
    4 |   1.3407 |     45.707 |   1.3300 |     46.871 |     0.2
    5 |   1.3111 |     45.177 |   1.3066 |     45.942 |     0.3
    6 |   1.2941 |     44.781 |   1.2828 |     44.579 |     0.4
    7 |   1.2641 |     44.202 |   1.2568 |     45.384 |     0.4
    8 |   1.2402 |     44.070 |   1.2336 |     43.990 |     0.5
    9 |   1.2204 |     43.375 |   1.2265 |     43.711 |     0.6
   10 |   1.2066 |     42.934 |   1.2089 |     43.185 |     0.6
   11 |   1.1911 |     42.609 |   1.2011 |     42.410 |     0.7
   12 |   1.1812 |     42.300 |   1.1929 |     42.317 |     0.7
   13 |   1.1729 |     42.075 |   1.1844 |     42.100 |     0.8
   14 |   1.1659 |     41.931 |   1.1863 |     42.131 |     0.9
   15 |   1.1591 |     41.562 |   1.1708 |     41.264 |     0.9
   16 |   1.1531 |     41.386 |   1.1683 |     41.512 |     1.0
   17 |   1.1468 |     41.319 |   1.1605 |     42.193 |     1.0
   18 |   1.1407 |     41.116 |   1.1583 |     41.202 |     1.1
   19 |   1.1333 |     40.840 |   1.1517 |     41.388 |     1.2
   20 |   1.1306 |     40.851 |   1.1494 |     41.884 |     1.2
   21 |   1.1233 |     40.752 |   1.1444 |     41.140 |     1.3
   22 |   1.1208 |     40.631 |   1.1433 |     41.109 |     1.3
   23 |   1.1152 |     40.394 |   1.1352 |     40.799 |     1.4
   24 |   1.1126 |     40.603 |   1.1335 |     40.830 |     1.5
   25 |   1.1051 |     40.487 |   1.1285 |     40.644 |     1.5
   26 |   1.1028 |     40.289 |   1.1322 |     41.109 |     1.6
   27 |   1.0976 |     40.079 |   1.1271 |     40.830 |     1.7
   28 |   1.0975 |     40.471 |   1.1173 |     41.295 |     1.7
   29 |   1.0913 |     40.168 |   1.1265 |     41.047 |     1.8
   30 |   1.0910 |     40.316 |   1.1179 |     40.706 |     1.8
   31 |   1.0873 |     39.942 |   1.1107 |     41.171 |     1.9
   32 |   1.0852 |     40.201 |   1.1119 |     40.861 |     2.0
   33 |   1.0812 |     39.925 |   1.1096 |     39.746 |     2.0
   34 |   1.0799 |     39.986 |   1.1088 |     40.799 |     2.1
   35 |   1.0801 |     39.782 |   1.1123 |     40.397 |     2.1
   36 |   1.0768 |     39.925 |   1.1092 |     40.551 |     2.2
   37 |   1.0762 |     39.688 |   1.1084 |     40.706 |     2.3
   38 |   1.0740 |     39.975 |   1.1012 |     40.087 |     2.3
   39 |   1.0713 |     39.859 |   1.1024 |     40.613 |     2.4
   40 |   1.0739 |     40.035 |   1.1001 |     40.118 |     2.5
   41 |   1.0686 |     39.699 |   1.1019 |     40.273 |     2.5
   42 |   1.0675 |     39.787 |   1.1043 |     42.720 |     2.6
   43 |   1.0685 |     39.479 |   1.0996 |     40.118 |     2.6
   44 |   1.0676 |     40.090 |   1.0984 |     41.512 |     2.7
   45 |   1.0669 |     39.710 |   1.0996 |     40.056 |     2.8
   46 |   1.0622 |     39.732 |   1.0993 |     41.171 |     2.8
   47 |   1.0655 |     39.760 |   1.0947 |     39.994 |     2.9
   48 |   1.0623 |     39.506 |   1.0952 |     40.273 |     3.0
   49 |   1.0621 |     39.721 |   1.0984 |     41.109 |     3.0
   50 |   1.0594 |     39.346 |   1.0946 |     41.326 |     3.1
   51 |   1.0593 |     39.694 |   1.0894 |     39.808 |     3.1
   52 |   1.0596 |     39.897 |   1.0901 |     40.211 |     3.2
   53 |   1.0600 |     39.638 |   1.0925 |     40.273 |     3.3
   54 |   1.0594 |     39.561 |   1.0873 |     40.242 |     3.3
   55 |   1.0574 |     39.754 |   1.0877 |     39.839 |     3.4
   56 |   1.0577 |     39.484 |   1.0921 |     39.932 |     3.4
   57 |   1.0579 |     39.517 |   1.0934 |     40.211 |     3.5
   58 |   1.0578 |     39.727 |   1.0879 |     39.870 |     3.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,132,962

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1740 |     59.055 |   1.5919 |     46.344 |     0.0
    2 |   1.4687 |     45.916 |   1.4139 |     47.150 |     0.1
    3 |   1.3932 |     45.817 |   1.3733 |     46.344 |     0.1
    4 |   1.3614 |     45.343 |   1.3456 |     45.105 |     0.2
    5 |   1.3359 |     45.117 |   1.3403 |     46.159 |     0.2
    6 |   1.3155 |     45.034 |   1.3103 |     44.362 |     0.2
    7 |   1.2948 |     44.544 |   1.2934 |     44.517 |     0.3
    8 |   1.2748 |     44.114 |   1.2730 |     43.928 |     0.3
    9 |   1.2579 |     43.767 |   1.2584 |     44.145 |     0.4
   10 |   1.2390 |     43.353 |   1.2363 |     42.751 |     0.4
   11 |   1.2158 |     42.879 |   1.2261 |     42.534 |     0.5
   12 |   1.1946 |     42.058 |   1.2104 |     41.914 |     0.5
   13 |   1.1764 |     41.413 |   1.2036 |     41.853 |     0.6
   14 |   1.1552 |     40.526 |   1.1769 |     40.737 |     0.6
   15 |   1.1307 |     39.616 |   1.1638 |     40.304 |     0.6
   16 |   1.1063 |     38.635 |   1.1436 |     40.087 |     0.7
   17 |   1.0808 |     37.754 |   1.1327 |     39.002 |     0.7
   18 |   1.0567 |     36.905 |   1.1094 |     38.693 |     0.8
   19 |   1.0274 |     35.549 |   1.0883 |     37.485 |     0.8
   20 |   1.0012 |     34.221 |   1.0764 |     37.175 |     0.8
   21 |   0.9745 |     33.444 |   1.0685 |     36.617 |     0.9
   22 |   0.9427 |     31.597 |   1.0377 |     35.316 |     0.9
   23 |   0.9095 |     30.666 |   1.0246 |     34.263 |     1.0
   24 |   0.8777 |     29.343 |   1.0069 |     33.767 |     1.0
   25 |   0.8399 |     28.075 |   1.0007 |     32.621 |     1.1
   26 |   0.8003 |     26.383 |   0.9862 |     32.280 |     1.1
   27 |   0.7612 |     25.028 |   0.9794 |     32.094 |     1.1
   28 |   0.7263 |     23.980 |   0.9760 |     30.886 |     1.2
   29 |   0.6999 |     22.834 |   0.9650 |     30.173 |     1.2
   30 |   0.6599 |     21.721 |   0.9799 |     30.483 |     1.3
   31 |   0.6251 |     20.332 |   0.9530 |     29.275 |     1.3
   32 |   0.5838 |     18.546 |   0.9638 |     28.996 |     1.3
   33 |   0.5560 |     17.708 |   0.9720 |     28.686 |     1.4
   34 |   0.5286 |     16.760 |   0.9790 |     28.779 |     1.4
   35 |   0.4965 |     15.427 |   0.9836 |     28.872 |     1.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,622,690

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5156 |     67.741 |   1.9616 |     58.426 |     0.1
    2 |   1.7246 |     48.837 |   1.5495 |     46.344 |     0.2
    3 |   1.4831 |     46.043 |   1.4493 |     46.344 |     0.2
    4 |   1.4266 |     46.192 |   1.4162 |     46.344 |     0.3
    5 |   1.4046 |     45.966 |   1.3963 |     46.344 |     0.4
    6 |   1.3918 |     45.993 |   1.3847 |     46.097 |     0.5
    7 |   1.3745 |     45.828 |   1.3675 |     45.353 |     0.6
    8 |   1.3544 |     45.282 |   1.3526 |     45.105 |     0.7
    9 |   1.3360 |     45.244 |   1.3304 |     45.260 |     0.7
   10 |   1.3194 |     44.775 |   1.3173 |     44.857 |     0.8
   11 |   1.3018 |     44.593 |   1.3038 |     44.610 |     0.9
   12 |   1.2858 |     44.224 |   1.2835 |     44.579 |     1.0
   13 |   1.2694 |     43.844 |   1.2706 |     43.835 |     1.1
   14 |   1.2552 |     43.722 |   1.2613 |     43.525 |     1.2
   15 |   1.2388 |     43.188 |   1.2440 |     43.463 |     1.2
   16 |   1.2245 |     42.912 |   1.2355 |     42.999 |     1.3
   17 |   1.2115 |     42.609 |   1.2216 |     43.897 |     1.4
   18 |   1.1951 |     42.234 |   1.2035 |     42.379 |     1.5
   19 |   1.1778 |     41.529 |   1.1941 |     42.348 |     1.6
   20 |   1.1656 |     41.253 |   1.1826 |     41.233 |     1.7
   21 |   1.1479 |     40.283 |   1.1689 |     41.047 |     1.7
   22 |   1.1308 |     39.881 |   1.1632 |     40.211 |     1.8
   23 |   1.1159 |     39.192 |   1.1470 |     40.397 |     1.9
   24 |   1.1032 |     38.663 |   1.1431 |     39.467 |     2.0
   25 |   1.0880 |     37.715 |   1.1319 |     39.095 |     2.1
   26 |   1.0765 |     37.616 |   1.1210 |     38.600 |     2.2
   27 |   1.0571 |     36.651 |   1.1095 |     38.879 |     2.3
   28 |   1.0442 |     36.254 |   1.1056 |     37.330 |     2.4
   29 |   1.0285 |     35.819 |   1.1123 |     37.918 |     2.5
   30 |   1.0140 |     35.174 |   1.0975 |     37.485 |     2.6
   31 |   0.9968 |     34.529 |   1.0926 |     36.865 |     2.6
   32 |   0.9816 |     33.785 |   1.0848 |     36.462 |     2.7
   33 |   0.9638 |     33.201 |   1.0795 |     36.493 |     2.8
   34 |   0.9456 |     32.518 |   1.0671 |     35.905 |     2.9
   35 |   0.9271 |     31.531 |   1.0671 |     35.750 |     3.0
   36 |   0.9050 |     30.489 |   1.0673 |     35.595 |     3.1
   37 |   0.8930 |     29.922 |   1.0538 |     34.851 |     3.2
   38 |   0.8660 |     28.549 |   1.0602 |     34.294 |     3.2
   39 |   0.8533 |     28.312 |   1.0434 |     33.767 |     3.3
   40 |   0.8301 |     27.210 |   1.0475 |     33.612 |     3.4
   41 |   0.8111 |     26.527 |   1.0372 |     32.683 |     3.5
   42 |   0.8009 |     26.251 |   1.0400 |     33.271 |     3.6
   43 |   0.7737 |     25.419 |   1.0376 |     32.931 |     3.7
   44 |   0.7477 |     24.476 |   1.0367 |     32.218 |     3.8
   45 |   0.7298 |     23.749 |   1.0463 |     32.125 |     3.9
   46 |   0.7143 |     23.280 |   1.0376 |     31.722 |     4.0
   47 |   0.6901 |     22.316 |   1.0227 |     32.125 |     4.1
   48 |   0.6689 |     21.346 |   1.0407 |     31.382 |     4.2
   49 |   0.6501 |     20.740 |   1.0381 |     30.731 |     4.2
   50 |   0.6318 |     20.211 |   1.0428 |     30.824 |     4.3
   51 |   0.6089 |     19.621 |   1.0237 |     29.988 |     4.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,573,730

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3260 |     60.681 |   1.7602 |     48.978 |     0.1
    2 |   1.5718 |     47.239 |   1.4523 |     46.097 |     0.2
    3 |   1.4089 |     45.861 |   1.3730 |     46.314 |     0.3
    4 |   1.3535 |     45.018 |   1.3366 |     45.229 |     0.3
    5 |   1.3220 |     44.588 |   1.3129 |     44.579 |     0.4
    6 |   1.2991 |     44.180 |   1.2980 |     44.579 |     0.5
    7 |   1.2818 |     44.130 |   1.2740 |     43.618 |     0.6
    8 |   1.2657 |     43.717 |   1.2638 |     43.123 |     0.7
    9 |   1.2468 |     43.397 |   1.2503 |     42.627 |     0.8
   10 |   1.2268 |     42.659 |   1.2280 |     42.100 |     0.9
   11 |   1.2087 |     41.937 |   1.2103 |     42.007 |     1.0
   12 |   1.1889 |     41.303 |   1.1964 |     41.636 |     1.0
   13 |   1.1673 |     40.355 |   1.1750 |     40.489 |     1.1
   14 |   1.1498 |     39.583 |   1.1646 |     40.768 |     1.2
   15 |   1.1267 |     38.674 |   1.1398 |     39.653 |     1.3
   16 |   1.1052 |     37.825 |   1.1261 |     38.941 |     1.4
   17 |   1.0830 |     37.257 |   1.1092 |     37.825 |     1.5
   18 |   1.0588 |     36.100 |   1.1028 |     38.042 |     1.6
   19 |   1.0355 |     34.788 |   1.0833 |     37.020 |     1.6
   20 |   1.0098 |     34.177 |   1.0710 |     36.586 |     1.7
   21 |   0.9753 |     32.319 |   1.0507 |     35.471 |     1.8
   22 |   0.9448 |     31.002 |   1.0423 |     35.006 |     1.9
   23 |   0.9195 |     30.390 |   1.0210 |     34.387 |     2.0
   24 |   0.8823 |     28.897 |   1.0169 |     34.603 |     2.1
   25 |   0.8533 |     27.712 |   0.9978 |     33.426 |     2.2
   26 |   0.8268 |     26.681 |   0.9948 |     32.652 |     2.3
   27 |   0.7920 |     25.777 |   0.9750 |     32.218 |     2.4
   28 |   0.7587 |     24.741 |   0.9688 |     32.342 |     2.5
   29 |   0.7239 |     23.253 |   0.9694 |     31.691 |     2.5
   30 |   0.6945 |     22.404 |   0.9686 |     31.629 |     2.6
   31 |   0.6739 |     21.555 |   0.9580 |     30.824 |     2.7
   32 |   0.6398 |     20.519 |   0.9669 |     30.235 |     2.8
   33 |   0.6140 |     19.466 |   0.9603 |     29.926 |     2.9
   34 |   0.5880 |     18.601 |   0.9783 |     30.019 |     3.0
   35 |   0.5747 |     18.243 |   0.9976 |     30.173 |     3.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,495,202

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0735 |     56.498 |   1.4962 |     46.344 |     0.1
    2 |   1.4216 |     45.817 |   1.3817 |     45.849 |     0.1
    3 |   1.3514 |     45.337 |   1.3311 |     45.632 |     0.2
    4 |   1.3039 |     44.533 |   1.2918 |     44.857 |     0.3
    5 |   1.2735 |     44.202 |   1.2607 |     44.052 |     0.3
    6 |   1.2466 |     43.199 |   1.2474 |     44.641 |     0.4
    7 |   1.2238 |     42.934 |   1.2257 |     42.875 |     0.5
    8 |   1.2071 |     42.400 |   1.2099 |     42.255 |     0.5
    9 |   1.1891 |     42.119 |   1.1972 |     41.760 |     0.6
   10 |   1.1708 |     41.435 |   1.1713 |     40.923 |     0.7
   11 |   1.1528 |     40.691 |   1.1612 |     40.397 |     0.7
   12 |   1.1315 |     39.705 |   1.1390 |     40.613 |     0.8
   13 |   1.1109 |     38.944 |   1.1389 |     40.520 |     0.9
   14 |   1.0899 |     38.068 |   1.1125 |     38.476 |     0.9
   15 |   1.0696 |     37.109 |   1.0948 |     38.321 |     1.0
   16 |   1.0521 |     36.745 |   1.0782 |     37.825 |     1.1
   17 |   1.0331 |     35.836 |   1.0569 |     37.144 |     1.2
   18 |   1.0101 |     35.295 |   1.0577 |     37.113 |     1.2
   19 |   0.9912 |     34.502 |   1.0288 |     35.905 |     1.3
   20 |   0.9701 |     33.526 |   1.0088 |     35.254 |     1.3
   21 |   0.9470 |     32.870 |   1.0019 |     34.851 |     1.4
   22 |   0.9304 |     32.137 |   0.9997 |     34.696 |     1.5
   23 |   0.9037 |     30.699 |   0.9837 |     34.232 |     1.5
   24 |   0.8847 |     30.511 |   0.9617 |     33.055 |     1.6
   25 |   0.8677 |     29.453 |   0.9624 |     33.240 |     1.7
   26 |   0.8428 |     28.654 |   0.9535 |     33.024 |     1.7
   27 |   0.8228 |     27.701 |   0.9303 |     32.435 |     1.8
   28 |   0.8011 |     26.979 |   0.9271 |     31.753 |     1.9
   29 |   0.7758 |     26.108 |   0.9123 |     31.475 |     1.9
   30 |   0.7503 |     25.116 |   0.9109 |     31.413 |     2.0
   31 |   0.7300 |     24.454 |   0.9107 |     31.165 |     2.1
   32 |   0.7100 |     23.506 |   0.9000 |     29.957 |     2.1
   33 |   0.6961 |     23.380 |   0.8910 |     29.120 |     2.2
   34 |   0.6681 |     22.162 |   0.8938 |     29.461 |     2.3
   35 |   0.6519 |     21.522 |   0.8824 |     28.748 |     2.3
   36 |   0.6257 |     20.613 |   0.8819 |     28.160 |     2.4
   37 |   0.5997 |     19.869 |   0.8914 |     28.532 |     2.5
   38 |   0.5856 |     19.213 |   0.8677 |     28.191 |     2.5
   39 |   0.5615 |     18.408 |   0.8646 |     27.509 |     2.6
   40 |   0.5414 |     17.835 |   0.8839 |     27.416 |     2.7
   41 |   0.5242 |     17.119 |   0.8694 |     26.890 |     2.8
   42 |   0.5076 |     16.512 |   0.8980 |     27.385 |     2.8
   43 |   0.4901 |     16.088 |   0.8622 |     26.363 |     2.9
   44 |   0.4672 |     15.112 |   0.8763 |     26.735 |     2.9
   45 |   0.4585 |     14.886 |   0.9131 |     27.014 |     3.0
   46 |   0.4435 |     14.401 |   0.8826 |     26.084 |     3.1
   47 |   0.4216 |     13.591 |   0.8758 |     25.836 |     3.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,098,722

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2070 |     59.777 |   1.5887 |     46.344 |     0.0
    2 |   1.4647 |     45.960 |   1.4097 |     46.344 |     0.1
    3 |   1.3805 |     45.707 |   1.3652 |     45.880 |     0.1
    4 |   1.3437 |     45.475 |   1.3402 |     45.818 |     0.2
    5 |   1.3143 |     45.266 |   1.3057 |     44.300 |     0.2
    6 |   1.2885 |     44.670 |   1.2861 |     45.570 |     0.3
    7 |   1.2629 |     44.241 |   1.2640 |     43.649 |     0.3
    8 |   1.2420 |     43.844 |   1.2370 |     43.309 |     0.4
    9 |   1.2205 |     43.006 |   1.2256 |     43.525 |     0.4
   10 |   1.2011 |     42.725 |   1.2109 |     42.255 |     0.4
   11 |   1.1879 |     42.124 |   1.1958 |     41.945 |     0.5
   12 |   1.1746 |     41.760 |   1.1988 |     42.751 |     0.5
   13 |   1.1623 |     41.402 |   1.1902 |     41.884 |     0.6
   14 |   1.1600 |     41.771 |   1.1787 |     42.503 |     0.6
   15 |   1.1493 |     41.628 |   1.1624 |     41.667 |     0.7
   16 |   1.1374 |     40.906 |   1.1501 |     41.791 |     0.7
   17 |   1.1240 |     40.322 |   1.1422 |     40.149 |     0.8
   18 |   1.1160 |     39.931 |   1.1392 |     40.520 |     0.8
   19 |   1.1092 |     39.903 |   1.1314 |     40.304 |     0.9
   20 |   1.0964 |     39.490 |   1.1174 |     39.963 |     0.9
   21 |   1.0891 |     39.236 |   1.1160 |     38.848 |     0.9
   22 |   1.0821 |     38.740 |   1.1171 |     40.242 |     1.0
   23 |   1.0726 |     38.641 |   1.0958 |     38.848 |     1.0
   24 |   1.0650 |     38.481 |   1.0933 |     39.436 |     1.1
   25 |   1.0579 |     38.145 |   1.0911 |     39.095 |     1.1
   26 |   1.0460 |     37.627 |   1.0815 |     39.281 |     1.1
   27 |   1.0416 |     37.787 |   1.0817 |     39.250 |     1.2
   28 |   1.0351 |     37.274 |   1.0867 |     39.312 |     1.2
   29 |   1.0296 |     36.965 |   1.0653 |     38.848 |     1.3
   30 |   1.0184 |     36.894 |   1.0585 |     37.639 |     1.3
   31 |   1.0106 |     36.580 |   1.0578 |     37.918 |     1.4
   32 |   1.0054 |     36.381 |   1.0496 |     37.732 |     1.4
   33 |   0.9959 |     35.703 |   1.0620 |     38.352 |     1.4
   34 |   0.9893 |     35.924 |   1.0322 |     36.493 |     1.5
   35 |   0.9773 |     35.169 |   1.0312 |     36.493 |     1.5
   36 |   0.9747 |     34.937 |   1.0253 |     36.307 |     1.6
   37 |   0.9628 |     34.634 |   1.0287 |     35.874 |     1.6
   38 |   0.9524 |     34.309 |   1.0187 |     36.090 |     1.7
   39 |   0.9484 |     33.918 |   1.0101 |     36.029 |     1.7
   40 |   0.9388 |     33.636 |   1.0088 |     35.781 |     1.7
   41 |   0.9271 |     33.174 |   1.0024 |     35.533 |     1.8
   42 |   0.9227 |     32.799 |   0.9904 |     35.068 |     1.8
   43 |   0.9071 |     32.055 |   0.9904 |     35.099 |     1.9
   44 |   0.8921 |     31.663 |   0.9832 |     34.603 |     1.9
   45 |   0.8909 |     31.250 |   0.9819 |     34.325 |     2.0
   46 |   0.8783 |     30.864 |   0.9857 |     33.271 |     2.0
   47 |   0.8658 |     30.456 |   0.9640 |     33.024 |     2.1
   48 |   0.8542 |     29.944 |   0.9570 |     33.116 |     2.1
   49 |   0.8489 |     29.624 |   0.9555 |     33.055 |     2.2
   50 |   0.8371 |     29.255 |   0.9569 |     33.395 |     2.2
   51 |   0.8249 |     28.786 |   0.9574 |     33.178 |     2.3
   52 |   0.8164 |     28.329 |   0.9494 |     32.032 |     2.3
   53 |   0.8117 |     28.202 |   0.9531 |     32.435 |     2.4
   54 |   0.7956 |     27.695 |   0.9569 |     32.528 |     2.4
   55 |   0.7938 |     27.491 |   0.9451 |     32.156 |     2.4
   56 |   0.7807 |     26.885 |   0.9334 |     31.475 |     2.5
   57 |   0.7724 |     26.455 |   0.9381 |     30.855 |     2.5
   58 |   0.7581 |     26.174 |   0.9368 |     31.134 |     2.6
   59 |   0.7598 |     26.047 |   0.9401 |     30.917 |     2.6
   60 |   0.7427 |     25.590 |   0.9289 |     30.824 |     2.7
   61 |   0.7360 |     25.237 |   0.9358 |     30.390 |     2.7
   62 |   0.7217 |     24.521 |   0.9284 |     30.948 |     2.8
   63 |   0.7112 |     24.091 |   0.9267 |     30.762 |     2.8
   64 |   0.7029 |     24.035 |   0.9413 |     30.793 |     2.9
   65 |   0.6975 |     23.821 |   0.9422 |     30.638 |     2.9
   66 |   0.6855 |     23.385 |   0.9347 |     30.297 |     2.9
   67 |   0.6776 |     22.762 |   0.9278 |     29.864 |     3.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 519,394

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5089 |     66.832 |   1.9086 |     49.876 |     0.0
    2 |   1.6905 |     48.159 |   1.5222 |     46.344 |     0.1
    3 |   1.4648 |     45.960 |   1.4285 |     46.344 |     0.1
    4 |   1.4121 |     45.833 |   1.4024 |     46.004 |     0.2
    5 |   1.3893 |     45.960 |   1.3843 |     46.066 |     0.2
    6 |   1.3752 |     45.492 |   1.3710 |     45.880 |     0.2
    7 |   1.3650 |     45.381 |   1.3641 |     46.530 |     0.3
    8 |   1.3490 |     45.222 |   1.3451 |     45.136 |     0.3
    9 |   1.3274 |     44.968 |   1.3289 |     44.610 |     0.3
   10 |   1.3087 |     44.500 |   1.3111 |     44.393 |     0.4
   11 |   1.2927 |     44.241 |   1.2904 |     45.229 |     0.4
   12 |   1.2732 |     43.904 |   1.2752 |     45.167 |     0.5
   13 |   1.2556 |     43.756 |   1.2579 |     43.866 |     0.5
   14 |   1.2375 |     43.430 |   1.2490 |     43.432 |     0.5
   15 |   1.2231 |     42.852 |   1.2246 |     42.317 |     0.6
   16 |   1.2076 |     42.069 |   1.2146 |     41.976 |     0.6
   17 |   1.1914 |     41.700 |   1.2006 |     41.574 |     0.6
   18 |   1.1788 |     41.424 |   1.1896 |     40.892 |     0.7
   19 |   1.1624 |     40.619 |   1.1739 |     40.861 |     0.7
   20 |   1.1463 |     39.909 |   1.1625 |     40.180 |     0.8
   21 |   1.1311 |     39.545 |   1.1577 |     39.839 |     0.8
   22 |   1.1184 |     38.988 |   1.1357 |     39.281 |     0.8
   23 |   1.1022 |     38.393 |   1.1275 |     38.507 |     0.9
   24 |   1.0863 |     37.776 |   1.1225 |     38.414 |     0.9
   25 |   1.0724 |     37.313 |   1.1087 |     37.732 |     0.9
   26 |   1.0569 |     36.502 |   1.1004 |     37.701 |     1.0
   27 |   1.0405 |     35.935 |   1.0907 |     37.577 |     1.0
   28 |   1.0292 |     35.648 |   1.0830 |     37.051 |     1.0
   29 |   1.0142 |     34.915 |   1.0813 |     37.144 |     1.1
   30 |   1.0017 |     34.281 |   1.0695 |     35.874 |     1.1
   31 |   0.9820 |     33.598 |   1.0638 |     36.029 |     1.2
   32 |   0.9646 |     33.091 |   1.0591 |     35.657 |     1.2
   33 |   0.9529 |     32.622 |   1.0555 |     36.121 |     1.2
   34 |   0.9330 |     31.796 |   1.0380 |     35.037 |     1.3
   35 |   0.9222 |     31.338 |   1.0375 |     35.378 |     1.3
   36 |   0.9123 |     31.024 |   1.0294 |     34.387 |     1.3
   37 |   0.8885 |     30.065 |   1.0280 |     35.037 |     1.4
   38 |   0.8665 |     29.227 |   1.0297 |     35.502 |     1.4
   39 |   0.8686 |     29.067 |   1.0181 |     34.603 |     1.5
   40 |   0.8453 |     28.153 |   1.0308 |     34.139 |     1.5
   41 |   0.8368 |     27.976 |   1.0240 |     34.201 |     1.5
   42 |   0.8246 |     27.668 |   1.0241 |     33.829 |     1.6
   43 |   0.8094 |     27.155 |   1.0051 |     33.055 |     1.6
   44 |   0.7826 |     25.926 |   1.0126 |     33.364 |     1.6
   45 |   0.7633 |     25.204 |   0.9949 |     31.877 |     1.7
   46 |   0.7489 |     24.432 |   1.0020 |     31.846 |     1.7
   47 |   0.7384 |     23.958 |   0.9964 |     31.908 |     1.8
   48 |   0.7276 |     24.002 |   1.0113 |     31.939 |     1.8
   49 |   0.7037 |     22.851 |   1.0101 |     31.444 |     1.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 273,250

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3497 |     61.166 |   1.7275 |     48.978 |     0.0
    2 |   1.5575 |     46.847 |   1.4461 |     45.849 |     0.0
    3 |   1.3990 |     45.668 |   1.3645 |     45.198 |     0.1
    4 |   1.3387 |     44.555 |   1.3276 |     44.300 |     0.1
    5 |   1.3075 |     44.196 |   1.2988 |     43.866 |     0.1
    6 |   1.2876 |     44.020 |   1.2827 |     43.835 |     0.1
    7 |   1.2684 |     43.855 |   1.2634 |     43.216 |     0.1
    8 |   1.2513 |     43.298 |   1.2565 |     44.486 |     0.1
    9 |   1.2357 |     43.138 |   1.2358 |     43.154 |     0.2
   10 |   1.2167 |     42.752 |   1.2233 |     42.658 |     0.2
   11 |   1.2059 |     42.488 |   1.2030 |     41.853 |     0.2
   12 |   1.1910 |     41.711 |   1.1984 |     41.884 |     0.2
   13 |   1.1813 |     41.672 |   1.1856 |     41.233 |     0.2
   14 |   1.1691 |     41.138 |   1.1715 |     41.667 |     0.3
   15 |   1.1586 |     41.011 |   1.1692 |     41.264 |     0.3
   16 |   1.1453 |     40.338 |   1.1754 |     41.264 |     0.3
   17 |   1.1374 |     40.096 |   1.1479 |     39.963 |     0.3
   18 |   1.1262 |     40.041 |   1.1446 |     40.211 |     0.3
   19 |   1.1169 |     39.699 |   1.1335 |     39.653 |     0.3
   20 |   1.1063 |     39.368 |   1.1221 |     39.002 |     0.4
   21 |   1.0915 |     38.542 |   1.1192 |     39.932 |     0.4
   22 |   1.0850 |     38.145 |   1.1142 |     39.777 |     0.4
   23 |   1.0765 |     38.211 |   1.1013 |     38.569 |     0.4
   24 |   1.0620 |     37.219 |   1.0931 |     38.879 |     0.4
   25 |   1.0558 |     37.164 |   1.0792 |     38.290 |     0.5
   26 |   1.0439 |     36.376 |   1.0796 |     37.887 |     0.5
   27 |   1.0327 |     35.973 |   1.0715 |     37.763 |     0.5
   28 |   1.0246 |     35.637 |   1.0666 |     37.608 |     0.5
   29 |   1.0150 |     34.943 |   1.0525 |     36.927 |     0.5
   30 |   1.0039 |     34.750 |   1.0455 |     36.803 |     0.6
   31 |   0.9933 |     34.055 |   1.0377 |     36.245 |     0.6
   32 |   0.9811 |     33.664 |   1.0356 |     35.967 |     0.6
   33 |   0.9690 |     33.433 |   1.0264 |     35.502 |     0.6
   34 |   0.9606 |     32.711 |   1.0220 |     35.905 |     0.7
   35 |   0.9506 |     32.683 |   1.0246 |     35.347 |     0.7
   36 |   0.9449 |     32.099 |   1.0091 |     35.006 |     0.7
   37 |   0.9347 |     31.939 |   1.0054 |     34.665 |     0.7
   38 |   0.9242 |     31.377 |   0.9965 |     34.325 |     0.7
   39 |   0.9101 |     30.936 |   0.9930 |     33.705 |     0.8
   40 |   0.9180 |     31.184 |   0.9956 |     34.913 |     0.8
   41 |   0.9023 |     30.771 |   0.9849 |     33.736 |     0.8
   42 |   0.8882 |     29.966 |   0.9729 |     33.086 |     0.8
   43 |   0.8700 |     29.420 |   0.9785 |     33.643 |     0.8
   44 |   0.8651 |     29.260 |   0.9829 |     33.147 |     0.9
   45 |   0.8550 |     28.759 |   0.9646 |     32.559 |     0.9
   46 |   0.8395 |     28.379 |   0.9645 |     32.559 |     0.9
   47 |   0.8328 |     28.009 |   0.9617 |     32.435 |     0.9
   48 |   0.8195 |     27.519 |   0.9607 |     32.528 |     0.9
   49 |   0.8091 |     27.183 |   0.9499 |     31.970 |     1.0
   50 |   0.7988 |     26.703 |   0.9436 |     31.877 |     1.0
   51 |   0.7891 |     26.472 |   0.9363 |     31.660 |     1.0
   52 |   0.7776 |     25.909 |   0.9357 |     31.506 |     1.0
   53 |   0.7680 |     25.634 |   0.9326 |     31.134 |     1.0
   54 |   0.7603 |     25.083 |   0.9328 |     31.165 |     1.1
   55 |   0.7456 |     24.735 |   0.9181 |     30.328 |     1.1
   56 |   0.7383 |     24.636 |   0.9309 |     30.607 |     1.1
   57 |   0.7312 |     24.212 |   0.9238 |     31.196 |     1.1
   58 |   0.7247 |     24.245 |   0.9339 |     30.607 |     1.1
   59 |   0.7085 |     23.286 |   0.9379 |     30.390 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,248,418

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3924 |     62.682 |   1.8286 |     50.155 |     0.1
    2 |   1.6144 |     47.112 |   1.4816 |     46.344 |     0.1
    3 |   1.4275 |     45.723 |   1.3938 |     45.694 |     0.2
    4 |   1.3599 |     45.144 |   1.3433 |     45.508 |     0.2
    5 |   1.3160 |     44.340 |   1.3106 |     44.269 |     0.3
    6 |   1.2860 |     43.888 |   1.2895 |     44.981 |     0.4
    7 |   1.2649 |     43.287 |   1.2631 |     43.835 |     0.4
    8 |   1.2426 |     43.188 |   1.2433 |     43.463 |     0.5
    9 |   1.2216 |     42.422 |   1.2202 |     42.875 |     0.6
   10 |   1.2002 |     41.854 |   1.2054 |     41.976 |     0.6
   11 |   1.1774 |     40.862 |   1.1955 |     41.698 |     0.7
   12 |   1.1522 |     39.920 |   1.1692 |     41.016 |     0.8
   13 |   1.1293 |     38.531 |   1.1475 |     39.312 |     0.8
   14 |   1.0991 |     37.180 |   1.1272 |     38.507 |     0.9
   15 |   1.0725 |     35.995 |   1.1134 |     39.002 |     0.9
   16 |   1.0382 |     34.590 |   1.1043 |     38.166 |     1.0
   17 |   1.0107 |     33.350 |   1.0712 |     36.555 |     1.1
   18 |   0.9915 |     32.793 |   1.0598 |     35.564 |     1.1
   19 |   0.9435 |     30.837 |   1.0384 |     35.378 |     1.2
   20 |   0.9109 |     29.514 |   1.0266 |     34.015 |     1.2
   21 |   0.8771 |     28.296 |   1.0081 |     33.550 |     1.3
   22 |   0.8311 |     26.554 |   0.9974 |     32.652 |     1.4
   23 |   0.7968 |     25.408 |   0.9749 |     32.621 |     1.4
   24 |   0.7547 |     23.528 |   0.9670 |     31.134 |     1.5
   25 |   0.7195 |     22.084 |   0.9743 |     31.010 |     1.6
   26 |   0.6768 |     20.756 |   0.9670 |     30.638 |     1.6
   27 |   0.6277 |     18.640 |   0.9502 |     29.554 |     1.7
   28 |   0.6007 |     18.017 |   0.9557 |     29.492 |     1.7
   29 |   0.5608 |     16.694 |   0.9670 |     28.903 |     1.8
   30 |   0.5336 |     15.785 |   0.9506 |     28.036 |     1.9
   31 |   0.4944 |     14.418 |   0.9567 |     28.067 |     1.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 604,450

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0842 |     56.944 |   1.5171 |     46.159 |     0.0
    2 |   1.4233 |     46.070 |   1.3819 |     45.849 |     0.1
    3 |   1.3444 |     44.940 |   1.3217 |     44.827 |     0.1
    4 |   1.2967 |     44.285 |   1.2858 |     44.021 |     0.1
    5 |   1.2625 |     43.932 |   1.2660 |     45.136 |     0.1
    6 |   1.2375 |     43.496 |   1.2368 |     42.751 |     0.2
    7 |   1.2129 |     42.697 |   1.2112 |     43.092 |     0.2
    8 |   1.1856 |     41.915 |   1.1847 |     41.605 |     0.2
    9 |   1.1614 |     40.691 |   1.1607 |     41.140 |     0.2
   10 |   1.1308 |     39.523 |   1.1406 |     39.684 |     0.3
   11 |   1.1028 |     38.553 |   1.1097 |     38.724 |     0.3
   12 |   1.0668 |     36.712 |   1.0840 |     37.763 |     0.3
   13 |   1.0321 |     35.626 |   1.0532 |     36.772 |     0.4
   14 |   0.9944 |     33.962 |   1.0228 |     34.975 |     0.4
   15 |   0.9574 |     32.595 |   1.0068 |     34.696 |     0.4
   16 |   0.9189 |     30.754 |   1.0054 |     34.325 |     0.4
   17 |   0.8789 |     29.707 |   0.9829 |     33.209 |     0.5
   18 |   0.8468 |     28.230 |   0.9830 |     33.055 |     0.5
   19 |   0.8084 |     26.935 |   0.9462 |     31.227 |     0.5
   20 |   0.7682 |     25.446 |   0.9352 |     30.979 |     0.5
   21 |   0.7402 |     24.570 |   0.9252 |     30.235 |     0.6
   22 |   0.6982 |     22.977 |   0.9178 |     29.120 |     0.6
   23 |   0.6653 |     21.831 |   0.8928 |     29.089 |     0.6
   24 |   0.6372 |     20.773 |   0.9109 |     28.779 |     0.7
   25 |   0.6038 |     19.637 |   0.9088 |     27.974 |     0.7
   26 |   0.5700 |     18.629 |   0.9100 |     28.129 |     0.7
   27 |   0.5411 |     17.593 |   0.9186 |     28.005 |     0.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 308,258

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4824 |     66.055 |   1.9197 |     50.620 |     0.0
    2 |   1.6811 |     48.032 |   1.5024 |     46.097 |     0.0
    3 |   1.4448 |     45.729 |   1.4025 |     45.849 |     0.1
    4 |   1.3787 |     45.613 |   1.3562 |     45.632 |     0.1
    5 |   1.3391 |     44.951 |   1.3282 |     44.424 |     0.1
    6 |   1.3148 |     44.224 |   1.3101 |     44.362 |     0.1
    7 |   1.2984 |     44.064 |   1.2918 |     44.021 |     0.1
    8 |   1.2823 |     44.130 |   1.2754 |     44.238 |     0.2
    9 |   1.2640 |     43.926 |   1.2595 |     43.742 |     0.2
   10 |   1.2459 |     43.811 |   1.2455 |     43.649 |     0.2
   11 |   1.2307 |     43.436 |   1.2326 |     43.463 |     0.2
   12 |   1.2157 |     43.138 |   1.2204 |     42.813 |     0.2
   13 |   1.2022 |     42.631 |   1.2073 |     42.906 |     0.3
   14 |   1.1866 |     41.975 |   1.1929 |     41.078 |     0.3
   15 |   1.1737 |     41.457 |   1.1794 |     41.202 |     0.3
   16 |   1.1607 |     40.868 |   1.1710 |     41.295 |     0.3
   17 |   1.1459 |     40.405 |   1.1622 |     40.985 |     0.3
   18 |   1.1314 |     39.920 |   1.1419 |     40.025 |     0.4
   19 |   1.1177 |     39.131 |   1.1315 |     39.963 |     0.4
   20 |   1.1008 |     38.233 |   1.1270 |     39.560 |     0.4
   21 |   1.0855 |     37.891 |   1.1011 |     38.476 |     0.4
   22 |   1.0701 |     37.202 |   1.0938 |     38.259 |     0.4
   23 |   1.0495 |     36.089 |   1.0833 |     38.042 |     0.5
   24 |   1.0386 |     35.736 |   1.0705 |     37.392 |     0.5
   25 |   1.0187 |     34.689 |   1.0715 |     37.206 |     0.5
   26 |   1.0026 |     34.336 |   1.0472 |     35.905 |     0.5
   27 |   0.9870 |     33.460 |   1.0402 |     35.440 |     0.6
   28 |   0.9680 |     32.815 |   1.0270 |     35.192 |     0.6
   29 |   0.9586 |     32.380 |   1.0260 |     35.254 |     0.6
   30 |   0.9406 |     31.305 |   1.0142 |     34.634 |     0.6
   31 |   0.9269 |     31.178 |   1.0027 |     34.634 |     0.6
   32 |   0.9499 |     32.192 |   1.0322 |     35.254 |     0.7
   33 |   0.9298 |     31.388 |   1.0097 |     35.006 |     0.7
   34 |   0.8998 |     30.252 |   0.9994 |     33.860 |     0.7
   35 |   0.8831 |     29.558 |   0.9852 |     33.612 |     0.7
   36 |   0.8618 |     28.687 |   0.9815 |     33.240 |     0.7
   37 |   0.8419 |     28.219 |   0.9697 |     32.590 |     0.8
   38 |   0.8300 |     27.491 |   0.9634 |     32.559 |     0.8
   39 |   0.8120 |     26.808 |   0.9693 |     32.559 |     0.8
   40 |   0.7937 |     26.394 |   0.9636 |     32.497 |     0.8
   41 |   0.7797 |     25.827 |   0.9673 |     32.342 |     0.8
   42 |   0.7610 |     25.110 |   0.9471 |     31.134 |     0.9
   43 |   0.7487 |     25.077 |   0.9459 |     31.134 |     0.9
   44 |   0.7324 |     24.190 |   0.9484 |     31.413 |     0.9
   45 |   0.7120 |     23.247 |   0.9417 |     30.638 |     0.9
   46 |   0.6976 |     22.834 |   0.9428 |     30.421 |     0.9
   47 |   0.7745 |     25.953 |   0.9515 |     31.506 |     1.0
   48 |   0.7260 |     24.140 |   0.9375 |     30.297 |     1.0
   49 |   0.6914 |     22.817 |   0.9515 |     30.173 |     1.0
   50 |   0.6710 |     22.173 |   0.9363 |     29.244 |     1.0
   51 |   0.6474 |     21.136 |   0.9382 |     29.678 |     1.0
   52 |   0.6366 |     20.910 |   0.9447 |     28.872 |     1.1
   53 |   0.6258 |     20.536 |   0.9310 |     28.903 |     1.1
   54 |   0.6067 |     19.604 |   0.9455 |     29.244 |     1.1
   55 |   0.5979 |     19.466 |   0.9438 |     28.903 |     1.1
   56 |   0.5873 |     19.191 |   0.9406 |     28.408 |     1.2
   57 |   0.5731 |     18.524 |   0.9604 |     28.594 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,160,418

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5173 |     67.598 |   1.9477 |     59.851 |     0.1
    2 |   1.7622 |     50.055 |   1.5802 |     46.344 |     0.1
    3 |   1.5098 |     45.988 |   1.4574 |     46.344 |     0.2
    4 |   1.4385 |     46.037 |   1.4238 |     46.344 |     0.3
    5 |   1.4134 |     46.015 |   1.4008 |     47.150 |     0.3
    6 |   1.3899 |     45.966 |   1.3783 |     46.344 |     0.4
    7 |   1.3693 |     45.762 |   1.3580 |     45.880 |     0.4
    8 |   1.3546 |     45.475 |   1.3477 |     46.468 |     0.5
    9 |   1.3379 |     45.651 |   1.3318 |     46.035 |     0.6
   10 |   1.3203 |     45.437 |   1.3185 |     45.570 |     0.6
   11 |   1.3052 |     45.078 |   1.3027 |     45.260 |     0.7
   12 |   1.2841 |     44.610 |   1.2846 |     44.269 |     0.8
   13 |   1.2690 |     43.926 |   1.2710 |     43.990 |     0.8
   14 |   1.2579 |     43.860 |   1.2631 |     43.525 |     0.9
   15 |   1.2460 |     43.403 |   1.2537 |     43.618 |     1.0
   16 |   1.2341 |     43.138 |   1.2406 |     43.123 |     1.0
   17 |   1.2238 |     42.846 |   1.2289 |     43.401 |     1.1
   18 |   1.2132 |     42.719 |   1.2206 |     42.472 |     1.1
   19 |   1.2010 |     42.289 |   1.2031 |     42.875 |     1.2
   20 |   1.1917 |     42.245 |   1.2011 |     42.100 |     1.3
   21 |   1.1789 |     41.777 |   1.1887 |     41.976 |     1.3
   22 |   1.1770 |     41.964 |   1.1821 |     41.698 |     1.4
   23 |   1.1633 |     41.325 |   1.1697 |     40.644 |     1.5
   24 |   1.1524 |     41.027 |   1.1577 |     39.932 |     1.5
   25 |   1.1398 |     40.829 |   1.1534 |     40.273 |     1.6
   26 |   1.1294 |     40.129 |   1.1467 |     39.839 |     1.7
   27 |   1.1158 |     39.727 |   1.1335 |     39.870 |     1.7
   28 |   1.1059 |     39.297 |   1.1324 |     39.188 |     1.8
   29 |   1.0939 |     38.845 |   1.1208 |     39.405 |     1.9
   30 |   1.0864 |     38.630 |   1.1073 |     38.352 |     1.9
   31 |   1.0679 |     37.897 |   1.0978 |     38.197 |     2.0
   32 |   1.0570 |     37.048 |   1.0904 |     37.423 |     2.0
   33 |   1.0448 |     36.547 |   1.0885 |     38.321 |     2.1
   34 |   1.0361 |     35.935 |   1.0797 |     38.104 |     2.2
   35 |   1.0198 |     35.510 |   1.0842 |     38.228 |     2.2
   36 |   1.0101 |     35.268 |   1.0706 |     36.834 |     2.3
   37 |   0.9944 |     34.452 |   1.0630 |     37.144 |     2.4
   38 |   0.9808 |     34.072 |   1.0467 |     35.874 |     2.4
   39 |   0.9632 |     33.278 |   1.0420 |     36.121 |     2.5
   40 |   0.9552 |     33.008 |   1.0426 |     36.586 |     2.6
   41 |   0.9434 |     32.529 |   1.0361 |     36.183 |     2.6
   42 |   0.9248 |     31.884 |   1.0238 |     35.130 |     2.7
   43 |   0.9155 |     31.785 |   1.0227 |     34.944 |     2.7
   44 |   0.9001 |     31.063 |   1.0184 |     34.975 |     2.8
   45 |   0.8905 |     30.589 |   1.0110 |     34.418 |     2.9
   46 |   0.8739 |     29.878 |   0.9992 |     34.201 |     2.9
   47 |   0.8558 |     28.996 |   1.0049 |     34.077 |     3.0
   48 |   0.8439 |     28.527 |   1.0076 |     33.674 |     3.1
   49 |   0.8300 |     27.916 |   1.0168 |     34.046 |     3.1
   50 |   0.8139 |     27.409 |   0.9909 |     32.714 |     3.2
   51 |   0.7966 |     26.488 |   1.0039 |     32.807 |     3.3
   52 |   0.7983 |     26.488 |   0.9803 |     32.404 |     3.3
   53 |   0.7757 |     25.650 |   0.9977 |     33.024 |     3.4
   54 |   0.7750 |     25.744 |   0.9905 |     31.877 |     3.4
   55 |   0.7480 |     24.724 |   0.9722 |     31.382 |     3.5
   56 |   0.7306 |     24.471 |   0.9791 |     30.700 |     3.6
   57 |   0.7163 |     23.688 |   0.9849 |     31.506 |     3.6
   58 |   0.7053 |     22.884 |   0.9988 |     31.289 |     3.7
   59 |   0.6901 |     22.465 |   0.9876 |     30.607 |     3.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,558,818

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2317 |     60.984 |   1.6328 |     49.442 |     0.1
    2 |   1.4890 |     46.318 |   1.4202 |     46.344 |     0.1
    3 |   1.3979 |     45.977 |   1.3718 |     46.344 |     0.2
    4 |   1.3554 |     45.657 |   1.3448 |     45.911 |     0.2
    5 |   1.3277 |     45.255 |   1.3207 |     45.632 |     0.3
    6 |   1.3020 |     44.979 |   1.2948 |     44.610 |     0.4
    7 |   1.2755 |     44.637 |   1.2728 |     44.145 |     0.4
    8 |   1.2543 |     43.959 |   1.2573 |     44.331 |     0.5
    9 |   1.2362 |     43.557 |   1.2518 |     43.278 |     0.6
   10 |   1.2210 |     43.221 |   1.2371 |     42.751 |     0.6
   11 |   1.2084 |     42.819 |   1.2156 |     42.937 |     0.7
   12 |   1.1933 |     42.433 |   1.2066 |     42.131 |     0.7
   13 |   1.1814 |     42.019 |   1.1969 |     42.317 |     0.8
   14 |   1.1736 |     41.788 |   1.1850 |     41.791 |     0.9
   15 |   1.1635 |     41.364 |   1.1780 |     41.543 |     0.9
   16 |   1.1558 |     41.281 |   1.1629 |     40.458 |     1.0
   17 |   1.1458 |     41.005 |   1.1550 |     41.016 |     1.1
   18 |   1.1378 |     40.923 |   1.1434 |     40.366 |     1.1
   19 |   1.1285 |     40.377 |   1.1430 |     41.202 |     1.2
   20 |   1.1202 |     40.146 |   1.1411 |     40.397 |     1.2
   21 |   1.1162 |     40.112 |   1.1304 |     40.428 |     1.3
   22 |   1.1101 |     39.765 |   1.1322 |     40.613 |     1.4
   23 |   1.1037 |     39.694 |   1.1286 |     40.273 |     1.4
   24 |   1.0910 |     39.148 |   1.1147 |     40.520 |     1.5
   25 |   1.0819 |     39.087 |   1.1013 |     40.428 |     1.6
   26 |   1.0759 |     38.817 |   1.0934 |     38.600 |     1.6
   27 |   1.0637 |     38.112 |   1.0882 |     38.073 |     1.7
   28 |   1.0556 |     38.150 |   1.0825 |     39.219 |     1.7
   29 |   1.0448 |     37.158 |   1.0741 |     38.910 |     1.8
   30 |   1.0364 |     36.960 |   1.0612 |     37.763 |     1.9
   31 |   1.0286 |     36.828 |   1.0607 |     37.980 |     1.9
   32 |   1.0208 |     36.624 |   1.0483 |     37.454 |     2.0
   33 |   1.0131 |     36.354 |   1.0457 |     37.361 |     2.1
   34 |   1.0008 |     35.902 |   1.0317 |     36.648 |     2.1
   35 |   1.0025 |     36.067 |   1.0334 |     36.834 |     2.2
   36 |   0.9892 |     35.428 |   1.0248 |     37.082 |     2.2
   37 |   0.9830 |     35.069 |   1.0349 |     37.144 |     2.3
   38 |   0.9768 |     34.783 |   1.0227 |     37.144 |     2.4
   39 |   0.9739 |     34.998 |   1.0148 |     36.276 |     2.4
   40 |   0.9573 |     34.182 |   1.0167 |     36.400 |     2.5
   41 |   0.9534 |     33.934 |   1.0071 |     35.533 |     2.6
   42 |   0.9473 |     33.659 |   1.0004 |     35.254 |     2.6
   43 |   0.9429 |     33.636 |   1.0027 |     35.688 |     2.7
   44 |   0.9340 |     33.223 |   1.0034 |     35.068 |     2.7
   45 |   0.9261 |     32.953 |   0.9850 |     34.201 |     2.8
   46 |   0.9137 |     32.369 |   0.9929 |     34.944 |     2.9
   47 |   0.9021 |     32.005 |   0.9779 |     34.046 |     2.9
   48 |   0.9011 |     31.895 |   0.9836 |     34.046 |     3.0
   49 |   0.8944 |     31.680 |   0.9703 |     33.395 |     3.1
   50 |   0.8864 |     31.211 |   0.9631 |     33.364 |     3.1
   51 |   0.8763 |     30.864 |   0.9700 |     33.891 |     3.2
   52 |   0.8738 |     30.517 |   0.9513 |     33.426 |     3.2
   53 |   0.8572 |     30.054 |   0.9644 |     33.643 |     3.3
   54 |   0.8550 |     30.021 |   0.9570 |     32.993 |     3.4
   55 |   0.8470 |     29.475 |   0.9473 |     32.993 |     3.4
   56 |   0.8451 |     29.216 |   0.9520 |     32.218 |     3.5
   57 |   0.8388 |     29.194 |   0.9478 |     32.683 |     3.6
   58 |   0.8410 |     29.134 |   1.0080 |     36.121 |     3.6
   59 |   0.8780 |     31.101 |   0.9726 |     33.674 |     3.7
   60 |   0.8397 |     29.608 |   0.9276 |     31.568 |     3.8
   61 |   0.8168 |     28.566 |   0.9282 |     31.320 |     3.8
   62 |   0.8011 |     27.568 |   0.9328 |     31.506 |     3.9
   63 |   0.8093 |     27.827 |   0.9255 |     31.537 |     3.9
   64 |   0.7885 |     27.045 |   0.9363 |     31.722 |     4.0
   65 |   0.7961 |     27.634 |   0.9167 |     30.483 |     4.1
   66 |   0.7718 |     26.483 |   0.9581 |     32.032 |     4.1
   67 |   0.7760 |     26.863 |   0.9153 |     30.483 |     4.2
   68 |   0.7520 |     25.722 |   0.9203 |     30.607 |     4.3
   69 |   0.7448 |     25.430 |   0.9146 |     29.740 |     4.3
   70 |   0.7378 |     25.226 |   0.9097 |     29.895 |     4.4
   71 |   0.7338 |     24.741 |   0.9133 |     30.483 |     4.5
   72 |   0.7258 |     24.708 |   0.9009 |     30.452 |     4.5
   73 |   0.7133 |     24.013 |   0.9100 |     30.700 |     4.6
   74 |   0.7080 |     24.151 |   0.9042 |     29.926 |     4.6
   75 |   0.6966 |     23.495 |   0.9010 |     28.841 |     4.7
   76 |   0.7381 |     25.182 |   0.9035 |     30.143 |     4.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 675,106

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0330 |     55.622 |   1.4739 |     45.849 |     0.0
    2 |   1.3913 |     45.315 |   1.3339 |     44.857 |     0.1
    3 |   1.3122 |     44.555 |   1.2978 |     44.857 |     0.1
    4 |   1.2750 |     43.965 |   1.2810 |     45.415 |     0.1
    5 |   1.2501 |     43.502 |   1.2387 |     42.875 |     0.1
    6 |   1.2201 |     42.648 |   1.2162 |     42.596 |     0.2
    7 |   1.1962 |     41.926 |   1.1992 |     42.100 |     0.2
    8 |   1.1691 |     41.237 |   1.1730 |     40.768 |     0.2
    9 |   1.1483 |     40.961 |   1.1590 |     40.675 |     0.3
   10 |   1.1256 |     39.798 |   1.1417 |     40.366 |     0.3
   11 |   1.0987 |     38.828 |   1.1168 |     39.250 |     0.3
   12 |   1.0748 |     37.439 |   1.0869 |     38.445 |     0.3
   13 |   1.0478 |     36.365 |   1.0599 |     37.175 |     0.4
   14 |   1.0233 |     35.610 |   1.0567 |     37.175 |     0.4
   15 |   0.9980 |     34.513 |   1.0204 |     35.440 |     0.4
   16 |   0.9785 |     33.995 |   1.0174 |     35.254 |     0.5
   17 |   0.9501 |     32.540 |   0.9975 |     34.913 |     0.5
   18 |   0.9237 |     31.338 |   0.9835 |     33.767 |     0.5
   19 |   0.9068 |     31.112 |   0.9790 |     34.263 |     0.5
   20 |   0.8808 |     30.115 |   0.9642 |     33.086 |     0.6
   21 |   0.8627 |     29.409 |   0.9551 |     32.218 |     0.6
   22 |   0.8388 |     28.263 |   0.9438 |     32.001 |     0.6
   23 |   0.8143 |     27.160 |   0.9268 |     31.722 |     0.7
   24 |   0.7865 |     26.240 |   0.9370 |     31.506 |     0.7
   25 |   0.7669 |     25.369 |   0.9052 |     30.359 |     0.7
   26 |   0.7465 |     24.884 |   0.9073 |     30.421 |     0.8
   27 |   0.7229 |     24.107 |   0.8871 |     28.532 |     0.8
   28 |   0.7053 |     23.446 |   0.8847 |     28.779 |     0.8
   29 |   0.6784 |     22.178 |   0.8776 |     28.748 |     0.8
   30 |   0.6584 |     21.561 |   0.8909 |     28.656 |     0.9
   31 |   0.6417 |     21.125 |   0.8966 |     28.996 |     0.9
   32 |   0.6280 |     20.481 |   0.8780 |     28.284 |     0.9
   33 |   0.6010 |     19.560 |   0.8789 |     27.509 |     1.0
   34 |   0.5864 |     19.097 |   0.8694 |     27.788 |     1.0
   35 |   0.5626 |     18.397 |   0.8708 |     26.952 |     1.0
   36 |   0.5480 |     17.752 |   0.8894 |     27.695 |     1.0
   37 |   0.5362 |     17.730 |   0.8795 |     27.943 |     1.1
   38 |   0.5173 |     17.080 |   0.8822 |     27.230 |     1.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 621,538

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0554 |     55.285 |   1.4877 |     46.097 |     0.0
    2 |   1.3918 |     45.227 |   1.3400 |     44.145 |     0.0
    3 |   1.3068 |     44.119 |   1.2979 |     44.455 |     0.1
    4 |   1.2681 |     43.645 |   1.2639 |     43.866 |     0.1
    5 |   1.2315 |     42.901 |   1.2326 |     42.906 |     0.1
    6 |   1.2006 |     42.455 |   1.2047 |     42.162 |     0.1
    7 |   1.1757 |     41.567 |   1.1835 |     41.636 |     0.2
    8 |   1.1541 |     41.220 |   1.1648 |     41.047 |     0.2
    9 |   1.1348 |     40.382 |   1.1433 |     40.428 |     0.2
   10 |   1.1156 |     39.611 |   1.1410 |     40.489 |     0.2
   11 |   1.0974 |     38.746 |   1.1220 |     39.684 |     0.3
   12 |   1.0827 |     38.431 |   1.1130 |     39.281 |     0.3
   13 |   1.0643 |     37.649 |   1.0937 |     39.002 |     0.3
   14 |   1.0435 |     36.772 |   1.0724 |     37.144 |     0.3
   15 |   1.0305 |     36.216 |   1.0756 |     37.949 |     0.4
   16 |   1.0099 |     35.180 |   1.0473 |     36.617 |     0.4
   17 |   0.9874 |     34.430 |   1.0311 |     35.750 |     0.4
   18 |   0.9684 |     33.460 |   1.0169 |     35.347 |     0.4
   19 |   0.9500 |     32.992 |   1.0191 |     35.378 |     0.5
   20 |   0.9295 |     32.187 |   0.9882 |     34.170 |     0.5
   21 |   0.9120 |     31.575 |   0.9856 |     33.829 |     0.5
   22 |   0.8911 |     30.605 |   0.9909 |     34.542 |     0.5
   23 |   0.8781 |     30.015 |   0.9577 |     33.271 |     0.6
   24 |   0.8534 |     29.387 |   0.9754 |     32.931 |     0.6
   25 |   0.8357 |     28.445 |   0.9648 |     33.024 |     0.6
   26 |   0.8163 |     27.739 |   0.9361 |     31.691 |     0.6
   27 |   0.7936 |     26.990 |   0.9354 |     31.908 |     0.7
   28 |   0.7797 |     26.301 |   0.9479 |     31.691 |     0.7
   29 |   0.7576 |     25.287 |   0.9372 |     30.514 |     0.7
   30 |   0.7383 |     24.361 |   0.9117 |     30.050 |     0.7
   31 |   0.7257 |     24.239 |   0.9199 |     30.328 |     0.8
   32 |   0.6973 |     22.950 |   0.9187 |     30.266 |     0.8
   33 |   0.6822 |     22.630 |   0.9232 |     29.430 |     0.8
   34 |   0.6625 |     22.084 |   0.9133 |     29.585 |     0.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 853,666

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5243 |     65.895 |   1.9998 |     59.851 |     0.0
    2 |   1.7547 |     49.377 |   1.5761 |     46.344 |     0.1
    3 |   1.4968 |     46.054 |   1.4508 |     46.344 |     0.1
    4 |   1.4207 |     45.988 |   1.4004 |     46.344 |     0.2
    5 |   1.3840 |     45.960 |   1.3718 |     46.344 |     0.2
    6 |   1.3573 |     45.387 |   1.3592 |     46.716 |     0.2
    7 |   1.3417 |     45.150 |   1.3435 |     45.694 |     0.3
    8 |   1.3283 |     44.858 |   1.3276 |     45.074 |     0.3
    9 |   1.3184 |     44.770 |   1.3205 |     45.415 |     0.4
   10 |   1.3042 |     44.158 |   1.3080 |     44.857 |     0.4
   11 |   1.2876 |     43.800 |   1.2935 |     44.424 |     0.5
   12 |   1.2714 |     43.287 |   1.2809 |     44.827 |     0.5
   13 |   1.2531 |     43.254 |   1.2716 |     43.525 |     0.6
   14 |   1.2342 |     42.686 |   1.2464 |     43.680 |     0.6
   15 |   1.2141 |     42.278 |   1.2377 |     43.030 |     0.7
   16 |   1.1932 |     41.860 |   1.2095 |     42.100 |     0.7
   17 |   1.1699 |     40.675 |   1.1971 |     41.295 |     0.7
   18 |   1.1455 |     39.997 |   1.1792 |     40.520 |     0.8
   19 |   1.1221 |     38.790 |   1.1613 |     39.932 |     0.8
   20 |   1.0984 |     38.062 |   1.1566 |     39.529 |     0.9
   21 |   1.0778 |     37.257 |   1.1467 |     40.087 |     0.9
   22 |   1.0486 |     36.398 |   1.1333 |     39.715 |     1.0
   23 |   1.0257 |     35.202 |   1.1300 |     38.414 |     1.0
   24 |   0.9968 |     34.182 |   1.1238 |     37.794 |     1.1
   25 |   0.9676 |     33.047 |   1.1297 |     38.755 |     1.1
   26 |   0.9416 |     32.000 |   1.1154 |     37.980 |     1.2
   27 |   0.9123 |     30.589 |   1.1102 |     36.586 |     1.2
   28 |   0.8870 |     29.707 |   1.1134 |     35.812 |     1.3
   29 |   0.8570 |     28.439 |   1.1224 |     35.936 |     1.3
   30 |   0.8333 |     27.337 |   1.1098 |     35.223 |     1.3
   31 |   0.8078 |     26.031 |   1.1170 |     35.533 |     1.4
   32 |   0.7699 |     24.791 |   1.1218 |     34.665 |     1.4
   33 |   0.7378 |     23.589 |   1.1450 |     34.263 |     1.5
   34 |   0.7133 |     22.542 |   1.1116 |     34.108 |     1.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 751,906

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4108 |     63.222 |   1.8377 |     48.978 |     0.0
    2 |   1.6325 |     47.558 |   1.4824 |     45.880 |     0.1
    3 |   1.4320 |     45.756 |   1.3878 |     45.632 |     0.1
    4 |   1.3676 |     44.715 |   1.3466 |     44.362 |     0.2
    5 |   1.3328 |     44.345 |   1.3228 |     44.393 |     0.2
    6 |   1.3034 |     44.015 |   1.2966 |     44.672 |     0.3
    7 |   1.2808 |     44.009 |   1.2836 |     45.074 |     0.3
    8 |   1.2644 |     43.893 |   1.2625 |     43.494 |     0.4
    9 |   1.2466 |     43.408 |   1.2481 |     43.154 |     0.4
   10 |   1.2317 |     42.890 |   1.2291 |     43.030 |     0.4
   11 |   1.2181 |     42.576 |   1.2172 |     42.441 |     0.5
   12 |   1.2000 |     42.218 |   1.2018 |     42.503 |     0.5
   13 |   1.1823 |     41.529 |   1.1954 |     41.729 |     0.6
   14 |   1.1610 |     40.366 |   1.1666 |     40.458 |     0.6
   15 |   1.1417 |     39.815 |   1.1613 |     40.613 |     0.6
   16 |   1.1168 |     38.569 |   1.1494 |     39.839 |     0.7
   17 |   1.0952 |     37.754 |   1.1286 |     38.817 |     0.7
   18 |   1.0711 |     36.717 |   1.1159 |     38.042 |     0.8
   19 |   1.0454 |     35.808 |   1.0839 |     37.020 |     0.8
   20 |   1.0158 |     34.452 |   1.0736 |     36.803 |     0.9
   21 |   0.9872 |     33.240 |   1.0493 |     35.533 |     0.9
   22 |   0.9588 |     32.055 |   1.0369 |     34.325 |     0.9
   23 |   0.9196 |     30.423 |   1.0260 |     34.325 |     1.0
   24 |   0.8840 |     29.233 |   1.0055 |     34.015 |     1.0
   25 |   0.8451 |     27.612 |   0.9962 |     32.993 |     1.1
   26 |   0.8129 |     26.141 |   0.9706 |     32.776 |     1.1
   27 |   0.7799 |     25.215 |   0.9745 |     32.435 |     1.1
   28 |   0.7433 |     24.024 |   0.9584 |     31.258 |     1.2
   29 |   0.7090 |     22.569 |   0.9570 |     30.700 |     1.2
   30 |   0.6776 |     21.517 |   0.9488 |     31.010 |     1.3
   31 |   0.6424 |     20.062 |   0.9465 |     30.421 |     1.3
   32 |   0.6127 |     19.108 |   0.9533 |     30.112 |     1.4
   33 |   0.5790 |     18.105 |   0.9658 |     29.585 |     1.4
   34 |   0.5586 |     17.615 |   0.9613 |     29.616 |     1.4
   35 |   0.5356 |     16.518 |   0.9610 |     29.120 |     1.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 537,954

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4953 |     66.044 |   1.8968 |     48.978 |     0.0
    2 |   1.6885 |     48.457 |   1.5204 |     46.344 |     0.1
    3 |   1.4669 |     46.065 |   1.4269 |     46.344 |     0.1
    4 |   1.4041 |     45.966 |   1.3825 |     45.446 |     0.1
    5 |   1.3698 |     45.596 |   1.3583 |     45.446 |     0.2
    6 |   1.3434 |     45.503 |   1.3405 |     45.384 |     0.2
    7 |   1.3186 |     45.222 |   1.3064 |     44.610 |     0.2
    8 |   1.2920 |     44.748 |   1.2883 |     45.012 |     0.3
    9 |   1.2731 |     44.400 |   1.2736 |     43.742 |     0.3
   10 |   1.2584 |     44.103 |   1.2656 |     44.517 |     0.3
   11 |   1.2463 |     43.855 |   1.2488 |     43.185 |     0.4
   12 |   1.2331 |     43.541 |   1.2387 |     44.238 |     0.4
   13 |   1.2226 |     43.111 |   1.2303 |     42.999 |     0.4
   14 |   1.2130 |     42.824 |   1.2260 |     43.216 |     0.5
   15 |   1.2047 |     42.675 |   1.2241 |     42.627 |     0.5
   16 |   1.1999 |     42.813 |   1.2146 |     42.193 |     0.5
   17 |   1.1933 |     42.493 |   1.2124 |     43.092 |     0.6
   18 |   1.1861 |     42.411 |   1.1986 |     41.945 |     0.6
   19 |   1.1859 |     42.444 |   1.1942 |     42.906 |     0.6
   20 |   1.1747 |     42.234 |   1.1874 |     41.512 |     0.7
   21 |   1.1720 |     41.876 |   1.1842 |     41.729 |     0.7
   22 |   1.1641 |     41.838 |   1.1820 |     41.264 |     0.7
   23 |   1.1601 |     41.650 |   1.1728 |     42.162 |     0.8
   24 |   1.1568 |     41.341 |   1.1726 |     41.914 |     0.8
   25 |   1.1523 |     41.562 |   1.1657 |     41.047 |     0.9
   26 |   1.1475 |     41.325 |   1.1676 |     42.286 |     0.9
   27 |   1.1429 |     40.895 |   1.1574 |     41.264 |     0.9
   28 |   1.1409 |     41.022 |   1.1561 |     41.109 |     1.0
   29 |   1.1383 |     40.950 |   1.1544 |     40.644 |     1.0
   30 |   1.1318 |     41.049 |   1.1516 |     41.791 |     1.0
   31 |   1.1289 |     40.642 |   1.1450 |     41.109 |     1.1
   32 |   1.1243 |     40.537 |   1.1468 |     40.706 |     1.1
   33 |   1.1226 |     40.542 |   1.1426 |     40.706 |     1.1
   34 |   1.1201 |     40.294 |   1.1484 |     41.047 |     1.2
   35 |   1.1150 |     40.294 |   1.1400 |     40.211 |     1.2
   36 |   1.1096 |     40.168 |   1.1326 |     40.304 |     1.2
   37 |   1.1078 |     39.942 |   1.1401 |     41.822 |     1.3
   38 |   1.1047 |     39.721 |   1.1291 |     39.963 |     1.3
   39 |   1.1036 |     39.809 |   1.1254 |     39.839 |     1.3
   40 |   1.0988 |     39.705 |   1.1236 |     41.047 |     1.4
   41 |   1.0954 |     39.468 |   1.1223 |     40.273 |     1.4
   42 |   1.0902 |     39.451 |   1.1239 |     40.954 |     1.4
   43 |   1.0899 |     39.539 |   1.1153 |     40.768 |     1.5
   44 |   1.0874 |     39.572 |   1.1135 |     39.653 |     1.5
   45 |   1.0841 |     39.264 |   1.1126 |     40.985 |     1.5
   46 |   1.0817 |     38.961 |   1.1115 |     39.374 |     1.6
   47 |   1.0771 |     38.966 |   1.1101 |     39.591 |     1.6
   48 |   1.0771 |     38.999 |   1.1118 |     40.551 |     1.7
   49 |   1.0714 |     38.927 |   1.1041 |     40.025 |     1.7
   50 |   1.0688 |     38.806 |   1.1008 |     39.839 |     1.7
   51 |   1.0700 |     38.900 |   1.0986 |     39.095 |     1.8
   52 |   1.0653 |     38.922 |   1.0990 |     38.755 |     1.8
   53 |   1.0628 |     38.586 |   1.0953 |     38.817 |     1.8
   54 |   1.0604 |     38.580 |   1.0967 |     39.405 |     1.9
   55 |   1.0562 |     38.376 |   1.0940 |     39.622 |     1.9
   56 |   1.0567 |     38.481 |   1.0895 |     38.693 |     1.9
   57 |   1.0527 |     38.448 |   1.0845 |     38.631 |     2.0
   58 |   1.0492 |     38.018 |   1.0841 |     38.662 |     2.0
   59 |   1.0488 |     37.963 |   1.0820 |     38.693 |     2.0
   60 |   1.0480 |     38.382 |   1.0921 |     39.188 |     2.1
   61 |   1.0448 |     38.040 |   1.0793 |     38.259 |     2.1
   62 |   1.0446 |     37.858 |   1.0734 |     37.701 |     2.1
   63 |   1.0393 |     37.594 |   1.0732 |     38.011 |     2.2
   64 |   1.0388 |     37.731 |   1.0744 |     37.887 |     2.2
   65 |   1.0348 |     37.572 |   1.0724 |     38.848 |     2.2
   66 |   1.0319 |     37.368 |   1.0747 |     38.569 |     2.3
   67 |   1.0329 |     37.368 |   1.0681 |     38.259 |     2.3
   68 |   1.0323 |     37.153 |   1.0784 |     38.662 |     2.3
   69 |   1.0311 |     37.489 |   1.0666 |     37.577 |     2.4
   70 |   1.0273 |     37.136 |   1.0714 |     37.980 |     2.4
   71 |   1.0263 |     37.362 |   1.0650 |     37.980 |     2.5
   72 |   1.0241 |     37.131 |   1.0657 |     37.670 |     2.5
   73 |   1.0220 |     37.009 |   1.0632 |     37.856 |     2.5
   74 |   1.0164 |     36.998 |   1.0680 |     37.918 |     2.6
   75 |   1.0176 |     36.850 |   1.0620 |     37.794 |     2.6
   76 |   1.0178 |     36.795 |   1.0654 |     38.259 |     2.6
   77 |   1.0171 |     37.015 |   1.0587 |     37.918 |     2.7
   78 |   1.0179 |     36.596 |   1.0570 |     37.732 |     2.7
   79 |   1.0127 |     36.795 |   1.0492 |     37.144 |     2.7
   80 |   1.0135 |     36.866 |   1.0544 |     36.958 |     2.8
   81 |   1.0117 |     36.657 |   1.0554 |     37.794 |     2.8
   82 |   1.0089 |     36.717 |   1.0591 |     37.794 |     2.8
   83 |   1.0075 |     36.640 |   1.0579 |     37.639 |     2.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 699,106

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4779 |     65.642 |   1.9071 |     51.890 |     0.0
    2 |   1.6664 |     47.294 |   1.5160 |     46.097 |     0.1
    3 |   1.4601 |     45.938 |   1.4246 |     45.942 |     0.1
    4 |   1.3992 |     45.811 |   1.3863 |     45.787 |     0.2
    5 |   1.3667 |     45.475 |   1.3541 |     45.477 |     0.2
    6 |   1.3366 |     45.381 |   1.3263 |     45.663 |     0.2
    7 |   1.3125 |     44.979 |   1.3069 |     44.517 |     0.3
    8 |   1.2915 |     44.433 |   1.2905 |     44.207 |     0.3
    9 |   1.2724 |     43.965 |   1.2756 |     44.579 |     0.4
   10 |   1.2574 |     43.860 |   1.2593 |     43.247 |     0.4
   11 |   1.2449 |     43.535 |   1.2472 |     43.618 |     0.5
   12 |   1.2324 |     43.342 |   1.2318 |     43.463 |     0.5
   13 |   1.2196 |     42.896 |   1.2235 |     43.494 |     0.5
   14 |   1.2066 |     42.675 |   1.2152 |     42.751 |     0.6
   15 |   1.1922 |     42.141 |   1.1973 |     42.255 |     0.6
   16 |   1.1812 |     41.738 |   1.1962 |     42.038 |     0.7
   17 |   1.1662 |     41.149 |   1.1758 |     41.326 |     0.7
   18 |   1.1501 |     40.548 |   1.1654 |     41.109 |     0.7
   19 |   1.1372 |     40.079 |   1.1507 |     40.737 |     0.8
   20 |   1.1173 |     39.280 |   1.1345 |     40.273 |     0.8
   21 |   1.0978 |     38.503 |   1.1180 |     38.507 |     0.9
   22 |   1.0741 |     37.257 |   1.1036 |     38.383 |     0.9
   23 |   1.0523 |     36.221 |   1.0908 |     38.569 |     0.9
   24 |   1.0261 |     35.042 |   1.0714 |     36.803 |     1.0
   25 |   1.0007 |     33.807 |   1.0674 |     36.493 |     1.0
   26 |   0.9736 |     32.661 |   1.0437 |     35.347 |     1.1
   27 |   0.9460 |     31.300 |   1.0337 |     35.595 |     1.1
   28 |   0.9161 |     30.407 |   1.0296 |     35.626 |     1.1
   29 |   0.8920 |     29.189 |   1.0099 |     34.572 |     1.2
   30 |   0.8564 |     27.860 |   0.9992 |     33.984 |     1.2
   31 |   0.8248 |     26.868 |   0.9862 |     33.426 |     1.3
   32 |   0.7876 |     25.309 |   0.9904 |     33.147 |     1.3
   33 |   0.7563 |     24.344 |   0.9815 |     32.559 |     1.4
   34 |   0.7246 |     23.065 |   0.9669 |     32.249 |     1.4
   35 |   0.6913 |     21.974 |   0.9609 |     31.568 |     1.4
   36 |   0.6546 |     20.475 |   0.9686 |     31.289 |     1.5
   37 |   0.6177 |     19.196 |   0.9468 |     30.235 |     1.5
   38 |   0.5848 |     17.736 |   0.9630 |     30.112 |     1.6
   39 |   0.5538 |     16.860 |   0.9647 |     30.050 |     1.6
   40 |   0.5233 |     15.884 |   0.9774 |     30.328 |     1.6
   41 |   0.4975 |     15.030 |   0.9747 |     30.112 |     1.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 771,490

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2218 |     61.111 |   1.6053 |     46.344 |     0.0
    2 |   1.4807 |     45.993 |   1.4213 |     47.150 |     0.1
    3 |   1.3956 |     46.131 |   1.3748 |     46.252 |     0.1
    4 |   1.3531 |     45.547 |   1.3363 |     45.291 |     0.1
    5 |   1.3162 |     45.188 |   1.3060 |     44.610 |     0.1
    6 |   1.2892 |     44.334 |   1.2836 |     44.455 |     0.2
    7 |   1.2625 |     43.849 |   1.2577 |     44.424 |     0.2
    8 |   1.2389 |     43.342 |   1.2400 |     43.154 |     0.2
    9 |   1.2231 |     43.237 |   1.2294 |     42.782 |     0.2
   10 |   1.2053 |     42.526 |   1.2215 |     42.627 |     0.3
   11 |   1.1964 |     42.146 |   1.2120 |     42.224 |     0.3
   12 |   1.1825 |     41.826 |   1.1935 |     41.636 |     0.3
   13 |   1.1728 |     41.700 |   1.1908 |     41.264 |     0.3
   14 |   1.1627 |     41.485 |   1.1798 |     41.574 |     0.4
   15 |   1.1513 |     40.763 |   1.1704 |     41.419 |     0.4
   16 |   1.1424 |     40.906 |   1.1658 |     40.458 |     0.4
   17 |   1.1329 |     40.245 |   1.1552 |     41.171 |     0.5
   18 |   1.1227 |     40.035 |   1.1419 |     40.768 |     0.5
   19 |   1.1123 |     39.754 |   1.1409 |     40.180 |     0.5
   20 |   1.1052 |     39.771 |   1.1330 |     40.397 |     0.5
   21 |   1.0998 |     39.352 |   1.1149 |     39.591 |     0.6
   22 |   1.0883 |     38.894 |   1.1146 |     40.520 |     0.6
   23 |   1.0800 |     39.087 |   1.1120 |     39.808 |     0.6
   24 |   1.0712 |     38.586 |   1.1009 |     39.002 |     0.6
   25 |   1.0660 |     38.316 |   1.1140 |     39.157 |     0.7
   26 |   1.0547 |     37.946 |   1.0814 |     38.383 |     0.7
   27 |   1.0461 |     37.340 |   1.0876 |     38.600 |     0.7
   28 |   1.0387 |     37.109 |   1.0826 |     38.414 |     0.7
   29 |   1.0290 |     36.602 |   1.0695 |     38.104 |     0.8
   30 |   1.0171 |     36.062 |   1.0573 |     37.918 |     0.8
   31 |   1.0120 |     35.951 |   1.0559 |     37.639 |     0.8
   32 |   1.0073 |     36.034 |   1.0555 |     37.577 |     0.9
   33 |   0.9953 |     35.428 |   1.0428 |     36.307 |     0.9
   34 |   0.9886 |     35.317 |   1.0426 |     36.958 |     0.9
   35 |   0.9801 |     34.518 |   1.0295 |     36.710 |     0.9
   36 |   0.9756 |     34.772 |   1.0342 |     37.175 |     1.0
   37 |   0.9660 |     34.188 |   1.0311 |     36.958 |     1.0
   38 |   0.9584 |     33.929 |   1.0166 |     35.347 |     1.0
   39 |   0.9473 |     33.686 |   1.0135 |     35.099 |     1.0
   40 |   0.9362 |     33.267 |   0.9951 |     35.068 |     1.1
   41 |   0.9266 |     32.463 |   1.0031 |     35.161 |     1.1
   42 |   0.9151 |     32.077 |   0.9954 |     34.572 |     1.1
   43 |   0.9055 |     31.520 |   0.9847 |     34.511 |     1.1
   44 |   0.8943 |     31.123 |   0.9881 |     33.519 |     1.2
   45 |   0.8902 |     30.974 |   0.9817 |     35.068 |     1.2
   46 |   0.8758 |     30.357 |   0.9775 |     33.643 |     1.2
   47 |   0.8685 |     30.137 |   0.9735 |     32.869 |     1.3
   48 |   0.8524 |     29.282 |   0.9526 |     32.187 |     1.3
   49 |   0.8422 |     29.062 |   0.9592 |     32.528 |     1.3
   50 |   0.8315 |     28.764 |   0.9553 |     33.024 |     1.3
   51 |   0.8177 |     27.965 |   0.9462 |     32.466 |     1.4
   52 |   0.8011 |     27.662 |   0.9497 |     31.939 |     1.4
   53 |   0.7955 |     27.199 |   0.9555 |     31.939 |     1.4
   54 |   0.7810 |     26.720 |   0.9498 |     31.568 |     1.4
   55 |   0.7726 |     26.405 |   0.9472 |     30.762 |     1.5
   56 |   0.7598 |     25.832 |   0.9314 |     30.390 |     1.5
   57 |   0.7475 |     25.457 |   0.9226 |     30.514 |     1.5
   58 |   0.7327 |     25.000 |   0.9173 |     30.081 |     1.6
   59 |   0.7204 |     24.256 |   0.9425 |     31.165 |     1.6
   60 |   0.7099 |     23.936 |   0.9280 |     30.669 |     1.6
   61 |   0.6986 |     23.837 |   0.9286 |     29.709 |     1.6
   62 |   0.6894 |     23.424 |   0.9155 |     29.740 |     1.7
   63 |   0.6757 |     22.977 |   0.9156 |     29.647 |     1.7
   64 |   0.6653 |     22.244 |   0.9191 |     30.019 |     1.7
   65 |   0.6496 |     21.963 |   0.9216 |     29.275 |     1.7
   66 |   0.6387 |     21.412 |   0.9084 |     28.377 |     1.8
   67 |   0.6319 |     21.021 |   0.8988 |     28.501 |     1.8
   68 |   0.6262 |     20.811 |   0.9143 |     28.625 |     1.8
   69 |   0.6164 |     20.442 |   0.9019 |     28.098 |     1.8
   70 |   0.5930 |     19.703 |   0.9067 |     27.726 |     1.9
   71 |   0.5874 |     19.323 |   0.9265 |     28.222 |     1.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 475,810

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5145 |     67.323 |   1.9270 |     55.917 |     0.0
    2 |   1.6867 |     47.729 |   1.5145 |     46.344 |     0.1
    3 |   1.4561 |     45.938 |   1.4238 |     46.066 |     0.1
    4 |   1.3932 |     45.795 |   1.3786 |     46.066 |     0.1
    5 |   1.3555 |     45.662 |   1.3585 |     46.159 |     0.1
    6 |   1.3266 |     44.896 |   1.3309 |     45.198 |     0.2
    7 |   1.3046 |     44.555 |   1.3028 |     44.827 |     0.2
    8 |   1.2864 |     43.943 |   1.2861 |     44.238 |     0.2
    9 |   1.2704 |     43.733 |   1.2650 |     43.649 |     0.2
   10 |   1.2528 |     43.607 |   1.2574 |     43.247 |     0.3
   11 |   1.2361 |     43.248 |   1.2395 |     43.463 |     0.3
   12 |   1.2211 |     42.598 |   1.2256 |     42.503 |     0.3
   13 |   1.2028 |     42.185 |   1.2138 |     42.193 |     0.3
   14 |   1.1887 |     42.075 |   1.2121 |     42.007 |     0.4
   15 |   1.1759 |     41.347 |   1.1930 |     40.985 |     0.4
   16 |   1.1617 |     40.801 |   1.1787 |     40.675 |     0.4
   17 |   1.1484 |     40.338 |   1.1930 |     40.799 |     0.5
   18 |   1.1393 |     39.875 |   1.1666 |     39.622 |     0.5
   19 |   1.1274 |     39.231 |   1.1557 |     39.157 |     0.5
   20 |   1.1149 |     38.961 |   1.1526 |     39.808 |     0.5
   21 |   1.1079 |     38.696 |   1.1431 |     39.405 |     0.6
   22 |   1.0933 |     37.974 |   1.1501 |     40.985 |     0.6
   23 |   1.0806 |     37.963 |   1.1325 |     38.971 |     0.6
   24 |   1.0739 |     37.412 |   1.1232 |     38.724 |     0.6
   25 |   1.0603 |     36.987 |   1.1168 |     38.786 |     0.7
   26 |   1.0501 |     36.734 |   1.1138 |     38.848 |     0.7
   27 |   1.0408 |     36.265 |   1.1086 |     39.312 |     0.7
   28 |   1.0288 |     36.017 |   1.1056 |     38.383 |     0.8
   29 |   1.0189 |     35.819 |   1.0979 |     37.485 |     0.8
   30 |   1.0077 |     34.816 |   1.0894 |     37.485 |     0.8
   31 |   0.9946 |     34.496 |   1.0885 |     37.608 |     0.8
   32 |   0.9823 |     34.055 |   1.0749 |     36.772 |     0.9
   33 |   0.9702 |     33.609 |   1.0818 |     36.679 |     0.9
   34 |   0.9597 |     33.019 |   1.0657 |     36.834 |     0.9
   35 |   0.9459 |     32.512 |   1.0619 |     35.781 |     0.9
   36 |   0.9308 |     31.856 |   1.0557 |     36.214 |     1.0
   37 |   0.9197 |     31.366 |   1.0547 |     36.276 |     1.0
   38 |   0.9061 |     30.848 |   1.0402 |     35.440 |     1.0
   39 |   0.8851 |     29.784 |   1.0433 |     35.347 |     1.0
   40 |   0.8684 |     29.260 |   1.0403 |     35.037 |     1.1
   41 |   0.8504 |     28.180 |   1.0228 |     34.634 |     1.1
   42 |   0.8439 |     27.877 |   1.0349 |     34.387 |     1.1
   43 |   0.8236 |     27.337 |   1.0313 |     33.519 |     1.2
   44 |   0.8044 |     26.477 |   1.0292 |     33.829 |     1.2
   45 |   0.7860 |     25.535 |   1.0152 |     33.055 |     1.2
   46 |   0.7657 |     25.209 |   1.0141 |     32.373 |     1.2
   47 |   0.7513 |     24.339 |   1.0160 |     32.683 |     1.3
   48 |   0.7336 |     23.721 |   1.0111 |     31.506 |     1.3
   49 |   0.7179 |     23.225 |   0.9871 |     31.784 |     1.3
   50 |   0.7037 |     22.801 |   1.0021 |     31.444 |     1.3
   51 |   0.6833 |     21.903 |   1.0124 |     31.660 |     1.4
   52 |   0.6700 |     21.324 |   0.9916 |     30.824 |     1.4
   53 |   0.6553 |     21.114 |   1.0153 |     30.452 |     1.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 503,970

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3823 |     63.564 |   1.8044 |     51.332 |     0.0
    2 |   1.6142 |     47.547 |   1.4784 |     46.344 |     0.1
    3 |   1.4361 |     45.850 |   1.3986 |     46.654 |     0.1
    4 |   1.3816 |     45.629 |   1.3623 |     45.849 |     0.1
    5 |   1.3457 |     45.348 |   1.3366 |     44.827 |     0.2
    6 |   1.3222 |     44.582 |   1.3195 |     44.424 |     0.2
    7 |   1.3023 |     44.400 |   1.2945 |     44.052 |     0.2
    8 |   1.2832 |     44.229 |   1.2799 |     43.897 |     0.3
    9 |   1.2682 |     43.783 |   1.2661 |     43.587 |     0.3
   10 |   1.2519 |     43.563 |   1.2471 |     43.432 |     0.4
   11 |   1.2345 |     43.282 |   1.2318 |     43.154 |     0.4
   12 |   1.2247 |     43.199 |   1.2198 |     42.658 |     0.4
   13 |   1.2095 |     42.416 |   1.2085 |     43.278 |     0.5
   14 |   1.1961 |     42.262 |   1.2061 |     42.255 |     0.5
   15 |   1.1844 |     41.860 |   1.1913 |     41.698 |     0.5
   16 |   1.1740 |     41.380 |   1.1809 |     41.047 |     0.6
   17 |   1.1617 |     41.033 |   1.1685 |     40.799 |     0.6
   18 |   1.1503 |     40.724 |   1.1534 |     40.025 |     0.6
   19 |   1.1416 |     40.366 |   1.1491 |     40.180 |     0.7
   20 |   1.1309 |     40.267 |   1.1347 |     39.188 |     0.7
   21 |   1.1195 |     39.451 |   1.1274 |     39.064 |     0.7
   22 |   1.1074 |     38.999 |   1.1184 |     39.157 |     0.8
   23 |   1.0943 |     38.277 |   1.1206 |     38.848 |     0.8
   24 |   1.0879 |     38.465 |   1.1041 |     38.662 |     0.8
   25 |   1.0783 |     37.588 |   1.0967 |     38.693 |     0.9
   26 |   1.0674 |     37.246 |   1.0860 |     38.631 |     0.9
   27 |   1.0567 |     36.833 |   1.0777 |     38.104 |     0.9
   28 |   1.0439 |     36.128 |   1.0696 |     37.206 |     1.0
   29 |   1.0335 |     35.571 |   1.0610 |     37.423 |     1.0
   30 |   1.0220 |     35.505 |   1.0516 |     36.989 |     1.0
   31 |   1.0136 |     34.948 |   1.0464 |     36.865 |     1.1
   32 |   1.0021 |     34.518 |   1.0418 |     37.051 |     1.1
   33 |   0.9932 |     34.287 |   1.0380 |     36.772 |     1.1
   34 |   0.9815 |     33.554 |   1.0255 |     35.719 |     1.2
   35 |   0.9707 |     33.256 |   1.0131 |     34.944 |     1.2
   36 |   0.9622 |     32.931 |   1.0135 |     35.285 |     1.2
   37 |   0.9493 |     32.259 |   1.0012 |     35.192 |     1.3
   38 |   0.9416 |     32.192 |   1.0009 |     34.820 |     1.3
   39 |   0.9304 |     31.680 |   0.9952 |     35.099 |     1.4
   40 |   0.9152 |     31.366 |   1.0026 |     35.037 |     1.4
   41 |   0.9037 |     30.456 |   0.9782 |     34.603 |     1.4
   42 |   0.8915 |     30.263 |   0.9797 |     34.325 |     1.5
   43 |   0.8866 |     29.878 |   0.9685 |     33.953 |     1.5
   44 |   0.8730 |     29.806 |   0.9695 |     34.263 |     1.5
   45 |   0.8764 |     29.619 |   0.9656 |     33.581 |     1.6
   46 |   0.8503 |     28.671 |   0.9633 |     33.643 |     1.6
   47 |   0.8392 |     27.910 |   0.9551 |     32.063 |     1.6
   48 |   0.8250 |     27.668 |   0.9454 |     31.753 |     1.7
   49 |   0.8074 |     27.001 |   0.9352 |     32.156 |     1.7
   50 |   0.7999 |     26.698 |   0.9432 |     32.001 |     1.7
   51 |   0.7901 |     26.146 |   0.9360 |     31.072 |     1.8
   52 |   0.7747 |     25.788 |   0.9312 |     31.413 |     1.8
   53 |   0.7639 |     25.314 |   0.9267 |     30.793 |     1.8
   54 |   0.7510 |     24.813 |   0.9258 |     30.607 |     1.9
   55 |   0.7365 |     24.443 |   0.9228 |     30.762 |     1.9
   56 |   0.7273 |     24.047 |   0.9171 |     30.607 |     1.9
   57 |   0.7165 |     23.727 |   0.9157 |     29.864 |     2.0
   58 |   0.6990 |     23.088 |   0.9059 |     29.957 |     2.0
   59 |   0.6937 |     22.834 |   0.8982 |     28.872 |     2.0
   60 |   0.6774 |     22.057 |   0.9145 |     29.740 |     2.1
   61 |   0.6677 |     21.947 |   0.9155 |     29.151 |     2.1
   62 |   0.6598 |     21.649 |   0.9162 |     29.678 |     2.2
   63 |   0.6452 |     21.076 |   0.9146 |     29.151 |     2.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 639,394

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0371 |     56.173 |   1.4837 |     47.274 |     0.0
    2 |   1.3985 |     45.585 |   1.3615 |     45.415 |     0.1
    3 |   1.3214 |     44.797 |   1.3038 |     45.167 |     0.1
    4 |   1.2795 |     44.274 |   1.2690 |     43.897 |     0.1
    5 |   1.2483 |     43.452 |   1.2532 |     43.680 |     0.1
    6 |   1.2255 |     43.221 |   1.2190 |     43.154 |     0.2
    7 |   1.2041 |     42.416 |   1.2004 |     43.494 |     0.2
    8 |   1.1792 |     41.948 |   1.1790 |     42.162 |     0.2
    9 |   1.1531 |     40.917 |   1.1613 |     41.202 |     0.3
   10 |   1.1289 |     39.820 |   1.1364 |     40.737 |     0.3
   11 |   1.1065 |     38.944 |   1.1138 |     39.374 |     0.3
   12 |   1.0857 |     38.051 |   1.1019 |     39.219 |     0.3
   13 |   1.0679 |     37.489 |   1.0821 |     38.600 |     0.4
   14 |   1.0459 |     36.712 |   1.0793 |     37.608 |     0.4
   15 |   1.0251 |     36.034 |   1.0592 |     37.485 |     0.4
   16 |   1.0075 |     34.805 |   1.0522 |     37.330 |     0.5
   17 |   0.9939 |     34.739 |   1.0276 |     36.586 |     0.5
   18 |   0.9729 |     33.995 |   1.0128 |     35.471 |     0.5
   19 |   0.9586 |     33.284 |   1.0119 |     35.936 |     0.5
   20 |   0.9422 |     32.639 |   1.0005 |     35.285 |     0.6
   21 |   0.9265 |     32.253 |   0.9846 |     34.820 |     0.6
   22 |   0.9099 |     31.316 |   0.9827 |     33.953 |     0.6
   23 |   0.8899 |     30.522 |   0.9745 |     34.077 |     0.7
   24 |   0.8775 |     30.214 |   0.9691 |     33.488 |     0.7
   25 |   0.8632 |     29.530 |   0.9594 |     33.612 |     0.7
   26 |   0.8420 |     28.588 |   0.9547 |     33.488 |     0.7
   27 |   0.8230 |     27.833 |   0.9603 |     32.094 |     0.8
   28 |   0.8063 |     27.331 |   0.9330 |     31.599 |     0.8
   29 |   0.7846 |     26.290 |   0.9381 |     31.320 |     0.8
   30 |   0.7876 |     26.483 |   0.9168 |     30.979 |     0.9
   31 |   0.7550 |     25.320 |   0.9214 |     30.669 |     0.9
   32 |   0.7335 |     24.416 |   0.9196 |     30.143 |     0.9
   33 |   0.7207 |     24.272 |   0.9127 |     30.266 |     0.9
   34 |   0.7078 |     23.573 |   0.9079 |     30.359 |     1.0
   35 |   0.6896 |     23.110 |   0.8989 |     29.647 |     1.0
   36 |   0.6708 |     22.261 |   0.8927 |     29.213 |     1.0
   37 |   0.6517 |     21.825 |   0.9056 |     29.244 |     1.0
   38 |   0.6494 |     21.616 |   0.9064 |     29.740 |     1.1
   39 |   0.6384 |     21.159 |   0.9080 |     29.833 |     1.1
   40 |   0.6176 |     20.585 |   0.8999 |     28.532 |     1.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,281,698

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5722 |     68.067 |   2.0205 |     59.851 |     0.1
    2 |   1.7779 |     50.887 |   1.5736 |     46.344 |     0.1
    3 |   1.5000 |     45.999 |   1.4558 |     46.468 |     0.2
    4 |   1.4186 |     45.988 |   1.4020 |     46.314 |     0.3
    5 |   1.3790 |     45.993 |   1.3621 |     46.066 |     0.3
    6 |   1.3464 |     45.751 |   1.3437 |     45.539 |     0.4
    7 |   1.3237 |     45.337 |   1.3212 |     47.305 |     0.4
    8 |   1.3045 |     44.985 |   1.3069 |     44.981 |     0.5
    9 |   1.2873 |     44.279 |   1.2841 |     44.981 |     0.6
   10 |   1.2690 |     43.915 |   1.2650 |     44.765 |     0.6
   11 |   1.2534 |     43.739 |   1.2483 |     44.331 |     0.7
   12 |   1.2380 |     43.607 |   1.2373 |     44.331 |     0.8
   13 |   1.2230 |     43.304 |   1.2288 |     43.092 |     0.8
   14 |   1.2129 |     42.885 |   1.2238 |     42.410 |     0.9
   15 |   1.2028 |     42.416 |   1.2102 |     41.884 |     1.0
   16 |   1.1948 |     42.207 |   1.2026 |     41.574 |     1.0
   17 |   1.1867 |     41.573 |   1.1970 |     41.760 |     1.1
   18 |   1.1790 |     41.584 |   1.1874 |     41.109 |     1.1
   19 |   1.1727 |     41.275 |   1.1854 |     42.410 |     1.2
   20 |   1.1641 |     41.347 |   1.1848 |     41.171 |     1.3
   21 |   1.1561 |     40.868 |   1.1786 |     40.799 |     1.3
   22 |   1.1507 |     40.834 |   1.1687 |     41.357 |     1.4
   23 |   1.1448 |     40.680 |   1.1615 |     40.397 |     1.5
   24 |   1.1371 |     40.597 |   1.1623 |     40.954 |     1.5
   25 |   1.1298 |     40.079 |   1.1489 |     40.180 |     1.6
   26 |   1.1232 |     40.002 |   1.1460 |     40.304 |     1.7
   27 |   1.1198 |     40.041 |   1.1446 |     41.047 |     1.7
   28 |   1.1154 |     39.809 |   1.1397 |     40.087 |     1.8
   29 |   1.1078 |     39.881 |   1.1331 |     40.180 |     1.8
   30 |   1.1011 |     39.352 |   1.1326 |     40.397 |     1.9
   31 |   1.0993 |     39.297 |   1.1292 |     39.746 |     2.0
   32 |   1.0938 |     39.076 |   1.1166 |     39.498 |     2.0
   33 |   1.0889 |     38.955 |   1.1273 |     39.870 |     2.1
   34 |   1.0842 |     38.740 |   1.1124 |     38.631 |     2.2
   35 |   1.0804 |     38.784 |   1.1103 |     39.405 |     2.2
   36 |   1.0736 |     38.316 |   1.1122 |     38.693 |     2.3
   37 |   1.0711 |     38.106 |   1.1010 |     38.693 |     2.4
   38 |   1.0646 |     37.941 |   1.0936 |     38.073 |     2.4
   39 |   1.0628 |     38.095 |   1.0905 |     37.763 |     2.5
   40 |   1.0552 |     37.787 |   1.0890 |     38.724 |     2.5
   41 |   1.0483 |     37.357 |   1.0889 |     38.538 |     2.6
   42 |   1.0467 |     37.269 |   1.0833 |     37.949 |     2.7
   43 |   1.0396 |     36.668 |   1.0722 |     37.392 |     2.7
   44 |   1.0326 |     36.839 |   1.0717 |     37.701 |     2.8
   45 |   1.0268 |     36.535 |   1.0673 |     37.206 |     2.9
   46 |   1.0260 |     36.188 |   1.0664 |     37.330 |     2.9
   47 |   1.0221 |     35.802 |   1.0583 |     37.113 |     3.0
   48 |   1.0118 |     35.703 |   1.0586 |     37.206 |     3.0
   49 |   1.0102 |     35.411 |   1.0499 |     36.369 |     3.1
   50 |   1.0041 |     35.444 |   1.0523 |     36.710 |     3.2
   51 |   1.0003 |     35.262 |   1.0439 |     35.998 |     3.2
   52 |   0.9910 |     34.546 |   1.0441 |     36.834 |     3.3
   53 |   0.9821 |     34.347 |   1.0380 |     36.214 |     3.4
   54 |   0.9774 |     34.006 |   1.0295 |     36.029 |     3.4
   55 |   0.9703 |     33.868 |   1.0340 |     35.719 |     3.5
   56 |   0.9658 |     33.714 |   1.0345 |     35.533 |     3.6
   57 |   0.9624 |     33.444 |   1.0228 |     35.750 |     3.6
   58 |   0.9550 |     33.063 |   1.0229 |     35.254 |     3.7
   59 |   0.9507 |     33.129 |   1.0722 |     36.989 |     3.7
   60 |   0.9462 |     32.826 |   1.0215 |     35.719 |     3.8
   61 |   0.9376 |     32.297 |   1.0206 |     35.595 |     3.9
   62 |   0.9391 |     32.451 |   1.0100 |     35.037 |     3.9
   63 |   0.9260 |     31.989 |   1.0102 |     35.161 |     4.0
   64 |   0.9281 |     31.829 |   0.9983 |     34.634 |     4.1
   65 |   0.9212 |     31.548 |   0.9949 |     34.263 |     4.1
   66 |   0.9070 |     30.936 |   0.9978 |     34.170 |     4.2
   67 |   0.9032 |     30.903 |   0.9955 |     33.860 |     4.3
   68 |   0.8943 |     30.456 |   1.0012 |     33.612 |     4.3
   69 |   0.8935 |     30.534 |   0.9884 |     34.263 |     4.4
   70 |   0.8847 |     30.274 |   0.9908 |     33.767 |     4.4
   71 |   0.8734 |     29.608 |   0.9824 |     32.931 |     4.5
   72 |   0.8694 |     29.492 |   0.9868 |     32.807 |     4.6
   73 |   0.8634 |     29.029 |   0.9829 |     32.962 |     4.6
   74 |   0.8595 |     29.200 |   0.9792 |     33.178 |     4.7
   75 |   0.8539 |     28.968 |   0.9866 |     33.426 |     4.8
   76 |   0.8452 |     28.356 |   0.9622 |     32.652 |     4.8
   77 |   0.8382 |     28.164 |   0.9707 |     33.829 |     4.9
   78 |   0.8331 |     28.048 |   0.9868 |     32.342 |     5.0
   79 |   0.8250 |     27.497 |   0.9682 |     32.466 |     5.0
   80 |   0.8186 |     27.464 |   0.9701 |     32.280 |     5.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 604,450

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0811 |     57.016 |   1.5305 |     46.344 |     0.0
    2 |   1.4314 |     45.872 |   1.3768 |     46.314 |     0.1
    3 |   1.3357 |     44.929 |   1.3213 |     45.198 |     0.1
    4 |   1.2885 |     44.218 |   1.2883 |     44.114 |     0.1
    5 |   1.2600 |     43.563 |   1.2661 |     43.556 |     0.1
    6 |   1.2357 |     43.259 |   1.2388 |     42.813 |     0.2
    7 |   1.2117 |     42.234 |   1.2186 |     42.906 |     0.2
    8 |   1.1823 |     41.782 |   1.1880 |     41.791 |     0.2
    9 |   1.1558 |     40.669 |   1.1602 |     40.458 |     0.2
   10 |   1.1277 |     39.809 |   1.1460 |     39.808 |     0.3
   11 |   1.0996 |     38.492 |   1.1213 |     39.715 |     0.3
   12 |   1.0654 |     37.213 |   1.0931 |     39.188 |     0.3
   13 |   1.0294 |     35.389 |   1.0664 |     36.896 |     0.3
   14 |   0.9954 |     33.973 |   1.0479 |     36.152 |     0.4
   15 |   0.9521 |     32.209 |   1.0279 |     35.161 |     0.4
   16 |   0.9221 |     31.228 |   0.9952 |     33.922 |     0.4
   17 |   0.8749 |     29.101 |   0.9901 |     33.984 |     0.4
   18 |   0.8403 |     28.053 |   0.9676 |     32.125 |     0.5
   19 |   0.7978 |     26.416 |   0.9676 |     32.962 |     0.5
   20 |   0.7680 |     25.204 |   0.9436 |     31.351 |     0.5
   21 |   0.7252 |     23.606 |   0.9183 |     30.607 |     0.5
   22 |   0.6808 |     22.140 |   0.9210 |     30.297 |     0.6
   23 |   0.6446 |     20.960 |   0.8999 |     29.213 |     0.6
   24 |   0.6072 |     19.659 |   0.9099 |     29.089 |     0.6
   25 |   0.5831 |     18.761 |   0.9097 |     29.523 |     0.7
   26 |   0.5484 |     17.411 |   0.9059 |     28.594 |     0.7
   27 |   0.5152 |     16.160 |   0.9283 |     28.934 |     0.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,555,170

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4395 |     65.515 |   1.9197 |     54.802 |     0.1
    2 |   1.6879 |     48.501 |   1.5158 |     46.344 |     0.2
    3 |   1.4577 |     45.982 |   1.4181 |     47.150 |     0.3
    4 |   1.3908 |     45.960 |   1.3766 |     46.097 |     0.3
    5 |   1.3551 |     45.343 |   1.3485 |     45.260 |     0.4
    6 |   1.3318 |     44.775 |   1.3301 |     44.734 |     0.5
    7 |   1.3127 |     44.274 |   1.3151 |     45.508 |     0.6
    8 |   1.2955 |     44.086 |   1.3024 |     44.331 |     0.7
    9 |   1.2762 |     43.965 |   1.2817 |     43.866 |     0.8
   10 |   1.2571 |     43.568 |   1.2623 |     43.216 |     0.9
   11 |   1.2393 |     42.934 |   1.2513 |     42.937 |     0.9
   12 |   1.2263 |     42.598 |   1.2378 |     43.773 |     1.0
   13 |   1.2096 |     42.356 |   1.2154 |     42.224 |     1.1
   14 |   1.1930 |     41.705 |   1.2082 |     42.534 |     1.2
   15 |   1.1769 |     40.752 |   1.1956 |     41.574 |     1.3
   16 |   1.1616 |     40.300 |   1.1783 |     40.613 |     1.4
   17 |   1.1457 |     39.495 |   1.1733 |     40.520 |     1.5
   18 |   1.1273 |     38.994 |   1.1556 |     40.458 |     1.5
   19 |   1.1124 |     38.178 |   1.1486 |     39.932 |     1.6
   20 |   1.0884 |     37.307 |   1.1310 |     39.188 |     1.7
   21 |   1.0682 |     36.640 |   1.1133 |     38.724 |     1.8
   22 |   1.0471 |     35.510 |   1.0964 |     37.577 |     1.9
   23 |   1.0245 |     35.025 |   1.0946 |     37.949 |     2.0
   24 |   1.0012 |     34.144 |   1.0763 |     37.454 |     2.0
   25 |   0.9716 |     32.810 |   1.0530 |     36.493 |     2.1
   26 |   0.9480 |     31.884 |   1.0419 |     35.440 |     2.2
   27 |   0.9120 |     30.418 |   1.0288 |     35.099 |     2.3
   28 |   0.8791 |     29.211 |   1.0226 |     34.325 |     2.4
   29 |   0.8499 |     28.081 |   1.0146 |     34.046 |     2.5
   30 |   0.8176 |     26.670 |   1.0090 |     33.984 |     2.6
   31 |   0.7796 |     25.463 |   0.9843 |     32.931 |     2.6
   32 |   0.7471 |     24.140 |   0.9897 |     32.807 |     2.7
   33 |   0.7102 |     22.735 |   0.9723 |     31.320 |     2.8
   34 |   0.6816 |     21.831 |   0.9847 |     31.475 |     2.9
   35 |   0.6506 |     20.751 |   0.9835 |     30.700 |     3.0
   36 |   0.6135 |     19.356 |   0.9836 |     30.607 |     3.1
   37 |   0.5841 |     18.237 |   0.9994 |     30.112 |     3.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 885,730

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2020 |     60.384 |   1.6077 |     49.442 |     0.0
    2 |   1.4682 |     46.103 |   1.4015 |     46.097 |     0.1
    3 |   1.3927 |     46.015 |   1.3730 |     46.468 |     0.1
    4 |   1.3456 |     45.778 |   1.3422 |     46.004 |     0.1
    5 |   1.3170 |     45.073 |   1.3178 |     44.641 |     0.2
    6 |   1.2942 |     44.571 |   1.2979 |     45.880 |     0.2
    7 |   1.2701 |     44.433 |   1.2677 |     44.579 |     0.2
    8 |   1.2470 |     44.218 |   1.2470 |     44.393 |     0.3
    9 |   1.2222 |     43.640 |   1.2247 |     42.999 |     0.3
   10 |   1.2037 |     42.951 |   1.2055 |     43.030 |     0.3
   11 |   1.1895 |     43.006 |   1.2011 |     42.596 |     0.4
   12 |   1.1749 |     42.130 |   1.1889 |     42.906 |     0.4
   13 |   1.1632 |     41.975 |   1.1725 |     42.162 |     0.4
   14 |   1.1481 |     41.264 |   1.1755 |     42.348 |     0.5
   15 |   1.1422 |     41.386 |   1.1657 |     41.357 |     0.5
   16 |   1.1299 |     40.840 |   1.1571 |     41.667 |     0.5
   17 |   1.1147 |     40.146 |   1.1564 |     41.450 |     0.6
   18 |   1.1041 |     39.848 |   1.1381 |     40.458 |     0.6
   19 |   1.0951 |     39.765 |   1.1256 |     39.839 |     0.6
   20 |   1.0860 |     39.275 |   1.1129 |     39.405 |     0.7
   21 |   1.0737 |     38.823 |   1.1077 |     39.777 |     0.7
   22 |   1.0643 |     38.365 |   1.1123 |     39.467 |     0.7
   23 |   1.0547 |     37.583 |   1.0988 |     39.219 |     0.8
   24 |   1.0452 |     37.577 |   1.0830 |     38.414 |     0.8
   25 |   1.0367 |     37.351 |   1.0972 |     38.662 |     0.8
   26 |   1.0298 |     37.087 |   1.0703 |     37.794 |     0.9
   27 |   1.0169 |     36.370 |   1.0801 |     37.423 |     0.9
   28 |   1.0106 |     35.836 |   1.0662 |     36.896 |     0.9
   29 |   0.9967 |     35.576 |   1.0527 |     36.834 |     0.9
   30 |   0.9894 |     35.472 |   1.0532 |     36.493 |     1.0
   31 |   0.9771 |     34.849 |   1.0449 |     36.617 |     1.0
   32 |   0.9698 |     34.695 |   1.0572 |     36.493 |     1.0
   33 |   0.9568 |     34.226 |   1.0415 |     35.967 |     1.1
   34 |   0.9543 |     34.243 |   1.0232 |     35.564 |     1.1
   35 |   0.9417 |     33.840 |   1.0314 |     36.431 |     1.1
   36 |   0.9353 |     33.350 |   1.0191 |     35.378 |     1.2
   37 |   0.9230 |     32.832 |   1.0139 |     35.378 |     1.2
   38 |   0.9165 |     32.997 |   1.0114 |     35.161 |     1.2
   39 |   0.9047 |     32.253 |   1.0111 |     35.409 |     1.3
   40 |   0.8960 |     31.718 |   1.0131 |     35.285 |     1.3
   41 |   0.8826 |     31.542 |   1.0097 |     35.099 |     1.3
   42 |   0.8764 |     30.919 |   1.0067 |     35.378 |     1.4
   43 |   0.8667 |     30.440 |   0.9962 |     34.913 |     1.4
   44 |   0.8555 |     30.341 |   0.9897 |     34.820 |     1.4
   45 |   0.8444 |     30.015 |   0.9940 |     34.572 |     1.5
   46 |   0.8336 |     29.260 |   0.9997 |     34.634 |     1.5
   47 |   0.8234 |     28.847 |   0.9895 |     33.984 |     1.5
   48 |   0.8106 |     28.560 |   0.9814 |     33.953 |     1.6
   49 |   0.8014 |     28.009 |   0.9852 |     34.015 |     1.6
   50 |   0.7872 |     27.497 |   0.9902 |     33.550 |     1.6
   51 |   0.7913 |     27.695 |   0.9775 |     33.333 |     1.7
   52 |   0.7693 |     26.835 |   0.9813 |     33.271 |     1.7
   53 |   0.7548 |     26.466 |   0.9761 |     33.364 |     1.7
   54 |   0.7383 |     25.623 |   0.9928 |     33.116 |     1.8
   55 |   0.7345 |     25.601 |   0.9887 |     33.581 |     1.8
   56 |   0.7211 |     25.149 |   0.9688 |     32.652 |     1.8
   57 |   0.7073 |     24.432 |   0.9597 |     32.187 |     1.9
   58 |   0.6914 |     24.113 |   0.9568 |     32.311 |     1.9
   59 |   0.6818 |     23.661 |   0.9691 |     31.970 |     1.9
   60 |   0.6706 |     23.374 |   0.9755 |     31.289 |     2.0
   61 |   0.6535 |     22.266 |   0.9679 |     30.917 |     2.0
   62 |   0.6404 |     22.062 |   0.9808 |     30.793 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,853,282

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1094 |     57.209 |   1.5528 |     46.344 |     0.1
    2 |   1.4480 |     46.120 |   1.4023 |     47.181 |     0.2
    3 |   1.3635 |     45.370 |   1.3322 |     44.610 |     0.2
    4 |   1.3129 |     43.932 |   1.3044 |     44.176 |     0.3
    5 |   1.2836 |     44.141 |   1.2786 |     43.928 |     0.4
    6 |   1.2596 |     43.728 |   1.2621 |     43.216 |     0.5
    7 |   1.2372 |     43.083 |   1.2505 |     43.866 |     0.6
    8 |   1.2155 |     42.334 |   1.2211 |     42.317 |     0.6
    9 |   1.1936 |     41.766 |   1.1988 |     41.791 |     0.7
   10 |   1.1690 |     41.556 |   1.1727 |     40.985 |     0.8
   11 |   1.1394 |     39.859 |   1.1527 |     39.591 |     0.9
   12 |   1.1066 |     38.514 |   1.1288 |     39.405 |     1.0
   13 |   1.0709 |     36.894 |   1.1072 |     37.670 |     1.0
   14 |   1.0385 |     35.499 |   1.0881 |     37.175 |     1.1
   15 |   1.0057 |     33.945 |   1.0402 |     34.975 |     1.2
   16 |   0.9563 |     32.022 |   1.0151 |     34.789 |     1.3
   17 |   0.9143 |     30.308 |   1.0124 |     34.634 |     1.4
   18 |   0.8695 |     28.323 |   0.9865 |     33.457 |     1.5
   19 |   0.8215 |     27.183 |   0.9883 |     34.449 |     1.5
   20 |   0.7804 |     25.259 |   0.9668 |     32.404 |     1.6
   21 |   0.7325 |     23.341 |   0.9300 |     30.545 |     1.7
   22 |   0.6872 |     22.112 |   0.9225 |     30.081 |     1.8
   23 |   0.6328 |     20.177 |   0.9375 |     29.988 |     1.9
   24 |   0.5931 |     18.789 |   0.9120 |     28.656 |     1.9
   25 |   0.5403 |     17.063 |   0.9182 |     28.748 |     2.0
   26 |   0.4997 |     15.564 |   0.9286 |     28.315 |     2.1
   27 |   0.4553 |     13.950 |   0.9384 |     27.323 |     2.2
   28 |   0.4175 |     12.941 |   0.9628 |     27.726 |     2.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,555,170

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4298 |     63.795 |   1.9145 |     54.027 |     0.1
    2 |   1.6830 |     48.049 |   1.5093 |     46.344 |     0.2
    3 |   1.4541 |     45.955 |   1.4216 |     46.344 |     0.3
    4 |   1.3931 |     45.910 |   1.3738 |     46.314 |     0.3
    5 |   1.3566 |     45.613 |   1.3506 |     46.097 |     0.4
    6 |   1.3305 |     44.781 |   1.3204 |     44.455 |     0.5
    7 |   1.3112 |     44.560 |   1.3031 |     44.579 |     0.6
    8 |   1.2928 |     43.882 |   1.2930 |     44.083 |     0.7
    9 |   1.2795 |     43.827 |   1.2795 |     43.742 |     0.8
   10 |   1.2681 |     43.689 |   1.2680 |     43.959 |     0.9
   11 |   1.2566 |     43.535 |   1.2617 |     43.494 |     0.9
   12 |   1.2454 |     43.326 |   1.2507 |     43.494 |     1.0
   13 |   1.2315 |     43.017 |   1.2390 |     43.463 |     1.1
   14 |   1.2188 |     42.863 |   1.2282 |     44.238 |     1.2
   15 |   1.2063 |     42.471 |   1.2180 |     42.875 |     1.3
   16 |   1.1945 |     41.970 |   1.2087 |     42.937 |     1.4
   17 |   1.1859 |     41.937 |   1.1971 |     41.945 |     1.4
   18 |   1.1722 |     41.667 |   1.1863 |     41.945 |     1.5
   19 |   1.1622 |     41.275 |   1.1760 |     40.861 |     1.6
   20 |   1.1524 |     41.044 |   1.1692 |     41.791 |     1.7
   21 |   1.1412 |     40.504 |   1.1606 |     40.520 |     1.8
   22 |   1.1306 |     39.815 |   1.1452 |     41.264 |     1.9
   23 |   1.1236 |     39.605 |   1.1350 |     40.025 |     2.0
   24 |   1.1126 |     39.115 |   1.1332 |     39.746 |     2.0
   25 |   1.1042 |     38.619 |   1.1246 |     39.281 |     2.1
   26 |   1.0940 |     38.420 |   1.1131 |     38.879 |     2.2
   27 |   1.0867 |     37.991 |   1.1123 |     39.808 |     2.3
   28 |   1.0817 |     37.930 |   1.1060 |     38.507 |     2.4
   29 |   1.0694 |     37.219 |   1.0977 |     38.104 |     2.5
   30 |   1.0615 |     37.285 |   1.0859 |     37.949 |     2.6
   31 |   1.0536 |     36.761 |   1.0812 |     37.515 |     2.6
   32 |   1.0475 |     36.750 |   1.0767 |     37.546 |     2.7
   33 |   1.0387 |     36.387 |   1.0730 |     36.896 |     2.8
   34 |   1.0288 |     36.045 |   1.0652 |     36.400 |     2.9
   35 |   1.0242 |     35.990 |   1.0538 |     36.462 |     3.0
   36 |   1.0146 |     35.731 |   1.0470 |     36.493 |     3.1
   37 |   1.0026 |     35.025 |   1.0409 |     36.369 |     3.2
   38 |   0.9993 |     35.009 |   1.0307 |     36.927 |     3.2
   39 |   0.9870 |     34.557 |   1.0306 |     36.090 |     3.3
   40 |   0.9785 |     34.634 |   1.0220 |     36.029 |     3.4
   41 |   0.9683 |     33.829 |   1.0147 |     35.285 |     3.5
   42 |   0.9626 |     33.427 |   1.0052 |     34.944 |     3.6
   43 |   0.9521 |     33.085 |   1.0027 |     35.068 |     3.7
   44 |   0.9493 |     32.848 |   1.0035 |     34.449 |     3.8
   45 |   0.9369 |     32.595 |   0.9966 |     34.449 |     3.8
   46 |   0.9280 |     32.226 |   0.9891 |     34.232 |     3.9
   47 |   0.9218 |     31.889 |   0.9843 |     33.736 |     4.0
   48 |   0.9149 |     31.718 |   1.0102 |     35.099 |     4.1
   49 |   0.9190 |     31.829 |   0.9836 |     34.572 |     4.2
   50 |   0.9006 |     30.980 |   0.9774 |     33.612 |     4.3
   51 |   0.8916 |     30.837 |   0.9697 |     33.488 |     4.3
   52 |   0.8827 |     30.330 |   0.9834 |     33.550 |     4.4
   53 |   0.8740 |     29.806 |   0.9614 |     33.086 |     4.5
   54 |   0.8615 |     29.426 |   0.9597 |     33.147 |     4.6
   55 |   0.8568 |     29.299 |   0.9533 |     32.962 |     4.7
   56 |   0.8509 |     28.869 |   0.9581 |     33.333 |     4.8
   57 |   0.8464 |     28.902 |   0.9736 |     33.271 |     4.9
   58 |   0.8392 |     28.483 |   0.9513 |     31.629 |     4.9
   59 |   0.8222 |     27.651 |   0.9463 |     32.280 |     5.0
   60 |   0.8095 |     27.331 |   0.9520 |     32.404 |     5.1
   61 |   0.8040 |     27.149 |   0.9392 |     31.722 |     5.2
   62 |   0.7961 |     26.879 |   0.9337 |     31.722 |     5.3
   63 |   0.7912 |     26.830 |   0.9419 |     31.877 |     5.4
   64 |   0.7782 |     26.268 |   0.9393 |     31.537 |     5.5
   65 |   0.7672 |     25.805 |   0.9323 |     31.103 |     5.6
   66 |   0.7546 |     25.292 |   0.9252 |     31.103 |     5.6
   67 |   0.7464 |     24.735 |   0.9333 |     30.855 |     5.7
   68 |   0.7461 |     25.083 |   0.9399 |     31.351 |     5.8
   69 |   0.7349 |     24.669 |   0.9432 |     31.599 |     5.9
   70 |   0.7223 |     24.063 |   0.9328 |     30.204 |     6.0
   71 |   0.7081 |     23.512 |   0.9222 |     30.483 |     6.1
   72 |   0.6989 |     23.302 |   0.9251 |     30.204 |     6.2
   73 |   0.6895 |     22.961 |   0.9265 |     30.204 |     6.2
   74 |   0.6770 |     22.404 |   0.9222 |     29.802 |     6.3
   75 |   0.6703 |     22.244 |   0.9264 |     29.709 |     6.4
   76 |   0.6613 |     21.781 |   0.9186 |     29.895 |     6.5
   77 |   0.6544 |     21.847 |   0.9279 |     29.647 |     6.6
   78 |   0.6401 |     20.944 |   0.9182 |     28.841 |     6.7
   79 |   0.6326 |     20.707 |   0.9149 |     29.306 |     6.8
   80 |   0.6162 |     20.464 |   0.9167 |     28.686 |     6.8
   81 |   0.6103 |     19.720 |   0.9301 |     29.957 |     6.9
   82 |   0.5973 |     19.759 |   0.9207 |     29.275 |     7.0
   83 |   0.5936 |     19.549 |   0.9319 |     29.244 |     7.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,145,698

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3472 |     59.932 |   1.8055 |     48.978 |     0.1
    2 |   1.6264 |     47.393 |   1.4880 |     45.911 |     0.1
    3 |   1.4313 |     45.569 |   1.3969 |     45.911 |     0.2
    4 |   1.3585 |     44.781 |   1.3389 |     44.393 |     0.2
    5 |   1.3199 |     44.218 |   1.3197 |     44.362 |     0.3
    6 |   1.2884 |     43.877 |   1.2838 |     43.959 |     0.4
    7 |   1.2607 |     43.403 |   1.2592 |     43.340 |     0.4
    8 |   1.2364 |     42.736 |   1.2432 |     43.340 |     0.5
    9 |   1.2140 |     42.251 |   1.2187 |     42.503 |     0.6
   10 |   1.1940 |     41.771 |   1.2067 |     43.185 |     0.6
   11 |   1.1720 |     41.138 |   1.1837 |     40.551 |     0.7
   12 |   1.1489 |     40.057 |   1.1702 |     40.799 |     0.7
   13 |   1.1257 |     38.850 |   1.1482 |     39.963 |     0.8
   14 |   1.1027 |     37.957 |   1.1280 |     38.971 |     0.9
   15 |   1.0750 |     36.596 |   1.1136 |     38.786 |     0.9
   16 |   1.0487 |     35.439 |   1.0883 |     37.051 |     1.0
   17 |   1.0173 |     34.375 |   1.0757 |     36.648 |     1.1
   18 |   0.9850 |     33.102 |   1.0538 |     35.409 |     1.1
   19 |   0.9479 |     31.272 |   1.0259 |     34.356 |     1.2
   20 |   0.9053 |     29.823 |   1.0155 |     34.758 |     1.2
   21 |   0.8713 |     28.516 |   1.0038 |     33.891 |     1.3
   22 |   0.8269 |     26.808 |   0.9982 |     33.364 |     1.4
   23 |   0.7877 |     25.386 |   0.9816 |     32.590 |     1.4
   24 |   0.7481 |     23.925 |   0.9717 |     31.568 |     1.5
   25 |   0.7060 |     22.156 |   0.9649 |     31.134 |     1.5
   26 |   0.6662 |     20.988 |   0.9559 |     30.514 |     1.6
   27 |   0.6313 |     19.555 |   0.9583 |     29.709 |     1.7
   28 |   0.5900 |     18.022 |   0.9502 |     29.306 |     1.7
   29 |   0.5577 |     17.030 |   0.9625 |     30.143 |     1.8
   30 |   0.5163 |     15.537 |   0.9680 |     29.151 |     1.9
   31 |   0.4898 |     14.842 |   0.9771 |     28.903 |     1.9
   32 |   0.4545 |     13.757 |   0.9669 |     28.439 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 324,386

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4128 |     64.175 |   1.8442 |     49.690 |     0.0
    2 |   1.6561 |     48.176 |   1.5075 |     46.344 |     0.0
    3 |   1.4594 |     45.971 |   1.4256 |     46.344 |     0.1
    4 |   1.4076 |     46.054 |   1.3865 |     46.344 |     0.1
    5 |   1.3772 |     45.922 |   1.3660 |     47.150 |     0.1
    6 |   1.3534 |     45.437 |   1.3464 |     45.074 |     0.1
    7 |   1.3357 |     44.990 |   1.3292 |     44.827 |     0.1
    8 |   1.3233 |     44.566 |   1.3203 |     44.300 |     0.1
    9 |   1.3114 |     44.224 |   1.3094 |     44.362 |     0.2
   10 |   1.2944 |     43.866 |   1.2933 |     44.269 |     0.2
   11 |   1.2796 |     43.711 |   1.2727 |     43.711 |     0.2
   12 |   1.2609 |     43.629 |   1.2589 |     43.185 |     0.2
   13 |   1.2444 |     43.287 |   1.2457 |     42.782 |     0.2
   14 |   1.2281 |     42.708 |   1.2298 |     42.472 |     0.3
   15 |   1.2128 |     42.372 |   1.2200 |     42.441 |     0.3
   16 |   1.1988 |     42.008 |   1.2073 |     42.162 |     0.3
   17 |   1.1911 |     41.893 |   1.1987 |     41.760 |     0.3
   18 |   1.1777 |     41.264 |   1.1903 |     41.233 |     0.3
   19 |   1.1623 |     40.686 |   1.1744 |     40.892 |     0.4
   20 |   1.1496 |     40.603 |   1.1697 |     41.264 |     0.4
   21 |   1.1383 |     39.936 |   1.1561 |     40.582 |     0.4
   22 |   1.1272 |     39.611 |   1.1493 |     39.932 |     0.4
   23 |   1.1110 |     38.916 |   1.1556 |     40.458 |     0.4
   24 |   1.1061 |     38.729 |   1.1335 |     40.056 |     0.4
   25 |   1.0933 |     38.376 |   1.1342 |     39.467 |     0.5
   26 |   1.0844 |     37.963 |   1.1280 |     38.971 |     0.5
   27 |   1.0694 |     37.428 |   1.1169 |     38.724 |     0.5
   28 |   1.0561 |     36.916 |   1.1086 |     38.538 |     0.5
   29 |   1.0458 |     36.469 |   1.0984 |     38.042 |     0.5
   30 |   1.0361 |     36.194 |   1.0916 |     37.980 |     0.6
   31 |   1.0207 |     35.698 |   1.0886 |     37.701 |     0.6
   32 |   1.0071 |     35.141 |   1.0821 |     37.949 |     0.6
   33 |   1.0008 |     34.860 |   1.0783 |     37.268 |     0.6
   34 |   0.9830 |     34.199 |   1.0709 |     37.454 |     0.6
   35 |   0.9755 |     33.896 |   1.0643 |     37.020 |     0.7
   36 |   0.9615 |     33.377 |   1.0631 |     36.493 |     0.7
   37 |   0.9561 |     32.925 |   1.0586 |     36.803 |     0.7
   38 |   0.9424 |     32.159 |   1.0506 |     36.555 |     0.7
   39 |   0.9250 |     31.873 |   1.0409 |     35.378 |     0.7
   40 |   0.9191 |     31.382 |   1.0420 |     35.471 |     0.8
   41 |   0.9044 |     30.798 |   1.0374 |     34.820 |     0.8
   42 |   0.8939 |     30.258 |   1.0431 |     35.006 |     0.8
   43 |   0.8800 |     29.828 |   1.0398 |     34.789 |     0.8
   44 |   0.8701 |     29.536 |   1.0499 |     35.161 |     0.8
   45 |   0.8628 |     29.260 |   1.0460 |     34.696 |     0.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 640,162

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0595 |     55.897 |   1.4932 |     46.097 |     0.0
    2 |   1.4124 |     45.784 |   1.3642 |     44.919 |     0.1
    3 |   1.3325 |     44.819 |   1.3194 |     44.641 |     0.1
    4 |   1.2967 |     44.185 |   1.2931 |     44.083 |     0.1
    5 |   1.2694 |     43.976 |   1.2649 |     43.804 |     0.2
    6 |   1.2477 |     43.392 |   1.2468 |     43.990 |     0.2
    7 |   1.2190 |     42.758 |   1.2233 |     42.441 |     0.2
    8 |   1.1957 |     42.047 |   1.2055 |     42.007 |     0.2
    9 |   1.1725 |     41.187 |   1.1875 |     41.233 |     0.3
   10 |   1.1422 |     40.129 |   1.1426 |     40.520 |     0.3
   11 |   1.1095 |     38.696 |   1.1118 |     38.600 |     0.3
   12 |   1.0772 |     37.346 |   1.0977 |     39.064 |     0.4
   13 |   1.0484 |     36.310 |   1.0738 |     37.639 |     0.4
   14 |   1.0178 |     34.871 |   1.0776 |     37.763 |     0.4
   15 |   0.9864 |     33.929 |   1.0288 |     36.462 |     0.5
   16 |   0.9498 |     32.198 |   1.0096 |     34.665 |     0.5
   17 |   0.9157 |     30.985 |   1.0066 |     34.387 |     0.5
   18 |   0.8759 |     29.134 |   0.9857 |     34.325 |     0.5
   19 |   0.8487 |     28.362 |   0.9536 |     32.280 |     0.6
   20 |   0.8177 |     27.039 |   0.9394 |     31.351 |     0.6
   21 |   0.7818 |     25.860 |   0.9312 |     31.103 |     0.6
   22 |   0.7605 |     25.116 |   0.9296 |     30.266 |     0.7
   23 |   0.7213 |     23.280 |   0.9108 |     29.151 |     0.7
   24 |   0.6891 |     22.332 |   0.8939 |     28.779 |     0.7
   25 |   0.6613 |     21.368 |   0.8856 |     28.532 |     0.8
   26 |   0.6550 |     21.440 |   0.9024 |     28.129 |     0.8
   27 |   0.6217 |     20.249 |   0.8776 |     27.571 |     0.8
   28 |   0.5843 |     18.563 |   0.8874 |     27.695 |     0.8
   29 |   0.5669 |     18.436 |   0.8719 |     26.828 |     0.9
   30 |   0.5779 |     19.037 |   0.9324 |     28.563 |     0.9
   31 |   0.5502 |     17.758 |   0.8903 |     27.014 |     0.9
   32 |   0.5220 |     16.639 |   0.8889 |     26.859 |     1.0
   33 |   0.4883 |     15.691 |   0.8928 |     26.518 |     1.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,161,378

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4256 |     64.622 |   1.8409 |     49.071 |     0.1
    2 |   1.6468 |     47.558 |   1.4983 |     46.097 |     0.1
    3 |   1.4400 |     45.745 |   1.4088 |     46.406 |     0.2
    4 |   1.3853 |     45.563 |   1.3726 |     46.499 |     0.3
    5 |   1.3506 |     45.381 |   1.3344 |     45.725 |     0.3
    6 |   1.3205 |     44.505 |   1.3109 |     44.672 |     0.4
    7 |   1.2972 |     44.290 |   1.2970 |     44.114 |     0.5
    8 |   1.2802 |     44.373 |   1.2784 |     44.517 |     0.5
    9 |   1.2619 |     43.877 |   1.2575 |     43.959 |     0.6
   10 |   1.2457 |     43.684 |   1.2426 |     43.928 |     0.7
   11 |   1.2314 |     43.414 |   1.2306 |     43.061 |     0.7
   12 |   1.2164 |     42.918 |   1.2192 |     42.565 |     0.8
   13 |   1.2041 |     42.262 |   1.2125 |     42.999 |     0.9
   14 |   1.1935 |     42.201 |   1.2056 |     41.760 |     0.9
   15 |   1.1817 |     41.441 |   1.1917 |     42.937 |     1.0
   16 |   1.1678 |     41.419 |   1.1783 |     41.543 |     1.0
   17 |   1.1581 |     41.060 |   1.1669 |     41.419 |     1.1
   18 |   1.1470 |     40.741 |   1.1557 |     40.458 |     1.2
   19 |   1.1372 |     40.289 |   1.1518 |     41.109 |     1.2
   20 |   1.1271 |     40.063 |   1.1411 |     40.211 |     1.3
   21 |   1.1163 |     39.539 |   1.1273 |     39.219 |     1.4
   22 |   1.1068 |     39.236 |   1.1233 |     39.281 |     1.4
   23 |   1.0983 |     38.795 |   1.1191 |     39.808 |     1.5
   24 |   1.0892 |     38.106 |   1.1029 |     38.507 |     1.6
   25 |   1.0771 |     37.632 |   1.1012 |     38.848 |     1.6
   26 |   1.0700 |     37.676 |   1.0930 |     38.507 |     1.7
   27 |   1.0573 |     36.932 |   1.0810 |     37.949 |     1.7
   28 |   1.0494 |     36.558 |   1.0760 |     38.104 |     1.8
   29 |   1.0374 |     36.100 |   1.0708 |     38.166 |     1.9
   30 |   1.0293 |     35.885 |   1.0717 |     37.485 |     1.9
   31 |   1.0205 |     35.389 |   1.0601 |     37.763 |     2.0
   32 |   1.0070 |     34.651 |   1.0512 |     36.958 |     2.1
   33 |   0.9914 |     34.105 |   1.0420 |     37.051 |     2.1
   34 |   0.9854 |     33.918 |   1.0363 |     36.524 |     2.2
   35 |   0.9781 |     33.896 |   1.0315 |     36.214 |     2.3
   36 |   0.9626 |     33.030 |   1.0214 |     36.029 |     2.3
   37 |   0.9502 |     32.639 |   1.0131 |     35.657 |     2.4
   38 |   0.9377 |     32.215 |   1.0048 |     35.378 |     2.4
   39 |   0.9257 |     31.305 |   1.0024 |     35.223 |     2.5
   40 |   0.9137 |     31.250 |   0.9989 |     35.223 |     2.6
   41 |   0.9026 |     30.759 |   0.9951 |     35.161 |     2.6
   42 |   0.8912 |     30.186 |   0.9771 |     34.418 |     2.7
   43 |   0.8754 |     29.575 |   0.9828 |     34.046 |     2.8
   44 |   0.8618 |     29.029 |   0.9736 |     33.643 |     2.8
   45 |   0.8491 |     28.687 |   0.9795 |     34.325 |     2.9
   46 |   0.8380 |     28.224 |   0.9727 |     33.116 |     3.0
   47 |   0.8181 |     27.177 |   0.9578 |     31.568 |     3.0
   48 |   0.8071 |     27.144 |   0.9582 |     32.125 |     3.1
   49 |   0.7878 |     26.224 |   0.9572 |     32.342 |     3.1
   50 |   0.7780 |     25.915 |   0.9532 |     31.815 |     3.2
   51 |   0.7661 |     25.413 |   0.9463 |     31.134 |     3.3
   52 |   0.7453 |     24.350 |   0.9504 |     30.576 |     3.3
   53 |   0.7342 |     24.256 |   0.9363 |     30.700 |     3.4
   54 |   0.7167 |     23.286 |   0.9377 |     30.948 |     3.5
   55 |   0.7027 |     22.895 |   0.9428 |     30.112 |     3.5
   56 |   0.6911 |     22.597 |   0.9442 |     30.576 |     3.6
   57 |   0.6760 |     22.057 |   0.9397 |     30.483 |     3.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,657,890

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4657 |     65.774 |   1.9448 |     54.306 |     0.1
    2 |   1.7198 |     49.162 |   1.5334 |     47.150 |     0.2
    3 |   1.4691 |     46.026 |   1.4238 |     46.344 |     0.3
    4 |   1.4029 |     45.839 |   1.3866 |     45.849 |     0.4
    5 |   1.3640 |     45.481 |   1.3458 |     45.601 |     0.4
    6 |   1.3323 |     44.858 |   1.3238 |     45.322 |     0.5
    7 |   1.3074 |     44.461 |   1.3060 |     44.672 |     0.6
    8 |   1.2866 |     44.097 |   1.2845 |     44.734 |     0.7
    9 |   1.2730 |     44.180 |   1.2740 |     43.897 |     0.8
   10 |   1.2581 |     43.711 |   1.2616 |     43.804 |     0.9
   11 |   1.2461 |     43.711 |   1.2497 |     43.525 |     1.0
   12 |   1.2340 |     43.474 |   1.2364 |     43.711 |     1.1
   13 |   1.2188 |     42.945 |   1.2216 |     43.061 |     1.2
   14 |   1.2061 |     42.774 |   1.2129 |     43.154 |     1.3
   15 |   1.1965 |     42.482 |   1.1967 |     41.698 |     1.3
   16 |   1.1832 |     42.069 |   1.1888 |     41.326 |     1.4
   17 |   1.1726 |     41.771 |   1.1747 |     40.675 |     1.5
   18 |   1.1596 |     41.187 |   1.1782 |     40.799 |     1.6
   19 |   1.1523 |     40.653 |   1.1669 |     40.582 |     1.7
   20 |   1.1390 |     40.013 |   1.1586 |     39.653 |     1.8
   21 |   1.1305 |     40.151 |   1.1395 |     39.963 |     1.9
   22 |   1.1194 |     39.457 |   1.1342 |     39.653 |     1.9
   23 |   1.1140 |     39.550 |   1.1264 |     38.910 |     2.0
   24 |   1.0987 |     38.872 |   1.1275 |     39.312 |     2.1
   25 |   1.0893 |     38.431 |   1.1038 |     38.414 |     2.2
   26 |   1.0758 |     37.676 |   1.1122 |     38.476 |     2.3
   27 |   1.0703 |     37.153 |   1.0921 |     38.135 |     2.4
   28 |   1.0581 |     36.894 |   1.0822 |     37.175 |     2.5
   29 |   1.0474 |     36.624 |   1.0700 |     36.865 |     2.6
   30 |   1.0354 |     35.968 |   1.0686 |     37.608 |     2.6
   31 |   1.0212 |     35.295 |   1.0582 |     36.059 |     2.7
   32 |   1.0124 |     34.899 |   1.0510 |     36.927 |     2.8
   33 |   0.9994 |     34.414 |   1.0473 |     36.090 |     2.9
   34 |   0.9851 |     33.978 |   1.0310 |     35.719 |     3.0
   35 |   0.9703 |     33.499 |   1.0318 |     35.595 |     3.1
   36 |   0.9595 |     32.777 |   1.0106 |     35.254 |     3.2
   37 |   0.9464 |     32.314 |   1.0048 |     34.139 |     3.3
   38 |   0.9376 |     31.862 |   1.0027 |     34.696 |     3.4
   39 |   0.9202 |     31.509 |   0.9967 |     34.077 |     3.5
   40 |   0.9039 |     30.445 |   0.9891 |     34.418 |     3.5
   41 |   0.8947 |     30.208 |   0.9886 |     33.643 |     3.6
   42 |   0.8789 |     29.756 |   0.9745 |     33.891 |     3.7
   43 |   0.8661 |     29.227 |   0.9830 |     33.055 |     3.8
   44 |   0.8532 |     28.792 |   0.9788 |     33.116 |     3.9
   45 |   0.8361 |     28.103 |   0.9662 |     32.559 |     4.0
   46 |   0.8200 |     27.464 |   0.9539 |     31.722 |     4.1
   47 |   0.8061 |     27.067 |   0.9506 |     31.908 |     4.1
   48 |   0.7874 |     26.466 |   0.9583 |     31.568 |     4.2
   49 |   0.7760 |     25.865 |   0.9401 |     31.072 |     4.3
   50 |   0.7642 |     25.435 |   0.9458 |     30.731 |     4.4
   51 |   0.7464 |     24.807 |   0.9433 |     30.669 |     4.5
   52 |   0.7412 |     24.735 |   0.9429 |     30.855 |     4.6
   53 |   0.7248 |     24.212 |   0.9341 |     29.895 |     4.7
   54 |   0.7088 |     23.611 |   0.9509 |     30.235 |     4.8
   55 |   0.7108 |     23.584 |   0.9345 |     29.709 |     4.9
   56 |   0.6897 |     22.713 |   0.9434 |     30.359 |     4.9
   57 |   0.6754 |     22.542 |   0.9424 |     30.266 |     5.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,676,450

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3174 |     59.342 |   1.7814 |     48.978 |     0.1
    2 |   1.5813 |     46.836 |   1.4565 |     46.066 |     0.2
    3 |   1.4061 |     45.100 |   1.3717 |     44.765 |     0.2
    4 |   1.3442 |     44.549 |   1.3270 |     44.579 |     0.3
    5 |   1.3044 |     44.378 |   1.3001 |     44.238 |     0.4
    6 |   1.2747 |     43.910 |   1.2730 |     43.711 |     0.5
    7 |   1.2535 |     43.530 |   1.2535 |     43.154 |     0.6
    8 |   1.2307 |     42.989 |   1.2395 |     42.720 |     0.7
    9 |   1.2127 |     42.708 |   1.2162 |     42.286 |     0.7
   10 |   1.1923 |     42.052 |   1.2009 |     41.976 |     0.8
   11 |   1.1770 |     41.419 |   1.1877 |     41.574 |     0.9
   12 |   1.1586 |     40.768 |   1.1752 |     41.419 |     1.0
   13 |   1.1442 |     40.625 |   1.1547 |     40.954 |     1.1
   14 |   1.1295 |     39.920 |   1.1458 |     40.087 |     1.1
   15 |   1.1108 |     39.236 |   1.1340 |     39.870 |     1.2
   16 |   1.0945 |     38.735 |   1.1208 |     38.971 |     1.3
   17 |   1.0787 |     37.792 |   1.1094 |     38.538 |     1.4
   18 |   1.0611 |     37.076 |   1.1030 |     38.259 |     1.5
   19 |   1.0426 |     36.095 |   1.0892 |     37.918 |     1.6
   20 |   1.0249 |     35.097 |   1.0873 |     37.392 |     1.6
   21 |   1.0025 |     33.780 |   1.0644 |     36.555 |     1.7
   22 |   0.9819 |     33.036 |   1.0596 |     36.090 |     1.8
   23 |   0.9608 |     32.137 |   1.0524 |     35.037 |     1.9
   24 |   0.9396 |     31.129 |   1.0305 |     34.542 |     2.0
   25 |   0.9183 |     30.357 |   1.0177 |     34.696 |     2.1
   26 |   0.8936 |     29.575 |   1.0147 |     34.572 |     2.1
   27 |   0.8740 |     28.830 |   0.9941 |     33.395 |     2.2
   28 |   0.8494 |     27.910 |   0.9837 |     33.086 |     2.3
   29 |   0.8251 |     26.874 |   0.9733 |     32.559 |     2.4
   30 |   0.8064 |     26.229 |   0.9690 |     32.528 |     2.5
   31 |   0.7813 |     25.843 |   0.9496 |     31.475 |     2.5
   32 |   0.7605 |     24.719 |   0.9556 |     31.846 |     2.6
   33 |   0.7352 |     23.881 |   0.9433 |     31.289 |     2.7
   34 |   0.7103 |     23.258 |   0.9335 |     30.607 |     2.8
   35 |   0.6900 |     22.156 |   0.9381 |     30.081 |     2.9
   36 |   0.6652 |     21.373 |   0.9448 |     30.019 |     3.0
   37 |   0.6417 |     20.337 |   0.9386 |     29.213 |     3.0
   38 |   0.6387 |     20.481 |   0.9423 |     29.430 |     3.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,019,618

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1997 |     60.527 |   1.5988 |     46.344 |     0.1
    2 |   1.4710 |     45.960 |   1.4255 |     46.344 |     0.2
    3 |   1.4071 |     46.026 |   1.4016 |     47.150 |     0.2
    4 |   1.3936 |     46.015 |   1.3967 |     47.150 |     0.3
    5 |   1.3749 |     45.894 |   1.3562 |     45.353 |     0.4
    6 |   1.3419 |     45.448 |   1.3356 |     46.499 |     0.5
    7 |   1.3113 |     45.249 |   1.3039 |     45.322 |     0.6
    8 |   1.2873 |     44.847 |   1.2768 |     44.888 |     0.6
    9 |   1.2602 |     44.406 |   1.2596 |     44.919 |     0.7
   10 |   1.2365 |     43.623 |   1.2395 |     44.919 |     0.8
   11 |   1.2151 |     42.863 |   1.2191 |     42.813 |     0.9
   12 |   1.1986 |     42.306 |   1.2042 |     42.813 |     1.0
   13 |   1.1731 |     41.314 |   1.1901 |     41.667 |     1.1
   14 |   1.1520 |     40.614 |   1.1693 |     40.799 |     1.1
   15 |   1.1325 |     39.920 |   1.1532 |     40.954 |     1.2
   16 |   1.1099 |     39.269 |   1.1320 |     39.219 |     1.3
   17 |   1.0944 |     38.657 |   1.1230 |     38.600 |     1.4
   18 |   1.0689 |     37.291 |   1.0935 |     37.577 |     1.5
   19 |   1.0450 |     36.497 |   1.0879 |     37.825 |     1.5
   20 |   1.0217 |     35.395 |   1.0730 |     37.268 |     1.6
   21 |   0.9997 |     34.860 |   1.0646 |     37.546 |     1.7
   22 |   0.9751 |     33.741 |   1.0446 |     36.493 |     1.8
   23 |   0.9482 |     32.644 |   1.0237 |     35.533 |     1.9
   24 |   0.9202 |     31.388 |   1.0099 |     34.665 |     2.0
   25 |   0.8893 |     29.883 |   1.0019 |     34.232 |     2.0
   26 |   0.8628 |     28.880 |   0.9801 |     32.869 |     2.1
   27 |   0.8269 |     27.425 |   0.9830 |     32.931 |     2.2
   28 |   0.7973 |     26.620 |   0.9836 |     32.435 |     2.3
   29 |   0.7641 |     25.072 |   0.9718 |     32.249 |     2.4
   30 |   0.7283 |     23.523 |   0.9685 |     31.072 |     2.4
   31 |   0.6947 |     22.503 |   0.9581 |     30.731 |     2.5
   32 |   0.6604 |     21.015 |   0.9584 |     30.143 |     2.6
   33 |   0.6234 |     19.544 |   0.9578 |     29.678 |     2.7
   34 |   0.5881 |     18.557 |   0.9667 |     28.934 |     2.7
   35 |   0.5558 |     17.582 |   0.9761 |     29.182 |     2.8
   36 |   0.5267 |     16.430 |   0.9773 |     29.151 |     2.9
   37 |   0.4936 |     15.206 |   0.9859 |     28.779 |     3.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,607,010

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5469 |     68.640 |   1.9720 |     54.957 |     0.1
    2 |   1.7709 |     50.353 |   1.5917 |     46.344 |     0.2
    3 |   1.5051 |     45.971 |   1.4500 |     46.344 |     0.3
    4 |   1.4257 |     46.010 |   1.4046 |     46.344 |     0.3
    5 |   1.3868 |     45.762 |   1.3707 |     46.747 |     0.4
    6 |   1.3508 |     45.409 |   1.3466 |     45.198 |     0.5
    7 |   1.3278 |     44.698 |   1.3259 |     45.725 |     0.6
    8 |   1.3093 |     44.544 |   1.3046 |     44.393 |     0.7
    9 |   1.2924 |     44.285 |   1.2928 |     45.198 |     0.8
   10 |   1.2746 |     44.103 |   1.2733 |     44.579 |     0.9
   11 |   1.2560 |     43.937 |   1.2561 |     44.021 |     1.0
   12 |   1.2419 |     43.524 |   1.2481 |     44.238 |     1.1
   13 |   1.2286 |     42.995 |   1.2337 |     42.689 |     1.2
   14 |   1.2202 |     42.670 |   1.2292 |     43.030 |     1.3
   15 |   1.2094 |     42.339 |   1.2143 |     42.100 |     1.4
   16 |   1.1982 |     42.174 |   1.2096 |     43.154 |     1.5
   17 |   1.1914 |     42.317 |   1.1980 |     42.286 |     1.5
   18 |   1.1842 |     42.190 |   1.1976 |     41.884 |     1.6
   19 |   1.1757 |     41.672 |   1.1844 |     41.543 |     1.7
   20 |   1.1691 |     41.584 |   1.1834 |     41.419 |     1.8
   21 |   1.1611 |     41.567 |   1.1749 |     41.698 |     1.9
   22 |   1.1547 |     41.286 |   1.1669 |     40.923 |     2.0
   23 |   1.1489 |     41.044 |   1.1667 |     41.295 |     2.1
   24 |   1.1451 |     41.264 |   1.1586 |     40.954 |     2.2
   25 |   1.1386 |     40.785 |   1.1553 |     41.047 |     2.2
   26 |   1.1324 |     40.945 |   1.1492 |     41.450 |     2.3
   27 |   1.1266 |     40.322 |   1.1454 |     41.760 |     2.4
   28 |   1.1225 |     40.768 |   1.1503 |     40.892 |     2.5
   29 |   1.1187 |     40.283 |   1.1411 |     40.335 |     2.6
   30 |   1.1143 |     40.355 |   1.1385 |     40.335 |     2.7
   31 |   1.1120 |     40.013 |   1.1328 |     40.644 |     2.8
   32 |   1.1058 |     40.074 |   1.1292 |     40.304 |     2.8
   33 |   1.0997 |     39.688 |   1.1330 |     40.397 |     2.9
   34 |   1.0991 |     39.864 |   1.1266 |     40.644 |     3.0
   35 |   1.0959 |     39.561 |   1.1260 |     39.312 |     3.1
   36 |   1.0932 |     39.688 |   1.1194 |     40.892 |     3.2
   37 |   1.0891 |     39.727 |   1.1241 |     40.242 |     3.2
   38 |   1.0865 |     39.677 |   1.1170 |     39.467 |     3.3
   39 |   1.0842 |     39.346 |   1.1122 |     39.033 |     3.4
   40 |   1.0807 |     39.076 |   1.1145 |     39.498 |     3.5
   41 |   1.0798 |     39.203 |   1.1073 |     39.188 |     3.6
   42 |   1.0730 |     38.938 |   1.1078 |     39.870 |     3.7
   43 |   1.0702 |     38.487 |   1.1060 |     38.879 |     3.7
   44 |   1.0668 |     38.757 |   1.1024 |     38.569 |     3.8
   45 |   1.0627 |     38.641 |   1.1028 |     38.910 |     3.9
   46 |   1.0606 |     38.239 |   1.1050 |     38.817 |     4.0
   47 |   1.0573 |     38.228 |   1.0946 |     39.250 |     4.1
   48 |   1.0561 |     38.228 |   1.0895 |     39.622 |     4.2
   49 |   1.0504 |     38.068 |   1.0885 |     38.290 |     4.2
   50 |   1.0490 |     37.897 |   1.0963 |     38.910 |     4.3
   51 |   1.0471 |     37.704 |   1.0886 |     38.290 |     4.4
   52 |   1.0399 |     37.445 |   1.0829 |     37.918 |     4.5
   53 |   1.0381 |     37.500 |   1.0907 |     39.746 |     4.6
   54 |   1.0384 |     37.621 |   1.0859 |     38.352 |     4.7
   55 |   1.0296 |     37.357 |   1.0789 |     38.600 |     4.7
   56 |   1.0277 |     37.257 |   1.0840 |     38.414 |     4.8
   57 |   1.0281 |     37.324 |   1.0716 |     37.825 |     4.9
   58 |   1.0237 |     37.070 |   1.0732 |     37.701 |     5.0
   59 |   1.0216 |     37.329 |   1.0757 |     38.011 |     5.1
   60 |   1.0174 |     36.701 |   1.0751 |     38.135 |     5.2
   61 |   1.0142 |     36.717 |   1.0653 |     37.423 |     5.2
   62 |   1.0124 |     36.453 |   1.0715 |     37.392 |     5.3
   63 |   1.0105 |     36.513 |   1.0689 |     38.941 |     5.4
   64 |   1.0052 |     36.398 |   1.0688 |     37.299 |     5.5
   65 |   1.0026 |     36.117 |   1.0629 |     37.639 |     5.6
   66 |   0.9997 |     35.940 |   1.0600 |     37.082 |     5.7
   67 |   0.9939 |     35.692 |   1.0533 |     37.113 |     5.7
   68 |   0.9901 |     35.813 |   1.0555 |     37.577 |     5.8
   69 |   0.9887 |     35.643 |   1.0546 |     37.144 |     5.9
   70 |   0.9860 |     35.654 |   1.0547 |     37.020 |     6.0
   71 |   0.9818 |     35.213 |   1.0478 |     37.020 |     6.1
   72 |   0.9796 |     35.455 |   1.0440 |     37.268 |     6.1
   73 |   0.9758 |     35.235 |   1.0420 |     36.865 |     6.2
   74 |   0.9728 |     35.025 |   1.0422 |     36.431 |     6.3
   75 |   0.9685 |     34.987 |   1.0436 |     36.989 |     6.4
   76 |   0.9639 |     34.706 |   1.0419 |     36.772 |     6.5
   77 |   0.9640 |     34.342 |   1.0288 |     36.214 |     6.6
   78 |   0.9611 |     34.551 |   1.0304 |     35.812 |     6.6
   79 |   0.9570 |     34.055 |   1.0323 |     36.152 |     6.7
   80 |   0.9507 |     34.028 |   1.0258 |     36.338 |     6.8
   81 |   0.9492 |     34.088 |   1.0266 |     36.710 |     6.9
   82 |   0.9484 |     33.802 |   1.0218 |     36.214 |     7.0
   83 |   0.9379 |     33.284 |   1.0255 |     35.905 |     7.1
   84 |   0.9366 |     33.300 |   1.0173 |     35.564 |     7.1
   85 |   0.9396 |     33.416 |   1.0148 |     35.719 |     7.2
   86 |   0.9311 |     33.317 |   1.0189 |     35.781 |     7.3
   87 |   0.9301 |     33.234 |   1.0163 |     35.223 |     7.4
   88 |   0.9251 |     33.091 |   1.0088 |     35.440 |     7.5
   89 |   0.9212 |     32.490 |   1.0133 |     35.688 |     7.6
