Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,559,233

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2065 |     60.737 |   1.6034 |     45.432 |     0.1
    2 |   1.4787 |     46.324 |   1.4063 |     45.432 |     0.1
    3 |   1.3867 |     46.066 |   1.3663 |     45.936 |     0.2
    4 |   1.3427 |     45.736 |   1.3189 |     45.243 |     0.2
    5 |   1.3141 |     45.313 |   1.2986 |     45.117 |     0.3
    6 |   1.2865 |     44.873 |   1.2766 |     44.423 |     0.3
    7 |   1.2600 |     44.604 |   1.2630 |     44.423 |     0.4
    8 |   1.2391 |     43.741 |   1.2315 |     42.659 |     0.5
    9 |   1.2188 |     43.087 |   1.2236 |     43.195 |     0.5
   10 |   1.2036 |     42.664 |   1.2044 |     41.619 |     0.6
   11 |   1.1918 |     42.389 |   1.2026 |     42.060 |     0.6
   12 |   1.1798 |     41.812 |   1.1920 |     42.565 |     0.7
   13 |   1.1690 |     41.790 |   1.1786 |     41.304 |     0.8
   14 |   1.1567 |     41.378 |   1.1683 |     40.926 |     0.8
   15 |   1.1480 |     41.340 |   1.1601 |     41.462 |     0.9
   16 |   1.1405 |     41.257 |   1.1601 |     41.430 |     0.9
   17 |   1.1338 |     41.070 |   1.1493 |     40.674 |     1.0
   18 |   1.1236 |     40.796 |   1.1403 |     40.863 |     1.0
   19 |   1.1193 |     40.966 |   1.1445 |     41.462 |     1.1
   20 |   1.1081 |     40.521 |   1.1365 |     40.517 |     1.2
   21 |   1.1033 |     40.323 |   1.1304 |     40.737 |     1.2
   22 |   1.0989 |     40.252 |   1.1306 |     40.076 |     1.3
   23 |   1.0942 |     39.988 |   1.1236 |     40.548 |     1.3
   24 |   1.0888 |     39.840 |   1.1136 |     39.067 |     1.4
   25 |   1.0798 |     39.422 |   1.1192 |     40.076 |     1.5
   26 |   1.0730 |     39.230 |   1.1112 |     38.815 |     1.5
   27 |   1.0677 |     39.274 |   1.1079 |     39.193 |     1.6
   28 |   1.0627 |     39.065 |   1.0992 |     38.973 |     1.6
   29 |   1.0568 |     38.251 |   1.1114 |     38.784 |     1.7
   30 |   1.0522 |     38.356 |   1.0909 |     38.248 |     1.7
   31 |   1.0450 |     37.773 |   1.0945 |     39.509 |     1.8
   32 |   1.0389 |     37.696 |   1.0878 |     38.595 |     1.9
   33 |   1.0327 |     37.213 |   1.0866 |     38.941 |     1.9
   34 |   1.0252 |     37.224 |   1.0758 |     38.028 |     2.0
   35 |   1.0222 |     36.812 |   1.0685 |     36.988 |     2.0
   36 |   1.0147 |     36.477 |   1.0773 |     38.280 |     2.1
   37 |   1.0097 |     36.163 |   1.0679 |     37.303 |     2.2
   38 |   1.0070 |     36.141 |   1.0661 |     38.374 |     2.2
   39 |   0.9991 |     35.828 |   1.0581 |     37.618 |     2.3
   40 |   0.9948 |     35.735 |   1.0524 |     36.862 |     2.3
   41 |   0.9900 |     35.421 |   1.0659 |     38.122 |     2.4
   42 |   0.9818 |     35.059 |   1.0438 |     36.547 |     2.5
   43 |   0.9767 |     35.086 |   1.0428 |     37.020 |     2.5
   44 |   0.9738 |     35.097 |   1.0533 |     36.894 |     2.6
   45 |   0.9672 |     34.773 |   1.0382 |     36.641 |     2.6
   46 |   0.9688 |     34.768 |   1.0433 |     36.074 |     2.7
   47 |   0.9570 |     34.262 |   1.0364 |     35.822 |     2.8
   48 |   0.9524 |     34.278 |   1.0426 |     36.452 |     2.8
   49 |   0.9498 |     33.839 |   1.0362 |     35.633 |     2.9
   50 |   0.9425 |     33.663 |   1.0327 |     36.547 |     2.9
   51 |   0.9382 |     33.680 |   1.0288 |     36.169 |     3.0
   52 |   0.9302 |     33.355 |   1.0238 |     35.192 |     3.1
   53 |   0.9288 |     33.460 |   1.0298 |     35.822 |     3.1
   54 |   0.9235 |     32.954 |   1.0288 |     36.358 |     3.2
   55 |   0.9202 |     33.108 |   1.0280 |     36.200 |     3.2
   56 |   0.9177 |     32.932 |   1.0242 |     35.791 |     3.3
   57 |   0.9170 |     32.734 |   1.0181 |     35.822 |     3.3
   58 |   0.9045 |     32.218 |   1.0071 |     34.436 |     3.4
   59 |   0.9070 |     32.575 |   1.0160 |     35.476 |     3.5
   60 |   0.9029 |     32.207 |   1.0093 |     34.846 |     3.5
   61 |   0.8923 |     31.767 |   1.0187 |     34.972 |     3.6
   62 |   0.8929 |     32.020 |   1.0058 |     34.909 |     3.6
   63 |   0.8878 |     31.597 |   1.0191 |     34.814 |     3.7
   64 |   0.8814 |     31.289 |   1.0122 |     35.224 |     3.8
   65 |   0.8805 |     31.674 |   1.0100 |     35.192 |     3.8
   66 |   0.8741 |     31.201 |   1.0033 |     34.972 |     3.9
   67 |   0.8736 |     31.135 |   1.0112 |     34.657 |     3.9
   68 |   0.8696 |     31.207 |   1.0172 |     34.657 |     4.0
   69 |   0.8652 |     31.058 |   1.0052 |     34.499 |     4.1
   70 |   0.8577 |     30.624 |   1.0043 |     34.625 |     4.1
   71 |   0.8572 |     30.789 |   0.9993 |     34.814 |     4.2
   72 |   0.8514 |     30.311 |   0.9998 |     34.216 |     4.2
   73 |   0.8433 |     30.086 |   0.9947 |     33.585 |     4.3
   74 |   0.8476 |     30.437 |   1.0078 |     34.279 |     4.4
   75 |   0.8399 |     29.778 |   0.9942 |     33.774 |     4.4
   76 |   0.8349 |     29.619 |   1.0040 |     34.184 |     4.5
   77 |   0.8324 |     29.805 |   1.0080 |     33.522 |     4.5
   78 |   0.8288 |     29.520 |   0.9921 |     33.491 |     4.6
   79 |   0.8285 |     29.657 |   1.0011 |     34.846 |     4.7
   80 |   0.8225 |     29.283 |   0.9963 |     34.089 |     4.7
   81 |   0.8195 |     29.426 |   1.0069 |     33.900 |     4.8
   82 |   0.8155 |     29.294 |   0.9984 |     34.058 |     4.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 537,057

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5144 |     67.321 |   1.9720 |     54.064 |     0.0
    2 |   1.7523 |     50.082 |   1.5673 |     45.432 |     0.1
    3 |   1.5002 |     46.302 |   1.4544 |     45.432 |     0.1
    4 |   1.4337 |     46.291 |   1.4168 |     45.432 |     0.1
    5 |   1.4052 |     46.269 |   1.3927 |     45.274 |     0.2
    6 |   1.3832 |     46.104 |   1.3676 |     44.928 |     0.2
    7 |   1.3622 |     45.554 |   1.3465 |     45.148 |     0.2
    8 |   1.3428 |     45.554 |   1.3346 |     45.400 |     0.3
    9 |   1.3268 |     45.269 |   1.3179 |     44.518 |     0.3
   10 |   1.3114 |     44.983 |   1.2976 |     44.203 |     0.3
   11 |   1.2971 |     44.670 |   1.2846 |     43.856 |     0.4
   12 |   1.2844 |     44.461 |   1.2746 |     43.573 |     0.4
   13 |   1.2710 |     44.274 |   1.2637 |     43.132 |     0.4
   14 |   1.2566 |     43.845 |   1.2523 |     42.659 |     0.5
   15 |   1.2447 |     43.609 |   1.2441 |     43.037 |     0.5
   16 |   1.2342 |     43.236 |   1.2357 |     42.029 |     0.5
   17 |   1.2202 |     42.917 |   1.2301 |     42.565 |     0.6
   18 |   1.2054 |     42.455 |   1.2181 |     42.250 |     0.6
   19 |   1.1922 |     42.483 |   1.2071 |     41.651 |     0.6
   20 |   1.1785 |     41.581 |   1.1946 |     41.241 |     0.7
   21 |   1.1656 |     41.114 |   1.1924 |     40.454 |     0.7
   22 |   1.1504 |     40.345 |   1.1739 |     39.981 |     0.7
   23 |   1.1315 |     39.565 |   1.1655 |     39.950 |     0.8
   24 |   1.1165 |     38.922 |   1.1571 |     39.887 |     0.8
   25 |   1.1027 |     38.427 |   1.1453 |     39.162 |     0.8
   26 |   1.0822 |     37.460 |   1.1313 |     38.154 |     0.9
   27 |   1.0689 |     37.021 |   1.1251 |     38.626 |     0.9
   28 |   1.0539 |     36.136 |   1.1196 |     38.658 |     0.9
   29 |   1.0384 |     36.130 |   1.1088 |     37.744 |     1.0
   30 |   1.0195 |     35.229 |   1.0965 |     36.767 |     1.0
   31 |   1.0074 |     34.669 |   1.1055 |     37.996 |     1.0
   32 |   0.9872 |     33.943 |   1.0907 |     37.240 |     1.1
   33 |   0.9738 |     33.712 |   1.1035 |     36.736 |     1.1
   34 |   0.9642 |     32.993 |   1.0825 |     36.484 |     1.1
   35 |   0.9426 |     32.207 |   1.0840 |     36.011 |     1.2
   36 |   0.9250 |     31.553 |   1.0599 |     35.255 |     1.2
   37 |   0.9081 |     30.734 |   1.0588 |     35.381 |     1.2
   38 |   0.8884 |     30.025 |   1.0626 |     35.287 |     1.3
   39 |   0.8712 |     29.542 |   1.0628 |     35.224 |     1.3
   40 |   0.8516 |     28.608 |   1.0458 |     34.688 |     1.3
   41 |   0.8399 |     28.294 |   1.0613 |     34.373 |     1.4
   42 |   0.8258 |     27.772 |   1.0456 |     33.963 |     1.4
   43 |   0.8022 |     26.992 |   1.0387 |     34.089 |     1.4
   44 |   0.7905 |     26.420 |   1.0401 |     34.058 |     1.5
   45 |   0.7777 |     26.052 |   1.0481 |     33.365 |     1.5
   46 |   0.7622 |     25.563 |   1.0369 |     32.766 |     1.5
   47 |   0.7450 |     24.519 |   1.0277 |     33.018 |     1.6
   48 |   0.7229 |     23.898 |   1.0449 |     32.924 |     1.6
   49 |   0.7098 |     23.497 |   1.0351 |     32.325 |     1.6
   50 |   0.6953 |     22.788 |   1.0325 |     32.231 |     1.7
   51 |   0.6864 |     22.502 |   1.0523 |     32.546 |     1.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 639,841

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2750 |     62.315 |   1.6401 |     45.432 |     0.0
    2 |   1.4863 |     46.340 |   1.4187 |     45.432 |     0.0
    3 |   1.3925 |     46.296 |   1.3673 |     44.928 |     0.1
    4 |   1.3487 |     45.489 |   1.3422 |     45.054 |     0.1
    5 |   1.3211 |     45.664 |   1.3132 |     44.329 |     0.1
    6 |   1.3011 |     45.258 |   1.2887 |     43.919 |     0.1
    7 |   1.2810 |     44.648 |   1.2798 |     43.541 |     0.1
    8 |   1.2623 |     43.972 |   1.2577 |     43.258 |     0.2
    9 |   1.2432 |     43.763 |   1.2447 |     43.100 |     0.2
   10 |   1.2224 |     42.961 |   1.2362 |     42.943 |     0.2
   11 |   1.1975 |     42.202 |   1.1979 |     41.210 |     0.2
   12 |   1.1664 |     41.092 |   1.1704 |     40.454 |     0.2
   13 |   1.1374 |     40.175 |   1.1610 |     40.800 |     0.3
   14 |   1.1087 |     39.158 |   1.1382 |     38.941 |     0.3
   15 |   1.0716 |     37.614 |   1.1094 |     37.839 |     0.3
   16 |   1.0354 |     36.048 |   1.1023 |     37.240 |     0.3
   17 |   0.9966 |     34.240 |   1.0800 |     36.169 |     0.3
   18 |   0.9625 |     32.899 |   1.0698 |     35.854 |     0.4
   19 |   0.9175 |     31.163 |   1.0513 |     34.342 |     0.4
   20 |   0.8799 |     29.800 |   1.0349 |     33.963 |     0.4
   21 |   0.8403 |     28.201 |   1.0327 |     33.207 |     0.4
   22 |   0.8035 |     26.904 |   1.0163 |     32.577 |     0.4
   23 |   0.7582 |     25.025 |   1.0249 |     32.703 |     0.4
   24 |   0.7243 |     23.799 |   1.0098 |     32.357 |     0.5
   25 |   0.6885 |     22.321 |   1.0132 |     31.664 |     0.5
   26 |   0.6501 |     20.969 |   1.0144 |     31.853 |     0.5
   27 |   0.6182 |     20.030 |   1.0111 |     30.561 |     0.5
   28 |   0.5793 |     18.584 |   1.0219 |     29.584 |     0.5
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,955,681

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0734 |     56.764 |   1.5326 |     45.463 |     0.1
    2 |   1.4476 |     46.247 |   1.4005 |     45.432 |     0.2
    3 |   1.3647 |     45.659 |   1.3386 |     44.266 |     0.2
    4 |   1.3202 |     45.082 |   1.3022 |     45.022 |     0.3
    5 |   1.2892 |     44.758 |   1.2789 |     43.919 |     0.4
    6 |   1.2608 |     44.164 |   1.2579 |     44.297 |     0.5
    7 |   1.2377 |     43.494 |   1.2312 |     42.659 |     0.5
    8 |   1.2127 |     42.702 |   1.2077 |     41.997 |     0.6
    9 |   1.1840 |     41.686 |   1.1939 |     41.430 |     0.7
   10 |   1.1588 |     40.790 |   1.1646 |     39.603 |     0.8
   11 |   1.1143 |     38.834 |   1.1366 |     39.256 |     0.9
   12 |   1.0678 |     36.718 |   1.1045 |     37.965 |     0.9
   13 |   1.0252 |     35.174 |   1.0960 |     37.681 |     1.0
   14 |   0.9772 |     33.443 |   1.0734 |     36.358 |     1.1
   15 |   0.9272 |     31.185 |   1.0483 |     36.169 |     1.2
   16 |   0.8753 |     29.141 |   1.0161 |     33.711 |     1.2
   17 |   0.8197 |     27.074 |   1.0079 |     32.861 |     1.3
   18 |   0.7667 |     24.992 |   0.9828 |     32.073 |     1.4
   19 |   0.7121 |     22.843 |   0.9598 |     30.561 |     1.5
   20 |   0.6501 |     20.414 |   0.9551 |     30.214 |     1.5
   21 |   0.6035 |     18.832 |   0.9654 |     30.088 |     1.6
   22 |   0.5475 |     17.024 |   0.9577 |     29.269 |     1.7
   23 |   0.5010 |     15.386 |   0.9311 |     27.725 |     1.8
   24 |   0.4441 |     13.480 |   0.9716 |     27.662 |     1.9
   25 |   0.3972 |     11.935 |   1.0052 |     27.316 |     1.9
   26 |   0.3655 |     11.023 |   0.9991 |     26.402 |     2.0
   27 |   0.3324 |     10.155 |   1.0031 |     26.402 |     2.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 489,153

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9908 |     54.990 |   1.4491 |     44.770 |     0.0
    2 |   1.3774 |     45.620 |   1.3264 |     44.486 |     0.0
    3 |   1.3008 |     44.582 |   1.2750 |     43.384 |     0.1
    4 |   1.2539 |     43.780 |   1.2389 |     42.754 |     0.1
    5 |   1.2207 |     42.818 |   1.2104 |     41.115 |     0.1
    6 |   1.1872 |     41.691 |   1.1760 |     40.359 |     0.1
    7 |   1.1609 |     41.142 |   1.1699 |     40.706 |     0.1
    8 |   1.1324 |     40.307 |   1.1406 |     39.603 |     0.1
    9 |   1.1049 |     39.416 |   1.1273 |     38.878 |     0.2
   10 |   1.0783 |     38.054 |   1.1033 |     37.713 |     0.2
   11 |   1.0500 |     36.845 |   1.0836 |     37.114 |     0.2
   12 |   1.0184 |     35.652 |   1.0747 |     36.957 |     0.2
   13 |   0.9870 |     34.493 |   1.0526 |     35.665 |     0.2
   14 |   0.9640 |     33.658 |   1.0331 |     35.413 |     0.2
   15 |   0.9349 |     32.597 |   1.0209 |     34.657 |     0.3
   16 |   0.8962 |     31.119 |   0.9966 |     33.680 |     0.3
   17 |   0.8673 |     30.025 |   0.9945 |     33.554 |     0.3
   18 |   0.8352 |     28.250 |   0.9797 |     32.798 |     0.3
   19 |   0.8115 |     27.470 |   0.9780 |     33.113 |     0.3
   20 |   0.7975 |     27.212 |   0.9669 |     32.420 |     0.3
   21 |   0.7602 |     25.563 |   0.9547 |     31.411 |     0.4
   22 |   0.7364 |     24.536 |   0.9594 |     31.506 |     0.4
   23 |   0.7147 |     23.926 |   0.9381 |     30.435 |     0.4
   24 |   0.6818 |     22.755 |   0.9392 |     30.372 |     0.4
   25 |   0.6641 |     22.200 |   0.9484 |     30.025 |     0.4
   26 |   0.6430 |     21.464 |   0.9332 |     29.931 |     0.5
   27 |   0.6162 |     20.486 |   0.9411 |     29.332 |     0.5
   28 |   0.5935 |     19.513 |   0.9301 |     28.828 |     0.5
   29 |   0.5727 |     18.997 |   0.9469 |     29.868 |     0.5
   30 |   0.5493 |     17.969 |   0.9308 |     28.292 |     0.5
   31 |   0.5330 |     17.524 |   0.9588 |     28.986 |     0.5
   32 |   0.5144 |     16.952 |   0.9647 |     28.481 |     0.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,494,881

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0800 |     57.259 |   1.5433 |     45.463 |     0.1
    2 |   1.4498 |     46.329 |   1.3885 |     45.810 |     0.1
    3 |   1.3627 |     45.818 |   1.3295 |     44.203 |     0.2
    4 |   1.3206 |     44.851 |   1.2950 |     43.730 |     0.2
    5 |   1.2878 |     44.659 |   1.2715 |     44.045 |     0.3
    6 |   1.2665 |     44.175 |   1.2573 |     42.880 |     0.4
    7 |   1.2424 |     43.648 |   1.2355 |     41.903 |     0.4
    8 |   1.2221 |     43.087 |   1.2192 |     42.124 |     0.5
    9 |   1.1993 |     42.406 |   1.1967 |     41.934 |     0.6
   10 |   1.1792 |     41.933 |   1.1790 |     40.611 |     0.6
   11 |   1.1603 |     41.483 |   1.1639 |     39.792 |     0.7
   12 |   1.1358 |     40.285 |   1.1514 |     39.288 |     0.7
   13 |   1.1163 |     39.433 |   1.1227 |     38.910 |     0.8
   14 |   1.0888 |     37.949 |   1.1049 |     37.870 |     0.9
   15 |   1.0624 |     37.207 |   1.0878 |     37.303 |     0.9
   16 |   1.0389 |     36.169 |   1.0750 |     36.925 |     1.0
   17 |   1.0164 |     35.185 |   1.0634 |     36.673 |     1.0
   18 |   0.9868 |     33.773 |   1.0504 |     35.791 |     1.1
   19 |   0.9641 |     33.355 |   1.0325 |     34.940 |     1.2
   20 |   0.9367 |     32.053 |   1.0237 |     35.350 |     1.2
   21 |   0.9164 |     31.295 |   1.0205 |     34.342 |     1.3
   22 |   0.8888 |     30.498 |   1.0054 |     33.806 |     1.3
   23 |   0.8632 |     29.228 |   0.9879 |     33.207 |     1.4
   24 |   0.8396 |     28.382 |   0.9850 |     32.987 |     1.5
   25 |   0.8119 |     27.459 |   0.9632 |     31.348 |     1.5
   26 |   0.7869 |     26.289 |   0.9705 |     31.916 |     1.6
   27 |   0.7601 |     25.113 |   0.9852 |     31.222 |     1.6
   28 |   0.7433 |     24.931 |   0.9482 |     30.750 |     1.7
   29 |   0.7071 |     23.211 |   0.9375 |     30.183 |     1.8
   30 |   0.6744 |     22.272 |   0.9263 |     28.733 |     1.8
   31 |   0.6615 |     22.057 |   0.9341 |     29.742 |     1.9
   32 |   0.6288 |     20.623 |   0.9135 |     29.112 |     2.0
   33 |   0.5961 |     19.255 |   0.9163 |     28.544 |     2.0
   34 |   0.5811 |     19.079 |   0.9025 |     28.355 |     2.1
   35 |   0.5494 |     17.793 |   0.9071 |     27.977 |     2.1
   36 |   0.5290 |     17.139 |   0.9093 |     27.820 |     2.2
   37 |   0.5097 |     16.216 |   0.9101 |     27.347 |     2.3
   38 |   0.4874 |     15.749 |   0.9105 |     27.253 |     2.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,676,129

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3488 |     62.040 |   1.8049 |     47.858 |     0.1
    2 |   1.6004 |     47.549 |   1.4661 |     44.928 |     0.2
    3 |   1.4222 |     46.027 |   1.3782 |     44.928 |     0.2
    4 |   1.3518 |     45.148 |   1.3231 |     43.667 |     0.3
    5 |   1.3081 |     44.219 |   1.2913 |     43.636 |     0.4
    6 |   1.2809 |     44.049 |   1.2664 |     42.880 |     0.5
    7 |   1.2559 |     43.730 |   1.2450 |     42.470 |     0.5
    8 |   1.2311 |     43.142 |   1.2274 |     41.273 |     0.6
    9 |   1.2104 |     42.549 |   1.2089 |     41.273 |     0.7
   10 |   1.1911 |     41.735 |   1.1952 |     40.328 |     0.8
   11 |   1.1723 |     41.092 |   1.1764 |     40.485 |     0.8
   12 |   1.1520 |     40.296 |   1.1668 |     40.202 |     0.9
   13 |   1.1336 |     39.735 |   1.1667 |     40.076 |     1.0
   14 |   1.1149 |     38.724 |   1.1463 |     39.351 |     1.1
   15 |   1.1007 |     38.317 |   1.1360 |     38.941 |     1.1
   16 |   1.0823 |     37.669 |   1.1286 |     38.752 |     1.2
   17 |   1.0693 |     37.202 |   1.1284 |     38.658 |     1.3
   18 |   1.0572 |     36.801 |   1.1102 |     37.461 |     1.4
   19 |   1.0373 |     36.037 |   1.1037 |     37.492 |     1.4
   20 |   1.0191 |     35.246 |   1.0959 |     37.461 |     1.5
   21 |   0.9977 |     34.289 |   1.0724 |     34.972 |     1.6
   22 |   0.9817 |     33.597 |   1.0698 |     34.594 |     1.7
   23 |   0.9586 |     32.487 |   1.0552 |     34.783 |     1.7
   24 |   0.9433 |     31.850 |   1.0530 |     35.444 |     1.8
   25 |   0.9181 |     30.850 |   1.0282 |     33.963 |     1.9
   26 |   0.8978 |     29.992 |   1.0297 |     33.963 |     2.0
   27 |   0.8786 |     29.201 |   1.0455 |     34.089 |     2.0
   28 |   0.8543 |     28.371 |   1.0188 |     33.585 |     2.1
   29 |   0.8332 |     27.459 |   1.0159 |     33.176 |     2.2
   30 |   0.8173 |     27.091 |   1.0198 |     33.617 |     2.3
   31 |   0.7982 |     26.228 |   1.0085 |     33.302 |     2.3
   32 |   0.7729 |     25.624 |   0.9971 |     32.294 |     2.4
   33 |   0.7496 |     24.448 |   1.0043 |     32.703 |     2.5
   34 |   0.7291 |     23.893 |   0.9798 |     31.411 |     2.6
   35 |   0.7072 |     22.942 |   0.9919 |     31.128 |     2.6
   36 |   0.6817 |     22.041 |   0.9779 |     31.191 |     2.7
   37 |   0.6578 |     21.316 |   0.9836 |     31.065 |     2.8
   38 |   0.6361 |     20.475 |   0.9808 |     30.844 |     2.9
   39 |   0.6149 |     19.898 |   0.9956 |     30.183 |     2.9
   40 |   0.5939 |     18.694 |   1.0154 |     30.813 |     3.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,853,057

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1281 |     58.314 |   1.5746 |     45.432 |     0.1
    2 |   1.4605 |     46.285 |   1.3990 |     45.274 |     0.2
    3 |   1.3755 |     46.000 |   1.3498 |     45.117 |     0.2
    4 |   1.3294 |     45.164 |   1.3016 |     43.636 |     0.3
    5 |   1.2906 |     44.461 |   1.2783 |     44.171 |     0.4
    6 |   1.2630 |     44.236 |   1.2562 |     43.100 |     0.5
    7 |   1.2379 |     43.659 |   1.2316 |     43.069 |     0.5
    8 |   1.2155 |     42.829 |   1.2165 |     41.903 |     0.6
    9 |   1.1865 |     41.856 |   1.1942 |     40.926 |     0.7
   10 |   1.1629 |     41.114 |   1.1821 |     40.769 |     0.8
   11 |   1.1390 |     39.867 |   1.1711 |     39.824 |     0.8
   12 |   1.1117 |     39.290 |   1.1264 |     38.469 |     0.9
   13 |   1.0750 |     37.641 |   1.1070 |     36.830 |     1.0
   14 |   1.0373 |     35.680 |   1.0899 |     36.830 |     1.1
   15 |   1.0082 |     34.987 |   1.0630 |     36.389 |     1.1
   16 |   0.9643 |     32.960 |   1.0440 |     34.373 |     1.2
   17 |   0.9240 |     31.058 |   1.0302 |     33.932 |     1.3
   18 |   0.8806 |     29.613 |   1.0198 |     33.743 |     1.4
   19 |   0.8351 |     27.761 |   0.9937 |     32.861 |     1.5
   20 |   0.7904 |     26.074 |   0.9802 |     31.916 |     1.5
   21 |   0.7477 |     24.354 |   0.9747 |     32.231 |     1.6
   22 |   0.6998 |     22.915 |   0.9446 |     30.655 |     1.7
   23 |   0.6444 |     20.706 |   0.9390 |     30.120 |     1.8
   24 |   0.6009 |     19.068 |   0.9211 |     28.702 |     1.8
   25 |   0.5562 |     17.474 |   0.9387 |     29.049 |     1.9
   26 |   0.5271 |     16.826 |   0.9303 |     28.891 |     2.0
   27 |   0.4775 |     15.084 |   0.9447 |     28.733 |     2.1
   28 |   0.4280 |     13.298 |   0.9660 |     28.513 |     2.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,657,633

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4061 |     64.903 |   1.8846 |     50.914 |     0.1
    2 |   1.6553 |     47.840 |   1.5067 |     45.432 |     0.2
    3 |   1.4582 |     46.148 |   1.4194 |     45.400 |     0.2
    4 |   1.4014 |     46.049 |   1.3774 |     45.558 |     0.3
    5 |   1.3617 |     45.664 |   1.3448 |     44.234 |     0.4
    6 |   1.3306 |     44.934 |   1.3164 |     44.108 |     0.5
    7 |   1.3040 |     44.637 |   1.2998 |     44.455 |     0.5
    8 |   1.2865 |     44.346 |   1.2782 |     44.140 |     0.6
    9 |   1.2678 |     44.208 |   1.2625 |     43.195 |     0.7
   10 |   1.2517 |     43.653 |   1.2533 |     42.943 |     0.8
   11 |   1.2365 |     43.065 |   1.2430 |     42.880 |     0.8
   12 |   1.2230 |     42.818 |   1.2355 |     42.596 |     0.9
   13 |   1.2097 |     42.395 |   1.2121 |     42.155 |     1.0
   14 |   1.1962 |     42.186 |   1.2039 |     40.989 |     1.1
   15 |   1.1849 |     41.708 |   1.1926 |     41.210 |     1.1
   16 |   1.1708 |     41.142 |   1.1888 |     41.462 |     1.2
   17 |   1.1559 |     40.576 |   1.1794 |     40.044 |     1.3
   18 |   1.1420 |     40.125 |   1.1727 |     40.359 |     1.4
   19 |   1.1255 |     39.383 |   1.1509 |     39.509 |     1.4
   20 |   1.1108 |     38.625 |   1.1370 |     38.563 |     1.5
   21 |   1.0947 |     38.136 |   1.1321 |     38.500 |     1.6
   22 |   1.0760 |     37.372 |   1.1150 |     38.059 |     1.7
   23 |   1.0552 |     36.586 |   1.1103 |     38.185 |     1.7
   24 |   1.0357 |     35.729 |   1.1098 |     37.240 |     1.8
   25 |   1.0193 |     34.833 |   1.0805 |     35.696 |     1.9
   26 |   0.9946 |     33.778 |   1.0617 |     35.287 |     2.0
   27 |   0.9787 |     33.273 |   1.0616 |     35.003 |     2.0
   28 |   0.9606 |     32.570 |   1.0595 |     35.381 |     2.1
   29 |   0.9422 |     31.932 |   1.0591 |     34.657 |     2.2
   30 |   0.9280 |     31.449 |   1.0382 |     34.310 |     2.3
   31 |   0.9022 |     30.481 |   1.0476 |     35.287 |     2.3
   32 |   0.8838 |     29.833 |   1.0373 |     34.594 |     2.4
   33 |   0.8628 |     28.794 |   1.0399 |     34.531 |     2.5
   34 |   0.8426 |     27.937 |   1.0245 |     33.239 |     2.6
   35 |   0.8228 |     27.030 |   1.0163 |     32.609 |     2.6
   36 |   0.7976 |     25.975 |   1.0089 |     32.577 |     2.7
   37 |   0.7741 |     25.085 |   1.0098 |     31.853 |     2.8
   38 |   0.7597 |     24.530 |   1.0046 |     31.947 |     2.9
   39 |   0.7240 |     23.376 |   1.0045 |     31.443 |     3.0
   40 |   0.7073 |     22.453 |   1.0093 |     32.073 |     3.0
   41 |   0.6782 |     21.640 |   1.0057 |     31.033 |     3.1
   42 |   0.6557 |     20.936 |   1.0089 |     31.411 |     3.2
   43 |   0.6303 |     19.815 |   1.0147 |     30.435 |     3.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 423,713

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4334 |     64.963 |   1.8717 |     47.889 |     0.0
    2 |   1.6393 |     47.225 |   1.4931 |     45.117 |     0.1
    3 |   1.4424 |     46.005 |   1.4053 |     44.928 |     0.1
    4 |   1.3818 |     45.818 |   1.3590 |     44.707 |     0.1
    5 |   1.3391 |     45.412 |   1.3217 |     44.234 |     0.1
    6 |   1.3084 |     44.631 |   1.2950 |     44.297 |     0.2
    7 |   1.2825 |     44.428 |   1.2718 |     43.762 |     0.2
    8 |   1.2568 |     43.483 |   1.2521 |     42.691 |     0.2
    9 |   1.2347 |     43.010 |   1.2294 |     42.533 |     0.2
   10 |   1.2106 |     42.296 |   1.2176 |     41.556 |     0.3
   11 |   1.1837 |     41.450 |   1.1939 |     40.926 |     0.3
   12 |   1.1577 |     40.351 |   1.1886 |     40.107 |     0.3
   13 |   1.1311 |     38.768 |   1.1584 |     39.603 |     0.3
   14 |   1.1037 |     38.339 |   1.1416 |     39.099 |     0.4
   15 |   1.0703 |     36.707 |   1.1194 |     39.288 |     0.4
   16 |   1.0399 |     35.224 |   1.1098 |     37.429 |     0.4
   17 |   1.0026 |     34.202 |   1.0836 |     36.610 |     0.4
   18 |   0.9632 |     32.300 |   1.0677 |     35.570 |     0.5
   19 |   0.9227 |     30.388 |   1.0506 |     34.562 |     0.5
   20 |   0.8809 |     28.602 |   1.0354 |     34.152 |     0.5
   21 |   0.8403 |     27.371 |   1.0230 |     33.396 |     0.6
   22 |   0.7993 |     25.662 |   1.0022 |     32.357 |     0.6
   23 |   0.7604 |     24.393 |   0.9998 |     31.443 |     0.6
   24 |   0.7229 |     22.772 |   0.9949 |     31.758 |     0.6
   25 |   0.6891 |     21.711 |   0.9903 |     30.687 |     0.7
   26 |   0.6544 |     20.354 |   0.9832 |     30.844 |     0.7
   27 |   0.6129 |     18.958 |   0.9905 |     30.183 |     0.7
   28 |   0.5815 |     17.826 |   0.9943 |     30.214 |     0.7
   29 |   0.5975 |     18.634 |   1.0109 |     30.025 |     0.8
   30 |   0.5439 |     16.804 |   1.0159 |     30.592 |     0.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,588,289

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5661 |     69.008 |   2.0125 |     58.727 |     0.1
    2 |   1.7736 |     51.033 |   1.5718 |     45.463 |     0.2
    3 |   1.4968 |     46.346 |   1.4425 |     45.463 |     0.2
    4 |   1.4243 |     46.214 |   1.4051 |     45.463 |     0.3
    5 |   1.3946 |     46.241 |   1.3783 |     44.991 |     0.4
    6 |   1.3727 |     46.038 |   1.3533 |     44.896 |     0.5
    7 |   1.3462 |     45.818 |   1.3272 |     44.455 |     0.6
    8 |   1.3246 |     45.516 |   1.3070 |     44.739 |     0.6
    9 |   1.3083 |     45.258 |   1.2958 |     43.919 |     0.7
   10 |   1.2954 |     44.818 |   1.2867 |     44.455 |     0.8
   11 |   1.2814 |     44.477 |   1.2743 |     43.951 |     0.9
   12 |   1.2697 |     44.021 |   1.2667 |     44.140 |     1.0
   13 |   1.2607 |     44.109 |   1.2557 |     43.321 |     1.0
   14 |   1.2489 |     43.714 |   1.2466 |     42.911 |     1.1
   15 |   1.2373 |     43.439 |   1.2381 |     43.510 |     1.2
   16 |   1.2284 |     43.477 |   1.2269 |     43.226 |     1.3
   17 |   1.2205 |     43.263 |   1.2193 |     43.226 |     1.3
   18 |   1.2102 |     43.115 |   1.2118 |     42.722 |     1.4
   19 |   1.2029 |     42.626 |   1.2034 |     42.502 |     1.5
   20 |   1.1931 |     42.406 |   1.2010 |     42.250 |     1.6
   21 |   1.1875 |     42.230 |   1.1953 |     41.336 |     1.7
   22 |   1.1807 |     41.862 |   1.1919 |     41.651 |     1.7
   23 |   1.1722 |     41.658 |   1.1812 |     41.714 |     1.8
   24 |   1.1667 |     41.571 |   1.1830 |     41.336 |     1.9
   25 |   1.1598 |     41.340 |   1.1702 |     41.178 |     2.0
   26 |   1.1567 |     41.257 |   1.1668 |     40.800 |     2.1
   27 |   1.1517 |     41.065 |   1.1629 |     41.336 |     2.1
   28 |   1.1465 |     40.999 |   1.1560 |     39.950 |     2.2
   29 |   1.1397 |     40.730 |   1.1544 |     39.981 |     2.3
   30 |   1.1340 |     40.482 |   1.1479 |     39.603 |     2.4
   31 |   1.1320 |     40.493 |   1.1472 |     40.359 |     2.5
   32 |   1.1271 |     40.307 |   1.1426 |     39.792 |     2.5
   33 |   1.1240 |     40.411 |   1.1399 |     39.887 |     2.6
   34 |   1.1178 |     40.345 |   1.1392 |     39.477 |     2.7
   35 |   1.1124 |     39.741 |   1.1337 |     38.941 |     2.8
   36 |   1.1139 |     40.004 |   1.1306 |     39.666 |     2.9
   37 |   1.1069 |     39.587 |   1.1238 |     39.414 |     2.9
   38 |   1.1044 |     39.559 |   1.1218 |     38.973 |     3.0
   39 |   1.1029 |     39.713 |   1.1242 |     39.225 |     3.1
   40 |   1.0979 |     39.570 |   1.1203 |     39.540 |     3.2
   41 |   1.0968 |     39.466 |   1.1164 |     39.036 |     3.2
   42 |   1.0932 |     39.389 |   1.1130 |     38.847 |     3.3
   43 |   1.0882 |     38.999 |   1.1097 |     38.910 |     3.4
   44 |   1.0869 |     39.285 |   1.1091 |     38.878 |     3.5
   45 |   1.0838 |     39.131 |   1.1155 |     39.540 |     3.6
   46 |   1.0824 |     39.004 |   1.1074 |     38.815 |     3.6
   47 |   1.0793 |     38.955 |   1.1066 |     38.815 |     3.7
   48 |   1.0774 |     39.059 |   1.1016 |     38.658 |     3.8
   49 |   1.0724 |     38.911 |   1.0982 |     38.532 |     3.9
   50 |   1.0711 |     38.779 |   1.0957 |     38.941 |     4.0
   51 |   1.0699 |     38.806 |   1.0956 |     38.784 |     4.0
   52 |   1.0666 |     38.499 |   1.1007 |     38.626 |     4.1
   53 |   1.0655 |     38.850 |   1.0970 |     38.721 |     4.2
   54 |   1.0576 |     38.438 |   1.0953 |     38.752 |     4.3
   55 |   1.0616 |     38.515 |   1.0878 |     38.689 |     4.4
   56 |   1.0584 |     38.702 |   1.0869 |     38.847 |     4.4
   57 |   1.0555 |     38.400 |   1.0854 |     38.185 |     4.5
   58 |   1.0516 |     38.367 |   1.0887 |     38.595 |     4.6
   59 |   1.0502 |     38.142 |   1.0819 |     38.280 |     4.7
   60 |   1.0477 |     37.850 |   1.0895 |     38.091 |     4.8
   61 |   1.0489 |     38.218 |   1.0827 |     38.028 |     4.8
   62 |   1.0485 |     38.180 |   1.0881 |     39.067 |     4.9
   63 |   1.0454 |     38.213 |   1.0785 |     38.280 |     5.0
   64 |   1.0430 |     38.142 |   1.0862 |     39.351 |     5.1
   65 |   1.0396 |     38.059 |   1.0771 |     38.595 |     5.1
   66 |   1.0383 |     38.054 |   1.0744 |     38.280 |     5.2
   67 |   1.0372 |     38.087 |   1.0721 |     38.500 |     5.3
   68 |   1.0337 |     37.735 |   1.0775 |     38.469 |     5.4
   69 |   1.0328 |     37.647 |   1.0825 |     39.256 |     5.5
   70 |   1.0309 |     37.982 |   1.0675 |     38.154 |     5.5
   71 |   1.0320 |     37.911 |   1.0786 |     38.752 |     5.6
   72 |   1.0280 |     37.526 |   1.0695 |     38.091 |     5.7
   73 |   1.0227 |     37.471 |   1.0644 |     37.776 |     5.8
   74 |   1.0204 |     37.488 |   1.0697 |     37.996 |     5.9
   75 |   1.0208 |     37.312 |   1.0652 |     37.870 |     5.9
   76 |   1.0173 |     37.262 |   1.0673 |     38.122 |     6.0
   77 |   1.0179 |     37.334 |   1.0699 |     37.839 |     6.1
   78 |   1.0134 |     37.279 |   1.0641 |     38.059 |     6.2
   79 |   1.0135 |     37.185 |   1.0613 |     37.965 |     6.3
   80 |   1.0142 |     37.427 |   1.0621 |     38.280 |     6.3
   81 |   1.0088 |     37.037 |   1.0582 |     37.650 |     6.4
   82 |   1.0081 |     37.076 |   1.0556 |     38.248 |     6.5
   83 |   1.0042 |     36.784 |   1.0488 |     37.681 |     6.6
   84 |   1.0061 |     37.015 |   1.0555 |     37.587 |     6.6
   85 |   1.0034 |     36.795 |   1.0580 |     38.721 |     6.7
   86 |   0.9988 |     36.603 |   1.0548 |     37.209 |     6.8
   87 |   1.0012 |     36.641 |   1.0577 |     37.650 |     6.9
   88 |   0.9967 |     36.652 |   1.0460 |     36.578 |     7.0
   89 |   0.9973 |     36.691 |   1.0529 |     36.957 |     7.0
   90 |   0.9947 |     36.669 |   1.0475 |     36.862 |     7.1
   91 |   0.9930 |     36.652 |   1.0435 |     37.114 |     7.2
   92 |   0.9885 |     36.262 |   1.0463 |     37.272 |     7.3
   93 |   0.9904 |     36.119 |   1.0462 |     36.515 |     7.4
   94 |   0.9830 |     35.993 |   1.0432 |     36.610 |     7.4
   95 |   0.9803 |     35.982 |   1.0390 |     37.083 |     7.5
   96 |   0.9775 |     35.976 |   1.0370 |     37.146 |     7.6
   97 |   0.9788 |     35.933 |   1.0330 |     36.137 |     7.7
   98 |   0.9732 |     35.669 |   1.0362 |     36.326 |     7.8
   99 |   0.9720 |     35.680 |   1.0317 |     36.263 |     7.8
  100 |   0.9722 |     35.581 |   1.0280 |     35.696 |     7.9
  101 |   0.9718 |     35.301 |   1.0356 |     35.917 |     8.0
  102 |   0.9655 |     35.108 |   1.0309 |     36.200 |     8.1
  103 |   0.9608 |     35.191 |   1.0327 |     35.980 |     8.2
  104 |   0.9618 |     35.421 |   1.0295 |     36.263 |     8.2
  105 |   0.9598 |     34.998 |   1.0260 |     35.917 |     8.3
  106 |   0.9572 |     34.866 |   1.0244 |     36.263 |     8.4
  107 |   0.9540 |     34.844 |   1.0286 |     36.326 |     8.5
  108 |   0.9532 |     34.883 |   1.0160 |     35.728 |     8.5
  109 |   0.9491 |     34.454 |   1.0199 |     35.318 |     8.6
  110 |   0.9467 |     34.537 |   1.0151 |     35.728 |     8.7
  111 |   0.9432 |     34.713 |   1.0164 |     35.696 |     8.8
  112 |   0.9423 |     34.300 |   1.0226 |     35.791 |     8.9
  113 |   0.9418 |     34.114 |   1.0159 |     35.633 |     8.9
  114 |   0.9373 |     34.180 |   1.0178 |     35.255 |     9.0
  115 |   0.9364 |     33.784 |   1.0119 |     35.539 |     9.1
  116 |   0.9329 |     33.971 |   1.0054 |     34.594 |     9.2
  117 |   0.9271 |     33.614 |   1.0125 |     35.129 |     9.3
  118 |   0.9305 |     33.570 |   1.0075 |     35.035 |     9.3
  119 |   0.9269 |     33.603 |   1.0045 |     35.035 |     9.4
  120 |   0.9221 |     33.278 |   1.0100 |     34.846 |     9.5
  121 |   0.9200 |     33.509 |   1.0028 |     34.058 |     9.6
  122 |   0.9171 |     33.218 |   1.0002 |     34.751 |     9.7
  123 |   0.9152 |     32.965 |   1.0038 |     34.751 |     9.7
  124 |   0.9092 |     32.679 |   1.0057 |     34.877 |     9.8
  125 |   0.9104 |     32.674 |   1.0064 |     34.720 |     9.9
  126 |   0.9073 |     32.888 |   1.0013 |     34.972 |    10.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 439,841

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5167 |     65.359 |   1.9063 |     52.583 |     0.0
    2 |   1.6943 |     49.077 |   1.5206 |     45.432 |     0.1
    3 |   1.4650 |     46.302 |   1.4170 |     45.211 |     0.1
    4 |   1.4030 |     46.131 |   1.3779 |     45.054 |     0.1
    5 |   1.3674 |     45.703 |   1.3480 |     44.140 |     0.1
    6 |   1.3424 |     45.263 |   1.3298 |     45.054 |     0.2
    7 |   1.3192 |     44.873 |   1.3028 |     43.699 |     0.2
    8 |   1.2985 |     44.472 |   1.2858 |     43.699 |     0.2
    9 |   1.2824 |     44.357 |   1.2742 |     44.234 |     0.2
   10 |   1.2671 |     44.203 |   1.2539 |     43.510 |     0.3
   11 |   1.2493 |     44.175 |   1.2428 |     43.793 |     0.3
   12 |   1.2370 |     43.922 |   1.2280 |     43.100 |     0.3
   13 |   1.2235 |     43.472 |   1.2192 |     42.943 |     0.3
   14 |   1.2108 |     43.263 |   1.2015 |     42.187 |     0.4
   15 |   1.1966 |     42.994 |   1.2004 |     42.470 |     0.4
   16 |   1.1898 |     42.582 |   1.1930 |     41.997 |     0.4
   17 |   1.1753 |     41.461 |   1.1799 |     41.021 |     0.4
   18 |   1.1699 |     41.669 |   1.1744 |     40.611 |     0.5
   19 |   1.1594 |     41.422 |   1.1698 |     40.769 |     0.5
   20 |   1.1527 |     41.043 |   1.1583 |     39.792 |     0.5
   21 |   1.1424 |     40.680 |   1.1618 |     40.170 |     0.5
   22 |   1.1363 |     40.620 |   1.1497 |     40.044 |     0.6
   23 |   1.1259 |     40.246 |   1.1443 |     39.729 |     0.6
   24 |   1.1217 |     39.763 |   1.1438 |     39.698 |     0.6
   25 |   1.1108 |     39.307 |   1.1382 |     39.414 |     0.6
   26 |   1.1040 |     39.092 |   1.1263 |     39.193 |     0.7
   27 |   1.0985 |     38.905 |   1.1441 |     40.422 |     0.7
   28 |   1.0931 |     38.977 |   1.1172 |     39.130 |     0.7
   29 |   1.0843 |     38.614 |   1.1232 |     39.288 |     0.7
   30 |   1.0811 |     38.460 |   1.1154 |     39.382 |     0.8
   31 |   1.0738 |     38.147 |   1.1093 |     38.563 |     0.8
   32 |   1.0689 |     37.850 |   1.1105 |     38.437 |     0.8
   33 |   1.0605 |     37.631 |   1.1153 |     38.752 |     0.8
   34 |   1.0543 |     37.367 |   1.1007 |     38.154 |     0.9
   35 |   1.0507 |     37.097 |   1.0980 |     38.374 |     0.9
   36 |   1.0425 |     36.839 |   1.1056 |     38.973 |     0.9
   37 |   1.0395 |     36.861 |   1.0921 |     38.217 |     0.9
   38 |   1.0341 |     36.669 |   1.0907 |     37.870 |     1.0
   39 |   1.0244 |     36.301 |   1.0896 |     38.122 |     1.0
   40 |   1.0196 |     36.059 |   1.0801 |     38.185 |     1.0
   41 |   1.0126 |     35.900 |   1.0830 |     37.461 |     1.0
   42 |   1.0067 |     35.801 |   1.0694 |     37.209 |     1.1
   43 |   0.9988 |     35.493 |   1.0711 |     36.767 |     1.1
   44 |   0.9930 |     35.207 |   1.0643 |     36.610 |     1.1
   45 |   0.9826 |     34.603 |   1.0700 |     36.894 |     1.1
   46 |   0.9818 |     34.636 |   1.0667 |     36.610 |     1.2
   47 |   0.9710 |     34.251 |   1.0588 |     36.547 |     1.2
   48 |   0.9655 |     34.114 |   1.0554 |     36.452 |     1.2
   49 |   0.9588 |     33.822 |   1.0498 |     36.011 |     1.2
   50 |   0.9492 |     33.064 |   1.0591 |     35.791 |     1.3
   51 |   0.9478 |     33.179 |   1.0521 |     36.043 |     1.3
   52 |   0.9415 |     32.932 |   1.0461 |     35.035 |     1.3
   53 |   0.9293 |     32.520 |   1.0489 |     35.507 |     1.3
   54 |   0.9272 |     32.608 |   1.0412 |     34.783 |     1.4
   55 |   0.9207 |     32.366 |   1.0472 |     34.688 |     1.4
   56 |   0.9202 |     32.421 |   1.0331 |     34.814 |     1.4
   57 |   0.9136 |     31.938 |   1.0352 |     34.405 |     1.4
   58 |   0.8960 |     31.069 |   1.0473 |     34.972 |     1.5
   59 |   0.8895 |     31.014 |   1.0269 |     34.751 |     1.5
   60 |   0.8818 |     30.536 |   1.0328 |     34.121 |     1.5
   61 |   0.8751 |     30.366 |   1.0206 |     34.310 |     1.5
   62 |   0.8762 |     30.454 |   1.0339 |     34.657 |     1.6
   63 |   0.8666 |     30.047 |   1.0186 |     33.680 |     1.6
   64 |   0.8594 |     29.904 |   1.0209 |     34.310 |     1.6
   65 |   0.8483 |     29.267 |   1.0260 |     34.405 |     1.6
   66 |   0.8413 |     29.393 |   1.0199 |     33.428 |     1.7
   67 |   0.8347 |     29.069 |   1.0242 |     33.774 |     1.7
   68 |   0.8249 |     28.415 |   1.0173 |     33.270 |     1.7
   69 |   0.8216 |     28.355 |   1.0081 |     33.806 |     1.7
   70 |   0.8123 |     27.959 |   1.0171 |     33.333 |     1.8
   71 |   0.8058 |     27.877 |   1.0139 |     32.798 |     1.8
   72 |   0.7951 |     27.432 |   1.0127 |     32.987 |     1.8
   73 |   0.7832 |     26.849 |   1.0164 |     33.302 |     1.8
   74 |   0.7834 |     26.932 |   1.0057 |     33.176 |     1.9
   75 |   0.7807 |     26.849 |   1.0068 |     32.136 |     1.9
   76 |   0.7724 |     26.486 |   1.0037 |     32.672 |     1.9
   77 |   0.7609 |     26.283 |   1.0053 |     32.892 |     1.9
   78 |   0.7566 |     25.948 |   1.0238 |     32.609 |     2.0
   79 |   0.7466 |     25.569 |   1.0057 |     32.136 |     2.0
   80 |   0.7380 |     25.168 |   1.0215 |     32.577 |     2.0
   81 |   0.7422 |     25.629 |   1.0024 |     31.758 |     2.0
   82 |   0.7313 |     24.981 |   1.0121 |     31.947 |     2.1
   83 |   0.7184 |     24.519 |   1.0152 |     31.758 |     2.1
   84 |   0.7106 |     24.228 |   1.0157 |     31.632 |     2.1
   85 |   0.6994 |     23.948 |   1.0194 |     32.483 |     2.1
   86 |   0.7109 |     24.288 |   1.0023 |     31.380 |     2.2
   87 |   0.7046 |     23.805 |   1.0289 |     31.569 |     2.2
   88 |   0.6950 |     23.574 |   1.0172 |     31.947 |     2.2
   89 |   0.6763 |     22.992 |   1.0217 |     31.853 |     2.2
   90 |   0.6762 |     23.025 |   1.0383 |     31.884 |     2.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 674,721

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9867 |     55.292 |   1.4752 |     46.314 |     0.0
    2 |   1.3882 |     45.851 |   1.3292 |     43.982 |     0.1
    3 |   1.3069 |     44.818 |   1.2830 |     43.762 |     0.1
    4 |   1.2634 |     43.873 |   1.2533 |     43.888 |     0.1
    5 |   1.2231 |     42.999 |   1.2232 |     43.006 |     0.1
    6 |   1.1882 |     41.834 |   1.1879 |     40.139 |     0.2
    7 |   1.1556 |     40.477 |   1.1634 |     40.265 |     0.2
    8 |   1.1203 |     39.318 |   1.1381 |     39.288 |     0.2
    9 |   1.0858 |     37.751 |   1.1192 |     38.374 |     0.2
   10 |   1.0498 |     36.394 |   1.0911 |     36.736 |     0.3
   11 |   1.0041 |     34.377 |   1.0678 |     36.421 |     0.3
   12 |   0.9615 |     32.190 |   1.0533 |     36.043 |     0.3
   13 |   0.9099 |     30.415 |   1.0097 |     33.270 |     0.3
   14 |   0.8621 |     28.739 |   1.0040 |     33.711 |     0.4
   15 |   0.8180 |     27.135 |   0.9995 |     33.302 |     0.4
   16 |   0.7752 |     25.541 |   0.9631 |     31.254 |     0.4
   17 |   0.7274 |     23.651 |   0.9515 |     31.033 |     0.5
   18 |   0.6888 |     22.524 |   0.9549 |     30.844 |     0.5
   19 |   0.6529 |     21.140 |   0.9377 |     30.372 |     0.5
   20 |   0.6062 |     19.700 |   0.9346 |     29.017 |     0.5
   21 |   0.5619 |     17.881 |   0.9403 |     28.954 |     0.6
   22 |   0.5480 |     17.441 |   0.9484 |     28.733 |     0.6
   23 |   0.5157 |     16.419 |   0.9552 |     29.301 |     0.6
   24 |   0.4722 |     14.925 |   0.9486 |     28.040 |     0.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 572,705

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4688 |     66.848 |   1.9286 |     54.159 |     0.0
    2 |   1.7103 |     48.373 |   1.5334 |     45.463 |     0.1
    3 |   1.4798 |     46.291 |   1.4407 |     45.432 |     0.1
    4 |   1.4241 |     46.258 |   1.4059 |     44.928 |     0.1
    5 |   1.3975 |     46.131 |   1.3874 |     45.274 |     0.2
    6 |   1.3780 |     46.049 |   1.3683 |     45.337 |     0.2
    7 |   1.3609 |     45.494 |   1.3521 |     44.739 |     0.2
    8 |   1.3445 |     45.252 |   1.3356 |     44.297 |     0.3
    9 |   1.3307 |     45.054 |   1.3251 |     44.707 |     0.3
   10 |   1.3148 |     44.730 |   1.3140 |     44.802 |     0.3
   11 |   1.2940 |     44.549 |   1.2848 |     43.762 |     0.4
   12 |   1.2755 |     44.049 |   1.2776 |     43.888 |     0.4
   13 |   1.2628 |     43.878 |   1.2660 |     43.226 |     0.4
   14 |   1.2536 |     43.884 |   1.2510 |     43.195 |     0.5
   15 |   1.2382 |     43.626 |   1.2388 |     42.911 |     0.5
   16 |   1.2269 |     43.428 |   1.2353 |     42.502 |     0.5
   17 |   1.2134 |     43.021 |   1.2175 |     42.124 |     0.6
   18 |   1.2001 |     42.213 |   1.2049 |     41.556 |     0.6
   19 |   1.1902 |     41.983 |   1.2064 |     42.124 |     0.6
   20 |   1.1790 |     41.560 |   1.1867 |     40.422 |     0.7
   21 |   1.1643 |     41.065 |   1.1819 |     40.233 |     0.7
   22 |   1.1563 |     40.647 |   1.1816 |     41.430 |     0.7
   23 |   1.1448 |     40.477 |   1.1648 |     39.950 |     0.8
   24 |   1.1362 |     40.395 |   1.1642 |     39.824 |     0.8
   25 |   1.1259 |     40.048 |   1.1601 |     39.792 |     0.8
   26 |   1.1169 |     39.686 |   1.1557 |     39.666 |     0.9
   27 |   1.1086 |     39.488 |   1.1413 |     39.729 |     0.9
   28 |   1.1011 |     39.471 |   1.1333 |     38.847 |     0.9
   29 |   1.0931 |     39.136 |   1.1335 |     40.076 |     1.0
   30 |   1.0831 |     38.911 |   1.1317 |     39.445 |     1.0
   31 |   1.0722 |     38.131 |   1.1235 |     39.288 |     1.0
   32 |   1.0643 |     37.812 |   1.1301 |     40.107 |     1.1
   33 |   1.0542 |     37.631 |   1.1183 |     38.847 |     1.1
   34 |   1.0468 |     37.334 |   1.1069 |     38.595 |     1.1
   35 |   1.0345 |     36.894 |   1.1084 |     39.256 |     1.2
   36 |   1.0270 |     36.400 |   1.1002 |     38.311 |     1.2
   37 |   1.0188 |     36.279 |   1.0981 |     38.343 |     1.2
   38 |   1.0147 |     35.987 |   1.0934 |     37.555 |     1.3
   39 |   1.0002 |     35.312 |   1.0865 |     37.083 |     1.3
   40 |   0.9901 |     34.680 |   1.0835 |     37.146 |     1.3
   41 |   0.9781 |     34.268 |   1.0678 |     36.358 |     1.4
   42 |   0.9669 |     33.811 |   1.0786 |     36.894 |     1.4
   43 |   0.9635 |     33.509 |   1.0799 |     35.759 |     1.4
   44 |   0.9480 |     33.119 |   1.0575 |     35.161 |     1.5
   45 |   0.9349 |     32.306 |   1.0716 |     36.894 |     1.5
   46 |   0.9251 |     31.982 |   1.0620 |     36.074 |     1.5
   47 |   0.9147 |     31.481 |   1.0569 |     35.507 |     1.6
   48 |   0.9016 |     31.025 |   1.0516 |     35.413 |     1.6
   49 |   0.8905 |     30.212 |   1.0509 |     35.255 |     1.6
   50 |   0.8776 |     29.751 |   1.0426 |     34.184 |     1.7
   51 |   0.8662 |     29.294 |   1.0420 |     34.783 |     1.7
   52 |   0.8544 |     28.860 |   1.0579 |     35.255 |     1.7
   53 |   0.8447 |     28.525 |   1.0450 |     35.035 |     1.8
   54 |   0.8301 |     27.739 |   1.0407 |     34.594 |     1.8
   55 |   0.8166 |     27.140 |   1.0227 |     33.176 |     1.8
   56 |   0.8007 |     26.646 |   1.0393 |     33.491 |     1.9
   57 |   0.7934 |     26.442 |   1.0273 |     34.499 |     1.9
   58 |   0.7801 |     25.871 |   1.0324 |     33.680 |     1.9
   59 |   0.7603 |     24.876 |   1.0269 |     33.207 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 732,225

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4888 |     67.161 |   1.9200 |     57.813 |     0.0
    2 |   1.6926 |     48.681 |   1.5255 |     45.463 |     0.1
    3 |   1.4764 |     46.291 |   1.4355 |     45.463 |     0.1
    4 |   1.4214 |     46.423 |   1.4015 |     45.432 |     0.2
    5 |   1.3938 |     46.000 |   1.3779 |     44.959 |     0.2
    6 |   1.3749 |     45.560 |   1.3631 |     44.959 |     0.2
    7 |   1.3603 |     45.615 |   1.3473 |     44.991 |     0.3
    8 |   1.3427 |     45.390 |   1.3294 |     44.675 |     0.3
    9 |   1.3265 |     45.395 |   1.3120 |     44.802 |     0.4
   10 |   1.3097 |     44.977 |   1.2963 |     44.266 |     0.4
   11 |   1.2983 |     44.747 |   1.2838 |     44.077 |     0.4
   12 |   1.2800 |     44.373 |   1.2753 |     43.856 |     0.5
   13 |   1.2659 |     44.362 |   1.2644 |     44.140 |     0.5
   14 |   1.2549 |     44.164 |   1.2523 |     43.352 |     0.6
   15 |   1.2463 |     44.098 |   1.2517 |     43.415 |     0.6
   16 |   1.2380 |     43.703 |   1.2377 |     43.321 |     0.6
   17 |   1.2314 |     43.483 |   1.2346 |     42.974 |     0.7
   18 |   1.2232 |     43.164 |   1.2261 |     42.344 |     0.7
   19 |   1.2192 |     43.219 |   1.2252 |     42.313 |     0.8
   20 |   1.2107 |     43.054 |   1.2174 |     42.439 |     0.8
   21 |   1.2051 |     43.043 |   1.2112 |     42.502 |     0.8
   22 |   1.2003 |     42.631 |   1.2017 |     42.060 |     0.9
   23 |   1.1937 |     42.516 |   1.2025 |     42.533 |     0.9
   24 |   1.1883 |     42.510 |   1.1976 |     42.407 |     0.9
   25 |   1.1831 |     42.356 |   1.1955 |     41.871 |     1.0
   26 |   1.1773 |     42.246 |   1.1891 |     41.682 |     1.0
   27 |   1.1737 |     42.049 |   1.1903 |     42.092 |     1.1
   28 |   1.1704 |     41.763 |   1.1853 |     42.060 |     1.1
   29 |   1.1657 |     41.895 |   1.1851 |     42.155 |     1.1
   30 |   1.1621 |     41.856 |   1.1794 |     41.304 |     1.2
   31 |   1.1581 |     41.614 |   1.1712 |     40.832 |     1.2
   32 |   1.1543 |     41.614 |   1.1726 |     41.556 |     1.3
   33 |   1.1498 |     41.461 |   1.1699 |     41.273 |     1.3
   34 |   1.1459 |     41.543 |   1.1660 |     41.178 |     1.3
   35 |   1.1433 |     41.433 |   1.1727 |     40.958 |     1.4
   36 |   1.1383 |     41.301 |   1.1638 |     40.737 |     1.4
   37 |   1.1359 |     41.296 |   1.1611 |     40.296 |     1.5
   38 |   1.1322 |     41.131 |   1.1608 |     41.588 |     1.5
   39 |   1.1292 |     40.972 |   1.1578 |     41.147 |     1.5
   40 |   1.1262 |     40.829 |   1.1588 |     41.115 |     1.6
   41 |   1.1240 |     40.730 |   1.1511 |     40.485 |     1.6
   42 |   1.1209 |     40.741 |   1.1468 |     40.233 |     1.7
   43 |   1.1180 |     40.576 |   1.1518 |     41.115 |     1.7
   44 |   1.1176 |     40.724 |   1.1474 |     40.296 |     1.7
   45 |   1.1135 |     40.439 |   1.1493 |     40.958 |     1.8
   46 |   1.1104 |     40.307 |   1.1478 |     41.084 |     1.8
   47 |   1.1116 |     40.581 |   1.1447 |     40.737 |     1.9
   48 |   1.1071 |     40.208 |   1.1453 |     41.147 |     1.9
   49 |   1.1060 |     40.279 |   1.1404 |     40.863 |     1.9
   50 |   1.1054 |     40.669 |   1.1440 |     41.241 |     2.0
   51 |   1.1024 |     40.307 |   1.1438 |     41.052 |     2.0
   52 |   1.0996 |     40.252 |   1.1380 |     40.391 |     2.1
   53 |   1.0984 |     40.334 |   1.1327 |     40.643 |     2.1
   54 |   1.0966 |     40.301 |   1.1429 |     40.989 |     2.1
   55 |   1.0964 |     40.345 |   1.1333 |     40.548 |     2.2
   56 |   1.0944 |     40.059 |   1.1342 |     40.706 |     2.2
   57 |   1.0936 |     40.197 |   1.1357 |     40.454 |     2.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,709,409

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4639 |     66.760 |   1.9142 |     57.876 |     0.1
    2 |   1.6974 |     48.736 |   1.5383 |     45.432 |     0.2
    3 |   1.4757 |     46.291 |   1.4380 |     45.463 |     0.2
    4 |   1.4080 |     46.329 |   1.3747 |     45.432 |     0.3
    5 |   1.3595 |     46.241 |   1.3365 |     45.211 |     0.4
    6 |   1.3294 |     45.406 |   1.3159 |     44.896 |     0.5
    7 |   1.3073 |     44.516 |   1.2987 |     43.730 |     0.5
    8 |   1.2863 |     44.411 |   1.2798 |     43.793 |     0.6
    9 |   1.2675 |     44.109 |   1.2626 |     44.140 |     0.7
   10 |   1.2444 |     43.851 |   1.2406 |     43.258 |     0.8
   11 |   1.2248 |     43.323 |   1.2188 |     42.911 |     0.8
   12 |   1.2038 |     42.653 |   1.2109 |     42.407 |     0.9
   13 |   1.1882 |     41.922 |   1.2001 |     41.430 |     1.0
   14 |   1.1737 |     41.494 |   1.1803 |     40.328 |     1.1
   15 |   1.1583 |     40.730 |   1.1753 |     40.296 |     1.1
   16 |   1.1438 |     40.477 |   1.1604 |     40.391 |     1.2
   17 |   1.1310 |     39.779 |   1.1551 |     39.666 |     1.3
   18 |   1.1215 |     39.279 |   1.1471 |     39.067 |     1.4
   19 |   1.1075 |     38.922 |   1.1468 |     39.193 |     1.4
   20 |   1.0934 |     38.471 |   1.1331 |     39.256 |     1.5
   21 |   1.0830 |     37.878 |   1.1293 |     39.067 |     1.6
   22 |   1.0706 |     37.290 |   1.1135 |     38.847 |     1.7
   23 |   1.0590 |     36.757 |   1.1238 |     38.563 |     1.7
   24 |   1.0449 |     36.416 |   1.1138 |     38.343 |     1.8
   25 |   1.0329 |     35.878 |   1.1050 |     37.713 |     1.9
   26 |   1.0190 |     35.163 |   1.0940 |     37.272 |     2.0
   27 |   1.0057 |     34.812 |   1.0965 |     37.146 |     2.0
   28 |   0.9925 |     34.257 |   1.0874 |     37.650 |     2.1
   29 |   0.9779 |     33.712 |   1.1058 |     37.650 |     2.2
   30 |   0.9695 |     33.520 |   1.0879 |     37.020 |     2.3
   31 |   0.9567 |     33.097 |   1.0686 |     35.539 |     2.3
   32 |   0.9397 |     32.295 |   1.0761 |     35.444 |     2.4
   33 |   0.9227 |     31.707 |   1.0659 |     36.452 |     2.5
   34 |   0.9117 |     31.234 |   1.0572 |     35.759 |     2.6
   35 |   0.8933 |     30.745 |   1.0555 |     35.192 |     2.6
   36 |   0.8800 |     30.097 |   1.0505 |     35.665 |     2.7
   37 |   0.8619 |     29.509 |   1.0420 |     34.688 |     2.8
   38 |   0.8565 |     29.498 |   1.0463 |     35.161 |     2.9
   39 |   0.8362 |     28.575 |   1.0398 |     34.468 |     2.9
   40 |   0.8218 |     28.003 |   1.0380 |     34.436 |     3.0
   41 |   0.8022 |     27.377 |   1.0322 |     33.932 |     3.1
   42 |   0.7929 |     26.712 |   1.0383 |     34.909 |     3.2
   43 |   0.7783 |     26.497 |   1.0311 |     32.987 |     3.2
   44 |   0.7585 |     25.437 |   1.0337 |     33.207 |     3.3
   45 |   0.7436 |     24.772 |   1.0402 |     33.743 |     3.4
   46 |   0.7277 |     24.349 |   1.0180 |     32.294 |     3.5
   47 |   0.7142 |     23.799 |   1.0389 |     32.735 |     3.5
   48 |   0.6974 |     22.992 |   1.0272 |     33.018 |     3.6
   49 |   0.6859 |     22.491 |   1.0486 |     32.892 |     3.7
   50 |   0.6661 |     21.854 |   1.0206 |     31.853 |     3.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,559,233

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1832 |     60.292 |   1.6061 |     45.432 |     0.1
    2 |   1.4850 |     46.307 |   1.4222 |     45.810 |     0.1
    3 |   1.4042 |     46.384 |   1.3826 |     45.337 |     0.2
    4 |   1.3701 |     45.697 |   1.3624 |     45.243 |     0.2
    5 |   1.3427 |     45.538 |   1.3250 |     44.770 |     0.3
    6 |   1.3191 |     45.065 |   1.3062 |     44.045 |     0.4
    7 |   1.3046 |     44.780 |   1.3004 |     43.352 |     0.4
    8 |   1.2876 |     44.780 |   1.2792 |     43.762 |     0.5
    9 |   1.2729 |     44.813 |   1.2670 |     43.604 |     0.5
   10 |   1.2571 |     44.252 |   1.2501 |     43.226 |     0.6
   11 |   1.2403 |     43.840 |   1.2402 |     42.565 |     0.7
   12 |   1.2199 |     43.400 |   1.2245 |     42.817 |     0.7
   13 |   1.2011 |     42.812 |   1.2034 |     41.651 |     0.8
   14 |   1.1817 |     41.977 |   1.1828 |     41.115 |     0.9
   15 |   1.1613 |     41.329 |   1.1705 |     40.454 |     0.9
   16 |   1.1426 |     40.730 |   1.1659 |     41.052 |     1.0
   17 |   1.1270 |     40.158 |   1.1725 |     41.021 |     1.0
   18 |   1.1289 |     40.455 |   1.1383 |     39.603 |     1.1
   19 |   1.0940 |     38.988 |   1.1310 |     39.572 |     1.2
   20 |   1.0758 |     38.180 |   1.1237 |     39.603 |     1.2
   21 |   1.0545 |     37.526 |   1.1062 |     38.532 |     1.3
   22 |   1.0402 |     36.784 |   1.0982 |     38.122 |     1.3
   23 |   1.0161 |     35.773 |   1.0935 |     37.146 |     1.4
   24 |   0.9947 |     35.020 |   1.0785 |     37.398 |     1.5
   25 |   0.9717 |     34.207 |   1.0703 |     37.398 |     1.5
   26 |   0.9418 |     32.982 |   1.0548 |     36.106 |     1.6
   27 |   0.9237 |     31.998 |   1.0432 |     35.035 |     1.6
   28 |   0.8923 |     30.608 |   1.0349 |     34.751 |     1.7
   29 |   0.8711 |     29.613 |   1.0187 |     34.216 |     1.8
   30 |   0.8423 |     28.575 |   1.0208 |     33.207 |     1.8
   31 |   0.8205 |     28.168 |   1.0186 |     34.216 |     1.9
   32 |   0.7942 |     27.102 |   1.0119 |     33.648 |     1.9
   33 |   0.7695 |     26.124 |   0.9934 |     33.144 |     2.0
   34 |   0.7424 |     25.058 |   0.9770 |     31.727 |     2.1
   35 |   0.7179 |     23.970 |   0.9844 |     31.569 |     2.1
   36 |   0.6935 |     23.316 |   0.9765 |     30.844 |     2.2
   37 |   0.6765 |     22.338 |   1.0024 |     31.537 |     2.3
   38 |   0.6566 |     22.266 |   0.9884 |     30.844 |     2.3
   39 |   0.6167 |     20.508 |   1.0080 |     30.624 |     2.4
   40 |   0.5901 |     19.376 |   0.9819 |     29.899 |     2.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 718,465

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0645 |     56.819 |   1.5028 |     45.369 |     0.0
    2 |   1.4218 |     46.153 |   1.3728 |     44.991 |     0.1
    3 |   1.3434 |     45.296 |   1.3114 |     44.045 |     0.1
    4 |   1.2935 |     44.565 |   1.2713 |     43.667 |     0.1
    5 |   1.2673 |     44.576 |   1.2582 |     43.699 |     0.2
    6 |   1.2436 |     44.038 |   1.2313 |     42.880 |     0.2
    7 |   1.2204 |     43.290 |   1.2097 |     42.281 |     0.2
    8 |   1.2024 |     42.889 |   1.1942 |     41.462 |     0.3
    9 |   1.1803 |     41.917 |   1.1849 |     41.304 |     0.3
   10 |   1.1639 |     41.400 |   1.1648 |     41.052 |     0.3
   11 |   1.1462 |     40.889 |   1.1561 |     40.643 |     0.4
   12 |   1.1350 |     40.906 |   1.1569 |     41.178 |     0.4
   13 |   1.1167 |     39.949 |   1.1332 |     39.824 |     0.4
   14 |   1.1017 |     39.361 |   1.1214 |     39.193 |     0.5
   15 |   1.0886 |     38.993 |   1.1169 |     38.658 |     0.5
   16 |   1.0736 |     38.394 |   1.1068 |     39.099 |     0.5
   17 |   1.0605 |     37.916 |   1.0967 |     38.532 |     0.6
   18 |   1.0493 |     37.713 |   1.0904 |     37.713 |     0.6
   19 |   1.0368 |     37.284 |   1.0862 |     37.776 |     0.6
   20 |   1.0215 |     36.279 |   1.0774 |     37.303 |     0.7
   21 |   1.0071 |     36.042 |   1.0631 |     37.051 |     0.7
   22 |   0.9941 |     35.389 |   1.0598 |     36.767 |     0.7
   23 |   0.9803 |     34.916 |   1.0541 |     36.957 |     0.8
   24 |   0.9649 |     34.460 |   1.0380 |     36.074 |     0.8
   25 |   0.9495 |     33.443 |   1.0327 |     35.035 |     0.8
   26 |   0.9365 |     33.026 |   1.0286 |     35.728 |     0.9
   27 |   0.9255 |     32.690 |   1.0183 |     34.909 |     0.9
   28 |   0.9139 |     32.372 |   1.0119 |     35.444 |     0.9
   29 |   0.8963 |     31.410 |   1.0134 |     33.491 |     1.0
   30 |   0.8838 |     30.948 |   1.0021 |     33.648 |     1.0
   31 |   0.8666 |     30.338 |   0.9939 |     34.373 |     1.0
   32 |   0.8544 |     29.855 |   0.9841 |     33.554 |     1.1
   33 |   0.8395 |     29.185 |   0.9748 |     33.239 |     1.1
   34 |   0.8326 |     29.086 |   0.9793 |     33.459 |     1.1
   35 |   0.8116 |     28.058 |   0.9694 |     32.892 |     1.2
   36 |   0.8011 |     27.789 |   0.9630 |     31.380 |     1.2
   37 |   0.7837 |     27.267 |   0.9533 |     32.231 |     1.2
   38 |   0.7715 |     26.624 |   0.9552 |     31.191 |     1.3
   39 |   0.7597 |     26.239 |   0.9590 |     32.325 |     1.3
   40 |   0.7467 |     25.794 |   0.9446 |     30.498 |     1.3
   41 |   0.7340 |     25.420 |   0.9364 |     29.616 |     1.4
   42 |   0.7192 |     24.574 |   0.9376 |     30.435 |     1.4
   43 |   0.7009 |     24.014 |   0.9329 |     29.616 |     1.4
   44 |   0.6885 |     23.750 |   0.9234 |     29.269 |     1.5
   45 |   0.6736 |     22.882 |   0.9323 |     29.710 |     1.5
   46 |   0.6610 |     22.535 |   0.9234 |     29.521 |     1.5
   47 |   0.6469 |     21.667 |   0.9280 |     29.458 |     1.6
   48 |   0.6426 |     21.909 |   0.9371 |     29.616 |     1.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 736,289

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1774 |     59.545 |   1.5865 |     45.432 |     0.0
    2 |   1.4690 |     46.346 |   1.4144 |     45.432 |     0.0
    3 |   1.4017 |     46.373 |   1.3762 |     45.400 |     0.1
    4 |   1.3607 |     46.082 |   1.3373 |     45.432 |     0.1
    5 |   1.3278 |     45.725 |   1.3121 |     44.802 |     0.1
    6 |   1.3078 |     45.186 |   1.3020 |     44.739 |     0.1
    7 |   1.2909 |     44.664 |   1.2878 |     44.549 |     0.2
    8 |   1.2674 |     44.675 |   1.2642 |     44.518 |     0.2
    9 |   1.2481 |     44.274 |   1.2426 |     43.289 |     0.2
   10 |   1.2301 |     43.560 |   1.2326 |     43.006 |     0.2
   11 |   1.2159 |     43.126 |   1.2204 |     42.218 |     0.3
   12 |   1.2052 |     42.873 |   1.2193 |     42.628 |     0.3
   13 |   1.1948 |     42.455 |   1.2045 |     42.470 |     0.3
   14 |   1.1820 |     42.027 |   1.1879 |     42.124 |     0.3
   15 |   1.1721 |     41.834 |   1.1806 |     41.210 |     0.4
   16 |   1.1562 |     41.323 |   1.1765 |     40.863 |     0.4
   17 |   1.1475 |     41.142 |   1.1679 |     40.643 |     0.4
   18 |   1.1327 |     40.526 |   1.1578 |     40.580 |     0.4
   19 |   1.1271 |     40.559 |   1.1469 |     39.855 |     0.5
   20 |   1.1138 |     39.960 |   1.1457 |     40.454 |     0.5
   21 |   1.1010 |     39.394 |   1.1347 |     39.761 |     0.5
   22 |   1.0893 |     39.059 |   1.1426 |     39.950 |     0.5
   23 |   1.0769 |     38.625 |   1.1358 |     39.382 |     0.5
   24 |   1.0753 |     38.416 |   1.1308 |     39.666 |     0.6
   25 |   1.0590 |     37.960 |   1.1082 |     38.847 |     0.6
   26 |   1.0430 |     37.389 |   1.1035 |     39.004 |     0.6
   27 |   1.0299 |     36.746 |   1.0969 |     38.122 |     0.6
   28 |   1.0216 |     36.350 |   1.0940 |     37.650 |     0.7
   29 |   1.0058 |     35.993 |   1.0869 |     37.618 |     0.7
   30 |   0.9947 |     35.476 |   1.0772 |     37.933 |     0.7
   31 |   0.9816 |     34.905 |   1.0732 |     37.240 |     0.7
   32 |   0.9694 |     34.361 |   1.0843 |     37.335 |     0.8
   33 |   0.9577 |     34.031 |   1.0639 |     36.106 |     0.8
   34 |   0.9397 |     33.372 |   1.0561 |     36.169 |     0.8
   35 |   0.9334 |     32.855 |   1.0460 |     35.791 |     0.8
   36 |   0.9141 |     32.009 |   1.0430 |     35.791 |     0.9
   37 |   0.9014 |     31.586 |   1.0279 |     35.350 |     0.9
   38 |   0.8867 |     30.817 |   1.0270 |     35.161 |     0.9
   39 |   0.8687 |     30.333 |   1.0273 |     35.161 |     0.9
   40 |   0.8591 |     29.937 |   1.0260 |     34.814 |     0.9
   41 |   0.8398 |     29.355 |   1.0160 |     35.350 |     1.0
   42 |   0.8281 |     28.728 |   1.0237 |     34.846 |     1.0
   43 |   0.8163 |     28.080 |   1.0028 |     32.987 |     1.0
   44 |   0.8011 |     27.607 |   1.0111 |     33.333 |     1.0
   45 |   0.7833 |     26.772 |   1.0056 |     32.955 |     1.1
   46 |   0.7619 |     26.135 |   1.0006 |     33.144 |     1.1
   47 |   0.7499 |     25.926 |   1.0204 |     33.522 |     1.1
   48 |   0.7369 |     25.223 |   1.0078 |     33.081 |     1.1
   49 |   0.7242 |     24.805 |   1.0125 |     32.577 |     1.2
   50 |   0.7046 |     23.739 |   1.0055 |     32.420 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,588,289

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5322 |     69.013 |   1.9909 |     58.727 |     0.1
    2 |   1.7581 |     49.753 |   1.5748 |     45.432 |     0.2
    3 |   1.5028 |     46.291 |   1.4594 |     45.432 |     0.2
    4 |   1.4394 |     46.291 |   1.4259 |     45.432 |     0.3
    5 |   1.4116 |     46.291 |   1.3993 |     45.432 |     0.4
    6 |   1.3817 |     45.890 |   1.3663 |     45.558 |     0.5
    7 |   1.3505 |     45.681 |   1.3307 |     45.211 |     0.5
    8 |   1.3244 |     45.181 |   1.3059 |     44.266 |     0.6
    9 |   1.2992 |     44.763 |   1.2822 |     44.077 |     0.7
   10 |   1.2759 |     44.109 |   1.2640 |     43.730 |     0.7
   11 |   1.2566 |     43.488 |   1.2507 |     42.376 |     0.8
   12 |   1.2428 |     43.159 |   1.2450 |     42.281 |     0.9
   13 |   1.2263 |     42.543 |   1.2287 |     41.430 |     1.0
   14 |   1.2137 |     42.307 |   1.2174 |     41.871 |     1.0
   15 |   1.2015 |     41.922 |   1.2105 |     40.706 |     1.1
   16 |   1.1841 |     41.318 |   1.1928 |     39.950 |     1.2
   17 |   1.1684 |     40.664 |   1.1860 |     40.706 |     1.3
   18 |   1.1537 |     40.307 |   1.1753 |     39.824 |     1.3
   19 |   1.1371 |     39.818 |   1.1763 |     40.107 |     1.4
   20 |   1.1225 |     38.894 |   1.1533 |     38.941 |     1.5
   21 |   1.1078 |     38.554 |   1.1459 |     38.437 |     1.6
   22 |   1.0888 |     37.817 |   1.1478 |     38.847 |     1.6
   23 |   1.0743 |     37.152 |   1.1407 |     38.343 |     1.7
   24 |   1.0575 |     36.878 |   1.1249 |     37.618 |     1.8
   25 |   1.0384 |     35.998 |   1.1099 |     37.587 |     1.9
   26 |   1.0189 |     35.581 |   1.1122 |     37.618 |     1.9
   27 |   0.9973 |     34.465 |   1.0906 |     36.610 |     2.0
   28 |   0.9820 |     33.998 |   1.0980 |     35.791 |     2.1
   29 |   0.9641 |     33.125 |   1.0902 |     36.326 |     2.2
   30 |   0.9384 |     32.047 |   1.0805 |     35.003 |     2.2
   31 |   0.9138 |     31.091 |   1.0762 |     34.909 |     2.3
   32 |   0.8927 |     30.295 |   1.0763 |     35.129 |     2.4
   33 |   0.8714 |     29.564 |   1.0688 |     34.751 |     2.5
   34 |   0.8477 |     28.783 |   1.0628 |     33.396 |     2.5
   35 |   0.8250 |     27.585 |   1.0642 |     33.144 |     2.6
   36 |   0.7975 |     26.541 |   1.0786 |     33.743 |     2.7
   37 |   0.7793 |     25.898 |   1.0712 |     32.861 |     2.8
   38 |   0.7580 |     24.547 |   1.0531 |     32.199 |     2.8
   39 |   0.7302 |     23.497 |   1.0603 |     32.357 |     2.9
   40 |   0.7001 |     22.448 |   1.0625 |     31.537 |     3.0
   41 |   0.6850 |     22.041 |   1.0669 |     31.979 |     3.1
   42 |   0.6613 |     21.228 |   1.0568 |     31.317 |     3.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 621,249

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2502 |     61.276 |   1.6288 |     45.432 |     0.0
    2 |   1.4890 |     46.313 |   1.4154 |     45.495 |     0.0
    3 |   1.3923 |     46.236 |   1.3609 |     44.928 |     0.1
    4 |   1.3490 |     45.527 |   1.3282 |     44.959 |     0.1
    5 |   1.3208 |     45.313 |   1.2990 |     44.392 |     0.1
    6 |   1.2956 |     44.895 |   1.2780 |     44.234 |     0.1
    7 |   1.2700 |     44.329 |   1.2653 |     43.510 |     0.1
    8 |   1.2491 |     44.170 |   1.2442 |     44.045 |     0.1
    9 |   1.2308 |     43.747 |   1.2207 |     42.848 |     0.2
   10 |   1.2064 |     42.686 |   1.2058 |     41.493 |     0.2
   11 |   1.1865 |     42.400 |   1.2006 |     41.840 |     0.2
   12 |   1.1713 |     41.609 |   1.1827 |     40.422 |     0.2
   13 |   1.1631 |     41.675 |   1.1816 |     42.250 |     0.2
   14 |   1.1567 |     41.384 |   1.1619 |     40.391 |     0.2
   15 |   1.1378 |     40.900 |   1.1493 |     40.013 |     0.3
   16 |   1.1233 |     40.076 |   1.1487 |     39.761 |     0.3
   17 |   1.1146 |     40.037 |   1.1361 |     39.981 |     0.3
   18 |   1.1092 |     39.878 |   1.1325 |     39.445 |     0.3
   19 |   1.1000 |     39.757 |   1.1242 |     39.256 |     0.3
   20 |   1.0884 |     39.136 |   1.1186 |     38.973 |     0.4
   21 |   1.0782 |     38.905 |   1.1086 |     38.406 |     0.4
   22 |   1.0698 |     38.664 |   1.0992 |     38.532 |     0.4
   23 |   1.0632 |     38.164 |   1.0978 |     38.784 |     0.4
   24 |   1.0558 |     38.103 |   1.1120 |     39.099 |     0.4
   25 |   1.0488 |     37.993 |   1.0879 |     37.996 |     0.4
   26 |   1.0381 |     37.334 |   1.0833 |     37.965 |     0.5
   27 |   1.0306 |     37.070 |   1.0762 |     38.154 |     0.5
   28 |   1.0229 |     36.850 |   1.0693 |     37.209 |     0.5
   29 |   1.0152 |     36.614 |   1.0644 |     36.830 |     0.5
   30 |   1.0053 |     36.284 |   1.0540 |     36.389 |     0.5
   31 |   0.9961 |     35.526 |   1.0446 |     36.421 |     0.6
   32 |   0.9839 |     35.125 |   1.0534 |     35.728 |     0.6
   33 |   0.9769 |     34.888 |   1.0388 |     35.885 |     0.6
   34 |   0.9700 |     34.658 |   1.0358 |     35.728 |     0.6
   35 |   0.9547 |     34.081 |   1.0245 |     34.751 |     0.6
   36 |   0.9507 |     33.998 |   1.0135 |     35.035 |     0.6
   37 |   0.9426 |     33.630 |   1.0200 |     34.751 |     0.7
   38 |   0.9252 |     32.685 |   1.0211 |     35.255 |     0.7
   39 |   0.9139 |     32.405 |   1.0189 |     35.066 |     0.7
   40 |   0.9083 |     32.322 |   1.0097 |     35.098 |     0.7
   41 |   0.9018 |     32.097 |   1.0160 |     35.224 |     0.7
   42 |   0.8926 |     31.635 |   1.0019 |     34.562 |     0.7
   43 |   0.8748 |     30.718 |   1.0097 |     34.562 |     0.8
   44 |   0.8681 |     30.454 |   0.9896 |     32.955 |     0.8
   45 |   0.8535 |     29.965 |   0.9883 |     32.892 |     0.8
   46 |   0.8489 |     29.937 |   0.9864 |     32.924 |     0.8
   47 |   0.8356 |     29.289 |   0.9773 |     32.325 |     0.8
   48 |   0.8183 |     28.421 |   0.9721 |     32.073 |     0.9
   49 |   0.8139 |     28.492 |   0.9651 |     31.727 |     0.9
   50 |   0.8064 |     27.899 |   0.9734 |     32.136 |     0.9
   51 |   0.7934 |     27.443 |   0.9735 |     32.325 |     0.9
   52 |   0.7850 |     27.382 |   0.9621 |     31.569 |     0.9
   53 |   0.7711 |     26.558 |   0.9594 |     31.569 |     0.9
   54 |   0.7638 |     26.272 |   0.9715 |     31.727 |     1.0
   55 |   0.7526 |     26.074 |   0.9561 |     31.096 |     1.0
   56 |   0.7593 |     26.355 |   0.9510 |     31.191 |     1.0
   57 |   0.7417 |     25.679 |   0.9555 |     30.781 |     1.0
   58 |   0.7219 |     24.695 |   0.9606 |     30.624 |     1.0
   59 |   0.7111 |     24.167 |   0.9462 |     30.466 |     1.0
   60 |   0.6986 |     23.887 |   0.9512 |     30.277 |     1.1
   61 |   0.7094 |     24.250 |   0.9505 |     30.120 |     1.1
   62 |   0.6879 |     23.486 |   0.9414 |     30.340 |     1.1
   63 |   0.6777 |     23.272 |   0.9523 |     30.151 |     1.1
   64 |   0.6662 |     22.832 |   0.9371 |     29.994 |     1.1
   65 |   0.6571 |     22.508 |   0.9529 |     30.403 |     1.2
   66 |   0.6486 |     21.997 |   0.9425 |     28.986 |     1.2
   67 |   0.6441 |     21.634 |   0.9319 |     28.922 |     1.2
   68 |   0.6325 |     21.398 |   0.9344 |     28.702 |     1.2
   69 |   0.6204 |     20.986 |   0.9322 |     28.607 |     1.2
   70 |   0.6187 |     20.931 |   0.9324 |     28.922 |     1.2
   71 |   0.5972 |     20.140 |   0.9403 |     29.112 |     1.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,126,977

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3811 |     64.183 |   1.8609 |     48.866 |     0.1
    2 |   1.6695 |     48.060 |   1.5187 |     45.274 |     0.1
    3 |   1.4643 |     46.126 |   1.4231 |     45.432 |     0.2
    4 |   1.4023 |     46.005 |   1.3809 |     44.959 |     0.2
    5 |   1.3681 |     45.879 |   1.3521 |     44.612 |     0.3
    6 |   1.3382 |     45.274 |   1.3302 |     44.707 |     0.4
    7 |   1.3163 |     45.021 |   1.3077 |     44.833 |     0.4
    8 |   1.2980 |     44.895 |   1.2950 |     44.423 |     0.5
    9 |   1.2828 |     44.554 |   1.2838 |     44.297 |     0.5
   10 |   1.2684 |     44.225 |   1.2696 |     43.604 |     0.6
   11 |   1.2570 |     44.060 |   1.2533 |     43.037 |     0.7
   12 |   1.2420 |     43.906 |   1.2414 |     42.880 |     0.7
   13 |   1.2303 |     43.659 |   1.2254 |     42.911 |     0.8
   14 |   1.2174 |     43.329 |   1.2177 |     42.439 |     0.8
   15 |   1.2065 |     42.692 |   1.2091 |     42.376 |     0.9
   16 |   1.1957 |     42.334 |   1.2006 |     41.367 |     1.0
   17 |   1.1869 |     42.032 |   1.1919 |     41.525 |     1.0
   18 |   1.1738 |     41.647 |   1.1862 |     41.399 |     1.1
   19 |   1.1658 |     41.241 |   1.1789 |     41.084 |     1.1
   20 |   1.1549 |     40.697 |   1.1634 |     40.548 |     1.2
   21 |   1.1436 |     40.340 |   1.1617 |     40.170 |     1.3
   22 |   1.1332 |     40.070 |   1.1487 |     39.792 |     1.3
   23 |   1.1235 |     39.669 |   1.1440 |     39.603 |     1.4
   24 |   1.1157 |     39.471 |   1.1356 |     39.509 |     1.4
   25 |   1.1058 |     39.285 |   1.1312 |     39.319 |     1.5
   26 |   1.0943 |     38.559 |   1.1210 |     38.406 |     1.6
   27 |   1.0890 |     38.554 |   1.1171 |     38.815 |     1.6
   28 |   1.0758 |     37.938 |   1.1009 |     37.681 |     1.7
   29 |   1.0666 |     37.680 |   1.1030 |     38.059 |     1.7
   30 |   1.0568 |     37.394 |   1.1024 |     38.059 |     1.8
   31 |   1.0457 |     36.960 |   1.0955 |     37.051 |     1.9
   32 |   1.0375 |     36.520 |   1.0868 |     36.736 |     1.9
   33 |   1.0291 |     36.174 |   1.0890 |     37.083 |     2.0
   34 |   1.0207 |     36.136 |   1.0694 |     37.051 |     2.0
   35 |   1.0099 |     35.339 |   1.0709 |     36.169 |     2.1
   36 |   1.0022 |     34.965 |   1.0644 |     35.980 |     2.2
   37 |   0.9933 |     34.850 |   1.0571 |     36.011 |     2.2
   38 |   0.9791 |     34.284 |   1.0496 |     35.129 |     2.3
   39 |   0.9718 |     34.053 |   1.0524 |     35.507 |     2.3
   40 |   0.9644 |     33.800 |   1.0384 |     34.972 |     2.4
   41 |   0.9513 |     32.921 |   1.0480 |     35.287 |     2.5
   42 |   0.9447 |     32.850 |   1.0346 |     35.318 |     2.5
   43 |   0.9361 |     32.289 |   1.0462 |     35.633 |     2.6
   44 |   0.9236 |     32.031 |   1.0277 |     35.003 |     2.6
   45 |   0.9131 |     31.712 |   1.0239 |     34.436 |     2.7
   46 |   0.9003 |     31.069 |   1.0143 |     34.089 |     2.8
   47 |   0.8944 |     30.959 |   1.0171 |     33.995 |     2.8
   48 |   0.8835 |     30.240 |   1.0123 |     33.806 |     2.9
   49 |   0.8748 |     30.229 |   1.0112 |     33.837 |     2.9
   50 |   0.8605 |     29.553 |   1.0059 |     33.333 |     3.0
   51 |   0.8481 |     29.185 |   0.9942 |     33.081 |     3.1
   52 |   0.8362 |     28.679 |   0.9925 |     32.924 |     3.1
   53 |   0.8265 |     28.036 |   0.9956 |     32.577 |     3.2
   54 |   0.8172 |     27.805 |   0.9934 |     32.199 |     3.2
   55 |   0.7996 |     27.058 |   0.9866 |     31.506 |     3.3
   56 |   0.7932 |     26.739 |   0.9785 |     31.285 |     3.4
   57 |   0.7813 |     26.256 |   0.9841 |     31.758 |     3.4
   58 |   0.7688 |     26.063 |   0.9751 |     30.907 |     3.5
   59 |   0.7504 |     25.442 |   0.9791 |     30.876 |     3.5
   60 |   0.7487 |     25.003 |   0.9752 |     30.624 |     3.6
   61 |   0.7289 |     24.492 |   0.9688 |     30.687 |     3.7
   62 |   0.7171 |     24.041 |   0.9737 |     30.718 |     3.7
   63 |   0.7130 |     23.772 |   0.9647 |     29.931 |     3.8
   64 |   0.6961 |     23.118 |   0.9760 |     31.033 |     3.8
   65 |   0.6810 |     22.442 |   0.9760 |     31.096 |     3.9
   66 |   0.6779 |     22.579 |   0.9720 |     30.183 |     4.0
   67 |   0.6579 |     21.821 |   0.9750 |     30.655 |     4.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 557,921

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3335 |     61.199 |   1.7656 |     47.889 |     0.0
    2 |   1.5752 |     47.110 |   1.4547 |     44.928 |     0.1
    3 |   1.4080 |     45.934 |   1.3722 |     44.644 |     0.1
    4 |   1.3488 |     44.972 |   1.3300 |     44.329 |     0.1
    5 |   1.3128 |     44.719 |   1.3021 |     43.856 |     0.2
    6 |   1.2839 |     44.181 |   1.2745 |     42.974 |     0.2
    7 |   1.2563 |     43.631 |   1.2549 |     42.754 |     0.2
    8 |   1.2345 |     43.043 |   1.2360 |     41.997 |     0.3
    9 |   1.2129 |     42.510 |   1.2216 |     41.903 |     0.3
   10 |   1.1929 |     41.686 |   1.2076 |     41.651 |     0.3
   11 |   1.1764 |     41.439 |   1.1927 |     40.800 |     0.4
   12 |   1.1553 |     40.741 |   1.1812 |     40.454 |     0.4
   13 |   1.1365 |     39.977 |   1.1718 |     40.580 |     0.4
   14 |   1.1146 |     39.158 |   1.1588 |     39.729 |     0.5
   15 |   1.0956 |     38.125 |   1.1412 |     38.878 |     0.5
   16 |   1.0748 |     37.696 |   1.1397 |     38.721 |     0.5
   17 |   1.0534 |     36.400 |   1.1269 |     38.941 |     0.6
   18 |   1.0346 |     35.614 |   1.1056 |     37.366 |     0.6
   19 |   1.0073 |     33.828 |   1.0855 |     36.232 |     0.6
   20 |   0.9851 |     33.278 |   1.0822 |     36.326 |     0.7
   21 |   0.9616 |     32.333 |   1.0750 |     36.137 |     0.7
   22 |   0.9359 |     31.168 |   1.0695 |     35.602 |     0.7
   23 |   0.9111 |     30.311 |   1.0487 |     34.688 |     0.8
   24 |   0.8907 |     29.437 |   1.0336 |     34.058 |     0.8
   25 |   0.8631 |     28.305 |   1.0312 |     33.302 |     0.8
   26 |   0.8441 |     27.712 |   1.0426 |     33.365 |     0.9
   27 |   0.8173 |     26.959 |   1.0156 |     32.829 |     0.9
   28 |   0.7915 |     25.756 |   1.0077 |     32.451 |     0.9
   29 |   0.7667 |     24.926 |   1.0064 |     31.979 |     1.0
   30 |   0.7415 |     24.063 |   1.0055 |     32.294 |     1.0
   31 |   0.7162 |     23.074 |   1.0063 |     31.537 |     1.0
   32 |   0.6954 |     22.579 |   1.0058 |     31.380 |     1.1
   33 |   0.6757 |     21.634 |   0.9889 |     30.781 |     1.1
   34 |   0.6484 |     20.870 |   0.9976 |     30.750 |     1.1
   35 |   0.6240 |     19.942 |   1.0174 |     30.435 |     1.2
   36 |   0.6036 |     19.150 |   1.0230 |     30.781 |     1.2
   37 |   0.5818 |     18.469 |   0.9908 |     29.647 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 966,337

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9974 |     54.841 |   1.4788 |     45.274 |     0.0
    2 |   1.3990 |     45.829 |   1.3465 |     45.054 |     0.1
    3 |   1.3176 |     45.049 |   1.2875 |     44.360 |     0.1
    4 |   1.2719 |     44.313 |   1.2603 |     43.541 |     0.2
    5 |   1.2435 |     43.659 |   1.2353 |     42.344 |     0.2
    6 |   1.2117 |     42.801 |   1.2055 |     41.525 |     0.2
    7 |   1.1834 |     41.834 |   1.1981 |     42.313 |     0.3
    8 |   1.1580 |     41.109 |   1.1794 |     41.115 |     0.3
    9 |   1.1273 |     40.241 |   1.1462 |     39.540 |     0.3
   10 |   1.0990 |     38.977 |   1.1279 |     39.130 |     0.4
   11 |   1.0680 |     37.587 |   1.1182 |     38.658 |     0.4
   12 |   1.0428 |     36.729 |   1.0874 |     37.461 |     0.5
   13 |   1.0073 |     34.740 |   1.0771 |     36.326 |     0.5
   14 |   0.9791 |     33.652 |   1.0676 |     35.822 |     0.5
   15 |   0.9477 |     32.674 |   1.0327 |     34.783 |     0.6
   16 |   0.9953 |     34.916 |   1.0514 |     35.192 |     0.6
   17 |   0.9293 |     32.086 |   1.0197 |     34.121 |     0.7
   18 |   0.8861 |     30.317 |   1.0004 |     33.554 |     0.7
   19 |   0.8476 |     28.613 |   0.9833 |     32.420 |     0.7
   20 |   0.8081 |     27.058 |   0.9878 |     32.861 |     0.8
   21 |   0.7746 |     25.745 |   0.9892 |     32.766 |     0.8
   22 |   0.7518 |     25.245 |   0.9587 |     31.727 |     0.9
   23 |   0.7085 |     23.865 |   0.9660 |     31.348 |     0.9
   24 |   0.6758 |     22.475 |   0.9576 |     31.285 |     0.9
   25 |   0.6428 |     21.068 |   0.9653 |     30.372 |     1.0
   26 |   0.6152 |     20.156 |   0.9498 |     30.372 |     1.0
   27 |   0.5768 |     18.832 |   0.9472 |     29.332 |     1.0
   28 |   0.5532 |     17.804 |   0.9565 |     29.773 |     1.1
   29 |   0.5286 |     16.875 |   0.9604 |     28.796 |     1.1
   30 |   0.5021 |     16.128 |   0.9678 |     28.954 |     1.2
   31 |   0.4835 |     15.447 |   0.9723 |     28.576 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 718,465

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1195 |     58.402 |   1.5367 |     45.432 |     0.0
    2 |   1.4265 |     46.071 |   1.3603 |     44.266 |     0.1
    3 |   1.3345 |     44.939 |   1.3170 |     44.171 |     0.1
    4 |   1.2952 |     44.615 |   1.2755 |     43.762 |     0.1
    5 |   1.2651 |     43.994 |   1.2603 |     43.289 |     0.2
    6 |   1.2381 |     43.400 |   1.2227 |     41.840 |     0.2
    7 |   1.2095 |     42.664 |   1.2146 |     42.439 |     0.2
    8 |   1.1874 |     41.999 |   1.1969 |     41.147 |     0.3
    9 |   1.1606 |     41.208 |   1.1733 |     40.989 |     0.3
   10 |   1.1370 |     40.444 |   1.1515 |     40.265 |     0.3
   11 |   1.1099 |     39.532 |   1.1414 |     40.107 |     0.4
   12 |   1.0814 |     38.400 |   1.1154 |     39.477 |     0.4
   13 |   1.0484 |     36.872 |   1.0922 |     37.429 |     0.4
   14 |   1.0202 |     35.806 |   1.0656 |     36.547 |     0.5
   15 |   0.9913 |     34.817 |   1.0567 |     35.948 |     0.5
   16 |   0.9649 |     33.564 |   1.0410 |     35.413 |     0.6
   17 |   0.9353 |     32.515 |   1.0260 |     34.184 |     0.6
   18 |   0.9004 |     30.937 |   1.0356 |     35.161 |     0.6
   19 |   0.8753 |     30.245 |   1.0140 |     33.396 |     0.7
   20 |   0.8389 |     28.723 |   0.9906 |     32.924 |     0.7
   21 |   0.8105 |     27.761 |   0.9913 |     32.766 |     0.7
   22 |   0.7749 |     26.261 |   0.9592 |     31.821 |     0.8
   23 |   0.7410 |     25.047 |   0.9473 |     31.537 |     0.8
   24 |   0.7074 |     23.508 |   0.9431 |     30.718 |     0.8
   25 |   0.6736 |     22.601 |   0.9420 |     29.490 |     0.9
   26 |   0.6472 |     21.403 |   0.9429 |     29.962 |     0.9
   27 |   0.6173 |     20.299 |   0.9290 |     29.679 |     0.9
   28 |   0.5975 |     19.398 |   0.9476 |     29.332 |     1.0
   29 |   0.5572 |     18.282 |   0.9470 |     29.112 |     1.0
   30 |   0.5274 |     17.095 |   0.9394 |     28.733 |     1.0
   31 |   0.5021 |     16.452 |   0.9617 |     28.765 |     1.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 733,153

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4118 |     65.150 |   1.8659 |     50.567 |     0.0
    2 |   1.6645 |     48.324 |   1.5116 |     45.432 |     0.1
    3 |   1.4599 |     46.159 |   1.4088 |     45.243 |     0.1
    4 |   1.3929 |     45.967 |   1.3634 |     45.022 |     0.2
    5 |   1.3568 |     45.247 |   1.3343 |     44.140 |     0.2
    6 |   1.3297 |     44.653 |   1.3125 |     43.573 |     0.2
    7 |   1.3079 |     44.395 |   1.2991 |     44.203 |     0.3
    8 |   1.2882 |     44.313 |   1.2750 |     43.951 |     0.3
    9 |   1.2728 |     44.269 |   1.2615 |     44.077 |     0.4
   10 |   1.2584 |     44.296 |   1.2507 |     43.006 |     0.4
   11 |   1.2447 |     43.675 |   1.2380 |     42.533 |     0.4
   12 |   1.2327 |     43.670 |   1.2319 |     42.848 |     0.5
   13 |   1.2208 |     43.329 |   1.2168 |     42.155 |     0.5
   14 |   1.2126 |     42.928 |   1.2060 |     41.493 |     0.6
   15 |   1.1978 |     42.131 |   1.1944 |     40.674 |     0.6
   16 |   1.1872 |     41.933 |   1.1894 |     41.399 |     0.6
   17 |   1.1770 |     41.746 |   1.1828 |     41.399 |     0.7
   18 |   1.1672 |     41.400 |   1.1698 |     40.769 |     0.7
   19 |   1.1563 |     41.109 |   1.1619 |     40.139 |     0.8
   20 |   1.1398 |     40.257 |   1.1541 |     39.824 |     0.8
   21 |   1.1331 |     40.340 |   1.1458 |     40.170 |     0.8
   22 |   1.1248 |     39.993 |   1.1515 |     39.792 |     0.9
   23 |   1.1128 |     39.658 |   1.1349 |     39.666 |     0.9
   24 |   1.1049 |     39.361 |   1.1346 |     39.603 |     1.0
   25 |   1.0936 |     38.889 |   1.1297 |     39.288 |     1.0
   26 |   1.0836 |     38.207 |   1.1222 |     38.626 |     1.0
   27 |   1.0936 |     38.900 |   1.1226 |     38.815 |     1.1
   28 |   1.0776 |     38.268 |   1.1172 |     38.784 |     1.1
   29 |   1.0837 |     38.312 |   1.1170 |     38.595 |     1.2
   30 |   1.0677 |     37.658 |   1.1092 |     39.036 |     1.2
   31 |   1.0575 |     37.438 |   1.0943 |     37.555 |     1.2
   32 |   1.0426 |     36.790 |   1.0952 |     37.965 |     1.3
   33 |   1.0314 |     36.163 |   1.0830 |     36.295 |     1.3
   34 |   1.0243 |     35.801 |   1.0866 |     36.673 |     1.4
   35 |   1.0177 |     35.520 |   1.0884 |     36.389 |     1.4
   36 |   1.0085 |     35.339 |   1.0718 |     36.200 |     1.4
   37 |   1.0010 |     34.877 |   1.0673 |     35.633 |     1.5
   38 |   0.9922 |     34.361 |   1.0620 |     35.728 |     1.5
   39 |   0.9814 |     34.015 |   1.0528 |     34.657 |     1.6
   40 |   0.9672 |     33.394 |   1.0520 |     35.665 |     1.6
   41 |   0.9597 |     33.108 |   1.0451 |     34.720 |     1.6
   42 |   0.9556 |     33.207 |   1.0376 |     34.247 |     1.7
   43 |   0.9395 |     32.438 |   1.0262 |     34.121 |     1.7
   44 |   0.9317 |     32.212 |   1.0238 |     34.247 |     1.8
   45 |   0.9214 |     31.701 |   1.0100 |     33.113 |     1.8
   46 |   0.9094 |     31.273 |   1.0065 |     33.018 |     1.8
   47 |   0.8975 |     30.992 |   1.0048 |     32.766 |     1.9
   48 |   0.8920 |     30.602 |   0.9982 |     32.987 |     1.9
   49 |   0.8802 |     30.014 |   0.9995 |     32.861 |     2.0
   50 |   0.8662 |     29.564 |   0.9925 |     32.136 |     2.0
   51 |   0.8573 |     29.305 |   0.9996 |     32.577 |     2.0
   52 |   0.8513 |     29.091 |   1.0243 |     33.239 |     2.1
   53 |   0.8574 |     29.531 |   0.9873 |     32.294 |     2.1
   54 |   0.8340 |     28.360 |   0.9766 |     31.790 |     2.2
   55 |   0.8148 |     27.871 |   0.9729 |     31.317 |     2.2
   56 |   0.7949 |     27.047 |   0.9729 |     32.073 |     2.2
   57 |   0.7947 |     26.838 |   0.9749 |     31.191 |     2.3
   58 |   0.7774 |     26.355 |   0.9679 |     31.285 |     2.3
   59 |   0.7592 |     25.580 |   0.9721 |     30.624 |     2.4
   60 |   0.7482 |     25.415 |   0.9672 |     30.655 |     2.4
   61 |   0.7363 |     24.843 |   0.9574 |     29.647 |     2.4
   62 |   0.7168 |     24.217 |   0.9753 |     31.222 |     2.5
   63 |   0.7083 |     23.854 |   0.9580 |     30.214 |     2.5
   64 |   0.6867 |     22.909 |   0.9480 |     29.395 |     2.6
   65 |   0.6785 |     22.338 |   0.9604 |     29.553 |     2.6
   66 |   0.6623 |     22.107 |   0.9626 |     29.710 |     2.6
   67 |   0.6468 |     21.403 |   0.9600 |     29.805 |     2.7
   68 |   0.6257 |     20.563 |   0.9549 |     28.828 |     2.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,606,785

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5083 |     67.909 |   1.9601 |     54.064 |     0.1
    2 |   1.7509 |     49.110 |   1.5820 |     45.432 |     0.2
    3 |   1.5133 |     46.291 |   1.4660 |     45.432 |     0.2
    4 |   1.4380 |     46.291 |   1.4158 |     45.432 |     0.3
    5 |   1.4022 |     46.362 |   1.3910 |     45.463 |     0.4
    6 |   1.3758 |     45.950 |   1.3599 |     44.991 |     0.5
    7 |   1.3458 |     45.373 |   1.3319 |     44.203 |     0.5
    8 |   1.3201 |     44.818 |   1.3009 |     43.888 |     0.6
    9 |   1.2959 |     44.411 |   1.2853 |     43.037 |     0.7
   10 |   1.2740 |     43.763 |   1.2619 |     43.069 |     0.8
   11 |   1.2456 |     43.060 |   1.2429 |     42.155 |     0.8
   12 |   1.2255 |     42.433 |   1.2248 |     41.525 |     0.9
   13 |   1.2052 |     42.147 |   1.2084 |     41.052 |     1.0
   14 |   1.1875 |     41.571 |   1.1979 |     40.958 |     1.1
   15 |   1.1686 |     40.785 |   1.1827 |     40.517 |     1.1
   16 |   1.1503 |     40.213 |   1.1731 |     40.202 |     1.2
   17 |   1.1319 |     39.669 |   1.1609 |     40.107 |     1.3
   18 |   1.1109 |     38.839 |   1.1531 |     39.698 |     1.4
   19 |   1.0945 |     38.142 |   1.1464 |     39.099 |     1.4
   20 |   1.0764 |     37.378 |   1.1333 |     38.658 |     1.5
   21 |   1.0564 |     36.520 |   1.1384 |     38.878 |     1.6
   22 |   1.0354 |     35.603 |   1.1234 |     37.303 |     1.7
   23 |   1.0166 |     34.888 |   1.1135 |     37.083 |     1.7
   24 |   0.9934 |     33.806 |   1.1121 |     37.870 |     1.8
   25 |   0.9713 |     33.097 |   1.0994 |     36.799 |     1.9
   26 |   0.9484 |     31.921 |   1.0843 |     35.854 |     2.0
   27 |   0.9209 |     30.959 |   1.0986 |     36.673 |     2.0
   28 |   0.8974 |     29.822 |   1.0801 |     35.035 |     2.1
   29 |   0.8647 |     28.206 |   1.0903 |     34.720 |     2.2
   30 |   0.8328 |     27.030 |   1.0785 |     33.932 |     2.3
   31 |   0.8017 |     25.865 |   1.0715 |     33.554 |     2.3
   32 |   0.7677 |     24.442 |   1.0673 |     33.333 |     2.4
   33 |   0.7472 |     24.030 |   1.0772 |     33.081 |     2.5
   34 |   0.7126 |     22.546 |   1.0719 |     32.861 |     2.6
   35 |   0.6879 |     21.871 |   1.0926 |     32.766 |     2.6
   36 |   0.6651 |     21.156 |   1.0872 |     32.199 |     2.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 421,345

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5555 |     68.876 |   1.9605 |     54.159 |     0.0
    2 |   1.7327 |     49.324 |   1.5487 |     45.432 |     0.1
    3 |   1.4892 |     46.329 |   1.4414 |     45.432 |     0.1
    4 |   1.4259 |     46.302 |   1.4057 |     45.432 |     0.1
    5 |   1.3956 |     46.186 |   1.3765 |     45.432 |     0.1
    6 |   1.3699 |     45.637 |   1.3525 |     45.085 |     0.2
    7 |   1.3463 |     45.532 |   1.3340 |     44.802 |     0.2
    8 |   1.3244 |     45.296 |   1.3073 |     44.928 |     0.2
    9 |   1.3048 |     45.109 |   1.2918 |     44.896 |     0.2
   10 |   1.2865 |     44.769 |   1.2729 |     43.919 |     0.3
   11 |   1.2698 |     44.466 |   1.2603 |     43.793 |     0.3
   12 |   1.2567 |     44.280 |   1.2542 |     43.352 |     0.3
   13 |   1.2463 |     43.670 |   1.2417 |     43.321 |     0.3
   14 |   1.2330 |     43.499 |   1.2357 |     43.069 |     0.4
   15 |   1.2231 |     43.307 |   1.2290 |     42.060 |     0.4
   16 |   1.2149 |     42.796 |   1.2194 |     42.596 |     0.4
   17 |   1.2063 |     42.664 |   1.2087 |     41.588 |     0.4
   18 |   1.1956 |     42.175 |   1.1987 |     41.588 |     0.5
   19 |   1.1883 |     41.988 |   1.1979 |     41.682 |     0.5
   20 |   1.1820 |     41.834 |   1.1899 |     40.706 |     0.5
   21 |   1.1769 |     41.845 |   1.1868 |     41.241 |     0.5
   22 |   1.1687 |     41.384 |   1.1763 |     40.296 |     0.6
   23 |   1.1639 |     41.340 |   1.1779 |     40.800 |     0.6
   24 |   1.1600 |     41.362 |   1.1759 |     40.517 |     0.6
   25 |   1.1539 |     40.834 |   1.1688 |     40.139 |     0.6
   26 |   1.1453 |     40.796 |   1.1687 |     40.139 |     0.7
   27 |   1.1404 |     40.664 |   1.1618 |     40.044 |     0.7
   28 |   1.1366 |     40.384 |   1.1645 |     40.737 |     0.7
   29 |   1.1336 |     40.471 |   1.1524 |     40.044 |     0.7
   30 |   1.1285 |     40.482 |   1.1555 |     40.044 |     0.8
   31 |   1.1236 |     40.125 |   1.1520 |     40.265 |     0.8
   32 |   1.1230 |     39.999 |   1.1505 |     40.422 |     0.8
   33 |   1.1175 |     39.922 |   1.1461 |     40.139 |     0.8
   34 |   1.1112 |     39.746 |   1.1425 |     39.477 |     0.9
   35 |   1.1137 |     39.944 |   1.1412 |     40.265 |     0.9
   36 |   1.1042 |     39.735 |   1.1381 |     39.918 |     0.9
   37 |   1.0980 |     39.515 |   1.1305 |     39.477 |     0.9
   38 |   1.0971 |     39.543 |   1.1242 |     39.603 |     1.0
   39 |   1.0896 |     39.318 |   1.1321 |     39.445 |     1.0
   40 |   1.0846 |     38.746 |   1.1254 |     39.414 |     1.0
   41 |   1.0808 |     38.730 |   1.1210 |     38.689 |     1.0
   42 |   1.0746 |     38.416 |   1.1178 |     38.847 |     1.1
   43 |   1.0700 |     38.262 |   1.1120 |     38.689 |     1.1
   44 |   1.0642 |     38.065 |   1.1092 |     38.122 |     1.1
   45 |   1.0609 |     38.279 |   1.0968 |     37.933 |     1.1
   46 |   1.0561 |     37.850 |   1.1014 |     38.500 |     1.2
   47 |   1.0519 |     37.751 |   1.0982 |     38.059 |     1.2
   48 |   1.0509 |     37.581 |   1.0969 |     37.870 |     1.2
   49 |   1.0424 |     37.312 |   1.0924 |     38.532 |     1.2
   50 |   1.0369 |     37.152 |   1.0909 |     38.469 |     1.3
   51 |   1.0339 |     36.988 |   1.0850 |     37.839 |     1.3
   52 |   1.0259 |     36.938 |   1.0878 |     37.492 |     1.3
   53 |   1.0202 |     36.312 |   1.0892 |     37.965 |     1.3
   54 |   1.0167 |     36.372 |   1.0741 |     36.547 |     1.4
   55 |   1.0139 |     36.257 |   1.0810 |     37.398 |     1.4
   56 |   1.0075 |     36.235 |   1.0782 |     37.492 |     1.4
   57 |   1.0016 |     35.861 |   1.0682 |     36.484 |     1.4
   58 |   0.9980 |     35.636 |   1.0675 |     36.957 |     1.5
   59 |   0.9941 |     35.636 |   1.0627 |     36.263 |     1.5
   60 |   0.9934 |     35.515 |   1.0675 |     36.862 |     1.5
   61 |   0.9876 |     35.092 |   1.0644 |     36.578 |     1.5
   62 |   0.9796 |     34.916 |   1.0620 |     36.641 |     1.6
   63 |   0.9766 |     34.746 |   1.0592 |     36.232 |     1.6
   64 |   0.9736 |     34.740 |   1.0538 |     35.885 |     1.6
   65 |   0.9665 |     34.289 |   1.0575 |     35.633 |     1.6
   66 |   0.9621 |     34.174 |   1.0433 |     35.885 |     1.7
   67 |   0.9592 |     34.092 |   1.0493 |     36.011 |     1.7
   68 |   0.9538 |     33.806 |   1.0484 |     36.232 |     1.7
   69 |   0.9533 |     33.756 |   1.0431 |     35.759 |     1.7
   70 |   0.9462 |     33.680 |   1.0460 |     35.287 |     1.8
   71 |   0.9449 |     33.504 |   1.0464 |     35.539 |     1.8
   72 |   0.9337 |     32.954 |   1.0367 |     35.035 |     1.8
   73 |   0.9330 |     33.125 |   1.0288 |     34.940 |     1.8
   74 |   0.9236 |     32.668 |   1.0318 |     35.287 |     1.9
   75 |   0.9247 |     32.745 |   1.0246 |     34.562 |     1.9
   76 |   0.9168 |     32.102 |   1.0245 |     35.035 |     1.9
   77 |   0.9106 |     31.916 |   1.0177 |     34.121 |     1.9
   78 |   0.9081 |     31.993 |   1.0181 |     34.625 |     2.0
   79 |   0.9003 |     31.652 |   1.0245 |     34.625 |     2.0
   80 |   0.8989 |     31.745 |   1.0142 |     35.003 |     2.0
   81 |   0.8856 |     31.207 |   1.0110 |     34.720 |     2.0
   82 |   0.8865 |     31.300 |   1.0144 |     33.711 |     2.1
   83 |   0.8800 |     30.641 |   1.0129 |     34.310 |     2.1
   84 |   0.8734 |     30.586 |   1.0124 |     33.837 |     2.1
   85 |   0.8747 |     30.432 |   1.0118 |     34.499 |     2.1
   86 |   0.8639 |     30.152 |   1.0013 |     33.680 |     2.2
   87 |   0.8562 |     29.921 |   1.0130 |     34.026 |     2.2
   88 |   0.8568 |     29.816 |   1.0077 |     33.869 |     2.2
   89 |   0.8481 |     29.514 |   1.0140 |     33.995 |     2.2
   90 |   0.8421 |     29.113 |   1.0104 |     34.247 |     2.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 904,033

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2218 |     60.386 |   1.6474 |     48.299 |     0.0
    2 |   1.5009 |     46.511 |   1.4261 |     45.432 |     0.1
    3 |   1.4070 |     46.318 |   1.3788 |     44.928 |     0.1
    4 |   1.3711 |     45.934 |   1.3475 |     44.518 |     0.1
    5 |   1.3407 |     45.747 |   1.3335 |     45.306 |     0.2
    6 |   1.3200 |     45.653 |   1.3110 |     44.770 |     0.2
    7 |   1.3008 |     44.944 |   1.3036 |     44.581 |     0.2
    8 |   1.2858 |     44.747 |   1.2823 |     44.644 |     0.3
    9 |   1.2720 |     44.527 |   1.2754 |     43.258 |     0.3
   10 |   1.2558 |     44.038 |   1.2551 |     43.037 |     0.3
   11 |   1.2362 |     43.615 |   1.2399 |     42.407 |     0.4
   12 |   1.2183 |     43.148 |   1.2174 |     42.218 |     0.4
   13 |   1.1968 |     42.708 |   1.2155 |     41.903 |     0.4
   14 |   1.1800 |     42.180 |   1.1968 |     40.989 |     0.5
   15 |   1.1636 |     41.219 |   1.1795 |     40.611 |     0.5
   16 |   1.1346 |     39.999 |   1.1444 |     39.067 |     0.5
   17 |   1.1019 |     38.504 |   1.1369 |     38.059 |     0.6
   18 |   1.0660 |     37.076 |   1.1219 |     37.524 |     0.6
   19 |   1.0327 |     35.883 |   1.0925 |     36.106 |     0.6
   20 |   0.9976 |     34.355 |   1.0562 |     35.665 |     0.7
   21 |   0.9590 |     32.938 |   1.0579 |     35.444 |     0.7
   22 |   0.9320 |     32.058 |   1.0382 |     34.877 |     0.7
   23 |   0.8940 |     30.311 |   1.0276 |     33.396 |     0.8
   24 |   0.8578 |     28.976 |   1.0227 |     34.026 |     0.8
   25 |   0.8152 |     27.113 |   1.0089 |     33.050 |     0.9
   26 |   0.7805 |     25.865 |   1.0034 |     32.672 |     0.9
   27 |   0.7424 |     24.552 |   0.9902 |     32.010 |     0.9
   28 |   0.7088 |     23.090 |   0.9787 |     30.277 |     1.0
   29 |   0.6761 |     21.980 |   0.9863 |     31.191 |     1.0
   30 |   0.6417 |     20.623 |   0.9949 |     30.844 |     1.0
   31 |   0.6116 |     19.651 |   1.0081 |     31.033 |     1.1
   32 |   0.5835 |     18.788 |   1.0017 |     29.742 |     1.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,179,681

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3261 |     61.672 |   1.7680 |     48.141 |     0.1
    2 |   1.5899 |     47.252 |   1.4661 |     45.054 |     0.1
    3 |   1.4277 |     46.126 |   1.3904 |     44.518 |     0.2
    4 |   1.3703 |     45.598 |   1.3467 |     44.108 |     0.2
    5 |   1.3332 |     45.021 |   1.3158 |     44.014 |     0.3
    6 |   1.3017 |     44.675 |   1.2959 |     43.730 |     0.4
    7 |   1.2783 |     44.115 |   1.2656 |     43.132 |     0.4
    8 |   1.2533 |     43.307 |   1.2500 |     42.691 |     0.5
    9 |   1.2323 |     43.049 |   1.2330 |     42.376 |     0.5
   10 |   1.2094 |     42.477 |   1.2130 |     41.115 |     0.6
   11 |   1.1870 |     41.461 |   1.1968 |     41.273 |     0.7
   12 |   1.1614 |     40.559 |   1.1698 |     39.761 |     0.7
   13 |   1.1360 |     39.378 |   1.1565 |     39.445 |     0.8
   14 |   1.1067 |     38.032 |   1.1406 |     38.595 |     0.9
   15 |   1.0785 |     36.999 |   1.1257 |     38.311 |     0.9
   16 |   1.0484 |     36.015 |   1.1041 |     37.177 |     1.0
   17 |   1.0194 |     35.081 |   1.0983 |     36.578 |     1.0
   18 |   0.9868 |     33.553 |   1.0854 |     35.696 |     1.1
   19 |   0.9553 |     31.888 |   1.0541 |     34.909 |     1.2
   20 |   0.9133 |     30.454 |   1.0401 |     34.089 |     1.2
   21 |   0.8787 |     29.014 |   1.0312 |     33.774 |     1.3
   22 |   0.8386 |     27.421 |   1.0210 |     33.050 |     1.3
   23 |   0.8038 |     26.250 |   1.0125 |     33.333 |     1.4
   24 |   0.7659 |     24.986 |   0.9947 |     31.916 |     1.5
   25 |   0.7327 |     23.656 |   0.9942 |     31.443 |     1.5
   26 |   0.6914 |     22.393 |   0.9812 |     29.553 |     1.6
   27 |   0.6567 |     21.030 |   0.9960 |     30.592 |     1.6
   28 |   0.6232 |     19.640 |   1.0028 |     30.340 |     1.7
   29 |   0.5972 |     18.969 |   1.0004 |     30.025 |     1.8
   30 |   0.5717 |     17.689 |   0.9942 |     28.765 |     1.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 456,993

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5453 |     68.095 |   1.9701 |     52.962 |     0.0
    2 |   1.7394 |     49.379 |   1.5528 |     45.432 |     0.1
    3 |   1.4902 |     46.307 |   1.4401 |     45.432 |     0.1
    4 |   1.4243 |     46.263 |   1.4002 |     45.432 |     0.1
    5 |   1.3906 |     46.115 |   1.3697 |     44.928 |     0.1
    6 |   1.3584 |     45.730 |   1.3371 |     45.180 |     0.2
    7 |   1.3352 |     45.543 |   1.3152 |     44.297 |     0.2
    8 |   1.3127 |     44.983 |   1.2972 |     44.171 |     0.2
    9 |   1.2930 |     44.571 |   1.2802 |     43.951 |     0.2
   10 |   1.2739 |     44.477 |   1.2662 |     43.825 |     0.3
   11 |   1.2603 |     44.186 |   1.2561 |     43.321 |     0.3
   12 |   1.2467 |     44.010 |   1.2427 |     43.100 |     0.3
   13 |   1.2346 |     43.527 |   1.2302 |     43.132 |     0.4
   14 |   1.2221 |     43.148 |   1.2207 |     42.124 |     0.4
   15 |   1.2131 |     43.109 |   1.2125 |     42.533 |     0.4
   16 |   1.2011 |     42.796 |   1.2000 |     41.840 |     0.4
   17 |   1.1903 |     42.301 |   1.1937 |     41.556 |     0.5
   18 |   1.1783 |     41.774 |   1.1807 |     41.084 |     0.5
   19 |   1.1717 |     41.647 |   1.1812 |     40.989 |     0.5
   20 |   1.1633 |     41.444 |   1.1725 |     40.737 |     0.5
   21 |   1.1563 |     41.191 |   1.1635 |     40.958 |     0.6
   22 |   1.1451 |     40.697 |   1.1624 |     40.674 |     0.6
   23 |   1.1403 |     40.840 |   1.1539 |     40.517 |     0.6
   24 |   1.1322 |     40.488 |   1.1545 |     40.233 |     0.7
   25 |   1.1255 |     40.136 |   1.1478 |     40.170 |     0.7
   26 |   1.1164 |     39.856 |   1.1404 |     40.107 |     0.7
   27 |   1.1107 |     39.801 |   1.1379 |     40.580 |     0.7
   28 |   1.1026 |     39.647 |   1.1363 |     40.076 |     0.8
   29 |   1.0978 |     39.400 |   1.1319 |     39.319 |     0.8
   30 |   1.0919 |     39.103 |   1.1239 |     39.950 |     0.8
   31 |   1.0829 |     38.664 |   1.1169 |     39.256 |     0.8
   32 |   1.0765 |     38.268 |   1.1187 |     39.099 |     0.9
   33 |   1.0708 |     38.350 |   1.1121 |     39.288 |     0.9
   34 |   1.0614 |     38.081 |   1.1021 |     38.469 |     0.9
   35 |   1.0566 |     37.955 |   1.1037 |     38.784 |     1.0
   36 |   1.0514 |     37.565 |   1.0996 |     38.437 |     1.0
   37 |   1.0470 |     37.185 |   1.1104 |     38.815 |     1.0
   38 |   1.0458 |     37.174 |   1.0930 |     38.028 |     1.0
   39 |   1.0338 |     36.696 |   1.0935 |     36.862 |     1.1
   40 |   1.0286 |     36.499 |   1.0828 |     36.641 |     1.1
   41 |   1.0174 |     36.048 |   1.0748 |     37.083 |     1.1
   42 |   1.0093 |     35.707 |   1.0693 |     36.200 |     1.1
   43 |   0.9999 |     35.323 |   1.0667 |     36.389 |     1.2
   44 |   0.9934 |     34.894 |   1.0690 |     36.610 |     1.2
   45 |   0.9866 |     34.823 |   1.0584 |     35.980 |     1.2
   46 |   0.9777 |     34.476 |   1.0649 |     35.885 |     1.3
   47 |   0.9709 |     34.224 |   1.0566 |     35.570 |     1.3
   48 |   0.9639 |     33.756 |   1.0520 |     35.570 |     1.3
   49 |   0.9543 |     33.317 |   1.0448 |     35.035 |     1.3
   50 |   0.9511 |     33.432 |   1.0469 |     35.444 |     1.4
   51 |   0.9435 |     32.883 |   1.0446 |     35.350 |     1.4
   52 |   0.9346 |     32.498 |   1.0432 |     34.751 |     1.4
   53 |   0.9351 |     32.712 |   1.0285 |     34.436 |     1.4
   54 |   0.9214 |     32.179 |   1.0302 |     34.310 |     1.5
   55 |   0.9117 |     31.932 |   1.0319 |     34.531 |     1.5
   56 |   0.9083 |     31.696 |   1.0284 |     34.436 |     1.5
   57 |   0.9021 |     31.377 |   1.0325 |     33.995 |     1.6
   58 |   0.8940 |     30.992 |   1.0352 |     33.995 |     1.6
   59 |   0.8877 |     30.509 |   1.0294 |     33.869 |     1.6
   60 |   0.8781 |     30.388 |   1.0171 |     33.239 |     1.6
   61 |   0.8751 |     30.207 |   1.0198 |     33.428 |     1.7
   62 |   0.8667 |     30.157 |   1.0318 |     33.302 |     1.7
   63 |   0.8590 |     29.250 |   1.0224 |     33.396 |     1.7
   64 |   0.8496 |     29.212 |   1.0215 |     33.869 |     1.8
   65 |   0.8457 |     28.959 |   1.0115 |     33.239 |     1.8
   66 |   0.8468 |     28.932 |   1.0270 |     33.491 |     1.8
   67 |   0.8304 |     28.316 |   1.0191 |     32.955 |     1.8
   68 |   0.8186 |     27.860 |   1.0064 |     32.798 |     1.9
   69 |   0.8074 |     27.300 |   1.0183 |     32.546 |     1.9
   70 |   0.8062 |     27.344 |   1.0234 |     32.735 |     1.9
   71 |   0.7959 |     27.052 |   1.0217 |     31.979 |     1.9
   72 |   0.7848 |     26.294 |   1.0188 |     33.144 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 736,289

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2309 |     61.089 |   1.6176 |     48.299 |     0.0
    2 |   1.4854 |     46.626 |   1.4140 |     45.432 |     0.1
    3 |   1.4028 |     46.280 |   1.3763 |     45.432 |     0.1
    4 |   1.3680 |     46.005 |   1.3467 |     44.549 |     0.1
    5 |   1.3329 |     45.516 |   1.3123 |     44.802 |     0.1
    6 |   1.3089 |     45.390 |   1.2979 |     44.928 |     0.2
    7 |   1.2906 |     45.093 |   1.2785 |     44.739 |     0.2
    8 |   1.2722 |     44.796 |   1.2627 |     43.919 |     0.2
    9 |   1.2570 |     44.637 |   1.2503 |     44.108 |     0.2
   10 |   1.2427 |     44.455 |   1.2328 |     43.951 |     0.3
   11 |   1.2284 |     43.983 |   1.2253 |     42.754 |     0.3
   12 |   1.2181 |     43.549 |   1.2123 |     43.415 |     0.3
   13 |   1.2060 |     43.268 |   1.2074 |     42.029 |     0.3
   14 |   1.1940 |     42.724 |   1.2035 |     42.029 |     0.4
   15 |   1.1834 |     42.230 |   1.1988 |     41.745 |     0.4
   16 |   1.1762 |     42.252 |   1.1985 |     41.021 |     0.4
   17 |   1.1683 |     41.966 |   1.1759 |     40.832 |     0.4
   18 |   1.1584 |     41.829 |   1.1725 |     40.769 |     0.5
   19 |   1.1460 |     41.142 |   1.1585 |     40.517 |     0.5
   20 |   1.1391 |     41.224 |   1.1570 |     40.328 |     0.5
   21 |   1.1306 |     40.801 |   1.1511 |     40.958 |     0.5
   22 |   1.1193 |     40.449 |   1.1477 |     40.359 |     0.6
   23 |   1.1131 |     40.142 |   1.1339 |     40.391 |     0.6
   24 |   1.1047 |     40.158 |   1.1230 |     39.319 |     0.6
   25 |   1.1000 |     39.944 |   1.1274 |     40.013 |     0.6
   26 |   1.0888 |     39.603 |   1.1196 |     39.382 |     0.7
   27 |   1.0835 |     39.339 |   1.1163 |     39.572 |     0.7
   28 |   1.0724 |     38.999 |   1.1116 |     39.067 |     0.7
   29 |   1.0629 |     38.383 |   1.0999 |     39.225 |     0.7
   30 |   1.0531 |     38.345 |   1.1051 |     39.099 |     0.8
   31 |   1.0447 |     38.191 |   1.0971 |     38.280 |     0.8
   32 |   1.0367 |     37.603 |   1.0905 |     38.217 |     0.8
   33 |   1.0266 |     37.394 |   1.0784 |     37.839 |     0.9
   34 |   1.0186 |     36.691 |   1.0799 |     37.776 |     0.9
   35 |   1.0064 |     36.504 |   1.0659 |     36.862 |     0.9
   36 |   1.0032 |     36.515 |   1.0588 |     36.704 |     0.9
   37 |   0.9924 |     35.856 |   1.0587 |     36.957 |     1.0
   38 |   0.9837 |     35.421 |   1.0494 |     36.389 |     1.0
   39 |   0.9862 |     35.443 |   1.0489 |     36.295 |     1.0
   40 |   0.9731 |     34.998 |   1.0320 |     35.287 |     1.0
   41 |   0.9635 |     34.361 |   1.0361 |     35.696 |     1.1
   42 |   0.9555 |     34.213 |   1.0220 |     35.476 |     1.1
   43 |   0.9472 |     33.811 |   1.0235 |     35.602 |     1.1
   44 |   0.9372 |     33.388 |   1.0165 |     35.003 |     1.1
   45 |   0.9299 |     33.020 |   1.0230 |     35.003 |     1.2
   46 |   0.9162 |     32.624 |   1.0128 |     35.066 |     1.2
   47 |   0.9126 |     32.559 |   1.0071 |     35.098 |     1.2
   48 |   0.9071 |     32.377 |   1.0032 |     34.310 |     1.2
   49 |   0.8994 |     31.602 |   1.0042 |     35.066 |     1.3
   50 |   0.8914 |     31.454 |   1.0054 |     34.058 |     1.3
   51 |   0.8792 |     31.229 |   1.0001 |     34.531 |     1.3
   52 |   0.8693 |     30.349 |   1.0008 |     34.405 |     1.3
   53 |   0.8619 |     30.481 |   1.0054 |     33.806 |     1.4
   54 |   0.8604 |     30.047 |   0.9946 |     33.239 |     1.4
   55 |   0.8486 |     30.009 |   0.9956 |     33.806 |     1.4
   56 |   0.8433 |     29.542 |   0.9946 |     33.806 |     1.4
   57 |   0.8316 |     28.959 |   0.9919 |     33.239 |     1.5
   58 |   0.8186 |     28.756 |   0.9909 |     32.861 |     1.5
   59 |   0.8140 |     28.564 |   0.9915 |     33.239 |     1.5
   60 |   0.8127 |     28.327 |   0.9900 |     33.459 |     1.5
   61 |   0.8008 |     27.959 |   0.9825 |     32.766 |     1.6
   62 |   0.7885 |     27.404 |   0.9852 |     33.270 |     1.6
   63 |   0.7865 |     27.481 |   0.9806 |     32.703 |     1.6
   64 |   0.7756 |     26.772 |   0.9840 |     32.514 |     1.7
   65 |   0.7702 |     26.975 |   0.9898 |     33.113 |     1.7
   66 |   0.7644 |     26.481 |   0.9794 |     32.546 |     1.7
   67 |   0.7534 |     25.772 |   0.9900 |     32.829 |     1.7
   68 |   0.7402 |     25.541 |   0.9860 |     32.451 |     1.8
   69 |   0.7368 |     25.668 |   0.9758 |     31.569 |     1.8
   70 |   0.7236 |     25.085 |   0.9731 |     31.285 |     1.8
   71 |   0.7241 |     24.997 |   0.9861 |     31.632 |     1.8
   72 |   0.7111 |     24.486 |   0.9724 |     30.309 |     1.9
   73 |   0.7042 |     24.288 |   0.9808 |     31.664 |     1.9
   74 |   0.6967 |     23.827 |   0.9682 |     30.907 |     1.9
   75 |   0.6974 |     23.651 |   0.9808 |     30.844 |     1.9
   76 |   0.6824 |     23.233 |   0.9856 |     32.042 |     2.0
   77 |   0.6788 |     23.233 |   0.9846 |     31.632 |     2.0
   78 |   0.6701 |     23.173 |   0.9776 |     30.561 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 423,713

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4101 |     65.117 |   1.8765 |     47.889 |     0.0
    2 |   1.6490 |     48.209 |   1.4966 |     45.463 |     0.1
    3 |   1.4501 |     46.230 |   1.4079 |     45.432 |     0.1
    4 |   1.3997 |     46.109 |   1.3822 |     44.991 |     0.1
    5 |   1.3700 |     45.796 |   1.3520 |     44.707 |     0.1
    6 |   1.3414 |     45.494 |   1.3366 |     44.392 |     0.2
    7 |   1.3129 |     45.390 |   1.2974 |     44.486 |     0.2
    8 |   1.2890 |     44.868 |   1.2817 |     43.919 |     0.2
    9 |   1.2671 |     44.076 |   1.2547 |     43.856 |     0.3
   10 |   1.2438 |     43.736 |   1.2351 |     42.250 |     0.3
   11 |   1.2242 |     43.065 |   1.2168 |     41.588 |     0.3
   12 |   1.2031 |     42.554 |   1.2049 |     40.706 |     0.3
   13 |   1.1867 |     41.807 |   1.1936 |     40.265 |     0.4
   14 |   1.1709 |     41.576 |   1.1829 |     40.044 |     0.4
   15 |   1.1539 |     40.669 |   1.1692 |     40.202 |     0.4
   16 |   1.1417 |     40.114 |   1.1548 |     39.824 |     0.4
   17 |   1.1244 |     39.598 |   1.1517 |     39.193 |     0.5
   18 |   1.1105 |     39.120 |   1.1344 |     38.406 |     0.5
   19 |   1.0934 |     38.142 |   1.1204 |     38.185 |     0.5
   20 |   1.0768 |     38.098 |   1.1138 |     37.083 |     0.6
   21 |   1.0582 |     36.900 |   1.1043 |     36.957 |     0.6
   22 |   1.0429 |     36.114 |   1.0881 |     36.452 |     0.6
   23 |   1.0236 |     35.504 |   1.0824 |     35.917 |     0.6
   24 |   1.0049 |     34.526 |   1.0851 |     36.452 |     0.7
   25 |   0.9945 |     34.136 |   1.0664 |     35.350 |     0.7
   26 |   0.9748 |     33.454 |   1.0634 |     35.255 |     0.7
   27 |   0.9546 |     32.597 |   1.0464 |     34.877 |     0.7
   28 |   0.9427 |     32.168 |   1.0503 |     34.877 |     0.8
   29 |   0.9277 |     31.844 |   1.0353 |     34.436 |     0.8
   30 |   0.9107 |     30.800 |   1.0276 |     34.247 |     0.8
   31 |   0.8901 |     30.097 |   1.0145 |     33.806 |     0.9
   32 |   0.8745 |     29.443 |   1.0160 |     33.050 |     0.9
   33 |   0.8554 |     28.998 |   1.0098 |     33.144 |     0.9
   34 |   0.8387 |     28.009 |   1.0005 |     33.270 |     0.9
   35 |   0.8202 |     27.322 |   1.0065 |     32.294 |     1.0
   36 |   0.8022 |     26.673 |   0.9975 |     32.546 |     1.0
   37 |   0.7854 |     26.129 |   0.9828 |     31.474 |     1.0
   38 |   0.7652 |     25.310 |   0.9940 |     31.601 |     1.0
   39 |   0.7549 |     25.184 |   0.9755 |     31.443 |     1.1
   40 |   0.7352 |     24.173 |   0.9620 |     30.214 |     1.1
   41 |   0.7096 |     23.211 |   0.9685 |     30.687 |     1.1
   42 |   0.6925 |     22.629 |   0.9673 |     29.836 |     1.2
   43 |   0.6769 |     21.986 |   0.9678 |     29.616 |     1.2
   44 |   0.6920 |     22.810 |   0.9627 |     30.372 |     1.2
   45 |   0.6550 |     21.277 |   0.9558 |     29.742 |     1.2
   46 |   0.6265 |     20.475 |   0.9703 |     29.868 |     1.3
   47 |   0.6114 |     19.766 |   0.9784 |     29.773 |     1.3
   48 |   0.5901 |     18.760 |   0.9757 |     28.922 |     1.3
   49 |   0.5757 |     18.650 |   0.9954 |     29.899 |     1.4
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,985,153

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1681 |     60.023 |   1.5861 |     45.432 |     0.1
    2 |   1.4762 |     46.351 |   1.4276 |     45.432 |     0.2
    3 |   1.4103 |     46.483 |   1.3960 |     45.463 |     0.2
    4 |   1.3819 |     46.044 |   1.3703 |     45.180 |     0.3
    5 |   1.3547 |     45.879 |   1.3380 |     45.400 |     0.4
    6 |   1.3253 |     45.532 |   1.3115 |     44.833 |     0.5
    7 |   1.3014 |     45.043 |   1.2965 |     44.423 |     0.5
    8 |   1.2848 |     45.148 |   1.2750 |     44.014 |     0.6
    9 |   1.2706 |     44.488 |   1.2671 |     43.289 |     0.7
   10 |   1.2607 |     44.054 |   1.2586 |     43.384 |     0.8
   11 |   1.2496 |     43.928 |   1.2474 |     42.502 |     0.8
   12 |   1.2397 |     43.807 |   1.2362 |     43.258 |     0.9
   13 |   1.2241 |     43.593 |   1.2232 |     42.502 |     1.0
   14 |   1.2070 |     42.521 |   1.2043 |     40.989 |     1.1
   15 |   1.1887 |     41.966 |   1.1980 |     41.084 |     1.1
   16 |   1.1702 |     41.598 |   1.1847 |     40.989 |     1.2
   17 |   1.1541 |     40.895 |   1.1699 |     40.202 |     1.3
   18 |   1.1311 |     40.373 |   1.1557 |     39.698 |     1.4
   19 |   1.1194 |     40.120 |   1.1446 |     39.887 |     1.5
   20 |   1.0977 |     38.784 |   1.1289 |     39.162 |     1.5
   21 |   1.0735 |     37.922 |   1.1287 |     39.445 |     1.6
   22 |   1.0536 |     37.290 |   1.0973 |     37.461 |     1.7
   23 |   1.0330 |     36.438 |   1.0898 |     37.429 |     1.8
   24 |   1.0056 |     35.152 |   1.0805 |     36.484 |     1.8
   25 |   1.0012 |     34.691 |   1.1004 |     38.469 |     1.9
   26 |   0.9862 |     34.680 |   1.0544 |     36.547 |     2.0
   27 |   0.9431 |     32.729 |   1.0417 |     35.476 |     2.1
   28 |   0.9146 |     31.707 |   1.0312 |     34.783 |     2.1
   29 |   0.8905 |     30.745 |   1.0190 |     35.035 |     2.2
   30 |   0.8612 |     29.223 |   1.0038 |     33.270 |     2.3
   31 |   0.8405 |     28.311 |   0.9976 |     33.018 |     2.4
   32 |   0.8089 |     27.311 |   1.0095 |     33.522 |     2.4
   33 |   0.7908 |     26.613 |   0.9912 |     32.388 |     2.5
   34 |   0.7465 |     24.854 |   0.9732 |     31.474 |     2.6
   35 |   0.7238 |     23.970 |   0.9723 |     31.317 |     2.7
   36 |   0.6880 |     22.612 |   0.9831 |     30.781 |     2.8
   37 |   0.6582 |     21.717 |   0.9620 |     30.277 |     2.8
   38 |   0.6236 |     20.101 |   0.9983 |     31.727 |     2.9
   39 |   0.6287 |     20.706 |   0.9877 |     30.970 |     3.0
   40 |   0.5748 |     18.321 |   0.9635 |     29.962 |     3.1
   41 |   0.5413 |     17.348 |   0.9626 |     29.080 |     3.1
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 753,345

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1649 |     59.188 |   1.5547 |     45.432 |     0.0
    2 |   1.4551 |     46.384 |   1.3954 |     45.432 |     0.1
    3 |   1.3682 |     46.016 |   1.3410 |     45.180 |     0.1
    4 |   1.3255 |     45.274 |   1.3037 |     44.108 |     0.1
    5 |   1.2994 |     44.703 |   1.2794 |     44.203 |     0.1
    6 |   1.2756 |     44.576 |   1.2655 |     43.919 |     0.2
    7 |   1.2553 |     44.054 |   1.2423 |     43.573 |     0.2
    8 |   1.2331 |     43.725 |   1.2294 |     43.478 |     0.2
    9 |   1.2117 |     43.494 |   1.2047 |     42.155 |     0.2
   10 |   1.1874 |     42.505 |   1.1875 |     41.052 |     0.3
   11 |   1.1631 |     41.351 |   1.1690 |     40.737 |     0.3
   12 |   1.1385 |     40.411 |   1.1554 |     40.485 |     0.3
   13 |   1.1313 |     40.439 |   1.1448 |     39.666 |     0.3
   14 |   1.1067 |     39.224 |   1.1294 |     39.666 |     0.4
   15 |   1.0832 |     38.422 |   1.1176 |     38.532 |     0.4
   16 |   1.0660 |     37.609 |   1.1100 |     37.870 |     0.4
   17 |   1.0517 |     37.367 |   1.1045 |     37.807 |     0.4
   18 |   1.0304 |     36.548 |   1.0865 |     38.248 |     0.5
   19 |   1.0122 |     35.608 |   1.0733 |     36.767 |     0.5
   20 |   0.9995 |     35.443 |   1.0658 |     36.736 |     0.5
   21 |   0.9776 |     34.262 |   1.0636 |     35.539 |     0.6
   22 |   0.9614 |     33.652 |   1.0377 |     35.444 |     0.6
   23 |   0.9355 |     32.712 |   1.0323 |     34.657 |     0.6
   24 |   0.9134 |     31.674 |   1.0327 |     34.846 |     0.6
   25 |   0.8923 |     30.448 |   1.0147 |     34.310 |     0.7
   26 |   0.8732 |     29.877 |   1.0184 |     34.121 |     0.7
   27 |   0.8534 |     29.283 |   1.0047 |     33.459 |     0.7
   28 |   0.8326 |     28.481 |   0.9949 |     32.892 |     0.7
   29 |   0.8116 |     27.745 |   0.9904 |     32.640 |     0.8
   30 |   0.7863 |     26.750 |   1.0296 |     33.270 |     0.8
   31 |   0.8296 |     28.591 |   0.9755 |     31.758 |     0.8
   32 |   0.7655 |     26.217 |   0.9759 |     31.790 |     0.8
   33 |   0.7358 |     25.113 |   0.9709 |     31.947 |     0.9
   34 |   0.7223 |     24.486 |   0.9755 |     31.159 |     0.9
   35 |   0.7033 |     23.788 |   0.9735 |     30.498 |     0.9
   36 |   0.6850 |     23.195 |   0.9784 |     30.844 |     0.9
   37 |   0.6669 |     22.299 |   0.9782 |     30.592 |     1.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 388,065

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3959 |     63.573 |   1.8206 |     47.858 |     0.0
    2 |   1.6086 |     47.692 |   1.4621 |     45.274 |     0.1
    3 |   1.4166 |     45.802 |   1.3667 |     44.865 |     0.1
    4 |   1.3528 |     44.944 |   1.3252 |     43.825 |     0.1
    5 |   1.3170 |     44.587 |   1.2991 |     43.352 |     0.1
    6 |   1.2923 |     44.109 |   1.2764 |     43.132 |     0.2
    7 |   1.2717 |     44.021 |   1.2625 |     43.006 |     0.2
    8 |   1.2546 |     43.637 |   1.2417 |     42.911 |     0.2
    9 |   1.2350 |     43.065 |   1.2256 |     42.187 |     0.2
   10 |   1.2179 |     42.746 |   1.2131 |     41.367 |     0.3
   11 |   1.1960 |     42.060 |   1.2018 |     41.493 |     0.3
   12 |   1.1798 |     41.417 |   1.1899 |     40.674 |     0.3
   13 |   1.1588 |     40.944 |   1.1675 |     40.076 |     0.3
   14 |   1.1366 |     39.862 |   1.1662 |     40.202 |     0.4
   15 |   1.1139 |     39.114 |   1.1434 |     39.193 |     0.4
   16 |   1.0894 |     37.867 |   1.1323 |     39.162 |     0.4
   17 |   1.0702 |     37.169 |   1.1117 |     37.933 |     0.4
   18 |   1.0409 |     35.905 |   1.1013 |     37.744 |     0.5
   19 |   1.0156 |     34.987 |   1.0905 |     37.713 |     0.5
   20 |   0.9941 |     34.284 |   1.0720 |     36.515 |     0.5
   21 |   0.9675 |     33.163 |   1.0633 |     36.232 |     0.5
   22 |   0.9432 |     32.207 |   1.0585 |     35.161 |     0.6
   23 |   0.9126 |     30.476 |   1.0270 |     33.995 |     0.6
   24 |   0.8814 |     29.547 |   1.0249 |     33.995 |     0.6
   25 |   0.8582 |     28.706 |   1.0166 |     33.144 |     0.6
   26 |   0.8329 |     28.009 |   1.0132 |     33.113 |     0.7
   27 |   0.8014 |     26.464 |   1.0084 |     32.136 |     0.7
   28 |   0.7727 |     25.140 |   0.9967 |     31.853 |     0.7
   29 |   0.7415 |     24.283 |   0.9988 |     31.916 |     0.8
   30 |   0.7204 |     23.217 |   0.9873 |     31.191 |     0.8
   31 |   0.6879 |     22.013 |   0.9788 |     30.435 |     0.8
   32 |   0.6586 |     21.211 |   0.9863 |     30.750 |     0.8
   33 |   0.6378 |     20.398 |   0.9722 |     29.773 |     0.9
   34 |   0.6088 |     19.216 |   0.9729 |     29.931 |     0.9
   35 |   0.5884 |     18.733 |   0.9840 |     29.994 |     0.9
   36 |   0.5713 |     18.145 |   0.9874 |     30.025 |     0.9
   37 |   0.5507 |     17.062 |   0.9961 |     29.175 |     1.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 2,020,033

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1337 |     58.825 |   1.5465 |     45.432 |     0.1
    2 |   1.4580 |     46.302 |   1.4075 |     45.432 |     0.2
    3 |   1.3945 |     46.412 |   1.3768 |     45.148 |     0.2
    4 |   1.3660 |     45.769 |   1.3486 |     44.612 |     0.3
    5 |   1.3370 |     45.406 |   1.3232 |     45.022 |     0.4
    6 |   1.3176 |     45.252 |   1.3083 |     45.148 |     0.5
    7 |   1.2961 |     44.994 |   1.2844 |     44.266 |     0.6
    8 |   1.2779 |     44.675 |   1.2724 |     44.644 |     0.7
    9 |   1.2580 |     44.362 |   1.2496 |     43.919 |     0.7
   10 |   1.2386 |     44.076 |   1.2333 |     42.911 |     0.8
   11 |   1.2230 |     43.527 |   1.2174 |     42.344 |     0.9
   12 |   1.2061 |     42.774 |   1.2073 |     41.304 |     1.0
   13 |   1.1891 |     42.334 |   1.2014 |     41.651 |     1.1
   14 |   1.1758 |     42.175 |   1.1765 |     40.170 |     1.1
   15 |   1.1614 |     41.554 |   1.1741 |     40.926 |     1.2
   16 |   1.1446 |     40.911 |   1.1594 |     40.107 |     1.3
   17 |   1.1302 |     40.395 |   1.1499 |     39.981 |     1.4
   18 |   1.1127 |     40.125 |   1.1431 |     39.792 |     1.5
   19 |   1.0952 |     39.378 |   1.1220 |     38.815 |     1.5
   20 |   1.0809 |     38.763 |   1.1277 |     39.509 |     1.6
   21 |   1.0704 |     38.614 |   1.1103 |     38.815 |     1.7
   22 |   1.0576 |     37.817 |   1.1092 |     39.004 |     1.8
   23 |   1.0414 |     37.097 |   1.0977 |     38.059 |     1.9
   24 |   1.0291 |     36.597 |   1.0917 |     38.185 |     1.9
   25 |   1.0115 |     35.823 |   1.0888 |     38.374 |     2.0
   26 |   0.9991 |     35.037 |   1.0736 |     36.704 |     2.1
   27 |   0.9840 |     34.828 |   1.0699 |     36.925 |     2.2
   28 |   0.9580 |     33.800 |   1.0586 |     35.791 |     2.3
   29 |   0.9389 |     32.729 |   1.0483 |     35.539 |     2.3
   30 |   0.9198 |     32.119 |   1.0464 |     35.696 |     2.4
   31 |   0.8985 |     31.113 |   1.0473 |     36.169 |     2.5
   32 |   0.8818 |     30.613 |   1.0362 |     35.129 |     2.6
   33 |   0.8755 |     30.503 |   1.0323 |     34.657 |     2.7
   34 |   0.8472 |     29.278 |   1.0317 |     34.657 |     2.8
   35 |   0.8167 |     27.976 |   1.0178 |     33.837 |     2.8
   36 |   0.7981 |     27.294 |   1.0077 |     33.428 |     2.9
   37 |   0.7729 |     26.519 |   1.0028 |     32.640 |     3.0
   38 |   0.7565 |     25.926 |   1.0183 |     33.113 |     3.1
   39 |   0.7360 |     25.085 |   1.0097 |     32.766 |     3.2
   40 |   0.7173 |     24.453 |   0.9965 |     32.420 |     3.2
   41 |   0.6937 |     23.601 |   0.9954 |     31.632 |     3.3
   42 |   0.6720 |     22.871 |   0.9928 |     30.529 |     3.4
   43 |   0.6516 |     21.783 |   1.0031 |     31.222 |     3.5
   44 |   0.6351 |     21.486 |   1.0005 |     31.601 |     3.6
   45 |   0.6142 |     20.359 |   1.0117 |     30.624 |     3.6
   46 |   0.5881 |     19.563 |   1.0056 |     29.773 |     3.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 557,921

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3499 |     60.655 |   1.7483 |     47.858 |     0.0
    2 |   1.5591 |     47.285 |   1.4424 |     45.274 |     0.1
    3 |   1.4093 |     45.983 |   1.3742 |     44.802 |     0.1
    4 |   1.3534 |     45.532 |   1.3364 |     44.833 |     0.1
    5 |   1.3186 |     44.648 |   1.3015 |     43.069 |     0.2
    6 |   1.2908 |     44.164 |   1.2848 |     43.226 |     0.2
    7 |   1.2684 |     43.950 |   1.2674 |     42.943 |     0.2
    8 |   1.2475 |     43.516 |   1.2436 |     42.533 |     0.3
    9 |   1.2240 |     42.779 |   1.2267 |     42.313 |     0.3
   10 |   1.2019 |     42.142 |   1.2164 |     41.619 |     0.3
   11 |   1.1795 |     41.059 |   1.1961 |     40.643 |     0.4
   12 |   1.1537 |     39.878 |   1.1741 |     40.548 |     0.4
   13 |   1.1269 |     39.076 |   1.1544 |     39.351 |     0.4
   14 |   1.0994 |     37.911 |   1.1378 |     37.996 |     0.5
   15 |   1.0743 |     36.674 |   1.1226 |     37.965 |     0.5
   16 |   1.0412 |     35.284 |   1.1036 |     36.515 |     0.5
   17 |   1.0114 |     34.169 |   1.0831 |     35.602 |     0.6
   18 |   0.9765 |     32.877 |   1.0677 |     34.909 |     0.6
   19 |   0.9374 |     31.278 |   1.0607 |     34.625 |     0.7
   20 |   0.9085 |     30.262 |   1.0339 |     33.932 |     0.7
   21 |   0.8744 |     28.690 |   1.0135 |     33.365 |     0.7
   22 |   0.8379 |     27.520 |   1.0239 |     33.333 |     0.8
   23 |   0.8066 |     26.234 |   1.0097 |     33.176 |     0.8
   24 |   0.7702 |     24.668 |   0.9908 |     32.672 |     0.8
   25 |   0.7405 |     23.810 |   0.9848 |     31.537 |     0.9
   26 |   0.7028 |     22.074 |   0.9713 |     31.317 |     0.9
   27 |   0.6699 |     21.107 |   0.9820 |     30.907 |     0.9
   28 |   0.6432 |     20.096 |   0.9710 |     30.655 |     1.0
   29 |   0.6132 |     19.205 |   0.9694 |     30.214 |     1.0
   30 |   0.5835 |     18.112 |   0.9669 |     29.490 |     1.0
   31 |   0.5514 |     17.222 |   1.0027 |     29.805 |     1.1
   32 |   0.5235 |     16.007 |   0.9903 |     29.868 |     1.1
   33 |   0.4973 |     15.139 |   0.9942 |     29.332 |     1.1
   34 |   0.4743 |     14.216 |   1.0078 |     29.049 |     1.2
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 717,441

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3760 |     62.826 |   1.7750 |     47.952 |     0.0
    2 |   1.5830 |     47.489 |   1.4587 |     45.274 |     0.1
    3 |   1.4157 |     45.890 |   1.3765 |     45.117 |     0.1
    4 |   1.3607 |     45.593 |   1.3393 |     44.581 |     0.2
    5 |   1.3240 |     45.214 |   1.3023 |     44.077 |     0.2
    6 |   1.2958 |     44.626 |   1.2833 |     43.415 |     0.2
    7 |   1.2703 |     43.856 |   1.2592 |     43.100 |     0.3
    8 |   1.2483 |     43.791 |   1.2409 |     42.565 |     0.3
    9 |   1.2304 |     43.065 |   1.2206 |     42.281 |     0.4
   10 |   1.2108 |     42.433 |   1.2107 |     41.084 |     0.4
   11 |   1.1944 |     42.016 |   1.1989 |     40.611 |     0.4
   12 |   1.1793 |     41.598 |   1.1821 |     40.706 |     0.5
   13 |   1.1659 |     40.994 |   1.1714 |     40.359 |     0.5
   14 |   1.1509 |     40.400 |   1.1581 |     39.225 |     0.6
   15 |   1.1374 |     40.054 |   1.1516 |     39.351 |     0.6
   16 |   1.1255 |     39.785 |   1.1455 |     39.036 |     0.6
   17 |   1.1134 |     39.180 |   1.1297 |     38.437 |     0.7
   18 |   1.0999 |     38.669 |   1.1212 |     37.965 |     0.7
   19 |   1.0886 |     38.361 |   1.1174 |     38.595 |     0.8
   20 |   1.0782 |     38.131 |   1.1086 |     37.524 |     0.8
   21 |   1.0628 |     37.218 |   1.0957 |     37.177 |     0.8
   22 |   1.0543 |     37.202 |   1.0915 |     36.830 |     0.9
   23 |   1.0421 |     36.471 |   1.0759 |     35.822 |     0.9
   24 |   1.0256 |     35.856 |   1.0711 |     36.263 |     0.9
   25 |   1.0130 |     35.328 |   1.0815 |     37.114 |     1.0
   26 |   1.0051 |     35.202 |   1.0546 |     36.011 |     1.0
   27 |   0.9901 |     34.520 |   1.0489 |     35.665 |     1.1
   28 |   0.9830 |     34.174 |   1.0413 |     35.066 |     1.1
   29 |   0.9663 |     33.712 |   1.0426 |     34.909 |     1.1
   30 |   0.9522 |     33.322 |   1.0301 |     34.373 |     1.2
   31 |   0.9431 |     32.811 |   1.0209 |     34.436 |     1.2
   32 |   0.9333 |     32.284 |   1.0309 |     35.035 |     1.3
   33 |   0.9219 |     31.712 |   1.0087 |     34.058 |     1.3
   34 |   0.9045 |     31.152 |   1.0073 |     33.900 |     1.3
   35 |   0.8872 |     30.756 |   0.9968 |     33.239 |     1.4
   36 |   0.8793 |     30.306 |   0.9922 |     32.703 |     1.4
   37 |   0.8660 |     29.514 |   0.9883 |     32.577 |     1.5
   38 |   0.8535 |     29.207 |   0.9925 |     33.050 |     1.5
   39 |   0.8412 |     28.597 |   0.9853 |     32.955 |     1.5
   40 |   0.8298 |     28.162 |   0.9781 |     32.420 |     1.6
   41 |   0.8106 |     27.509 |   0.9802 |     31.664 |     1.6
   42 |   0.7924 |     26.783 |   0.9623 |     31.254 |     1.7
   43 |   0.7804 |     26.377 |   0.9646 |     30.970 |     1.7
   44 |   0.7694 |     25.684 |   0.9663 |     31.002 |     1.7
   45 |   0.7547 |     25.256 |   0.9538 |     29.931 |     1.8
   46 |   0.7284 |     24.107 |   0.9616 |     31.065 |     1.8
   47 |   0.7161 |     23.695 |   0.9521 |     30.088 |     1.9
   48 |   0.6929 |     22.722 |   0.9537 |     29.521 |     1.9
   49 |   0.6786 |     22.244 |   0.9595 |     29.616 |     1.9
   50 |   0.6646 |     21.684 |   0.9552 |     30.246 |     2.0
   51 |   0.6520 |     21.332 |   0.9531 |     30.183 |     2.0
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 639,073

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1852 |     59.963 |   1.5906 |     45.432 |     0.0
    2 |   1.4674 |     46.362 |   1.4020 |     45.432 |     0.0
    3 |   1.3815 |     45.813 |   1.3626 |     45.810 |     0.1
    4 |   1.3412 |     46.066 |   1.3163 |     45.211 |     0.1
    5 |   1.3099 |     45.648 |   1.2967 |     44.770 |     0.1
    6 |   1.2888 |     44.873 |   1.2780 |     44.518 |     0.1
    7 |   1.2633 |     44.379 |   1.2558 |     44.234 |     0.1
    8 |   1.2388 |     43.939 |   1.2320 |     43.100 |     0.1
    9 |   1.2150 |     43.225 |   1.2097 |     41.462 |     0.2
   10 |   1.1947 |     42.510 |   1.2021 |     41.367 |     0.2
   11 |   1.1760 |     41.807 |   1.1837 |     40.643 |     0.2
   12 |   1.1534 |     40.845 |   1.1663 |     41.399 |     0.2
   13 |   1.1323 |     40.356 |   1.1518 |     39.477 |     0.2
   14 |   1.1095 |     39.477 |   1.1428 |     39.792 |     0.3
   15 |   1.0890 |     38.691 |   1.1391 |     39.729 |     0.3
   16 |   1.0664 |     37.773 |   1.1135 |     37.965 |     0.3
   17 |   1.0413 |     36.773 |   1.1116 |     38.406 |     0.3
   18 |   1.0214 |     36.202 |   1.0964 |     37.807 |     0.3
   19 |   1.0011 |     35.196 |   1.0906 |     37.555 |     0.3
   20 |   0.9844 |     34.729 |   1.0995 |     36.862 |     0.4
   21 |   0.9574 |     33.537 |   1.0738 |     35.917 |     0.4
   22 |   0.9375 |     32.454 |   1.0794 |     36.641 |     0.4
   23 |   0.9081 |     31.443 |   1.0644 |     35.413 |     0.4
   24 |   0.8874 |     30.240 |   1.0604 |     34.814 |     0.4
   25 |   0.8571 |     29.289 |   1.0387 |     34.688 |     0.5
   26 |   0.8361 |     28.558 |   1.0336 |     33.270 |     0.5
   27 |   0.8094 |     27.261 |   1.0297 |     33.176 |     0.5
   28 |   0.7818 |     26.629 |   1.0240 |     33.428 |     0.5
   29 |   0.7653 |     25.580 |   1.0233 |     32.357 |     0.5
   30 |   0.7541 |     25.459 |   1.0182 |     32.105 |     0.5
   31 |   0.7221 |     24.162 |   1.0107 |     32.168 |     0.6
   32 |   0.6990 |     23.239 |   1.0044 |     31.033 |     0.6
   33 |   0.6801 |     22.788 |   0.9949 |     30.561 |     0.6
   34 |   0.6656 |     21.893 |   1.0048 |     31.159 |     0.6
   35 |   0.6456 |     21.579 |   1.0002 |     31.159 |     0.6
   36 |   0.6224 |     20.673 |   1.0107 |     30.435 |     0.7
   37 |   0.6014 |     19.640 |   1.0010 |     30.120 |     0.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 771,937

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2489 |     61.419 |   1.6113 |     45.432 |     0.0
    2 |   1.4834 |     46.445 |   1.4209 |     45.432 |     0.1
    3 |   1.4027 |     46.313 |   1.3820 |     45.432 |     0.1
    4 |   1.3600 |     45.945 |   1.3396 |     45.684 |     0.1
    5 |   1.3265 |     45.412 |   1.3069 |     44.203 |     0.1
    6 |   1.3047 |     44.884 |   1.2933 |     44.455 |     0.2
    7 |   1.2881 |     44.752 |   1.2766 |     44.549 |     0.2
    8 |   1.2718 |     44.439 |   1.2662 |     43.888 |     0.2
    9 |   1.2600 |     44.560 |   1.2699 |     43.321 |     0.3
   10 |   1.2461 |     44.148 |   1.2410 |     43.069 |     0.3
   11 |   1.2321 |     43.999 |   1.2331 |     43.762 |     0.3
   12 |   1.2170 |     43.433 |   1.2190 |     42.880 |     0.3
   13 |   1.2060 |     43.093 |   1.2171 |     42.470 |     0.4
   14 |   1.1970 |     42.867 |   1.2021 |     42.155 |     0.4
   15 |   1.1841 |     42.312 |   1.1952 |     41.682 |     0.4
   16 |   1.1734 |     42.307 |   1.1848 |     41.241 |     0.4
   17 |   1.1685 |     42.032 |   1.1806 |     41.682 |     0.5
   18 |   1.1629 |     41.856 |   1.1835 |     41.021 |     0.5
   19 |   1.1519 |     41.603 |   1.1742 |     40.580 |     0.5
   20 |   1.1415 |     41.065 |   1.1657 |     40.737 |     0.6
   21 |   1.1342 |     41.081 |   1.1566 |     40.737 |     0.6
   22 |   1.1255 |     40.796 |   1.1610 |     40.674 |     0.6
   23 |   1.1192 |     40.609 |   1.1415 |     39.761 |     0.6
   24 |   1.1043 |     40.142 |   1.1328 |     39.193 |     0.7
   25 |   1.0969 |     39.598 |   1.1342 |     40.202 |     0.7
   26 |   1.0910 |     39.383 |   1.1286 |     38.784 |     0.7
   27 |   1.0826 |     39.367 |   1.1170 |     39.193 |     0.8
   28 |   1.0759 |     38.905 |   1.1184 |     38.028 |     0.8
   29 |   1.0673 |     38.427 |   1.1184 |     39.382 |     0.8
   30 |   1.0573 |     38.235 |   1.1014 |     38.185 |     0.8
   31 |   1.0521 |     37.911 |   1.0937 |     38.343 |     0.9
   32 |   1.0408 |     37.477 |   1.0888 |     38.059 |     0.9
   33 |   1.0354 |     37.477 |   1.0839 |     37.902 |     0.9
   34 |   1.0211 |     36.537 |   1.0740 |     37.240 |     1.0
   35 |   1.0141 |     36.575 |   1.0719 |     37.020 |     1.0
   36 |   1.0027 |     35.993 |   1.0709 |     36.988 |     1.0
   37 |   0.9967 |     35.592 |   1.0593 |     36.547 |     1.0
   38 |   0.9888 |     35.279 |   1.0564 |     36.389 |     1.1
   39 |   0.9834 |     35.015 |   1.0872 |     37.965 |     1.1
   40 |   0.9812 |     35.290 |   1.0494 |     35.791 |     1.1
   41 |   0.9689 |     34.669 |   1.0470 |     36.389 |     1.1
   42 |   0.9703 |     34.443 |   1.0497 |     35.318 |     1.2
   43 |   0.9560 |     34.180 |   1.0369 |     35.696 |     1.2
   44 |   0.9460 |     33.564 |   1.0307 |     34.373 |     1.2
   45 |   0.9355 |     33.218 |   1.0295 |     34.846 |     1.3
   46 |   0.9315 |     32.998 |   1.0233 |     34.688 |     1.3
   47 |   0.9207 |     32.284 |   1.0212 |     33.806 |     1.3
   48 |   0.9136 |     32.179 |   1.0292 |     34.783 |     1.3
   49 |   0.9059 |     31.685 |   1.0284 |     34.310 |     1.4
   50 |   0.8944 |     31.624 |   1.0212 |     34.814 |     1.4
   51 |   0.8912 |     31.438 |   1.0193 |     34.657 |     1.4
   52 |   0.8806 |     30.855 |   1.0150 |     33.869 |     1.5
   53 |   0.8712 |     30.476 |   1.0054 |     33.491 |     1.5
   54 |   0.8666 |     30.273 |   1.0025 |     33.680 |     1.5
   55 |   0.8660 |     30.179 |   1.0081 |     34.089 |     1.5
   56 |   0.8543 |     29.641 |   1.0071 |     33.585 |     1.6
   57 |   0.8420 |     29.146 |   1.0089 |     34.751 |     1.6
   58 |   0.8356 |     29.086 |   0.9941 |     34.216 |     1.6
   59 |   0.8234 |     28.635 |   0.9811 |     32.955 |     1.7
   60 |   0.8172 |     28.206 |   0.9881 |     33.018 |     1.7
   61 |   0.8115 |     28.300 |   0.9945 |     33.365 |     1.7
   62 |   0.8020 |     28.107 |   0.9868 |     33.207 |     1.7
   63 |   0.7999 |     27.882 |   0.9825 |     32.577 |     1.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,126,977

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4494 |     64.853 |   1.9157 |     48.960 |     0.1
    2 |   1.6800 |     48.115 |   1.5208 |     45.432 |     0.1
    3 |   1.4580 |     46.313 |   1.4173 |     45.432 |     0.2
    4 |   1.3885 |     46.153 |   1.3657 |     44.360 |     0.2
    5 |   1.3554 |     45.769 |   1.3360 |     44.770 |     0.3
    6 |   1.3307 |     45.395 |   1.3191 |     44.297 |     0.3
    7 |   1.3130 |     45.445 |   1.3081 |     44.865 |     0.4
    8 |   1.2952 |     44.598 |   1.2829 |     43.667 |     0.5
    9 |   1.2756 |     44.214 |   1.2656 |     43.384 |     0.5
   10 |   1.2577 |     44.076 |   1.2499 |     43.195 |     0.6
   11 |   1.2433 |     43.994 |   1.2376 |     43.037 |     0.6
   12 |   1.2297 |     43.813 |   1.2288 |     42.974 |     0.7
   13 |   1.2124 |     43.225 |   1.2117 |     42.155 |     0.7
   14 |   1.1990 |     42.571 |   1.2030 |     41.147 |     0.8
   15 |   1.1866 |     42.153 |   1.2003 |     41.241 |     0.9
   16 |   1.1722 |     41.790 |   1.1830 |     40.485 |     0.9
   17 |   1.1556 |     40.867 |   1.1695 |     40.296 |     1.0
   18 |   1.1438 |     40.373 |   1.1593 |     40.044 |     1.0
   19 |   1.1300 |     40.010 |   1.1520 |     39.540 |     1.1
   20 |   1.1165 |     39.570 |   1.1502 |     39.666 |     1.1
   21 |   1.1048 |     38.933 |   1.1383 |     39.477 |     1.2
   22 |   1.0929 |     38.647 |   1.1251 |     38.689 |     1.2
   23 |   1.0817 |     38.246 |   1.1206 |     37.744 |     1.3
   24 |   1.0684 |     37.537 |   1.1122 |     37.650 |     1.4
   25 |   1.0541 |     37.196 |   1.0988 |     37.335 |     1.4
   26 |   1.0350 |     36.191 |   1.0962 |     37.083 |     1.5
   27 |   1.0232 |     35.548 |   1.0810 |     35.381 |     1.5
   28 |   1.0063 |     34.823 |   1.0780 |     35.791 |     1.6
   29 |   0.9870 |     34.075 |   1.0732 |     35.381 |     1.6
   30 |   0.9800 |     33.850 |   1.0593 |     34.688 |     1.7
   31 |   0.9653 |     33.300 |   1.0627 |     34.657 |     1.8
   32 |   0.9517 |     32.762 |   1.0473 |     35.035 |     1.8
   33 |   0.9359 |     32.179 |   1.0518 |     34.720 |     1.9
   34 |   0.9228 |     31.476 |   1.0285 |     34.279 |     1.9
   35 |   0.9054 |     30.800 |   1.0353 |     33.806 |     2.0
   36 |   0.8913 |     30.289 |   1.0381 |     34.310 |     2.0
   37 |   0.8794 |     29.679 |   1.0205 |     33.239 |     2.1
   38 |   0.8675 |     29.305 |   1.0353 |     34.751 |     2.2
   39 |   0.8528 |     28.613 |   1.0100 |     33.302 |     2.2
   40 |   0.8331 |     27.937 |   1.0154 |     33.050 |     2.3
   41 |   0.8219 |     27.327 |   1.0233 |     33.491 |     2.3
   42 |   0.8050 |     26.866 |   1.0059 |     32.766 |     2.4
   43 |   0.7860 |     25.843 |   1.0066 |     32.924 |     2.4
   44 |   0.7677 |     25.245 |   1.0011 |     32.609 |     2.5
   45 |   0.7456 |     24.404 |   0.9953 |     31.979 |     2.6
   46 |   0.7311 |     23.926 |   0.9989 |     31.853 |     2.6
   47 |   0.7145 |     23.547 |   0.9887 |     30.592 |     2.7
   48 |   0.7970 |     27.025 |   1.0006 |     31.979 |     2.7
   49 |   0.7848 |     26.256 |   0.9827 |     31.632 |     2.8
   50 |   0.7087 |     23.288 |   0.9616 |     30.876 |     2.8
   51 |   0.6718 |     21.645 |   0.9588 |     30.466 |     2.9
   52 |   0.6482 |     20.865 |   0.9671 |     30.214 |     3.0
   53 |   0.6237 |     19.914 |   0.9657 |     30.120 |     3.0
   54 |   0.6050 |     19.425 |   0.9555 |     29.301 |     3.1
   55 |   0.5841 |     18.491 |   0.9712 |     30.057 |     3.1
   56 |   0.5645 |     17.777 |   0.9577 |     29.742 |     3.2
   57 |   0.5857 |     18.991 |   0.9893 |     29.899 |     3.2
   58 |   0.5465 |     17.244 |   0.9684 |     29.458 |     3.3
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,248,097

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3068 |     61.782 |   1.7163 |     47.952 |     0.1
    2 |   1.5401 |     46.708 |   1.4302 |     44.991 |     0.1
    3 |   1.3951 |     45.934 |   1.3547 |     45.022 |     0.2
    4 |   1.3379 |     44.977 |   1.3217 |     43.856 |     0.2
    5 |   1.3057 |     44.318 |   1.2896 |     43.667 |     0.3
    6 |   1.2819 |     43.867 |   1.2709 |     42.344 |     0.4
    7 |   1.2617 |     43.780 |   1.2599 |     42.817 |     0.4
    8 |   1.2405 |     43.093 |   1.2381 |     41.462 |     0.5
    9 |   1.2204 |     42.422 |   1.2179 |     41.336 |     0.6
   10 |   1.2001 |     41.653 |   1.2065 |     40.643 |     0.6
   11 |   1.1751 |     40.812 |   1.1833 |     39.603 |     0.7
   12 |   1.1512 |     39.862 |   1.1708 |     39.509 |     0.7
   13 |   1.1211 |     38.713 |   1.1461 |     38.469 |     0.8
   14 |   1.0908 |     37.795 |   1.1291 |     38.028 |     0.9
   15 |   1.0537 |     35.718 |   1.1169 |     38.028 |     0.9
   16 |   1.0225 |     34.548 |   1.0939 |     36.263 |     1.0
   17 |   0.9861 |     33.251 |   1.0698 |     35.507 |     1.1
   18 |   0.9447 |     31.591 |   1.0537 |     34.877 |     1.1
   19 |   0.8988 |     30.058 |   1.0264 |     34.058 |     1.2
   20 |   0.8553 |     28.410 |   1.0273 |     33.428 |     1.2
   21 |   0.8144 |     26.712 |   1.0050 |     32.325 |     1.3
   22 |   0.7785 |     25.409 |   0.9904 |     32.388 |     1.4
   23 |   0.7338 |     23.948 |   0.9771 |     30.813 |     1.4
   24 |   0.6985 |     22.448 |   0.9833 |     31.191 |     1.5
   25 |   0.6541 |     20.815 |   0.9710 |     30.435 |     1.5
   26 |   0.6096 |     19.183 |   0.9735 |     29.868 |     1.6
   27 |   0.5859 |     18.381 |   0.9876 |     29.364 |     1.7
   28 |   0.5426 |     16.766 |   0.9926 |     30.057 |     1.7
   29 |   0.5105 |     15.804 |   0.9955 |     28.922 |     1.8
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 555,553

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5128 |     67.469 |   1.9630 |     57.593 |     0.0
    2 |   1.7242 |     48.906 |   1.5456 |     45.432 |     0.1
    3 |   1.4800 |     46.291 |   1.4353 |     45.432 |     0.1
    4 |   1.4167 |     46.241 |   1.4013 |     45.432 |     0.1
    5 |   1.3815 |     46.071 |   1.3671 |     44.928 |     0.2
    6 |   1.3500 |     45.395 |   1.3317 |     44.739 |     0.2
    7 |   1.3216 |     44.835 |   1.3066 |     44.266 |     0.2
    8 |   1.2949 |     44.626 |   1.2857 |     44.329 |     0.2
    9 |   1.2763 |     44.417 |   1.2720 |     43.793 |     0.3
   10 |   1.2607 |     44.065 |   1.2536 |     43.384 |     0.3
   11 |   1.2437 |     43.813 |   1.2401 |     43.226 |     0.3
   12 |   1.2328 |     43.466 |   1.2306 |     43.258 |     0.4
   13 |   1.2179 |     43.120 |   1.2140 |     41.808 |     0.4
   14 |   1.2063 |     42.505 |   1.2043 |     41.399 |     0.4
   15 |   1.1899 |     41.862 |   1.1995 |     41.556 |     0.5
   16 |   1.1769 |     41.625 |   1.1847 |     40.517 |     0.5
   17 |   1.1632 |     41.142 |   1.1771 |     40.233 |     0.5
   18 |   1.1536 |     40.691 |   1.1769 |     39.981 |     0.6
   19 |   1.1417 |     40.499 |   1.1630 |     39.761 |     0.6
   20 |   1.1296 |     40.114 |   1.1585 |     39.887 |     0.6
   21 |   1.1199 |     39.416 |   1.1446 |     39.540 |     0.6
   22 |   1.1104 |     39.290 |   1.1499 |     39.477 |     0.7
   23 |   1.1010 |     38.922 |   1.1426 |     39.130 |     0.7
   24 |   1.0924 |     38.438 |   1.1549 |     40.265 |     0.7
   25 |   1.0973 |     39.224 |   1.1350 |     39.319 |     0.8
   26 |   1.0831 |     38.257 |   1.1232 |     38.563 |     0.8
   27 |   1.0671 |     37.493 |   1.1160 |     38.847 |     0.8
   28 |   1.0627 |     37.565 |   1.1197 |     39.099 |     0.9
   29 |   1.0471 |     36.680 |   1.1103 |     39.256 |     0.9
   30 |   1.0404 |     36.608 |   1.1060 |     38.406 |     0.9
   31 |   1.0276 |     36.092 |   1.1133 |     39.351 |     1.0
   32 |   1.0241 |     36.020 |   1.1117 |     38.595 |     1.0
   33 |   1.0156 |     35.597 |   1.0916 |     37.870 |     1.0
   34 |   1.0051 |     35.158 |   1.0929 |     37.902 |     1.0
   35 |   0.9947 |     34.779 |   1.0781 |     37.209 |     1.1
   36 |   0.9839 |     34.196 |   1.0797 |     37.461 |     1.1
   37 |   0.9742 |     34.037 |   1.0808 |     37.555 |     1.1
   38 |   0.9651 |     33.702 |   1.0706 |     36.358 |     1.2
   39 |   0.9508 |     32.905 |   1.0699 |     36.547 |     1.2
   40 |   0.9440 |     32.295 |   1.0651 |     36.358 |     1.2
   41 |   0.9319 |     31.916 |   1.0616 |     36.232 |     1.3
   42 |   0.9335 |     31.833 |   1.0959 |     37.366 |     1.3
   43 |   0.9323 |     31.773 |   1.0503 |     35.633 |     1.3
   44 |   0.9026 |     30.723 |   1.0435 |     35.224 |     1.4
   45 |   0.8894 |     30.503 |   1.0490 |     35.507 |     1.4
   46 |   0.8745 |     29.707 |   1.0554 |     35.003 |     1.4
   47 |   0.8772 |     30.091 |   1.0338 |     34.562 |     1.4
   48 |   0.8594 |     29.036 |   1.0353 |     34.310 |     1.5
   49 |   0.8406 |     28.091 |   1.0362 |     34.152 |     1.5
   50 |   0.8269 |     27.756 |   1.0305 |     33.207 |     1.5
   51 |   0.8179 |     27.344 |   1.0245 |     33.176 |     1.6
   52 |   0.8025 |     26.915 |   1.0331 |     33.869 |     1.6
   53 |   0.8020 |     26.948 |   1.0549 |     34.405 |     1.6
   54 |   0.8022 |     27.008 |   1.0193 |     32.609 |     1.7
   55 |   0.7726 |     25.822 |   1.0195 |     32.609 |     1.7
   56 |   0.7529 |     25.124 |   1.0192 |     32.388 |     1.7
   57 |   0.7469 |     24.728 |   1.0230 |     32.829 |     1.8
   58 |   0.7367 |     24.503 |   1.0487 |     32.703 |     1.8
   59 |   0.7243 |     24.091 |   1.0376 |     32.766 |     1.8
   60 |   0.7148 |     23.629 |   1.0195 |     32.420 |     1.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,179,681

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3987 |     63.738 |   1.8408 |     51.953 |     0.1
    2 |   1.6376 |     48.099 |   1.4914 |     45.463 |     0.1
    3 |   1.4426 |     46.148 |   1.3977 |     45.085 |     0.2
    4 |   1.3808 |     46.115 |   1.3540 |     44.896 |     0.2
    5 |   1.3446 |     45.532 |   1.3262 |     43.762 |     0.3
    6 |   1.3167 |     44.615 |   1.3003 |     43.289 |     0.4
    7 |   1.2932 |     44.109 |   1.2824 |     43.415 |     0.4
    8 |   1.2755 |     43.884 |   1.2634 |     43.226 |     0.5
    9 |   1.2551 |     43.417 |   1.2482 |     42.596 |     0.5
   10 |   1.2399 |     43.197 |   1.2348 |     42.124 |     0.6
   11 |   1.2261 |     43.065 |   1.2201 |     42.124 |     0.7
   12 |   1.2103 |     42.774 |   1.2111 |     42.376 |     0.7
   13 |   1.1938 |     42.268 |   1.1950 |     40.800 |     0.8
   14 |   1.1778 |     41.466 |   1.1854 |     40.832 |     0.8
   15 |   1.1661 |     41.400 |   1.1776 |     40.989 |     0.9
   16 |   1.1539 |     40.752 |   1.1656 |     40.265 |     1.0
   17 |   1.1376 |     39.862 |   1.1521 |     39.288 |     1.0
   18 |   1.1242 |     39.131 |   1.1423 |     39.288 |     1.1
   19 |   1.1121 |     38.697 |   1.1403 |     38.532 |     1.1
   20 |   1.0975 |     38.142 |   1.1171 |     37.681 |     1.2
   21 |   1.0866 |     37.955 |   1.1119 |     37.933 |     1.3
   22 |   1.0704 |     37.191 |   1.1038 |     37.555 |     1.3
   23 |   1.0579 |     36.537 |   1.0858 |     36.326 |     1.4
   24 |   1.0440 |     36.290 |   1.0879 |     36.988 |     1.4
   25 |   1.0309 |     35.707 |   1.0787 |     36.736 |     1.5
   26 |   1.0229 |     35.608 |   1.0787 |     36.799 |     1.6
   27 |   1.0143 |     35.438 |   1.0653 |     36.484 |     1.6
   28 |   1.0100 |     35.004 |   1.0538 |     35.476 |     1.7
   29 |   0.9878 |     34.268 |   1.0487 |     35.098 |     1.7
   30 |   0.9756 |     33.762 |   1.0508 |     35.066 |     1.8
   31 |   0.9621 |     33.454 |   1.0319 |     34.657 |     1.9
   32 |   0.9491 |     32.729 |   1.0381 |     35.255 |     1.9
   33 |   0.9399 |     32.482 |   1.0238 |     34.657 |     2.0
   34 |   0.9274 |     31.954 |   1.0288 |     34.625 |     2.0
   35 |   0.9132 |     31.350 |   1.0184 |     34.026 |     2.1
   36 |   0.9266 |     31.690 |   1.0276 |     34.594 |     2.2
   37 |   0.8965 |     30.762 |   1.0039 |     33.302 |     2.2
   38 |   0.8813 |     30.163 |   0.9982 |     33.270 |     2.3
   39 |   0.8762 |     29.855 |   0.9995 |     33.648 |     2.3
   40 |   0.8546 |     29.212 |   1.0043 |     33.333 |     2.4
   41 |   0.8361 |     28.278 |   0.9952 |     32.546 |     2.5
   42 |   0.8284 |     27.937 |   0.9880 |     32.955 |     2.5
   43 |   0.8129 |     27.256 |   1.0064 |     33.050 |     2.6
   44 |   0.8001 |     27.014 |   0.9832 |     32.388 |     2.6
   45 |   0.7986 |     26.855 |   0.9776 |     31.601 |     2.7
   46 |   0.7675 |     25.816 |   0.9677 |     31.096 |     2.8
   47 |   0.7588 |     25.453 |   0.9663 |     31.002 |     2.8
   48 |   0.7472 |     24.970 |   0.9633 |     31.443 |     2.9
   49 |   0.7268 |     24.283 |   0.9602 |     30.340 |     2.9
   50 |   0.7100 |     23.514 |   0.9537 |     30.309 |     3.0
   51 |   0.7054 |     23.536 |   0.9544 |     30.403 |     3.1
   52 |   0.6851 |     22.739 |   0.9551 |     30.057 |     3.1
   53 |   0.6692 |     21.684 |   0.9452 |     29.836 |     3.2
   54 |   0.6563 |     21.294 |   0.9414 |     29.364 |     3.2
   55 |   0.6421 |     21.123 |   0.9425 |     29.143 |     3.3
   56 |   0.6266 |     20.645 |   0.9371 |     29.206 |     3.4
   57 |   0.6047 |     19.700 |   0.9463 |     29.553 |     3.4
   58 |   0.5944 |     19.277 |   0.9466 |     28.702 |     3.5
   59 |   0.5908 |     19.508 |   1.0076 |     31.916 |     3.5
   60 |   0.6007 |     19.909 |   0.9692 |     29.143 |     3.6
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 454,273

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1361 |     58.111 |   1.5318 |     45.400 |     0.0
    2 |   1.4301 |     46.109 |   1.3652 |     44.991 |     0.0
    3 |   1.3451 |     45.818 |   1.3195 |     44.360 |     0.1
    4 |   1.3068 |     44.994 |   1.2899 |     43.793 |     0.1
    5 |   1.2778 |     44.554 |   1.2590 |     43.541 |     0.1
    6 |   1.2549 |     44.027 |   1.2512 |     43.447 |     0.1
    7 |   1.2355 |     43.472 |   1.2267 |     42.911 |     0.1
    8 |   1.2197 |     42.856 |   1.2084 |     41.273 |     0.1
    9 |   1.2043 |     42.582 |   1.1994 |     40.989 |     0.2
   10 |   1.1875 |     42.136 |   1.1873 |     40.895 |     0.2
   11 |   1.1689 |     41.664 |   1.1724 |     40.958 |     0.2
   12 |   1.1547 |     41.169 |   1.1623 |     40.517 |     0.2
   13 |   1.1368 |     40.312 |   1.1458 |     40.139 |     0.2
   14 |   1.1237 |     40.142 |   1.1478 |     40.328 |     0.2
   15 |   1.1078 |     39.444 |   1.1316 |     39.477 |     0.3
   16 |   1.0917 |     38.823 |   1.1237 |     39.225 |     0.3
   17 |   1.0780 |     38.741 |   1.1211 |     39.509 |     0.3
   18 |   1.0633 |     37.905 |   1.1123 |     37.650 |     0.3
   19 |   1.0495 |     37.488 |   1.0897 |     37.366 |     0.3
   20 |   1.0279 |     36.367 |   1.0810 |     36.610 |     0.3
   21 |   1.0125 |     35.905 |   1.0749 |     36.452 |     0.4
   22 |   0.9982 |     35.257 |   1.0601 |     35.822 |     0.4
   23 |   0.9849 |     34.515 |   1.0624 |     35.570 |     0.4
   24 |   0.9772 |     34.333 |   1.0581 |     35.066 |     0.4
   25 |   0.9587 |     34.119 |   1.0409 |     34.751 |     0.4
   26 |   0.9455 |     33.081 |   1.0303 |     34.783 |     0.5
   27 |   0.9326 |     32.718 |   1.0254 |     35.035 |     0.5
   28 |   0.9199 |     32.196 |   1.0150 |     34.688 |     0.5
   29 |   0.9055 |     31.427 |   1.0096 |     34.247 |     0.5
   30 |   0.8928 |     30.937 |   0.9982 |     33.176 |     0.5
   31 |   0.8751 |     30.349 |   0.9948 |     33.018 |     0.5
   32 |   0.8620 |     29.690 |   0.9968 |     33.774 |     0.6
   33 |   0.8495 |     29.157 |   0.9954 |     33.365 |     0.6
   34 |   0.8367 |     28.882 |   0.9850 |     32.577 |     0.6
   35 |   0.8236 |     27.976 |   0.9823 |     31.758 |     0.6
   36 |   0.8114 |     27.959 |   0.9919 |     32.766 |     0.6
   37 |   0.8017 |     27.712 |   0.9810 |     31.317 |     0.6
   38 |   0.7834 |     26.778 |   0.9660 |     32.042 |     0.7
   39 |   0.7804 |     26.695 |   0.9691 |     32.073 |     0.7
   40 |   0.7624 |     26.069 |   0.9650 |     31.443 |     0.7
   41 |   0.7459 |     25.415 |   0.9602 |     31.443 |     0.7
   42 |   0.7341 |     25.047 |   0.9538 |     31.664 |     0.7
   43 |   0.7143 |     24.536 |   0.9582 |     31.254 |     0.7
   44 |   0.7015 |     23.981 |   0.9491 |     30.907 |     0.8
   45 |   0.6873 |     23.448 |   0.9827 |     31.601 |     0.8
   46 |   0.7108 |     24.343 |   0.9718 |     32.010 |     0.8
   47 |   0.6781 |     23.096 |   0.9400 |     30.435 |     0.8
   48 |   0.6541 |     22.123 |   0.9507 |     29.994 |     0.8
   49 |   0.6453 |     21.843 |   0.9483 |     29.805 |     0.9
   50 |   0.6327 |     21.244 |   0.9532 |     30.340 |     0.9
   51 |   0.6154 |     20.678 |   0.9549 |     30.214 |     0.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 736,289

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1790 |     59.985 |   1.5752 |     45.432 |     0.0
    2 |   1.4656 |     46.302 |   1.4190 |     45.810 |     0.1
    3 |   1.3952 |     46.434 |   1.3759 |     45.400 |     0.1
    4 |   1.3645 |     45.923 |   1.3528 |     45.337 |     0.1
    5 |   1.3371 |     45.686 |   1.3214 |     45.243 |     0.1
    6 |   1.3175 |     45.159 |   1.3076 |     44.266 |     0.2
    7 |   1.3010 |     45.142 |   1.2940 |     44.770 |     0.2
    8 |   1.2846 |     44.857 |   1.2861 |     44.297 |     0.2
    9 |   1.2756 |     44.851 |   1.2667 |     44.140 |     0.2
   10 |   1.2597 |     44.346 |   1.2596 |     43.510 |     0.3
   11 |   1.2434 |     43.983 |   1.2410 |     42.785 |     0.3
   12 |   1.2241 |     43.714 |   1.2297 |     42.817 |     0.3
   13 |   1.2028 |     42.779 |   1.2123 |     41.777 |     0.3
   14 |   1.1838 |     41.807 |   1.1906 |     41.714 |     0.4
   15 |   1.1651 |     41.581 |   1.1841 |     40.611 |     0.4
   16 |   1.1426 |     40.587 |   1.1635 |     41.052 |     0.4
   17 |   1.1196 |     39.471 |   1.1378 |     38.658 |     0.5
   18 |   1.0933 |     38.488 |   1.1276 |     38.154 |     0.5
   19 |   1.0653 |     37.488 |   1.1051 |     38.280 |     0.5
   20 |   1.0347 |     36.064 |   1.0945 |     37.650 |     0.5
   21 |   1.0129 |     35.009 |   1.0746 |     36.484 |     0.6
   22 |   0.9826 |     33.795 |   1.0621 |     36.074 |     0.6
   23 |   0.9566 |     32.932 |   1.0438 |     35.161 |     0.6
   24 |   0.9276 |     31.608 |   1.0418 |     34.216 |     0.6
   25 |   0.9093 |     30.712 |   1.0320 |     34.121 |     0.7
   26 |   0.8788 |     29.608 |   1.0200 |     34.279 |     0.7
   27 |   0.8451 |     28.140 |   1.0136 |     33.743 |     0.7
   28 |   0.8206 |     27.294 |   1.0082 |     32.577 |     0.7
   29 |   0.7933 |     26.019 |   1.0120 |     32.987 |     0.8
   30 |   0.7788 |     25.618 |   0.9847 |     31.128 |     0.8
   31 |   0.7397 |     24.118 |   0.9860 |     30.813 |     0.8
   32 |   0.7177 |     23.464 |   0.9935 |     31.096 |     0.9
   33 |   0.6868 |     22.453 |   0.9896 |     31.191 |     0.9
   34 |   0.6673 |     21.744 |   0.9901 |     29.868 |     0.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,690,913

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5781 |     69.431 |   2.0417 |     58.727 |     0.1
    2 |   1.8071 |     51.588 |   1.5915 |     45.463 |     0.2
    3 |   1.5189 |     46.401 |   1.4592 |     45.463 |     0.2
    4 |   1.4344 |     46.373 |   1.4070 |     45.841 |     0.3
    5 |   1.3918 |     46.263 |   1.3715 |     45.432 |     0.4
    6 |   1.3611 |     45.615 |   1.3435 |     45.274 |     0.5
    7 |   1.3394 |     45.406 |   1.3296 |     44.455 |     0.6
    8 |   1.3209 |     45.082 |   1.3074 |     44.108 |     0.6
    9 |   1.3030 |     44.686 |   1.2944 |     43.888 |     0.7
   10 |   1.2854 |     44.329 |   1.2800 |     43.667 |     0.8
   11 |   1.2689 |     44.175 |   1.2663 |     43.510 |     0.9
   12 |   1.2526 |     43.928 |   1.2478 |     43.447 |     1.0
   13 |   1.2404 |     43.862 |   1.2324 |     43.100 |     1.0
   14 |   1.2272 |     43.505 |   1.2227 |     42.281 |     1.1
   15 |   1.2150 |     43.109 |   1.2161 |     41.934 |     1.2
   16 |   1.2067 |     42.730 |   1.2082 |     42.218 |     1.3
   17 |   1.1964 |     42.433 |   1.1948 |     41.304 |     1.4
   18 |   1.1913 |     42.109 |   1.1901 |     41.840 |     1.4
   19 |   1.1823 |     42.021 |   1.1902 |     41.178 |     1.5
   20 |   1.1745 |     41.763 |   1.1874 |     41.304 |     1.6
   21 |   1.1788 |     42.049 |   1.1828 |     41.997 |     1.7
   22 |   1.1678 |     41.680 |   1.1689 |     40.296 |     1.8
   23 |   1.1559 |     41.296 |   1.1692 |     40.737 |     1.8
   24 |   1.1521 |     41.081 |   1.1628 |     40.485 |     1.9
   25 |   1.1474 |     41.120 |   1.1634 |     40.328 |     2.0
   26 |   1.1391 |     40.961 |   1.1532 |     40.233 |     2.1
   27 |   1.1346 |     40.296 |   1.1513 |     40.233 |     2.2
   28 |   1.1271 |     40.334 |   1.1500 |     39.950 |     2.3
   29 |   1.1269 |     40.059 |   1.1427 |     40.044 |     2.3
   30 |   1.1231 |     40.153 |   1.1436 |     39.824 |     2.4
   31 |   1.1162 |     40.087 |   1.1402 |     39.635 |     2.5
   32 |   1.1136 |     39.763 |   1.1433 |     40.328 |     2.6
   33 |   1.1062 |     39.449 |   1.1331 |     39.382 |     2.7
   34 |   1.1009 |     39.268 |   1.1354 |     39.855 |     2.7
   35 |   1.0986 |     39.081 |   1.1268 |     39.477 |     2.8
   36 |   1.0916 |     38.724 |   1.1277 |     39.477 |     2.9
   37 |   1.0911 |     38.977 |   1.1199 |     38.878 |     3.0
   38 |   1.0850 |     38.625 |   1.1230 |     39.099 |     3.1
   39 |   1.0830 |     38.834 |   1.1214 |     38.878 |     3.1
   40 |   1.0787 |     38.669 |   1.1164 |     38.941 |     3.2
   41 |   1.0787 |     38.625 |   1.1080 |     38.469 |     3.3
   42 |   1.0770 |     38.719 |   1.1116 |     38.532 |     3.4
   43 |   1.0697 |     38.284 |   1.1110 |     38.784 |     3.5
   44 |   1.0675 |     38.125 |   1.1025 |     38.532 |     3.5
   45 |   1.0650 |     38.043 |   1.1027 |     38.658 |     3.6
   46 |   1.0609 |     38.004 |   1.0980 |     38.185 |     3.7
   47 |   1.0547 |     37.685 |   1.0974 |     38.248 |     3.8
   48 |   1.0515 |     37.350 |   1.1084 |     38.343 |     3.9
   49 |   1.0500 |     37.625 |   1.0970 |     38.059 |     3.9
   50 |   1.0496 |     37.422 |   1.0940 |     38.406 |     4.0
   51 |   1.0426 |     37.317 |   1.0904 |     37.870 |     4.1
   52 |   1.0371 |     37.103 |   1.0951 |     37.902 |     4.2
   53 |   1.0332 |     37.015 |   1.0963 |     38.374 |     4.3
   54 |   1.0268 |     36.455 |   1.0858 |     37.713 |     4.3
   55 |   1.0292 |     36.944 |   1.0820 |     37.902 |     4.4
   56 |   1.0295 |     36.938 |   1.0898 |     38.437 |     4.5
   57 |   1.0286 |     36.691 |   1.0841 |     37.870 |     4.6
   58 |   1.0238 |     36.713 |   1.0816 |     37.587 |     4.7
   59 |   1.0149 |     35.965 |   1.0741 |     37.524 |     4.7
   60 |   1.0155 |     36.394 |   1.0769 |     37.650 |     4.8
   61 |   1.0051 |     35.987 |   1.0749 |     36.988 |     4.9
   62 |   1.0044 |     35.845 |   1.0829 |     37.587 |     5.0
   63 |   0.9997 |     35.922 |   1.0760 |     36.830 |     5.1
   64 |   0.9974 |     35.685 |   1.0679 |     36.862 |     5.1
   65 |   0.9950 |     35.493 |   1.0766 |     37.335 |     5.2
   66 |   0.9885 |     35.075 |   1.0742 |     37.555 |     5.3
   67 |   0.9862 |     35.416 |   1.0687 |     37.114 |     5.4
   68 |   0.9985 |     35.509 |   1.0758 |     37.051 |     5.5
   69 |   0.9794 |     34.603 |   1.0656 |     36.704 |     5.5
   70 |   0.9698 |     34.647 |   1.0613 |     36.704 |     5.6
   71 |   0.9681 |     34.405 |   1.0612 |     36.641 |     5.7
   72 |   0.9672 |     34.273 |   1.0635 |     36.547 |     5.8
   73 |   0.9593 |     34.031 |   1.0611 |     36.295 |     5.9
   74 |   0.9534 |     33.712 |   1.0645 |     36.515 |     5.9
   75 |   0.9501 |     33.350 |   1.0529 |     35.539 |     6.0
   76 |   0.9458 |     33.366 |   1.0577 |     36.232 |     6.1
   77 |   0.9400 |     33.163 |   1.0456 |     35.602 |     6.2
   78 |   0.9322 |     32.998 |   1.0536 |     35.413 |     6.3
   79 |   0.9392 |     33.267 |   1.0540 |     35.633 |     6.3
   80 |   0.9279 |     32.657 |   1.0461 |     35.224 |     6.4
   81 |   0.9216 |     32.570 |   1.0514 |     35.633 |     6.5
   82 |   0.9326 |     32.822 |   1.0402 |     35.381 |     6.6
   83 |   0.9213 |     32.157 |   1.0433 |     35.255 |     6.7
   84 |   0.9132 |     32.075 |   1.0440 |     35.413 |     6.8
   85 |   0.9018 |     31.679 |   1.0360 |     35.224 |     6.8
   86 |   0.8994 |     31.514 |   1.0417 |     35.003 |     6.9
   87 |   0.8949 |     31.212 |   1.0427 |     34.814 |     7.0
   88 |   0.8894 |     31.256 |   1.0425 |     34.720 |     7.1
   89 |   0.8840 |     30.811 |   1.0306 |     34.688 |     7.2
   90 |   0.8790 |     30.525 |   1.0347 |     34.436 |     7.2
   91 |   0.8722 |     30.157 |   1.0405 |     34.152 |     7.3
   92 |   0.8690 |     30.163 |   1.0286 |     33.585 |     7.4
   93 |   0.8622 |     29.976 |   1.0352 |     33.774 |     7.5
   94 |   0.8683 |     29.987 |   1.0316 |     34.436 |     7.6
   95 |   0.8557 |     29.531 |   1.0422 |     34.279 |     7.6
   96 |   0.8469 |     29.448 |   1.0289 |     33.239 |     7.7
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 2,054,241

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1812 |     58.671 |   1.6024 |     45.463 |     0.1
    2 |   1.4776 |     46.417 |   1.4093 |     45.432 |     0.2
    3 |   1.3896 |     46.005 |   1.3774 |     45.243 |     0.2
    4 |   1.3495 |     45.719 |   1.3208 |     44.581 |     0.3
    5 |   1.3150 |     45.258 |   1.3071 |     44.612 |     0.4
    6 |   1.2931 |     44.769 |   1.2876 |     44.077 |     0.5
    7 |   1.2648 |     44.351 |   1.2557 |     44.140 |     0.6
    8 |   1.2384 |     43.763 |   1.2312 |     42.722 |     0.6
    9 |   1.2172 |     43.181 |   1.2174 |     42.218 |     0.7
   10 |   1.2014 |     42.301 |   1.2063 |     41.966 |     0.8
   11 |   1.1860 |     41.994 |   1.1934 |     41.493 |     0.9
   12 |   1.1737 |     41.691 |   1.1830 |     40.863 |     1.0
   13 |   1.1633 |     41.191 |   1.1769 |     40.391 |     1.0
   14 |   1.1522 |     41.059 |   1.1698 |     40.548 |     1.1
   15 |   1.1417 |     40.647 |   1.1642 |     40.422 |     1.2
   16 |   1.1326 |     40.329 |   1.1519 |     39.666 |     1.3
   17 |   1.1250 |     40.202 |   1.1441 |     38.941 |     1.4
   18 |   1.1164 |     40.037 |   1.1373 |     39.950 |     1.4
   19 |   1.1075 |     39.851 |   1.1312 |     39.572 |     1.5
   20 |   1.0992 |     39.361 |   1.1255 |     39.288 |     1.6
   21 |   1.0899 |     39.361 |   1.1219 |     39.256 |     1.7
   22 |   1.0845 |     39.323 |   1.1233 |     39.540 |     1.8
   23 |   1.0771 |     38.889 |   1.1173 |     39.635 |     1.8
   24 |   1.0668 |     38.795 |   1.1205 |     40.170 |     1.9
   25 |   1.0582 |     38.482 |   1.1119 |     39.477 |     2.0
   26 |   1.0542 |     38.372 |   1.1088 |     39.477 |     2.1
   27 |   1.0459 |     38.191 |   1.0984 |     38.626 |     2.2
   28 |   1.0376 |     37.724 |   1.0894 |     38.469 |     2.2
   29 |   1.0290 |     37.273 |   1.0858 |     38.122 |     2.3
   30 |   1.0237 |     37.202 |   1.0904 |     38.280 |     2.4
   31 |   1.0171 |     37.043 |   1.0827 |     38.028 |     2.5
   32 |   1.0103 |     36.641 |   1.0704 |     38.595 |     2.6
   33 |   1.0015 |     36.581 |   1.0684 |     37.744 |     2.6
   34 |   0.9941 |     36.053 |   1.0600 |     37.713 |     2.7
   35 |   0.9831 |     35.268 |   1.0541 |     37.524 |     2.8
   36 |   0.9756 |     35.262 |   1.0543 |     36.578 |     2.9
   37 |   0.9715 |     35.103 |   1.0520 |     36.263 |     3.0
   38 |   0.9623 |     34.438 |   1.0395 |     35.728 |     3.0
   39 |   0.9504 |     33.910 |   1.0419 |     36.673 |     3.1
   40 |   0.9512 |     34.092 |   1.0320 |     35.980 |     3.2
   41 |   0.9377 |     33.119 |   1.0391 |     35.350 |     3.3
   42 |   0.9308 |     33.201 |   1.0356 |     35.381 |     3.4
   43 |   0.9571 |     34.174 |   1.0498 |     36.232 |     3.4
   44 |   0.9357 |     33.086 |   1.0203 |     34.499 |     3.5
   45 |   0.9089 |     32.135 |   1.0088 |     34.751 |     3.6
   46 |   0.8988 |     31.619 |   1.0168 |     35.066 |     3.7
   47 |   0.8882 |     31.201 |   1.0026 |     34.688 |     3.8
   48 |   0.8742 |     30.564 |   0.9920 |     33.774 |     3.8
   49 |   0.8662 |     30.196 |   0.9904 |     33.365 |     3.9
   50 |   0.8691 |     30.564 |   0.9936 |     34.184 |     4.0
   51 |   0.8474 |     29.893 |   0.9759 |     33.207 |     4.1
   52 |   0.8347 |     29.179 |   0.9899 |     33.711 |     4.2
   53 |   0.8247 |     28.789 |   0.9823 |     32.861 |     4.2
   54 |   0.8174 |     28.564 |   0.9704 |     32.703 |     4.3
   55 |   0.8022 |     28.113 |   0.9745 |     32.955 |     4.4
   56 |   0.7932 |     27.767 |   0.9719 |     31.853 |     4.5
   57 |   0.7776 |     27.129 |   0.9475 |     32.136 |     4.6
   58 |   0.7678 |     26.475 |   0.9503 |     31.380 |     4.6
   59 |   0.7555 |     25.997 |   0.9563 |     30.498 |     4.7
   60 |   0.7495 |     25.712 |   0.9581 |     30.939 |     4.8
   61 |   0.7360 |     25.179 |   0.9517 |     31.569 |     4.9
Early stopping

Model: Seq2Seq Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 771,169

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0896 |     57.017 |   1.5099 |     45.274 |     0.0
    2 |   1.4191 |     46.011 |   1.3640 |     45.180 |     0.1
    3 |   1.3310 |     45.170 |   1.2957 |     43.258 |     0.1
    4 |   1.2782 |     44.093 |   1.2564 |     43.793 |     0.1
    5 |   1.2396 |     43.301 |   1.2279 |     42.754 |     0.2
    6 |   1.2112 |     42.598 |   1.1972 |     40.989 |     0.2
    7 |   1.1811 |     41.999 |   1.1860 |     41.588 |     0.2
    8 |   1.1573 |     41.246 |   1.1653 |     40.170 |     0.2
    9 |   1.1352 |     40.521 |   1.1523 |     39.950 |     0.3
   10 |   1.1141 |     39.543 |   1.1338 |     39.572 |     0.3
   11 |   1.0934 |     38.817 |   1.1174 |     38.154 |     0.3
   12 |   1.0715 |     37.784 |   1.1058 |     38.091 |     0.4
   13 |   1.0470 |     36.850 |   1.0919 |     36.232 |     0.4
   14 |   1.0258 |     36.136 |   1.0909 |     37.618 |     0.4
   15 |   1.0054 |     35.163 |   1.0755 |     36.767 |     0.5
   16 |   0.9820 |     34.169 |   1.0566 |     35.476 |     0.5
   17 |   0.9591 |     33.020 |   1.0503 |     36.232 |     0.5
   18 |   0.9400 |     32.520 |   1.0286 |     35.066 |     0.6
   19 |   0.9149 |     31.569 |   1.0271 |     35.098 |     0.6
   20 |   0.8997 |     30.833 |   1.0069 |     33.113 |     0.6
   21 |   0.8702 |     29.756 |   0.9979 |     33.050 |     0.6
   22 |   0.8485 |     28.822 |   0.9917 |     32.451 |     0.7
   23 |   0.8231 |     28.146 |   0.9846 |     32.672 |     0.7
   24 |   0.7939 |     26.673 |   0.9709 |     31.569 |     0.7
   25 |   0.7684 |     25.838 |   0.9614 |     30.750 |     0.8
   26 |   0.7455 |     25.234 |   0.9476 |     31.033 |     0.8
   27 |   0.7204 |     24.069 |   0.9414 |     31.065 |     0.8
   28 |   0.7076 |     23.700 |   0.9605 |     31.474 |     0.9
   29 |   0.6821 |     22.981 |   0.9325 |     29.490 |     0.9
   30 |   0.6564 |     21.706 |   0.9383 |     30.529 |     0.9
   31 |   0.6348 |     20.920 |   0.9351 |     30.655 |     1.0
   32 |   0.6116 |     20.277 |   0.9269 |     28.954 |     1.0
   33 |   0.5852 |     19.277 |   0.9321 |     28.954 |     1.0
   34 |   0.5636 |     18.288 |   0.9395 |     29.017 |     1.0
   35 |   0.5371 |     17.266 |   0.9404 |     28.733 |     1.1
   36 |   0.5208 |     16.760 |   0.9422 |     29.269 |     1.1
Early stopping

