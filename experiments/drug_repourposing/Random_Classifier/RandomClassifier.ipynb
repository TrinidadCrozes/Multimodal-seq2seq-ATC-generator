{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9606e0f7-ce9d-43af-8fd2-72cd6ba96d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split \n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))\n",
    "from seq2seq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2d1c6a-f935-470f-943c-b16f544beceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string that simulates a list to a real list\n",
    "def convert_string_list(element):\n",
    "    # Delete [] of the string\n",
    "    element = element[0:len(element)]\n",
    "    # Create a list that contains each code as e.g. 'A'\n",
    "    ATC_list = list(element.split('; '))\n",
    "    for index, code in enumerate(ATC_list):\n",
    "        # Delete '' of the code\n",
    "        ATC_list[index] = code[0:len(code)] \n",
    "    return ATC_list\n",
    "\n",
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def multiplicate_rows(df):\n",
    "    # Duplicate each compound the number of ATC codes associated to it, copying its SMILES in new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        atc_codes = row['ATC Codes']\n",
    "        atc_codes_list = convert_string_list(atc_codes)\n",
    "        \n",
    "        if len(atc_codes_list) > 1:\n",
    "            for code in atc_codes_list:\n",
    "                if len(code) == 5:\n",
    "                    new_row = row.copy()\n",
    "                    new_row['ATC Codes'] = code\n",
    "                    new_rows.append(new_row)\n",
    "        else:\n",
    "            if len(atc_codes_list[0]) == 5:\n",
    "                new_rows.append(row)\n",
    "    \n",
    "    new_set = pd.DataFrame(new_rows)\n",
    "    new_set = new_set.reset_index(drop=True)\n",
    "\n",
    "    return new_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828d612-7497-4982-bcd8-4b021c556939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Temp\\ipykernel_23884\\3164191770.py:184: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 4 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 3 for 0 compounds\n",
      "The model predicted less than 3 ATC codes of level 2 for 0 compounds\n",
      "Mean: Precision            0.000526\n",
      "Recall               0.001245\n",
      "F1                   0.000701\n",
      "Precision_level3     0.004512\n",
      "Recall_level3        0.010943\n",
      "F1_level3            0.006133\n",
      "Precision_level2     0.016207\n",
      "Recall_level2        0.041380\n",
      "F1_level2            0.022584\n",
      "Precision level 1    0.099474\n",
      "Precision level 2    0.161353\n",
      "Precision level 3    0.273219\n",
      "Precision level 4    0.108204\n",
      "Recall level 1       0.240008\n",
      "Recall level 2       0.169264\n",
      "Recall level 3       0.271994\n",
      "Recall level 4       0.108204\n",
      "dtype: float64\n",
      "Std: Precision            0.000403\n",
      "Recall               0.000990\n",
      "F1                   0.000533\n",
      "Precision_level3     0.001640\n",
      "Recall_level3        0.003848\n",
      "F1_level3            0.002194\n",
      "Precision_level2     0.003745\n",
      "Recall_level2        0.010461\n",
      "F1_level2            0.005413\n",
      "Precision level 1    0.002574\n",
      "Precision level 2    0.039618\n",
      "Precision level 3    0.055804\n",
      "Precision level 4    0.082654\n",
      "Recall level 1       0.007884\n",
      "Recall level 2       0.041628\n",
      "Recall level 3       0.052947\n",
      "Recall level 4       0.082654\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 47899, 2025, 1, 20, 99, 1020, 345, 78] \n",
    "columns = [\n",
    "    'Seed', \n",
    "    'Precision', 'Recall', 'F1',\n",
    "    'Precision_level3', 'Recall_level3', 'F1_level3',\n",
    "    'Precision_level2', 'Recall_level2', 'F1_level2',\n",
    "    'Precision level 1', 'Precision level 2', 'Precision level 3', 'Precision level 4',\n",
    "    'Recall level 1', 'Recall level 2', 'Recall level 3', 'Recall level 4',\n",
    "    '#Compounds that have at least one match'\n",
    "]\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    train_set = pd.read_csv(f'../Datasets/Rep_complete_train_set{seed}.csv')\n",
    "    test_set = pd.read_csv(f'../Datasets/Rep_test_set{seed}.csv')\n",
    "    \n",
    "    new_train_set = multiplicate_rows(train_set)\n",
    "    new_test_set = multiplicate_rows(test_set)\n",
    "\n",
    "    X_train = new_train_set['Neutralized SMILES']\n",
    "    y_train = new_train_set['ATC Codes']\n",
    "    X_test = new_test_set['Neutralized SMILES']\n",
    "    X_test2 = test_set['Neutralized SMILES']\n",
    "    y_test = new_test_set['ATC Codes']\n",
    "    \n",
    "    atc_nivel1 = []\n",
    "    for y in y_train:\n",
    "        atc_nivel1.append(y[0])\n",
    "    y_train_nivel1 = pd.DataFrame(atc_nivel1)\n",
    "    y_train_nivel1 = y_train_nivel1.reset_index(drop=True)\n",
    "\n",
    "    atc_nivel2 = []\n",
    "    for y in y_train:\n",
    "        atc_nivel2.append(y[1:3])\n",
    "    y_train_nivel2 = pd.DataFrame(atc_nivel2)\n",
    "    y_train_nivel2 = y_train_nivel2.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    atc_nivel3 = []\n",
    "    for y in y_train:\n",
    "        atc_nivel3.append(y[3:4])\n",
    "    y_train_nivel3 = pd.DataFrame(atc_nivel3)\n",
    "    y_train_nivel3 = y_train_nivel3.reset_index(drop=True)\n",
    "\n",
    "    atc_nivel4 = []\n",
    "    for y in y_train:\n",
    "        atc_nivel4.append(y[4:5])\n",
    "    y_train_nivel4 = pd.DataFrame(atc_nivel4)\n",
    "    y_train_nivel4 = y_train_nivel4.reset_index(drop=True)\n",
    "\n",
    "    # Contar la frecuencia de cada elemento\n",
    "    conteo1 = Counter(atc_nivel1)\n",
    "    # Calcular la probabilidad de cada elemento\n",
    "    total_elementos1 = len(atc_nivel1)\n",
    "    probabilidades1 = {elemento: frecuencia / total_elementos1 for elemento, frecuencia in conteo1.items()}\n",
    "    nivel1 = np.random.choice(list(probabilidades1.keys()), size=(len(X_test2),20), p=list(probabilidades1.values()))\n",
    "\n",
    "    # Contar la frecuencia de cada elemento\n",
    "    conteo2 = Counter(atc_nivel2)\n",
    "    \n",
    "    # Calcular la probabilidad de cada elemento\n",
    "    total_elementos2 = len(atc_nivel2)\n",
    "    probabilidades2 = {elemento: frecuencia / total_elementos2 for elemento, frecuencia in conteo2.items()}\n",
    "    nivel2 = np.random.choice(list(probabilidades2.keys()), size=(len(X_test2),20), p=list(probabilidades2.values()))\n",
    "        \n",
    "    # Contar la frecuencia de cada elemento\n",
    "    conteo3 = Counter(atc_nivel3)\n",
    "    \n",
    "    # Calcular la probabilidad de cada elemento\n",
    "    total_elementos3 = len(atc_nivel3)\n",
    "    probabilidades3 = {elemento: frecuencia / total_elementos3 for elemento, frecuencia in conteo3.items()}\n",
    "    nivel3 = np.random.choice(list(probabilidades3.keys()), size=(len(X_test2),20), p=list(probabilidades3.values()))\n",
    "\n",
    "    # Contar la frecuencia de cada elemento\n",
    "    conteo4 = Counter(atc_nivel4)\n",
    "    \n",
    "    # Calcular la probabilidad de cada elemento\n",
    "    total_elementos4 = len(atc_nivel4)\n",
    "    probabilidades4 = {elemento: frecuencia / total_elementos4 for elemento, frecuencia in conteo4.items()}\n",
    "    nivel4 = np.random.choice(list(probabilidades4.keys()), size=(len(X_test2),20), p=list(probabilidades4.values()))\n",
    "\n",
    "    predictions = []\n",
    "    for i, atc1 in enumerate(nivel1):\n",
    "        codes = []\n",
    "        for j, code1 in enumerate(atc1):\n",
    "            codes.append(code1 + nivel2[i][j] + nivel3[i][j] + nivel4[i][j])\n",
    "        predictions.append(codes)\n",
    "    predictions_clean = []\n",
    "    counter4_lessthan3 = 0\n",
    "    for preds in predictions:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            if len(clean_pred) == 5:\n",
    "                interm.append(clean_pred)\n",
    "        if len(interm) >= 3:\n",
    "            predictions_clean.append(interm[0:3])\n",
    "        else:\n",
    "            counter4_lessthan3 += 1\n",
    "            predictions_clean.append(interm)\n",
    "    print(f\"The model predicted less than 3 ATC codes of level 4 for {counter4_lessthan3} compounds\")                 \n",
    "    predictions_clean_level3 = []\n",
    "    counter3_lessthan3 = 0\n",
    "    for preds in predictions:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            pred_3 = clean_pred[0:4]\n",
    "            if len(pred_3) == 4 and pred_3 not in interm:\n",
    "                interm.append(pred_3)\n",
    "        if len(interm) >= 3:\n",
    "            predictions_clean_level3.append(interm[0:3])\n",
    "        else:\n",
    "            counter3_lessthan3 += 1\n",
    "            predictions_clean_level3.append(interm)\n",
    "    print(f\"The model predicted less than 3 ATC codes of level 3 for {counter3_lessthan3} compounds\")       \n",
    "    predictions_clean_level2 = []\n",
    "    counter2_lessthan3 = 0\n",
    "    for preds in predictions:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            pred_2 = clean_pred[0:3]\n",
    "            if len(pred_2) == 3 and pred_2 not in interm:\n",
    "                interm.append(pred_2)\n",
    "        if len(interm) >= 3:\n",
    "            predictions_clean_level2.append(interm[0:3])\n",
    "        else:\n",
    "            counter2_lessthan3 += 1\n",
    "            predictions_clean_level2.append(interm)\n",
    "    print(f\"The model predicted less than 3 ATC codes of level 2 for {counter2_lessthan3} compounds\")       \n",
    "    precision_1, precision_2, precision_3, precision_4 = defined_metrics.precision(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes')\n",
    "    recall_1, recall_2, recall_3, recall_4, counter_compound_match = defined_metrics.recall(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes')\n",
    "    precisions, recalls, f1s = defined_metrics.complete_metrics(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_level3, recalls_level3, f1s_level3 = defined_metrics.complete_metrics_level3(predictions_clean_level3, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_level2, recalls_level2, f1s_level2 = defined_metrics.complete_metrics_level2(predictions_clean_level2, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_average = sum(precisions)/len(precisions)\n",
    "    recalls_average = sum(recalls)/len(recalls)\n",
    "    f1s_average = sum(f1s)/len(f1s)\n",
    "\n",
    "    precisions_average_level3 = sum(precisions_level3)/len(precisions_level3)\n",
    "    recalls_average_level3 = sum(recalls_level3)/len(recalls_level3)\n",
    "    f1s_average_level3 = sum(f1s_level3)/len(f1s_level3)\n",
    "\n",
    "    precisions_average_level2 = sum(precisions_level2)/len(precisions_level2)\n",
    "    recalls_average_level2 = sum(recalls_level2)/len(recalls_level2)\n",
    "    f1s_average_level2 = sum(f1s_level2)/len(f1s_level2)\n",
    "    \n",
    "    precisions_average_level3 = sum(precisions_level3)/len(precisions_level3)\n",
    "    recalls_average_level3 = sum(recalls_level3)/len(recalls_level3)\n",
    "    f1s_average_level3 = sum(f1s_level3)/len(f1s_level3)\n",
    "        \n",
    "    metrics = {\n",
    "        'Precision': precisions_average, \n",
    "        'Recall': recalls_average,\n",
    "        'F1': f1s_average,\n",
    "        'Precision_level3': precisions_average_level3, \n",
    "        'Recall_level3': recalls_average_level3,\n",
    "        'F1_level3': f1s_average_level3,\n",
    "        'Precision_level2': precisions_average_level2, \n",
    "        'Recall_level2': recalls_average_level2,\n",
    "        'F1_level2': f1s_average_level2,\n",
    "        'Precision level 1': precision_1,\n",
    "        'Precision level 2': precision_2,\n",
    "        'Precision level 3': precision_3,\n",
    "        'Precision level 4': precision_4,\n",
    "        'Recall level 1': recall_1,\n",
    "        'Recall level 2': recall_2,\n",
    "        'Recall level 3': recall_3,\n",
    "        'Recall level 4': recall_4,\n",
    "        '#Compounds that have at least one match': counter_compound_match\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Build the row\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "metrics_df.to_csv(\"random_metrics.csv\", index=False)\n",
    "print(\"Mean:\", metrics_df.mean(numeric_only=True))\n",
    "print(\"Std:\", metrics_df.std(numeric_only=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
