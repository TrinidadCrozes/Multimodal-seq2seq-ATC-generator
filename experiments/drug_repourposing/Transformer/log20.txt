Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 847,522

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4599 |     61.785 |   1.6300 |     46.617 |     0.1
    2 |   1.6547 |     46.490 |   1.4307 |     45.562 |     0.3
    3 |   1.4963 |     46.110 |   1.3696 |     45.313 |     0.4
    4 |   1.4207 |     45.477 |   1.3293 |     44.165 |     0.5
    5 |   1.3806 |     45.157 |   1.3027 |     44.351 |     0.7
    6 |   1.3462 |     44.490 |   1.2900 |     44.227 |     0.8
    7 |   1.3233 |     43.857 |   1.2655 |     42.986 |     1.0
    8 |   1.3054 |     43.510 |   1.2576 |     42.955 |     1.1
    9 |   1.2810 |     42.788 |   1.2484 |     42.924 |     1.2
   10 |   1.2596 |     42.314 |   1.2501 |     42.893 |     1.4
   11 |   1.2467 |     41.702 |   1.2446 |     42.613 |     1.5
   12 |   1.2264 |     41.163 |   1.2266 |     41.434 |     1.7
   13 |   1.2107 |     40.545 |   1.2335 |     41.403 |     1.8
   14 |   1.1944 |     40.110 |   1.2375 |     41.465 |     2.0
   15 |   1.1825 |     40.176 |   1.2437 |     42.086 |     2.1
   16 |   1.1670 |     39.372 |   1.2216 |     41.092 |     2.2
   17 |   1.1490 |     38.821 |   1.2340 |     41.279 |     2.4
   18 |   1.1419 |     38.501 |   1.2348 |     40.627 |     2.5
   19 |   1.1301 |     38.072 |   1.2368 |     40.751 |     2.7
   20 |   1.1175 |     37.796 |   1.2462 |     41.341 |     2.8
   21 |   1.1092 |     37.427 |   1.2037 |     39.789 |     3.0
   22 |   1.0945 |     37.047 |   1.2602 |     41.279 |     3.1
   23 |   1.0850 |     36.755 |   1.2394 |     40.534 |     3.2
   24 |   1.0755 |     36.353 |   1.2228 |     40.534 |     3.4
   25 |   1.0633 |     35.956 |   1.2268 |     40.410 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 814,242

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0947 |     53.085 |   1.5277 |     45.841 |     0.1
    2 |   1.4320 |     45.096 |   1.3695 |     44.475 |     0.2
    3 |   1.3187 |     43.019 |   1.2931 |     42.800 |     0.3
    4 |   1.2547 |     41.455 |   1.2380 |     40.534 |     0.3
    5 |   1.2038 |     39.912 |   1.2113 |     40.565 |     0.4
    6 |   1.1667 |     39.190 |   1.1755 |     40.006 |     0.5
    7 |   1.1346 |     38.314 |   1.1527 |     38.237 |     0.6
    8 |   1.1037 |     37.444 |   1.1372 |     38.796 |     0.7
    9 |   1.0753 |     36.512 |   1.1303 |     38.082 |     0.8
   10 |   1.0558 |     35.818 |   1.1181 |     38.206 |     0.9
   11 |   1.0293 |     34.832 |   1.0834 |     36.716 |     1.0
   12 |   1.0028 |     33.928 |   1.0921 |     36.778 |     1.1
   13 |   0.9827 |     32.997 |   1.0886 |     36.716 |     1.1
   14 |   0.9596 |     32.270 |   1.0631 |     35.878 |     1.2
   15 |   0.9355 |     31.554 |   1.0570 |     35.040 |     1.3
   16 |   0.9154 |     30.865 |   1.0587 |     34.730 |     1.4
   17 |   0.8946 |     29.879 |   1.0380 |     34.575 |     1.5
   18 |   0.8708 |     29.262 |   1.0470 |     34.389 |     1.6
   19 |   0.8494 |     28.347 |   1.0339 |     33.892 |     1.7
   20 |   0.8297 |     27.482 |   1.0543 |     33.582 |     1.8
   21 |   0.8150 |     26.992 |   1.0406 |     33.023 |     1.8
   22 |   0.7865 |     26.094 |   1.0257 |     33.923 |     1.9
   23 |   0.7704 |     25.614 |   1.0183 |     31.937 |     2.0
   24 |   0.7483 |     24.970 |   1.0225 |     33.116 |     2.1
   25 |   0.7341 |     24.364 |   1.0021 |     32.682 |     2.2
   26 |   0.7114 |     23.377 |   1.0140 |     32.651 |     2.3
   27 |   0.6932 |     22.931 |   1.0089 |     31.782 |     2.4
   28 |   0.6727 |     22.160 |   1.0096 |     31.254 |     2.5
   29 |   0.6515 |     21.554 |   1.0209 |     31.595 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 326,626

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8709 |     72.116 |   2.0545 |     48.355 |     0.1
    2 |   2.0409 |     48.887 |   1.6469 |     46.586 |     0.2
    3 |   1.7174 |     46.716 |   1.5238 |     45.717 |     0.3
    4 |   1.5953 |     46.292 |   1.4640 |     45.779 |     0.4
    5 |   1.5298 |     46.292 |   1.4276 |     45.717 |     0.5
    6 |   1.4857 |     46.154 |   1.4028 |     45.779 |     0.6
    7 |   1.4524 |     45.835 |   1.3849 |     45.624 |     0.7
    8 |   1.4285 |     45.609 |   1.3614 |     44.817 |     0.9
    9 |   1.4094 |     45.570 |   1.3418 |     44.817 |     1.0
   10 |   1.3923 |     45.339 |   1.3332 |     44.382 |     1.1
   11 |   1.3744 |     45.058 |   1.3170 |     44.134 |     1.2
   12 |   1.3547 |     44.507 |   1.3015 |     43.420 |     1.3
   13 |   1.3415 |     44.435 |   1.2947 |     44.072 |     1.4
   14 |   1.3328 |     44.171 |   1.2823 |     42.955 |     1.5
   15 |   1.3166 |     43.912 |   1.2732 |     42.893 |     1.6
   16 |   1.3121 |     43.917 |   1.2667 |     42.613 |     1.7
   17 |   1.3012 |     43.570 |   1.2592 |     42.831 |     1.8
   18 |   1.2898 |     43.157 |   1.2424 |     42.675 |     1.9
   19 |   1.2798 |     43.118 |   1.2430 |     42.458 |     2.0
   20 |   1.2694 |     42.876 |   1.2334 |     42.055 |     2.1
   21 |   1.2641 |     42.771 |   1.2356 |     42.272 |     2.2
   22 |   1.2511 |     42.314 |   1.2280 |     42.055 |     2.4
   23 |   1.2458 |     41.912 |   1.2114 |     41.403 |     2.5
   24 |   1.2421 |     42.138 |   1.2040 |     40.627 |     2.6
   25 |   1.2317 |     41.642 |   1.2070 |     41.155 |     2.7
   26 |   1.2250 |     41.344 |   1.2049 |     41.496 |     2.8
   27 |   1.2146 |     41.234 |   1.1917 |     41.403 |     2.9
   28 |   1.2101 |     41.179 |   1.1883 |     40.751 |     3.0
   29 |   1.2058 |     41.179 |   1.1810 |     40.844 |     3.1
   30 |   1.1954 |     40.738 |   1.1854 |     41.124 |     3.2
   31 |   1.1895 |     40.551 |   1.1877 |     41.155 |     3.3
   32 |   1.1850 |     40.033 |   1.1821 |     40.441 |     3.4
   33 |   1.1767 |     40.083 |   1.1631 |     40.410 |     3.5
   34 |   1.1708 |     39.752 |   1.1705 |     40.596 |     3.6
   35 |   1.1671 |     39.702 |   1.1808 |     40.689 |     3.7
   36 |   1.1595 |     39.642 |   1.1563 |     39.789 |     3.9
   37 |   1.1528 |     39.466 |   1.1608 |     40.006 |     4.0
   38 |   1.1521 |     39.300 |   1.1486 |     39.044 |     4.1
   39 |   1.1482 |     39.124 |   1.1550 |     39.261 |     4.2
   40 |   1.1344 |     38.975 |   1.1680 |     39.603 |     4.3
   41 |   1.1308 |     38.760 |   1.1548 |     39.696 |     4.4
   42 |   1.1267 |     38.391 |   1.1547 |     39.137 |     4.5
   43 |   1.1199 |     38.446 |   1.1376 |     38.579 |     4.6
   44 |   1.1185 |     38.259 |   1.1415 |     39.168 |     4.7
   45 |   1.1099 |     38.292 |   1.1466 |     38.858 |     4.8
   46 |   1.1077 |     37.873 |   1.1407 |     39.013 |     4.9
   47 |   1.1080 |     37.846 |   1.1406 |     38.827 |     5.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 814,242

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1919 |     55.658 |   1.5244 |     45.282 |     0.1
    2 |   1.5201 |     46.198 |   1.3880 |     45.810 |     0.2
    3 |   1.4090 |     44.937 |   1.3277 |     43.327 |     0.3
    4 |   1.3523 |     44.264 |   1.2925 |     42.706 |     0.5
    5 |   1.3129 |     43.223 |   1.2583 |     42.055 |     0.6
    6 |   1.2746 |     42.066 |   1.2391 |     42.365 |     0.7
    7 |   1.2454 |     41.471 |   1.2204 |     40.441 |     0.8
    8 |   1.2225 |     40.733 |   1.2081 |     40.782 |     0.9
    9 |   1.1968 |     39.884 |   1.1896 |     39.975 |     1.0
   10 |   1.1788 |     39.477 |   1.1697 |     39.789 |     1.1
   11 |   1.1586 |     38.986 |   1.1593 |     38.858 |     1.3
   12 |   1.1384 |     38.441 |   1.1679 |     40.006 |     1.4
   13 |   1.1209 |     37.780 |   1.1374 |     38.672 |     1.5
   14 |   1.1058 |     37.570 |   1.1259 |     38.547 |     1.6
   15 |   1.0933 |     36.755 |   1.1105 |     37.399 |     1.7
   16 |   1.0744 |     36.209 |   1.1160 |     37.958 |     1.8
   17 |   1.0611 |     35.702 |   1.0865 |     36.623 |     1.9
   18 |   1.0445 |     35.433 |   1.0967 |     36.840 |     2.1
   19 |   1.0266 |     34.485 |   1.0961 |     37.368 |     2.2
   20 |   1.0145 |     34.154 |   1.0973 |     36.437 |     2.3
   21 |   1.0018 |     33.565 |   1.0865 |     36.406 |     2.4
   22 |   0.9849 |     33.030 |   1.0880 |     36.747 |     2.5
   23 |   0.9779 |     32.810 |   1.0680 |     35.692 |     2.6
   24 |   0.9631 |     32.204 |   1.0871 |     36.251 |     2.8
   25 |   0.9447 |     31.780 |   1.0695 |     35.537 |     2.9
   26 |   0.9343 |     31.355 |   1.0576 |     35.444 |     3.0
   27 |   0.9164 |     30.551 |   1.0819 |     35.258 |     3.1
   28 |   0.9123 |     30.733 |   1.0472 |     34.482 |     3.2
   29 |   0.8987 |     30.105 |   1.0572 |     34.327 |     3.3
   30 |   0.8790 |     29.344 |   1.0632 |     34.885 |     3.4
   31 |   0.8700 |     29.052 |   1.0689 |     34.792 |     3.6
   32 |   0.8556 |     28.634 |   1.0662 |     34.451 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 277,090

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9569 |     75.802 |   2.3578 |     57.263 |     0.1
    2 |   2.2930 |     54.507 |   1.8272 |     48.324 |     0.2
    3 |   1.8917 |     48.700 |   1.5897 |     46.555 |     0.3
    4 |   1.6807 |     46.755 |   1.5029 |     45.469 |     0.4
    5 |   1.5782 |     46.281 |   1.4501 |     45.655 |     0.5
    6 |   1.5178 |     46.121 |   1.4238 |     45.282 |     0.6
    7 |   1.4781 |     45.906 |   1.3905 |     45.717 |     0.7
    8 |   1.4467 |     45.636 |   1.3701 |     45.034 |     0.8
    9 |   1.4240 |     45.598 |   1.3528 |     43.886 |     1.0
   10 |   1.4050 |     45.229 |   1.3409 |     44.631 |     1.1
   11 |   1.3871 |     45.168 |   1.3248 |     43.855 |     1.2
   12 |   1.3723 |     44.804 |   1.3136 |     43.669 |     1.3
   13 |   1.3604 |     44.711 |   1.2996 |     43.327 |     1.4
   14 |   1.3470 |     44.237 |   1.2924 |     43.513 |     1.5
   15 |   1.3355 |     44.182 |   1.2776 |     42.924 |     1.6
   16 |   1.3226 |     43.559 |   1.2711 |     42.644 |     1.7
   17 |   1.3116 |     43.262 |   1.2609 |     42.086 |     1.8
   18 |   1.3041 |     43.008 |   1.2547 |     41.930 |     1.9
   19 |   1.2910 |     42.843 |   1.2507 |     42.489 |     2.0
   20 |   1.2853 |     42.898 |   1.2402 |     41.620 |     2.1
   21 |   1.2744 |     42.303 |   1.2337 |     41.372 |     2.2
   22 |   1.2692 |     42.441 |   1.2287 |     41.341 |     2.3
   23 |   1.2616 |     42.132 |   1.2263 |     41.589 |     2.4
   24 |   1.2503 |     42.143 |   1.2192 |     41.061 |     2.5
   25 |   1.2474 |     41.691 |   1.2172 |     41.155 |     2.6
   26 |   1.2426 |     41.620 |   1.2105 |     40.658 |     2.7
   27 |   1.2360 |     41.466 |   1.2126 |     40.906 |     2.8
   28 |   1.2328 |     41.405 |   1.2050 |     40.782 |     3.0
   29 |   1.2242 |     40.942 |   1.1974 |     40.689 |     3.1
   30 |   1.2202 |     41.174 |   1.1978 |     40.441 |     3.2
   31 |   1.2111 |     40.843 |   1.1935 |     40.441 |     3.3
   32 |   1.2059 |     40.893 |   1.1932 |     40.534 |     3.4
   33 |   1.1980 |     40.457 |   1.1837 |     40.192 |     3.5
   34 |   1.1976 |     40.562 |   1.1821 |     40.223 |     3.6
   35 |   1.1910 |     40.171 |   1.1811 |     40.286 |     3.7
   36 |   1.1863 |     40.044 |   1.1712 |     39.975 |     3.8
   37 |   1.1837 |     39.923 |   1.1801 |     40.441 |     3.9
   38 |   1.1810 |     39.862 |   1.1772 |     40.161 |     4.0
   39 |   1.1725 |     40.039 |   1.1693 |     39.603 |     4.1
   40 |   1.1668 |     39.526 |   1.1622 |     39.820 |     4.2
   41 |   1.1650 |     39.758 |   1.1672 |     39.727 |     4.3
   42 |   1.1639 |     39.961 |   1.1564 |     39.696 |     4.4
   43 |   1.1574 |     39.052 |   1.1544 |     39.572 |     4.5
   44 |   1.1539 |     39.201 |   1.1494 |     39.385 |     4.6
   45 |   1.1464 |     38.986 |   1.1563 |     39.510 |     4.7
   46 |   1.1437 |     38.837 |   1.1462 |     39.230 |     4.8
   47 |   1.1351 |     38.815 |   1.1510 |     39.137 |     5.0
   48 |   1.1381 |     38.788 |   1.1409 |     38.858 |     5.1
   49 |   1.1291 |     38.601 |   1.1480 |     38.516 |     5.2
   50 |   1.1246 |     38.303 |   1.1429 |     38.796 |     5.3
   51 |   1.1182 |     37.950 |   1.1360 |     39.044 |     5.4
   52 |   1.1140 |     37.796 |   1.1380 |     38.951 |     5.5
   53 |   1.1081 |     37.774 |   1.1382 |     39.013 |     5.6
   54 |   1.1041 |     37.725 |   1.1318 |     38.610 |     5.7
   55 |   1.1026 |     37.769 |   1.1437 |     38.765 |     5.8
   56 |   1.0981 |     37.339 |   1.1352 |     38.516 |     5.9
   57 |   1.0975 |     37.620 |   1.1227 |     38.144 |     6.0
   58 |   1.0941 |     37.543 |   1.1196 |     37.554 |     6.1
   59 |   1.0828 |     36.926 |   1.1168 |     37.523 |     6.2
   60 |   1.0841 |     37.047 |   1.1276 |     38.113 |     6.3
   61 |   1.0779 |     36.986 |   1.1210 |     37.958 |     6.4
   62 |   1.0740 |     36.353 |   1.1279 |     38.020 |     6.5
   63 |   1.0706 |     36.545 |   1.1126 |     36.996 |     6.6
   64 |   1.0687 |     36.490 |   1.1173 |     37.275 |     6.7
   65 |   1.0611 |     36.452 |   1.1186 |     37.399 |     6.8
   66 |   1.0589 |     36.270 |   1.1157 |     37.368 |     6.9
   67 |   1.0576 |     36.198 |   1.1144 |     37.182 |     7.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 243,554

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8698 |     67.190 |   2.3090 |     52.421 |     0.1
    2 |   2.0864 |     49.295 |   1.7207 |     45.748 |     0.3
    3 |   1.7029 |     46.281 |   1.5416 |     45.779 |     0.4
    4 |   1.5649 |     46.088 |   1.4629 |     45.748 |     0.6
    5 |   1.4927 |     45.477 |   1.4177 |     45.779 |     0.8
    6 |   1.4446 |     45.289 |   1.3813 |     45.127 |     0.9
    7 |   1.4091 |     45.140 |   1.3558 |     44.165 |     1.1
    8 |   1.3789 |     44.281 |   1.3275 |     43.048 |     1.2
    9 |   1.3539 |     43.802 |   1.3143 |     42.924 |     1.4
   10 |   1.3358 |     43.207 |   1.2999 |     42.706 |     1.5
   11 |   1.3180 |     43.251 |   1.2778 |     42.241 |     1.7
   12 |   1.2976 |     42.777 |   1.2679 |     41.962 |     1.8
   13 |   1.2822 |     42.364 |   1.2546 |     42.117 |     2.0
   14 |   1.2711 |     41.945 |   1.2389 |     41.868 |     2.1
   15 |   1.2579 |     42.033 |   1.2323 |     41.527 |     2.3
   16 |   1.2465 |     41.614 |   1.2263 |     41.651 |     2.4
   17 |   1.2327 |     41.085 |   1.2213 |     41.744 |     2.6
   18 |   1.2257 |     40.865 |   1.1999 |     40.906 |     2.7
   19 |   1.2127 |     40.468 |   1.1962 |     40.782 |     2.9
   20 |   1.2005 |     40.226 |   1.2001 |     41.310 |     3.0
   21 |   1.1940 |     40.176 |   1.1834 |     40.503 |     3.2
   22 |   1.1880 |     39.928 |   1.1714 |     40.099 |     3.3
   23 |   1.1774 |     39.713 |   1.1745 |     40.627 |     3.5
   24 |   1.1680 |     39.565 |   1.1624 |     39.727 |     3.6
   25 |   1.1612 |     39.157 |   1.1798 |     40.844 |     3.8
   26 |   1.1479 |     39.135 |   1.1514 |     39.479 |     3.9
   27 |   1.1434 |     38.821 |   1.1388 |     39.541 |     4.1
   28 |   1.1355 |     38.782 |   1.1415 |     39.417 |     4.2
   29 |   1.1316 |     38.744 |   1.1326 |     39.199 |     4.4
   30 |   1.1228 |     38.556 |   1.1247 |     38.951 |     4.5
   31 |   1.1144 |     38.028 |   1.1301 |     39.199 |     4.7
   32 |   1.1070 |     37.669 |   1.1292 |     39.541 |     4.8
   33 |   1.1016 |     37.394 |   1.1165 |     38.920 |     5.0
   34 |   1.0930 |     37.218 |   1.1089 |     38.330 |     5.1
   35 |   1.0863 |     37.212 |   1.1027 |     38.858 |     5.3
   36 |   1.0798 |     36.909 |   1.1094 |     38.920 |     5.4
   37 |   1.0750 |     36.722 |   1.1024 |     38.082 |     5.6
   38 |   1.0687 |     36.259 |   1.1009 |     37.896 |     5.7
   39 |   1.0628 |     36.193 |   1.0950 |     38.485 |     5.9
   40 |   1.0619 |     36.072 |   1.0906 |     38.392 |     6.0
   41 |   1.0529 |     35.730 |   1.0931 |     38.268 |     6.2
   42 |   1.0439 |     35.405 |   1.0905 |     38.175 |     6.3
   43 |   1.0401 |     35.515 |   1.0857 |     37.741 |     6.5
   44 |   1.0323 |     35.174 |   1.0924 |     37.616 |     6.6
   45 |   1.0256 |     34.871 |   1.0759 |     37.120 |     6.8
   46 |   1.0196 |     34.501 |   1.0929 |     37.461 |     6.9
   47 |   1.0123 |     34.579 |   1.0848 |     37.430 |     7.1
   48 |   1.0157 |     34.705 |   1.0885 |     37.151 |     7.2
   49 |   1.0054 |     34.264 |   1.0763 |     36.685 |     7.4
   50 |   1.0027 |     34.127 |   1.0719 |     37.058 |     7.5
   51 |   0.9968 |     33.928 |   1.0749 |     37.368 |     7.7
   52 |   0.9935 |     33.515 |   1.0752 |     36.872 |     7.9
   53 |   0.9879 |     33.554 |   1.0715 |     36.654 |     8.0
   54 |   0.9775 |     33.410 |   1.0658 |     36.282 |     8.2
   55 |   0.9712 |     32.887 |   1.0833 |     36.344 |     8.3
   56 |   0.9696 |     32.964 |   1.0687 |     36.406 |     8.5
   57 |   0.9596 |     32.380 |   1.0670 |     36.002 |     8.6
   58 |   0.9605 |     32.876 |   1.0719 |     36.282 |     8.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 582,562

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3465 |     58.391 |   1.6369 |     46.151 |     0.1
    2 |   1.5878 |     45.928 |   1.4191 |     46.027 |     0.2
    3 |   1.4378 |     45.135 |   1.3392 |     43.637 |     0.3
    4 |   1.3669 |     44.050 |   1.2995 |     42.862 |     0.4
    5 |   1.3258 |     43.317 |   1.2681 |     42.334 |     0.5
    6 |   1.2910 |     42.275 |   1.2443 |     41.279 |     0.6
    7 |   1.2638 |     41.945 |   1.2339 |     42.148 |     0.7
    8 |   1.2391 |     41.576 |   1.2057 |     40.441 |     0.8
    9 |   1.2118 |     41.041 |   1.1831 |     40.317 |     0.9
   10 |   1.1926 |     40.259 |   1.1779 |     39.448 |     1.0
   11 |   1.1707 |     39.686 |   1.1837 |     40.596 |     1.1
   12 |   1.1524 |     38.683 |   1.1436 |     38.951 |     1.2
   13 |   1.1322 |     38.077 |   1.1539 |     39.665 |     1.3
   14 |   1.1175 |     37.824 |   1.1416 |     39.261 |     1.4
   15 |   1.0981 |     37.014 |   1.1246 |     38.951 |     1.5
   16 |   1.0861 |     36.738 |   1.1278 |     38.330 |     1.6
   17 |   1.0704 |     36.110 |   1.1264 |     38.485 |     1.7
   18 |   1.0515 |     35.609 |   1.1294 |     37.834 |     1.9
   19 |   1.0370 |     34.815 |   1.0956 |     37.027 |     2.0
   20 |   1.0296 |     35.212 |   1.1078 |     37.399 |     2.1
   21 |   1.0109 |     34.176 |   1.1025 |     37.120 |     2.2
   22 |   0.9994 |     33.730 |   1.0949 |     37.244 |     2.3
   23 |   0.9873 |     33.306 |   1.1018 |     36.592 |     2.4
   24 |   0.9719 |     32.788 |   1.1072 |     36.778 |     2.5
   25 |   0.9560 |     32.397 |   1.0752 |     36.034 |     2.6
   26 |   0.9452 |     31.780 |   1.1049 |     36.592 |     2.7
   27 |   0.9334 |     31.102 |   1.0978 |     36.065 |     2.8
   28 |   0.9216 |     31.008 |   1.0869 |     36.251 |     2.9
   29 |   0.9130 |     30.843 |   1.1153 |     36.499 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 193,122

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7614 |     49.135 |   1.3627 |     45.251 |     0.1
    2 |   1.3368 |     44.760 |   1.2522 |     42.582 |     0.2
    3 |   1.2493 |     42.220 |   1.1965 |     42.117 |     0.3
    4 |   1.1983 |     41.284 |   1.1581 |     39.696 |     0.4
    5 |   1.1562 |     39.972 |   1.1427 |     40.099 |     0.4
    6 |   1.1175 |     38.534 |   1.1033 |     38.299 |     0.5
    7 |   1.0846 |     37.190 |   1.0955 |     37.337 |     0.6
    8 |   1.0527 |     36.083 |   1.0594 |     36.530 |     0.7
    9 |   1.0280 |     35.218 |   1.0613 |     35.878 |     0.8
   10 |   0.9917 |     34.105 |   1.0766 |     36.034 |     0.9
   11 |   0.9750 |     33.355 |   1.0433 |     35.506 |     1.0
   12 |   0.9494 |     32.556 |   1.0451 |     34.513 |     1.1
   13 |   0.9159 |     31.273 |   1.0239 |     34.854 |     1.1
   14 |   0.8922 |     30.579 |   1.0283 |     34.947 |     1.2
   15 |   0.8704 |     29.510 |   1.0352 |     34.885 |     1.3
   16 |   0.8489 |     28.986 |   1.0198 |     34.420 |     1.4
   17 |   0.8242 |     27.967 |   1.0274 |     34.295 |     1.5
   18 |   0.8007 |     27.190 |   1.0480 |     33.985 |     1.6
   19 |   0.7785 |     26.606 |   1.0370 |     33.613 |     1.7
   20 |   0.7603 |     26.099 |   1.0465 |     34.420 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 277,090

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6024 |     60.579 |   1.9697 |     46.617 |     0.1
    2 |   1.7454 |     46.116 |   1.6056 |     45.624 |     0.2
    3 |   1.5420 |     45.124 |   1.4899 |     45.034 |     0.3
    4 |   1.4492 |     44.154 |   1.4239 |     43.513 |     0.4
    5 |   1.3875 |     43.449 |   1.3808 |     43.606 |     0.5
    6 |   1.3440 |     43.047 |   1.3377 |     43.420 |     0.6
    7 |   1.3050 |     41.983 |   1.3094 |     41.930 |     0.7
    8 |   1.2714 |     41.449 |   1.2844 |     42.458 |     0.8
    9 |   1.2441 |     40.893 |   1.2570 |     41.403 |     0.9
   10 |   1.2211 |     40.342 |   1.2328 |     41.186 |     1.0
   11 |   1.2025 |     40.171 |   1.2283 |     41.496 |     1.1
   12 |   1.1822 |     39.625 |   1.2129 |     41.124 |     1.2
   13 |   1.1626 |     39.085 |   1.2162 |     41.030 |     1.3
   14 |   1.1520 |     39.036 |   1.1953 |     40.627 |     1.4
   15 |   1.1325 |     38.342 |   1.1692 |     39.230 |     1.5
   16 |   1.1187 |     37.840 |   1.1739 |     40.037 |     1.6
   17 |   1.1066 |     37.625 |   1.1526 |     38.734 |     1.7
   18 |   1.0927 |     37.350 |   1.1464 |     38.982 |     1.7
   19 |   1.0761 |     36.430 |   1.1292 |     38.237 |     1.8
   20 |   1.0690 |     36.413 |   1.1371 |     39.417 |     1.9
   21 |   1.0564 |     36.160 |   1.1316 |     39.075 |     2.0
   22 |   1.0437 |     35.300 |   1.1192 |     37.616 |     2.1
   23 |   1.0285 |     34.970 |   1.1025 |     37.709 |     2.2
   24 |   1.0192 |     34.573 |   1.1010 |     37.337 |     2.3
   25 |   1.0119 |     34.551 |   1.0929 |     37.058 |     2.4
   26 |   0.9947 |     33.620 |   1.0961 |     37.213 |     2.5
   27 |   0.9842 |     33.245 |   1.0885 |     36.623 |     2.6
   28 |   0.9723 |     32.777 |   1.0976 |     37.306 |     2.7
   29 |   0.9618 |     32.446 |   1.0890 |     36.561 |     2.8
   30 |   0.9511 |     32.110 |   1.0721 |     35.878 |     2.9
   31 |   0.9435 |     31.780 |   1.0785 |     36.375 |     3.0
   32 |   0.9297 |     31.218 |   1.0627 |     35.164 |     3.1
   33 |   0.9177 |     30.942 |   1.0705 |     35.599 |     3.2
   34 |   0.9049 |     30.281 |   1.0727 |     35.723 |     3.3
   35 |   0.9005 |     30.347 |   1.0730 |     35.289 |     3.4
   36 |   0.8870 |     29.923 |   1.0533 |     34.264 |     3.5
   37 |   0.8743 |     29.548 |   1.0508 |     34.482 |     3.6
   38 |   0.8683 |     29.152 |   1.0530 |     34.916 |     3.7
   39 |   0.8555 |     28.871 |   1.0489 |     33.954 |     3.8
   40 |   0.8502 |     28.336 |   1.0544 |     35.040 |     3.9
   41 |   0.8319 |     27.796 |   1.0522 |     34.575 |     4.0
   42 |   0.8244 |     27.658 |   1.0768 |     35.071 |     4.1
   43 |   0.8201 |     27.603 |   1.0503 |     33.954 |     4.2
   44 |   0.8101 |     27.102 |   1.0423 |     34.482 |     4.3
   45 |   0.8028 |     26.953 |   1.0420 |     34.451 |     4.4
   46 |   0.7912 |     26.375 |   1.0606 |     34.544 |     4.5
   47 |   0.7804 |     25.890 |   1.0367 |     33.985 |     4.6
   48 |   0.7692 |     25.631 |   1.0517 |     34.233 |     4.7
   49 |   0.7637 |     25.421 |   1.0479 |     34.295 |     4.8
   50 |   0.7543 |     25.185 |   1.0452 |     33.644 |     4.9
   51 |   0.7478 |     24.937 |   1.0549 |     34.171 |     5.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 235,106

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6520 |     47.978 |   1.3312 |     44.103 |     0.1
    2 |   1.2689 |     42.667 |   1.2356 |     42.210 |     0.1
    3 |   1.1820 |     40.281 |   1.1672 |     39.603 |     0.2
    4 |   1.1169 |     38.612 |   1.1367 |     38.920 |     0.3
    5 |   1.0735 |     37.118 |   1.1108 |     37.865 |     0.3
    6 |   1.0312 |     35.631 |   1.0836 |     37.741 |     0.4
    7 |   0.9985 |     34.474 |   1.0556 |     36.406 |     0.5
    8 |   0.9622 |     32.915 |   1.0376 |     35.475 |     0.5
    9 |   0.9256 |     31.840 |   1.0267 |     34.947 |     0.6
   10 |   0.8961 |     30.534 |   0.9952 |     33.333 |     0.7
   11 |   0.8587 |     29.455 |   1.0028 |     33.799 |     0.7
   12 |   0.8223 |     28.375 |   1.0354 |     34.482 |     0.8
   13 |   0.7931 |     27.245 |   1.0066 |     33.209 |     0.9
   14 |   0.7636 |     26.452 |   0.9591 |     31.906 |     0.9
   15 |   0.7354 |     25.284 |   0.9888 |     32.371 |     1.0
   16 |   0.7213 |     24.430 |   1.0052 |     32.278 |     1.1
   17 |   0.6834 |     23.377 |   0.9725 |     30.757 |     1.1
   18 |   0.6576 |     22.755 |   1.0159 |     32.775 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 425,698

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7320 |     67.868 |   2.0307 |     52.948 |     0.1
    2 |   1.9616 |     49.245 |   1.6237 |     46.151 |     0.2
    3 |   1.6690 |     46.022 |   1.5031 |     45.748 |     0.2
    4 |   1.5636 |     45.912 |   1.4482 |     45.748 |     0.3
    5 |   1.5010 |     45.741 |   1.4111 |     45.500 |     0.4
    6 |   1.4583 |     45.570 |   1.3776 |     45.220 |     0.5
    7 |   1.4305 |     45.631 |   1.3575 |     44.879 |     0.6
    8 |   1.3999 |     45.328 |   1.3305 |     44.413 |     0.7
    9 |   1.3827 |     45.179 |   1.3065 |     43.544 |     0.7
   10 |   1.3564 |     44.639 |   1.2909 |     42.862 |     0.8
   11 |   1.3417 |     43.972 |   1.2732 |     42.024 |     0.9
   12 |   1.3243 |     43.708 |   1.2618 |     42.489 |     1.0
   13 |   1.3089 |     43.653 |   1.2527 |     42.427 |     1.1
   14 |   1.2957 |     43.289 |   1.2554 |     42.644 |     1.2
   15 |   1.2841 |     42.926 |   1.2391 |     42.303 |     1.2
   16 |   1.2712 |     42.380 |   1.2236 |     41.341 |     1.3
   17 |   1.2616 |     42.253 |   1.2219 |     41.651 |     1.4
   18 |   1.2532 |     42.518 |   1.2141 |     40.999 |     1.5
   19 |   1.2408 |     41.565 |   1.2052 |     40.875 |     1.6
   20 |   1.2313 |     41.570 |   1.2106 |     41.620 |     1.7
   21 |   1.2261 |     41.669 |   1.2095 |     41.217 |     1.7
   22 |   1.2217 |     41.466 |   1.1998 |     41.124 |     1.8
   23 |   1.2098 |     41.152 |   1.2032 |     41.217 |     1.9
   24 |   1.2030 |     40.391 |   1.1851 |     40.689 |     2.0
   25 |   1.1981 |     40.485 |   1.1924 |     40.906 |     2.1
   26 |   1.1893 |     40.331 |   1.1762 |     40.658 |     2.2
   27 |   1.1834 |     40.253 |   1.1630 |     39.975 |     2.2
   28 |   1.1757 |     39.945 |   1.1795 |     40.472 |     2.3
   29 |   1.1701 |     39.642 |   1.1677 |     40.130 |     2.4
   30 |   1.1675 |     39.879 |   1.1655 |     40.223 |     2.5
   31 |   1.1611 |     39.581 |   1.1558 |     39.696 |     2.6
   32 |   1.1487 |     39.344 |   1.1733 |     40.192 |     2.7
   33 |   1.1478 |     39.262 |   1.1522 |     40.068 |     2.7
   34 |   1.1414 |     39.058 |   1.1578 |     39.913 |     2.8
   35 |   1.1306 |     38.755 |   1.1419 |     39.075 |     2.9
   36 |   1.1293 |     38.556 |   1.1452 |     39.541 |     3.0
   37 |   1.1256 |     38.419 |   1.1557 |     39.479 |     3.1
   38 |   1.1177 |     38.088 |   1.1572 |     39.696 |     3.2
   39 |   1.1154 |     38.369 |   1.1216 |     38.516 |     3.2
   40 |   1.1120 |     38.105 |   1.1376 |     39.665 |     3.3
   41 |   1.1041 |     37.614 |   1.1272 |     38.734 |     3.4
   42 |   1.0984 |     37.741 |   1.1359 |     38.672 |     3.5
   43 |   1.0922 |     37.675 |   1.1304 |     39.106 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,442,466

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5310 |     47.934 |   1.2997 |     45.282 |     0.1
    2 |   1.2586 |     44.094 |   1.2224 |     42.241 |     0.3
    3 |   1.2002 |     42.534 |   1.1917 |     42.675 |     0.5
    4 |   1.1659 |     42.083 |   1.1797 |     42.613 |     0.6
    5 |   1.1423 |     41.416 |   1.1835 |     42.334 |     0.8
    6 |   1.1285 |     41.284 |   1.1496 |     41.030 |     0.9
    7 |   1.1088 |     40.441 |   1.1420 |     41.899 |     1.1
    8 |   1.0906 |     39.691 |   1.1234 |     40.410 |     1.2
    9 |   1.0775 |     39.592 |   1.1029 |     39.292 |     1.4
   10 |   1.0609 |     38.959 |   1.1024 |     38.796 |     1.6
   11 |   1.0494 |     38.424 |   1.0834 |     37.492 |     1.7
   12 |   1.0394 |     38.242 |   1.0846 |     37.772 |     1.9
   13 |   1.0317 |     37.785 |   1.0660 |     37.989 |     2.0
   14 |   1.0155 |     37.267 |   1.0621 |     38.579 |     2.2
   15 |   1.0044 |     37.074 |   1.0566 |     37.120 |     2.3
   16 |   0.9912 |     36.061 |   1.0572 |     37.616 |     2.5
   17 |   0.9771 |     36.000 |   1.0470 |     36.716 |     2.6
   18 |   0.9708 |     35.488 |   1.0351 |     36.406 |     2.8
   19 |   0.9626 |     34.997 |   1.0336 |     36.282 |     3.0
   20 |   0.9451 |     34.132 |   1.0502 |     37.151 |     3.1
   21 |   0.9273 |     33.559 |   1.0445 |     36.654 |     3.3
   22 |   0.9160 |     33.041 |   1.0202 |     35.475 |     3.4
   23 |   0.9047 |     32.358 |   1.0036 |     34.699 |     3.6
   24 |   0.8857 |     31.934 |   1.0152 |     35.816 |     3.7
   25 |   0.8713 |     31.295 |   0.9779 |     34.358 |     3.9
   26 |   0.8715 |     31.251 |   0.9843 |     33.954 |     4.1
   27 |   0.8481 |     30.309 |   0.9899 |     34.295 |     4.2
   28 |   0.8360 |     30.110 |   0.9758 |     33.892 |     4.4
   29 |   0.8169 |     29.030 |   0.9736 |     32.557 |     4.5
   30 |   0.8104 |     28.744 |   0.9772 |     33.333 |     4.7
   31 |   0.7900 |     28.061 |   0.9703 |     32.682 |     4.8
   32 |   0.7823 |     28.072 |   0.9599 |     31.844 |     5.0
   33 |   0.7708 |     27.185 |   0.9626 |     31.844 |     5.2
   34 |   0.7560 |     27.058 |   0.9511 |     31.564 |     5.3
   35 |   0.7422 |     26.320 |   0.9561 |     31.626 |     5.5
   36 |   0.7312 |     25.769 |   0.9341 |     30.726 |     5.6
   37 |   0.7175 |     25.642 |   0.9543 |     31.782 |     5.8
   38 |   0.7074 |     25.058 |   0.9832 |     31.813 |     5.9
   39 |   0.6928 |     24.672 |   0.9465 |     30.633 |     6.1
   40 |   0.6790 |     23.747 |   0.9290 |     30.385 |     6.2
   41 |   0.6602 |     23.311 |   0.9597 |     31.068 |     6.4
   42 |   0.6624 |     23.471 |   0.9714 |     30.540 |     6.6
   43 |   0.6455 |     22.948 |   0.9752 |     30.788 |     6.7
   44 |   0.6403 |     22.556 |   0.9613 |     30.168 |     6.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 235,106

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8345 |     50.551 |   1.3784 |     45.810 |     0.1
    2 |   1.3766 |     45.163 |   1.3103 |     45.531 |     0.2
    3 |   1.3041 |     43.769 |   1.2305 |     42.458 |     0.3
    4 |   1.2539 |     42.634 |   1.2050 |     41.372 |     0.4
    5 |   1.2194 |     41.780 |   1.1816 |     40.782 |     0.5
    6 |   1.1806 |     40.468 |   1.1631 |     39.975 |     0.6
    7 |   1.1539 |     39.328 |   1.1610 |     39.385 |     0.7
    8 |   1.1306 |     38.826 |   1.1299 |     38.703 |     0.8
    9 |   1.0923 |     37.471 |   1.1268 |     39.013 |     0.9
   10 |   1.0772 |     36.760 |   1.1333 |     39.479 |     1.0
   11 |   1.0426 |     35.669 |   1.1161 |     37.803 |     1.1
   12 |   1.0234 |     34.975 |   1.1050 |     36.685 |     1.2
   13 |   0.9932 |     34.055 |   1.1084 |     36.499 |     1.3
   14 |   0.9735 |     33.394 |   1.1272 |     36.375 |     1.4
   15 |   0.9528 |     32.793 |   1.1052 |     36.251 |     1.5
   16 |   0.9294 |     31.802 |   1.1059 |     36.561 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 814,242

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5156 |     46.821 |   1.2963 |     43.172 |     0.1
    2 |   1.2270 |     42.022 |   1.2111 |     42.117 |     0.2
    3 |   1.1466 |     40.066 |   1.1401 |     39.230 |     0.3
    4 |   1.0739 |     37.554 |   1.1089 |     38.268 |     0.3
    5 |   1.0235 |     35.620 |   1.0972 |     37.741 |     0.4
    6 |   0.9649 |     33.653 |   1.0662 |     37.182 |     0.5
    7 |   0.9169 |     31.653 |   1.0585 |     36.716 |     0.6
    8 |   0.8797 |     30.430 |   1.0547 |     35.971 |     0.7
    9 |   0.8267 |     28.474 |   1.0304 |     33.923 |     0.8
   10 |   0.7919 |     27.080 |   1.0461 |     34.637 |     0.9
   11 |   0.7498 |     25.840 |   1.0314 |     33.706 |     1.0
   12 |   0.7061 |     24.468 |   1.0179 |     32.526 |     1.0
   13 |   0.6704 |     23.058 |   1.1023 |     34.016 |     1.1
   14 |   0.6390 |     22.215 |   1.0564 |     33.271 |     1.2
   15 |   0.5914 |     20.358 |   1.0716 |     32.526 |     1.3
   16 |   0.5654 |     19.405 |   1.0827 |     32.588 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 814,242

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0801 |     52.821 |   1.5172 |     46.182 |     0.1
    2 |   1.4317 |     44.375 |   1.3665 |     44.010 |     0.2
    3 |   1.3222 |     43.102 |   1.3068 |     43.513 |     0.3
    4 |   1.2585 |     41.532 |   1.2432 |     40.751 |     0.4
    5 |   1.2101 |     40.055 |   1.2157 |     40.782 |     0.5
    6 |   1.1711 |     39.074 |   1.1811 |     39.230 |     0.6
    7 |   1.1351 |     38.452 |   1.1628 |     38.889 |     0.7
    8 |   1.1070 |     37.377 |   1.1307 |     38.516 |     0.9
    9 |   1.0780 |     36.656 |   1.1115 |     37.834 |     1.0
   10 |   1.0533 |     35.675 |   1.1114 |     37.709 |     1.1
   11 |   1.0294 |     34.986 |   1.0924 |     36.965 |     1.2
   12 |   1.0017 |     33.978 |   1.0724 |     36.065 |     1.3
   13 |   0.9782 |     32.981 |   1.0575 |     36.065 |     1.4
   14 |   0.9539 |     32.220 |   1.0512 |     35.351 |     1.5
   15 |   0.9335 |     31.592 |   1.0443 |     35.599 |     1.6
   16 |   0.9082 |     30.253 |   1.0382 |     35.071 |     1.7
   17 |   0.8902 |     29.675 |   1.0338 |     34.420 |     1.8
   18 |   0.8627 |     29.047 |   1.0362 |     34.575 |     1.9
   19 |   0.8374 |     27.939 |   1.0311 |     33.768 |     2.0
   20 |   0.8165 |     27.190 |   1.0671 |     34.978 |     2.2
   21 |   0.7929 |     26.468 |   1.0097 |     33.644 |     2.3
   22 |   0.7677 |     25.521 |   1.0117 |     33.426 |     2.4
   23 |   0.7463 |     24.887 |   1.0207 |     33.271 |     2.5
   24 |   0.7202 |     23.824 |   1.0182 |     32.464 |     2.6
   25 |   0.7011 |     23.212 |   1.0248 |     33.520 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 847,522

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6045 |     48.452 |   1.3070 |     45.313 |     0.2
    2 |   1.3217 |     44.926 |   1.2480 |     43.762 |     0.4
    3 |   1.2683 |     44.391 |   1.2116 |     43.762 |     0.5
    4 |   1.2387 |     43.636 |   1.1942 |     42.489 |     0.7
    5 |   1.2120 |     42.937 |   1.1713 |     41.993 |     0.9
    6 |   1.1972 |     42.678 |   1.1704 |     42.737 |     1.1
    7 |   1.1851 |     42.430 |   1.1560 |     41.775 |     1.3
    8 |   1.1703 |     42.083 |   1.1583 |     40.627 |     1.5
    9 |   1.1665 |     42.287 |   1.1577 |     41.713 |     1.7
   10 |   1.1585 |     42.204 |   1.1470 |     41.527 |     1.9
   11 |   1.1526 |     41.785 |   1.1390 |     41.837 |     2.1
   12 |   1.1452 |     41.824 |   1.1297 |     40.720 |     2.2
   13 |   1.1383 |     41.658 |   1.1380 |     40.534 |     2.4
   14 |   1.1343 |     41.587 |   1.1344 |     40.751 |     2.6
   15 |   1.1268 |     41.366 |   1.1336 |     40.720 |     2.8
   16 |   1.1264 |     41.510 |   1.1194 |     39.913 |     3.0
   17 |   1.1209 |     40.992 |   1.1199 |     40.720 |     3.2
   18 |   1.1173 |     41.245 |   1.1289 |     40.782 |     3.3
   19 |   1.1168 |     41.366 |   1.1221 |     39.665 |     3.5
   20 |   1.1096 |     40.788 |   1.1327 |     41.310 |     3.7
   21 |   1.1101 |     41.025 |   1.1170 |     40.037 |     3.9
   22 |   1.1035 |     41.069 |   1.1181 |     39.758 |     4.1
   23 |   1.1065 |     40.926 |   1.1172 |     40.348 |     4.3
   24 |   1.1035 |     41.080 |   1.1113 |     40.006 |     4.5
   25 |   1.1020 |     40.744 |   1.1124 |     41.465 |     4.7
   26 |   1.0972 |     40.623 |   1.1140 |     40.441 |     4.9
   27 |   1.0990 |     41.052 |   1.1171 |     40.161 |     5.1
   28 |   1.0995 |     40.937 |   1.1036 |     40.379 |     5.2
   29 |   1.0959 |     40.788 |   1.1082 |     40.410 |     5.4
   30 |   1.0951 |     40.904 |   1.1100 |     40.099 |     5.6
   31 |   1.0932 |     40.590 |   1.1112 |     40.130 |     5.8
   32 |   1.0894 |     40.474 |   1.1134 |     40.658 |     6.0
   33 |   1.0899 |     40.634 |   1.0984 |     39.882 |     6.2
   34 |   1.0790 |     39.537 |   1.0912 |     39.820 |     6.4
   35 |   1.0741 |     39.543 |   1.0984 |     39.168 |     6.6
   36 |   1.0659 |     38.793 |   1.0932 |     39.075 |     6.8
   37 |   1.0652 |     38.672 |   1.0854 |     38.889 |     7.0
   38 |   1.0542 |     38.584 |   1.0825 |     38.206 |     7.2
   39 |   1.0528 |     38.496 |   1.0732 |     38.361 |     7.4
   40 |   1.0461 |     38.386 |   1.0872 |     39.323 |     7.6
   41 |   1.0413 |     38.017 |   1.0828 |     38.268 |     7.8
   42 |   1.0390 |     37.939 |   1.0917 |     39.572 |     8.0
   43 |   1.0377 |     37.818 |   1.0654 |     37.803 |     8.2
   44 |   1.0318 |     37.691 |   1.0810 |     38.361 |     8.3
   45 |   1.0312 |     37.774 |   1.0769 |     38.641 |     8.5
   46 |   1.0238 |     37.196 |   1.0769 |     38.765 |     8.7
   47 |   1.0189 |     37.284 |   1.0675 |     38.516 |     8.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 193,122

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7980 |     68.242 |   2.2000 |     50.435 |     0.1
    2 |   2.0334 |     48.601 |   1.7156 |     46.027 |     0.1
    3 |   1.7074 |     46.408 |   1.5499 |     45.717 |     0.2
    4 |   1.5761 |     46.050 |   1.4761 |     45.686 |     0.3
    5 |   1.5028 |     45.592 |   1.4272 |     45.562 |     0.3
    6 |   1.4539 |     45.433 |   1.3853 |     44.848 |     0.4
    7 |   1.4149 |     45.140 |   1.3534 |     44.879 |     0.5
    8 |   1.3891 |     45.234 |   1.3331 |     44.041 |     0.5
    9 |   1.3636 |     44.694 |   1.3150 |     43.824 |     0.6
   10 |   1.3435 |     44.479 |   1.2977 |     43.917 |     0.6
   11 |   1.3212 |     44.165 |   1.2852 |     43.575 |     0.7
   12 |   1.3066 |     43.548 |   1.2736 |     43.265 |     0.8
   13 |   1.2935 |     43.207 |   1.2617 |     42.986 |     0.8
   14 |   1.2778 |     42.915 |   1.2569 |     42.520 |     0.9
   15 |   1.2650 |     42.617 |   1.2406 |     41.899 |     1.0
   16 |   1.2548 |     42.424 |   1.2332 |     41.620 |     1.0
   17 |   1.2400 |     41.752 |   1.2196 |     41.279 |     1.1
   18 |   1.2329 |     41.752 |   1.2169 |     41.465 |     1.2
   19 |   1.2175 |     41.372 |   1.2043 |     41.248 |     1.2
   20 |   1.2093 |     40.793 |   1.1960 |     41.155 |     1.3
   21 |   1.1978 |     40.309 |   1.1874 |     40.813 |     1.4
   22 |   1.1865 |     40.242 |   1.1864 |     41.248 |     1.4
   23 |   1.1780 |     40.198 |   1.1746 |     40.503 |     1.5
   24 |   1.1715 |     39.680 |   1.1679 |     40.161 |     1.6
   25 |   1.1657 |     39.851 |   1.1673 |     40.689 |     1.6
   26 |   1.1567 |     39.218 |   1.1670 |     40.379 |     1.7
   27 |   1.1505 |     39.344 |   1.1484 |     39.696 |     1.8
   28 |   1.1434 |     39.036 |   1.1553 |     39.882 |     1.8
   29 |   1.1365 |     38.893 |   1.1502 |     39.230 |     1.9
   30 |   1.1281 |     38.556 |   1.1503 |     39.851 |     1.9
   31 |   1.1260 |     38.342 |   1.1431 |     39.572 |     2.0
   32 |   1.1216 |     38.204 |   1.1398 |     39.168 |     2.1
   33 |   1.1141 |     38.314 |   1.1443 |     39.106 |     2.1
   34 |   1.1121 |     38.077 |   1.1377 |     38.920 |     2.2
   35 |   1.1002 |     37.377 |   1.1271 |     38.765 |     2.3
   36 |   1.0947 |     37.647 |   1.1306 |     39.013 |     2.3
   37 |   1.0936 |     37.576 |   1.1270 |     38.920 |     2.4
   38 |   1.0877 |     37.223 |   1.1302 |     38.920 |     2.5
   39 |   1.0832 |     37.322 |   1.1224 |     38.485 |     2.5
   40 |   1.0772 |     37.113 |   1.1285 |     38.268 |     2.6
   41 |   1.0702 |     37.074 |   1.1207 |     38.392 |     2.7
   42 |   1.0662 |     36.590 |   1.1186 |     38.330 |     2.7
   43 |   1.0663 |     36.562 |   1.1100 |     37.709 |     2.8
   44 |   1.0603 |     36.463 |   1.1165 |     38.454 |     2.9
   45 |   1.0561 |     36.309 |   1.1166 |     38.641 |     2.9
   46 |   1.0526 |     36.160 |   1.1000 |     37.647 |     3.0
   47 |   1.0472 |     36.028 |   1.0989 |     37.554 |     3.1
   48 |   1.0389 |     35.482 |   1.1028 |     37.772 |     3.1
   49 |   1.0351 |     35.708 |   1.0970 |     37.275 |     3.2
   50 |   1.0355 |     35.421 |   1.0987 |     37.089 |     3.2
   51 |   1.0285 |     35.190 |   1.1051 |     37.709 |     3.3
   52 |   1.0273 |     35.328 |   1.0993 |     37.399 |     3.4
   53 |   1.0216 |     35.383 |   1.0928 |     37.492 |     3.4
   54 |   1.0135 |     34.496 |   1.0874 |     37.430 |     3.5
   55 |   1.0187 |     35.146 |   1.0901 |     37.275 |     3.6
   56 |   1.0114 |     34.793 |   1.0903 |     37.554 |     3.6
   57 |   1.0080 |     34.325 |   1.0889 |     37.337 |     3.7
   58 |   0.9997 |     34.072 |   1.0772 |     36.903 |     3.8
   59 |   0.9985 |     34.270 |   1.0861 |     37.896 |     3.8
   60 |   0.9977 |     34.353 |   1.0880 |     37.275 |     3.9
   61 |   0.9888 |     33.945 |   1.0936 |     37.678 |     4.0
   62 |   0.9858 |     33.807 |   1.0784 |     37.554 |     4.0
   63 |   0.9793 |     33.609 |   1.0763 |     37.120 |     4.1
   64 |   0.9791 |     33.697 |   1.0855 |     37.554 |     4.1
   65 |   0.9751 |     33.493 |   1.0781 |     36.934 |     4.2
   66 |   0.9721 |     33.096 |   1.0692 |     36.282 |     4.3
   67 |   0.9702 |     33.388 |   1.0703 |     36.965 |     4.3
   68 |   0.9635 |     33.140 |   1.0787 |     37.275 |     4.4
   69 |   0.9636 |     33.152 |   1.0590 |     36.127 |     4.5
   70 |   0.9597 |     32.826 |   1.0687 |     36.375 |     4.5
   71 |   0.9535 |     32.909 |   1.0771 |     37.275 |     4.6
   72 |   0.9525 |     32.777 |   1.0688 |     36.561 |     4.7
   73 |   0.9489 |     32.446 |   1.0706 |     36.437 |     4.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 292,194

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6243 |     47.752 |   1.3294 |     43.979 |     0.1
    2 |   1.2741 |     43.129 |   1.2281 |     41.496 |     0.2
    3 |   1.1918 |     41.174 |   1.1763 |     41.651 |     0.3
    4 |   1.1352 |     39.758 |   1.1408 |     39.479 |     0.3
    5 |   1.0930 |     38.567 |   1.1118 |     40.130 |     0.4
    6 |   1.0566 |     37.118 |   1.0869 |     37.927 |     0.5
    7 |   1.0167 |     35.868 |   1.0790 |     37.399 |     0.6
    8 |   0.9794 |     34.601 |   1.0656 |     36.872 |     0.7
    9 |   0.9536 |     33.488 |   1.0640 |     36.561 |     0.8
   10 |   0.9205 |     32.171 |   1.0219 |     34.544 |     0.9
   11 |   0.8851 |     31.025 |   1.0301 |     35.351 |     0.9
   12 |   0.8510 |     29.614 |   1.0190 |     34.047 |     1.0
   13 |   0.8199 |     28.766 |   1.0375 |     35.413 |     1.1
   14 |   0.7900 |     27.262 |   1.0451 |     34.482 |     1.2
   15 |   0.7630 |     26.683 |   1.0335 |     33.302 |     1.3
   16 |   0.7248 |     25.102 |   1.0412 |     34.016 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 748,834

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5794 |     48.176 |   1.3019 |     44.910 |     0.1
    2 |   1.3019 |     44.612 |   1.2669 |     44.693 |     0.3
    3 |   1.2586 |     44.165 |   1.2118 |     43.637 |     0.4
    4 |   1.2181 |     42.832 |   1.1896 |     43.637 |     0.6
    5 |   1.1998 |     42.744 |   1.1681 |     41.713 |     0.7
    6 |   1.1821 |     42.298 |   1.1673 |     42.582 |     0.8
    7 |   1.1616 |     41.262 |   1.1681 |     42.831 |     1.0
    8 |   1.1440 |     40.402 |   1.1320 |     39.727 |     1.1
    9 |   1.1298 |     40.204 |   1.1334 |     40.255 |     1.3
   10 |   1.1156 |     39.730 |   1.1214 |     39.944 |     1.4
   11 |   1.1072 |     39.554 |   1.1128 |     39.292 |     1.5
   12 |   1.0974 |     39.190 |   1.1130 |     39.354 |     1.7
   13 |   1.0900 |     38.909 |   1.1038 |     38.703 |     1.8
   14 |   1.0805 |     38.727 |   1.1010 |     39.913 |     2.0
   15 |   1.0694 |     38.281 |   1.0901 |     38.051 |     2.1
   16 |   1.0627 |     38.226 |   1.0880 |     39.075 |     2.2
   17 |   1.0524 |     37.713 |   1.0908 |     38.051 |     2.4
   18 |   1.0430 |     37.680 |   1.0761 |     37.865 |     2.5
   19 |   1.0426 |     37.350 |   1.0738 |     38.330 |     2.7
   20 |   1.0360 |     37.444 |   1.0925 |     38.982 |     2.8
   21 |   1.0293 |     37.019 |   1.0626 |     37.337 |     2.9
   22 |   1.0224 |     36.523 |   1.0726 |     37.896 |     3.1
   23 |   1.0193 |     36.479 |   1.0694 |     37.834 |     3.2
   24 |   1.0066 |     36.160 |   1.0675 |     37.275 |     3.4
   25 |   1.0021 |     35.813 |   1.0782 |     37.585 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 898,274

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5409 |     47.537 |   1.2776 |     43.575 |     0.2
    2 |   1.2459 |     43.350 |   1.2174 |     43.700 |     0.4
    3 |   1.1688 |     41.074 |   1.1609 |     40.565 |     0.6
    4 |   1.1214 |     39.884 |   1.1280 |     40.006 |     0.7
    5 |   1.0762 |     38.793 |   1.1031 |     38.796 |     0.9
    6 |   1.0440 |     37.069 |   1.0960 |     38.858 |     1.1
    7 |   1.0238 |     36.749 |   1.0933 |     38.641 |     1.3
    8 |   1.0037 |     36.264 |   1.0433 |     36.934 |     1.5
    9 |   0.9733 |     35.080 |   1.0529 |     36.903 |     1.7
   10 |   0.9526 |     34.264 |   1.0642 |     36.002 |     1.9
   11 |   0.9400 |     33.802 |   1.0434 |     36.530 |     2.0
   12 |   0.9338 |     33.708 |   1.0420 |     36.747 |     2.2
   13 |   0.9220 |     32.634 |   1.0562 |     36.468 |     2.4
   14 |   0.9050 |     32.551 |   1.0353 |     35.785 |     2.6
   15 |   0.8824 |     31.306 |   1.0271 |     36.158 |     2.8
   16 |   0.8667 |     31.080 |   1.0280 |     34.916 |     3.0
   17 |   0.8481 |     30.320 |   1.0424 |     34.761 |     3.2
   18 |   0.8237 |     29.207 |   1.0142 |     35.599 |     3.4
   19 |   0.8172 |     29.278 |   1.0209 |     35.133 |     3.6
   20 |   0.7862 |     27.950 |   1.0375 |     34.792 |     3.8
   21 |   0.7773 |     27.725 |   1.0424 |     34.389 |     4.0
   22 |   0.7659 |     27.229 |   1.0480 |     33.923 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 978,722

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5167 |     48.127 |   1.2742 |     42.768 |     0.1
    2 |   1.2325 |     42.474 |   1.1994 |     41.465 |     0.2
    3 |   1.1539 |     40.342 |   1.1559 |     41.558 |     0.3
    4 |   1.0954 |     38.435 |   1.1170 |     39.417 |     0.5
    5 |   1.0424 |     36.634 |   1.1115 |     38.547 |     0.6
    6 |   0.9947 |     34.837 |   1.0901 |     36.996 |     0.7
    7 |   0.9535 |     33.295 |   1.0631 |     35.723 |     0.8
    8 |   0.9047 |     31.598 |   1.0388 |     34.854 |     0.9
    9 |   0.8663 |     30.259 |   1.0355 |     35.351 |     1.0
   10 |   0.8349 |     28.771 |   1.0177 |     34.233 |     1.2
   11 |   0.7873 |     27.118 |   1.0097 |     33.240 |     1.3
   12 |   0.7460 |     25.581 |   1.0272 |     34.699 |     1.4
   13 |   0.7190 |     24.997 |   1.0074 |     32.464 |     1.5
   14 |   0.6814 |     23.466 |   1.0230 |     32.402 |     1.6
   15 |   0.6362 |     21.884 |   1.0257 |     32.340 |     1.7
   16 |   0.5942 |     20.237 |   1.0782 |     32.775 |     1.8
   17 |   0.5470 |     18.788 |   1.0525 |     31.750 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 732,002

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6881 |     49.912 |   1.3278 |     45.376 |     0.1
    2 |   1.3210 |     44.353 |   1.2491 |     42.986 |     0.2
    3 |   1.2468 |     42.424 |   1.2419 |     42.334 |     0.3
    4 |   1.2037 |     41.069 |   1.1751 |     40.255 |     0.5
    5 |   1.1598 |     39.410 |   1.1598 |     40.782 |     0.6
    6 |   1.1290 |     38.904 |   1.1626 |     38.951 |     0.7
    7 |   1.0922 |     37.427 |   1.1364 |     38.020 |     0.8
    8 |   1.0628 |     36.441 |   1.1398 |     38.858 |     0.9
    9 |   1.0354 |     35.278 |   1.0965 |     37.523 |     1.1
   10 |   1.0024 |     34.215 |   1.1264 |     37.958 |     1.2
   11 |   0.9720 |     33.030 |   1.1204 |     36.282 |     1.3
   12 |   0.9442 |     32.623 |   1.0897 |     36.034 |     1.4
   13 |   0.9246 |     31.901 |   1.0942 |     35.785 |     1.5
   14 |   0.8955 |     30.815 |   1.1021 |     36.065 |     1.6
   15 |   0.8686 |     29.713 |   1.0977 |     34.668 |     1.8
   16 |   0.8335 |     28.287 |   1.1294 |     34.637 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 277,090

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7848 |     50.518 |   1.3650 |     44.724 |     0.1
    2 |   1.3502 |     44.678 |   1.2770 |     42.831 |     0.2
    3 |   1.2739 |     43.196 |   1.2169 |     43.017 |     0.3
    4 |   1.2123 |     41.554 |   1.2029 |     40.999 |     0.5
    5 |   1.1713 |     40.226 |   1.1387 |     39.137 |     0.6
    6 |   1.1401 |     39.427 |   1.1340 |     39.975 |     0.7
    7 |   1.0990 |     37.780 |   1.1338 |     38.920 |     0.8
    8 |   1.0714 |     37.014 |   1.0780 |     37.058 |     0.9
    9 |   1.0353 |     35.504 |   1.0642 |     35.940 |     1.1
   10 |   1.0195 |     35.102 |   1.0740 |     36.778 |     1.2
   11 |   0.9803 |     33.862 |   1.0530 |     35.661 |     1.3
   12 |   0.9565 |     32.915 |   1.0497 |     35.227 |     1.4
   13 |   0.9279 |     31.780 |   1.0429 |     35.196 |     1.5
   14 |   0.9131 |     31.333 |   1.0242 |     34.854 |     1.7
   15 |   0.8794 |     30.309 |   1.0166 |     34.078 |     1.8
   16 |   0.8573 |     29.388 |   0.9993 |     32.961 |     1.9
   17 |   0.8345 |     29.118 |   0.9922 |     32.030 |     2.0
   18 |   0.8089 |     27.708 |   1.0474 |     33.271 |     2.1
   19 |   0.7933 |     27.190 |   0.9932 |     32.588 |     2.2
   20 |   0.7585 |     26.033 |   1.0510 |     32.619 |     2.3
   21 |   0.7434 |     25.879 |   1.0966 |     34.637 |     2.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 285,538

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9107 |     52.882 |   1.4093 |     45.779 |     0.1
    2 |   1.4178 |     46.397 |   1.3389 |     45.438 |     0.2
    3 |   1.3520 |     45.251 |   1.3000 |     43.731 |     0.4
    4 |   1.3073 |     44.590 |   1.2697 |     44.072 |     0.5
    5 |   1.2795 |     43.774 |   1.2334 |     42.272 |     0.6
    6 |   1.2477 |     42.810 |   1.2133 |     42.055 |     0.7
    7 |   1.2322 |     42.397 |   1.1866 |     41.651 |     0.8
    8 |   1.2063 |     41.565 |   1.2010 |     42.303 |     0.9
    9 |   1.1887 |     41.328 |   1.1698 |     41.061 |     1.1
   10 |   1.1741 |     40.782 |   1.1421 |     39.820 |     1.2
   11 |   1.1545 |     40.523 |   1.2112 |     41.651 |     1.3
   12 |   1.1356 |     39.306 |   1.1308 |     38.827 |     1.4
   13 |   1.1240 |     38.810 |   1.1455 |     39.820 |     1.5
   14 |   1.1146 |     38.667 |   1.1482 |     40.348 |     1.7
   15 |   1.1041 |     38.375 |   1.1199 |     38.703 |     1.8
   16 |   1.0936 |     38.237 |   1.1357 |     39.137 |     1.9
   17 |   1.0853 |     37.780 |   1.1382 |     39.510 |     2.0
   18 |   1.0717 |     37.581 |   1.1357 |     39.975 |     2.1
   19 |   1.0524 |     36.579 |   1.1162 |     39.168 |     2.3
   20 |   1.0412 |     36.193 |   1.1380 |     39.137 |     2.4
   21 |   1.0356 |     35.884 |   1.1726 |     40.441 |     2.5
   22 |   1.0311 |     35.499 |   1.0971 |     38.144 |     2.6
   23 |   1.0134 |     35.377 |   1.1013 |     37.678 |     2.7
   24 |   1.0022 |     34.584 |   1.1178 |     38.175 |     2.8
   25 |   0.9951 |     34.716 |   1.1166 |     38.579 |     3.0
   26 |   0.9852 |     34.160 |   1.1000 |     38.423 |     3.1
   27 |   0.9757 |     33.901 |   1.0786 |     37.058 |     3.2
   28 |   0.9642 |     33.565 |   1.1198 |     38.361 |     3.3
   29 |   0.9563 |     33.267 |   1.1130 |     38.547 |     3.4
   30 |   0.9555 |     33.537 |   1.1202 |     39.199 |     3.6
   31 |   0.9415 |     32.496 |   1.1211 |     38.051 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 748,834

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4775 |     59.603 |   1.7403 |     48.324 |     0.1
    2 |   1.6966 |     46.501 |   1.4555 |     46.151 |     0.3
    3 |   1.4949 |     45.455 |   1.3875 |     45.313 |     0.4
    4 |   1.4172 |     45.107 |   1.3264 |     44.351 |     0.6
    5 |   1.3677 |     44.446 |   1.2958 |     43.296 |     0.7
    6 |   1.3356 |     43.829 |   1.2746 |     42.955 |     0.9
    7 |   1.3064 |     43.201 |   1.2518 |     41.868 |     1.0
    8 |   1.2865 |     43.036 |   1.2416 |     41.993 |     1.1
    9 |   1.2694 |     42.364 |   1.2362 |     42.024 |     1.3
   10 |   1.2538 |     42.176 |   1.2357 |     41.930 |     1.4
   11 |   1.2368 |     41.471 |   1.2124 |     41.434 |     1.6
   12 |   1.2244 |     41.421 |   1.2166 |     41.372 |     1.7
   13 |   1.2122 |     41.295 |   1.1906 |     40.596 |     1.9
   14 |   1.2036 |     40.667 |   1.2136 |     41.651 |     2.0
   15 |   1.1883 |     40.358 |   1.2071 |     40.689 |     2.1
   16 |   1.1766 |     40.270 |   1.1991 |     40.689 |     2.3
   17 |   1.1656 |     40.077 |   1.2016 |     40.223 |     2.4
   18 |   1.1560 |     39.444 |   1.1618 |     39.727 |     2.6
   19 |   1.1486 |     39.339 |   1.1863 |     40.565 |     2.7
   20 |   1.1374 |     38.964 |   1.1711 |     40.006 |     2.9
   21 |   1.1246 |     37.989 |   1.1651 |     39.603 |     3.0
   22 |   1.1169 |     38.149 |   1.1489 |     39.448 |     3.2
   23 |   1.1066 |     37.410 |   1.1345 |     39.013 |     3.3
   24 |   1.1000 |     37.780 |   1.1516 |     39.137 |     3.4
   25 |   1.0914 |     37.118 |   1.1667 |     39.634 |     3.6
   26 |   1.0825 |     37.289 |   1.1342 |     38.796 |     3.7
   27 |   1.0727 |     36.639 |   1.1378 |     38.206 |     3.9
   28 |   1.0683 |     36.353 |   1.1562 |     38.641 |     4.0
   29 |   1.0618 |     35.901 |   1.1489 |     38.951 |     4.1
   30 |   1.0525 |     35.763 |   1.1317 |     38.330 |     4.3
   31 |   1.0403 |     35.256 |   1.1286 |     38.485 |     4.4
   32 |   1.0376 |     35.350 |   1.1368 |     37.958 |     4.6
   33 |   1.0257 |     34.887 |   1.1362 |     38.175 |     4.7
   34 |   1.0170 |     34.562 |   1.1324 |     37.989 |     4.9
   35 |   1.0158 |     34.711 |   1.1470 |     38.268 |     5.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,013,410

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0509 |     52.171 |   1.5016 |     45.469 |     0.2
    2 |   1.4194 |     44.601 |   1.3730 |     44.507 |     0.4
    3 |   1.3277 |     43.135 |   1.3064 |     43.731 |     0.5
    4 |   1.2682 |     42.083 |   1.2544 |     41.962 |     0.7
    5 |   1.2207 |     40.672 |   1.2191 |     40.875 |     0.9
    6 |   1.1796 |     39.769 |   1.1972 |     39.820 |     1.1
    7 |   1.1473 |     38.843 |   1.1854 |     40.223 |     1.3
    8 |   1.1133 |     37.587 |   1.1561 |     38.920 |     1.4
    9 |   1.0874 |     36.733 |   1.1369 |     39.075 |     1.6
   10 |   1.0535 |     35.879 |   1.1187 |     38.113 |     1.8
   11 |   1.0262 |     34.992 |   1.1047 |     37.803 |     2.0
   12 |   1.0035 |     33.774 |   1.1060 |     37.585 |     2.2
   13 |   0.9685 |     32.507 |   1.0840 |     36.840 |     2.3
   14 |   0.9353 |     31.113 |   1.0654 |     35.661 |     2.5
   15 |   0.9054 |     30.325 |   1.0734 |     35.506 |     2.7
   16 |   0.8796 |     29.289 |   1.0420 |     34.420 |     2.9
   17 |   0.8475 |     28.248 |   1.0398 |     35.164 |     3.1
   18 |   0.8123 |     26.656 |   1.0550 |     35.102 |     3.3
   19 |   0.7828 |     25.846 |   1.0434 |     34.047 |     3.4
   20 |   0.7477 |     24.309 |   1.0292 |     33.861 |     3.6
   21 |   0.7242 |     23.631 |   1.0408 |     34.171 |     3.8
   22 |   0.6913 |     22.364 |   1.0501 |     33.675 |     4.0
   23 |   0.6670 |     21.730 |   1.0570 |     33.613 |     4.2
   24 |   0.6326 |     20.380 |   1.0573 |     33.706 |     4.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 748,834

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5999 |     48.132 |   1.3323 |     46.027 |     0.1
    2 |   1.3479 |     46.397 |   1.2870 |     45.003 |     0.3
    3 |   1.2989 |     45.256 |   1.2489 |     45.779 |     0.4
    4 |   1.2646 |     44.749 |   1.2116 |     42.458 |     0.6
    5 |   1.2359 |     43.609 |   1.2008 |     42.582 |     0.7
    6 |   1.2251 |     43.675 |   1.2077 |     44.382 |     0.9
    7 |   1.2101 |     43.251 |   1.1885 |     42.365 |     1.0
    8 |   1.2014 |     42.964 |   1.1771 |     40.751 |     1.2
    9 |   1.1885 |     42.799 |   1.1697 |     40.875 |     1.3
   10 |   1.1844 |     42.992 |   1.1666 |     41.837 |     1.5
   11 |   1.1720 |     42.534 |   1.1609 |     41.434 |     1.6
   12 |   1.1637 |     42.138 |   1.1618 |     41.837 |     1.7
   13 |   1.1623 |     42.242 |   1.1734 |     43.358 |     1.9
   14 |   1.1529 |     41.967 |   1.1499 |     40.999 |     2.1
   15 |   1.1474 |     41.691 |   1.1599 |     43.358 |     2.2
   16 |   1.1488 |     42.044 |   1.1610 |     41.155 |     2.4
   17 |   1.1457 |     41.895 |   1.1406 |     40.689 |     2.5
   18 |   1.1368 |     41.526 |   1.1524 |     41.030 |     2.7
   19 |   1.1404 |     41.653 |   1.1382 |     40.782 |     2.8
   20 |   1.1336 |     41.372 |   1.1286 |     41.061 |     3.0
   21 |   1.1330 |     41.460 |   1.1322 |     41.682 |     3.1
   22 |   1.1320 |     41.669 |   1.1318 |     41.061 |     3.3
   23 |   1.1276 |     41.510 |   1.1245 |     40.999 |     3.4
   24 |   1.1240 |     41.455 |   1.1387 |     40.751 |     3.6
   25 |   1.1283 |     41.499 |   1.1250 |     40.534 |     3.7
   26 |   1.1190 |     40.981 |   1.1240 |     40.317 |     3.8
   27 |   1.1134 |     40.391 |   1.1060 |     39.603 |     4.0
   28 |   1.1079 |     40.242 |   1.1079 |     39.975 |     4.1
   29 |   1.0962 |     39.961 |   1.1089 |     38.827 |     4.3
   30 |   1.0981 |     39.741 |   1.1088 |     39.137 |     4.4
   31 |   1.0936 |     39.669 |   1.1015 |     39.510 |     4.6
   32 |   1.0900 |     39.620 |   1.0951 |     39.261 |     4.7
   33 |   1.0855 |     39.383 |   1.0857 |     37.989 |     4.8
   34 |   1.0751 |     38.656 |   1.0787 |     37.958 |     5.0
   35 |   1.0752 |     38.926 |   1.0917 |     39.665 |     5.1
   36 |   1.0749 |     38.915 |   1.0833 |     38.982 |     5.3
   37 |   1.0687 |     38.848 |   1.0652 |     37.834 |     5.4
   38 |   1.0582 |     38.193 |   1.0853 |     38.641 |     5.6
   39 |   1.0550 |     38.143 |   1.1262 |     40.813 |     5.7
   40 |   1.0595 |     38.364 |   1.0714 |     38.454 |     5.8
   41 |   1.0523 |     38.061 |   1.0744 |     37.803 |     6.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 732,002

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2707 |     57.449 |   1.5829 |     46.276 |     0.1
    2 |   1.5528 |     46.198 |   1.4017 |     45.469 |     0.2
    3 |   1.4176 |     45.185 |   1.3329 |     44.507 |     0.4
    4 |   1.3538 |     43.675 |   1.2919 |     42.489 |     0.5
    5 |   1.3105 |     42.959 |   1.2563 |     41.868 |     0.6
    6 |   1.2806 |     42.612 |   1.2372 |     41.837 |     0.7
    7 |   1.2493 |     41.609 |   1.2176 |     41.403 |     0.9
    8 |   1.2242 |     40.865 |   1.1980 |     41.092 |     1.0
    9 |   1.1991 |     40.397 |   1.1930 |     40.565 |     1.1
   10 |   1.1805 |     39.879 |   1.1596 |     39.510 |     1.2
   11 |   1.1595 |     39.289 |   1.1509 |     39.510 |     1.3
   12 |   1.1479 |     39.091 |   1.1346 |     39.354 |     1.5
   13 |   1.1235 |     38.364 |   1.1177 |     38.361 |     1.6
   14 |   1.1116 |     38.061 |   1.1137 |     39.137 |     1.7
   15 |   1.0952 |     37.273 |   1.1100 |     38.796 |     1.8
   16 |   1.0755 |     36.446 |   1.0979 |     38.175 |     1.9
   17 |   1.0632 |     35.939 |   1.0938 |     38.175 |     2.0
   18 |   1.0462 |     35.570 |   1.0889 |     37.772 |     2.1
   19 |   1.0313 |     34.953 |   1.0761 |     37.306 |     2.3
   20 |   1.0223 |     34.584 |   1.0781 |     37.709 |     2.4
   21 |   1.0083 |     33.752 |   1.0654 |     37.151 |     2.5
   22 |   0.9887 |     33.229 |   1.0624 |     36.530 |     2.6
   23 |   0.9793 |     33.003 |   1.0545 |     36.158 |     2.7
   24 |   0.9661 |     32.457 |   1.0448 |     36.034 |     2.8
   25 |   0.9504 |     31.862 |   1.0556 |     35.971 |     3.0
   26 |   0.9370 |     31.565 |   1.0538 |     35.816 |     3.1
   27 |   0.9274 |     31.140 |   1.0471 |     35.723 |     3.2
   28 |   0.9093 |     30.507 |   1.0419 |     35.164 |     3.3
   29 |   0.8988 |     29.901 |   1.0426 |     34.823 |     3.5
   30 |   0.8839 |     29.631 |   1.0430 |     34.699 |     3.6
   31 |   0.8763 |     29.587 |   1.0445 |     34.730 |     3.7
   32 |   0.8588 |     28.777 |   1.0428 |     34.606 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 392,162

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6706 |     63.030 |   1.9350 |     46.151 |     0.1
    2 |   1.8196 |     46.358 |   1.5889 |     46.151 |     0.2
    3 |   1.6035 |     45.725 |   1.4804 |     44.786 |     0.4
    4 |   1.5041 |     44.848 |   1.4266 |     44.569 |     0.5
    5 |   1.4479 |     44.518 |   1.3842 |     43.544 |     0.6
    6 |   1.4066 |     44.182 |   1.3592 |     43.513 |     0.7
    7 |   1.3784 |     44.000 |   1.3308 |     43.172 |     0.8
    8 |   1.3532 |     43.565 |   1.3151 |     42.893 |     1.0
    9 |   1.3285 |     43.179 |   1.3021 |     43.141 |     1.1
   10 |   1.3061 |     42.512 |   1.2933 |     43.420 |     1.2
   11 |   1.2907 |     42.231 |   1.2648 |     42.210 |     1.3
   12 |   1.2731 |     41.862 |   1.2675 |     42.427 |     1.4
   13 |   1.2586 |     41.344 |   1.2474 |     41.310 |     1.5
   14 |   1.2440 |     40.887 |   1.2450 |     42.303 |     1.6
   15 |   1.2303 |     40.760 |   1.2176 |     40.782 |     1.8
   16 |   1.2155 |     40.105 |   1.2195 |     40.782 |     1.9
   17 |   1.2031 |     39.807 |   1.1976 |     40.441 |     2.0
   18 |   1.1909 |     39.570 |   1.1933 |     40.317 |     2.1
   19 |   1.1789 |     39.322 |   1.1889 |     40.192 |     2.2
   20 |   1.1681 |     39.311 |   1.1656 |     40.068 |     2.3
   21 |   1.1597 |     38.705 |   1.1776 |     40.317 |     2.5
   22 |   1.1503 |     38.898 |   1.1573 |     40.006 |     2.6
   23 |   1.1414 |     38.198 |   1.1538 |     39.727 |     2.7
   24 |   1.1312 |     38.386 |   1.1453 |     39.603 |     2.8
   25 |   1.1179 |     37.526 |   1.1512 |     40.037 |     2.9
   26 |   1.1132 |     37.923 |   1.1229 |     39.168 |     3.0
   27 |   1.1034 |     37.394 |   1.1298 |     39.385 |     3.1
   28 |   1.0933 |     37.537 |   1.1304 |     39.137 |     3.2
   29 |   1.0822 |     36.771 |   1.1180 |     38.454 |     3.4
   30 |   1.0752 |     36.650 |   1.1202 |     38.703 |     3.5
   31 |   1.0686 |     36.138 |   1.1000 |     37.958 |     3.6
   32 |   1.0589 |     36.088 |   1.0996 |     38.485 |     3.7
   33 |   1.0499 |     35.405 |   1.0869 |     37.585 |     3.8
   34 |   1.0506 |     35.664 |   1.1055 |     38.610 |     3.9
   35 |   1.0395 |     35.300 |   1.0877 |     37.461 |     4.1
   36 |   1.0370 |     35.118 |   1.0795 |     37.213 |     4.2
   37 |   1.0245 |     34.887 |   1.0819 |     37.927 |     4.3
   38 |   1.0190 |     34.369 |   1.0626 |     36.778 |     4.4
   39 |   1.0113 |     34.490 |   1.0915 |     37.554 |     4.5
   40 |   1.0060 |     34.242 |   1.0783 |     36.685 |     4.6
   41 |   1.0023 |     33.928 |   1.0677 |     36.903 |     4.8
   42 |   0.9928 |     33.603 |   1.0972 |     37.616 |     4.9
   43 |   0.9875 |     33.598 |   1.0563 |     36.375 |     5.0
   44 |   0.9795 |     33.416 |   1.0602 |     35.940 |     5.1
   45 |   0.9720 |     33.036 |   1.0648 |     36.282 |     5.2
   46 |   0.9699 |     32.871 |   1.0542 |     35.878 |     5.3
   47 |   0.9652 |     33.019 |   1.0649 |     36.716 |     5.5
   48 |   0.9563 |     32.678 |   1.0460 |     35.537 |     5.6
   49 |   0.9523 |     32.342 |   1.0525 |     36.127 |     5.7
   50 |   0.9481 |     32.650 |   1.0675 |     36.375 |     5.8
   51 |   0.9407 |     31.890 |   1.0518 |     35.723 |     5.9
   52 |   0.9402 |     31.868 |   1.0445 |     36.127 |     6.0
   53 |   0.9298 |     31.471 |   1.0408 |     36.127 |     6.2
   54 |   0.9250 |     31.339 |   1.0481 |     36.002 |     6.3
   55 |   0.9217 |     31.157 |   1.0407 |     35.444 |     6.4
   56 |   0.9195 |     31.366 |   1.0248 |     34.575 |     6.5
   57 |   0.9108 |     31.174 |   1.0375 |     35.071 |     6.6
   58 |   0.9036 |     30.628 |   1.0528 |     35.692 |     6.7
   59 |   0.9056 |     30.876 |   1.0379 |     34.978 |     6.9
   60 |   0.8957 |     30.479 |   1.0335 |     34.420 |     7.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 235,106

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6420 |     62.275 |   1.9732 |     47.052 |     0.1
    2 |   1.7569 |     45.642 |   1.6097 |     45.562 |     0.1
    3 |   1.5485 |     45.069 |   1.4892 |     44.475 |     0.2
    4 |   1.4572 |     44.248 |   1.4208 |     44.196 |     0.3
    5 |   1.3989 |     43.614 |   1.3798 |     44.134 |     0.3
    6 |   1.3588 |     43.196 |   1.3483 |     43.482 |     0.4
    7 |   1.3261 |     42.474 |   1.3365 |     44.134 |     0.5
    8 |   1.2986 |     42.033 |   1.3066 |     43.451 |     0.6
    9 |   1.2757 |     41.311 |   1.2941 |     43.234 |     0.6
   10 |   1.2561 |     41.262 |   1.2658 |     42.334 |     0.7
   11 |   1.2359 |     40.441 |   1.2535 |     41.403 |     0.8
   12 |   1.2175 |     40.149 |   1.2259 |     40.937 |     0.8
   13 |   1.2049 |     39.983 |   1.2251 |     41.682 |     0.9
   14 |   1.1854 |     39.471 |   1.2031 |     40.751 |     1.0
   15 |   1.1692 |     39.014 |   1.1962 |     40.782 |     1.0
   16 |   1.1558 |     38.815 |   1.1920 |     40.410 |     1.1
   17 |   1.1417 |     38.198 |   1.1734 |     39.696 |     1.2
   18 |   1.1287 |     37.890 |   1.1566 |     39.323 |     1.3
   19 |   1.1161 |     37.262 |   1.1828 |     40.472 |     1.3
   20 |   1.1028 |     36.788 |   1.1559 |     38.920 |     1.4
   21 |   1.0913 |     36.650 |   1.1585 |     39.044 |     1.5
   22 |   1.0776 |     35.697 |   1.1518 |     39.044 |     1.6
   23 |   1.0695 |     35.950 |   1.1209 |     37.989 |     1.6
   24 |   1.0583 |     35.174 |   1.1287 |     37.958 |     1.7
   25 |   1.0478 |     34.882 |   1.1272 |     38.237 |     1.8
   26 |   1.0365 |     34.358 |   1.1428 |     38.268 |     1.8
   27 |   1.0244 |     34.077 |   1.1046 |     37.461 |     1.9
   28 |   1.0134 |     33.592 |   1.1163 |     37.647 |     2.0
   29 |   1.0018 |     33.273 |   1.0934 |     36.747 |     2.1
   30 |   0.9922 |     32.766 |   1.0920 |     36.872 |     2.1
   31 |   0.9783 |     32.485 |   1.0962 |     36.778 |     2.2
   32 |   0.9672 |     31.978 |   1.0944 |     36.127 |     2.3
   33 |   0.9622 |     31.780 |   1.0835 |     36.189 |     2.3
   34 |   0.9490 |     31.570 |   1.0815 |     35.723 |     2.4
   35 |   0.9421 |     30.926 |   1.0863 |     35.599 |     2.5
   36 |   0.9322 |     30.815 |   1.0711 |     35.754 |     2.6
   37 |   0.9210 |     30.479 |   1.0642 |     35.754 |     2.6
   38 |   0.9148 |     30.138 |   1.0630 |     35.661 |     2.7
   39 |   0.9033 |     29.923 |   1.0780 |     35.909 |     2.8
   40 |   0.8954 |     29.763 |   1.0582 |     35.102 |     2.8
   41 |   0.8858 |     29.460 |   1.0555 |     34.978 |     2.9
   42 |   0.8778 |     29.036 |   1.0636 |     34.854 |     3.0
   43 |   0.8691 |     28.645 |   1.0508 |     34.420 |     3.1
   44 |   0.8617 |     28.121 |   1.0656 |     35.506 |     3.1
   45 |   0.8542 |     28.331 |   1.0454 |     34.202 |     3.2
   46 |   0.8407 |     27.741 |   1.0689 |     34.761 |     3.3
   47 |   0.8361 |     27.537 |   1.0778 |     35.878 |     3.3
   48 |   0.8232 |     27.069 |   1.0568 |     34.482 |     3.4
   49 |   0.8213 |     26.981 |   1.0592 |     34.171 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 582,562

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5974 |     47.923 |   1.3190 |     44.724 |     0.1
    2 |   1.3039 |     44.099 |   1.2509 |     41.993 |     0.2
    3 |   1.2408 |     42.375 |   1.2353 |     41.558 |     0.3
    4 |   1.1956 |     41.218 |   1.1558 |     40.223 |     0.4
    5 |   1.1608 |     39.939 |   1.1623 |     40.689 |     0.5
    6 |   1.1334 |     39.212 |   1.1559 |     39.261 |     0.7
    7 |   1.1072 |     38.242 |   1.1416 |     38.951 |     0.8
    8 |   1.0849 |     37.416 |   1.1042 |     37.865 |     0.9
    9 |   1.0608 |     36.380 |   1.1046 |     37.244 |     1.0
   10 |   1.0365 |     36.386 |   1.0979 |     37.678 |     1.1
   11 |   1.0150 |     34.909 |   1.0887 |     36.840 |     1.2
   12 |   0.9938 |     34.193 |   1.0836 |     36.313 |     1.3
   13 |   0.9769 |     33.741 |   1.0750 |     35.847 |     1.4
   14 |   0.9511 |     32.518 |   1.0995 |     35.723 |     1.5
   15 |   0.9347 |     32.193 |   1.0830 |     36.499 |     1.6
   16 |   0.9135 |     31.603 |   1.0877 |     35.382 |     1.7
   17 |   0.9023 |     31.096 |   1.1190 |     36.158 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 277,090

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6897 |     48.606 |   1.3200 |     44.010 |     0.1
    2 |   1.2571 |     42.523 |   1.2107 |     40.968 |     0.2
    3 |   1.1595 |     39.906 |   1.1475 |     39.417 |     0.3
    4 |   1.0985 |     37.873 |   1.1023 |     37.492 |     0.4
    5 |   1.0402 |     35.680 |   1.1019 |     37.896 |     0.5
    6 |   0.9913 |     34.044 |   1.0687 |     35.568 |     0.6
    7 |   0.9448 |     32.435 |   1.0419 |     35.475 |     0.7
    8 |   0.8956 |     30.579 |   1.0479 |     35.320 |     0.8
    9 |   0.8423 |     29.003 |   1.0266 |     34.823 |     0.9
   10 |   0.7976 |     27.212 |   1.0135 |     33.892 |     1.0
   11 |   0.7525 |     25.890 |   1.0461 |     32.992 |     1.1
   12 |   0.7184 |     24.474 |   1.0239 |     33.023 |     1.2
   13 |   0.6642 |     22.661 |   1.0197 |     33.613 |     1.3
   14 |   0.6283 |     21.532 |   1.0652 |     32.557 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 277,090

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9807 |     80.055 |   2.4574 |     54.097 |     0.1
    2 |   2.3173 |     54.033 |   1.8076 |     48.324 |     0.2
    3 |   1.8638 |     48.044 |   1.5656 |     46.151 |     0.3
    4 |   1.6580 |     46.512 |   1.4813 |     45.965 |     0.3
    5 |   1.5596 |     46.116 |   1.4335 |     45.189 |     0.4
    6 |   1.5042 |     45.813 |   1.4050 |     45.531 |     0.5
    7 |   1.4656 |     45.967 |   1.3793 |     45.251 |     0.6
    8 |   1.4381 |     45.587 |   1.3576 |     44.631 |     0.7
    9 |   1.4127 |     45.410 |   1.3406 |     44.507 |     0.8
   10 |   1.3925 |     45.317 |   1.3274 |     44.475 |     0.8
   11 |   1.3757 |     45.091 |   1.3171 |     44.227 |     0.9
   12 |   1.3626 |     44.358 |   1.3058 |     43.700 |     1.0
   13 |   1.3499 |     44.529 |   1.2918 |     43.513 |     1.1
   14 |   1.3377 |     44.220 |   1.2804 |     42.706 |     1.2
   15 |   1.3275 |     43.868 |   1.2695 |     42.862 |     1.3
   16 |   1.3154 |     43.532 |   1.2638 |     42.148 |     1.3
   17 |   1.3055 |     43.372 |   1.2536 |     42.893 |     1.4
   18 |   1.2953 |     43.405 |   1.2489 |     42.675 |     1.5
   19 |   1.2844 |     42.777 |   1.2415 |     42.427 |     1.6
   20 |   1.2799 |     42.821 |   1.2358 |     42.334 |     1.7
   21 |   1.2689 |     42.689 |   1.2268 |     41.868 |     1.8
   22 |   1.2610 |     42.298 |   1.2268 |     41.589 |     1.8
   23 |   1.2556 |     42.132 |   1.2157 |     41.155 |     1.9
   24 |   1.2452 |     42.072 |   1.2257 |     42.117 |     2.0
   25 |   1.2394 |     41.906 |   1.2121 |     41.527 |     2.1
   26 |   1.2339 |     41.664 |   1.2100 |     41.279 |     2.2
   27 |   1.2245 |     41.240 |   1.1966 |     41.061 |     2.3
   28 |   1.2183 |     41.554 |   1.1974 |     41.248 |     2.4
   29 |   1.2109 |     41.135 |   1.2027 |     41.372 |     2.4
   30 |   1.2065 |     40.882 |   1.1818 |     40.503 |     2.5
   31 |   1.2046 |     40.854 |   1.1852 |     40.906 |     2.6
   32 |   1.1959 |     40.534 |   1.1893 |     40.379 |     2.7
   33 |   1.1926 |     40.672 |   1.1693 |     40.255 |     2.8
   34 |   1.1910 |     40.567 |   1.1666 |     40.223 |     2.9
   35 |   1.1841 |     40.231 |   1.1691 |     40.286 |     2.9
   36 |   1.1760 |     39.989 |   1.1880 |     40.720 |     3.0
   37 |   1.1755 |     40.088 |   1.1678 |     39.975 |     3.1
   38 |   1.1694 |     40.061 |   1.1758 |     39.944 |     3.2
   39 |   1.1664 |     39.747 |   1.1556 |     39.385 |     3.3
   40 |   1.1590 |     39.730 |   1.1571 |     39.789 |     3.4
   41 |   1.1573 |     39.675 |   1.1604 |     39.354 |     3.4
   42 |   1.1535 |     39.565 |   1.1639 |     39.665 |     3.5
   43 |   1.1535 |     39.306 |   1.1566 |     39.261 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 327,522

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7700 |     50.264 |   1.3608 |     45.189 |     0.2
    2 |   1.3558 |     44.826 |   1.2819 |     43.296 |     0.3
    3 |   1.2905 |     43.989 |   1.2369 |     42.334 |     0.5
    4 |   1.2502 |     43.576 |   1.2056 |     42.334 |     0.7
    5 |   1.2210 |     42.953 |   1.1903 |     41.465 |     0.9
    6 |   1.1906 |     41.895 |   1.1848 |     41.434 |     1.0
    7 |   1.1736 |     41.675 |   1.1559 |     40.223 |     1.2
    8 |   1.1518 |     41.107 |   1.1490 |     41.713 |     1.4
    9 |   1.1371 |     40.645 |   1.1309 |     39.882 |     1.6
   10 |   1.1190 |     39.857 |   1.1154 |     39.665 |     1.7
   11 |   1.1038 |     39.416 |   1.1004 |     38.299 |     1.9
   12 |   1.0876 |     38.716 |   1.0911 |     38.144 |     2.1
   13 |   1.0677 |     38.006 |   1.0854 |     38.299 |     2.2
   14 |   1.0548 |     37.521 |   1.0697 |     38.082 |     2.4
   15 |   1.0441 |     37.168 |   1.0592 |     37.554 |     2.6
   16 |   1.0324 |     36.942 |   1.0445 |     37.244 |     2.8
   17 |   1.0163 |     36.287 |   1.0585 |     37.089 |     2.9
   18 |   1.0019 |     35.868 |   1.0348 |     36.096 |     3.1
   19 |   0.9956 |     35.537 |   1.0330 |     35.506 |     3.3
   20 |   0.9793 |     35.014 |   1.0304 |     35.847 |     3.5
   21 |   0.9686 |     34.165 |   1.0224 |     36.096 |     3.6
   22 |   0.9582 |     33.807 |   1.0172 |     35.196 |     3.8
   23 |   0.9490 |     33.537 |   1.0241 |     35.102 |     4.0
   24 |   0.9265 |     32.716 |   1.0042 |     34.637 |     4.2
   25 |   0.9206 |     32.347 |   1.0124 |     34.606 |     4.3
   26 |   0.9133 |     32.353 |   0.9908 |     33.768 |     4.5
   27 |   0.9003 |     31.824 |   0.9909 |     33.768 |     4.7
   28 |   0.8930 |     31.466 |   0.9835 |     33.178 |     4.9
   29 |   0.8774 |     30.898 |   0.9769 |     32.868 |     5.0
   30 |   0.8700 |     30.314 |   0.9786 |     33.023 |     5.2
   31 |   0.8537 |     30.022 |   1.0034 |     33.395 |     5.4
   32 |   0.8466 |     29.543 |   1.0023 |     33.861 |     5.6
   33 |   0.8408 |     29.405 |   0.9721 |     33.178 |     5.8
   34 |   0.8250 |     29.058 |   1.0077 |     33.892 |     5.9
   35 |   0.8167 |     28.672 |   1.0043 |     32.868 |     6.1
   36 |   0.8044 |     27.928 |   1.0062 |     33.116 |     6.3
   37 |   0.7984 |     28.259 |   0.9743 |     31.564 |     6.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 343,330

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6439 |     61.499 |   1.8880 |     46.524 |     0.2
    2 |   1.8206 |     46.220 |   1.5804 |     46.120 |     0.3
    3 |   1.6056 |     45.747 |   1.4813 |     44.693 |     0.5
    4 |   1.5162 |     45.658 |   1.4234 |     44.910 |     0.7
    5 |   1.4557 |     45.102 |   1.3910 |     44.631 |     0.8
    6 |   1.4186 |     44.601 |   1.3548 |     42.800 |     1.0
    7 |   1.3871 |     44.248 |   1.3340 |     43.513 |     1.2
    8 |   1.3594 |     43.983 |   1.3158 |     42.675 |     1.3
    9 |   1.3371 |     43.515 |   1.2904 |     42.365 |     1.5
   10 |   1.3176 |     43.377 |   1.2738 |     42.086 |     1.7
   11 |   1.2966 |     42.727 |   1.2561 |     40.813 |     1.9
   12 |   1.2812 |     42.204 |   1.2409 |     40.720 |     2.0
   13 |   1.2667 |     42.325 |   1.2248 |     40.037 |     2.2
   14 |   1.2528 |     41.537 |   1.2106 |     40.006 |     2.4
   15 |   1.2361 |     41.168 |   1.2027 |     40.037 |     2.5
   16 |   1.2262 |     40.981 |   1.1936 |     39.665 |     2.7
   17 |   1.2155 |     40.782 |   1.1823 |     39.323 |     2.9
   18 |   1.2047 |     40.424 |   1.1694 |     39.385 |     3.0
   19 |   1.1944 |     40.375 |   1.1677 |     39.541 |     3.2
   20 |   1.1833 |     39.928 |   1.1566 |     39.541 |     3.4
   21 |   1.1733 |     39.554 |   1.1464 |     38.920 |     3.6
   22 |   1.1591 |     39.267 |   1.1447 |     38.889 |     3.7
   23 |   1.1509 |     38.942 |   1.1334 |     38.175 |     3.9
   24 |   1.1442 |     38.678 |   1.1347 |     38.237 |     4.1
   25 |   1.1339 |     38.435 |   1.1260 |     38.516 |     4.2
   26 |   1.1232 |     37.956 |   1.1214 |     38.051 |     4.4
   27 |   1.1194 |     38.022 |   1.1208 |     37.585 |     4.6
   28 |   1.1056 |     37.284 |   1.1077 |     37.337 |     4.7
   29 |   1.1021 |     37.229 |   1.1124 |     37.461 |     4.9
   30 |   1.0896 |     36.639 |   1.1076 |     37.678 |     5.1
   31 |   1.0867 |     36.667 |   1.0944 |     36.996 |     5.3
   32 |   1.0770 |     36.347 |   1.1052 |     37.182 |     5.4
   33 |   1.0722 |     35.917 |   1.1069 |     37.120 |     5.6
   34 |   1.0638 |     35.857 |   1.0837 |     36.096 |     5.8
   35 |   1.0583 |     35.532 |   1.0838 |     36.313 |     5.9
   36 |   1.0509 |     35.339 |   1.0762 |     36.530 |     6.1
   37 |   1.0411 |     35.113 |   1.0785 |     36.561 |     6.3
   38 |   1.0334 |     34.848 |   1.0656 |     35.537 |     6.4
   39 |   1.0243 |     34.711 |   1.0864 |     36.034 |     6.6
   40 |   1.0237 |     34.253 |   1.0816 |     36.065 |     6.8
   41 |   1.0132 |     34.342 |   1.0793 |     35.754 |     6.9
   42 |   1.0058 |     33.427 |   1.0706 |     35.723 |     7.1
   43 |   1.0033 |     34.094 |   1.0615 |     35.040 |     7.3
   44 |   0.9900 |     33.416 |   1.0592 |     35.164 |     7.4
   45 |   0.9897 |     32.920 |   1.0621 |     35.475 |     7.6
   46 |   0.9807 |     33.069 |   1.0671 |     35.506 |     7.8
   47 |   0.9802 |     33.135 |   1.0544 |     34.854 |     8.0
   48 |   0.9722 |     32.452 |   1.0556 |     35.009 |     8.1
   49 |   0.9653 |     32.408 |   1.0479 |     34.358 |     8.3
   50 |   0.9619 |     32.176 |   1.0714 |     35.537 |     8.5
   51 |   0.9589 |     32.496 |   1.0492 |     34.451 |     8.6
   52 |   0.9465 |     31.752 |   1.0345 |     33.954 |     8.8
   53 |   0.9434 |     31.730 |   1.0506 |     34.513 |     9.0
   54 |   0.9403 |     31.614 |   1.0498 |     34.358 |     9.2
   55 |   0.9320 |     31.168 |   1.0506 |     34.575 |     9.3
   56 |   0.9231 |     31.295 |   1.0502 |     34.637 |     9.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 458,914

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6193 |     47.107 |   1.3197 |     44.320 |     0.2
    2 |   1.2798 |     44.259 |   1.2340 |     42.924 |     0.3
    3 |   1.2084 |     42.287 |   1.1818 |     40.596 |     0.5
    4 |   1.1556 |     40.727 |   1.1540 |     39.820 |     0.6
    5 |   1.1156 |     39.802 |   1.1198 |     39.417 |     0.8
    6 |   1.0877 |     38.678 |   1.1139 |     38.672 |     1.0
    7 |   1.0634 |     37.868 |   1.0914 |     38.299 |     1.1
    8 |   1.0386 |     37.047 |   1.0933 |     38.454 |     1.3
    9 |   1.0253 |     36.722 |   1.0634 |     37.709 |     1.4
   10 |   1.0017 |     35.713 |   1.0482 |     36.778 |     1.6
   11 |   0.9911 |     35.835 |   1.0811 |     37.151 |     1.8
   12 |   0.9693 |     35.030 |   1.0579 |     37.306 |     1.9
   13 |   0.9547 |     34.672 |   1.0301 |     35.940 |     2.1
   14 |   0.9410 |     33.669 |   1.0303 |     35.754 |     2.2
   15 |   0.9187 |     33.052 |   1.0526 |     35.940 |     2.4
   16 |   0.9024 |     32.347 |   1.0173 |     35.009 |     2.6
   17 |   0.8810 |     31.273 |   1.0148 |     34.978 |     2.7
   18 |   0.8678 |     30.804 |   0.9973 |     34.264 |     2.9
   19 |   0.8411 |     29.857 |   1.0212 |     34.854 |     3.0
   20 |   0.8270 |     29.278 |   0.9981 |     33.116 |     3.2
   21 |   0.8075 |     28.628 |   1.0176 |     34.078 |     3.4
   22 |   0.7806 |     27.449 |   1.0003 |     33.271 |     3.5
   23 |   0.7719 |     27.306 |   0.9911 |     33.302 |     3.7
   24 |   0.7530 |     26.496 |   0.9844 |     32.619 |     3.8
   25 |   0.7318 |     25.846 |   0.9735 |     31.471 |     4.0
   26 |   0.7101 |     24.606 |   0.9735 |     33.023 |     4.2
   27 |   0.7032 |     24.854 |   0.9828 |     30.385 |     4.3
   28 |   0.6850 |     24.022 |   1.0279 |     33.271 |     4.5
   29 |   0.6603 |     23.234 |   1.0048 |     31.968 |     4.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 847,522

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3485 |     58.700 |   1.6057 |     45.779 |     0.2
    2 |   1.6112 |     46.314 |   1.4166 |     45.593 |     0.4
    3 |   1.4657 |     45.791 |   1.3599 |     45.282 |     0.6
    4 |   1.4074 |     45.339 |   1.3254 |     44.196 |     0.8
    5 |   1.3653 |     44.755 |   1.3101 |     44.910 |     1.0
    6 |   1.3397 |     44.375 |   1.2730 |     42.768 |     1.2
    7 |   1.3085 |     43.322 |   1.2527 |     42.365 |     1.4
    8 |   1.2793 |     42.656 |   1.2280 |     41.155 |     1.6
    9 |   1.2584 |     41.862 |   1.2199 |     41.030 |     1.8
   10 |   1.2381 |     41.229 |   1.2320 |     41.899 |     2.0
   11 |   1.2229 |     40.804 |   1.2290 |     41.061 |     2.2
   12 |   1.2059 |     40.292 |   1.2109 |     41.124 |     2.4
   13 |   1.1906 |     40.132 |   1.2067 |     40.720 |     2.6
   14 |   1.1763 |     39.559 |   1.2124 |     41.061 |     2.8
   15 |   1.1609 |     39.383 |   1.1977 |     40.472 |     3.0
   16 |   1.1475 |     38.716 |   1.2352 |     41.092 |     3.2
   17 |   1.1357 |     38.567 |   1.2203 |     40.068 |     3.4
   18 |   1.1239 |     37.857 |   1.2041 |     40.565 |     3.6
   19 |   1.1171 |     37.598 |   1.2089 |     39.789 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 326,626

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7593 |     50.044 |   1.3807 |     44.538 |     0.1
    2 |   1.3522 |     45.168 |   1.2821 |     42.768 |     0.2
    3 |   1.2815 |     43.868 |   1.2306 |     41.713 |     0.3
    4 |   1.2439 |     42.986 |   1.1910 |     41.775 |     0.3
    5 |   1.2047 |     41.895 |   1.1589 |     40.099 |     0.4
    6 |   1.1612 |     40.529 |   1.1451 |     39.634 |     0.5
    7 |   1.1380 |     39.548 |   1.1336 |     39.944 |     0.6
    8 |   1.1073 |     38.628 |   1.1364 |     39.292 |     0.7
    9 |   1.0829 |     37.543 |   1.1045 |     37.927 |     0.8
   10 |   1.0629 |     36.997 |   1.0740 |     37.772 |     0.9
   11 |   1.0409 |     36.336 |   1.0787 |     37.461 |     0.9
   12 |   1.0159 |     35.085 |   1.0542 |     36.313 |     1.0
   13 |   0.9969 |     34.485 |   1.0661 |     36.437 |     1.1
   14 |   0.9758 |     33.840 |   1.0238 |     35.475 |     1.2
   15 |   0.9580 |     33.118 |   1.0398 |     35.816 |     1.3
   16 |   0.9404 |     32.479 |   1.0200 |     34.513 |     1.3
   17 |   0.9246 |     32.077 |   1.0205 |     34.823 |     1.4
   18 |   0.9058 |     31.174 |   1.0149 |     34.327 |     1.5
   19 |   0.8890 |     30.722 |   0.9943 |     33.830 |     1.6
   20 |   0.8666 |     30.143 |   0.9806 |     33.271 |     1.7
   21 |   0.8540 |     29.532 |   1.0292 |     34.295 |     1.8
   22 |   0.8416 |     29.107 |   0.9955 |     32.061 |     1.9
   23 |   0.8175 |     28.154 |   0.9845 |     32.713 |     1.9
   24 |   0.7998 |     27.713 |   1.0418 |     33.644 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 285,538

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8838 |     52.017 |   1.3821 |     45.779 |     0.1
    2 |   1.4025 |     46.314 |   1.3207 |     45.003 |     0.2
    3 |   1.3436 |     45.410 |   1.2942 |     45.003 |     0.3
    4 |   1.3026 |     44.782 |   1.2655 |     45.127 |     0.4
    5 |   1.2756 |     44.331 |   1.2331 |     43.482 |     0.6
    6 |   1.2508 |     43.945 |   1.2013 |     42.024 |     0.7
    7 |   1.2242 |     42.634 |   1.1869 |     41.558 |     0.8
    8 |   1.2041 |     42.006 |   1.1835 |     41.186 |     0.9
    9 |   1.1905 |     41.868 |   1.1686 |     41.434 |     1.0
   10 |   1.1725 |     41.179 |   1.1449 |     41.713 |     1.1
   11 |   1.1586 |     40.650 |   1.1496 |     41.186 |     1.2
   12 |   1.1425 |     40.391 |   1.1281 |     39.882 |     1.3
   13 |   1.1352 |     40.154 |   1.1191 |     39.696 |     1.5
   14 |   1.1246 |     39.741 |   1.1139 |     39.572 |     1.6
   15 |   1.1112 |     39.014 |   1.1197 |     40.720 |     1.7
   16 |   1.1003 |     38.992 |   1.1179 |     39.199 |     1.8
   17 |   1.0943 |     38.612 |   1.1074 |     39.665 |     1.9
   18 |   1.0859 |     38.523 |   1.1165 |     39.913 |     2.0
   19 |   1.0679 |     37.543 |   1.1177 |     39.727 |     2.2
   20 |   1.0615 |     37.625 |   1.1300 |     39.572 |     2.3
   21 |   1.0544 |     37.322 |   1.1288 |     39.820 |     2.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 343,330

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8562 |     72.452 |   2.1326 |     47.548 |     0.1
    2 |   2.0547 |     48.727 |   1.6531 |     46.524 |     0.2
    3 |   1.7140 |     46.590 |   1.5290 |     46.524 |     0.4
    4 |   1.5886 |     46.022 |   1.4641 |     45.282 |     0.5
    5 |   1.5231 |     46.061 |   1.4264 |     45.624 |     0.6
    6 |   1.4841 |     45.950 |   1.4041 |     46.151 |     0.7
    7 |   1.4495 |     45.917 |   1.3831 |     46.058 |     0.8
    8 |   1.4225 |     45.702 |   1.3551 |     45.065 |     1.0
    9 |   1.3981 |     45.620 |   1.3357 |     45.003 |     1.1
   10 |   1.3793 |     45.190 |   1.3136 |     45.158 |     1.2
   11 |   1.3575 |     44.810 |   1.3032 |     44.538 |     1.3
   12 |   1.3407 |     44.567 |   1.2805 |     42.675 |     1.5
   13 |   1.3205 |     43.879 |   1.2729 |     43.296 |     1.6
   14 |   1.3127 |     43.361 |   1.2572 |     42.117 |     1.7
   15 |   1.2943 |     43.311 |   1.2530 |     42.737 |     1.8
   16 |   1.2902 |     43.058 |   1.2381 |     41.713 |     2.0
   17 |   1.2754 |     42.562 |   1.2318 |     41.620 |     2.1
   18 |   1.2687 |     42.320 |   1.2259 |     42.551 |     2.2
   19 |   1.2565 |     41.895 |   1.2114 |     40.937 |     2.3
   20 |   1.2508 |     42.143 |   1.2250 |     42.241 |     2.5
   21 |   1.2364 |     41.675 |   1.2026 |     41.527 |     2.6
   22 |   1.2346 |     41.890 |   1.2002 |     41.465 |     2.7
   23 |   1.2239 |     41.361 |   1.2028 |     40.751 |     2.9
   24 |   1.2190 |     41.344 |   1.1903 |     40.937 |     3.0
   25 |   1.2104 |     40.948 |   1.1964 |     40.937 |     3.1
   26 |   1.2027 |     40.871 |   1.1748 |     40.255 |     3.2
   27 |   1.1994 |     40.689 |   1.1819 |     40.906 |     3.4
   28 |   1.1944 |     40.893 |   1.1759 |     40.348 |     3.5
   29 |   1.1846 |     40.474 |   1.1801 |     40.006 |     3.6
   30 |   1.1824 |     40.441 |   1.1646 |     39.758 |     3.7
   31 |   1.1714 |     39.978 |   1.1655 |     40.006 |     3.9
   32 |   1.1681 |     39.835 |   1.1772 |     40.844 |     4.0
   33 |   1.1614 |     39.466 |   1.1723 |     40.037 |     4.1
   34 |   1.1579 |     39.388 |   1.1546 |     39.385 |     4.2
   35 |   1.1512 |     39.278 |   1.1780 |     39.944 |     4.4
   36 |   1.1485 |     39.543 |   1.1593 |     39.882 |     4.5
   37 |   1.1371 |     38.656 |   1.1588 |     39.168 |     4.6
   38 |   1.1317 |     38.882 |   1.1803 |     40.348 |     4.7
   39 |   1.1344 |     38.573 |   1.1431 |     39.603 |     4.8
   40 |   1.1230 |     38.209 |   1.1595 |     39.479 |     5.0
   41 |   1.1185 |     38.187 |   1.1613 |     39.044 |     5.1
   42 |   1.1120 |     37.879 |   1.1436 |     39.354 |     5.2
   43 |   1.1098 |     37.972 |   1.1783 |     39.975 |     5.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 732,002

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3251 |     57.223 |   1.6017 |     45.872 |     0.1
    2 |   1.4713 |     45.229 |   1.3920 |     44.382 |     0.2
    3 |   1.3389 |     43.207 |   1.3040 |     42.613 |     0.3
    4 |   1.2661 |     41.410 |   1.2494 |     41.341 |     0.4
    5 |   1.2125 |     40.298 |   1.2058 |     39.603 |     0.5
    6 |   1.1722 |     38.837 |   1.1811 |     39.323 |     0.6
    7 |   1.1370 |     38.099 |   1.1543 |     38.610 |     0.8
    8 |   1.1065 |     36.953 |   1.1347 |     37.244 |     0.9
    9 |   1.0800 |     36.386 |   1.1148 |     37.585 |     1.0
   10 |   1.0566 |     35.102 |   1.1006 |     36.778 |     1.1
   11 |   1.0336 |     34.485 |   1.0850 |     36.468 |     1.2
   12 |   1.0072 |     33.554 |   1.0989 |     37.461 |     1.3
   13 |   0.9898 |     33.129 |   1.0862 |     35.909 |     1.4
   14 |   0.9656 |     32.143 |   1.0840 |     36.065 |     1.6
   15 |   0.9414 |     31.543 |   1.0648 |     35.164 |     1.7
   16 |   0.9181 |     30.419 |   1.0543 |     34.544 |     1.8
   17 |   0.8948 |     29.444 |   1.0557 |     35.258 |     1.9
   18 |   0.8730 |     28.744 |   1.0314 |     33.799 |     2.0
   19 |   0.8502 |     28.242 |   1.0200 |     33.489 |     2.1
   20 |   0.8231 |     27.025 |   1.0297 |     34.016 |     2.2
   21 |   0.8004 |     26.055 |   1.0315 |     34.482 |     2.3
   22 |   0.7862 |     25.994 |   1.0321 |     34.885 |     2.5
   23 |   0.7638 |     25.008 |   1.0245 |     33.520 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,177,506

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9573 |     52.942 |   1.4643 |     46.462 |     0.1
    2 |   1.3921 |     44.342 |   1.3402 |     43.482 |     0.2
    3 |   1.2977 |     41.879 |   1.2748 |     41.682 |     0.3
    4 |   1.2278 |     40.187 |   1.2209 |     40.720 |     0.4
    5 |   1.1714 |     39.014 |   1.1765 |     38.734 |     0.5
    6 |   1.1257 |     37.647 |   1.1694 |     39.541 |     0.6
    7 |   1.0854 |     36.369 |   1.1291 |     37.678 |     0.7
    8 |   1.0518 |     35.366 |   1.1035 |     36.654 |     0.8
    9 |   1.0201 |     34.209 |   1.0952 |     36.437 |     1.0
   10 |   0.9889 |     33.218 |   1.0949 |     36.685 |     1.1
   11 |   0.9579 |     32.132 |   1.0634 |     35.568 |     1.2
   12 |   0.9332 |     31.174 |   1.0401 |     34.575 |     1.3
   13 |   0.9043 |     30.066 |   1.0453 |     35.289 |     1.4
   14 |   0.8751 |     28.860 |   1.0235 |     34.482 |     1.5
   15 |   0.8554 |     28.231 |   1.0141 |     33.302 |     1.6
   16 |   0.8324 |     27.311 |   1.0161 |     33.892 |     1.7
   17 |   0.8032 |     26.512 |   0.9914 |     32.309 |     1.8
   18 |   0.7814 |     25.840 |   1.0146 |     33.333 |     1.9
   19 |   0.7572 |     24.964 |   0.9839 |     32.837 |     2.0
   20 |   0.7367 |     24.380 |   1.0009 |     32.775 |     2.1
   21 |   0.7054 |     23.333 |   0.9850 |     32.495 |     2.2
   22 |   0.6884 |     22.788 |   0.9895 |     32.216 |     2.3
   23 |   0.6653 |     21.702 |   1.0149 |     32.682 |     2.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,243,682

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9335 |     50.722 |   1.4632 |     46.586 |     0.2
    2 |   1.3947 |     44.474 |   1.3453 |     43.575 |     0.4
    3 |   1.3129 |     43.493 |   1.2955 |     42.117 |     0.6
    4 |   1.2560 |     41.675 |   1.2534 |     42.396 |     0.8
    5 |   1.2159 |     40.860 |   1.2140 |     40.751 |     1.0
    6 |   1.1810 |     40.127 |   1.1842 |     40.379 |     1.2
    7 |   1.1493 |     39.350 |   1.1786 |     39.913 |     1.4
    8 |   1.1207 |     38.353 |   1.1410 |     39.479 |     1.5
    9 |   1.0874 |     37.129 |   1.1372 |     38.703 |     1.7
   10 |   1.0560 |     36.154 |   1.1113 |     38.051 |     1.9
   11 |   1.0269 |     34.915 |   1.0837 |     36.468 |     2.1
   12 |   0.9933 |     33.410 |   1.0757 |     37.492 |     2.3
   13 |   0.9641 |     32.744 |   1.0666 |     37.058 |     2.5
   14 |   0.9375 |     31.680 |   1.0531 |     35.009 |     2.7
   15 |   0.9109 |     30.518 |   1.0275 |     35.102 |     2.9
   16 |   0.8805 |     29.554 |   1.0549 |     35.382 |     3.1
   17 |   0.8513 |     28.303 |   1.0302 |     33.923 |     3.3
   18 |   0.8238 |     27.278 |   1.0067 |     33.054 |     3.5
   19 |   0.8045 |     26.854 |   1.0159 |     33.178 |     3.7
   20 |   0.7760 |     25.862 |   1.0125 |     33.364 |     3.9
   21 |   0.7497 |     24.672 |   1.0028 |     32.806 |     4.1
   22 |   0.7243 |     23.961 |   1.0380 |     33.457 |     4.3
   23 |   0.7024 |     23.041 |   1.0058 |     32.185 |     4.5
   24 |   0.6796 |     22.331 |   1.0250 |     32.961 |     4.7
   25 |   0.6521 |     21.317 |   1.0394 |     33.675 |     4.9
   26 |   0.6322 |     20.843 |   1.0027 |     32.247 |     5.0
   27 |   0.6085 |     19.708 |   1.0506 |     32.495 |     5.2
   28 |   0.5836 |     18.871 |   1.0407 |     32.775 |     5.4
   29 |   0.5642 |     18.298 |   1.0333 |     31.471 |     5.6
   30 |   0.5393 |     17.438 |   1.0802 |     32.806 |     5.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 748,834

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2605 |     57.939 |   1.5870 |     46.089 |     0.2
    2 |   1.5409 |     45.780 |   1.4090 |     45.065 |     0.4
    3 |   1.4179 |     44.634 |   1.3457 |     44.196 |     0.6
    4 |   1.3547 |     43.515 |   1.2981 |     43.172 |     0.8
    5 |   1.3081 |     42.441 |   1.2716 |     42.117 |     0.9
    6 |   1.2748 |     42.176 |   1.2520 |     42.396 |     1.1
    7 |   1.2471 |     41.372 |   1.2366 |     42.086 |     1.3
    8 |   1.2208 |     40.837 |   1.2097 |     41.030 |     1.5
    9 |   1.1964 |     40.342 |   1.2189 |     40.875 |     1.7
   10 |   1.1798 |     39.713 |   1.1911 |     40.658 |     1.9
   11 |   1.1603 |     39.196 |   1.1829 |     40.161 |     2.1
   12 |   1.1462 |     39.096 |   1.1635 |     39.510 |     2.3
   13 |   1.1266 |     38.017 |   1.1546 |     39.199 |     2.5
   14 |   1.1081 |     37.664 |   1.1581 |     38.827 |     2.7
   15 |   1.0935 |     36.931 |   1.1404 |     38.765 |     2.8
   16 |   1.0784 |     36.551 |   1.1233 |     38.734 |     3.0
   17 |   1.0610 |     35.658 |   1.1510 |     38.858 |     3.2
   18 |   1.0410 |     35.433 |   1.1277 |     38.237 |     3.4
   19 |   1.0294 |     34.788 |   1.1145 |     37.958 |     3.6
   20 |   1.0147 |     33.928 |   1.1151 |     37.927 |     3.8
   21 |   1.0028 |     33.824 |   1.1167 |     37.337 |     4.0
   22 |   0.9850 |     33.245 |   1.1296 |     38.454 |     4.2
   23 |   0.9672 |     32.567 |   1.0803 |     36.592 |     4.3
   24 |   0.9587 |     32.584 |   1.1070 |     37.461 |     4.5
   25 |   0.9518 |     32.000 |   1.0898 |     36.778 |     4.7
   26 |   0.9335 |     31.339 |   1.0788 |     36.158 |     4.9
   27 |   0.9225 |     30.837 |   1.0981 |     36.778 |     5.1
   28 |   0.9095 |     30.419 |   1.0956 |     36.623 |     5.3
   29 |   0.8923 |     29.994 |   1.0767 |     35.816 |     5.5
   30 |   0.8846 |     29.752 |   1.0918 |     36.561 |     5.7
   31 |   0.8713 |     29.394 |   1.0919 |     36.096 |     5.9
   32 |   0.8665 |     29.096 |   1.1139 |     36.840 |     6.0
   33 |   0.8498 |     28.694 |   1.1073 |     36.096 |     6.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 779,938

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2263 |     54.529 |   1.5497 |     45.779 |     0.1
    2 |   1.5652 |     45.835 |   1.4087 |     45.779 |     0.2
    3 |   1.4452 |     45.587 |   1.3440 |     44.662 |     0.3
    4 |   1.3941 |     45.317 |   1.3171 |     44.755 |     0.5
    5 |   1.3552 |     44.948 |   1.2837 |     43.172 |     0.6
    6 |   1.3170 |     43.868 |   1.2569 |     41.589 |     0.7
    7 |   1.2901 |     43.256 |   1.2329 |     41.341 |     0.8
    8 |   1.2680 |     42.358 |   1.2228 |     41.279 |     0.9
    9 |   1.2433 |     41.664 |   1.2157 |     41.930 |     1.0
   10 |   1.2241 |     40.793 |   1.1933 |     40.937 |     1.1
   11 |   1.2065 |     40.468 |   1.1934 |     40.627 |     1.3
   12 |   1.1914 |     39.873 |   1.1850 |     40.130 |     1.4
   13 |   1.1786 |     39.868 |   1.1909 |     40.751 |     1.5
   14 |   1.1618 |     39.554 |   1.1910 |     40.627 |     1.6
   15 |   1.1463 |     38.771 |   1.1889 |     40.037 |     1.7
   16 |   1.1387 |     38.744 |   1.1754 |     39.820 |     1.8
   17 |   1.1196 |     38.017 |   1.1420 |     39.727 |     1.9
   18 |   1.1099 |     37.647 |   1.1828 |     40.472 |     2.0
   19 |   1.0950 |     37.383 |   1.1359 |     38.951 |     2.2
   20 |   1.0868 |     36.744 |   1.1567 |     38.734 |     2.3
   21 |   1.0757 |     36.595 |   1.1350 |     38.827 |     2.4
   22 |   1.0649 |     35.895 |   1.1226 |     38.423 |     2.5
   23 |   1.0506 |     35.675 |   1.1414 |     38.765 |     2.6
   24 |   1.0457 |     35.879 |   1.1319 |     38.765 |     2.7
   25 |   1.0345 |     35.377 |   1.1364 |     38.082 |     2.9
   26 |   1.0238 |     34.540 |   1.1165 |     38.020 |     3.0
   27 |   1.0159 |     34.264 |   1.1381 |     38.330 |     3.1
   28 |   1.0013 |     34.110 |   1.1381 |     38.144 |     3.2
   29 |   0.9876 |     33.565 |   1.1663 |     38.299 |     3.3
   30 |   0.9781 |     33.300 |   1.1471 |     37.368 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 292,194

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6710 |     48.793 |   1.3265 |     44.072 |     0.1
    2 |   1.2834 |     43.675 |   1.2422 |     42.644 |     0.2
    3 |   1.1982 |     41.587 |   1.1934 |     41.868 |     0.3
    4 |   1.1396 |     39.829 |   1.1458 |     39.789 |     0.4
    5 |   1.0998 |     38.369 |   1.1122 |     39.354 |     0.5
    6 |   1.0605 |     37.399 |   1.0929 |     38.516 |     0.6
    7 |   1.0261 |     36.143 |   1.0751 |     37.244 |     0.6
    8 |   0.9948 |     35.129 |   1.0664 |     37.275 |     0.7
    9 |   0.9607 |     33.713 |   1.0485 |     36.406 |     0.8
   10 |   0.9311 |     32.479 |   1.0533 |     35.071 |     0.9
   11 |   0.8944 |     31.174 |   1.0564 |     35.692 |     1.0
   12 |   0.8593 |     29.967 |   1.0469 |     35.289 |     1.1
   13 |   0.8170 |     28.540 |   1.0338 |     34.792 |     1.2
   14 |   0.7850 |     27.344 |   1.0523 |     35.133 |     1.3
   15 |   0.7435 |     25.846 |   1.0721 |     34.140 |     1.4
   16 |   0.7060 |     24.766 |   1.0750 |     34.389 |     1.5
   17 |   0.6716 |     23.063 |   1.1090 |     34.109 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 847,522

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5240 |     47.163 |   1.2967 |     45.158 |     0.1
    2 |   1.2592 |     44.000 |   1.2495 |     46.058 |     0.3
    3 |   1.2075 |     42.623 |   1.2221 |     42.737 |     0.4
    4 |   1.1698 |     41.719 |   1.1914 |     41.589 |     0.6
    5 |   1.1370 |     40.733 |   1.1410 |     40.596 |     0.7
    6 |   1.1093 |     39.862 |   1.1453 |     40.161 |     0.9
    7 |   1.0860 |     38.948 |   1.1406 |     40.441 |     1.0
    8 |   1.0667 |     38.331 |   1.1006 |     39.230 |     1.1
    9 |   1.0480 |     37.697 |   1.1025 |     39.448 |     1.3
   10 |   1.0243 |     36.942 |   1.0860 |     38.144 |     1.4
   11 |   1.0152 |     36.154 |   1.0815 |     38.516 |     1.6
   12 |   1.0038 |     35.939 |   1.0661 |     36.965 |     1.7
   13 |   0.9871 |     35.537 |   1.0714 |     37.492 |     1.9
   14 |   0.9738 |     34.727 |   1.0588 |     37.089 |     2.0
   15 |   0.9593 |     34.116 |   1.0686 |     37.430 |     2.2
   16 |   0.9460 |     33.769 |   1.0514 |     37.089 |     2.3
   17 |   0.9431 |     33.763 |   1.0780 |     37.430 |     2.5
   18 |   0.9327 |     33.372 |   1.0599 |     36.965 |     2.6
   19 |   0.9226 |     33.113 |   1.0542 |     36.654 |     2.7
   20 |   0.9014 |     32.270 |   1.0488 |     35.878 |     2.9
   21 |   0.8922 |     31.736 |   1.0372 |     35.723 |     3.0
   22 |   0.8725 |     31.163 |   1.0236 |     35.102 |     3.2
   23 |   0.8612 |     30.716 |   1.0369 |     35.320 |     3.3
   24 |   0.8465 |     30.132 |   1.0110 |     35.040 |     3.5
   25 |   0.8350 |     29.950 |   1.0222 |     34.668 |     3.6
   26 |   0.8280 |     29.444 |   1.0223 |     35.071 |     3.8
   27 |   0.8134 |     29.366 |   1.0096 |     34.078 |     3.9
   28 |   0.8156 |     29.074 |   1.0236 |     34.761 |     4.1
   29 |   0.7975 |     28.281 |   1.0311 |     34.327 |     4.2
   30 |   0.7834 |     28.364 |   1.0154 |     34.140 |     4.3
   31 |   0.7675 |     27.317 |   1.0209 |     34.761 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 235,106

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5374 |     60.882 |   1.8691 |     46.276 |     0.1
    2 |   1.6958 |     45.647 |   1.5715 |     45.655 |     0.2
    3 |   1.5245 |     45.532 |   1.4728 |     45.345 |     0.3
    4 |   1.4420 |     44.138 |   1.4041 |     43.389 |     0.4
    5 |   1.3870 |     43.449 |   1.3610 |     43.048 |     0.5
    6 |   1.3496 |     43.096 |   1.3332 |     42.675 |     0.6
    7 |   1.3162 |     42.567 |   1.3095 |     41.775 |     0.7
    8 |   1.2909 |     42.237 |   1.2877 |     42.086 |     0.8
    9 |   1.2647 |     41.642 |   1.2602 |     41.465 |     0.9
   10 |   1.2448 |     40.854 |   1.2504 |     41.620 |     1.0
   11 |   1.2257 |     40.612 |   1.2319 |     40.782 |     1.0
   12 |   1.2046 |     39.879 |   1.2183 |     40.782 |     1.1
   13 |   1.1873 |     39.570 |   1.2083 |     40.627 |     1.2
   14 |   1.1700 |     38.926 |   1.1975 |     40.006 |     1.3
   15 |   1.1575 |     38.953 |   1.1857 |     39.820 |     1.4
   16 |   1.1385 |     38.022 |   1.1849 |     39.479 |     1.5
   17 |   1.1248 |     37.802 |   1.1729 |     39.292 |     1.6
   18 |   1.1116 |     37.482 |   1.1528 |     38.579 |     1.7
   19 |   1.0976 |     36.799 |   1.1412 |     38.765 |     1.8
   20 |   1.0862 |     36.650 |   1.1432 |     39.572 |     1.9
   21 |   1.0738 |     36.066 |   1.1329 |     38.237 |     2.0
   22 |   1.0609 |     35.708 |   1.1316 |     38.827 |     2.1
   23 |   1.0512 |     35.421 |   1.1267 |     38.361 |     2.2
   24 |   1.0399 |     34.997 |   1.1114 |     38.237 |     2.3
   25 |   1.0295 |     34.766 |   1.0992 |     37.585 |     2.4
   26 |   1.0192 |     34.259 |   1.0992 |     37.182 |     2.5
   27 |   1.0091 |     34.022 |   1.0929 |     36.685 |     2.6
   28 |   0.9985 |     33.857 |   1.0866 |     36.872 |     2.7
   29 |   0.9894 |     33.399 |   1.0926 |     37.306 |     2.8
   30 |   0.9809 |     33.052 |   1.0687 |     35.506 |     2.9
   31 |   0.9698 |     32.595 |   1.0618 |     35.568 |     3.0
   32 |   0.9581 |     32.022 |   1.0655 |     36.096 |     3.0
   33 |   0.9498 |     31.928 |   1.0651 |     35.847 |     3.1
   34 |   0.9374 |     31.427 |   1.0712 |     36.158 |     3.2
   35 |   0.9304 |     31.058 |   1.0503 |     34.916 |     3.3
   36 |   0.9199 |     30.893 |   1.0569 |     35.351 |     3.4
   37 |   0.9092 |     30.424 |   1.0441 |     34.730 |     3.5
   38 |   0.9001 |     30.061 |   1.0322 |     34.575 |     3.6
   39 |   0.8911 |     30.039 |   1.0416 |     34.761 |     3.7
   40 |   0.8804 |     29.499 |   1.0277 |     34.264 |     3.8
   41 |   0.8751 |     29.273 |   1.0377 |     34.823 |     3.9
   42 |   0.8637 |     28.860 |   1.0284 |     33.923 |     4.0
   43 |   0.8573 |     28.876 |   1.0405 |     34.761 |     4.1
   44 |   0.8499 |     28.689 |   1.0403 |     33.954 |     4.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 980,130

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0693 |     53.460 |   1.5129 |     45.810 |     0.1
    2 |   1.4200 |     44.821 |   1.3468 |     44.227 |     0.2
    3 |   1.3070 |     42.512 |   1.2926 |     42.737 |     0.3
    4 |   1.2415 |     40.937 |   1.2330 |     40.658 |     0.4
    5 |   1.1909 |     39.719 |   1.1959 |     40.286 |     0.5
    6 |   1.1541 |     39.102 |   1.1644 |     39.448 |     0.6
    7 |   1.1169 |     37.713 |   1.1387 |     37.803 |     0.7
    8 |   1.0811 |     36.479 |   1.1243 |     38.144 |     0.8
    9 |   1.0561 |     35.758 |   1.1048 |     37.803 |     0.9
   10 |   1.0245 |     34.573 |   1.1071 |     37.492 |     1.0
   11 |   0.9948 |     33.515 |   1.0708 |     35.506 |     1.1
   12 |   0.9638 |     32.496 |   1.0575 |     35.506 |     1.3
   13 |   0.9412 |     31.548 |   1.0613 |     35.909 |     1.4
   14 |   0.9137 |     30.402 |   1.0394 |     34.358 |     1.5
   15 |   0.8909 |     29.686 |   1.0229 |     33.489 |     1.6
   16 |   0.8614 |     28.490 |   1.0210 |     34.295 |     1.7
   17 |   0.8349 |     27.807 |   1.0246 |     34.016 |     1.8
   18 |   0.8141 |     27.030 |   1.0169 |     33.333 |     1.9
   19 |   0.7842 |     25.961 |   1.0198 |     33.054 |     2.0
   20 |   0.7556 |     25.069 |   1.0124 |     32.651 |     2.1
   21 |   0.7423 |     24.430 |   1.0053 |     32.713 |     2.2
   22 |   0.7086 |     23.267 |   1.0158 |     32.868 |     2.3
   23 |   0.6834 |     22.617 |   1.0149 |     33.023 |     2.4
   24 |   0.6614 |     21.829 |   1.0159 |     31.875 |     2.5
   25 |   0.6433 |     20.843 |   0.9973 |     31.564 |     2.6
   26 |   0.6189 |     20.358 |   1.0173 |     32.464 |     2.7
   27 |   0.5943 |     19.190 |   1.0305 |     31.968 |     2.8
   28 |   0.5705 |     18.435 |   1.0274 |     31.347 |     2.9
   29 |   0.5539 |     18.039 |   1.0454 |     32.402 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 525,666

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 467])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3044 |     56.463 |   1.7101 |     45.748 |     0.2
    2 |   1.6019 |     45.267 |   1.5178 |     45.127 |     0.3
    3 |   1.4740 |     44.446 |   1.4331 |     43.948 |     0.5
    4 |   1.4045 |     43.851 |   1.3796 |     43.110 |     0.7
    5 |   1.3531 |     43.025 |   1.3402 |     42.706 |     0.9
    6 |   1.3101 |     42.287 |   1.3089 |     41.713 |     1.0
    7 |   1.2749 |     41.234 |   1.2655 |     40.658 |     1.2
    8 |   1.2419 |     40.782 |   1.2460 |     41.682 |     1.4
    9 |   1.2117 |     40.309 |   1.2407 |     41.682 |     1.6
   10 |   1.1895 |     39.725 |   1.2094 |     39.851 |     1.7
   11 |   1.1662 |     38.876 |   1.2123 |     40.844 |     1.9
   12 |   1.1424 |     38.165 |   1.1728 |     38.765 |     2.1
   13 |   1.1195 |     37.333 |   1.1517 |     37.865 |     2.3
   14 |   1.0986 |     36.865 |   1.1380 |     38.330 |     2.4
   15 |   1.0781 |     35.824 |   1.1350 |     38.299 |     2.6
   16 |   1.0575 |     35.014 |   1.1285 |     37.213 |     2.8
   17 |   1.0400 |     34.556 |   1.0961 |     36.654 |     3.0
   18 |   1.0263 |     33.961 |   1.1097 |     36.158 |     3.1
   19 |   1.0028 |     33.372 |   1.0800 |     35.723 |     3.3
   20 |   0.9830 |     32.760 |   1.0711 |     36.002 |     3.5
   21 |   0.9710 |     32.347 |   1.0662 |     35.444 |     3.7
   22 |   0.9577 |     31.697 |   1.0740 |     35.971 |     3.8
   23 |   0.9382 |     31.256 |   1.0553 |     35.289 |     4.0
   24 |   0.9160 |     30.099 |   1.0576 |     35.475 |     4.2
   25 |   0.8969 |     29.576 |   1.0327 |     34.668 |     4.3
   26 |   0.8896 |     29.697 |   1.0652 |     35.196 |     4.5
   27 |   0.8697 |     28.826 |   1.0348 |     34.544 |     4.7
   28 |   0.8574 |     28.551 |   1.0434 |     34.668 |     4.9
   29 |   0.8442 |     28.215 |   1.0103 |     33.768 |     5.0
   30 |   0.8266 |     27.449 |   1.0458 |     34.171 |     5.2
   31 |   0.8132 |     26.860 |   1.0533 |     33.985 |     5.4
   32 |   0.7955 |     26.209 |   1.0101 |     33.489 |     5.5
   33 |   0.7875 |     25.725 |   1.0086 |     32.899 |     5.7
   34 |   0.7634 |     25.096 |   1.0158 |     33.364 |     5.9
   35 |   0.7524 |     24.860 |   1.0256 |     32.806 |     6.1
   36 |   0.7327 |     24.039 |   0.9984 |     31.999 |     6.2
   37 |   0.7212 |     23.741 |   1.0189 |     32.744 |     6.4
   38 |   0.7099 |     23.289 |   1.0356 |     33.116 |     6.6
   39 |   0.6921 |     22.683 |   1.0342 |     33.116 |     6.8
   40 |   0.6766 |     22.358 |   1.0505 |     33.768 |     6.9
Early stopping

