Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 193,186

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8227 |     71.777 |   2.2372 |     50.122 |     0.1
    2 |   1.9520 |     48.249 |   1.7313 |     45.474 |     0.1
    3 |   1.6411 |     45.525 |   1.5485 |     44.618 |     0.2
    4 |   1.5124 |     45.012 |   1.4608 |     44.495 |     0.2
    5 |   1.4380 |     44.271 |   1.4082 |     44.893 |     0.3
    6 |   1.3841 |     43.305 |   1.3695 |     43.731 |     0.3
    7 |   1.3403 |     42.575 |   1.3384 |     43.670 |     0.4
    8 |   1.3080 |     41.968 |   1.3115 |     43.180 |     0.5
    9 |   1.2778 |     41.598 |   1.2861 |     42.263 |     0.5
   10 |   1.2543 |     41.100 |   1.2808 |     42.997 |     0.6
   11 |   1.2291 |     40.366 |   1.2837 |     43.180 |     0.6
   12 |   1.2082 |     39.741 |   1.2463 |     41.193 |     0.7
   13 |   1.1906 |     39.498 |   1.2351 |     41.223 |     0.7
   14 |   1.1753 |     39.393 |   1.2283 |     41.315 |     0.8
   15 |   1.1615 |     38.797 |   1.2212 |     41.621 |     0.8
   16 |   1.1474 |     38.819 |   1.2134 |     40.367 |     0.9
   17 |   1.1342 |     38.156 |   1.2142 |     41.223 |     1.0
   18 |   1.1196 |     37.858 |   1.2011 |     40.214 |     1.0
   19 |   1.1060 |     37.278 |   1.1804 |     39.327 |     1.1
   20 |   1.0968 |     37.123 |   1.1851 |     39.602 |     1.1
   21 |   1.0866 |     36.869 |   1.1819 |     39.388 |     1.2
   22 |   1.0742 |     36.327 |   1.1687 |     38.960 |     1.2
   23 |   1.0653 |     36.300 |   1.1488 |     37.859 |     1.3
   24 |   1.0525 |     35.399 |   1.1495 |     38.471 |     1.4
   25 |   1.0438 |     35.383 |   1.1574 |     38.349 |     1.4
   26 |   1.0350 |     35.051 |   1.1450 |     37.309 |     1.5
   27 |   1.0231 |     34.560 |   1.1388 |     37.615 |     1.5
   28 |   1.0128 |     34.018 |   1.1308 |     37.370 |     1.6
   29 |   1.0038 |     34.007 |   1.1308 |     37.706 |     1.7
   30 |   0.9952 |     33.598 |   1.1194 |     36.972 |     1.7
   31 |   0.9864 |     33.052 |   1.1251 |     36.820 |     1.8
   32 |   0.9775 |     32.864 |   1.1149 |     36.667 |     1.8
   33 |   0.9698 |     32.560 |   1.1331 |     37.462 |     1.9
   34 |   0.9600 |     32.372 |   1.1068 |     36.820 |     1.9
   35 |   0.9521 |     31.847 |   1.1202 |     36.850 |     2.0
   36 |   0.9443 |     31.566 |   1.0968 |     36.667 |     2.1
   37 |   0.9376 |     31.527 |   1.1054 |     37.064 |     2.1
   38 |   0.9301 |     31.334 |   1.1060 |     36.881 |     2.2
   39 |   0.9220 |     30.836 |   1.1008 |     36.208 |     2.2
   40 |   0.9124 |     30.510 |   1.1058 |     36.575 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7574 |     49.834 |   1.3635 |     45.657 |     0.1
    2 |   1.3652 |     45.520 |   1.2897 |     43.517 |     0.1
    3 |   1.2823 |     43.614 |   1.2317 |     43.272 |     0.2
    4 |   1.2307 |     42.194 |   1.1964 |     42.385 |     0.2
    5 |   1.1997 |     41.852 |   1.1911 |     41.376 |     0.3
    6 |   1.1687 |     40.741 |   1.1739 |     40.520 |     0.4
    7 |   1.1465 |     40.167 |   1.1767 |     39.786 |     0.4
    8 |   1.1210 |     39.288 |   1.1480 |     37.951 |     0.5
    9 |   1.1008 |     38.355 |   1.1462 |     38.746 |     0.6
   10 |   1.0832 |     37.471 |   1.1121 |     37.034 |     0.6
   11 |   1.0627 |     36.709 |   1.1046 |     36.789 |     0.7
   12 |   1.0369 |     35.963 |   1.0889 |     36.177 |     0.7
   13 |   1.0195 |     35.272 |   1.0849 |     35.138 |     0.8
   14 |   1.0076 |     34.913 |   1.0789 |     35.902 |     0.9
   15 |   0.9807 |     33.842 |   1.0517 |     34.343 |     0.9
   16 |   0.9558 |     32.974 |   1.0528 |     33.823 |     1.0
   17 |   0.9476 |     32.604 |   1.0530 |     34.465 |     1.1
   18 |   0.9220 |     31.952 |   1.0183 |     33.456 |     1.1
   19 |   0.9073 |     31.195 |   1.0470 |     33.364 |     1.2
   20 |   0.8890 |     30.676 |   1.0425 |     33.517 |     1.3
   21 |   0.8782 |     30.428 |   1.0423 |     32.446 |     1.3
   22 |   0.8579 |     29.720 |   1.0314 |     33.394 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7708 |     49.751 |   1.3757 |     45.902 |     0.1
    2 |   1.3737 |     45.492 |   1.3096 |     44.220 |     0.1
    3 |   1.3052 |     44.106 |   1.2431 |     42.202 |     0.2
    4 |   1.2592 |     42.957 |   1.2133 |     41.284 |     0.2
    5 |   1.2271 |     42.238 |   1.2074 |     40.979 |     0.3
    6 |   1.1932 |     41.216 |   1.1864 |     41.407 |     0.4
    7 |   1.1693 |     40.327 |   1.1540 |     39.297 |     0.4
    8 |   1.1430 |     39.692 |   1.1318 |     39.450 |     0.5
    9 |   1.1203 |     38.659 |   1.1078 |     38.869 |     0.6
   10 |   1.0991 |     38.040 |   1.1166 |     38.165 |     0.6
   11 |   1.0835 |     37.769 |   1.1298 |     39.297 |     0.7
   12 |   1.0592 |     36.858 |   1.1151 |     38.073 |     0.8
   13 |   1.0446 |     36.123 |   1.1018 |     37.278 |     0.8
   14 |   1.0275 |     35.775 |   1.1029 |     37.431 |     0.9
   15 |   1.0007 |     34.521 |   1.0761 |     36.636 |     0.9
   16 |   0.9867 |     33.919 |   1.0842 |     36.269 |     1.0
   17 |   0.9733 |     33.571 |   1.0745 |     35.872 |     1.1
   18 |   0.9564 |     33.151 |   1.0656 |     35.229 |     1.1
   19 |   0.9419 |     32.339 |   1.0776 |     35.535 |     1.2
   20 |   0.9238 |     31.737 |   1.1033 |     35.810 |     1.3
   21 |   0.9005 |     30.858 |   1.0882 |     36.147 |     1.3
   22 |   0.8903 |     30.875 |   1.0853 |     35.260 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 582,690

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6499 |     48.873 |   1.3130 |     44.037 |     0.1
    2 |   1.3217 |     44.531 |   1.2569 |     42.661 |     0.2
    3 |   1.2461 |     42.481 |   1.2012 |     41.743 |     0.3
    4 |   1.1855 |     41.388 |   1.1868 |     40.245 |     0.4
    5 |   1.1445 |     39.609 |   1.1730 |     39.297 |     0.5
    6 |   1.0988 |     38.106 |   1.1471 |     37.187 |     0.6
    7 |   1.0726 |     37.206 |   1.1663 |     38.379 |     0.7
    8 |   1.0254 |     35.361 |   1.1178 |     36.208 |     0.8
    9 |   1.0086 |     34.797 |   1.1649 |     37.951 |     0.9
   10 |   0.9730 |     33.891 |   1.1504 |     37.370 |     1.0
   11 |   0.9508 |     33.273 |   1.1260 |     36.269 |     1.1
   12 |   0.9211 |     31.930 |   1.1378 |     37.095 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 327,586

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6699 |     63.927 |   2.0009 |     48.654 |     0.2
    2 |   1.9308 |     47.453 |   1.6453 |     45.627 |     0.3
    3 |   1.6759 |     46.249 |   1.5206 |     45.627 |     0.5
    4 |   1.5663 |     46.139 |   1.4599 |     45.474 |     0.6
    5 |   1.5052 |     46.205 |   1.4184 |     45.566 |     0.8
    6 |   1.4647 |     45.774 |   1.3900 |     45.015 |     1.0
    7 |   1.4325 |     45.752 |   1.3669 |     44.832 |     1.1
    8 |   1.4067 |     45.420 |   1.3431 |     44.618 |     1.3
    9 |   1.3835 |     44.945 |   1.3335 |     43.853 |     1.5
   10 |   1.3636 |     44.641 |   1.3218 |     43.609 |     1.6
   11 |   1.3454 |     44.249 |   1.3114 |     44.006 |     1.8
   12 |   1.3310 |     44.194 |   1.3106 |     44.862 |     2.0
   13 |   1.3145 |     43.774 |   1.2877 |     43.028 |     2.1
   14 |   1.2960 |     43.028 |   1.2781 |     42.538 |     2.3
   15 |   1.2799 |     42.647 |   1.2699 |     41.865 |     2.5
   16 |   1.2708 |     42.531 |   1.2483 |     41.621 |     2.6
   17 |   1.2566 |     42.133 |   1.2667 |     42.599 |     2.8
   18 |   1.2420 |     41.929 |   1.2428 |     41.284 |     2.9
   19 |   1.2272 |     41.371 |   1.2226 |     40.765 |     3.1
   20 |   1.2185 |     41.156 |   1.2245 |     40.245 |     3.3
   21 |   1.2113 |     40.708 |   1.2247 |     41.437 |     3.4
   22 |   1.1996 |     40.415 |   1.2097 |     40.275 |     3.6
   23 |   1.1916 |     40.206 |   1.2077 |     40.122 |     3.8
   24 |   1.1827 |     40.438 |   1.2012 |     40.520 |     3.9
   25 |   1.1742 |     39.692 |   1.1925 |     39.541 |     4.1
   26 |   1.1673 |     39.421 |   1.1968 |     40.398 |     4.2
   27 |   1.1573 |     38.979 |   1.1948 |     40.031 |     4.4
   28 |   1.1552 |     39.587 |   1.1830 |     39.297 |     4.6
   29 |   1.1441 |     38.863 |   1.1895 |     40.398 |     4.7
   30 |   1.1345 |     38.272 |   1.1916 |     39.847 |     4.9
   31 |   1.1258 |     37.836 |   1.1828 |     40.000 |     5.1
   32 |   1.1188 |     37.775 |   1.1932 |     40.122 |     5.2
   33 |   1.1126 |     37.880 |   1.1899 |     40.092 |     5.4
   34 |   1.1115 |     37.465 |   1.1660 |     38.777 |     5.5
   35 |   1.1006 |     37.526 |   1.1705 |     39.235 |     5.7
   36 |   1.0952 |     37.057 |   1.1606 |     39.174 |     5.9
   37 |   1.0837 |     36.670 |   1.1639 |     39.297 |     6.0
   38 |   1.0769 |     36.399 |   1.1562 |     38.807 |     6.2
   39 |   1.0720 |     36.725 |   1.1439 |     38.165 |     6.4
   40 |   1.0593 |     35.770 |   1.1568 |     38.869 |     6.5
   41 |   1.0568 |     36.018 |   1.1537 |     39.021 |     6.7
   42 |   1.0526 |     35.919 |   1.1548 |     38.930 |     6.9
   43 |   1.0485 |     35.709 |   1.1547 |     39.052 |     7.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 748,962

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2020 |     55.193 |   1.6119 |     45.657 |     0.1
    2 |   1.4994 |     45.271 |   1.4141 |     45.229 |     0.2
    3 |   1.3755 |     43.857 |   1.3464 |     44.954 |     0.4
    4 |   1.3046 |     42.382 |   1.3038 |     43.945 |     0.5
    5 |   1.2582 |     41.410 |   1.2768 |     42.875 |     0.6
    6 |   1.2204 |     40.581 |   1.2390 |     40.765 |     0.8
    7 |   1.1890 |     39.736 |   1.2188 |     40.917 |     0.9
    8 |   1.1545 |     38.802 |   1.2056 |     40.734 |     1.0
    9 |   1.1225 |     37.642 |   1.1789 |     39.633 |     1.1
   10 |   1.0949 |     36.687 |   1.1753 |     38.899 |     1.3
   11 |   1.0688 |     35.532 |   1.1532 |     38.379 |     1.4
   12 |   1.0396 |     34.604 |   1.1364 |     37.920 |     1.5
   13 |   1.0095 |     33.262 |   1.1381 |     38.471 |     1.6
   14 |   0.9882 |     32.383 |   1.1160 |     36.942 |     1.8
   15 |   0.9539 |     31.184 |   1.1179 |     36.697 |     1.9
   16 |   0.9277 |     30.278 |   1.1496 |     37.462 |     2.0
   17 |   0.9025 |     29.395 |   1.1338 |     37.248 |     2.2
   18 |   0.8791 |     28.538 |   1.1067 |     36.177 |     2.3
   19 |   0.8494 |     27.748 |   1.1467 |     37.217 |     2.4
   20 |   0.8228 |     26.715 |   1.1331 |     36.300 |     2.5
   21 |   0.7965 |     25.831 |   1.1400 |     35.963 |     2.7
   22 |   0.7710 |     25.025 |   1.1582 |     36.728 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,442,594

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9149 |     50.624 |   1.4504 |     45.902 |     0.2
    2 |   1.3948 |     44.288 |   1.3530 |     43.242 |     0.4
    3 |   1.3140 |     43.443 |   1.2956 |     43.639 |     0.6
    4 |   1.2597 |     42.261 |   1.2797 |     43.303 |     0.7
    5 |   1.2150 |     41.382 |   1.2374 |     41.529 |     0.9
    6 |   1.1779 |     40.062 |   1.2269 |     42.171 |     1.1
    7 |   1.1477 |     38.990 |   1.2110 |     40.856 |     1.3
    8 |   1.1163 |     37.814 |   1.1941 |     40.367 |     1.5
    9 |   1.0878 |     36.792 |   1.1649 |     39.297 |     1.7
   10 |   1.0497 |     35.648 |   1.1742 |     39.878 |     1.9
   11 |   1.0266 |     34.681 |   1.1615 |     38.410 |     2.1
   12 |   0.9929 |     33.372 |   1.1186 |     36.239 |     2.2
   13 |   0.9677 |     32.449 |   1.1345 |     37.431 |     2.4
   14 |   0.9379 |     31.267 |   1.0736 |     34.404 |     2.6
   15 |   0.9160 |     30.836 |   1.0928 |     35.474 |     2.8
   16 |   0.8774 |     29.240 |   1.0771 |     34.832 |     3.0
   17 |   0.8575 |     28.588 |   1.0941 |     35.321 |     3.2
   18 |   0.8376 |     27.936 |   1.0900 |     34.924 |     3.4
   19 |   0.8109 |     27.058 |   1.0721 |     34.709 |     3.6
   20 |   0.7823 |     25.958 |   1.0864 |     34.893 |     3.8
   21 |   0.7591 |     25.235 |   1.0650 |     33.823 |     3.9
   22 |   0.7285 |     24.323 |   1.0844 |     33.945 |     4.1
   23 |   0.7028 |     23.196 |   1.0361 |     33.242 |     4.3
   24 |   0.6833 |     22.478 |   1.0729 |     33.517 |     4.5
   25 |   0.6621 |     21.926 |   1.0560 |     33.242 |     4.7
   26 |   0.6399 |     21.075 |   1.0709 |     33.486 |     4.9
   27 |   0.6208 |     20.368 |   1.0993 |     33.119 |     5.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 980,258

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7910 |     52.696 |   1.3414 |     45.566 |     0.1
    2 |   1.3585 |     45.271 |   1.2743 |     43.517 |     0.2
    3 |   1.2751 |     43.216 |   1.2239 |     42.171 |     0.4
    4 |   1.2193 |     41.907 |   1.2162 |     41.346 |     0.5
    5 |   1.1910 |     41.001 |   1.1867 |     40.979 |     0.6
    6 |   1.1530 |     40.018 |   1.1752 |     40.367 |     0.7
    7 |   1.1235 |     38.764 |   1.1908 |     40.122 |     0.8
    8 |   1.0906 |     37.593 |   1.1900 |     38.960 |     1.0
    9 |   1.0640 |     36.902 |   1.1798 |     38.318 |     1.1
   10 |   1.0418 |     35.676 |   1.1930 |     38.471 |     1.2
   11 |   1.0133 |     35.256 |   1.1402 |     37.706 |     1.3
   12 |   0.9814 |     33.792 |   1.1334 |     36.422 |     1.5
   13 |   0.9400 |     32.317 |   1.1547 |     36.881 |     1.6
   14 |   0.9262 |     31.715 |   1.1524 |     37.003 |     1.7
   15 |   0.8919 |     30.742 |   1.1688 |     36.330 |     1.8
   16 |   0.8640 |     29.980 |   1.2046 |     36.483 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 980,258

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7284 |     51.315 |   1.3493 |     46.483 |     0.1
    2 |   1.3489 |     45.415 |   1.2708 |     43.914 |     0.2
    3 |   1.2969 |     44.177 |   1.2626 |     43.823 |     0.4
    4 |   1.2547 |     43.283 |   1.2475 |     43.058 |     0.5
    5 |   1.2238 |     42.548 |   1.2023 |     41.590 |     0.6
    6 |   1.1846 |     41.520 |   1.1791 |     40.153 |     0.7
    7 |   1.1483 |     39.973 |   1.1717 |     39.083 |     0.8
    8 |   1.1109 |     38.620 |   1.1672 |     39.266 |     1.0
    9 |   1.0846 |     37.825 |   1.1447 |     38.532 |     1.1
   10 |   1.0642 |     37.090 |   1.1087 |     37.003 |     1.2
   11 |   1.0355 |     36.051 |   1.1048 |     37.003 |     1.3
   12 |   1.0145 |     35.322 |   1.0996 |     35.994 |     1.5
   13 |   0.9827 |     34.129 |   1.1194 |     36.453 |     1.6
   14 |   0.9604 |     33.295 |   1.0996 |     35.627 |     1.7
   15 |   0.9413 |     32.687 |   1.1061 |     35.749 |     1.8
   16 |   0.9149 |     31.842 |   1.1149 |     35.963 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 748,962

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5731 |     48.127 |   1.3178 |     44.832 |     0.2
    2 |   1.2970 |     45.089 |   1.2619 |     44.037 |     0.3
    3 |   1.2397 |     43.912 |   1.2230 |     43.945 |     0.5
    4 |   1.2112 |     43.399 |   1.1969 |     42.752 |     0.7
    5 |   1.1913 |     42.946 |   1.1612 |     41.804 |     0.9
    6 |   1.1713 |     42.504 |   1.1591 |     41.988 |     1.0
    7 |   1.1588 |     42.249 |   1.1695 |     42.018 |     1.2
    8 |   1.1477 |     41.785 |   1.1583 |     40.673 |     1.4
    9 |   1.1420 |     41.741 |   1.1447 |     40.000 |     1.6
   10 |   1.1422 |     41.609 |   1.1341 |     40.459 |     1.7
   11 |   1.1286 |     41.404 |   1.1144 |     40.214 |     1.9
   12 |   1.1275 |     41.647 |   1.1411 |     41.223 |     2.1
   13 |   1.1208 |     41.437 |   1.1279 |     40.734 |     2.2
   14 |   1.1162 |     41.012 |   1.1208 |     41.774 |     2.4
   15 |   1.1123 |     41.355 |   1.1261 |     41.162 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,243,810

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5990 |     48.834 |   1.3092 |     44.709 |     0.2
    2 |   1.3226 |     45.326 |   1.2942 |     46.483 |     0.4
    3 |   1.2766 |     44.680 |   1.2356 |     44.098 |     0.6
    4 |   1.2501 |     44.244 |   1.2147 |     42.569 |     0.8
    5 |   1.2202 |     43.470 |   1.2080 |     42.813 |     1.0
    6 |   1.2056 |     43.100 |   1.1771 |     41.896 |     1.1
    7 |   1.1880 |     42.752 |   1.1715 |     41.009 |     1.3
    8 |   1.1732 |     42.040 |   1.1898 |     41.804 |     1.5
    9 |   1.1695 |     42.084 |   1.1596 |     42.049 |     1.7
   10 |   1.1567 |     41.846 |   1.1461 |     40.275 |     1.9
   11 |   1.1503 |     41.863 |   1.1245 |     40.734 |     2.1
   12 |   1.1407 |     41.653 |   1.1393 |     40.153 |     2.3
   13 |   1.1382 |     41.393 |   1.1400 |     40.275 |     2.5
   14 |   1.1354 |     41.924 |   1.1361 |     39.755 |     2.7
   15 |   1.1259 |     41.277 |   1.1148 |     40.336 |     2.9
   16 |   1.1275 |     41.421 |   1.1193 |     40.856 |     3.1
   17 |   1.1235 |     41.625 |   1.1272 |     40.887 |     3.3
   18 |   1.1160 |     40.946 |   1.1190 |     40.581 |     3.5
   19 |   1.1141 |     41.194 |   1.1115 |     40.428 |     3.6
   20 |   1.1095 |     41.106 |   1.1321 |     40.336 |     3.8
   21 |   1.1104 |     41.062 |   1.1005 |     41.070 |     4.0
   22 |   1.1034 |     41.349 |   1.1221 |     40.459 |     4.2
   23 |   1.1016 |     40.841 |   1.1107 |     39.939 |     4.4
   24 |   1.1035 |     40.995 |   1.0911 |     39.327 |     4.6
   25 |   1.0949 |     40.266 |   1.1240 |     41.040 |     4.8
   26 |   1.0870 |     39.416 |   1.1054 |     40.122 |     5.0
   27 |   1.0794 |     39.609 |   1.1006 |     40.765 |     5.2
   28 |   1.0725 |     39.073 |   1.1242 |     41.284 |     5.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,013,538

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2870 |     56.933 |   1.5688 |     46.024 |     0.2
    2 |   1.5521 |     45.868 |   1.4034 |     45.657 |     0.4
    3 |   1.4216 |     44.973 |   1.3411 |     43.976 |     0.6
    4 |   1.3535 |     44.161 |   1.3075 |     44.404 |     0.7
    5 |   1.3055 |     43.084 |   1.2758 |     43.761 |     0.9
    6 |   1.2669 |     41.918 |   1.2634 |     42.599 |     1.1
    7 |   1.2337 |     41.515 |   1.2475 |     42.936 |     1.3
    8 |   1.2082 |     40.957 |   1.2544 |     42.294 |     1.5
    9 |   1.1824 |     39.869 |   1.2129 |     40.734 |     1.7
   10 |   1.1627 |     39.300 |   1.2317 |     41.743 |     1.9
   11 |   1.1393 |     38.554 |   1.2132 |     40.367 |     2.0
   12 |   1.1218 |     38.101 |   1.1889 |     39.388 |     2.2
   13 |   1.1015 |     37.338 |   1.2024 |     39.480 |     2.4
   14 |   1.0817 |     36.720 |   1.1902 |     39.358 |     2.6
   15 |   1.0619 |     35.808 |   1.1804 |     39.388 |     2.8
   16 |   1.0456 |     35.245 |   1.2098 |     39.878 |     3.0
   17 |   1.0276 |     34.626 |   1.1439 |     37.462 |     3.2
   18 |   1.0118 |     34.272 |   1.1480 |     37.339 |     3.3
   19 |   0.9981 |     33.737 |   1.1479 |     37.829 |     3.5
   20 |   0.9837 |     33.582 |   1.1358 |     37.064 |     3.7
   21 |   0.9641 |     32.726 |   1.1439 |     36.667 |     3.9
   22 |   0.9529 |     31.886 |   1.1765 |     37.859 |     4.1
   23 |   0.9336 |     31.450 |   1.1380 |     36.575 |     4.3
   24 |   0.9221 |     30.963 |   1.1442 |     36.789 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 425,762

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7859 |     50.779 |   1.3559 |     46.789 |     0.1
    2 |   1.3759 |     45.829 |   1.3039 |     44.924 |     0.2
    3 |   1.3093 |     44.260 |   1.2468 |     43.945 |     0.2
    4 |   1.2660 |     43.316 |   1.2437 |     43.792 |     0.3
    5 |   1.2394 |     42.791 |   1.2127 |     42.141 |     0.4
    6 |   1.2144 |     42.216 |   1.1974 |     41.162 |     0.5
    7 |   1.1882 |     41.194 |   1.1855 |     40.948 |     0.6
    8 |   1.1663 |     40.565 |   1.1695 |     40.673 |     0.6
    9 |   1.1487 |     40.078 |   1.1461 |     39.908 |     0.7
   10 |   1.1257 |     39.283 |   1.1657 |     40.061 |     0.8
   11 |   1.1104 |     39.073 |   1.1403 |     38.991 |     0.9
   12 |   1.1030 |     38.344 |   1.1362 |     38.318 |     1.0
   13 |   1.0775 |     37.670 |   1.1202 |     37.615 |     1.1
   14 |   1.0624 |     36.880 |   1.1174 |     37.676 |     1.1
   15 |   1.0402 |     35.803 |   1.1089 |     37.034 |     1.2
   16 |   1.0253 |     35.543 |   1.1048 |     36.086 |     1.3
   17 |   1.0092 |     34.902 |   1.1152 |     36.483 |     1.4
   18 |   0.9956 |     34.372 |   1.1030 |     36.361 |     1.5
   19 |   0.9742 |     33.875 |   1.1328 |     36.300 |     1.5
   20 |   0.9603 |     33.151 |   1.1361 |     36.330 |     1.6
   21 |   0.9557 |     33.107 |   1.0976 |     35.199 |     1.7
   22 |   0.9292 |     32.057 |   1.0839 |     35.015 |     1.8
   23 |   0.9157 |     31.726 |   1.1041 |     35.107 |     1.9
   24 |   0.9044 |     31.118 |   1.0835 |     35.107 |     2.0
   25 |   0.8921 |     30.941 |   1.0854 |     33.853 |     2.0
   26 |   0.8726 |     30.245 |   1.0548 |     34.251 |     2.1
   27 |   0.8571 |     29.350 |   1.0942 |     33.609 |     2.2
   28 |   0.8469 |     29.135 |   1.0812 |     34.740 |     2.3
   29 |   0.8232 |     28.759 |   1.0975 |     34.098 |     2.4
   30 |   0.8165 |     28.433 |   1.0947 |     33.609 |     2.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 582,690

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4973 |     46.481 |   1.3041 |     42.813 |     0.1
    2 |   1.2126 |     41.277 |   1.2362 |     42.446 |     0.2
    3 |   1.1394 |     39.471 |   1.1610 |     39.266 |     0.3
    4 |   1.0766 |     37.399 |   1.1515 |     39.878 |     0.4
    5 |   1.0308 |     36.024 |   1.1303 |     37.676 |     0.5
    6 |   0.9827 |     34.333 |   1.1025 |     36.636 |     0.6
    7 |   0.9340 |     32.621 |   1.0971 |     36.606 |     0.6
    8 |   0.8805 |     30.709 |   1.0860 |     35.657 |     0.7
    9 |   0.8371 |     29.201 |   1.0784 |     35.107 |     0.8
   10 |   0.7910 |     27.235 |   1.0905 |     35.199 |     0.9
   11 |   0.7453 |     25.793 |   1.1130 |     34.312 |     1.0
   12 |   0.6980 |     23.865 |   1.1322 |     34.404 |     1.1
   13 |   0.6643 |     22.799 |   1.1189 |     33.089 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 277,154

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9234 |     53.055 |   1.3791 |     45.841 |     0.1
    2 |   1.3837 |     45.514 |   1.2920 |     44.128 |     0.2
    3 |   1.3163 |     43.940 |   1.2585 |     43.119 |     0.3
    4 |   1.2716 |     43.376 |   1.2507 |     42.997 |     0.4
    5 |   1.2384 |     42.520 |   1.2388 |     41.896 |     0.5
    6 |   1.2112 |     41.598 |   1.2281 |     42.202 |     0.6
    7 |   1.1826 |     40.642 |   1.2107 |     40.795 |     0.7
    8 |   1.1547 |     39.973 |   1.2070 |     40.336 |     0.8
    9 |   1.1290 |     39.073 |   1.1953 |     39.511 |     0.9
   10 |   1.1044 |     38.261 |   1.1900 |     38.287 |     1.0
   11 |   1.0813 |     37.057 |   1.2097 |     38.685 |     1.1
   12 |   1.0611 |     36.504 |   1.1618 |     38.073 |     1.2
   13 |   1.0348 |     35.289 |   1.1748 |     38.318 |     1.3
   14 |   1.0134 |     34.803 |   1.1711 |     37.217 |     1.4
   15 |   0.9867 |     33.610 |   1.1531 |     37.003 |     1.5
   16 |   0.9630 |     33.029 |   1.1319 |     36.024 |     1.6
   17 |   0.9445 |     32.560 |   1.1576 |     36.514 |     1.7
   18 |   0.9274 |     31.753 |   1.1472 |     35.229 |     1.8
   19 |   0.9058 |     30.737 |   1.1295 |     36.055 |     1.9
   20 |   0.8793 |     30.185 |   1.1514 |     35.719 |     2.1
   21 |   0.8623 |     29.522 |   1.1566 |     35.657 |     2.2
   22 |   0.8344 |     28.715 |   1.1607 |     35.168 |     2.3
   23 |   0.8171 |     28.345 |   1.1627 |     35.657 |     2.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 393,634

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6790 |     48.481 |   1.3468 |     44.373 |     0.1
    2 |   1.2653 |     43.581 |   1.2533 |     43.517 |     0.2
    3 |   1.2024 |     42.493 |   1.1963 |     41.529 |     0.3
    4 |   1.1640 |     41.134 |   1.1674 |     42.294 |     0.4
    5 |   1.1291 |     39.857 |   1.1556 |     42.263 |     0.5
    6 |   1.0978 |     39.095 |   1.0846 |     38.838 |     0.6
    7 |   1.0787 |     38.465 |   1.1113 |     39.052 |     0.8
    8 |   1.0549 |     37.581 |   1.0852 |     38.318 |     0.9
    9 |   1.0353 |     37.206 |   1.0819 |     38.257 |     1.0
   10 |   1.0209 |     36.913 |   1.0668 |     37.309 |     1.1
   11 |   1.0010 |     35.897 |   1.0476 |     37.462 |     1.2
   12 |   0.9928 |     35.703 |   1.0400 |     36.942 |     1.3
   13 |   0.9709 |     34.996 |   1.0485 |     36.911 |     1.4
   14 |   0.9493 |     34.024 |   1.0144 |     36.606 |     1.5
   15 |   0.9408 |     33.615 |   1.0277 |     35.933 |     1.6
   16 |   0.9160 |     32.422 |   0.9954 |     34.067 |     1.7
   17 |   0.9004 |     32.140 |   0.9951 |     35.872 |     1.8
   18 |   0.8882 |     31.715 |   1.0175 |     34.771 |     2.0
   19 |   0.8664 |     30.881 |   0.9996 |     33.700 |     2.1
   20 |   0.8527 |     30.019 |   0.9988 |     34.343 |     2.2
   21 |   0.8402 |     29.787 |   1.0039 |     34.404 |     2.3
   22 |   0.8250 |     28.991 |   0.9947 |     34.526 |     2.4
   23 |   0.8006 |     28.212 |   0.9929 |     34.404 |     2.5
   24 |   0.7937 |     27.770 |   1.0031 |     33.058 |     2.6
   25 |   0.7674 |     27.014 |   0.9867 |     32.936 |     2.7
   26 |   0.7523 |     26.190 |   0.9920 |     33.425 |     2.8
   27 |   0.7420 |     26.008 |   1.0376 |     34.312 |     2.9
   28 |   0.7283 |     25.428 |   0.9810 |     32.691 |     3.0
   29 |   0.6946 |     24.224 |   0.9901 |     31.651 |     3.1
   30 |   0.6748 |     23.572 |   0.9953 |     32.294 |     3.3
   31 |   0.6706 |     23.649 |   1.0086 |     31.804 |     3.4
   32 |   0.6553 |     22.716 |   0.9805 |     32.324 |     3.5
   33 |   0.6299 |     22.158 |   1.0347 |     32.599 |     3.6
   34 |   0.6101 |     21.594 |   1.0317 |     32.783 |     3.7
   35 |   0.5923 |     20.539 |   1.0386 |     31.896 |     3.8
   36 |   0.5818 |     20.633 |   1.0419 |     31.713 |     3.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 732,130

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5497 |     63.777 |   1.7278 |     48.471 |     0.1
    2 |   1.7021 |     46.940 |   1.4555 |     45.841 |     0.2
    3 |   1.4957 |     46.194 |   1.3716 |     45.994 |     0.3
    4 |   1.4186 |     45.636 |   1.3343 |     44.709 |     0.4
    5 |   1.3755 |     44.802 |   1.3132 |     44.557 |     0.5
    6 |   1.3405 |     44.238 |   1.2912 |     44.557 |     0.7
    7 |   1.3141 |     43.697 |   1.2782 |     43.914 |     0.8
    8 |   1.2923 |     43.078 |   1.2593 |     43.364 |     0.9
    9 |   1.2716 |     42.990 |   1.2563 |     43.211 |     1.0
   10 |   1.2524 |     42.150 |   1.2435 |     43.089 |     1.1
   11 |   1.2414 |     41.846 |   1.2231 |     42.661 |     1.2
   12 |   1.2172 |     41.123 |   1.2232 |     41.927 |     1.3
   13 |   1.2018 |     40.763 |   1.2200 |     41.529 |     1.4
   14 |   1.1903 |     40.504 |   1.2109 |     41.437 |     1.5
   15 |   1.1812 |     40.460 |   1.2014 |     41.009 |     1.7
   16 |   1.1615 |     39.664 |   1.1918 |     40.489 |     1.8
   17 |   1.1542 |     39.250 |   1.1806 |     40.459 |     1.9
   18 |   1.1464 |     39.261 |   1.1755 |     40.703 |     2.0
   19 |   1.1335 |     38.719 |   1.1807 |     40.306 |     2.1
   20 |   1.1234 |     38.526 |   1.2130 |     40.612 |     2.2
   21 |   1.1107 |     37.880 |   1.1785 |     40.275 |     2.3
   22 |   1.0996 |     37.653 |   1.1689 |     39.235 |     2.4
   23 |   1.0952 |     37.421 |   1.1892 |     39.419 |     2.5
   24 |   1.0816 |     36.775 |   1.1590 |     39.083 |     2.6
   25 |   1.0736 |     36.742 |   1.1514 |     38.104 |     2.8
   26 |   1.0620 |     36.615 |   1.1472 |     38.165 |     2.9
   27 |   1.0511 |     35.819 |   1.2014 |     39.144 |     3.0
   28 |   1.0456 |     35.604 |   1.2140 |     39.725 |     3.1
   29 |   1.0360 |     35.410 |   1.1656 |     38.624 |     3.2
   30 |   1.0284 |     35.212 |   1.1788 |     38.287 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,243,810

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3575 |     59.485 |   1.5553 |     45.994 |     0.2
    2 |   1.5844 |     46.382 |   1.4034 |     46.024 |     0.4
    3 |   1.4599 |     46.271 |   1.3485 |     46.208 |     0.6
    4 |   1.4046 |     45.503 |   1.3326 |     44.557 |     0.8
    5 |   1.3648 |     44.907 |   1.2914 |     42.875 |     1.0
    6 |   1.3304 |     44.194 |   1.2763 |     43.028 |     1.1
    7 |   1.3088 |     43.586 |   1.2645 |     43.303 |     1.3
    8 |   1.2875 |     42.995 |   1.2855 |     44.159 |     1.5
    9 |   1.2694 |     42.736 |   1.2522 |     43.486 |     1.7
   10 |   1.2472 |     42.040 |   1.2343 |     42.232 |     1.9
   11 |   1.2280 |     41.294 |   1.2221 |     41.040 |     2.1
   12 |   1.2072 |     40.526 |   1.2253 |     42.171 |     2.3
   13 |   1.1956 |     40.509 |   1.2023 |     40.520 |     2.5
   14 |   1.1813 |     39.863 |   1.2077 |     40.948 |     2.7
   15 |   1.1622 |     39.614 |   1.2094 |     40.489 |     2.9
   16 |   1.1474 |     39.023 |   1.1775 |     39.419 |     3.1
   17 |   1.1366 |     38.670 |   1.1988 |     39.725 |     3.3
   18 |   1.1247 |     38.371 |   1.1760 |     38.869 |     3.4
   19 |   1.1091 |     37.769 |   1.1934 |     39.083 |     3.6
   20 |   1.0955 |     37.106 |   1.1977 |     39.174 |     3.8
   21 |   1.0831 |     36.946 |   1.1870 |     38.746 |     4.0
   22 |   1.0683 |     36.189 |   1.2057 |     38.563 |     4.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,045,026

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5179 |     47.575 |   1.2872 |     44.098 |     0.2
    2 |   1.2673 |     44.432 |   1.2445 |     43.272 |     0.4
    3 |   1.2163 |     43.399 |   1.2326 |     44.985 |     0.5
    4 |   1.1892 |     43.012 |   1.1872 |     41.927 |     0.7
    5 |   1.1663 |     42.321 |   1.1799 |     43.028 |     0.9
    6 |   1.1476 |     41.824 |   1.1664 |     41.621 |     1.1
    7 |   1.1402 |     42.012 |   1.1727 |     41.835 |     1.3
    8 |   1.1283 |     41.443 |   1.1456 |     41.193 |     1.5
    9 |   1.1220 |     41.382 |   1.1424 |     41.009 |     1.6
   10 |   1.1140 |     41.426 |   1.1339 |     40.612 |     1.8
   11 |   1.1115 |     40.957 |   1.1288 |     40.948 |     2.0
   12 |   1.1034 |     41.029 |   1.1220 |     40.917 |     2.2
   13 |   1.1035 |     41.161 |   1.1081 |     40.275 |     2.4
   14 |   1.0976 |     40.907 |   1.1119 |     40.765 |     2.5
   15 |   1.0944 |     40.896 |   1.1062 |     40.489 |     2.7
   16 |   1.0918 |     40.476 |   1.1050 |     41.131 |     2.9
   17 |   1.0879 |     40.802 |   1.1067 |     41.376 |     3.1
   18 |   1.0860 |     40.714 |   1.1152 |     40.336 |     3.3
   19 |   1.0839 |     40.631 |   1.1213 |     40.428 |     3.5
   20 |   1.0900 |     40.587 |   1.1038 |     39.878 |     3.6
   21 |   1.0807 |     40.664 |   1.0902 |     40.703 |     3.8
   22 |   1.0813 |     40.625 |   1.1002 |     39.878 |     4.0
   23 |   1.0816 |     40.620 |   1.0970 |     40.245 |     4.2
   24 |   1.0768 |     40.073 |   1.0987 |     40.306 |     4.4
   25 |   1.0771 |     40.509 |   1.1147 |     40.214 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 235,170

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8424 |     51.016 |   1.3744 |     45.382 |     0.1
    2 |   1.3824 |     45.785 |   1.3176 |     45.535 |     0.2
    3 |   1.3093 |     44.144 |   1.2631 |     42.661 |     0.3
    4 |   1.2609 |     42.979 |   1.2142 |     42.080 |     0.4
    5 |   1.2197 |     42.349 |   1.1959 |     41.957 |     0.5
    6 |   1.1860 |     40.846 |   1.2083 |     41.682 |     0.6
    7 |   1.1660 |     40.172 |   1.1715 |     40.275 |     0.7
    8 |   1.1341 |     39.327 |   1.1599 |     39.450 |     0.8
    9 |   1.1098 |     38.349 |   1.1445 |     39.205 |     0.9
   10 |   1.0870 |     37.454 |   1.1394 |     38.624 |     0.9
   11 |   1.0674 |     36.720 |   1.1459 |     38.165 |     1.0
   12 |   1.0447 |     36.112 |   1.1367 |     37.920 |     1.1
   13 |   1.0238 |     35.576 |   1.1293 |     37.034 |     1.2
   14 |   1.0006 |     35.018 |   1.1293 |     36.575 |     1.3
   15 |   0.9796 |     33.753 |   1.1066 |     36.269 |     1.4
   16 |   0.9639 |     33.344 |   1.1215 |     36.911 |     1.5
   17 |   0.9483 |     32.593 |   1.1377 |     35.352 |     1.6
   18 |   0.9240 |     32.096 |   1.1051 |     35.107 |     1.7
   19 |   0.9060 |     31.157 |   1.1576 |     35.291 |     1.8
   20 |   0.8915 |     30.682 |   1.1456 |     35.872 |     1.9
   21 |   0.8696 |     30.229 |   1.1117 |     34.985 |     2.0
   22 |   0.8473 |     29.306 |   1.0926 |     35.382 |     2.1
   23 |   0.8384 |     28.953 |   1.1582 |     36.055 |     2.2
   24 |   0.8217 |     28.505 |   1.1626 |     35.535 |     2.3
   25 |   0.8010 |     27.505 |   1.1728 |     35.291 |     2.4
   26 |   0.7756 |     26.627 |   1.1652 |     35.291 |     2.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 458,978

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6598 |     48.205 |   1.3490 |     46.177 |     0.1
    2 |   1.3218 |     44.940 |   1.2633 |     45.443 |     0.2
    3 |   1.2586 |     44.244 |   1.2362 |     42.661 |     0.3
    4 |   1.2218 |     43.531 |   1.2019 |     42.752 |     0.5
    5 |   1.1975 |     42.807 |   1.1836 |     41.284 |     0.6
    6 |   1.1827 |     42.465 |   1.1733 |     42.171 |     0.7
    7 |   1.1602 |     41.377 |   1.1568 |     41.407 |     0.8
    8 |   1.1481 |     41.134 |   1.1462 |     40.612 |     0.9
    9 |   1.1249 |     39.852 |   1.1412 |     40.122 |     1.0
   10 |   1.1175 |     40.106 |   1.1285 |     39.419 |     1.1
   11 |   1.1013 |     39.454 |   1.1296 |     39.664 |     1.3
   12 |   1.0940 |     39.073 |   1.1202 |     40.275 |     1.4
   13 |   1.0744 |     38.642 |   1.1012 |     39.052 |     1.5
   14 |   1.0708 |     38.664 |   1.0960 |     38.135 |     1.6
   15 |   1.0587 |     38.095 |   1.0883 |     38.593 |     1.7
   16 |   1.0472 |     37.697 |   1.0751 |     37.920 |     1.8
   17 |   1.0347 |     37.239 |   1.1013 |     39.144 |     1.9
   18 |   1.0303 |     37.095 |   1.0766 |     37.278 |     2.1
   19 |   1.0214 |     36.565 |   1.0855 |     37.982 |     2.2
   20 |   1.0176 |     36.532 |   1.0825 |     38.196 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 392,226

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6753 |     48.089 |   1.3238 |     44.037 |     0.1
    2 |   1.3136 |     44.332 |   1.2701 |     43.578 |     0.2
    3 |   1.2583 |     43.945 |   1.2331 |     43.456 |     0.3
    4 |   1.2266 |     43.443 |   1.2177 |     42.477 |     0.4
    5 |   1.2016 |     42.863 |   1.2153 |     41.896 |     0.5
    6 |   1.1864 |     42.675 |   1.1831 |     41.407 |     0.6
    7 |   1.1704 |     42.056 |   1.1804 |     42.508 |     0.7
    8 |   1.1630 |     42.045 |   1.1736 |     42.324 |     0.9
    9 |   1.1559 |     41.780 |   1.1524 |     42.141 |     1.0
   10 |   1.1447 |     41.912 |   1.1557 |     41.040 |     1.1
   11 |   1.1393 |     41.653 |   1.1401 |     41.070 |     1.2
   12 |   1.1344 |     41.636 |   1.1582 |     41.957 |     1.3
   13 |   1.1312 |     41.564 |   1.1456 |     40.520 |     1.4
   14 |   1.1231 |     41.183 |   1.1245 |     41.346 |     1.5
   15 |   1.1191 |     41.001 |   1.1193 |     40.122 |     1.6
   16 |   1.1130 |     41.167 |   1.1129 |     41.284 |     1.7
   17 |   1.1151 |     40.962 |   1.1083 |     39.664 |     1.8
   18 |   1.1133 |     40.924 |   1.1197 |     40.275 |     1.9
   19 |   1.1064 |     40.636 |   1.1069 |     40.122 |     2.0
   20 |   1.1065 |     40.708 |   1.1110 |     40.153 |     2.1
   21 |   1.1005 |     40.476 |   1.1115 |     40.673 |     2.2
   22 |   1.0973 |     40.542 |   1.1172 |     39.878 |     2.4
   23 |   1.0990 |     40.725 |   1.1184 |     41.009 |     2.5
   24 |   1.0910 |     40.449 |   1.1011 |     39.878 |     2.6
   25 |   1.0884 |     39.697 |   1.0834 |     39.450 |     2.7
   26 |   1.0741 |     39.520 |   1.0974 |     39.633 |     2.8
   27 |   1.0691 |     39.123 |   1.0965 |     39.817 |     2.9
   28 |   1.0616 |     38.587 |   1.0921 |     38.746 |     3.0
   29 |   1.0622 |     38.355 |   1.1026 |     39.083 |     3.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 277,154

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9885 |     55.088 |   1.4094 |     45.627 |     0.1
    2 |   1.4123 |     46.227 |   1.3386 |     45.291 |     0.2
    3 |   1.3471 |     45.581 |   1.2901 |     44.985 |     0.2
    4 |   1.2957 |     44.117 |   1.2318 |     42.538 |     0.3
    5 |   1.2557 |     43.178 |   1.2266 |     41.988 |     0.4
    6 |   1.2215 |     42.178 |   1.2003 |     41.376 |     0.5
    7 |   1.1967 |     41.272 |   1.2040 |     41.804 |     0.5
    8 |   1.1709 |     40.813 |   1.1743 |     39.297 |     0.6
    9 |   1.1533 |     40.145 |   1.1819 |     40.367 |     0.7
   10 |   1.1283 |     38.891 |   1.1838 |     39.755 |     0.8
   11 |   1.1108 |     38.134 |   1.1644 |     39.083 |     0.9
   12 |   1.0893 |     37.526 |   1.1516 |     38.287 |     0.9
   13 |   1.0699 |     36.979 |   1.1342 |     37.431 |     1.0
   14 |   1.0566 |     36.554 |   1.1335 |     37.125 |     1.1
   15 |   1.0417 |     36.051 |   1.1292 |     36.911 |     1.2
   16 |   1.0210 |     35.212 |   1.1269 |     36.361 |     1.3
   17 |   1.0105 |     34.753 |   1.1353 |     37.095 |     1.3
   18 |   0.9831 |     33.880 |   1.1270 |     37.064 |     1.4
   19 |   0.9738 |     33.499 |   1.1483 |     36.453 |     1.5
   20 |   0.9646 |     33.565 |   1.1636 |     37.584 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 648,482

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5749 |     48.321 |   1.3182 |     44.373 |     0.1
    2 |   1.3009 |     43.824 |   1.2675 |     44.067 |     0.2
    3 |   1.2494 |     43.122 |   1.2414 |     42.569 |     0.2
    4 |   1.2087 |     41.940 |   1.2181 |     42.477 |     0.3
    5 |   1.1715 |     40.813 |   1.1864 |     40.367 |     0.4
    6 |   1.1459 |     39.973 |   1.1879 |     40.826 |     0.5
    7 |   1.1188 |     39.123 |   1.1791 |     40.061 |     0.6
    8 |   1.0979 |     38.504 |   1.1603 |     39.817 |     0.6
    9 |   1.0696 |     37.548 |   1.1651 |     39.297 |     0.7
   10 |   1.0451 |     36.460 |   1.1604 |     39.083 |     0.8
   11 |   1.0260 |     35.742 |   1.1556 |     38.807 |     0.9
   12 |   1.0014 |     34.781 |   1.1769 |     38.654 |     1.0
   13 |   0.9798 |     34.284 |   1.1757 |     38.349 |     1.1
   14 |   0.9542 |     33.300 |   1.1577 |     37.737 |     1.1
   15 |   0.9481 |     32.831 |   1.1586 |     36.942 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 327,586

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9204 |     78.179 |   2.3578 |     53.180 |     0.2
    2 |   2.2799 |     52.110 |   1.7835 |     48.379 |     0.3
    3 |   1.8518 |     47.183 |   1.5725 |     45.382 |     0.5
    4 |   1.6526 |     46.431 |   1.4881 |     45.596 |     0.7
    5 |   1.5645 |     46.116 |   1.4460 |     45.566 |     0.8
    6 |   1.5125 |     46.288 |   1.4160 |     45.505 |     1.0
    7 |   1.4819 |     46.199 |   1.3994 |     45.719 |     1.1
    8 |   1.4493 |     45.868 |   1.3719 |     45.168 |     1.3
    9 |   1.4293 |     45.774 |   1.3555 |     44.801 |     1.5
   10 |   1.4121 |     45.647 |   1.3453 |     44.343 |     1.6
   11 |   1.3949 |     45.266 |   1.3296 |     44.343 |     1.8
   12 |   1.3831 |     45.244 |   1.3202 |     44.098 |     2.0
   13 |   1.3641 |     44.934 |   1.3082 |     43.914 |     2.1
   14 |   1.3527 |     44.752 |   1.3070 |     43.394 |     2.3
   15 |   1.3411 |     44.503 |   1.2947 |     43.425 |     2.4
   16 |   1.3311 |     44.122 |   1.2918 |     43.180 |     2.6
   17 |   1.3195 |     43.818 |   1.2827 |     42.905 |     2.8
   18 |   1.3125 |     43.509 |   1.2791 |     42.997 |     2.9
   19 |   1.2991 |     43.520 |   1.2747 |     42.569 |     3.1
   20 |   1.2928 |     43.017 |   1.2644 |     43.089 |     3.3
   21 |   1.2802 |     43.111 |   1.2601 |     43.211 |     3.4
   22 |   1.2789 |     42.835 |   1.2564 |     42.813 |     3.6
   23 |   1.2688 |     42.918 |   1.2466 |     42.477 |     3.7
   24 |   1.2558 |     42.504 |   1.2429 |     42.263 |     3.9
   25 |   1.2504 |     42.470 |   1.2402 |     42.508 |     4.1
   26 |   1.2456 |     42.045 |   1.2326 |     41.896 |     4.2
   27 |   1.2379 |     41.791 |   1.2399 |     42.202 |     4.4
   28 |   1.2362 |     41.863 |   1.2351 |     41.498 |     4.6
   29 |   1.2268 |     41.603 |   1.2278 |     41.621 |     4.7
   30 |   1.2261 |     41.752 |   1.2314 |     41.560 |     4.9
   31 |   1.2138 |     41.448 |   1.2225 |     41.498 |     5.0
   32 |   1.2085 |     41.399 |   1.2203 |     41.223 |     5.2
   33 |   1.2001 |     40.968 |   1.2153 |     40.917 |     5.4
   34 |   1.1934 |     40.471 |   1.2192 |     40.948 |     5.5
   35 |   1.1867 |     40.250 |   1.2258 |     41.131 |     5.7
   36 |   1.1870 |     40.371 |   1.2177 |     40.795 |     5.9
   37 |   1.1842 |     40.554 |   1.2213 |     41.529 |     6.0
   38 |   1.1767 |     40.056 |   1.2060 |     40.367 |     6.2
   39 |   1.1722 |     39.918 |   1.2161 |     41.193 |     6.4
   40 |   1.1673 |     39.940 |   1.2116 |     40.612 |     6.5
   41 |   1.1579 |     39.609 |   1.2061 |     40.092 |     6.7
   42 |   1.1569 |     39.554 |   1.2011 |     39.633 |     6.8
   43 |   1.1566 |     39.438 |   1.2019 |     40.367 |     7.0
   44 |   1.1508 |     39.631 |   1.2133 |     40.489 |     7.2
   45 |   1.1401 |     39.172 |   1.2025 |     40.367 |     7.3
   46 |   1.1413 |     39.427 |   1.2026 |     39.633 |     7.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 235,170

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8673 |     51.972 |   1.3796 |     45.107 |     0.1
    2 |   1.3520 |     44.945 |   1.2856 |     43.609 |     0.1
    3 |   1.2705 |     43.310 |   1.2547 |     43.914 |     0.2
    4 |   1.2174 |     41.979 |   1.2200 |     42.171 |     0.3
    5 |   1.1769 |     40.697 |   1.1913 |     40.367 |     0.3
    6 |   1.1439 |     39.416 |   1.1567 |     39.235 |     0.4
    7 |   1.1101 |     38.653 |   1.1557 |     39.327 |     0.5
    8 |   1.0932 |     37.709 |   1.1509 |     39.725 |     0.6
    9 |   1.0652 |     36.692 |   1.1222 |     37.645 |     0.6
   10 |   1.0402 |     36.024 |   1.1005 |     36.881 |     0.7
   11 |   1.0127 |     34.626 |   1.1209 |     37.339 |     0.8
   12 |   0.9894 |     34.057 |   1.1115 |     37.248 |     0.8
   13 |   0.9743 |     33.869 |   1.0947 |     36.330 |     0.9
   14 |   0.9631 |     32.831 |   1.1186 |     35.963 |     1.0
   15 |   0.9310 |     31.825 |   1.0733 |     35.229 |     1.0
   16 |   0.9189 |     31.775 |   1.0737 |     34.862 |     1.1
   17 |   0.8937 |     30.417 |   1.0518 |     34.526 |     1.2
   18 |   0.8816 |     30.510 |   1.0597 |     34.832 |     1.3
   19 |   0.8647 |     29.577 |   1.0555 |     33.425 |     1.3
   20 |   0.8432 |     28.837 |   1.0574 |     33.639 |     1.4
   21 |   0.8315 |     28.698 |   1.0807 |     33.853 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5633 |     59.270 |   1.9783 |     46.850 |     0.1
    2 |   1.7702 |     45.840 |   1.6051 |     46.055 |     0.2
    3 |   1.5463 |     45.338 |   1.4766 |     44.128 |     0.2
    4 |   1.4503 |     44.216 |   1.4144 |     44.862 |     0.3
    5 |   1.3937 |     43.559 |   1.3709 |     43.333 |     0.4
    6 |   1.3506 |     42.813 |   1.3461 |     44.281 |     0.5
    7 |   1.3157 |     42.437 |   1.3160 |     43.394 |     0.6
    8 |   1.2842 |     41.504 |   1.2991 |     43.486 |     0.6
    9 |   1.2553 |     41.051 |   1.2777 |     42.661 |     0.7
   10 |   1.2326 |     40.382 |   1.2693 |     42.538 |     0.8
   11 |   1.2127 |     40.089 |   1.2457 |     41.835 |     0.9
   12 |   1.1921 |     39.741 |   1.2341 |     41.865 |     1.0
   13 |   1.1745 |     39.427 |   1.2181 |     41.590 |     1.0
   14 |   1.1598 |     38.929 |   1.2099 |     40.459 |     1.1
   15 |   1.1419 |     38.487 |   1.2006 |     40.795 |     1.2
   16 |   1.1267 |     38.062 |   1.1858 |     40.122 |     1.3
   17 |   1.1159 |     37.852 |   1.1690 |     39.205 |     1.4
   18 |   1.1027 |     37.305 |   1.1692 |     39.021 |     1.4
   19 |   1.0888 |     36.642 |   1.1692 |     38.960 |     1.5
   20 |   1.0784 |     36.554 |   1.1672 |     39.725 |     1.6
   21 |   1.0669 |     35.863 |   1.1568 |     38.991 |     1.7
   22 |   1.0541 |     35.366 |   1.1350 |     37.951 |     1.8
   23 |   1.0419 |     35.372 |   1.1343 |     38.135 |     1.8
   24 |   1.0342 |     35.002 |   1.1261 |     37.339 |     1.9
   25 |   1.0208 |     34.372 |   1.1254 |     37.462 |     2.0
   26 |   1.0079 |     33.731 |   1.1114 |     36.636 |     2.1
   27 |   0.9952 |     33.378 |   1.1036 |     37.003 |     2.2
   28 |   0.9875 |     32.980 |   1.1292 |     37.156 |     2.2
   29 |   0.9749 |     32.532 |   1.1136 |     36.881 |     2.3
   30 |   0.9670 |     32.367 |   1.0959 |     35.505 |     2.4
   31 |   0.9567 |     32.151 |   1.1148 |     36.911 |     2.5
   32 |   0.9471 |     31.615 |   1.0895 |     35.749 |     2.6
   33 |   0.9372 |     31.201 |   1.1123 |     36.575 |     2.6
   34 |   0.9275 |     30.831 |   1.1034 |     36.636 |     2.7
   35 |   0.9198 |     30.610 |   1.0953 |     35.933 |     2.8
   36 |   0.9113 |     30.256 |   1.1063 |     36.177 |     2.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 343,394

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7035 |     68.429 |   2.0112 |     48.624 |     0.1
    2 |   1.8831 |     47.354 |   1.5958 |     45.596 |     0.2
    3 |   1.6279 |     46.127 |   1.4939 |     45.994 |     0.3
    4 |   1.5321 |     46.144 |   1.4297 |     45.535 |     0.4
    5 |   1.4664 |     45.741 |   1.3893 |     45.902 |     0.5
    6 |   1.4258 |     45.222 |   1.3661 |     44.709 |     0.7
    7 |   1.3895 |     44.503 |   1.3405 |     44.924 |     0.8
    8 |   1.3636 |     44.288 |   1.3209 |     44.220 |     0.9
    9 |   1.3402 |     43.791 |   1.3084 |     43.456 |     1.0
   10 |   1.3245 |     43.387 |   1.2897 |     43.089 |     1.1
   11 |   1.3018 |     43.012 |   1.2794 |     43.364 |     1.2
   12 |   1.2851 |     42.990 |   1.2707 |     43.150 |     1.3
   13 |   1.2699 |     42.393 |   1.2788 |     43.333 |     1.4
   14 |   1.2536 |     42.040 |   1.2566 |     42.385 |     1.5
   15 |   1.2455 |     41.835 |   1.2471 |     42.049 |     1.6
   16 |   1.2301 |     41.360 |   1.2646 |     43.058 |     1.8
   17 |   1.2212 |     41.349 |   1.2432 |     42.018 |     1.9
   18 |   1.2088 |     41.062 |   1.2370 |     42.263 |     2.0
   19 |   1.2010 |     40.896 |   1.2554 |     42.294 |     2.1
   20 |   1.1931 |     40.714 |   1.2344 |     41.896 |     2.2
   21 |   1.1829 |     39.863 |   1.2244 |     41.529 |     2.3
   22 |   1.1723 |     39.797 |   1.2276 |     41.682 |     2.4
   23 |   1.1660 |     39.747 |   1.2200 |     41.743 |     2.5
   24 |   1.1560 |     39.189 |   1.2242 |     42.080 |     2.6
   25 |   1.1488 |     39.189 |   1.2292 |     41.682 |     2.7
   26 |   1.1403 |     38.929 |   1.1907 |     41.193 |     2.9
   27 |   1.1328 |     38.719 |   1.2120 |     40.336 |     3.0
   28 |   1.1251 |     38.046 |   1.2047 |     40.795 |     3.1
   29 |   1.1156 |     37.847 |   1.2065 |     39.939 |     3.2
   30 |   1.1104 |     37.802 |   1.2267 |     40.703 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,177,634

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8719 |     50.779 |   1.4274 |     45.321 |     0.1
    2 |   1.3798 |     44.150 |   1.3300 |     43.639 |     0.2
    3 |   1.2880 |     42.178 |   1.2943 |     42.630 |     0.3
    4 |   1.2288 |     40.951 |   1.2506 |     42.752 |     0.4
    5 |   1.1779 |     39.471 |   1.2053 |     40.245 |     0.5
    6 |   1.1377 |     38.620 |   1.1801 |     38.593 |     0.6
    7 |   1.0984 |     36.863 |   1.1477 |     37.798 |     0.7
    8 |   1.0633 |     35.504 |   1.1275 |     37.431 |     0.8
    9 |   1.0341 |     34.477 |   1.1111 |     37.003 |     0.9
   10 |   0.9938 |     32.764 |   1.1013 |     35.810 |     1.0
   11 |   0.9672 |     31.963 |   1.1024 |     35.535 |     1.1
   12 |   0.9343 |     30.991 |   1.0801 |     35.321 |     1.2
   13 |   0.8990 |     29.842 |   1.0764 |     34.526 |     1.3
   14 |   0.8722 |     28.842 |   1.0552 |     33.272 |     1.4
   15 |   0.8381 |     27.444 |   1.0473 |     33.456 |     1.5
   16 |   0.8152 |     26.875 |   1.0361 |     33.394 |     1.5
   17 |   0.7807 |     26.041 |   1.0647 |     34.832 |     1.6
   18 |   0.7508 |     24.881 |   1.0548 |     34.037 |     1.7
   19 |   0.7183 |     23.434 |   1.0701 |     33.731 |     1.8
   20 |   0.6938 |     22.898 |   1.1301 |     34.495 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 292,258

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5693 |     60.148 |   1.9512 |     46.208 |     0.1
    2 |   1.7415 |     46.365 |   1.6006 |     45.719 |     0.1
    3 |   1.5471 |     45.719 |   1.4946 |     45.168 |     0.2
    4 |   1.4602 |     44.708 |   1.4253 |     44.281 |     0.2
    5 |   1.4014 |     44.012 |   1.3915 |     44.985 |     0.3
    6 |   1.3601 |     43.305 |   1.3510 |     43.761 |     0.4
    7 |   1.3240 |     42.730 |   1.3318 |     44.251 |     0.4
    8 |   1.2975 |     42.222 |   1.3167 |     42.936 |     0.5
    9 |   1.2734 |     41.526 |   1.3116 |     43.609 |     0.5
   10 |   1.2498 |     41.283 |   1.2901 |     42.936 |     0.6
   11 |   1.2293 |     40.802 |   1.2760 |     42.232 |     0.7
   12 |   1.2081 |     40.228 |   1.2680 |     41.437 |     0.7
   13 |   1.1883 |     39.808 |   1.2497 |     41.590 |     0.8
   14 |   1.1715 |     39.139 |   1.2688 |     41.437 |     0.8
   15 |   1.1573 |     39.051 |   1.2345 |     40.673 |     0.9
   16 |   1.1409 |     38.615 |   1.2250 |     40.979 |     1.0
   17 |   1.1251 |     37.880 |   1.2318 |     40.306 |     1.0
   18 |   1.1111 |     37.664 |   1.2012 |     39.786 |     1.1
   19 |   1.0993 |     37.338 |   1.1923 |     39.297 |     1.2
   20 |   1.0857 |     36.924 |   1.2088 |     40.092 |     1.2
   21 |   1.0770 |     36.637 |   1.2000 |     39.297 |     1.3
   22 |   1.0636 |     36.211 |   1.1840 |     38.807 |     1.3
   23 |   1.0500 |     35.455 |   1.2030 |     39.450 |     1.4
   24 |   1.0381 |     35.250 |   1.1722 |     39.144 |     1.5
   25 |   1.0274 |     34.980 |   1.1646 |     38.226 |     1.5
   26 |   1.0187 |     34.538 |   1.1811 |     38.685 |     1.6
   27 |   1.0118 |     34.074 |   1.1898 |     39.358 |     1.6
   28 |   0.9996 |     33.604 |   1.1788 |     38.777 |     1.7
   29 |   0.9890 |     33.328 |   1.1580 |     37.645 |     1.8
   30 |   0.9748 |     32.731 |   1.1645 |     37.859 |     1.8
   31 |   0.9650 |     32.621 |   1.1719 |     38.410 |     1.9
   32 |   0.9574 |     32.543 |   1.1491 |     37.309 |     1.9
   33 |   0.9479 |     32.079 |   1.1548 |     37.492 |     2.0
   34 |   0.9400 |     31.566 |   1.1448 |     37.187 |     2.1
   35 |   0.9272 |     31.195 |   1.1425 |     37.156 |     2.1
   36 |   0.9212 |     30.986 |   1.1555 |     37.584 |     2.2
   37 |   0.9112 |     30.516 |   1.1315 |     36.942 |     2.2
   38 |   0.9041 |     30.251 |   1.1635 |     37.431 |     2.3
   39 |   0.8927 |     29.986 |   1.1455 |     37.187 |     2.4
   40 |   0.8846 |     29.599 |   1.1544 |     37.064 |     2.4
   41 |   0.8738 |     29.251 |   1.1530 |     36.514 |     2.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 748,962

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6265 |     48.779 |   1.3168 |     43.853 |     0.2
    2 |   1.3229 |     45.067 |   1.2732 |     45.780 |     0.3
    3 |   1.2665 |     44.012 |   1.2335 |     43.333 |     0.5
    4 |   1.2277 |     42.763 |   1.2145 |     41.437 |     0.7
    5 |   1.1996 |     41.890 |   1.2006 |     42.324 |     0.9
    6 |   1.1767 |     41.294 |   1.2035 |     41.315 |     1.0
    7 |   1.1598 |     40.658 |   1.1806 |     41.284 |     1.2
    8 |   1.1407 |     40.371 |   1.1922 |     41.254 |     1.4
    9 |   1.1288 |     39.537 |   1.2108 |     40.673 |     1.5
   10 |   1.1139 |     39.255 |   1.1818 |     39.144 |     1.7
   11 |   1.1031 |     39.007 |   1.1809 |     39.358 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,013,538

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5703 |     48.398 |   1.3043 |     44.740 |     0.2
    2 |   1.2900 |     44.802 |   1.2444 |     44.098 |     0.4
    3 |   1.2333 |     43.990 |   1.2386 |     43.639 |     0.6
    4 |   1.2057 |     43.503 |   1.1933 |     41.865 |     0.7
    5 |   1.1845 |     42.553 |   1.1901 |     42.936 |     0.9
    6 |   1.1674 |     42.432 |   1.1679 |     41.682 |     1.1
    7 |   1.1541 |     42.255 |   1.1543 |     40.765 |     1.3
    8 |   1.1410 |     41.653 |   1.1478 |     40.000 |     1.5
    9 |   1.1354 |     41.465 |   1.1284 |     40.459 |     1.7
   10 |   1.1246 |     41.261 |   1.1298 |     40.765 |     1.9
   11 |   1.1182 |     40.940 |   1.1063 |     40.428 |     2.0
   12 |   1.1162 |     41.327 |   1.1398 |     40.673 |     2.2
   13 |   1.1121 |     40.907 |   1.1248 |     40.979 |     2.4
   14 |   1.1039 |     40.968 |   1.1284 |     40.245 |     2.6
   15 |   1.1064 |     40.802 |   1.1218 |     40.550 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,243,810

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6206 |     48.840 |   1.3294 |     45.719 |     0.1
    2 |   1.3487 |     45.785 |   1.2885 |     44.618 |     0.3
    3 |   1.3089 |     44.857 |   1.2510 |     44.312 |     0.5
    4 |   1.2727 |     44.421 |   1.2244 |     43.028 |     0.6
    5 |   1.2531 |     44.200 |   1.2136 |     42.569 |     0.8
    6 |   1.2340 |     43.470 |   1.1937 |     42.997 |     0.9
    7 |   1.2115 |     43.399 |   1.1854 |     42.080 |     1.1
    8 |   1.1943 |     42.769 |   1.1867 |     41.009 |     1.2
    9 |   1.1879 |     42.686 |   1.1755 |     42.018 |     1.4
   10 |   1.1774 |     42.504 |   1.1527 |     41.590 |     1.5
   11 |   1.1693 |     42.581 |   1.1505 |     41.498 |     1.7
   12 |   1.1637 |     42.371 |   1.1695 |     41.682 |     1.8
   13 |   1.1545 |     41.719 |   1.1473 |     41.131 |     2.0
   14 |   1.1465 |     41.697 |   1.1427 |     40.489 |     2.1
   15 |   1.1439 |     41.852 |   1.1582 |     41.040 |     2.3
   16 |   1.1376 |     41.747 |   1.1293 |     40.795 |     2.4
   17 |   1.1369 |     41.680 |   1.1361 |     40.948 |     2.6
   18 |   1.1332 |     41.548 |   1.1336 |     40.581 |     2.8
   19 |   1.1272 |     41.316 |   1.1295 |     40.428 |     2.9
   20 |   1.1229 |     41.421 |   1.1026 |     39.786 |     3.1
   21 |   1.1206 |     41.288 |   1.1214 |     40.459 |     3.2
   22 |   1.1197 |     41.454 |   1.1130 |     39.480 |     3.4
   23 |   1.1139 |     41.222 |   1.1268 |     40.826 |     3.5
   24 |   1.1141 |     41.316 |   1.1146 |     40.061 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 814,370

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6589 |     49.503 |   1.3327 |     45.015 |     0.1
    2 |   1.3335 |     44.907 |   1.2671 |     43.364 |     0.2
    3 |   1.2771 |     43.432 |   1.2562 |     42.661 |     0.3
    4 |   1.2332 |     42.493 |   1.2172 |     41.284 |     0.4
    5 |   1.2139 |     41.636 |   1.2094 |     42.538 |     0.4
    6 |   1.1862 |     40.984 |   1.2111 |     42.110 |     0.5
    7 |   1.1614 |     40.228 |   1.1913 |     39.419 |     0.6
    8 |   1.1316 |     39.029 |   1.1657 |     39.388 |     0.7
    9 |   1.1136 |     38.349 |   1.1678 |     39.052 |     0.8
   10 |   1.0940 |     37.775 |   1.1495 |     39.052 |     0.9
   11 |   1.0694 |     36.841 |   1.1611 |     38.899 |     1.0
   12 |   1.0547 |     36.615 |   1.1442 |     37.737 |     1.1
   13 |   1.0404 |     36.095 |   1.1294 |     37.584 |     1.2
   14 |   1.0262 |     35.433 |   1.1178 |     36.330 |     1.3
   15 |   1.0001 |     34.571 |   1.1337 |     37.125 |     1.4
   16 |   0.9847 |     33.897 |   1.1207 |     35.994 |     1.4
   17 |   0.9677 |     33.582 |   1.1205 |     35.291 |     1.5
   18 |   0.9519 |     33.013 |   1.1050 |     36.514 |     1.6
   19 |   0.9322 |     32.135 |   1.1261 |     36.177 |     1.7
   20 |   0.9201 |     31.869 |   1.1276 |     35.260 |     1.8
   21 |   0.9032 |     31.113 |   1.1448 |     35.596 |     1.9
   22 |   0.8912 |     30.494 |   1.1211 |     35.719 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 525,730

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3164 |     57.679 |   1.6746 |     45.596 |     0.1
    2 |   1.5730 |     45.536 |   1.5091 |     45.872 |     0.2
    3 |   1.4562 |     44.603 |   1.4345 |     45.291 |     0.3
    4 |   1.3857 |     43.769 |   1.3817 |     44.740 |     0.4
    5 |   1.3354 |     42.702 |   1.3534 |     43.272 |     0.6
    6 |   1.2935 |     41.824 |   1.3234 |     41.957 |     0.7
    7 |   1.2541 |     40.874 |   1.2885 |     42.446 |     0.8
    8 |   1.2264 |     40.322 |   1.2828 |     42.294 |     0.9
    9 |   1.2003 |     39.863 |   1.2645 |     41.682 |     1.0
   10 |   1.1741 |     39.211 |   1.2530 |     41.407 |     1.1
   11 |   1.1478 |     38.117 |   1.2460 |     40.917 |     1.2
   12 |   1.1250 |     37.692 |   1.2012 |     39.083 |     1.3
   13 |   1.1040 |     37.046 |   1.2208 |     40.245 |     1.5
   14 |   1.0816 |     35.930 |   1.1836 |     39.113 |     1.6
   15 |   1.0625 |     35.565 |   1.1547 |     37.217 |     1.7
   16 |   1.0405 |     34.869 |   1.1768 |     38.135 |     1.8
   17 |   1.0204 |     34.289 |   1.1574 |     37.859 |     1.9
   18 |   0.9950 |     33.267 |   1.1445 |     37.125 |     2.0
   19 |   0.9860 |     32.869 |   1.1778 |     37.920 |     2.1
   20 |   0.9552 |     31.698 |   1.1369 |     37.095 |     2.3
   21 |   0.9413 |     31.300 |   1.1635 |     37.951 |     2.4
   22 |   0.9202 |     30.334 |   1.1452 |     36.697 |     2.5
   23 |   0.8992 |     29.732 |   1.1407 |     35.566 |     2.6
   24 |   0.8862 |     29.439 |   1.1335 |     36.483 |     2.7
   25 |   0.8686 |     28.582 |   1.1332 |     35.994 |     2.8
   26 |   0.8515 |     28.008 |   1.1085 |     35.505 |     2.9
   27 |   0.8300 |     27.444 |   1.1188 |     35.413 |     3.0
   28 |   0.8143 |     26.831 |   1.1039 |     34.832 |     3.2
   29 |   0.7998 |     26.483 |   1.1148 |     34.862 |     3.3
   30 |   0.7829 |     25.489 |   1.1414 |     35.902 |     3.4
   31 |   0.7604 |     24.865 |   1.1236 |     35.902 |     3.5
   32 |   0.7459 |     24.749 |   1.1307 |     35.657 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 648,482

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6087 |     48.033 |   1.3093 |     44.220 |     0.1
    2 |   1.2991 |     43.724 |   1.2741 |     43.150 |     0.2
    3 |   1.2464 |     42.531 |   1.2425 |     42.599 |     0.2
    4 |   1.2009 |     41.172 |   1.1835 |     40.550 |     0.3
    5 |   1.1682 |     40.117 |   1.1932 |     40.183 |     0.4
    6 |   1.1348 |     39.106 |   1.1429 |     38.012 |     0.5
    7 |   1.1095 |     38.150 |   1.1462 |     38.960 |     0.6
    8 |   1.0811 |     37.366 |   1.1451 |     37.951 |     0.6
    9 |   1.0613 |     36.366 |   1.1263 |     36.758 |     0.7
   10 |   1.0357 |     35.886 |   1.1369 |     37.034 |     0.8
   11 |   1.0023 |     34.477 |   1.1153 |     36.300 |     0.9
   12 |   0.9895 |     34.261 |   1.1330 |     36.239 |     1.0
   13 |   0.9692 |     33.162 |   1.1455 |     36.789 |     1.1
   14 |   0.9482 |     32.781 |   1.1106 |     34.924 |     1.1
   15 |   0.9222 |     31.571 |   1.1108 |     34.465 |     1.2
   16 |   0.9062 |     31.505 |   1.0865 |     34.557 |     1.3
   17 |   0.8920 |     30.781 |   1.1205 |     34.037 |     1.4
   18 |   0.8730 |     30.063 |   1.1036 |     33.547 |     1.5
   19 |   0.8567 |     29.649 |   1.1434 |     34.740 |     1.5
   20 |   0.8258 |     28.721 |   1.1035 |     33.609 |     1.6
   21 |   0.8198 |     28.356 |   1.0817 |     33.884 |     1.7
   22 |   0.7881 |     27.168 |   1.1280 |     34.128 |     1.8
   23 |   0.7787 |     26.997 |   1.1444 |     34.832 |     1.9
   24 |   0.7660 |     26.483 |   1.1796 |     34.771 |     2.0
   25 |   0.7436 |     25.528 |   1.1322 |     32.905 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 525,730

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6056 |     47.288 |   1.3095 |     44.128 |     0.1
    2 |   1.2835 |     43.724 |   1.2770 |     44.434 |     0.2
    3 |   1.2209 |     42.934 |   1.2104 |     41.193 |     0.3
    4 |   1.1747 |     41.531 |   1.1872 |     41.743 |     0.5
    5 |   1.1366 |     40.487 |   1.1640 |     40.367 |     0.6
    6 |   1.1035 |     39.211 |   1.1604 |     40.000 |     0.7
    7 |   1.0833 |     38.266 |   1.1317 |     38.746 |     0.8
    8 |   1.0599 |     37.416 |   1.0961 |     38.899 |     0.9
    9 |   1.0352 |     36.974 |   1.0855 |     37.339 |     1.0
   10 |   1.0242 |     36.316 |   1.0890 |     37.768 |     1.1
   11 |   1.0071 |     36.002 |   1.0735 |     37.920 |     1.2
   12 |   0.9984 |     35.515 |   1.0673 |     36.758 |     1.4
   13 |   0.9878 |     35.062 |   1.0659 |     37.339 |     1.5
   14 |   0.9682 |     34.206 |   1.0506 |     37.370 |     1.6
   15 |   0.9495 |     33.438 |   1.0239 |     35.810 |     1.7
   16 |   0.9409 |     33.665 |   1.0318 |     35.076 |     1.8
   17 |   0.9347 |     33.350 |   1.0173 |     36.239 |     1.9
   18 |   0.9239 |     32.610 |   1.0038 |     34.281 |     2.0
   19 |   0.9111 |     32.416 |   1.0181 |     35.260 |     2.1
   20 |   0.8904 |     31.427 |   1.0066 |     34.098 |     2.3
   21 |   0.8802 |     31.472 |   1.0026 |     34.495 |     2.4
   22 |   0.8638 |     30.477 |   1.0182 |     34.740 |     2.5
   23 |   0.8479 |     29.980 |   1.0273 |     35.657 |     2.6
   24 |   0.8410 |     29.372 |   0.9891 |     33.517 |     2.7
   25 |   0.8208 |     28.897 |   0.9629 |     32.263 |     2.8
   26 |   0.8108 |     28.538 |   0.9806 |     33.150 |     3.0
   27 |   0.7987 |     28.025 |   0.9651 |     32.385 |     3.1
   28 |   0.7733 |     27.257 |   0.9307 |     31.743 |     3.2
   29 |   0.7722 |     27.080 |   0.9610 |     32.202 |     3.3
   30 |   0.7512 |     26.621 |   0.9981 |     33.425 |     3.4
   31 |   0.7318 |     25.644 |   0.9398 |     32.477 |     3.5
   32 |   0.7193 |     25.323 |   0.9804 |     31.835 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 425,762

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7994 |     50.315 |   1.3674 |     45.535 |     0.1
    2 |   1.3718 |     45.697 |   1.2895 |     43.731 |     0.2
    3 |   1.3041 |     44.028 |   1.2638 |     43.578 |     0.3
    4 |   1.2531 |     42.725 |   1.2438 |     42.416 |     0.4
    5 |   1.2204 |     41.957 |   1.1726 |     40.703 |     0.5
    6 |   1.1883 |     41.189 |   1.1891 |     41.193 |     0.6
    7 |   1.1592 |     40.554 |   1.1476 |     38.930 |     0.7
    8 |   1.1328 |     39.134 |   1.1341 |     38.654 |     0.9
    9 |   1.1121 |     38.769 |   1.1490 |     38.930 |     1.0
   10 |   1.0857 |     37.570 |   1.1448 |     38.502 |     1.1
   11 |   1.0652 |     36.985 |   1.1202 |     36.820 |     1.2
   12 |   1.0500 |     36.029 |   1.1454 |     37.064 |     1.3
   13 |   1.0210 |     35.250 |   1.1063 |     36.239 |     1.4
   14 |   1.0022 |     34.549 |   1.1454 |     35.963 |     1.5
   15 |   0.9749 |     33.554 |   1.1117 |     36.575 |     1.6
   16 |   0.9655 |     33.488 |   1.1196 |     36.239 |     1.7
   17 |   0.9384 |     32.416 |   1.1051 |     36.972 |     1.8
   18 |   0.9142 |     31.588 |   1.1246 |     35.810 |     1.9
   19 |   0.8936 |     30.842 |   1.0877 |     36.086 |     2.0
   20 |   0.8823 |     30.494 |   1.1013 |     35.933 |     2.1
   21 |   0.8612 |     29.400 |   1.1117 |     34.434 |     2.2
   22 |   0.8259 |     28.649 |   1.1076 |     34.465 |     2.4
   23 |   0.8211 |     28.367 |   1.1259 |     35.107 |     2.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 814,370

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1946 |     54.845 |   1.5169 |     45.627 |     0.1
    2 |   1.5228 |     46.255 |   1.3885 |     45.260 |     0.2
    3 |   1.4198 |     45.592 |   1.3349 |     44.557 |     0.3
    4 |   1.3587 |     44.470 |   1.3120 |     44.159 |     0.4
    5 |   1.3194 |     43.564 |   1.2810 |     43.119 |     0.6
    6 |   1.2852 |     42.780 |   1.2738 |     43.547 |     0.7
    7 |   1.2605 |     42.349 |   1.2466 |     42.997 |     0.8
    8 |   1.2390 |     41.415 |   1.2566 |     43.425 |     0.9
    9 |   1.2088 |     40.852 |   1.2399 |     42.080 |     1.0
   10 |   1.1903 |     40.283 |   1.2129 |     41.529 |     1.1
   11 |   1.1736 |     40.266 |   1.1905 |     41.254 |     1.2
   12 |   1.1523 |     39.399 |   1.1926 |     40.550 |     1.3
   13 |   1.1386 |     38.918 |   1.1923 |     40.061 |     1.4
   14 |   1.1246 |     38.587 |   1.1684 |     39.419 |     1.6
   15 |   1.1051 |     37.808 |   1.1608 |     38.685 |     1.7
   16 |   1.0962 |     37.206 |   1.1456 |     38.043 |     1.8
   17 |   1.0775 |     36.648 |   1.1640 |     39.052 |     1.9
   18 |   1.0668 |     36.399 |   1.1481 |     37.798 |     2.0
   19 |   1.0555 |     36.068 |   1.1233 |     37.187 |     2.1
   20 |   1.0404 |     35.416 |   1.1287 |     36.667 |     2.2
   21 |   1.0247 |     34.858 |   1.1171 |     36.055 |     2.3
   22 |   1.0201 |     34.908 |   1.1294 |     36.728 |     2.5
   23 |   1.0081 |     34.383 |   1.1239 |     36.391 |     2.6
   24 |   0.9956 |     33.764 |   1.1363 |     36.300 |     2.7
   25 |   0.9834 |     33.681 |   1.1165 |     35.994 |     2.8
   26 |   0.9725 |     32.919 |   1.1053 |     35.505 |     2.9
   27 |   0.9629 |     32.825 |   1.1410 |     36.422 |     3.0
   28 |   0.9510 |     31.985 |   1.0911 |     35.076 |     3.1
   29 |   0.9355 |     31.637 |   1.0945 |     35.474 |     3.2
   30 |   0.9270 |     31.278 |   1.1015 |     34.862 |     3.4
   31 |   0.9213 |     31.582 |   1.0910 |     34.679 |     3.5
   32 |   0.9063 |     30.792 |   1.0839 |     34.465 |     3.6
   33 |   0.8976 |     30.256 |   1.0885 |     34.801 |     3.7
   34 |   0.8848 |     29.941 |   1.0824 |     34.465 |     3.8
   35 |   0.8743 |     29.737 |   1.0801 |     33.945 |     3.9
   36 |   0.8671 |     29.566 |   1.0974 |     34.190 |     4.0
   37 |   0.8584 |     29.124 |   1.0585 |     33.731 |     4.1
   38 |   0.8457 |     28.538 |   1.0725 |     33.823 |     4.3
   39 |   0.8363 |     28.284 |   1.0778 |     34.006 |     4.4
   40 |   0.8244 |     27.654 |   1.0924 |     34.526 |     4.5
   41 |   0.8219 |     27.770 |   1.0868 |     33.914 |     4.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 732,130

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6282 |     48.912 |   1.3303 |     44.557 |     0.1
    2 |   1.3220 |     44.039 |   1.2619 |     43.425 |     0.2
    3 |   1.2554 |     42.564 |   1.2130 |     41.376 |     0.3
    4 |   1.2091 |     41.415 |   1.2273 |     42.477 |     0.4
    5 |   1.1707 |     40.194 |   1.1747 |     40.000 |     0.4
    6 |   1.1339 |     39.023 |   1.1691 |     39.725 |     0.5
    7 |   1.1060 |     37.863 |   1.1571 |     38.991 |     0.6
    8 |   1.0816 |     37.068 |   1.1285 |     36.911 |     0.7
    9 |   1.0518 |     36.057 |   1.1316 |     36.575 |     0.8
   10 |   1.0228 |     35.399 |   1.1516 |     37.370 |     0.9
   11 |   1.0009 |     34.449 |   1.1193 |     36.300 |     1.0
   12 |   0.9748 |     33.344 |   1.1345 |     35.780 |     1.1
   13 |   0.9567 |     32.864 |   1.1130 |     35.810 |     1.2
   14 |   0.9376 |     32.383 |   1.1585 |     35.291 |     1.2
   15 |   0.9085 |     31.450 |   1.1483 |     35.076 |     1.3
   16 |   0.8887 |     30.781 |   1.1238 |     34.893 |     1.4
   17 |   0.8648 |     30.118 |   1.1007 |     34.006 |     1.5
   18 |   0.8437 |     29.185 |   1.1588 |     35.749 |     1.6
   19 |   0.8340 |     29.240 |   1.1779 |     33.976 |     1.7
   20 |   0.8107 |     28.047 |   1.1258 |     34.557 |     1.8
   21 |   0.7877 |     27.229 |   1.1494 |     35.688 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 292,258

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7216 |     48.851 |   1.3517 |     45.046 |     0.1
    2 |   1.3505 |     45.050 |   1.2704 |     44.159 |     0.2
    3 |   1.2804 |     43.857 |   1.2323 |     42.752 |     0.3
    4 |   1.2361 |     42.874 |   1.2027 |     41.896 |     0.4
    5 |   1.2055 |     41.752 |   1.1800 |     42.049 |     0.5
    6 |   1.1741 |     40.968 |   1.1700 |     40.765 |     0.5
    7 |   1.1532 |     40.277 |   1.1737 |     39.939 |     0.6
    8 |   1.1345 |     39.576 |   1.1390 |     39.694 |     0.7
    9 |   1.1078 |     38.780 |   1.1457 |     38.930 |     0.8
   10 |   1.0916 |     38.471 |   1.1269 |     38.869 |     0.9
   11 |   1.0768 |     37.559 |   1.1086 |     37.523 |     1.0
   12 |   1.0614 |     36.653 |   1.1315 |     38.869 |     1.1
   13 |   1.0436 |     36.206 |   1.1074 |     36.697 |     1.2
   14 |   1.0260 |     35.565 |   1.1023 |     36.942 |     1.3
   15 |   1.0081 |     35.167 |   1.1128 |     36.758 |     1.3
   16 |   0.9985 |     34.587 |   1.0942 |     37.034 |     1.4
   17 |   0.9808 |     34.118 |   1.1117 |     37.095 |     1.5
   18 |   0.9755 |     33.819 |   1.0777 |     35.413 |     1.6
   19 |   0.9613 |     33.449 |   1.1091 |     36.514 |     1.7
   20 |   0.9422 |     32.742 |   1.0897 |     35.505 |     1.8
   21 |   0.9325 |     32.212 |   1.1173 |     36.789 |     1.9
   22 |   0.9245 |     32.135 |   1.0715 |     35.229 |     2.0
   23 |   0.9004 |     31.102 |   1.1010 |     35.321 |     2.1
   24 |   0.8898 |     30.698 |   1.1252 |     34.985 |     2.2
   25 |   0.8799 |     30.229 |   1.1302 |     35.566 |     2.2
   26 |   0.8622 |     29.798 |   1.0944 |     34.648 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 327,586

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6888 |     63.054 |   1.9967 |     48.410 |     0.2
    2 |   1.9366 |     47.243 |   1.6287 |     46.544 |     0.3
    3 |   1.6650 |     46.315 |   1.5021 |     45.627 |     0.5
    4 |   1.5522 |     46.023 |   1.4359 |     45.627 |     0.7
    5 |   1.4890 |     45.592 |   1.4038 |     44.495 |     0.8
    6 |   1.4465 |     45.547 |   1.3722 |     44.098 |     1.0
    7 |   1.4075 |     44.669 |   1.3506 |     43.670 |     1.1
    8 |   1.3788 |     44.188 |   1.3300 |     43.945 |     1.3
    9 |   1.3559 |     43.658 |   1.3187 |     43.914 |     1.5
   10 |   1.3322 |     43.260 |   1.3025 |     43.761 |     1.6
   11 |   1.3139 |     42.714 |   1.2822 |     42.569 |     1.8
   12 |   1.2967 |     42.493 |   1.2721 |     42.508 |     2.0
   13 |   1.2809 |     42.437 |   1.2751 |     43.058 |     2.1
   14 |   1.2672 |     41.951 |   1.2730 |     43.028 |     2.3
   15 |   1.2576 |     41.471 |   1.2610 |     42.783 |     2.5
   16 |   1.2394 |     41.366 |   1.2586 |     42.569 |     2.6
   17 |   1.2283 |     41.100 |   1.2366 |     41.774 |     2.8
   18 |   1.2198 |     41.111 |   1.2296 |     42.171 |     3.0
   19 |   1.2093 |     40.852 |   1.2276 |     41.927 |     3.1
   20 |   1.2006 |     40.769 |   1.2208 |     41.957 |     3.3
   21 |   1.1886 |     40.106 |   1.2148 |     41.590 |     3.5
   22 |   1.1788 |     39.819 |   1.2180 |     41.315 |     3.6
   23 |   1.1748 |     39.432 |   1.2129 |     40.428 |     3.8
   24 |   1.1619 |     39.548 |   1.2032 |     40.550 |     3.9
   25 |   1.1508 |     39.090 |   1.2154 |     40.061 |     4.1
   26 |   1.1485 |     38.863 |   1.1885 |     39.969 |     4.3
   27 |   1.1360 |     38.454 |   1.2054 |     39.939 |     4.4
   28 |   1.1275 |     38.167 |   1.1849 |     39.327 |     4.6
   29 |   1.1203 |     37.802 |   1.2105 |     39.664 |     4.8
   30 |   1.1139 |     37.692 |   1.2130 |     39.419 |     4.9
   31 |   1.1097 |     37.294 |   1.1833 |     38.379 |     5.1
   32 |   1.0966 |     36.703 |   1.1880 |     38.746 |     5.3
   33 |   1.0918 |     37.106 |   1.1901 |     38.471 |     5.4
   34 |   1.0804 |     36.322 |   1.1833 |     38.287 |     5.6
   35 |   1.0768 |     36.228 |   1.1962 |     38.471 |     5.7
   36 |   1.0725 |     36.421 |   1.1821 |     38.287 |     5.9
   37 |   1.0659 |     35.930 |   1.1986 |     38.777 |     6.1
   38 |   1.0566 |     35.742 |   1.1791 |     37.676 |     6.2
   39 |   1.0531 |     35.422 |   1.1941 |     38.043 |     6.4
   40 |   1.0484 |     35.162 |   1.1814 |     37.401 |     6.6
   41 |   1.0348 |     35.013 |   1.2019 |     37.982 |     6.7
   42 |   1.0332 |     34.687 |   1.1740 |     37.339 |     6.9
   43 |   1.0299 |     34.836 |   1.1908 |     37.982 |     7.0
   44 |   1.0236 |     34.659 |   1.2074 |     38.196 |     7.2
   45 |   1.0192 |     34.339 |   1.1846 |     37.492 |     7.4
   46 |   1.0106 |     34.173 |   1.2022 |     38.440 |     7.5
   47 |   1.0071 |     33.819 |   1.1733 |     37.125 |     7.7
   48 |   0.9944 |     33.565 |   1.1610 |     37.339 |     7.9
   49 |   0.9945 |     33.543 |   1.1643 |     36.636 |     8.0
   50 |   0.9867 |     33.085 |   1.1822 |     36.820 |     8.2
   51 |   0.9831 |     33.366 |   1.1605 |     36.850 |     8.4
   52 |   0.9736 |     32.952 |   1.2021 |     37.554 |     8.5
   53 |   0.9693 |     32.477 |   1.1738 |     36.606 |     8.7
   54 |   0.9678 |     32.466 |   1.1803 |     37.339 |     8.8
   55 |   0.9625 |     32.284 |   1.1638 |     36.116 |     9.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 814,370

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6727 |     49.575 |   1.3139 |     44.557 |     0.1
    2 |   1.3236 |     44.686 |   1.2684 |     43.394 |     0.2
    3 |   1.2700 |     43.365 |   1.2103 |     42.080 |     0.3
    4 |   1.2194 |     41.995 |   1.2120 |     42.080 |     0.4
    5 |   1.1855 |     40.570 |   1.1809 |     40.856 |     0.6
    6 |   1.1398 |     39.084 |   1.1524 |     39.235 |     0.7
    7 |   1.1153 |     38.366 |   1.1469 |     38.838 |     0.8
    8 |   1.0809 |     37.145 |   1.1409 |     38.502 |     0.9
    9 |   1.0542 |     36.217 |   1.1352 |     37.890 |     1.0
   10 |   1.0191 |     35.366 |   1.1396 |     37.339 |     1.1
   11 |   0.9974 |     34.521 |   1.1632 |     36.514 |     1.2
   12 |   0.9644 |     33.598 |   1.1147 |     36.239 |     1.3
   13 |   0.9477 |     33.134 |   1.1221 |     36.758 |     1.5
   14 |   0.9127 |     31.483 |   1.1191 |     35.260 |     1.6
   15 |   0.8945 |     30.858 |   1.1540 |     35.291 |     1.7
   16 |   0.8606 |     29.941 |   1.1481 |     34.373 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 847,650

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0929 |     53.359 |   1.5301 |     46.636 |     0.2
    2 |   1.4525 |     45.608 |   1.3895 |     44.495 |     0.3
    3 |   1.3604 |     44.343 |   1.3307 |     44.281 |     0.5
    4 |   1.3047 |     43.349 |   1.3028 |     43.272 |     0.6
    5 |   1.2627 |     42.122 |   1.2678 |     42.875 |     0.8
    6 |   1.2272 |     41.084 |   1.2334 |     40.917 |     1.0
    7 |   1.1881 |     40.084 |   1.2061 |     40.612 |     1.1
    8 |   1.1587 |     39.139 |   1.1997 |     40.336 |     1.3
    9 |   1.1344 |     38.637 |   1.1828 |     40.459 |     1.5
   10 |   1.1068 |     37.510 |   1.1588 |     38.991 |     1.6
   11 |   1.0818 |     36.455 |   1.1587 |     39.388 |     1.8
   12 |   1.0546 |     35.394 |   1.1379 |     37.737 |     2.0
   13 |   1.0328 |     34.985 |   1.1146 |     37.003 |     2.1
   14 |   1.0088 |     33.908 |   1.1332 |     38.165 |     2.3
   15 |   0.9871 |     33.068 |   1.1333 |     37.217 |     2.4
   16 |   0.9693 |     32.599 |   1.1165 |     37.951 |     2.6
   17 |   0.9487 |     31.914 |   1.1150 |     36.483 |     2.8
   18 |   0.9223 |     30.870 |   1.0974 |     35.719 |     2.9
   19 |   0.9099 |     30.472 |   1.0800 |     35.168 |     3.1
   20 |   0.8840 |     29.455 |   1.0892 |     34.985 |     3.3
   21 |   0.8645 |     28.748 |   1.0892 |     35.688 |     3.4
   22 |   0.8457 |     27.842 |   1.0889 |     35.138 |     3.6
   23 |   0.8292 |     27.340 |   1.1135 |     36.116 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 193,186

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6698 |     60.386 |   2.0417 |     47.003 |     0.1
    2 |   1.9106 |     47.310 |   1.6328 |     46.575 |     0.1
    3 |   1.6422 |     46.249 |   1.5045 |     45.627 |     0.2
    4 |   1.5383 |     46.050 |   1.4449 |     45.413 |     0.2
    5 |   1.4822 |     45.846 |   1.4068 |     45.168 |     0.3
    6 |   1.4458 |     45.802 |   1.3845 |     44.709 |     0.4
    7 |   1.4140 |     45.454 |   1.3609 |     44.740 |     0.4
    8 |   1.3904 |     44.973 |   1.3442 |     44.618 |     0.5
    9 |   1.3696 |     45.111 |   1.3300 |     44.740 |     0.6
   10 |   1.3491 |     44.553 |   1.3163 |     44.465 |     0.6
   11 |   1.3292 |     44.216 |   1.3031 |     44.190 |     0.7
   12 |   1.3143 |     43.785 |   1.2958 |     44.128 |     0.8
   13 |   1.2987 |     43.454 |   1.2746 |     43.547 |     0.8
   14 |   1.2855 |     43.078 |   1.2715 |     44.098 |     0.9
   15 |   1.2715 |     42.984 |   1.2672 |     43.884 |     0.9
   16 |   1.2658 |     42.404 |   1.2554 |     43.700 |     1.0
   17 |   1.2540 |     42.012 |   1.2493 |     43.180 |     1.1
   18 |   1.2436 |     41.951 |   1.2405 |     43.456 |     1.1
   19 |   1.2305 |     41.697 |   1.2451 |     42.966 |     1.2
   20 |   1.2265 |     41.349 |   1.2405 |     42.783 |     1.3
   21 |   1.2226 |     41.040 |   1.2417 |     42.905 |     1.3
   22 |   1.2092 |     41.150 |   1.2290 |     42.691 |     1.4
   23 |   1.1994 |     40.377 |   1.2300 |     42.294 |     1.4
   24 |   1.1923 |     40.432 |   1.2191 |     41.651 |     1.5
   25 |   1.1865 |     40.194 |   1.2198 |     41.865 |     1.6
   26 |   1.1799 |     40.101 |   1.2073 |     41.560 |     1.6
   27 |   1.1726 |     39.902 |   1.2032 |     41.651 |     1.7
   28 |   1.1672 |     39.808 |   1.2018 |     40.979 |     1.8
   29 |   1.1608 |     39.614 |   1.2134 |     41.621 |     1.8
   30 |   1.1494 |     39.377 |   1.1954 |     41.284 |     1.9
   31 |   1.1508 |     39.051 |   1.1978 |     41.804 |     2.0
   32 |   1.1402 |     39.045 |   1.1901 |     41.101 |     2.0
   33 |   1.1337 |     38.692 |   1.1760 |     40.153 |     2.1
   34 |   1.1246 |     38.305 |   1.1761 |     40.214 |     2.1
   35 |   1.1234 |     38.421 |   1.1642 |     39.266 |     2.2
   36 |   1.1127 |     38.117 |   1.1729 |     39.266 |     2.3
   37 |   1.1058 |     37.742 |   1.1619 |     39.052 |     2.3
   38 |   1.1015 |     37.526 |   1.1836 |     39.939 |     2.4
   39 |   1.1001 |     37.697 |   1.1706 |     39.266 |     2.5
   40 |   1.0859 |     36.847 |   1.1662 |     38.991 |     2.5
   41 |   1.0855 |     36.780 |   1.1544 |     38.930 |     2.6
   42 |   1.0857 |     37.062 |   1.1483 |     38.777 |     2.6
   43 |   1.0736 |     36.565 |   1.1537 |     38.532 |     2.7
   44 |   1.0747 |     36.322 |   1.1532 |     38.991 |     2.8
   45 |   1.0682 |     36.532 |   1.1589 |     39.266 |     2.8
   46 |   1.0592 |     36.112 |   1.1611 |     38.899 |     2.9
   47 |   1.0573 |     35.930 |   1.1466 |     38.257 |     3.0
   48 |   1.0514 |     35.919 |   1.1475 |     38.685 |     3.0
   49 |   1.0457 |     35.770 |   1.1577 |     38.349 |     3.1
   50 |   1.0492 |     35.714 |   1.1553 |     38.196 |     3.1
   51 |   1.0414 |     35.223 |   1.1370 |     37.278 |     3.2
   52 |   1.0367 |     35.344 |   1.1445 |     37.829 |     3.3
   53 |   1.0334 |     35.178 |   1.1434 |     37.798 |     3.3
   54 |   1.0261 |     34.913 |   1.1361 |     37.187 |     3.4
   55 |   1.0213 |     34.858 |   1.1623 |     38.073 |     3.5
   56 |   1.0205 |     34.709 |   1.1499 |     37.890 |     3.5
   57 |   1.0122 |     34.101 |   1.1389 |     36.972 |     3.6
   58 |   1.0096 |     34.217 |   1.1403 |     36.972 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 898,402

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2917 |     56.126 |   1.5948 |     45.688 |     0.1
    2 |   1.5757 |     46.072 |   1.4184 |     45.535 |     0.3
    3 |   1.4427 |     45.338 |   1.3492 |     44.373 |     0.4
    4 |   1.3780 |     44.155 |   1.3093 |     44.312 |     0.6
    5 |   1.3289 |     43.410 |   1.2704 |     43.150 |     0.7
    6 |   1.2947 |     42.598 |   1.2528 |     42.018 |     0.9
    7 |   1.2616 |     42.233 |   1.2272 |     41.284 |     1.0
    8 |   1.2319 |     41.145 |   1.2230 |     41.804 |     1.2
    9 |   1.2106 |     40.763 |   1.2071 |     41.376 |     1.3
   10 |   1.1895 |     40.167 |   1.1930 |     41.284 |     1.4
   11 |   1.1745 |     39.576 |   1.1905 |     41.223 |     1.6
   12 |   1.1564 |     39.338 |   1.1694 |     40.153 |     1.7
   13 |   1.1423 |     38.819 |   1.1664 |     39.327 |     1.9
   14 |   1.1307 |     38.708 |   1.1555 |     39.266 |     2.0
   15 |   1.1177 |     38.007 |   1.1569 |     39.266 |     2.2
   16 |   1.0983 |     37.488 |   1.1369 |     38.991 |     2.3
   17 |   1.0901 |     37.245 |   1.1355 |     38.624 |     2.5
   18 |   1.0750 |     36.720 |   1.1277 |     39.021 |     2.6
   19 |   1.0649 |     36.493 |   1.1360 |     38.624 |     2.8
   20 |   1.0485 |     35.714 |   1.1144 |     38.135 |     2.9
   21 |   1.0425 |     35.118 |   1.1136 |     37.706 |     3.0
   22 |   1.0288 |     34.985 |   1.1025 |     37.920 |     3.2
   23 |   1.0184 |     34.466 |   1.1018 |     37.064 |     3.3
   24 |   1.0018 |     34.057 |   1.0818 |     36.239 |     3.5
   25 |   0.9951 |     33.913 |   1.0894 |     36.575 |     3.6
   26 |   0.9824 |     33.284 |   1.0889 |     36.453 |     3.8
   27 |   0.9732 |     33.300 |   1.0768 |     36.116 |     3.9
   28 |   0.9575 |     32.499 |   1.0753 |     36.269 |     4.1
   29 |   0.9492 |     31.858 |   1.0874 |     36.177 |     4.2
   30 |   0.9346 |     31.720 |   1.0591 |     35.107 |     4.4
   31 |   0.9239 |     31.422 |   1.0909 |     35.719 |     4.5
   32 |   0.9147 |     30.969 |   1.0842 |     35.321 |     4.7
   33 |   0.9044 |     30.842 |   1.0866 |     35.443 |     4.8
   34 |   0.8931 |     30.057 |   1.0614 |     34.618 |     4.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 732,130

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6474 |     49.486 |   1.3488 |     44.343 |     0.1
    2 |   1.3284 |     44.713 |   1.2901 |     43.976 |     0.2
    3 |   1.2668 |     43.421 |   1.2064 |     41.835 |     0.3
    4 |   1.2126 |     41.714 |   1.2127 |     42.752 |     0.4
    5 |   1.1936 |     41.349 |   1.1697 |     40.856 |     0.4
    6 |   1.1625 |     40.101 |   1.1737 |     40.275 |     0.5
    7 |   1.1304 |     39.382 |   1.1690 |     38.624 |     0.6
    8 |   1.1074 |     38.300 |   1.1457 |     39.297 |     0.7
    9 |   1.0776 |     36.797 |   1.1773 |     38.777 |     0.8
   10 |   1.0576 |     36.327 |   1.1331 |     37.462 |     0.9
   11 |   1.0313 |     34.935 |   1.1375 |     36.453 |     1.0
   12 |   1.0032 |     34.620 |   1.1586 |     37.156 |     1.1
   13 |   0.9825 |     33.875 |   1.1362 |     37.064 |     1.2
   14 |   0.9666 |     33.140 |   1.1241 |     35.566 |     1.3
   15 |   0.9490 |     32.599 |   1.1352 |     36.177 |     1.4
   16 |   0.9237 |     31.941 |   1.1203 |     35.229 |     1.4
   17 |   0.8968 |     30.776 |   1.1503 |     36.147 |     1.5
   18 |   0.8888 |     30.488 |   1.1694 |     35.474 |     1.6
   19 |   0.8572 |     29.367 |   1.1574 |     36.086 |     1.7
   20 |   0.8432 |     28.605 |   1.1638 |     35.657 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,045,026

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0082 |     51.751 |   1.5131 |     45.596 |     0.2
    2 |   1.4537 |     45.520 |   1.3811 |     44.220 |     0.3
    3 |   1.3537 |     44.249 |   1.3325 |     43.211 |     0.5
    4 |   1.2943 |     43.161 |   1.2891 |     42.966 |     0.7
    5 |   1.2475 |     41.415 |   1.2752 |     44.312 |     0.9
    6 |   1.2072 |     40.344 |   1.2595 |     43.333 |     1.0
    7 |   1.1721 |     39.581 |   1.2049 |     40.948 |     1.2
    8 |   1.1419 |     38.797 |   1.2015 |     39.725 |     1.4
    9 |   1.1077 |     37.637 |   1.1568 |     38.869 |     1.5
   10 |   1.0756 |     35.841 |   1.1716 |     38.777 |     1.7
   11 |   1.0442 |     35.040 |   1.1364 |     37.431 |     1.9
   12 |   1.0143 |     34.112 |   1.1142 |     37.064 |     2.0
   13 |   0.9857 |     32.897 |   1.0991 |     36.177 |     2.2
   14 |   0.9519 |     31.306 |   1.1339 |     36.239 |     2.4
   15 |   0.9201 |     30.267 |   1.0918 |     34.526 |     2.6
   16 |   0.8881 |     29.450 |   1.1078 |     35.963 |     2.7
   17 |   0.8565 |     27.953 |   1.0847 |     34.954 |     2.9
   18 |   0.8333 |     27.207 |   1.0857 |     34.954 |     3.1
   19 |   0.7956 |     26.063 |   1.0980 |     34.801 |     3.2
   20 |   0.7622 |     24.887 |   1.1019 |     34.434 |     3.4
   21 |   0.7380 |     24.169 |   1.0874 |     34.037 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 425,762

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7626 |     49.486 |   1.3694 |     46.911 |     0.1
    2 |   1.3690 |     45.222 |   1.2883 |     44.037 |     0.2
    3 |   1.3029 |     43.951 |   1.2586 |     42.569 |     0.3
    4 |   1.2652 |     42.857 |   1.2326 |     43.425 |     0.4
    5 |   1.2232 |     41.901 |   1.1817 |     40.703 |     0.5
    6 |   1.1950 |     41.239 |   1.1954 |     40.092 |     0.6
    7 |   1.1650 |     39.935 |   1.1717 |     40.153 |     0.8
    8 |   1.1408 |     39.117 |   1.1541 |     39.450 |     0.9
    9 |   1.1197 |     38.570 |   1.1221 |     37.982 |     1.0
   10 |   1.1061 |     38.156 |   1.1300 |     37.492 |     1.1
   11 |   1.0791 |     37.294 |   1.1251 |     37.370 |     1.2
   12 |   1.0624 |     37.073 |   1.1816 |     39.786 |     1.3
   13 |   1.0461 |     36.018 |   1.1199 |     37.737 |     1.4
   14 |   1.0224 |     35.223 |   1.1014 |     36.697 |     1.5
   15 |   1.0071 |     35.018 |   1.0755 |     35.749 |     1.6
   16 |   0.9916 |     34.201 |   1.0639 |     35.382 |     1.7
   17 |   0.9663 |     33.284 |   1.0642 |     34.954 |     1.8
   18 |   0.9486 |     32.659 |   1.0825 |     35.627 |     1.9
   19 |   0.9377 |     32.184 |   1.0846 |     35.566 |     2.0
   20 |   0.9157 |     31.659 |   1.0751 |     34.067 |     2.2
   21 |   0.9041 |     31.085 |   1.0458 |     34.954 |     2.3
   22 |   0.8857 |     30.433 |   1.0262 |     33.823 |     2.4
   23 |   0.8731 |     30.041 |   1.0415 |     32.752 |     2.5
   24 |   0.8495 |     29.135 |   1.0417 |     32.905 |     2.6
   25 |   0.8375 |     28.892 |   1.0675 |     34.343 |     2.7
   26 |   0.8152 |     28.207 |   1.0497 |     34.067 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7283 |     48.829 |   1.3406 |     45.229 |     0.1
    2 |   1.3341 |     44.503 |   1.2756 |     43.792 |     0.1
    3 |   1.2591 |     42.957 |   1.2255 |     42.324 |     0.2
    4 |   1.2090 |     41.515 |   1.2028 |     42.569 |     0.3
    5 |   1.1688 |     40.614 |   1.1742 |     39.939 |     0.3
    6 |   1.1380 |     39.532 |   1.1480 |     39.725 |     0.4
    7 |   1.1088 |     38.521 |   1.1460 |     38.838 |     0.4
    8 |   1.0795 |     37.731 |   1.1021 |     37.156 |     0.5
    9 |   1.0514 |     36.565 |   1.1094 |     37.125 |     0.6
   10 |   1.0247 |     35.631 |   1.0897 |     36.606 |     0.6
   11 |   1.0065 |     34.687 |   1.1087 |     37.034 |     0.7
   12 |   0.9825 |     34.516 |   1.0946 |     36.086 |     0.8
   13 |   0.9567 |     33.046 |   1.0670 |     35.015 |     0.8
   14 |   0.9328 |     32.228 |   1.0669 |     34.771 |     0.9
   15 |   0.9078 |     31.588 |   1.0950 |     34.954 |     1.0
   16 |   0.8841 |     30.444 |   1.0582 |     33.700 |     1.0
   17 |   0.8674 |     30.334 |   1.0812 |     35.413 |     1.1
   18 |   0.8507 |     29.229 |   1.0841 |     34.740 |     1.2
   19 |   0.8314 |     28.682 |   1.0722 |     34.618 |     1.2
   20 |   0.8040 |     27.765 |   1.0752 |     34.465 |     1.3
Early stopping

