Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 358,817

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6545 |     48.950 |   1.3386 |     44.014 |     0.1
    2 |   1.3120 |     44.565 |   1.2391 |     41.588 |     0.1
    3 |   1.2362 |     42.516 |   1.2080 |     40.611 |     0.2
    4 |   1.1807 |     40.944 |   1.1695 |     39.950 |     0.3
    5 |   1.1451 |     39.884 |   1.1357 |     38.973 |     0.4
    6 |   1.1055 |     38.317 |   1.1093 |     37.461 |     0.4
    7 |   1.0779 |     37.504 |   1.1042 |     37.429 |     0.5
    8 |   1.0497 |     36.581 |   1.1023 |     36.925 |     0.6
    9 |   1.0110 |     35.169 |   1.0770 |     36.295 |     0.6
   10 |   0.9911 |     34.372 |   1.0751 |     35.980 |     0.7
   11 |   0.9635 |     33.674 |   1.0370 |     34.121 |     0.8
   12 |   0.9347 |     32.377 |   1.0312 |     34.972 |     0.9
   13 |   0.9085 |     31.300 |   1.0497 |     35.602 |     0.9
   14 |   0.8987 |     31.201 |   1.0044 |     33.144 |     1.0
   15 |   0.8693 |     29.970 |   1.0149 |     33.648 |     1.1
   16 |   0.8536 |     29.690 |   1.0216 |     33.900 |     1.2
   17 |   0.8311 |     28.910 |   1.0412 |     33.239 |     1.2
   18 |   0.7992 |     27.624 |   1.0529 |     34.310 |     1.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 327,393

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7599 |     50.275 |   1.3616 |     44.959 |     0.1
    2 |   1.3543 |     45.956 |   1.2705 |     43.510 |     0.2
    3 |   1.2786 |     44.230 |   1.2140 |     41.399 |     0.3
    4 |   1.2312 |     42.670 |   1.1851 |     40.296 |     0.5
    5 |   1.1991 |     41.499 |   1.1745 |     39.887 |     0.6
    6 |   1.1683 |     40.779 |   1.1709 |     39.729 |     0.7
    7 |   1.1443 |     40.026 |   1.1389 |     38.847 |     0.8
    8 |   1.1288 |     39.455 |   1.1191 |     37.933 |     0.9
    9 |   1.1056 |     38.350 |   1.0940 |     36.925 |     1.0
   10 |   1.0793 |     37.652 |   1.0901 |     37.366 |     1.1
   11 |   1.0561 |     36.922 |   1.0999 |     37.398 |     1.3
   12 |   1.0339 |     35.784 |   1.0603 |     35.980 |     1.4
   13 |   1.0283 |     35.570 |   1.0490 |     35.255 |     1.5
   14 |   1.0034 |     34.570 |   1.0305 |     35.035 |     1.6
   15 |   0.9826 |     34.031 |   1.0335 |     34.846 |     1.7
   16 |   0.9626 |     33.251 |   1.0372 |     34.940 |     1.8
   17 |   0.9423 |     32.916 |   1.0931 |     35.381 |     2.0
   18 |   0.9271 |     32.289 |   1.0118 |     33.459 |     2.1
   19 |   0.9067 |     31.427 |   1.0475 |     34.594 |     2.2
   20 |   0.8892 |     30.976 |   1.0508 |     33.680 |     2.3
   21 |   0.8785 |     30.415 |   1.0142 |     33.711 |     2.4
   22 |   0.8525 |     29.756 |   1.0052 |     33.239 |     2.5
   23 |   0.8361 |     28.981 |   1.0081 |     33.617 |     2.7
   24 |   0.8202 |     28.492 |   1.0344 |     34.562 |     2.8
   25 |   0.7986 |     27.750 |   1.0103 |     32.955 |     2.9
   26 |   0.7794 |     27.333 |   1.0387 |     32.892 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 292,961

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7768 |     49.379 |   1.3814 |     44.770 |     0.1
    2 |   1.3794 |     45.868 |   1.2927 |     43.573 |     0.3
    3 |   1.3157 |     45.521 |   1.2540 |     43.573 |     0.4
    4 |   1.2783 |     44.890 |   1.2285 |     42.848 |     0.6
    5 |   1.2473 |     44.252 |   1.2025 |     42.911 |     0.7
    6 |   1.2306 |     43.538 |   1.1971 |     42.218 |     0.9
    7 |   1.2168 |     43.279 |   1.1909 |     41.682 |     1.0
    8 |   1.1966 |     42.801 |   1.1736 |     41.525 |     1.2
    9 |   1.1801 |     41.719 |   1.1560 |     40.485 |     1.4
   10 |   1.1666 |     41.296 |   1.1685 |     39.792 |     1.5
   11 |   1.1484 |     40.840 |   1.1357 |     40.265 |     1.7
   12 |   1.1434 |     40.537 |   1.1468 |     39.477 |     1.8
   13 |   1.1234 |     39.713 |   1.1773 |     40.548 |     2.0
   14 |   1.1163 |     39.664 |   1.1630 |     40.265 |     2.1
   15 |   1.1018 |     39.422 |   1.1522 |     40.233 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 813,985

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5892 |     48.923 |   1.2833 |     43.415 |     0.1
    2 |   1.2789 |     44.521 |   1.2174 |     42.470 |     0.2
    3 |   1.2065 |     41.620 |   1.1980 |     40.485 |     0.3
    4 |   1.1490 |     39.807 |   1.1385 |     38.626 |     0.4
    5 |   1.1117 |     38.955 |   1.1323 |     37.996 |     0.6
    6 |   1.0762 |     37.130 |   1.1061 |     36.830 |     0.7
    7 |   1.0519 |     36.471 |   1.1029 |     36.641 |     0.8
    8 |   1.0257 |     35.619 |   1.1124 |     36.957 |     0.9
    9 |   0.9986 |     34.322 |   1.0823 |     36.295 |     1.0
   10 |   0.9678 |     33.592 |   1.0467 |     34.814 |     1.1
   11 |   0.9404 |     32.696 |   1.0605 |     35.476 |     1.2
   12 |   0.9112 |     31.602 |   1.0291 |     34.499 |     1.3
   13 |   0.8894 |     31.075 |   1.0316 |     34.342 |     1.5
   14 |   0.8676 |     29.937 |   1.0438 |     35.161 |     1.6
   15 |   0.8389 |     28.915 |   1.0422 |     34.184 |     1.7
   16 |   0.8157 |     28.118 |   1.0464 |     33.900 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 582,305

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5587 |     47.648 |   1.3163 |     43.636 |     0.1
    2 |   1.2772 |     43.527 |   1.2190 |     41.210 |     0.2
    3 |   1.2045 |     41.603 |   1.1624 |     39.792 |     0.2
    4 |   1.1473 |     39.570 |   1.1393 |     38.784 |     0.3
    5 |   1.1147 |     38.092 |   1.1267 |     38.059 |     0.4
    6 |   1.0804 |     36.696 |   1.1117 |     37.807 |     0.5
    7 |   1.0376 |     35.542 |   1.1267 |     37.366 |     0.6
    8 |   1.0138 |     34.636 |   1.0888 |     36.988 |     0.6
    9 |   0.9768 |     33.048 |   1.0704 |     35.507 |     0.7
   10 |   0.9509 |     32.493 |   1.0622 |     34.783 |     0.8
   11 |   0.9294 |     32.300 |   1.0762 |     35.602 |     0.9
   12 |   0.9042 |     31.053 |   1.0680 |     34.814 |     1.0
   13 |   0.8905 |     30.360 |   1.0725 |     34.342 |     1.1
   14 |   0.8590 |     29.267 |   1.0507 |     34.531 |     1.1
   15 |   0.8298 |     28.525 |   1.0567 |     33.837 |     1.2
   16 |   0.8018 |     27.382 |   1.1048 |     34.783 |     1.3
   17 |   0.7794 |     26.745 |   1.1154 |     34.405 |     1.4
   18 |   0.7611 |     26.036 |   1.1109 |     34.184 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,044,641

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5215 |     47.604 |   1.3066 |     44.959 |     0.1
    2 |   1.2770 |     44.587 |   1.2288 |     44.203 |     0.3
    3 |   1.2312 |     43.928 |   1.2009 |     42.250 |     0.4
    4 |   1.1989 |     43.340 |   1.1763 |     41.084 |     0.6
    5 |   1.1772 |     42.384 |   1.1723 |     42.092 |     0.7
    6 |   1.1637 |     42.241 |   1.1752 |     41.462 |     0.9
    7 |   1.1592 |     42.224 |   1.1693 |     40.989 |     1.0
    8 |   1.1429 |     41.598 |   1.1645 |     43.006 |     1.2
    9 |   1.1343 |     41.664 |   1.1329 |     40.391 |     1.3
   10 |   1.1291 |     41.730 |   1.1342 |     39.981 |     1.5
   11 |   1.1219 |     41.362 |   1.1363 |     41.178 |     1.6
   12 |   1.1201 |     41.186 |   1.1368 |     41.588 |     1.8
   13 |   1.1107 |     41.224 |   1.1268 |     41.084 |     1.9
   14 |   1.1118 |     41.219 |   1.1217 |     41.304 |     2.0
   15 |   1.1040 |     40.878 |   1.1271 |     40.359 |     2.2
   16 |   1.1023 |     41.257 |   1.1176 |     40.359 |     2.3
   17 |   1.1015 |     40.911 |   1.1162 |     40.296 |     2.5
   18 |   1.0961 |     40.862 |   1.1211 |     40.580 |     2.6
   19 |   1.0935 |     40.510 |   1.0974 |     38.815 |     2.8
   20 |   1.0838 |     39.916 |   1.1318 |     40.170 |     2.9
   21 |   1.0731 |     39.285 |   1.1796 |     41.619 |     3.1
   22 |   1.0726 |     39.213 |   1.1372 |     40.013 |     3.2
   23 |   1.0573 |     38.790 |   1.1879 |     40.800 |     3.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 292,961

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8059 |     50.198 |   1.3724 |     45.243 |     0.1
    2 |   1.3765 |     45.719 |   1.2923 |     43.982 |     0.2
    3 |   1.3209 |     45.510 |   1.2586 |     44.108 |     0.3
    4 |   1.2867 |     45.164 |   1.2273 |     42.785 |     0.4
    5 |   1.2560 |     44.631 |   1.2119 |     42.691 |     0.5
    6 |   1.2351 |     44.032 |   1.2000 |     42.060 |     0.6
    7 |   1.2218 |     43.714 |   1.1892 |     41.525 |     0.7
    8 |   1.2145 |     43.433 |   1.1821 |     40.769 |     0.8
    9 |   1.1979 |     42.972 |   1.1669 |     40.895 |     0.9
   10 |   1.1907 |     42.911 |   1.1610 |     40.359 |     1.0
   11 |   1.1846 |     42.807 |   1.1722 |     41.525 |     1.1
   12 |   1.1748 |     42.290 |   1.1568 |     40.580 |     1.2
   13 |   1.1684 |     42.411 |   1.1566 |     40.611 |     1.3
   14 |   1.1670 |     42.461 |   1.1528 |     40.674 |     1.4
   15 |   1.1619 |     42.565 |   1.1485 |     41.430 |     1.5
   16 |   1.1566 |     42.126 |   1.1469 |     40.517 |     1.6
   17 |   1.1503 |     41.950 |   1.1515 |     41.871 |     1.8
   18 |   1.1445 |     42.252 |   1.1485 |     41.178 |     1.9
   19 |   1.1426 |     41.702 |   1.1446 |     41.084 |     2.0
   20 |   1.1396 |     41.807 |   1.1335 |     40.832 |     2.1
   21 |   1.1347 |     41.576 |   1.1353 |     41.462 |     2.2
   22 |   1.1361 |     41.576 |   1.1331 |     40.485 |     2.3
   23 |   1.1335 |     41.494 |   1.1270 |     39.792 |     2.4
   24 |   1.1287 |     41.779 |   1.1255 |     40.485 |     2.5
   25 |   1.1252 |     41.323 |   1.1324 |     40.643 |     2.6
   26 |   1.1229 |     41.411 |   1.1276 |     40.233 |     2.7
   27 |   1.1242 |     41.477 |   1.1287 |     40.643 |     2.8
   28 |   1.1199 |     41.120 |   1.1286 |     40.643 |     2.9
   29 |   1.1148 |     41.043 |   1.1223 |     40.580 |     3.0
   30 |   1.1137 |     41.158 |   1.1215 |     40.454 |     3.1
   31 |   1.1180 |     41.092 |   1.1157 |     40.107 |     3.2
   32 |   1.1075 |     40.939 |   1.1408 |     40.926 |     3.3
   33 |   1.1021 |     39.878 |   1.1138 |     39.792 |     3.4
   34 |   1.0974 |     40.098 |   1.1400 |     40.832 |     3.5
   35 |   1.0896 |     39.543 |   1.1059 |     39.855 |     3.6
   36 |   1.0826 |     39.570 |   1.1310 |     40.674 |     3.7
   37 |   1.0839 |     39.592 |   1.1133 |     39.256 |     3.8
   38 |   1.0756 |     39.175 |   1.1462 |     40.202 |     3.9
   39 |   1.0717 |     38.614 |   1.1170 |     39.288 |     4.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 458,785

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4813 |     60.617 |   1.8006 |     46.408 |     0.1
    2 |   1.7554 |     46.714 |   1.5689 |     45.463 |     0.2
    3 |   1.5846 |     46.269 |   1.4800 |     45.085 |     0.3
    4 |   1.5007 |     45.708 |   1.4180 |     44.014 |     0.5
    5 |   1.4428 |     45.274 |   1.3777 |     43.132 |     0.6
    6 |   1.4032 |     44.780 |   1.3478 |     42.911 |     0.7
    7 |   1.3714 |     44.252 |   1.3263 |     42.596 |     0.8
    8 |   1.3437 |     43.994 |   1.3035 |     42.281 |     0.9
    9 |   1.3216 |     43.725 |   1.2930 |     42.817 |     1.0
   10 |   1.3024 |     42.944 |   1.2836 |     42.596 |     1.1
   11 |   1.2798 |     42.499 |   1.2673 |     41.871 |     1.3
   12 |   1.2628 |     41.988 |   1.2667 |     42.313 |     1.4
   13 |   1.2441 |     41.631 |   1.2339 |     40.611 |     1.5
   14 |   1.2257 |     41.109 |   1.2330 |     40.958 |     1.6
   15 |   1.2146 |     40.906 |   1.2182 |     40.391 |     1.7
   16 |   1.2021 |     40.499 |   1.2219 |     40.517 |     1.8
   17 |   1.1935 |     40.362 |   1.2137 |     40.202 |     2.0
   18 |   1.1803 |     39.823 |   1.2058 |     39.288 |     2.1
   19 |   1.1662 |     39.455 |   1.2145 |     39.981 |     2.2
   20 |   1.1563 |     39.521 |   1.2020 |     39.887 |     2.3
   21 |   1.1523 |     39.285 |   1.1906 |     38.752 |     2.4
   22 |   1.1373 |     38.702 |   1.2021 |     39.887 |     2.5
   23 |   1.1319 |     38.779 |   1.2047 |     39.729 |     2.6
   24 |   1.1207 |     37.988 |   1.1793 |     39.950 |     2.8
   25 |   1.1162 |     38.043 |   1.1953 |     39.445 |     2.9
   26 |   1.1061 |     37.647 |   1.2086 |     39.445 |     3.0
   27 |   1.0995 |     37.817 |   1.1812 |     39.603 |     3.1
   28 |   1.0866 |     36.839 |   1.1856 |     39.193 |     3.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 276,257

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6284 |     47.461 |   1.3425 |     45.369 |     0.1
    2 |   1.2785 |     43.895 |   1.2383 |     42.187 |     0.1
    3 |   1.1920 |     41.664 |   1.1888 |     40.643 |     0.2
    4 |   1.1359 |     39.741 |   1.1687 |     39.225 |     0.3
    5 |   1.0788 |     37.609 |   1.1253 |     38.469 |     0.3
    6 |   1.0376 |     36.246 |   1.0895 |     36.767 |     0.4
    7 |   0.9903 |     34.328 |   1.1270 |     38.154 |     0.5
    8 |   0.9539 |     33.564 |   1.0754 |     36.263 |     0.5
    9 |   0.9106 |     31.580 |   1.0857 |     36.106 |     0.6
   10 |   0.8723 |     30.470 |   1.0596 |     35.759 |     0.7
   11 |   0.8345 |     28.734 |   1.0710 |     35.822 |     0.7
   12 |   0.7937 |     27.426 |   1.0978 |     35.602 |     0.8
   13 |   0.7518 |     26.223 |   1.1279 |     36.326 |     0.9
   14 |   0.7143 |     24.755 |   1.0913 |     35.192 |     0.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 582,305

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5790 |     48.318 |   1.2937 |     43.667 |     0.1
    2 |   1.2680 |     43.104 |   1.2065 |     41.273 |     0.2
    3 |   1.1897 |     41.197 |   1.1728 |     39.509 |     0.3
    4 |   1.1336 |     39.087 |   1.1116 |     37.240 |     0.4
    5 |   1.0724 |     37.070 |   1.0917 |     37.114 |     0.5
    6 |   1.0374 |     36.185 |   1.0778 |     36.547 |     0.6
    7 |   0.9874 |     33.811 |   1.0866 |     35.696 |     0.7
    8 |   0.9455 |     32.388 |   1.0495 |     34.720 |     0.8
    9 |   0.9097 |     31.289 |   1.0533 |     34.940 |     0.9
   10 |   0.8698 |     29.932 |   1.0721 |     35.255 |     1.0
   11 |   0.8388 |     28.844 |   1.0710 |     35.570 |     1.1
   12 |   0.8058 |     27.712 |   1.0676 |     33.365 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,179,041

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6442 |     49.951 |   1.3577 |     45.337 |     0.1
    2 |   1.3272 |     45.824 |   1.2843 |     44.486 |     0.3
    3 |   1.2694 |     44.763 |   1.2455 |     43.951 |     0.5
    4 |   1.2252 |     43.120 |   1.1765 |     40.391 |     0.6
    5 |   1.1902 |     41.878 |   1.1741 |     41.210 |     0.8
    6 |   1.1634 |     41.202 |   1.1499 |     40.107 |     0.9
    7 |   1.1482 |     40.565 |   1.1323 |     39.477 |     1.1
    8 |   1.1358 |     40.180 |   1.1185 |     39.792 |     1.2
    9 |   1.1114 |     39.768 |   1.1239 |     38.532 |     1.4
   10 |   1.1049 |     39.570 |   1.1138 |     38.784 |     1.6
   11 |   1.0982 |     39.345 |   1.1117 |     39.351 |     1.7
   12 |   1.0897 |     39.125 |   1.0921 |     38.185 |     1.9
   13 |   1.0755 |     38.746 |   1.0998 |     38.595 |     2.0
   14 |   1.0673 |     38.213 |   1.0907 |     38.406 |     2.2
   15 |   1.0611 |     38.218 |   1.0877 |     37.681 |     2.3
   16 |   1.0524 |     38.043 |   1.0750 |     38.406 |     2.5
   17 |   1.0396 |     37.356 |   1.0730 |     37.996 |     2.6
   18 |   1.0414 |     37.504 |   1.0633 |     37.335 |     2.8
   19 |   1.0274 |     36.982 |   1.0656 |     37.114 |     3.0
   20 |   1.0196 |     36.724 |   1.0635 |     37.902 |     3.1
   21 |   1.0149 |     36.537 |   1.0741 |     38.563 |     3.3
   22 |   1.0178 |     36.828 |   1.0708 |     38.091 |     3.4
   23 |   1.0137 |     36.669 |   1.0503 |     36.925 |     3.6
   24 |   1.0026 |     36.174 |   1.0570 |     37.240 |     3.7
   25 |   1.0038 |     36.180 |   1.0492 |     37.177 |     3.9
   26 |   0.9910 |     35.707 |   1.0432 |     36.641 |     4.0
   27 |   0.9868 |     35.685 |   1.0465 |     37.083 |     4.2
   28 |   0.9893 |     36.026 |   1.0512 |     36.894 |     4.4
   29 |   0.9821 |     35.630 |   1.0608 |     37.303 |     4.5
   30 |   0.9838 |     35.713 |   1.0373 |     36.641 |     4.7
   31 |   0.9761 |     35.476 |   1.0532 |     37.398 |     4.8
   32 |   0.9710 |     35.323 |   1.0442 |     37.524 |     5.0
   33 |   0.9674 |     35.152 |   1.0326 |     35.980 |     5.1
   34 |   0.9634 |     35.202 |   1.0260 |     36.043 |     5.3
   35 |   0.9583 |     34.833 |   1.0369 |     36.767 |     5.4
   36 |   0.9569 |     34.855 |   1.0477 |     37.240 |     5.6
   37 |   0.9483 |     34.388 |   1.0290 |     35.885 |     5.8
   38 |   0.9503 |     34.762 |   1.0124 |     35.980 |     5.9
   39 |   0.9420 |     33.971 |   1.0444 |     36.925 |     6.1
   40 |   0.9344 |     34.004 |   1.0276 |     35.917 |     6.2
   41 |   0.9339 |     33.965 |   1.0464 |     37.618 |     6.4
   42 |   0.9357 |     34.246 |   1.0279 |     35.602 |     6.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 276,961

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7395 |     67.255 |   1.9966 |     47.984 |     0.1
    2 |   1.9165 |     47.824 |   1.6355 |     45.558 |     0.2
    3 |   1.6604 |     46.555 |   1.5202 |     44.991 |     0.2
    4 |   1.5581 |     46.478 |   1.4644 |     45.054 |     0.3
    5 |   1.4966 |     46.055 |   1.4233 |     45.085 |     0.4
    6 |   1.4541 |     45.818 |   1.3890 |     44.266 |     0.5
    7 |   1.4216 |     45.379 |   1.3653 |     43.825 |     0.5
    8 |   1.3996 |     45.082 |   1.3546 |     44.928 |     0.6
    9 |   1.3782 |     44.813 |   1.3370 |     44.329 |     0.7
   10 |   1.3579 |     44.313 |   1.3270 |     43.951 |     0.8
   11 |   1.3433 |     44.192 |   1.3243 |     44.612 |     0.9
   12 |   1.3289 |     43.769 |   1.3133 |     44.266 |     0.9
   13 |   1.3154 |     43.626 |   1.3020 |     44.140 |     1.0
   14 |   1.3022 |     43.444 |   1.2927 |     43.636 |     1.1
   15 |   1.2879 |     43.285 |   1.2952 |     43.699 |     1.2
   16 |   1.2811 |     43.065 |   1.2835 |     43.447 |     1.2
   17 |   1.2691 |     42.900 |   1.2697 |     42.754 |     1.3
   18 |   1.2573 |     42.735 |   1.2738 |     43.037 |     1.4
   19 |   1.2468 |     42.356 |   1.2645 |     42.565 |     1.5
   20 |   1.2375 |     42.164 |   1.2726 |     42.533 |     1.6
   21 |   1.2307 |     42.005 |   1.2606 |     42.470 |     1.6
   22 |   1.2181 |     41.571 |   1.2617 |     42.628 |     1.7
   23 |   1.2093 |     41.334 |   1.2561 |     42.880 |     1.8
   24 |   1.2038 |     41.571 |   1.2388 |     41.997 |     1.9
   25 |   1.1946 |     41.092 |   1.2380 |     41.147 |     1.9
   26 |   1.1881 |     40.554 |   1.2411 |     41.903 |     2.0
   27 |   1.1820 |     40.988 |   1.2606 |     42.470 |     2.1
   28 |   1.1735 |     40.521 |   1.2477 |     41.997 |     2.2
   29 |   1.1661 |     40.219 |   1.2216 |     41.084 |     2.3
   30 |   1.1623 |     39.851 |   1.2285 |     41.714 |     2.3
   31 |   1.1529 |     39.988 |   1.2464 |     41.556 |     2.4
   32 |   1.1465 |     39.598 |   1.2258 |     41.430 |     2.5
   33 |   1.1438 |     39.499 |   1.2573 |     41.997 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 226,017

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7733 |     49.879 |   1.3567 |     44.518 |     0.1
    2 |   1.3574 |     45.648 |   1.2822 |     44.423 |     0.2
    3 |   1.2848 |     43.730 |   1.2419 |     43.762 |     0.3
    4 |   1.2384 |     42.834 |   1.1740 |     39.824 |     0.3
    5 |   1.1918 |     41.208 |   1.1766 |     39.918 |     0.4
    6 |   1.1620 |     40.351 |   1.1674 |     40.265 |     0.5
    7 |   1.1456 |     39.713 |   1.1571 |     38.878 |     0.6
    8 |   1.1169 |     38.609 |   1.1171 |     37.744 |     0.7
    9 |   1.0905 |     37.779 |   1.1446 |     38.689 |     0.8
   10 |   1.0694 |     36.889 |   1.1008 |     36.326 |     0.9
   11 |   1.0433 |     36.037 |   1.0946 |     37.398 |     1.0
   12 |   1.0244 |     35.207 |   1.1172 |     36.074 |     1.0
   13 |   1.0130 |     35.015 |   1.1103 |     36.547 |     1.1
   14 |   0.9898 |     33.916 |   1.1057 |     36.673 |     1.2
   15 |   0.9739 |     33.284 |   1.0906 |     35.507 |     1.3
   16 |   0.9562 |     32.921 |   1.0671 |     34.972 |     1.4
   17 |   0.9328 |     32.108 |   1.0995 |     35.287 |     1.5
   18 |   0.9253 |     31.762 |   1.0716 |     34.688 |     1.6
   19 |   0.9052 |     30.767 |   1.0863 |     34.909 |     1.6
   20 |   0.8840 |     30.322 |   1.1162 |     35.570 |     1.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 343,201

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7037 |     49.302 |   1.3549 |     44.171 |     0.1
    2 |   1.3487 |     45.324 |   1.2864 |     43.699 |     0.2
    3 |   1.2853 |     44.697 |   1.2439 |     44.423 |     0.3
    4 |   1.2457 |     43.889 |   1.2086 |     42.659 |     0.4
    5 |   1.2176 |     43.450 |   1.1896 |     42.344 |     0.5
    6 |   1.1952 |     42.659 |   1.1803 |     40.958 |     0.7
    7 |   1.1775 |     42.609 |   1.1562 |     40.107 |     0.8
    8 |   1.1638 |     41.840 |   1.1545 |     40.265 |     0.9
    9 |   1.1481 |     41.268 |   1.1393 |     39.540 |     1.0
   10 |   1.1339 |     41.010 |   1.1194 |     38.658 |     1.1
   11 |   1.1256 |     40.329 |   1.1302 |     39.319 |     1.2
   12 |   1.1076 |     39.603 |   1.1098 |     38.784 |     1.3
   13 |   1.1008 |     39.285 |   1.1076 |     38.154 |     1.4
   14 |   1.0856 |     38.905 |   1.0944 |     38.217 |     1.5
   15 |   1.0720 |     38.537 |   1.0889 |     37.965 |     1.6
   16 |   1.0606 |     37.823 |   1.0741 |     37.776 |     1.8
   17 |   1.0549 |     38.026 |   1.0713 |     37.555 |     1.9
   18 |   1.0455 |     37.312 |   1.0711 |     37.398 |     2.0
   19 |   1.0388 |     37.207 |   1.0751 |     37.839 |     2.1
   20 |   1.0291 |     37.086 |   1.0720 |     36.925 |     2.2
   21 |   1.0242 |     36.647 |   1.0694 |     36.389 |     2.3
   22 |   1.0156 |     36.542 |   1.0650 |     37.366 |     2.4
   23 |   1.0022 |     35.663 |   1.0515 |     36.641 |     2.5
   24 |   0.9982 |     36.042 |   1.0653 |     36.830 |     2.6
   25 |   0.9967 |     36.053 |   1.0501 |     37.051 |     2.7
   26 |   0.9841 |     35.240 |   1.0443 |     36.074 |     2.9
   27 |   0.9830 |     35.169 |   1.0299 |     36.452 |     3.0
   28 |   0.9682 |     34.570 |   1.0369 |     35.791 |     3.1
   29 |   0.9613 |     34.482 |   1.0354 |     35.822 |     3.2
   30 |   0.9513 |     33.691 |   1.0406 |     35.476 |     3.3
   31 |   0.9427 |     33.696 |   1.0393 |     35.255 |     3.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 779,681

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5524 |     47.769 |   1.3060 |     44.045 |     0.1
    2 |   1.3039 |     44.450 |   1.2497 |     42.407 |     0.2
    3 |   1.2318 |     42.681 |   1.1824 |     40.769 |     0.3
    4 |   1.1883 |     41.538 |   1.1534 |     39.509 |     0.4
    5 |   1.1519 |     40.285 |   1.1471 |     39.887 |     0.5
    6 |   1.1213 |     39.559 |   1.1295 |     38.374 |     0.6
    7 |   1.0950 |     38.620 |   1.1291 |     38.091 |     0.7
    8 |   1.0824 |     37.834 |   1.1193 |     37.776 |     0.8
    9 |   1.0575 |     37.460 |   1.0928 |     37.996 |     0.9
   10 |   1.0295 |     36.152 |   1.0949 |     36.106 |     1.1
   11 |   1.0044 |     35.493 |   1.1055 |     36.862 |     1.2
   12 |   0.9859 |     34.366 |   1.0695 |     36.106 |     1.3
   13 |   0.9634 |     33.619 |   1.1113 |     36.767 |     1.4
   14 |   0.9504 |     33.130 |   1.1159 |     37.303 |     1.5
   15 |   0.9283 |     32.333 |   1.0949 |     36.106 |     1.6
   16 |   0.9088 |     31.938 |   1.0609 |     35.413 |     1.7
   17 |   0.8885 |     30.970 |   1.1091 |     36.484 |     1.8
   18 |   0.8578 |     29.794 |   1.0777 |     35.759 |     1.9
   19 |   0.8472 |     29.674 |   1.1011 |     35.791 |     2.0
   20 |   0.8116 |     28.349 |   1.1186 |     36.358 |     2.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 276,257

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8280 |     71.480 |   2.0711 |     47.322 |     0.1
    2 |   2.0229 |     48.522 |   1.6357 |     44.991 |     0.2
    3 |   1.7076 |     46.631 |   1.5132 |     44.991 |     0.3
    4 |   1.5774 |     46.225 |   1.4556 |     44.991 |     0.4
    5 |   1.5169 |     46.269 |   1.4220 |     44.865 |     0.5
    6 |   1.4707 |     46.351 |   1.3959 |     44.928 |     0.6
    7 |   1.4399 |     46.137 |   1.3724 |     44.770 |     0.7
    8 |   1.4148 |     45.752 |   1.3550 |     43.919 |     0.8
    9 |   1.3925 |     45.758 |   1.3364 |     43.321 |     0.9
   10 |   1.3750 |     45.346 |   1.3248 |     42.880 |     1.0
   11 |   1.3633 |     45.120 |   1.3146 |     42.943 |     1.0
   12 |   1.3467 |     44.758 |   1.3009 |     43.100 |     1.1
   13 |   1.3339 |     44.494 |   1.2870 |     42.407 |     1.2
   14 |   1.3188 |     44.076 |   1.2783 |     42.911 |     1.3
   15 |   1.3103 |     43.878 |   1.2726 |     43.541 |     1.4
   16 |   1.3018 |     43.747 |   1.2678 |     42.880 |     1.5
   17 |   1.2910 |     43.587 |   1.2718 |     43.856 |     1.6
   18 |   1.2773 |     43.087 |   1.2594 |     42.943 |     1.7
   19 |   1.2665 |     42.845 |   1.2575 |     43.699 |     1.8
   20 |   1.2601 |     42.472 |   1.2490 |     42.848 |     1.9
   21 |   1.2550 |     42.900 |   1.2421 |     41.808 |     2.0
   22 |   1.2418 |     42.224 |   1.2345 |     41.462 |     2.1
   23 |   1.2380 |     41.774 |   1.2371 |     42.060 |     2.2
   24 |   1.2251 |     41.169 |   1.2260 |     41.336 |     2.3
   25 |   1.2207 |     41.472 |   1.2255 |     41.336 |     2.4
   26 |   1.2128 |     40.856 |   1.2189 |     41.178 |     2.5
   27 |   1.2056 |     40.834 |   1.2212 |     41.430 |     2.6
   28 |   1.1987 |     40.658 |   1.2093 |     40.454 |     2.7
   29 |   1.1940 |     40.774 |   1.2000 |     39.950 |     2.8
   30 |   1.1883 |     40.362 |   1.2175 |     41.241 |     2.9
   31 |   1.1824 |     40.241 |   1.1953 |     40.422 |     3.0
   32 |   1.1727 |     39.785 |   1.2011 |     40.328 |     3.1
   33 |   1.1702 |     40.065 |   1.1978 |     39.981 |     3.2
   34 |   1.1673 |     39.730 |   1.2035 |     39.981 |     3.2
   35 |   1.1594 |     39.636 |   1.2061 |     40.107 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 847,265

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2538 |     54.665 |   1.5931 |     44.991 |     0.1
    2 |   1.5565 |     46.137 |   1.4232 |     44.108 |     0.3
    3 |   1.4297 |     45.609 |   1.3649 |     45.117 |     0.4
    4 |   1.3693 |     44.444 |   1.3292 |     44.266 |     0.5
    5 |   1.3282 |     43.785 |   1.2922 |     43.006 |     0.7
    6 |   1.2922 |     42.702 |   1.2513 |     40.832 |     0.8
    7 |   1.2631 |     41.757 |   1.2365 |     41.273 |     1.0
    8 |   1.2356 |     41.356 |   1.2326 |     41.399 |     1.1
    9 |   1.2144 |     40.906 |   1.2106 |     40.013 |     1.2
   10 |   1.1914 |     40.417 |   1.2097 |     40.170 |     1.4
   11 |   1.1710 |     39.840 |   1.1851 |     40.548 |     1.5
   12 |   1.1536 |     39.125 |   1.1621 |     39.414 |     1.7
   13 |   1.1360 |     38.653 |   1.1595 |     39.319 |     1.8
   14 |   1.1154 |     37.817 |   1.1454 |     39.067 |     1.9
   15 |   1.0968 |     37.224 |   1.1693 |     39.067 |     2.1
   16 |   1.0829 |     36.839 |   1.1510 |     38.973 |     2.2
   17 |   1.0681 |     36.119 |   1.1671 |     38.248 |     2.3
   18 |   1.0568 |     35.916 |   1.1421 |     38.091 |     2.5
   19 |   1.0370 |     34.987 |   1.1477 |     37.807 |     2.6
   20 |   1.0296 |     34.839 |   1.1291 |     37.870 |     2.8
   21 |   1.0140 |     34.372 |   1.1169 |     37.083 |     2.9
   22 |   1.0001 |     33.734 |   1.1129 |     36.799 |     3.0
   23 |   0.9897 |     33.608 |   1.1076 |     37.398 |     3.2
   24 |   0.9742 |     33.053 |   1.1601 |     38.595 |     3.3
   25 |   0.9606 |     32.339 |   1.1241 |     37.051 |     3.4
   26 |   0.9523 |     32.163 |   1.1152 |     37.209 |     3.6
   27 |   0.9346 |     31.745 |   1.0990 |     36.673 |     3.7
   28 |   0.9288 |     31.196 |   1.1056 |     36.421 |     3.9
   29 |   0.9202 |     30.937 |   1.1217 |     36.704 |     4.0
   30 |   0.9070 |     30.564 |   1.1211 |     37.114 |     4.1
   31 |   0.8905 |     30.014 |   1.0943 |     35.570 |     4.3
   32 |   0.8864 |     30.031 |   1.1191 |     36.421 |     4.4
   33 |   0.8769 |     29.591 |   1.0793 |     35.035 |     4.6
   34 |   0.8657 |     29.223 |   1.0871 |     34.877 |     4.7
   35 |   0.8525 |     28.613 |   1.1008 |     36.169 |     4.8
   36 |   0.8473 |     28.800 |   1.1082 |     34.814 |     5.0
   37 |   0.8356 |     28.157 |   1.1057 |     34.909 |     5.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 731,745

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5089 |     62.386 |   1.6844 |     45.054 |     0.1
    2 |   1.6807 |     46.818 |   1.4471 |     44.707 |     0.2
    3 |   1.4949 |     46.164 |   1.3737 |     43.919 |     0.3
    4 |   1.4264 |     45.741 |   1.3374 |     44.329 |     0.4
    5 |   1.3813 |     45.236 |   1.3017 |     42.848 |     0.6
    6 |   1.3482 |     44.455 |   1.2979 |     43.699 |     0.7
    7 |   1.3216 |     43.977 |   1.2739 |     42.691 |     0.8
    8 |   1.2964 |     43.170 |   1.2564 |     41.619 |     0.9
    9 |   1.2742 |     42.433 |   1.2617 |     42.943 |     1.0
   10 |   1.2555 |     42.301 |   1.2310 |     40.958 |     1.1
   11 |   1.2377 |     42.104 |   1.2274 |     41.052 |     1.2
   12 |   1.2196 |     41.614 |   1.2426 |     41.714 |     1.3
   13 |   1.2042 |     41.059 |   1.1941 |     39.635 |     1.4
   14 |   1.1869 |     40.554 |   1.1850 |     39.288 |     1.6
   15 |   1.1770 |     40.213 |   1.1982 |     39.918 |     1.7
   16 |   1.1663 |     39.812 |   1.1805 |     39.225 |     1.8
   17 |   1.1544 |     39.471 |   1.1734 |     38.595 |     1.9
   18 |   1.1437 |     39.416 |   1.1793 |     38.878 |     2.0
   19 |   1.1293 |     38.817 |   1.1610 |     37.902 |     2.1
   20 |   1.1192 |     38.279 |   1.1653 |     38.941 |     2.2
   21 |   1.1080 |     38.026 |   1.1571 |     37.744 |     2.3
   22 |   1.0963 |     37.685 |   1.1498 |     37.524 |     2.4
   23 |   1.0869 |     37.504 |   1.1605 |     38.406 |     2.6
   24 |   1.0804 |     36.977 |   1.1398 |     37.209 |     2.7
   25 |   1.0704 |     36.845 |   1.1358 |     37.335 |     2.8
   26 |   1.0567 |     36.119 |   1.1549 |     37.272 |     2.9
   27 |   1.0495 |     36.257 |   1.1245 |     36.894 |     3.0
   28 |   1.0421 |     35.597 |   1.1410 |     37.209 |     3.1
   29 |   1.0312 |     35.812 |   1.1497 |     37.429 |     3.2
   30 |   1.0245 |     35.290 |   1.1580 |     37.776 |     3.3
   31 |   1.0145 |     34.685 |   1.1230 |     36.862 |     3.4
   32 |   1.0080 |     34.663 |   1.1329 |     37.051 |     3.5
   33 |   1.0019 |     34.531 |   1.1212 |     36.043 |     3.7
   34 |   0.9871 |     34.048 |   1.1198 |     36.295 |     3.8
   35 |   0.9782 |     33.322 |   1.1205 |     36.169 |     3.9
   36 |   0.9762 |     33.784 |   1.1257 |     36.515 |     4.0
   37 |   0.9658 |     33.086 |   1.1474 |     37.303 |     4.1
   38 |   0.9619 |     32.982 |   1.1301 |     36.295 |     4.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 458,785

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6324 |     62.914 |   1.9259 |     45.967 |     0.2
    2 |   1.8926 |     47.390 |   1.6005 |     44.739 |     0.3
    3 |   1.6561 |     46.483 |   1.5095 |     45.337 |     0.5
    4 |   1.5565 |     46.340 |   1.4462 |     44.612 |     0.7
    5 |   1.4964 |     46.192 |   1.3999 |     44.423 |     0.8
    6 |   1.4562 |     46.241 |   1.3693 |     43.919 |     1.0
    7 |   1.4209 |     45.675 |   1.3480 |     44.612 |     1.1
    8 |   1.3938 |     45.362 |   1.3238 |     44.234 |     1.3
    9 |   1.3695 |     44.917 |   1.3066 |     43.699 |     1.5
   10 |   1.3547 |     44.774 |   1.2902 |     42.691 |     1.6
   11 |   1.3339 |     44.318 |   1.2799 |     42.596 |     1.8
   12 |   1.3201 |     44.131 |   1.2774 |     43.384 |     2.0
   13 |   1.3094 |     43.944 |   1.2729 |     42.943 |     2.1
   14 |   1.2932 |     43.686 |   1.2537 |     42.376 |     2.3
   15 |   1.2845 |     43.692 |   1.2574 |     43.163 |     2.4
   16 |   1.2708 |     42.961 |   1.2515 |     42.880 |     2.6
   17 |   1.2600 |     42.620 |   1.2406 |     42.817 |     2.8
   18 |   1.2505 |     42.472 |   1.2355 |     41.714 |     2.9
   19 |   1.2403 |     42.246 |   1.2365 |     41.777 |     3.1
   20 |   1.2365 |     42.268 |   1.2273 |     41.430 |     3.3
   21 |   1.2269 |     41.834 |   1.2305 |     41.493 |     3.4
   22 |   1.2156 |     41.444 |   1.2207 |     41.210 |     3.6
   23 |   1.2110 |     41.395 |   1.2330 |     41.556 |     3.8
   24 |   1.1994 |     40.917 |   1.2324 |     41.619 |     3.9
   25 |   1.1962 |     41.087 |   1.2321 |     41.619 |     4.1
   26 |   1.1875 |     40.406 |   1.2292 |     41.021 |     4.2
   27 |   1.1841 |     40.752 |   1.2027 |     40.737 |     4.4
   28 |   1.1739 |     39.933 |   1.2019 |     40.485 |     4.6
   29 |   1.1704 |     40.164 |   1.2277 |     40.737 |     4.7
   30 |   1.1612 |     39.658 |   1.2146 |     40.422 |     4.9
   31 |   1.1549 |     39.537 |   1.1946 |     39.729 |     5.1
   32 |   1.1519 |     39.361 |   1.2280 |     40.706 |     5.2
   33 |   1.1449 |     39.054 |   1.2079 |     40.548 |     5.4
   34 |   1.1399 |     39.109 |   1.2009 |     39.792 |     5.6
   35 |   1.1375 |     39.092 |   1.2164 |     40.170 |     5.7
   36 |   1.1288 |     38.455 |   1.1894 |     39.256 |     5.9
   37 |   1.1185 |     38.240 |   1.2004 |     39.729 |     6.0
   38 |   1.1147 |     38.175 |   1.1992 |     40.202 |     6.2
   39 |   1.1108 |     38.147 |   1.1884 |     39.603 |     6.4
   40 |   1.1022 |     37.504 |   1.2328 |     39.981 |     6.5
   41 |   1.1002 |     37.669 |   1.2014 |     39.540 |     6.7
   42 |   1.0979 |     37.477 |   1.1962 |     39.225 |     6.9
   43 |   1.0915 |     37.196 |   1.2060 |     40.076 |     7.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 881,185

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5865 |     48.681 |   1.3012 |     43.447 |     0.1
    2 |   1.2444 |     43.175 |   1.2368 |     42.281 |     0.2
    3 |   1.1647 |     40.290 |   1.1816 |     40.863 |     0.3
    4 |   1.0878 |     37.696 |   1.1062 |     36.736 |     0.4
    5 |   1.0231 |     35.119 |   1.1023 |     37.681 |     0.5
    6 |   0.9771 |     33.674 |   1.1093 |     37.051 |     0.6
    7 |   0.9259 |     31.910 |   1.0592 |     34.657 |     0.6
    8 |   0.8662 |     29.608 |   1.0798 |     34.688 |     0.7
    9 |   0.8343 |     28.586 |   1.0374 |     33.585 |     0.8
   10 |   0.7838 |     26.965 |   1.0532 |     34.468 |     0.9
   11 |   0.7422 |     25.503 |   1.0232 |     32.861 |     1.0
   12 |   0.6948 |     23.634 |   1.0913 |     33.743 |     1.1
   13 |   0.6691 |     22.931 |   1.1236 |     36.799 |     1.2
   14 |   0.6317 |     22.156 |   1.0916 |     33.837 |     1.3
   15 |   0.5935 |     20.585 |   1.1077 |     33.333 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 648,097

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0205 |     51.841 |   1.5354 |     45.526 |     0.1
    2 |   1.4434 |     45.467 |   1.3881 |     43.636 |     0.2
    3 |   1.3463 |     44.225 |   1.3162 |     42.376 |     0.3
    4 |   1.2832 |     42.697 |   1.2799 |     42.943 |     0.4
    5 |   1.2373 |     41.274 |   1.2520 |     41.966 |     0.5
    6 |   1.1985 |     40.252 |   1.2368 |     41.115 |     0.6
    7 |   1.1626 |     39.213 |   1.1982 |     39.414 |     0.7
    8 |   1.1322 |     38.306 |   1.1788 |     39.603 |     0.8
    9 |   1.0997 |     37.295 |   1.1627 |     38.784 |     0.9
   10 |   1.0681 |     36.125 |   1.1432 |     37.713 |     0.9
   11 |   1.0418 |     35.345 |   1.1309 |     36.894 |     1.0
   12 |   1.0170 |     34.377 |   1.1179 |     36.673 |     1.1
   13 |   0.9915 |     33.449 |   1.1049 |     36.610 |     1.2
   14 |   0.9692 |     32.471 |   1.1036 |     36.137 |     1.3
   15 |   0.9408 |     31.597 |   1.1051 |     36.894 |     1.4
   16 |   0.9188 |     30.844 |   1.0819 |     35.476 |     1.5
   17 |   0.8973 |     30.069 |   1.0819 |     35.854 |     1.6
   18 |   0.8742 |     29.294 |   1.0760 |     35.444 |     1.7
   19 |   0.8513 |     28.492 |   1.0816 |     34.783 |     1.8
   20 |   0.8303 |     27.437 |   1.0683 |     35.066 |     1.9
   21 |   0.8096 |     26.673 |   1.0711 |     35.696 |     2.0
   22 |   0.7872 |     26.245 |   1.0693 |     34.625 |     2.1
   23 |   0.7653 |     25.316 |   1.0656 |     35.224 |     2.2
   24 |   0.7464 |     24.624 |   1.0579 |     34.121 |     2.3
   25 |   0.7263 |     24.129 |   1.0859 |     36.011 |     2.4
   26 |   0.7060 |     23.442 |   1.0902 |     36.011 |     2.5
   27 |   0.6838 |     22.426 |   1.1097 |     34.972 |     2.6
   28 |   0.6668 |     22.101 |   1.1077 |     35.255 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 243,425

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7932 |     50.088 |   1.3776 |     44.802 |     0.1
    2 |   1.3684 |     45.373 |   1.3055 |     44.644 |     0.3
    3 |   1.3019 |     44.258 |   1.2552 |     41.808 |     0.4
    4 |   1.2570 |     43.340 |   1.2128 |     41.745 |     0.6
    5 |   1.2245 |     42.428 |   1.2349 |     43.447 |     0.7
    6 |   1.2003 |     41.889 |   1.2052 |     40.328 |     0.9
    7 |   1.1782 |     41.301 |   1.1665 |     39.761 |     1.0
    8 |   1.1640 |     40.983 |   1.1542 |     38.910 |     1.2
    9 |   1.1498 |     40.455 |   1.1600 |     39.855 |     1.3
   10 |   1.1275 |     39.746 |   1.1367 |     38.721 |     1.5
   11 |   1.1116 |     38.763 |   1.1452 |     39.004 |     1.6
   12 |   1.1031 |     38.675 |   1.1343 |     38.815 |     1.8
   13 |   1.0924 |     38.290 |   1.1298 |     38.311 |     1.9
   14 |   1.0780 |     37.669 |   1.1514 |     38.752 |     2.1
   15 |   1.0649 |     37.383 |   1.0905 |     36.957 |     2.2
   16 |   1.0557 |     36.993 |   1.1293 |     37.902 |     2.4
   17 |   1.0408 |     36.185 |   1.1406 |     38.343 |     2.5
   18 |   1.0317 |     36.301 |   1.1023 |     37.587 |     2.7
   19 |   1.0215 |     35.718 |   1.1195 |     38.059 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 979,873

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6191 |     48.742 |   1.3088 |     43.006 |     0.1
    2 |   1.3084 |     44.417 |   1.2512 |     42.281 |     0.2
    3 |   1.2391 |     43.032 |   1.2234 |     40.706 |     0.3
    4 |   1.1903 |     41.345 |   1.1683 |     39.666 |     0.4
    5 |   1.1403 |     39.768 |   1.1528 |     39.382 |     0.5
    6 |   1.1101 |     38.554 |   1.1333 |     38.847 |     0.6
    7 |   1.0656 |     36.938 |   1.1368 |     38.217 |     0.7
    8 |   1.0388 |     35.965 |   1.1027 |     37.146 |     0.8
    9 |   1.0040 |     34.866 |   1.1269 |     35.885 |     0.9
   10 |   0.9786 |     33.630 |   1.0785 |     35.570 |     1.0
   11 |   0.9543 |     32.954 |   1.0749 |     35.948 |     1.1
   12 |   0.9142 |     31.542 |   1.0633 |     35.098 |     1.2
   13 |   0.8968 |     30.888 |   1.0439 |     33.774 |     1.3
   14 |   0.8624 |     29.773 |   1.0555 |     34.751 |     1.4
   15 |   0.8413 |     29.289 |   1.0753 |     35.035 |     1.5
   16 |   0.8178 |     28.009 |   1.0484 |     34.594 |     1.6
   17 |   0.7845 |     27.305 |   1.0993 |     34.499 |     1.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 326,497

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4221 |     58.803 |   1.8154 |     46.849 |     0.1
    2 |   1.6432 |     45.873 |   1.5651 |     44.991 |     0.1
    3 |   1.4962 |     44.961 |   1.4647 |     44.739 |     0.2
    4 |   1.4213 |     44.373 |   1.4093 |     44.392 |     0.3
    5 |   1.3651 |     43.626 |   1.3639 |     43.289 |     0.4
    6 |   1.3235 |     42.939 |   1.3410 |     41.871 |     0.4
    7 |   1.2856 |     41.917 |   1.3177 |     41.556 |     0.5
    8 |   1.2492 |     40.510 |   1.2999 |     41.084 |     0.6
    9 |   1.2205 |     40.169 |   1.2737 |     41.399 |     0.7
   10 |   1.1913 |     38.905 |   1.2655 |     40.611 |     0.7
   11 |   1.1665 |     38.345 |   1.2393 |     40.328 |     0.8
   12 |   1.1411 |     37.960 |   1.2372 |     39.981 |     0.9
   13 |   1.1202 |     37.466 |   1.2383 |     39.887 |     1.0
   14 |   1.0991 |     36.889 |   1.2040 |     38.973 |     1.0
   15 |   1.0813 |     36.515 |   1.2018 |     39.004 |     1.1
   16 |   1.0620 |     35.894 |   1.2177 |     39.351 |     1.2
   17 |   1.0447 |     35.059 |   1.2196 |     39.540 |     1.3
   18 |   1.0311 |     34.724 |   1.1928 |     38.595 |     1.3
   19 |   1.0163 |     34.081 |   1.2001 |     38.280 |     1.4
   20 |   1.0012 |     33.718 |   1.1744 |     38.248 |     1.5
   21 |   0.9883 |     33.086 |   1.1696 |     37.776 |     1.6
   22 |   0.9749 |     32.718 |   1.1503 |     36.862 |     1.6
   23 |   0.9570 |     31.729 |   1.1669 |     37.776 |     1.7
   24 |   0.9469 |     31.520 |   1.1606 |     37.524 |     1.8
   25 |   0.9355 |     30.959 |   1.1762 |     38.091 |     1.9
   26 |   0.9256 |     30.976 |   1.1757 |     38.532 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,044,641

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9733 |     51.495 |   1.5078 |     45.652 |     0.2
    2 |   1.4209 |     45.379 |   1.3617 |     44.077 |     0.3
    3 |   1.3228 |     43.483 |   1.2957 |     42.470 |     0.5
    4 |   1.2618 |     42.005 |   1.2606 |     42.565 |     0.7
    5 |   1.2111 |     40.801 |   1.2129 |     39.351 |     0.8
    6 |   1.1719 |     39.686 |   1.1933 |     38.721 |     1.0
    7 |   1.1356 |     38.422 |   1.1743 |     39.351 |     1.2
    8 |   1.1020 |     37.295 |   1.1736 |     39.004 |     1.3
    9 |   1.0715 |     36.520 |   1.1296 |     37.303 |     1.5
   10 |   1.0384 |     35.119 |   1.1335 |     37.965 |     1.7
   11 |   1.0137 |     34.218 |   1.1205 |     37.020 |     1.8
   12 |   0.9805 |     33.136 |   1.0951 |     37.272 |     2.0
   13 |   0.9508 |     31.905 |   1.0881 |     36.200 |     2.2
   14 |   0.9270 |     31.130 |   1.1034 |     35.602 |     2.3
   15 |   0.9009 |     30.240 |   1.1116 |     37.335 |     2.5
   16 |   0.8708 |     29.410 |   1.0852 |     35.885 |     2.7
   17 |   0.8465 |     28.289 |   1.0929 |     36.232 |     2.8
   18 |   0.8178 |     27.267 |   1.1207 |     36.452 |     3.0
   19 |   0.7956 |     26.580 |   1.1083 |     35.980 |     3.2
   20 |   0.7725 |     25.668 |   1.1079 |     36.137 |     3.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 327,393

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7290 |     68.870 |   2.0901 |     48.614 |     0.2
    2 |   1.9547 |     48.071 |   1.6456 |     45.621 |     0.3
    3 |   1.6626 |     46.610 |   1.5227 |     45.432 |     0.5
    4 |   1.5512 |     46.225 |   1.4598 |     45.243 |     0.7
    5 |   1.4921 |     46.263 |   1.4196 |     45.369 |     0.8
    6 |   1.4460 |     46.258 |   1.3814 |     44.266 |     1.0
    7 |   1.4131 |     45.615 |   1.3671 |     44.959 |     1.1
    8 |   1.3848 |     45.115 |   1.3391 |     43.352 |     1.3
    9 |   1.3627 |     45.054 |   1.3208 |     42.848 |     1.5
   10 |   1.3412 |     44.411 |   1.3050 |     42.407 |     1.6
   11 |   1.3246 |     43.928 |   1.2974 |     42.911 |     1.8
   12 |   1.3074 |     43.499 |   1.2752 |     41.714 |     2.0
   13 |   1.2926 |     43.301 |   1.2776 |     42.281 |     2.1
   14 |   1.2786 |     42.521 |   1.2685 |     41.777 |     2.3
   15 |   1.2637 |     42.307 |   1.2510 |     41.651 |     2.5
   16 |   1.2507 |     42.180 |   1.2398 |     40.359 |     2.6
   17 |   1.2405 |     41.867 |   1.2323 |     40.737 |     2.8
   18 |   1.2294 |     41.735 |   1.2223 |     40.296 |     3.0
   19 |   1.2142 |     41.191 |   1.2068 |     39.918 |     3.1
   20 |   1.2067 |     40.840 |   1.2006 |     39.256 |     3.3
   21 |   1.1960 |     40.603 |   1.2080 |     40.107 |     3.4
   22 |   1.1841 |     40.065 |   1.1874 |     39.193 |     3.6
   23 |   1.1795 |     40.257 |   1.1829 |     38.721 |     3.8
   24 |   1.1712 |     40.103 |   1.1906 |     39.288 |     3.9
   25 |   1.1604 |     39.581 |   1.1687 |     38.406 |     4.1
   26 |   1.1539 |     39.537 |   1.1657 |     38.406 |     4.3
   27 |   1.1474 |     39.356 |   1.1663 |     38.878 |     4.4
   28 |   1.1381 |     39.219 |   1.1602 |     38.248 |     4.6
   29 |   1.1288 |     38.471 |   1.1615 |     38.374 |     4.8
   30 |   1.1202 |     38.372 |   1.1487 |     37.807 |     4.9
   31 |   1.1155 |     38.444 |   1.1487 |     37.618 |     5.1
   32 |   1.1109 |     38.092 |   1.1539 |     38.059 |     5.3
   33 |   1.1033 |     38.015 |   1.1606 |     38.154 |     5.4
   34 |   1.0938 |     37.933 |   1.1238 |     37.020 |     5.6
   35 |   1.0931 |     37.795 |   1.1426 |     37.744 |     5.7
   36 |   1.0801 |     37.383 |   1.1309 |     38.154 |     5.9
   37 |   1.0790 |     36.977 |   1.1239 |     37.114 |     6.1
   38 |   1.0709 |     36.757 |   1.1201 |     37.555 |     6.2
   39 |   1.0658 |     36.658 |   1.1139 |     36.925 |     6.4
   40 |   1.0601 |     36.537 |   1.1263 |     37.461 |     6.6
   41 |   1.0510 |     36.191 |   1.1005 |     36.641 |     6.7
   42 |   1.0502 |     36.097 |   1.0939 |     36.578 |     6.9
   43 |   1.0417 |     35.707 |   1.1109 |     36.736 |     7.1
   44 |   1.0367 |     35.460 |   1.1009 |     36.358 |     7.2
   45 |   1.0276 |     35.169 |   1.0984 |     36.799 |     7.4
   46 |   1.0281 |     35.202 |   1.1006 |     36.641 |     7.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 648,097

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2274 |     54.033 |   1.5844 |     44.991 |     0.1
    2 |   1.5442 |     46.274 |   1.4085 |     44.234 |     0.2
    3 |   1.4266 |     45.686 |   1.3447 |     43.541 |     0.2
    4 |   1.3662 |     44.543 |   1.2991 |     42.533 |     0.3
    5 |   1.3205 |     43.373 |   1.2758 |     41.462 |     0.4
    6 |   1.2827 |     42.719 |   1.2369 |     40.706 |     0.5
    7 |   1.2482 |     41.686 |   1.2195 |     40.202 |     0.6
    8 |   1.2231 |     41.164 |   1.2102 |     39.382 |     0.6
    9 |   1.1995 |     40.471 |   1.1952 |     39.256 |     0.7
   10 |   1.1823 |     40.125 |   1.1718 |     39.099 |     0.8
   11 |   1.1601 |     39.521 |   1.1554 |     38.500 |     0.9
   12 |   1.1504 |     39.257 |   1.1681 |     40.107 |     1.0
   13 |   1.1348 |     38.795 |   1.1636 |     39.067 |     1.1
   14 |   1.1189 |     38.460 |   1.1447 |     38.878 |     1.1
   15 |   1.1055 |     38.076 |   1.1249 |     38.406 |     1.2
   16 |   1.0901 |     37.218 |   1.1342 |     37.807 |     1.3
   17 |   1.0759 |     36.702 |   1.1247 |     37.870 |     1.4
   18 |   1.0676 |     36.680 |   1.1315 |     37.744 |     1.5
   19 |   1.0572 |     35.998 |   1.1228 |     36.925 |     1.5
   20 |   1.0477 |     35.685 |   1.0987 |     36.547 |     1.6
   21 |   1.0336 |     35.125 |   1.0973 |     36.547 |     1.7
   22 |   1.0219 |     34.844 |   1.0949 |     36.389 |     1.8
   23 |   1.0097 |     34.471 |   1.0952 |     36.200 |     1.9
   24 |   1.0028 |     34.262 |   1.0856 |     36.200 |     2.0
   25 |   0.9982 |     34.268 |   1.0757 |     35.791 |     2.0
   26 |   0.9834 |     33.806 |   1.0994 |     36.295 |     2.1
   27 |   0.9755 |     33.103 |   1.0771 |     35.413 |     2.2
   28 |   0.9688 |     33.037 |   1.0728 |     35.507 |     2.3
   29 |   0.9594 |     32.493 |   1.0702 |     35.035 |     2.4
   30 |   0.9468 |     32.146 |   1.0674 |     35.161 |     2.5
   31 |   0.9424 |     31.608 |   1.0562 |     35.318 |     2.5
   32 |   0.9324 |     31.580 |   1.0622 |     35.003 |     2.6
   33 |   0.9275 |     31.141 |   1.0703 |     35.476 |     2.7
   34 |   0.9176 |     31.064 |   1.0634 |     35.539 |     2.8
   35 |   0.9029 |     30.399 |   1.0534 |     34.720 |     2.9
   36 |   0.9025 |     30.553 |   1.0601 |     34.814 |     3.0
   37 |   0.8937 |     30.174 |   1.0654 |     35.098 |     3.0
   38 |   0.8828 |     30.349 |   1.0629 |     35.728 |     3.1
   39 |   0.8734 |     29.476 |   1.0490 |     34.846 |     3.2
   40 |   0.8703 |     29.174 |   1.0565 |     35.192 |     3.3
   41 |   0.8579 |     28.965 |   1.0477 |     34.594 |     3.4
   42 |   0.8521 |     29.014 |   1.0528 |     34.531 |     3.4
   43 |   0.8413 |     28.107 |   1.0520 |     34.216 |     3.5
   44 |   0.8423 |     28.245 |   1.0586 |     34.436 |     3.6
   45 |   0.8313 |     27.701 |   1.0565 |     34.499 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,177,249

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3588 |     59.100 |   1.6464 |     47.858 |     0.1
    2 |   1.6187 |     47.110 |   1.4203 |     44.581 |     0.2
    3 |   1.4662 |     46.258 |   1.3645 |     45.180 |     0.3
    4 |   1.4107 |     45.818 |   1.3401 |     44.833 |     0.4
    5 |   1.3710 |     45.395 |   1.3018 |     44.423 |     0.5
    6 |   1.3400 |     44.477 |   1.2728 |     42.596 |     0.6
    7 |   1.3108 |     43.867 |   1.2569 |     42.439 |     0.7
    8 |   1.2829 |     43.027 |   1.2468 |     42.722 |     0.8
    9 |   1.2629 |     42.301 |   1.2213 |     41.840 |     0.9
   10 |   1.2443 |     41.906 |   1.2127 |     41.241 |     1.0
   11 |   1.2272 |     41.587 |   1.1891 |     40.454 |     1.1
   12 |   1.2109 |     41.362 |   1.1901 |     40.233 |     1.2
   13 |   1.1981 |     41.081 |   1.1929 |     40.296 |     1.3
   14 |   1.1785 |     40.521 |   1.2027 |     41.840 |     1.4
   15 |   1.1704 |     40.043 |   1.1668 |     39.319 |     1.5
   16 |   1.1569 |     39.823 |   1.1575 |     38.658 |     1.7
   17 |   1.1383 |     38.861 |   1.1601 |     39.540 |     1.8
   18 |   1.1330 |     38.982 |   1.1578 |     38.847 |     1.9
   19 |   1.1215 |     38.636 |   1.1531 |     39.004 |     2.0
   20 |   1.1101 |     38.004 |   1.1502 |     38.311 |     2.1
   21 |   1.0996 |     37.378 |   1.1547 |     39.099 |     2.2
   22 |   1.0937 |     37.471 |   1.1299 |     38.248 |     2.3
   23 |   1.0812 |     36.927 |   1.1446 |     38.595 |     2.4
   24 |   1.0709 |     36.597 |   1.1430 |     37.555 |     2.5
   25 |   1.0659 |     36.515 |   1.1461 |     37.650 |     2.6
   26 |   1.0563 |     36.081 |   1.1316 |     37.429 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 243,425

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7178 |     65.150 |   2.1336 |     49.370 |     0.1
    2 |   1.8671 |     46.653 |   1.6952 |     45.054 |     0.3
    3 |   1.6149 |     45.923 |   1.5555 |     44.833 |     0.4
    4 |   1.5128 |     45.340 |   1.4753 |     44.802 |     0.5
    5 |   1.4491 |     45.016 |   1.4207 |     44.108 |     0.7
    6 |   1.4025 |     44.763 |   1.3860 |     43.415 |     0.8
    7 |   1.3666 |     43.598 |   1.3531 |     42.155 |     0.9
    8 |   1.3347 |     42.928 |   1.3321 |     42.250 |     1.1
    9 |   1.3088 |     42.582 |   1.3296 |     43.069 |     1.2
   10 |   1.2845 |     42.175 |   1.3016 |     42.470 |     1.4
   11 |   1.2624 |     41.614 |   1.2941 |     42.691 |     1.5
   12 |   1.2438 |     41.285 |   1.2775 |     42.060 |     1.6
   13 |   1.2261 |     41.026 |   1.2517 |     41.115 |     1.8
   14 |   1.2114 |     40.526 |   1.2474 |     41.525 |     1.9
   15 |   1.1929 |     40.098 |   1.2368 |     40.832 |     2.0
   16 |   1.1769 |     39.263 |   1.2111 |     40.296 |     2.2
   17 |   1.1643 |     39.186 |   1.2051 |     40.044 |     2.3
   18 |   1.1509 |     38.510 |   1.2116 |     39.824 |     2.4
   19 |   1.1328 |     37.696 |   1.2142 |     40.611 |     2.6
   20 |   1.1190 |     37.499 |   1.1874 |     39.414 |     2.7
   21 |   1.1059 |     37.125 |   1.1742 |     39.477 |     2.8
   22 |   1.0935 |     36.652 |   1.1826 |     39.319 |     3.0
   23 |   1.0781 |     36.389 |   1.1581 |     38.500 |     3.1
   24 |   1.0664 |     36.020 |   1.1728 |     38.941 |     3.2
   25 |   1.0540 |     35.564 |   1.1631 |     38.217 |     3.4
   26 |   1.0407 |     35.092 |   1.1661 |     38.878 |     3.5
   27 |   1.0278 |     34.504 |   1.1569 |     38.122 |     3.6
   28 |   1.0186 |     34.207 |   1.1698 |     37.933 |     3.8
   29 |   1.0067 |     33.723 |   1.1604 |     38.185 |     3.9
   30 |   0.9977 |     33.581 |   1.1699 |     38.374 |     4.1
   31 |   0.9858 |     33.383 |   1.1613 |     38.784 |     4.2
   32 |   0.9734 |     32.927 |   1.1449 |     37.965 |     4.3
   33 |   0.9630 |     32.581 |   1.1441 |     38.028 |     4.5
   34 |   0.9548 |     32.366 |   1.1468 |     37.681 |     4.6
   35 |   0.9427 |     31.668 |   1.1604 |     38.028 |     4.7
   36 |   0.9353 |     31.525 |   1.1507 |     38.469 |     4.9
   37 |   0.9242 |     31.229 |   1.1503 |     38.595 |     5.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 898,017

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5321 |     47.758 |   1.2893 |     43.888 |     0.2
    2 |   1.2464 |     43.933 |   1.2177 |     42.754 |     0.3
    3 |   1.1807 |     41.642 |   1.1752 |     40.422 |     0.5
    4 |   1.1328 |     40.614 |   1.1552 |     40.485 |     0.7
    5 |   1.0980 |     39.515 |   1.1340 |     38.878 |     0.8
    6 |   1.0705 |     38.427 |   1.1135 |     39.950 |     1.0
    7 |   1.0473 |     37.499 |   1.1089 |     39.036 |     1.2
    8 |   1.0373 |     37.246 |   1.0778 |     36.421 |     1.4
    9 |   1.0130 |     36.477 |   1.0727 |     37.177 |     1.5
   10 |   0.9981 |     35.768 |   1.0774 |     37.744 |     1.7
   11 |   0.9756 |     34.751 |   1.0705 |     38.532 |     1.9
   12 |   0.9739 |     34.685 |   1.0455 |     35.665 |     2.0
   13 |   0.9591 |     34.526 |   1.0495 |     37.209 |     2.2
   14 |   0.9389 |     33.586 |   1.0265 |     35.318 |     2.4
   15 |   0.9274 |     32.894 |   1.0364 |     35.885 |     2.5
   16 |   0.9292 |     33.037 |   1.0486 |     37.240 |     2.7
   17 |   0.9175 |     32.976 |   1.0195 |     35.255 |     2.9
   18 |   0.9004 |     32.015 |   1.0339 |     36.074 |     3.1
   19 |   0.8972 |     31.877 |   1.0393 |     35.917 |     3.2
   20 |   0.8867 |     31.454 |   0.9947 |     33.995 |     3.4
   21 |   0.8746 |     31.361 |   1.0178 |     34.688 |     3.6
   22 |   0.8608 |     30.613 |   1.0391 |     35.003 |     3.7
   23 |   0.8573 |     30.454 |   1.0087 |     34.026 |     3.9
   24 |   0.8436 |     30.273 |   1.0073 |     34.594 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 748,577

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5151 |     47.505 |   1.2785 |     42.974 |     0.2
    2 |   1.2299 |     42.928 |   1.1993 |     42.092 |     0.3
    3 |   1.1798 |     41.884 |   1.1852 |     41.052 |     0.5
    4 |   1.1411 |     40.939 |   1.1632 |     41.493 |     0.6
    5 |   1.1041 |     39.339 |   1.1419 |     39.887 |     0.8
    6 |   1.0891 |     38.999 |   1.1440 |     39.698 |     1.0
    7 |   1.0709 |     38.642 |   1.1080 |     39.319 |     1.1
    8 |   1.0590 |     38.098 |   1.1168 |     40.265 |     1.3
    9 |   1.0421 |     37.565 |   1.1081 |     39.950 |     1.4
   10 |   1.0363 |     37.460 |   1.0917 |     39.319 |     1.6
   11 |   1.0248 |     37.317 |   1.0798 |     38.059 |     1.8
   12 |   1.0196 |     37.235 |   1.0691 |     37.429 |     1.9
   13 |   1.0105 |     36.564 |   1.0785 |     38.091 |     2.1
   14 |   1.0016 |     36.317 |   1.0729 |     38.437 |     2.2
   15 |   0.9946 |     36.185 |   1.0466 |     37.398 |     2.4
   16 |   0.9790 |     35.740 |   1.0674 |     37.492 |     2.6
   17 |   0.9687 |     35.427 |   1.0563 |     37.429 |     2.7
   18 |   0.9672 |     35.410 |   1.0543 |     37.398 |     2.9
   19 |   0.9593 |     34.866 |   1.0635 |     37.555 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 648,097

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1726 |     53.412 |   1.5653 |     45.148 |     0.1
    2 |   1.5251 |     46.164 |   1.4018 |     45.369 |     0.2
    3 |   1.4084 |     45.115 |   1.3467 |     44.234 |     0.2
    4 |   1.3494 |     44.329 |   1.2999 |     43.163 |     0.3
    5 |   1.3139 |     43.609 |   1.2716 |     42.313 |     0.4
    6 |   1.2768 |     42.648 |   1.2577 |     41.714 |     0.5
    7 |   1.2449 |     41.708 |   1.2243 |     40.296 |     0.6
    8 |   1.2200 |     41.098 |   1.2120 |     40.170 |     0.7
    9 |   1.1967 |     40.504 |   1.1987 |     39.918 |     0.7
   10 |   1.1728 |     39.763 |   1.1879 |     40.013 |     0.8
   11 |   1.1565 |     39.114 |   1.1690 |     38.973 |     0.9
   12 |   1.1406 |     38.773 |   1.1751 |     38.406 |     1.0
   13 |   1.1208 |     38.240 |   1.1571 |     37.776 |     1.1
   14 |   1.1051 |     37.554 |   1.1392 |     36.578 |     1.1
   15 |   1.0892 |     37.004 |   1.1361 |     36.988 |     1.2
   16 |   1.0718 |     36.361 |   1.1347 |     36.767 |     1.3
   17 |   1.0568 |     35.630 |   1.1311 |     36.200 |     1.4
   18 |   1.0459 |     35.389 |   1.1368 |     36.767 |     1.5
   19 |   1.0318 |     34.608 |   1.1107 |     35.917 |     1.6
   20 |   1.0170 |     34.273 |   1.1217 |     36.358 |     1.6
   21 |   1.0042 |     33.789 |   1.1112 |     35.917 |     1.7
   22 |   0.9958 |     33.691 |   1.1237 |     35.539 |     1.8
   23 |   0.9799 |     32.921 |   1.1148 |     36.106 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 847,265

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0607 |     51.572 |   1.5262 |     44.959 |     0.2
    2 |   1.4439 |     45.593 |   1.3710 |     43.195 |     0.3
    3 |   1.3400 |     43.999 |   1.3033 |     42.502 |     0.5
    4 |   1.2799 |     42.362 |   1.2626 |     39.603 |     0.6
    5 |   1.2326 |     40.867 |   1.2492 |     40.863 |     0.8
    6 |   1.1931 |     39.757 |   1.2020 |     38.847 |     1.0
    7 |   1.1554 |     39.010 |   1.1875 |     38.784 |     1.1
    8 |   1.1204 |     37.543 |   1.1687 |     38.185 |     1.3
    9 |   1.0921 |     37.054 |   1.1506 |     37.209 |     1.5
   10 |   1.0631 |     36.130 |   1.1286 |     36.641 |     1.6
   11 |   1.0331 |     34.943 |   1.1224 |     37.335 |     1.8
   12 |   1.0061 |     33.778 |   1.1294 |     37.335 |     2.0
   13 |   0.9792 |     32.690 |   1.0956 |     35.885 |     2.1
   14 |   0.9537 |     32.223 |   1.0993 |     36.421 |     2.3
   15 |   0.9253 |     31.014 |   1.0941 |     36.988 |     2.4
   16 |   0.9019 |     30.278 |   1.0994 |     36.326 |     2.6
   17 |   0.8775 |     29.459 |   1.0971 |     35.444 |     2.8
   18 |   0.8606 |     28.888 |   1.0816 |     36.200 |     2.9
   19 |   0.8288 |     27.525 |   1.1038 |     36.263 |     3.1
   20 |   0.8037 |     26.921 |   1.0693 |     35.287 |     3.3
   21 |   0.7758 |     26.063 |   1.1284 |     36.736 |     3.4
   22 |   0.7514 |     24.893 |   1.1211 |     36.767 |     3.6
   23 |   0.7299 |     23.953 |   1.0924 |     35.696 |     3.7
   24 |   0.7008 |     23.019 |   1.1197 |     36.011 |     3.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,013,153

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5883 |     48.978 |   1.3139 |     45.243 |     0.1
    2 |   1.3074 |     45.170 |   1.2643 |     43.919 |     0.3
    3 |   1.2453 |     43.758 |   1.2515 |     43.321 |     0.4
    4 |   1.2113 |     42.439 |   1.1928 |     42.218 |     0.6
    5 |   1.1757 |     41.510 |   1.1738 |     40.202 |     0.7
    6 |   1.1447 |     40.774 |   1.1441 |     40.202 |     0.9
    7 |   1.1188 |     40.153 |   1.1249 |     39.036 |     1.0
    8 |   1.1038 |     39.438 |   1.1252 |     39.319 |     1.2
    9 |   1.0857 |     38.493 |   1.0988 |     38.374 |     1.3
   10 |   1.0665 |     38.054 |   1.1105 |     38.941 |     1.5
   11 |   1.0607 |     37.625 |   1.1100 |     38.847 |     1.6
   12 |   1.0453 |     37.076 |   1.1132 |     38.185 |     1.8
   13 |   1.0343 |     36.685 |   1.0802 |     37.776 |     1.9
   14 |   1.0199 |     36.334 |   1.0906 |     37.650 |     2.1
   15 |   1.0030 |     35.834 |   1.0810 |     38.595 |     2.2
   16 |   1.0022 |     35.498 |   1.0918 |     37.839 |     2.4
   17 |   0.9830 |     34.866 |   1.0826 |     38.311 |     2.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 358,817

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5561 |     61.507 |   1.8255 |     45.400 |     0.1
    2 |   1.7493 |     46.588 |   1.5615 |     44.959 |     0.2
    3 |   1.5783 |     46.263 |   1.4706 |     44.928 |     0.3
    4 |   1.4959 |     45.532 |   1.4133 |     44.077 |     0.4
    5 |   1.4397 |     45.038 |   1.3747 |     43.982 |     0.5
    6 |   1.4054 |     44.901 |   1.3430 |     42.659 |     0.6
    7 |   1.3694 |     43.928 |   1.3326 |     43.415 |     0.7
    8 |   1.3467 |     43.763 |   1.3093 |     43.195 |     0.8
    9 |   1.3242 |     43.181 |   1.2958 |     43.226 |     0.9
   10 |   1.3035 |     42.845 |   1.2869 |     43.069 |     1.0
   11 |   1.2806 |     42.532 |   1.2848 |     42.691 |     1.1
   12 |   1.2658 |     42.005 |   1.2589 |     41.619 |     1.2
   13 |   1.2432 |     41.323 |   1.2569 |     42.155 |     1.3
   14 |   1.2291 |     41.219 |   1.2425 |     41.336 |     1.4
   15 |   1.2146 |     41.087 |   1.2293 |     40.391 |     1.5
   16 |   1.2037 |     40.669 |   1.2153 |     39.729 |     1.6
   17 |   1.1895 |     40.065 |   1.2223 |     39.950 |     1.7
   18 |   1.1738 |     39.620 |   1.2146 |     39.981 |     1.8
   19 |   1.1650 |     39.444 |   1.1955 |     39.067 |     1.9
   20 |   1.1566 |     39.164 |   1.2067 |     39.855 |     2.0
   21 |   1.1428 |     38.768 |   1.2025 |     40.013 |     2.1
   22 |   1.1331 |     38.642 |   1.1925 |     39.319 |     2.2
   23 |   1.1272 |     38.471 |   1.1832 |     38.784 |     2.3
   24 |   1.1134 |     37.724 |   1.1804 |     38.721 |     2.4
   25 |   1.1058 |     37.746 |   1.1665 |     37.933 |     2.5
   26 |   1.0970 |     37.279 |   1.1624 |     38.343 |     2.6
   27 |   1.0891 |     36.955 |   1.1608 |     38.532 |     2.7
   28 |   1.0790 |     37.097 |   1.1694 |     37.996 |     2.8
   29 |   1.0769 |     36.762 |   1.1582 |     37.965 |     2.9
   30 |   1.0669 |     35.987 |   1.1537 |     38.185 |     3.0
   31 |   1.0563 |     35.850 |   1.1284 |     37.146 |     3.1
   32 |   1.0536 |     35.900 |   1.1501 |     38.059 |     3.2
   33 |   1.0410 |     35.438 |   1.1441 |     38.311 |     3.3
   34 |   1.0317 |     35.191 |   1.1451 |     37.933 |     3.4
   35 |   1.0272 |     35.114 |   1.1342 |     37.713 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 779,681

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1345 |     54.643 |   1.5391 |     45.495 |     0.1
    2 |   1.4391 |     45.065 |   1.3731 |     43.321 |     0.2
    3 |   1.3360 |     43.582 |   1.3084 |     42.659 |     0.2
    4 |   1.2784 |     42.219 |   1.2736 |     42.344 |     0.3
    5 |   1.2318 |     41.070 |   1.2528 |     41.147 |     0.4
    6 |   1.1919 |     40.065 |   1.2320 |     40.265 |     0.5
    7 |   1.1601 |     39.427 |   1.2071 |     39.540 |     0.6
    8 |   1.1301 |     38.114 |   1.1792 |     38.658 |     0.6
    9 |   1.0999 |     37.334 |   1.1660 |     38.343 |     0.7
   10 |   1.0756 |     36.449 |   1.1531 |     38.469 |     0.8
   11 |   1.0452 |     35.751 |   1.1348 |     37.335 |     0.9
   12 |   1.0145 |     34.581 |   1.1417 |     36.704 |     1.0
   13 |   0.9932 |     33.756 |   1.1088 |     36.200 |     1.0
   14 |   0.9665 |     32.767 |   1.1093 |     36.263 |     1.1
   15 |   0.9412 |     31.679 |   1.1005 |     35.854 |     1.2
   16 |   0.9192 |     30.954 |   1.0772 |     34.877 |     1.3
   17 |   0.8969 |     30.256 |   1.0942 |     35.035 |     1.4
   18 |   0.8730 |     29.212 |   1.0767 |     34.373 |     1.4
   19 |   0.8501 |     28.278 |   1.0813 |     33.680 |     1.5
   20 |   0.8317 |     27.904 |   1.0895 |     34.121 |     1.6
   21 |   0.8079 |     26.811 |   1.0934 |     34.846 |     1.7
   22 |   0.7833 |     26.003 |   1.1080 |     34.940 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 326,497

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5610 |     62.062 |   1.8419 |     46.723 |     0.1
    2 |   1.7856 |     47.159 |   1.5630 |     46.251 |     0.2
    3 |   1.5841 |     46.401 |   1.4725 |     45.778 |     0.2
    4 |   1.5025 |     46.181 |   1.4148 |     44.392 |     0.3
    5 |   1.4473 |     45.736 |   1.3789 |     43.415 |     0.4
    6 |   1.4098 |     45.076 |   1.3537 |     44.518 |     0.5
    7 |   1.3799 |     44.714 |   1.3342 |     43.289 |     0.6
    8 |   1.3560 |     44.466 |   1.3114 |     42.817 |     0.6
    9 |   1.3365 |     43.988 |   1.2930 |     42.250 |     0.7
   10 |   1.3149 |     43.450 |   1.2866 |     43.541 |     0.8
   11 |   1.2997 |     43.148 |   1.2793 |     43.478 |     0.9
   12 |   1.2794 |     42.785 |   1.2659 |     43.321 |     0.9
   13 |   1.2657 |     42.356 |   1.2511 |     42.754 |     1.0
   14 |   1.2494 |     41.845 |   1.2415 |     41.777 |     1.1
   15 |   1.2369 |     41.472 |   1.2477 |     42.439 |     1.2
   16 |   1.2242 |     41.461 |   1.2225 |     41.147 |     1.3
   17 |   1.2100 |     41.131 |   1.2411 |     41.903 |     1.3
   18 |   1.1975 |     40.439 |   1.2100 |     40.989 |     1.4
   19 |   1.1901 |     40.417 |   1.2155 |     41.052 |     1.5
   20 |   1.1798 |     40.114 |   1.2129 |     40.832 |     1.6
   21 |   1.1672 |     39.938 |   1.2063 |     40.202 |     1.7
   22 |   1.1649 |     39.647 |   1.1967 |     40.013 |     1.7
   23 |   1.1503 |     39.241 |   1.1834 |     39.540 |     1.8
   24 |   1.1435 |     39.021 |   1.2035 |     39.635 |     1.9
   25 |   1.1372 |     38.960 |   1.1721 |     38.626 |     2.0
   26 |   1.1264 |     38.169 |   1.1782 |     38.595 |     2.1
   27 |   1.1187 |     38.109 |   1.1840 |     39.162 |     2.1
   28 |   1.1074 |     37.872 |   1.1568 |     38.343 |     2.2
   29 |   1.1039 |     37.828 |   1.1557 |     38.311 |     2.3
   30 |   1.0949 |     37.427 |   1.1719 |     38.500 |     2.4
   31 |   1.0883 |     37.141 |   1.1434 |     37.366 |     2.4
   32 |   1.0796 |     37.010 |   1.1563 |     37.776 |     2.5
   33 |   1.0761 |     36.839 |   1.1431 |     37.461 |     2.6
   34 |   1.0680 |     36.427 |   1.1505 |     37.587 |     2.7
   35 |   1.0627 |     36.306 |   1.1559 |     38.217 |     2.8
   36 |   1.0541 |     35.938 |   1.1324 |     37.051 |     2.8
   37 |   1.0512 |     35.900 |   1.1096 |     35.948 |     2.9
   38 |   1.0448 |     35.559 |   1.1222 |     36.452 |     3.0
   39 |   1.0364 |     35.290 |   1.1418 |     36.610 |     3.1
   40 |   1.0318 |     35.301 |   1.1430 |     36.704 |     3.2
   41 |   1.0285 |     35.081 |   1.1438 |     36.673 |     3.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 813,985

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1093 |     54.715 |   1.5424 |     44.865 |     0.1
    2 |   1.4483 |     44.983 |   1.3955 |     43.919 |     0.2
    3 |   1.3486 |     43.411 |   1.3380 |     43.100 |     0.3
    4 |   1.2857 |     42.318 |   1.2919 |     42.187 |     0.3
    5 |   1.2340 |     40.829 |   1.2561 |     41.210 |     0.4
    6 |   1.1939 |     39.993 |   1.2172 |     39.635 |     0.5
    7 |   1.1575 |     39.054 |   1.1821 |     38.248 |     0.6
    8 |   1.1237 |     38.021 |   1.1876 |     39.130 |     0.7
    9 |   1.0980 |     37.279 |   1.1615 |     38.311 |     0.8
   10 |   1.0689 |     35.922 |   1.1366 |     37.177 |     0.8
   11 |   1.0434 |     34.910 |   1.1261 |     37.146 |     0.9
   12 |   1.0197 |     34.257 |   1.1065 |     36.169 |     1.0
   13 |   0.9941 |     33.152 |   1.1008 |     36.232 |     1.1
   14 |   0.9702 |     32.284 |   1.1027 |     35.885 |     1.2
   15 |   0.9504 |     31.723 |   1.0670 |     34.499 |     1.3
   16 |   0.9279 |     30.981 |   1.0819 |     35.381 |     1.4
   17 |   0.9077 |     30.108 |   1.0881 |     35.507 |     1.4
   18 |   0.8819 |     29.239 |   1.0686 |     33.743 |     1.5
   19 |   0.8636 |     28.575 |   1.0581 |     34.499 |     1.6
   20 |   0.8458 |     27.888 |   1.0668 |     35.003 |     1.7
   21 |   0.8211 |     26.833 |   1.0848 |     36.106 |     1.8
   22 |   0.8016 |     26.113 |   1.0551 |     33.837 |     1.9
   23 |   0.7771 |     25.431 |   1.0502 |     33.680 |     2.0
   24 |   0.7633 |     24.970 |   1.0705 |     33.774 |     2.1
   25 |   0.7440 |     24.426 |   1.0643 |     33.837 |     2.1
   26 |   0.7207 |     23.200 |   1.0569 |     32.924 |     2.2
   27 |   0.7031 |     22.645 |   1.0647 |     33.869 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 458,785

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7300 |     49.203 |   1.3530 |     44.077 |     0.2
    2 |   1.3545 |     45.417 |   1.2767 |     42.880 |     0.3
    3 |   1.2979 |     45.115 |   1.2427 |     42.628 |     0.5
    4 |   1.2640 |     44.340 |   1.2153 |     42.628 |     0.7
    5 |   1.2292 |     43.560 |   1.2087 |     43.163 |     0.8
    6 |   1.2172 |     43.362 |   1.1995 |     42.281 |     1.0
    7 |   1.1986 |     42.862 |   1.1816 |     41.525 |     1.1
    8 |   1.1894 |     42.796 |   1.1837 |     41.997 |     1.3
    9 |   1.1786 |     42.571 |   1.1650 |     40.958 |     1.5
   10 |   1.1704 |     42.115 |   1.1581 |     41.462 |     1.6
   11 |   1.1608 |     41.889 |   1.1596 |     40.769 |     1.8
   12 |   1.1556 |     42.109 |   1.1476 |     41.178 |     2.0
   13 |   1.1522 |     42.164 |   1.1428 |     40.265 |     2.1
   14 |   1.1428 |     41.609 |   1.1378 |     39.761 |     2.3
   15 |   1.1388 |     41.719 |   1.1356 |     40.611 |     2.5
   16 |   1.1327 |     41.494 |   1.1306 |     40.233 |     2.6
   17 |   1.1295 |     41.301 |   1.1359 |     41.021 |     2.8
   18 |   1.1250 |     41.422 |   1.1341 |     40.895 |     2.9
   19 |   1.1225 |     41.356 |   1.1340 |     39.792 |     3.1
   20 |   1.1200 |     41.230 |   1.1218 |     40.107 |     3.3
   21 |   1.1140 |     41.356 |   1.1174 |     39.887 |     3.4
   22 |   1.1127 |     40.983 |   1.1188 |     40.422 |     3.6
   23 |   1.1093 |     40.774 |   1.1124 |     39.887 |     3.8
   24 |   1.1091 |     41.032 |   1.1149 |     41.241 |     3.9
   25 |   1.1107 |     40.955 |   1.1149 |     39.603 |     4.1
   26 |   1.1045 |     40.911 |   1.1105 |     40.454 |     4.2
   27 |   1.0993 |     40.829 |   1.1047 |     39.382 |     4.4
   28 |   1.0923 |     40.158 |   1.1139 |     39.540 |     4.6
   29 |   1.0903 |     40.312 |   1.1044 |     38.941 |     4.7
   30 |   1.0768 |     39.312 |   1.1044 |     39.099 |     4.9
   31 |   1.0698 |     38.812 |   1.0973 |     39.319 |     5.1
   32 |   1.0695 |     38.916 |   1.1107 |     39.855 |     5.2
   33 |   1.0638 |     38.801 |   1.0934 |     38.563 |     5.4
   34 |   1.0596 |     39.010 |   1.0884 |     38.595 |     5.5
   35 |   1.0538 |     38.790 |   1.0983 |     38.815 |     5.7
   36 |   1.0550 |     38.763 |   1.1094 |     39.130 |     5.9
   37 |   1.0423 |     37.916 |   1.1101 |     39.288 |     6.0
   38 |   1.0409 |     38.087 |   1.1543 |     40.611 |     6.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 393,441

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3511 |     58.754 |   1.7557 |     44.612 |     0.1
    2 |   1.6042 |     45.703 |   1.5270 |     44.423 |     0.3
    3 |   1.4712 |     44.736 |   1.4367 |     43.636 |     0.5
    4 |   1.4043 |     44.137 |   1.3965 |     43.951 |     0.6
    5 |   1.3573 |     43.708 |   1.3658 |     42.502 |     0.8
    6 |   1.3226 |     42.911 |   1.3375 |     43.321 |     0.9
    7 |   1.2905 |     41.972 |   1.3351 |     42.691 |     1.1
    8 |   1.2580 |     41.362 |   1.3032 |     41.745 |     1.2
    9 |   1.2266 |     40.362 |   1.2951 |     42.060 |     1.4
   10 |   1.2015 |     39.900 |   1.2637 |     40.737 |     1.5
   11 |   1.1753 |     39.241 |   1.2355 |     39.572 |     1.7
   12 |   1.1561 |     38.828 |   1.2380 |     40.422 |     1.8
   13 |   1.1346 |     38.125 |   1.2432 |     40.013 |     2.0
   14 |   1.1161 |     37.614 |   1.2319 |     39.635 |     2.1
   15 |   1.0967 |     37.097 |   1.2337 |     40.643 |     2.3
   16 |   1.0800 |     36.383 |   1.1880 |     39.193 |     2.4
   17 |   1.0650 |     35.746 |   1.2057 |     39.603 |     2.6
   18 |   1.0475 |     35.454 |   1.1937 |     39.288 |     2.7
   19 |   1.0319 |     34.817 |   1.1778 |     38.941 |     2.9
   20 |   1.0157 |     34.086 |   1.1946 |     38.847 |     3.0
   21 |   1.0019 |     33.537 |   1.1626 |     38.469 |     3.2
   22 |   0.9844 |     32.954 |   1.1895 |     38.815 |     3.3
   23 |   0.9717 |     32.581 |   1.1547 |     37.965 |     3.5
   24 |   0.9601 |     32.108 |   1.1552 |     38.374 |     3.6
   25 |   0.9423 |     31.443 |   1.1367 |     37.461 |     3.8
   26 |   0.9277 |     30.833 |   1.1686 |     38.469 |     4.0
   27 |   0.9146 |     30.476 |   1.1340 |     37.146 |     4.1
   28 |   0.9016 |     29.981 |   1.1402 |     37.429 |     4.3
   29 |   0.8911 |     29.338 |   1.1715 |     38.658 |     4.4
   30 |   0.8803 |     29.333 |   1.1286 |     37.429 |     4.6
   31 |   0.8671 |     28.619 |   1.1297 |     37.177 |     4.7
   32 |   0.8535 |     28.454 |   1.1275 |     36.704 |     4.9
   33 |   0.8441 |     27.882 |   1.1299 |     36.957 |     5.0
   34 |   0.8383 |     27.910 |   1.1238 |     36.641 |     5.2
   35 |   0.8254 |     27.465 |   1.1420 |     37.335 |     5.3
   36 |   0.8078 |     26.563 |   1.1185 |     36.452 |     5.5
   37 |   0.7954 |     26.118 |   1.1236 |     35.980 |     5.6
   38 |   0.7894 |     26.267 |   1.1176 |     36.326 |     5.8
   39 |   0.7769 |     25.602 |   1.1304 |     36.200 |     5.9
   40 |   0.7713 |     25.541 |   1.1299 |     36.232 |     6.1
   41 |   0.7628 |     25.398 |   1.1245 |     36.326 |     6.2
   42 |   0.7463 |     24.761 |   1.1382 |     36.988 |     6.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 326,497

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8504 |     51.830 |   1.3921 |     45.274 |     0.1
    2 |   1.3775 |     45.626 |   1.2884 |     43.321 |     0.2
    3 |   1.3059 |     44.131 |   1.2388 |     41.745 |     0.3
    4 |   1.2494 |     43.109 |   1.2086 |     41.147 |     0.4
    5 |   1.2100 |     41.565 |   1.1694 |     39.193 |     0.5
    6 |   1.1733 |     40.312 |   1.2140 |     40.863 |     0.6
    7 |   1.1468 |     39.394 |   1.1339 |     37.902 |     0.7
    8 |   1.1223 |     39.010 |   1.1624 |     38.374 |     0.8
    9 |   1.0916 |     37.328 |   1.1299 |     38.752 |     0.9
   10 |   1.0769 |     37.163 |   1.1287 |     38.658 |     1.0
   11 |   1.0495 |     36.229 |   1.1066 |     36.673 |     1.1
   12 |   1.0270 |     35.345 |   1.1123 |     37.902 |     1.2
   13 |   1.0089 |     34.669 |   1.1121 |     36.704 |     1.3
   14 |   0.9863 |     33.993 |   1.1043 |     35.728 |     1.5
   15 |   0.9647 |     33.372 |   1.1078 |     35.507 |     1.6
   16 |   0.9428 |     32.454 |   1.1477 |     37.209 |     1.7
   17 |   0.9271 |     31.905 |   1.1165 |     35.917 |     1.8
   18 |   0.9027 |     30.817 |   1.0878 |     35.161 |     1.9
   19 |   0.8800 |     29.948 |   1.0762 |     34.499 |     2.0
   20 |   0.8713 |     29.838 |   1.1123 |     35.161 |     2.1
   21 |   0.8462 |     28.860 |   1.0945 |     33.680 |     2.2
   22 |   0.8262 |     28.135 |   1.0807 |     34.940 |     2.3
   23 |   0.8103 |     28.036 |   1.0880 |     34.625 |     2.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 881,185

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5425 |     47.972 |   1.2886 |     45.400 |     0.1
    2 |   1.2256 |     42.692 |   1.2422 |     43.573 |     0.2
    3 |   1.1526 |     40.400 |   1.1690 |     39.162 |     0.3
    4 |   1.0977 |     38.186 |   1.1393 |     39.319 |     0.4
    5 |   1.0577 |     36.834 |   1.0911 |     36.988 |     0.6
    6 |   1.0148 |     35.416 |   1.0794 |     37.209 |     0.7
    7 |   0.9613 |     33.427 |   1.0783 |     36.106 |     0.8
    8 |   0.9298 |     32.223 |   1.0643 |     35.728 |     0.9
    9 |   0.8644 |     30.069 |   1.0251 |     32.514 |     1.0
   10 |   0.8291 |     28.772 |   1.0534 |     33.428 |     1.1
   11 |   0.7842 |     27.058 |   1.0498 |     33.554 |     1.2
   12 |   0.7347 |     25.459 |   1.0470 |     33.743 |     1.3
   13 |   0.6874 |     23.525 |   1.0772 |     33.270 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 393,441

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6554 |     64.441 |   1.9595 |     45.463 |     0.2
    2 |   1.8646 |     46.851 |   1.6015 |     45.274 |     0.3
    3 |   1.6242 |     46.384 |   1.4954 |     44.991 |     0.5
    4 |   1.5230 |     46.098 |   1.4306 |     44.865 |     0.7
    5 |   1.4613 |     45.560 |   1.3843 |     43.982 |     0.8
    6 |   1.4147 |     44.879 |   1.3520 |     43.289 |     1.0
    7 |   1.3801 |     44.769 |   1.3241 |     42.628 |     1.2
    8 |   1.3489 |     44.065 |   1.3030 |     43.037 |     1.3
    9 |   1.3262 |     43.675 |   1.2880 |     42.565 |     1.5
   10 |   1.3026 |     42.796 |   1.2705 |     42.533 |     1.7
   11 |   1.2799 |     42.933 |   1.2688 |     43.163 |     1.8
   12 |   1.2598 |     41.983 |   1.2545 |     42.250 |     2.0
   13 |   1.2463 |     41.686 |   1.2377 |     41.651 |     2.1
   14 |   1.2305 |     41.378 |   1.2184 |     40.454 |     2.3
   15 |   1.2218 |     41.153 |   1.2068 |     40.328 |     2.5
   16 |   1.2069 |     40.554 |   1.2021 |     40.580 |     2.6
   17 |   1.1950 |     40.400 |   1.2071 |     40.454 |     2.8
   18 |   1.1880 |     40.296 |   1.1889 |     40.170 |     3.0
   19 |   1.1707 |     39.554 |   1.2116 |     40.989 |     3.1
   20 |   1.1623 |     39.422 |   1.1879 |     40.076 |     3.3
   21 |   1.1545 |     39.120 |   1.1890 |     40.076 |     3.5
   22 |   1.1416 |     38.565 |   1.1872 |     40.202 |     3.6
   23 |   1.1350 |     38.543 |   1.1624 |     38.815 |     3.8
   24 |   1.1261 |     38.356 |   1.1748 |     39.130 |     4.0
   25 |   1.1151 |     37.625 |   1.1696 |     39.036 |     4.1
   26 |   1.1105 |     37.707 |   1.1661 |     38.784 |     4.3
   27 |   1.1035 |     37.587 |   1.1651 |     38.910 |     4.5
   28 |   1.0931 |     37.169 |   1.1484 |     38.154 |     4.6
   29 |   1.0813 |     36.861 |   1.1633 |     38.910 |     4.8
   30 |   1.0767 |     36.367 |   1.1472 |     38.091 |     5.0
   31 |   1.0661 |     36.372 |   1.1438 |     37.839 |     5.1
   32 |   1.0621 |     36.191 |   1.1296 |     37.398 |     5.3
   33 |   1.0550 |     35.795 |   1.1473 |     38.122 |     5.5
   34 |   1.0485 |     35.630 |   1.1294 |     37.146 |     5.6
   35 |   1.0380 |     35.218 |   1.1376 |     37.429 |     5.8
   36 |   1.0336 |     35.152 |   1.1450 |     38.626 |     6.0
   37 |   1.0207 |     34.735 |   1.1139 |     36.862 |     6.1
   38 |   1.0207 |     34.597 |   1.1283 |     37.366 |     6.3
   39 |   1.0113 |     34.361 |   1.1240 |     36.894 |     6.5
   40 |   1.0027 |     33.828 |   1.1559 |     38.311 |     6.6
   41 |   0.9985 |     34.141 |   1.1149 |     36.988 |     6.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 226,017

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7169 |     49.027 |   1.3478 |     44.423 |     0.1
    2 |   1.3233 |     44.433 |   1.2475 |     41.619 |     0.2
    3 |   1.2456 |     42.928 |   1.2297 |     41.619 |     0.3
    4 |   1.1923 |     41.543 |   1.1507 |     39.288 |     0.3
    5 |   1.1547 |     40.048 |   1.1619 |     40.076 |     0.4
    6 |   1.1202 |     38.900 |   1.1168 |     37.744 |     0.5
    7 |   1.0933 |     38.235 |   1.1051 |     37.650 |     0.6
    8 |   1.0643 |     37.152 |   1.0956 |     37.744 |     0.7
    9 |   1.0304 |     35.614 |   1.0791 |     36.515 |     0.8
   10 |   1.0077 |     34.927 |   1.0663 |     35.885 |     0.9
   11 |   0.9784 |     33.877 |   1.0673 |     34.972 |     1.0
   12 |   0.9515 |     32.855 |   1.0680 |     35.318 |     1.0
   13 |   0.9292 |     32.168 |   1.0486 |     35.035 |     1.1
   14 |   0.9023 |     31.223 |   1.0307 |     34.184 |     1.2
   15 |   0.8813 |     30.476 |   1.0845 |     34.688 |     1.3
   16 |   0.8578 |     29.679 |   1.0382 |     33.869 |     1.4
   17 |   0.8351 |     28.860 |   1.0880 |     34.972 |     1.5
   18 |   0.8168 |     27.998 |   1.0539 |     34.089 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 847,265

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2222 |     57.083 |   1.5592 |     45.400 |     0.2
    2 |   1.5316 |     46.203 |   1.4061 |     46.345 |     0.3
    3 |   1.4185 |     45.813 |   1.3347 |     44.077 |     0.5
    4 |   1.3548 |     44.208 |   1.2885 |     43.667 |     0.7
    5 |   1.3059 |     43.197 |   1.2687 |     42.880 |     0.9
    6 |   1.2734 |     42.521 |   1.2515 |     42.596 |     1.0
    7 |   1.2359 |     41.103 |   1.2231 |     41.273 |     1.2
    8 |   1.2091 |     40.504 |   1.2067 |     40.422 |     1.4
    9 |   1.1888 |     39.900 |   1.1949 |     39.729 |     1.6
   10 |   1.1695 |     39.449 |   1.2018 |     40.328 |     1.8
   11 |   1.1457 |     38.361 |   1.1863 |     39.540 |     1.9
   12 |   1.1295 |     38.098 |   1.1654 |     38.784 |     2.1
   13 |   1.1132 |     37.729 |   1.1697 |     39.477 |     2.3
   14 |   1.0936 |     37.125 |   1.1804 |     39.067 |     2.5
   15 |   1.0767 |     36.218 |   1.1846 |     39.635 |     2.6
   16 |   1.0655 |     36.180 |   1.1849 |     39.729 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,047,457

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6119 |     49.330 |   1.3478 |     44.896 |     0.2
    2 |   1.3231 |     45.214 |   1.2676 |     43.037 |     0.4
    3 |   1.2583 |     43.483 |   1.2240 |     42.281 |     0.6
    4 |   1.2135 |     42.532 |   1.1938 |     41.273 |     0.8
    5 |   1.1809 |     41.147 |   1.1867 |     40.076 |     1.0
    6 |   1.1596 |     40.818 |   1.1706 |     40.863 |     1.2
    7 |   1.1315 |     39.955 |   1.1356 |     39.004 |     1.3
    8 |   1.1194 |     39.763 |   1.1353 |     39.792 |     1.5
    9 |   1.0972 |     38.878 |   1.1382 |     39.256 |     1.7
   10 |   1.0837 |     38.471 |   1.1146 |     38.374 |     1.9
   11 |   1.0679 |     37.724 |   1.1280 |     40.454 |     2.1
   12 |   1.0605 |     37.548 |   1.0950 |     38.343 |     2.3
   13 |   1.0466 |     36.949 |   1.0966 |     37.933 |     2.5
   14 |   1.0410 |     37.015 |   1.1111 |     39.067 |     2.7
   15 |   1.0231 |     36.361 |   1.0917 |     38.406 |     2.9
   16 |   1.0079 |     35.757 |   1.0918 |     37.429 |     3.1
   17 |   0.9983 |     35.421 |   1.0594 |     36.137 |     3.3
   18 |   0.9821 |     34.773 |   1.0671 |     36.578 |     3.5
   19 |   0.9737 |     34.432 |   1.0521 |     36.736 |     3.7
   20 |   0.9668 |     34.702 |   1.0574 |     37.272 |     3.9
   21 |   0.9500 |     33.773 |   1.0721 |     36.200 |     4.1
   22 |   0.9398 |     33.421 |   1.0630 |     36.767 |     4.2
   23 |   0.9234 |     32.542 |   1.0423 |     35.224 |     4.4
   24 |   0.9200 |     32.646 |   1.0702 |     36.106 |     4.6
   25 |   0.9127 |     32.306 |   1.0463 |     35.192 |     4.8
   26 |   0.8945 |     31.668 |   1.0852 |     35.885 |     5.0
   27 |   0.8849 |     31.174 |   1.0499 |     36.295 |     5.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,047,457

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2593 |     56.122 |   1.5885 |     46.471 |     0.1
    2 |   1.5625 |     46.120 |   1.4113 |     44.991 |     0.3
    3 |   1.4393 |     45.368 |   1.3510 |     44.423 |     0.5
    4 |   1.3766 |     44.582 |   1.3157 |     43.132 |     0.6
    5 |   1.3373 |     43.878 |   1.2997 |     43.447 |     0.8
    6 |   1.3019 |     43.263 |   1.2556 |     42.155 |     0.9
    7 |   1.2678 |     42.219 |   1.2387 |     41.147 |     1.1
    8 |   1.2393 |     41.944 |   1.2260 |     40.769 |     1.2
    9 |   1.2213 |     41.400 |   1.2003 |     39.729 |     1.4
   10 |   1.1992 |     40.834 |   1.2400 |     42.596 |     1.5
   11 |   1.1754 |     40.142 |   1.1795 |     39.319 |     1.7
   12 |   1.1594 |     39.658 |   1.1797 |     39.225 |     1.8
   13 |   1.1460 |     39.460 |   1.1746 |     38.689 |     2.0
   14 |   1.1274 |     38.378 |   1.1752 |     39.099 |     2.1
   15 |   1.1130 |     38.372 |   1.1788 |     38.910 |     2.3
   16 |   1.0960 |     37.510 |   1.1486 |     38.217 |     2.4
   17 |   1.0841 |     36.988 |   1.1471 |     37.744 |     2.6
   18 |   1.0716 |     36.839 |   1.1503 |     37.996 |     2.7
   19 |   1.0522 |     35.916 |   1.1551 |     38.280 |     2.9
   20 |   1.0373 |     35.328 |   1.1448 |     37.744 |     3.1
   21 |   1.0279 |     35.174 |   1.1303 |     37.524 |     3.2
   22 |   1.0180 |     34.432 |   1.1171 |     36.799 |     3.4
   23 |   0.9980 |     34.174 |   1.1328 |     37.272 |     3.5
   24 |   0.9872 |     33.625 |   1.1352 |     37.177 |     3.7
   25 |   0.9761 |     33.190 |   1.1278 |     36.578 |     3.8
   26 |   0.9658 |     32.701 |   1.1060 |     36.169 |     4.0
   27 |   0.9516 |     32.251 |   1.1010 |     35.759 |     4.1
   28 |   0.9413 |     31.894 |   1.1181 |     35.350 |     4.3
   29 |   0.9263 |     31.525 |   1.1107 |     35.759 |     4.4
   30 |   0.9176 |     30.981 |   1.1029 |     35.728 |     4.6
   31 |   0.8983 |     30.245 |   1.0921 |     35.066 |     4.7
   32 |   0.8953 |     30.525 |   1.1144 |     35.413 |     4.9
   33 |   0.8820 |     30.009 |   1.1254 |     35.318 |     5.0
   34 |   0.8697 |     29.509 |   1.1136 |     35.255 |     5.2
   35 |   0.8575 |     28.761 |   1.0772 |     34.184 |     5.4
   36 |   0.8490 |     28.520 |   1.0927 |     34.940 |     5.5
   37 |   0.8305 |     28.234 |   1.1023 |     34.436 |     5.7
   38 |   0.8286 |     27.926 |   1.1348 |     35.255 |     5.8
   39 |   0.8151 |     27.514 |   1.0856 |     33.837 |     6.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 978,465

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4832 |     46.818 |   1.2619 |     42.785 |     0.1
    2 |   1.2205 |     42.554 |   1.1985 |     41.115 |     0.2
    3 |   1.1388 |     39.856 |   1.1676 |     40.265 |     0.3
    4 |   1.0862 |     38.081 |   1.1081 |     37.965 |     0.4
    5 |   1.0363 |     36.191 |   1.1137 |     38.878 |     0.4
    6 |   0.9933 |     34.795 |   1.0820 |     36.547 |     0.5
    7 |   0.9505 |     33.092 |   1.0722 |     36.295 |     0.6
    8 |   0.9171 |     31.910 |   1.0632 |     36.200 |     0.7
    9 |   0.8804 |     30.795 |   1.0410 |     34.121 |     0.8
   10 |   0.8440 |     29.163 |   1.0450 |     35.003 |     0.9
   11 |   0.7987 |     27.662 |   1.0612 |     35.192 |     1.0
   12 |   0.7645 |     26.662 |   1.0282 |     33.837 |     1.1
   13 |   0.7296 |     25.398 |   1.0403 |     33.491 |     1.2
   14 |   0.7061 |     24.503 |   1.0883 |     35.444 |     1.2
   15 |   0.6667 |     23.035 |   1.0686 |     33.963 |     1.3
   16 |   0.6214 |     21.799 |   1.0858 |     34.342 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 813,985

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5262 |     47.340 |   1.2843 |     43.163 |     0.1
    2 |   1.2343 |     42.576 |   1.1968 |     40.800 |     0.2
    3 |   1.1495 |     39.949 |   1.1694 |     39.067 |     0.3
    4 |   1.0939 |     38.279 |   1.1231 |     38.059 |     0.3
    5 |   1.0495 |     36.702 |   1.1242 |     38.059 |     0.4
    6 |   1.0019 |     34.768 |   1.0883 |     36.610 |     0.5
    7 |   0.9671 |     33.306 |   1.0887 |     35.885 |     0.6
    8 |   0.9334 |     32.498 |   1.0721 |     35.476 |     0.7
    9 |   0.8898 |     31.036 |   1.0472 |     35.948 |     0.8
   10 |   0.8457 |     29.278 |   1.0591 |     34.279 |     0.9
   11 |   0.8030 |     27.734 |   1.0744 |     35.507 |     0.9
   12 |   0.7508 |     26.234 |   1.0513 |     33.900 |     1.0
   13 |   0.7106 |     24.651 |   1.0690 |     33.806 |     1.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 731,745

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5034 |     63.040 |   1.6807 |     47.858 |     0.1
    2 |   1.6831 |     47.461 |   1.4444 |     45.337 |     0.2
    3 |   1.5032 |     46.505 |   1.3833 |     44.928 |     0.3
    4 |   1.4326 |     46.126 |   1.3463 |     44.581 |     0.4
    5 |   1.3905 |     45.648 |   1.3210 |     43.226 |     0.4
    6 |   1.3596 |     44.840 |   1.2992 |     43.352 |     0.5
    7 |   1.3306 |     44.027 |   1.2734 |     41.714 |     0.6
    8 |   1.3086 |     43.659 |   1.2682 |     41.903 |     0.7
    9 |   1.2822 |     42.549 |   1.2564 |     41.997 |     0.8
   10 |   1.2614 |     42.142 |   1.2657 |     41.241 |     0.9
   11 |   1.2488 |     41.988 |   1.2477 |     41.210 |     1.0
   12 |   1.2300 |     41.334 |   1.2318 |     41.399 |     1.1
   13 |   1.2212 |     41.257 |   1.2196 |     40.328 |     1.2
   14 |   1.2087 |     40.878 |   1.2055 |     40.170 |     1.3
   15 |   1.1945 |     40.444 |   1.1990 |     39.509 |     1.3
   16 |   1.1875 |     40.323 |   1.1965 |     39.635 |     1.4
   17 |   1.1747 |     39.840 |   1.2108 |     40.265 |     1.5
   18 |   1.1654 |     39.741 |   1.1792 |     39.225 |     1.6
   19 |   1.1534 |     39.125 |   1.1935 |     39.477 |     1.7
   20 |   1.1441 |     38.861 |   1.1609 |     38.878 |     1.8
   21 |   1.1304 |     38.290 |   1.1652 |     38.437 |     1.9
   22 |   1.1219 |     38.372 |   1.1739 |     38.374 |     2.0
   23 |   1.1127 |     37.779 |   1.1845 |     38.910 |     2.1
   24 |   1.1073 |     37.960 |   1.1769 |     38.532 |     2.2
Early stopping

