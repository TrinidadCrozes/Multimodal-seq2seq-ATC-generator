Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,442,594

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3606 |     58.592 |   1.5850 |     45.756 |     0.2
    2 |   1.5933 |     46.203 |   1.4156 |     45.756 |     0.3
    3 |   1.4565 |     45.701 |   1.3702 |     45.880 |     0.5
    4 |   1.3966 |     45.001 |   1.3232 |     43.804 |     0.6
    5 |   1.3557 |     44.152 |   1.3096 |     44.331 |     0.8
    6 |   1.3189 |     43.441 |   1.2721 |     43.773 |     1.0
    7 |   1.2965 |     43.050 |   1.2809 |     43.649 |     1.1
    8 |   1.2716 |     42.317 |   1.2290 |     42.286 |     1.3
    9 |   1.2513 |     41.705 |   1.2508 |     43.216 |     1.4
   10 |   1.2311 |     41.358 |   1.2254 |     41.976 |     1.6
   11 |   1.2094 |     40.752 |   1.1937 |     41.574 |     1.7
   12 |   1.2013 |     40.261 |   1.2191 |     42.658 |     1.9
   13 |   1.1850 |     40.035 |   1.2009 |     41.945 |     2.1
   14 |   1.1678 |     39.280 |   1.1894 |     41.140 |     2.2
   15 |   1.1573 |     39.153 |   1.1608 |     40.118 |     2.4
   16 |   1.1456 |     38.685 |   1.1694 |     40.397 |     2.5
   17 |   1.1336 |     38.459 |   1.1994 |     41.078 |     2.7
   18 |   1.1289 |     38.492 |   1.1604 |     39.560 |     2.8
   19 |   1.1138 |     37.632 |   1.1876 |     40.582 |     3.0
   20 |   1.0999 |     37.379 |   1.1650 |     39.777 |     3.2
   21 |   1.0916 |     36.932 |   1.1575 |     39.529 |     3.3
   22 |   1.0790 |     36.723 |   1.1603 |     40.458 |     3.5
   23 |   1.0713 |     36.569 |   1.1657 |     39.529 |     3.6
   24 |   1.0595 |     35.720 |   1.1703 |     39.560 |     3.8
   25 |   1.0459 |     35.516 |   1.1664 |     40.335 |     3.9
   26 |   1.0337 |     34.744 |   1.1449 |     38.910 |     4.1
   27 |   1.0271 |     34.843 |   1.1875 |     40.335 |     4.3
   28 |   1.0139 |     34.347 |   1.1537 |     38.476 |     4.4
   29 |   1.0078 |     34.210 |   1.1171 |     37.887 |     4.6
   30 |   0.9943 |     33.714 |   1.1857 |     39.126 |     4.8
   31 |   0.9877 |     33.262 |   1.1402 |     38.321 |     4.9
   32 |   0.9741 |     32.793 |   1.1694 |     38.352 |     5.1
   33 |   0.9652 |     32.782 |   1.1222 |     36.989 |     5.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 293,154

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7240 |     49.223 |   1.3518 |     45.942 |     0.1
    2 |   1.3251 |     44.770 |   1.2741 |     43.773 |     0.2
    3 |   1.2646 |     44.229 |   1.2127 |     42.596 |     0.3
    4 |   1.2257 |     43.265 |   1.1910 |     43.154 |     0.4
    5 |   1.2003 |     42.642 |   1.1716 |     41.760 |     0.5
    6 |   1.1756 |     41.788 |   1.1467 |     40.799 |     0.6
    7 |   1.1622 |     41.297 |   1.1357 |     40.025 |     0.7
    8 |   1.1460 |     40.349 |   1.1275 |     41.357 |     0.8
    9 |   1.1348 |     40.763 |   1.1137 |     39.684 |     0.9
   10 |   1.1198 |     39.495 |   1.0983 |     39.312 |     1.0
   11 |   1.1068 |     38.674 |   1.0837 |     38.941 |     1.1
   12 |   1.0887 |     38.740 |   1.0865 |     38.848 |     1.2
   13 |   1.0757 |     38.057 |   1.0750 |     39.436 |     1.3
   14 |   1.0619 |     37.781 |   1.0667 |     38.073 |     1.4
   15 |   1.0528 |     37.048 |   1.0657 |     38.786 |     1.5
   16 |   1.0379 |     37.054 |   1.0511 |     37.454 |     1.6
   17 |   1.0267 |     36.183 |   1.0485 |     36.865 |     1.7
   18 |   1.0164 |     36.034 |   1.0338 |     36.307 |     1.8
   19 |   1.0197 |     36.150 |   1.0462 |     37.361 |     1.9
   20 |   1.0053 |     35.257 |   1.0273 |     36.648 |     2.0
   21 |   0.9907 |     34.816 |   1.0198 |     36.245 |     2.2
   22 |   0.9831 |     34.717 |   1.0292 |     37.051 |     2.3
   23 |   0.9800 |     34.458 |   1.0118 |     36.183 |     2.4
   24 |   0.9667 |     34.386 |   0.9958 |     35.285 |     2.5
   25 |   0.9515 |     33.857 |   1.0171 |     36.338 |     2.6
   26 |   0.9481 |     33.471 |   1.0142 |     35.843 |     2.7
   27 |   0.9419 |     33.129 |   1.0130 |     36.369 |     2.8
   28 |   0.9298 |     32.964 |   0.9914 |     33.643 |     2.9
   29 |   0.9173 |     32.358 |   0.9791 |     34.170 |     3.0
   30 |   0.9158 |     32.540 |   0.9710 |     34.387 |     3.1
   31 |   0.9046 |     31.889 |   0.9875 |     34.356 |     3.2
   32 |   0.8933 |     31.487 |   0.9945 |     34.820 |     3.3
   33 |   0.8770 |     30.842 |   0.9720 |     33.333 |     3.4
   34 |   0.8818 |     30.759 |   0.9804 |     33.767 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 847,650

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5081 |     46.869 |   1.2765 |     44.981 |     0.2
    2 |   1.2290 |     43.535 |   1.2113 |     43.061 |     0.3
    3 |   1.1756 |     41.749 |   1.1531 |     40.892 |     0.5
    4 |   1.1328 |     40.410 |   1.1130 |     39.746 |     0.6
    5 |   1.0941 |     39.440 |   1.1024 |     39.064 |     0.8
    6 |   1.0776 |     38.850 |   1.1135 |     40.180 |     1.0
    7 |   1.0521 |     38.068 |   1.0730 |     39.188 |     1.1
    8 |   1.0357 |     37.533 |   1.0917 |     39.994 |     1.3
    9 |   1.0335 |     37.329 |   1.0690 |     39.343 |     1.4
   10 |   1.0076 |     36.524 |   1.0546 |     38.104 |     1.6
   11 |   0.9966 |     36.453 |   1.0278 |     36.586 |     1.8
   12 |   0.9827 |     35.588 |   1.0388 |     37.361 |     1.9
   13 |   0.9770 |     35.643 |   1.0311 |     37.670 |     2.1
   14 |   0.9599 |     34.910 |   1.0389 |     36.989 |     2.2
   15 |   0.9610 |     34.970 |   1.0274 |     36.896 |     2.4
   16 |   0.9397 |     34.204 |   1.0237 |     36.152 |     2.6
   17 |   0.9299 |     34.121 |   1.0227 |     36.214 |     2.7
   18 |   0.9278 |     33.526 |   1.0159 |     35.750 |     2.9
   19 |   0.9200 |     33.218 |   1.0226 |     36.462 |     3.0
   20 |   0.9018 |     32.490 |   1.0207 |     35.967 |     3.2
   21 |   0.9031 |     32.463 |   1.0122 |     35.688 |     3.4
   22 |   0.8883 |     31.834 |   1.0067 |     35.254 |     3.5
   23 |   0.8815 |     31.520 |   0.9881 |     34.418 |     3.7
   24 |   0.8716 |     31.333 |   1.0145 |     35.068 |     3.8
   25 |   0.8674 |     31.454 |   0.9979 |     35.130 |     4.0
   26 |   0.8585 |     30.693 |   0.9987 |     34.542 |     4.2
   27 |   0.8439 |     30.423 |   1.0282 |     35.564 |     4.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7912 |     50.149 |   1.3596 |     45.973 |     0.1
    2 |   1.3494 |     45.188 |   1.2656 |     43.216 |     0.2
    3 |   1.2843 |     43.634 |   1.2206 |     42.627 |     0.3
    4 |   1.2384 |     42.323 |   1.1910 |     41.450 |     0.3
    5 |   1.2041 |     41.612 |   1.1949 |     41.047 |     0.4
    6 |   1.1747 |     40.779 |   1.1379 |     40.799 |     0.5
    7 |   1.1498 |     39.842 |   1.1362 |     40.428 |     0.6
    8 |   1.1274 |     38.861 |   1.1397 |     40.551 |     0.7
    9 |   1.1041 |     38.360 |   1.0906 |     38.507 |     0.8
   10 |   1.0807 |     36.883 |   1.0958 |     38.538 |     0.9
   11 |   1.0609 |     36.596 |   1.0767 |     37.577 |     0.9
   12 |   1.0447 |     36.205 |   1.0753 |     37.856 |     1.0
   13 |   1.0275 |     35.560 |   1.0558 |     36.865 |     1.1
   14 |   1.0120 |     34.728 |   1.0710 |     37.051 |     1.2
   15 |   0.9890 |     34.248 |   1.0843 |     36.834 |     1.3
   16 |   0.9788 |     33.785 |   1.0426 |     35.967 |     1.4
   17 |   0.9548 |     32.970 |   1.0520 |     35.781 |     1.5
   18 |   0.9429 |     32.496 |   1.0524 |     35.843 |     1.5
   19 |   0.9260 |     31.757 |   1.0404 |     35.099 |     1.6
   20 |   0.9131 |     31.200 |   1.0139 |     34.758 |     1.7
   21 |   0.8961 |     31.129 |   1.0395 |     35.595 |     1.8
   22 |   0.8855 |     30.434 |   1.0415 |     34.665 |     1.9
   23 |   0.8708 |     30.164 |   1.0077 |     34.139 |     2.0
   24 |   0.8480 |     29.382 |   1.0567 |     35.316 |     2.1
   25 |   0.8376 |     28.731 |   1.0728 |     35.967 |     2.1
   26 |   0.8206 |     28.323 |   1.0538 |     34.418 |     2.2
   27 |   0.8125 |     27.982 |   1.0279 |     34.170 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,013,538

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5102 |     47.509 |   1.2911 |     45.508 |     0.2
    2 |   1.2472 |     44.191 |   1.1979 |     42.441 |     0.3
    3 |   1.1894 |     42.466 |   1.1826 |     41.698 |     0.5
    4 |   1.1529 |     41.628 |   1.1611 |     40.644 |     0.7
    5 |   1.1284 |     40.829 |   1.1387 |     40.706 |     0.8
    6 |   1.1031 |     40.008 |   1.1287 |     40.768 |     1.0
    7 |   1.0889 |     39.749 |   1.0913 |     39.374 |     1.2
    8 |   1.0672 |     38.635 |   1.1068 |     40.551 |     1.3
    9 |   1.0511 |     37.979 |   1.0644 |     38.755 |     1.5
   10 |   1.0342 |     37.340 |   1.0673 |     37.856 |     1.7
   11 |   1.0173 |     36.949 |   1.0618 |     37.175 |     1.8
   12 |   1.0091 |     36.668 |   1.0472 |     37.608 |     2.0
   13 |   0.9963 |     36.117 |   1.0555 |     38.135 |     2.2
   14 |   0.9995 |     36.436 |   1.0211 |     36.462 |     2.3
   15 |   0.9784 |     35.698 |   1.0253 |     36.617 |     2.5
   16 |   0.9696 |     35.295 |   1.0269 |     36.803 |     2.7
   17 |   0.9588 |     34.673 |   1.0075 |     35.471 |     2.9
   18 |   0.9472 |     34.656 |   1.0120 |     36.183 |     3.0
   19 |   0.9449 |     34.673 |   1.0164 |     36.369 |     3.2
   20 |   0.9406 |     34.292 |   1.0253 |     36.772 |     3.4
   21 |   0.9370 |     33.989 |   1.0062 |     35.626 |     3.5
   22 |   0.9307 |     33.686 |   1.0005 |     35.564 |     3.7
   23 |   0.9303 |     34.149 |   0.9984 |     34.851 |     3.9
   24 |   0.9093 |     33.311 |   0.9956 |     34.913 |     4.0
   25 |   0.9030 |     33.124 |   0.9948 |     35.440 |     4.2
   26 |   0.8944 |     32.705 |   0.9959 |     34.727 |     4.4
   27 |   0.8973 |     32.810 |   1.0055 |     35.936 |     4.5
   28 |   0.8963 |     32.711 |   1.0066 |     35.223 |     4.7
   29 |   0.8948 |     32.501 |   0.9966 |     35.068 |     4.9
   30 |   0.8720 |     31.785 |   0.9862 |     33.705 |     5.0
   31 |   0.8635 |     31.382 |   0.9940 |     34.758 |     5.2
   32 |   0.8619 |     31.316 |   0.9772 |     34.727 |     5.4
   33 |   0.8539 |     31.206 |   0.9655 |     33.209 |     5.5
   34 |   0.8422 |     30.556 |   0.9846 |     34.263 |     5.7
   35 |   0.8352 |     30.644 |   0.9663 |     33.519 |     5.9
   36 |   0.8333 |     30.616 |   0.9812 |     34.170 |     6.0
   37 |   0.8332 |     30.462 |   0.9599 |     33.055 |     6.2
   38 |   0.8363 |     30.434 |   0.9678 |     33.302 |     6.4
   39 |   0.8214 |     29.933 |   0.9766 |     34.139 |     6.6
   40 |   0.8204 |     30.021 |   0.9801 |     34.201 |     6.7
   41 |   0.8066 |     29.668 |   0.9606 |     33.240 |     6.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,179,426

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6425 |     67.912 |   1.7914 |     48.978 |     0.1
    2 |   1.7342 |     47.046 |   1.4699 |     45.663 |     0.3
    3 |   1.5137 |     45.806 |   1.4126 |     45.322 |     0.5
    4 |   1.4464 |     45.828 |   1.3693 |     44.888 |     0.6
    5 |   1.4027 |     45.216 |   1.3493 |     44.734 |     0.8
    6 |   1.3736 |     44.726 |   1.3391 |     45.136 |     0.9
    7 |   1.3394 |     43.596 |   1.3173 |     44.114 |     1.1
    8 |   1.3247 |     43.447 |   1.2901 |     43.185 |     1.2
    9 |   1.3002 |     42.802 |   1.3103 |     43.835 |     1.4
   10 |   1.2773 |     42.212 |   1.2882 |     43.061 |     1.5
   11 |   1.2620 |     41.590 |   1.2969 |     43.278 |     1.7
   12 |   1.2482 |     41.700 |   1.2970 |     43.340 |     1.8
   13 |   1.2316 |     40.989 |   1.2728 |     42.348 |     2.0
   14 |   1.2177 |     40.388 |   1.2593 |     41.512 |     2.1
   15 |   1.2043 |     40.278 |   1.2648 |     42.317 |     2.3
   16 |   1.1897 |     40.035 |   1.2388 |     41.605 |     2.4
   17 |   1.1811 |     39.512 |   1.2492 |     41.884 |     2.6
   18 |   1.1672 |     39.192 |   1.2272 |     40.861 |     2.7
   19 |   1.1540 |     38.707 |   1.2410 |     41.667 |     2.9
   20 |   1.1405 |     37.924 |   1.2473 |     40.087 |     3.0
   21 |   1.1292 |     37.676 |   1.2320 |     41.140 |     3.2
   22 |   1.1129 |     37.709 |   1.2289 |     40.428 |     3.3
   23 |   1.1089 |     37.329 |   1.2184 |     39.870 |     3.5
   24 |   1.0985 |     36.839 |   1.2087 |     39.560 |     3.7
   25 |   1.0897 |     36.453 |   1.2653 |     40.675 |     3.8
   26 |   1.0760 |     36.122 |   1.2182 |     39.622 |     4.0
   27 |   1.0682 |     36.017 |   1.2274 |     39.436 |     4.1
   28 |   1.0577 |     35.588 |   1.2233 |     39.467 |     4.3
   29 |   1.0497 |     35.538 |   1.1578 |     38.011 |     4.4
   30 |   1.0391 |     34.882 |   1.1926 |     38.445 |     4.6
   31 |   1.0253 |     34.353 |   1.2349 |     39.374 |     4.7
   32 |   1.0232 |     34.358 |   1.2044 |     38.786 |     4.9
   33 |   1.0115 |     34.099 |   1.2157 |     39.064 |     5.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,045,026

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3333 |     58.162 |   1.6059 |     46.406 |     0.1
    2 |   1.5817 |     46.087 |   1.4180 |     46.252 |     0.3
    3 |   1.4492 |     45.414 |   1.3687 |     45.508 |     0.4
    4 |   1.3931 |     44.963 |   1.3276 |     44.331 |     0.6
    5 |   1.3511 |     44.334 |   1.3032 |     43.928 |     0.7
    6 |   1.3262 |     43.590 |   1.2894 |     43.990 |     0.8
    7 |   1.3012 |     42.747 |   1.2698 |     43.309 |     1.0
    8 |   1.2817 |     42.482 |   1.2530 |     43.061 |     1.1
    9 |   1.2651 |     41.953 |   1.2477 |     42.658 |     1.3
   10 |   1.2478 |     41.656 |   1.2414 |     42.565 |     1.4
   11 |   1.2303 |     41.005 |   1.2179 |     42.410 |     1.6
   12 |   1.2151 |     40.388 |   1.2138 |     41.853 |     1.7
   13 |   1.1971 |     40.179 |   1.2043 |     41.760 |     1.8
   14 |   1.1806 |     39.765 |   1.1952 |     41.543 |     2.0
   15 |   1.1659 |     39.236 |   1.1765 |     40.366 |     2.1
   16 |   1.1495 |     38.823 |   1.1943 |     40.923 |     2.3
   17 |   1.1373 |     38.194 |   1.1624 |     40.737 |     2.4
   18 |   1.1291 |     38.250 |   1.1544 |     40.242 |     2.6
   19 |   1.1184 |     37.946 |   1.1528 |     40.025 |     2.7
   20 |   1.1014 |     37.136 |   1.1373 |     39.405 |     2.9
   21 |   1.0893 |     36.822 |   1.1537 |     39.715 |     3.0
   22 |   1.0809 |     36.392 |   1.1514 |     39.901 |     3.1
   23 |   1.0671 |     35.946 |   1.1604 |     39.932 |     3.3
   24 |   1.0556 |     35.725 |   1.1351 |     38.941 |     3.4
   25 |   1.0428 |     35.235 |   1.1270 |     38.383 |     3.6
   26 |   1.0403 |     35.036 |   1.1292 |     38.600 |     3.7
   27 |   1.0247 |     34.860 |   1.1751 |     39.870 |     3.8
   28 |   1.0175 |     34.386 |   1.1277 |     38.197 |     4.0
   29 |   1.0039 |     33.763 |   1.1543 |     39.095 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 327,586

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9605 |     73.369 |   2.4143 |     61.431 |     0.2
    2 |   2.3300 |     54.525 |   1.8721 |     49.040 |     0.3
    3 |   1.9077 |     47.724 |   1.6448 |     46.685 |     0.5
    4 |   1.6925 |     46.462 |   1.5337 |     46.406 |     0.6
    5 |   1.5906 |     46.092 |   1.4806 |     46.654 |     0.8
    6 |   1.5263 |     46.125 |   1.4381 |     46.035 |     1.0
    7 |   1.4842 |     45.899 |   1.4130 |     45.663 |     1.1
    8 |   1.4483 |     45.674 |   1.3877 |     46.066 |     1.3
    9 |   1.4232 |     45.585 |   1.3676 |     45.880 |     1.5
   10 |   1.3967 |     44.731 |   1.3596 |     44.919 |     1.6
   11 |   1.3800 |     44.665 |   1.3381 |     44.765 |     1.8
   12 |   1.3618 |     44.538 |   1.3171 |     44.734 |     1.9
   13 |   1.3443 |     44.136 |   1.3087 |     44.021 |     2.1
   14 |   1.3330 |     43.541 |   1.3033 |     44.176 |     2.3
   15 |   1.3193 |     43.392 |   1.2945 |     43.742 |     2.4
   16 |   1.3098 |     43.122 |   1.2850 |     43.866 |     2.6
   17 |   1.3006 |     43.232 |   1.2773 |     43.990 |     2.7
   18 |   1.2863 |     42.945 |   1.2684 |     43.309 |     2.9
   19 |   1.2764 |     42.598 |   1.2663 |     43.990 |     3.1
   20 |   1.2716 |     42.444 |   1.2587 |     43.804 |     3.2
   21 |   1.2608 |     42.207 |   1.2599 |     43.463 |     3.4
   22 |   1.2551 |     41.992 |   1.2570 |     43.525 |     3.6
   23 |   1.2466 |     41.893 |   1.2577 |     43.340 |     3.7
   24 |   1.2394 |     41.656 |   1.2599 |     42.968 |     3.9
   25 |   1.2311 |     41.551 |   1.2435 |     42.937 |     4.0
   26 |   1.2234 |     41.071 |   1.2516 |     42.472 |     4.2
   27 |   1.2172 |     40.928 |   1.2554 |     42.503 |     4.4
   28 |   1.2102 |     40.752 |   1.2489 |     42.348 |     4.5
   29 |   1.2053 |     40.410 |   1.2484 |     42.348 |     4.7
   30 |   1.2032 |     40.625 |   1.2431 |     42.131 |     4.9
   31 |   1.1952 |     40.322 |   1.2295 |     42.007 |     5.0
   32 |   1.1902 |     40.002 |   1.2390 |     42.255 |     5.2
   33 |   1.1870 |     40.008 |   1.2488 |     42.348 |     5.3
   34 |   1.1767 |     39.721 |   1.2334 |     41.636 |     5.5
   35 |   1.1729 |     39.517 |   1.2236 |     41.884 |     5.7
   36 |   1.1633 |     39.297 |   1.2374 |     41.791 |     5.8
   37 |   1.1620 |     39.258 |   1.2220 |     41.109 |     6.0
   38 |   1.1577 |     39.071 |   1.2359 |     41.481 |     6.2
   39 |   1.1519 |     38.872 |   1.2231 |     41.419 |     6.3
   40 |   1.1477 |     38.905 |   1.2116 |     41.419 |     6.5
   41 |   1.1438 |     39.065 |   1.2010 |     40.923 |     6.6
   42 |   1.1383 |     38.420 |   1.2180 |     41.016 |     6.8
   43 |   1.1264 |     38.283 |   1.2025 |     40.954 |     7.0
   44 |   1.1267 |     38.420 |   1.2102 |     41.264 |     7.1
   45 |   1.1227 |     38.200 |   1.1902 |     40.520 |     7.3
   46 |   1.1144 |     37.952 |   1.2098 |     40.830 |     7.4
   47 |   1.1185 |     38.112 |   1.1950 |     40.520 |     7.6
   48 |   1.1104 |     38.117 |   1.2030 |     40.892 |     7.8
   49 |   1.1061 |     37.533 |   1.1989 |     40.644 |     7.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 276,450

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8482 |     69.533 |   2.1900 |     56.351 |     0.1
    2 |   2.1162 |     50.920 |   1.7415 |     46.344 |     0.2
    3 |   1.7730 |     46.632 |   1.5719 |     45.973 |     0.3
    4 |   1.6157 |     45.982 |   1.4868 |     45.694 |     0.4
    5 |   1.5358 |     45.894 |   1.4381 |     45.601 |     0.5
    6 |   1.4821 |     45.519 |   1.4036 |     45.477 |     0.6
    7 |   1.4457 |     45.883 |   1.3757 |     45.322 |     0.7
    8 |   1.4198 |     45.525 |   1.3573 |     45.167 |     0.7
    9 |   1.3940 |     45.194 |   1.3341 |     44.207 |     0.8
   10 |   1.3751 |     44.885 |   1.3164 |     43.092 |     0.9
   11 |   1.3564 |     44.819 |   1.3071 |     43.061 |     1.0
   12 |   1.3374 |     44.031 |   1.2913 |     42.968 |     1.1
   13 |   1.3198 |     43.579 |   1.2845 |     43.401 |     1.2
   14 |   1.3095 |     43.337 |   1.2747 |     42.906 |     1.3
   15 |   1.2959 |     43.348 |   1.2599 |     42.999 |     1.4
   16 |   1.2876 |     42.785 |   1.2575 |     42.379 |     1.5
   17 |   1.2767 |     42.604 |   1.2433 |     42.193 |     1.6
   18 |   1.2630 |     42.686 |   1.2394 |     42.069 |     1.7
   19 |   1.2585 |     41.997 |   1.2322 |     42.255 |     1.8
   20 |   1.2483 |     41.893 |   1.2255 |     42.348 |     1.9
   21 |   1.2362 |     41.882 |   1.2240 |     42.503 |     2.0
   22 |   1.2282 |     41.601 |   1.2110 |     42.224 |     2.1
   23 |   1.2218 |     41.435 |   1.2093 |     41.945 |     2.2
   24 |   1.2151 |     41.027 |   1.1995 |     41.574 |     2.3
   25 |   1.2084 |     41.077 |   1.2061 |     42.007 |     2.3
   26 |   1.2012 |     40.746 |   1.1959 |     41.357 |     2.4
   27 |   1.1949 |     40.454 |   1.1925 |     41.481 |     2.5
   28 |   1.1895 |     40.173 |   1.1944 |     41.481 |     2.6
   29 |   1.1808 |     39.892 |   1.1946 |     41.450 |     2.7
   30 |   1.1745 |     39.831 |   1.1830 |     40.582 |     2.8
   31 |   1.1702 |     39.914 |   1.1852 |     40.830 |     2.9
   32 |   1.1665 |     39.589 |   1.1798 |     40.830 |     3.0
   33 |   1.1606 |     39.302 |   1.1699 |     40.768 |     3.1
   34 |   1.1560 |     39.501 |   1.1798 |     41.357 |     3.2
   35 |   1.1503 |     39.043 |   1.1826 |     40.954 |     3.3
   36 |   1.1470 |     38.707 |   1.1835 |     40.985 |     3.4
   37 |   1.1412 |     38.641 |   1.1773 |     40.985 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 814,370

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4051 |     59.155 |   1.6734 |     48.451 |     0.1
    2 |   1.6494 |     46.561 |   1.4428 |     46.499 |     0.2
    3 |   1.4773 |     45.569 |   1.3851 |     46.747 |     0.3
    4 |   1.4137 |     45.084 |   1.3557 |     46.933 |     0.4
    5 |   1.3743 |     44.885 |   1.3356 |     45.632 |     0.4
    6 |   1.3494 |     43.910 |   1.3321 |     45.787 |     0.5
    7 |   1.3251 |     43.673 |   1.3229 |     45.353 |     0.6
    8 |   1.3034 |     42.984 |   1.2945 |     44.331 |     0.7
    9 |   1.2809 |     42.405 |   1.2771 |     43.928 |     0.8
   10 |   1.2638 |     42.350 |   1.2823 |     43.835 |     0.9
   11 |   1.2458 |     41.501 |   1.2568 |     43.309 |     1.0
   12 |   1.2323 |     41.281 |   1.2569 |     43.123 |     1.1
   13 |   1.2125 |     40.735 |   1.2531 |     42.875 |     1.2
   14 |   1.2007 |     40.868 |   1.2236 |     41.884 |     1.2
   15 |   1.1895 |     40.184 |   1.2163 |     41.945 |     1.3
   16 |   1.1776 |     39.892 |   1.2360 |     42.255 |     1.4
   17 |   1.1665 |     39.457 |   1.2218 |     41.822 |     1.5
   18 |   1.1530 |     39.159 |   1.2394 |     41.481 |     1.6
   19 |   1.1434 |     39.049 |   1.1994 |     40.861 |     1.7
   20 |   1.1296 |     38.608 |   1.1867 |     41.450 |     1.8
   21 |   1.1246 |     38.404 |   1.1970 |     41.047 |     1.9
   22 |   1.1098 |     37.583 |   1.1686 |     40.675 |     2.0
   23 |   1.1050 |     37.550 |   1.2181 |     41.202 |     2.0
   24 |   1.0964 |     37.373 |   1.1677 |     39.870 |     2.1
   25 |   1.0830 |     37.009 |   1.1701 |     40.273 |     2.2
   26 |   1.0785 |     36.315 |   1.1758 |     39.839 |     2.3
   27 |   1.0709 |     36.287 |   1.1728 |     40.211 |     2.4
   28 |   1.0638 |     36.117 |   1.1544 |     39.777 |     2.5
   29 |   1.0525 |     35.830 |   1.2068 |     40.489 |     2.6
   30 |   1.0448 |     35.599 |   1.1476 |     38.971 |     2.7
   31 |   1.0310 |     34.921 |   1.1592 |     39.436 |     2.8
   32 |   1.0345 |     34.970 |   1.1654 |     39.126 |     2.9
   33 |   1.0211 |     34.601 |   1.1823 |     39.808 |     2.9
   34 |   1.0146 |     34.386 |   1.1465 |     38.538 |     3.0
   35 |   1.0071 |     34.028 |   1.1544 |     38.538 |     3.1
   36 |   0.9992 |     33.912 |   1.1223 |     37.918 |     3.2
   37 |   0.9919 |     33.377 |   1.1482 |     38.383 |     3.3
   38 |   0.9838 |     33.311 |   1.1505 |     38.011 |     3.4
   39 |   0.9738 |     32.881 |   1.1123 |     37.485 |     3.5
   40 |   0.9692 |     32.821 |   1.1583 |     38.197 |     3.6
   41 |   0.9650 |     32.766 |   1.1267 |     36.741 |     3.7
   42 |   0.9533 |     32.154 |   1.1465 |     37.608 |     3.8
   43 |   0.9452 |     31.895 |   1.1346 |     37.392 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 732,130

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6553 |     48.754 |   1.3148 |     44.981 |     0.1
    2 |   1.3191 |     44.296 |   1.2371 |     42.255 |     0.2
    3 |   1.2503 |     42.218 |   1.2123 |     42.441 |     0.3
    4 |   1.2097 |     41.209 |   1.1624 |     41.078 |     0.3
    5 |   1.1674 |     40.190 |   1.1290 |     39.746 |     0.4
    6 |   1.1393 |     39.220 |   1.1463 |     39.870 |     0.5
    7 |   1.1069 |     38.139 |   1.1247 |     38.848 |     0.6
    8 |   1.0807 |     37.048 |   1.1109 |     38.879 |     0.7
    9 |   1.0553 |     35.951 |   1.0865 |     37.546 |     0.8
   10 |   1.0251 |     35.075 |   1.0527 |     35.967 |     0.9
   11 |   1.0017 |     34.199 |   1.0645 |     36.276 |     1.0
   12 |   0.9820 |     33.780 |   1.0349 |     35.719 |     1.1
   13 |   0.9518 |     32.518 |   1.0594 |     35.719 |     1.1
   14 |   0.9383 |     32.088 |   1.0619 |     35.812 |     1.2
   15 |   0.9103 |     30.952 |   1.0536 |     36.462 |     1.3
   16 |   0.8913 |     30.467 |   1.0894 |     36.431 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 978,850

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4822 |     47.057 |   1.2714 |     44.362 |     0.1
    2 |   1.2221 |     43.359 |   1.1921 |     42.751 |     0.2
    3 |   1.1468 |     40.460 |   1.1354 |     39.157 |     0.3
    4 |   1.0967 |     38.746 |   1.1330 |     39.994 |     0.4
    5 |   1.0640 |     37.120 |   1.0877 |     37.887 |     0.5
    6 |   1.0048 |     35.042 |   1.0502 |     37.794 |     0.6
    7 |   0.9729 |     34.028 |   1.0270 |     35.347 |     0.7
    8 |   0.9272 |     32.231 |   1.0127 |     35.223 |     0.8
    9 |   0.8845 |     30.991 |   0.9733 |     33.550 |     1.0
   10 |   0.8386 |     29.172 |   0.9732 |     32.993 |     1.1
   11 |   0.7903 |     27.425 |   0.9988 |     33.705 |     1.2
   12 |   0.7577 |     26.455 |   0.9822 |     33.457 |     1.3
   13 |   0.7111 |     24.785 |   0.9736 |     32.094 |     1.4
   14 |   0.6675 |     23.258 |   0.9941 |     33.147 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 393,634

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4734 |     58.477 |   1.8536 |     46.685 |     0.1
    2 |   1.6885 |     45.574 |   1.5920 |     45.291 |     0.2
    3 |   1.5324 |     44.737 |   1.4978 |     44.083 |     0.3
    4 |   1.4504 |     43.689 |   1.4370 |     44.393 |     0.4
    5 |   1.3876 |     42.835 |   1.4038 |     44.424 |     0.5
    6 |   1.3422 |     42.135 |   1.3626 |     43.711 |     0.6
    7 |   1.3033 |     41.777 |   1.3373 |     43.556 |     0.7
    8 |   1.2699 |     41.226 |   1.3253 |     43.371 |     0.9
    9 |   1.2410 |     40.597 |   1.2788 |     41.853 |     1.0
   10 |   1.2144 |     39.942 |   1.2892 |     42.441 |     1.1
   11 |   1.1898 |     39.297 |   1.2419 |     42.193 |     1.2
   12 |   1.1690 |     38.652 |   1.2200 |     41.822 |     1.3
   13 |   1.1493 |     38.150 |   1.2203 |     41.264 |     1.4
   14 |   1.1318 |     37.770 |   1.1735 |     39.622 |     1.5
   15 |   1.1138 |     36.927 |   1.1930 |     40.304 |     1.6
   16 |   1.0967 |     36.464 |   1.1721 |     40.211 |     1.7
   17 |   1.0805 |     35.979 |   1.1804 |     40.118 |     1.8
   18 |   1.0637 |     35.251 |   1.1685 |     39.901 |     1.9
   19 |   1.0538 |     35.378 |   1.1598 |     39.715 |     2.0
   20 |   1.0373 |     34.689 |   1.1500 |     38.755 |     2.1
   21 |   1.0195 |     33.896 |   1.1498 |     39.374 |     2.2
   22 |   1.0094 |     33.813 |   1.1387 |     39.405 |     2.4
   23 |   0.9954 |     33.262 |   1.1157 |     37.949 |     2.5
   24 |   0.9738 |     32.264 |   1.1409 |     39.405 |     2.6
   25 |   0.9601 |     31.718 |   1.1456 |     38.971 |     2.7
   26 |   0.9507 |     31.564 |   1.1373 |     38.631 |     2.8
   27 |   0.9365 |     31.300 |   1.0983 |     37.980 |     2.9
   28 |   0.9235 |     30.467 |   1.1419 |     38.197 |     3.0
   29 |   0.9087 |     30.071 |   1.0937 |     36.896 |     3.1
   30 |   0.9023 |     29.690 |   1.0997 |     36.803 |     3.2
   31 |   0.8871 |     29.508 |   1.1134 |     37.639 |     3.3
   32 |   0.8757 |     29.034 |   1.1422 |     37.980 |     3.4
   33 |   0.8616 |     28.461 |   1.1102 |     36.927 |     3.5
   34 |   0.8504 |     28.114 |   1.0860 |     35.967 |     3.6
   35 |   0.8375 |     27.651 |   1.1127 |     36.803 |     3.7
   36 |   0.8236 |     27.403 |   1.1072 |     36.803 |     3.8
   37 |   0.8145 |     26.841 |   1.1091 |     36.121 |     4.0
   38 |   0.8048 |     26.494 |   1.0902 |     36.772 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,177,634

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5279 |     47.680 |   1.3283 |     45.322 |     0.1
    2 |   1.2504 |     43.028 |   1.2389 |     42.968 |     0.2
    3 |   1.1933 |     41.915 |   1.2005 |     42.627 |     0.3
    4 |   1.1407 |     40.228 |   1.1254 |     40.304 |     0.4
    5 |   1.0987 |     39.104 |   1.1140 |     39.932 |     0.5
    6 |   1.0628 |     37.599 |   1.0736 |     37.670 |     0.6
    7 |   1.0470 |     37.081 |   1.0619 |     38.445 |     0.7
    8 |   1.0062 |     35.836 |   1.0501 |     36.121 |     0.8
    9 |   0.9738 |     34.204 |   1.0350 |     36.958 |     0.9
   10 |   0.9420 |     33.262 |   1.0429 |     36.059 |     0.9
   11 |   0.9179 |     32.485 |   1.0091 |     35.657 |     1.0
   12 |   0.8827 |     31.123 |   1.0196 |     35.936 |     1.1
   13 |   0.8622 |     30.230 |   1.0055 |     34.603 |     1.2
   14 |   0.8270 |     28.786 |   1.0063 |     34.820 |     1.3
   15 |   0.8002 |     28.153 |   0.9894 |     33.271 |     1.4
   16 |   0.7717 |     26.957 |   0.9901 |     33.829 |     1.5
   17 |   0.7467 |     25.992 |   1.0275 |     34.232 |     1.6
   18 |   0.7112 |     24.724 |   1.0167 |     33.302 |     1.7
   19 |   0.6753 |     23.666 |   1.0247 |     32.342 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 277,154

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7251 |     48.799 |   1.3590 |     44.734 |     0.1
    2 |   1.3297 |     43.827 |   1.2824 |     44.083 |     0.2
    3 |   1.2616 |     42.841 |   1.2391 |     43.061 |     0.3
    4 |   1.2104 |     41.645 |   1.2144 |     42.503 |     0.4
    5 |   1.1743 |     40.636 |   1.1633 |     41.202 |     0.5
    6 |   1.1397 |     39.209 |   1.1552 |     40.025 |     0.6
    7 |   1.1052 |     37.919 |   1.1370 |     39.467 |     0.7
    8 |   1.0780 |     36.850 |   1.0931 |     37.887 |     0.8
    9 |   1.0562 |     36.425 |   1.0937 |     38.507 |     0.9
   10 |   1.0255 |     35.378 |   1.0568 |     36.710 |     1.0
   11 |   1.0001 |     34.364 |   1.0564 |     36.121 |     1.1
   12 |   0.9753 |     33.410 |   1.0325 |     35.192 |     1.2
   13 |   0.9533 |     33.129 |   1.0258 |     34.572 |     1.3
   14 |   0.9265 |     31.944 |   1.0218 |     34.325 |     1.4
   15 |   0.9018 |     30.776 |   1.0089 |     33.984 |     1.5
   16 |   0.8831 |     30.374 |   1.0422 |     34.263 |     1.6
   17 |   0.8563 |     29.161 |   0.9698 |     32.590 |     1.7
   18 |   0.8437 |     29.045 |   0.9951 |     32.373 |     1.8
   19 |   0.8250 |     28.241 |   0.9919 |     33.612 |     1.9
   20 |   0.8017 |     27.315 |   1.0175 |     32.497 |     2.0
   21 |   0.7837 |     26.714 |   0.9796 |     31.939 |     2.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 425,762

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7205 |     49.708 |   1.3493 |     45.074 |     0.1
    2 |   1.3268 |     45.012 |   1.2715 |     43.649 |     0.2
    3 |   1.2674 |     44.020 |   1.2231 |     42.596 |     0.3
    4 |   1.2287 |     43.243 |   1.2045 |     42.472 |     0.4
    5 |   1.1948 |     41.727 |   1.1464 |     40.799 |     0.5
    6 |   1.1523 |     40.272 |   1.1297 |     39.684 |     0.6
    7 |   1.1276 |     39.385 |   1.1027 |     39.250 |     0.7
    8 |   1.1041 |     38.531 |   1.0984 |     39.808 |     0.8
    9 |   1.0725 |     37.246 |   1.0591 |     37.918 |     0.9
   10 |   1.0384 |     36.282 |   1.0468 |     36.276 |     1.0
   11 |   1.0118 |     35.125 |   1.0382 |     35.905 |     1.2
   12 |   0.9885 |     34.353 |   1.0029 |     34.665 |     1.3
   13 |   0.9624 |     33.499 |   0.9877 |     34.201 |     1.4
   14 |   0.9420 |     32.970 |   1.0146 |     35.533 |     1.5
   15 |   0.9101 |     31.889 |   0.9796 |     34.449 |     1.6
   16 |   0.8961 |     31.316 |   0.9719 |     33.860 |     1.7
   17 |   0.8606 |     29.767 |   0.9920 |     34.325 |     1.8
   18 |   0.8366 |     28.908 |   0.9653 |     33.024 |     1.9
   19 |   0.8044 |     27.965 |   0.9831 |     33.550 |     2.0
   20 |   0.7838 |     27.447 |   0.9839 |     33.550 |     2.1
   21 |   0.7565 |     26.273 |   0.9580 |     32.187 |     2.2
   22 |   0.7332 |     25.143 |   1.0050 |     33.550 |     2.3
   23 |   0.7102 |     24.427 |   0.9810 |     31.784 |     2.4
   24 |   0.6757 |     23.291 |   0.9940 |     32.001 |     2.5
   25 |   0.6492 |     22.630 |   1.0176 |     31.877 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,177,634

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6657 |     49.653 |   1.3859 |     45.973 |     0.1
    2 |   1.3553 |     45.905 |   1.2861 |     44.981 |     0.2
    3 |   1.2989 |     44.466 |   1.2468 |     43.711 |     0.3
    4 |   1.2688 |     44.075 |   1.2197 |     43.556 |     0.4
    5 |   1.2398 |     43.309 |   1.2046 |     43.680 |     0.5
    6 |   1.2166 |     42.664 |   1.2200 |     43.494 |     0.6
    7 |   1.2024 |     42.207 |   1.1892 |     41.853 |     0.7
    8 |   1.1834 |     41.364 |   1.1662 |     41.202 |     0.8
    9 |   1.1622 |     40.493 |   1.1461 |     39.746 |     0.9
   10 |   1.1424 |     39.600 |   1.1148 |     40.056 |     1.0
   11 |   1.1164 |     38.806 |   1.1040 |     38.848 |     1.1
   12 |   1.1043 |     38.547 |   1.0924 |     38.786 |     1.2
   13 |   1.0860 |     37.853 |   1.0843 |     38.817 |     1.3
   14 |   1.0675 |     36.998 |   1.0784 |     37.670 |     1.4
   15 |   1.0543 |     36.745 |   1.0435 |     36.493 |     1.5
   16 |   1.0376 |     36.023 |   1.0507 |     37.980 |     1.6
   17 |   1.0252 |     35.979 |   1.0412 |     36.648 |     1.7
   18 |   1.0071 |     34.893 |   1.0327 |     36.369 |     1.8
   19 |   0.9905 |     34.695 |   1.0218 |     35.843 |     1.9
   20 |   0.9783 |     34.347 |   1.0069 |     35.037 |     2.0
   21 |   0.9596 |     33.207 |   1.0056 |     34.975 |     2.1
   22 |   0.9454 |     33.113 |   1.0055 |     35.471 |     2.2
   23 |   0.9374 |     32.771 |   0.9934 |     34.882 |     2.3
   24 |   0.9190 |     31.917 |   0.9682 |     33.147 |     2.4
   25 |   0.9003 |     31.476 |   0.9730 |     33.488 |     2.5
   26 |   0.8892 |     30.809 |   0.9737 |     34.139 |     2.6
   27 |   0.8764 |     30.556 |   0.9783 |     33.674 |     2.7
   28 |   0.8612 |     29.856 |   0.9751 |     33.086 |     2.8
   29 |   0.8483 |     29.679 |   0.9447 |     32.776 |     2.9
   30 |   0.8341 |     29.139 |   0.9712 |     32.373 |     3.0
   31 |   0.8289 |     28.919 |   0.9618 |     32.466 |     3.1
   32 |   0.8129 |     28.478 |   0.9535 |     31.691 |     3.2
   33 |   0.7965 |     27.866 |   0.9694 |     32.435 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8280 |     69.659 |   2.1629 |     51.084 |     0.1
    2 |   2.0986 |     49.702 |   1.7099 |     47.305 |     0.1
    3 |   1.7546 |     46.583 |   1.5598 |     47.150 |     0.2
    4 |   1.6094 |     45.866 |   1.4859 |     45.973 |     0.2
    5 |   1.5314 |     46.120 |   1.4432 |     46.902 |     0.3
    6 |   1.4796 |     45.872 |   1.4135 |     45.942 |     0.4
    7 |   1.4502 |     45.822 |   1.3905 |     45.477 |     0.4
    8 |   1.4248 |     45.674 |   1.3702 |     45.167 |     0.5
    9 |   1.4013 |     45.448 |   1.3529 |     44.269 |     0.6
   10 |   1.3824 |     44.924 |   1.3450 |     44.579 |     0.6
   11 |   1.3664 |     44.742 |   1.3301 |     44.610 |     0.7
   12 |   1.3523 |     44.549 |   1.3279 |     45.260 |     0.7
   13 |   1.3350 |     43.645 |   1.3161 |     45.012 |     0.8
   14 |   1.3316 |     43.910 |   1.3137 |     45.198 |     0.9
   15 |   1.3203 |     43.761 |   1.3065 |     44.888 |     0.9
   16 |   1.3091 |     43.375 |   1.3095 |     44.981 |     1.0
   17 |   1.3024 |     43.298 |   1.3033 |     44.827 |     1.0
   18 |   1.2915 |     43.149 |   1.2902 |     44.300 |     1.1
   19 |   1.2834 |     42.797 |   1.2971 |     44.888 |     1.2
   20 |   1.2783 |     42.989 |   1.2924 |     44.703 |     1.2
   21 |   1.2696 |     42.565 |   1.2770 |     43.711 |     1.3
   22 |   1.2645 |     42.444 |   1.2807 |     43.866 |     1.4
   23 |   1.2536 |     41.997 |   1.2844 |     44.021 |     1.4
   24 |   1.2470 |     41.871 |   1.2669 |     43.401 |     1.5
   25 |   1.2432 |     41.992 |   1.2848 |     43.928 |     1.5
   26 |   1.2369 |     41.551 |   1.2636 |     43.556 |     1.6
   27 |   1.2268 |     41.259 |   1.2703 |     43.401 |     1.7
   28 |   1.2268 |     41.386 |   1.2607 |     43.556 |     1.7
   29 |   1.2180 |     41.308 |   1.2706 |     43.928 |     1.8
   30 |   1.2084 |     40.989 |   1.2679 |     43.773 |     1.8
   31 |   1.2078 |     40.829 |   1.2653 |     43.587 |     1.9
   32 |   1.2004 |     40.680 |   1.2291 |     42.689 |     2.0
   33 |   1.1951 |     40.625 |   1.2605 |     43.463 |     2.0
   34 |   1.1900 |     40.300 |   1.2473 |     43.061 |     2.1
   35 |   1.1841 |     40.096 |   1.2647 |     43.309 |     2.2
   36 |   1.1810 |     40.449 |   1.2418 |     42.813 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,045,026

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0222 |     52.657 |   1.5049 |     46.035 |     0.1
    2 |   1.4223 |     45.343 |   1.3828 |     44.145 |     0.3
    3 |   1.3356 |     43.899 |   1.3180 |     44.579 |     0.4
    4 |   1.2861 |     42.802 |   1.2816 |     42.503 |     0.5
    5 |   1.2414 |     41.567 |   1.2714 |     42.782 |     0.7
    6 |   1.2063 |     40.586 |   1.2777 |     42.875 |     0.8
    7 |   1.1732 |     39.942 |   1.2385 |     42.596 |     0.9
    8 |   1.1405 |     39.120 |   1.2451 |     41.574 |     1.1
    9 |   1.1133 |     38.046 |   1.1698 |     40.211 |     1.2
   10 |   1.0909 |     37.098 |   1.1760 |     40.613 |     1.3
   11 |   1.0605 |     35.858 |   1.1355 |     39.560 |     1.5
   12 |   1.0377 |     34.954 |   1.1345 |     39.064 |     1.6
   13 |   1.0100 |     33.796 |   1.1600 |     40.644 |     1.7
   14 |   0.9852 |     33.207 |   1.0977 |     38.352 |     1.9
   15 |   0.9571 |     31.972 |   1.0891 |     37.608 |     2.0
   16 |   0.9342 |     31.074 |   1.1067 |     38.166 |     2.1
   17 |   0.9047 |     30.126 |   1.0948 |     37.113 |     2.3
   18 |   0.8748 |     28.853 |   1.0784 |     36.400 |     2.4
   19 |   0.8465 |     27.756 |   1.1164 |     37.515 |     2.5
   20 |   0.8169 |     26.753 |   1.1034 |     36.648 |     2.7
   21 |   0.7918 |     26.124 |   1.0709 |     36.090 |     2.8
   22 |   0.7616 |     24.857 |   1.0744 |     35.626 |     2.9
   23 |   0.7326 |     23.782 |   1.0889 |     35.440 |     3.1
   24 |   0.7034 |     23.104 |   1.1039 |     35.161 |     3.2
   25 |   0.6707 |     21.759 |   1.1170 |     36.307 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 392,226

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6638 |     47.922 |   1.3525 |     45.322 |     0.2
    2 |   1.3129 |     44.626 |   1.2624 |     45.012 |     0.3
    3 |   1.2597 |     43.993 |   1.2305 |     43.773 |     0.5
    4 |   1.2246 |     43.298 |   1.1938 |     43.401 |     0.6
    5 |   1.1983 |     43.127 |   1.1790 |     41.853 |     0.8
    6 |   1.1826 |     42.582 |   1.1651 |     41.822 |     0.9
    7 |   1.1690 |     42.449 |   1.1610 |     41.357 |     1.1
    8 |   1.1608 |     42.097 |   1.1346 |     40.675 |     1.2
    9 |   1.1484 |     41.711 |   1.1429 |     41.202 |     1.4
   10 |   1.1392 |     41.171 |   1.1305 |     40.954 |     1.5
   11 |   1.1219 |     40.261 |   1.1224 |     41.543 |     1.7
   12 |   1.1134 |     40.278 |   1.1147 |     40.397 |     1.8
   13 |   1.1008 |     39.578 |   1.1052 |     39.002 |     2.0
   14 |   1.0991 |     39.572 |   1.0907 |     39.064 |     2.1
   15 |   1.0872 |     39.198 |   1.0923 |     39.591 |     2.3
   16 |   1.0795 |     39.253 |   1.0945 |     38.631 |     2.4
   17 |   1.0724 |     38.900 |   1.1014 |     40.737 |     2.6
   18 |   1.0666 |     38.586 |   1.0937 |     39.560 |     2.7
   19 |   1.0612 |     38.465 |   1.0853 |     38.197 |     2.9
   20 |   1.0529 |     38.453 |   1.0805 |     38.817 |     3.0
   21 |   1.0503 |     37.952 |   1.1106 |     39.684 |     3.2
   22 |   1.0472 |     37.946 |   1.0800 |     39.188 |     3.4
   23 |   1.0384 |     37.616 |   1.1132 |     40.273 |     3.5
   24 |   1.0383 |     37.754 |   1.1380 |     41.698 |     3.7
   25 |   1.0293 |     37.307 |   1.0764 |     38.507 |     3.8
   26 |   1.0238 |     37.098 |   1.0986 |     39.777 |     4.0
   27 |   1.0212 |     36.960 |   1.1104 |     40.397 |     4.1
   28 |   1.0133 |     36.761 |   1.0948 |     39.064 |     4.3
   29 |   1.0097 |     36.877 |   1.1664 |     41.729 |     4.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,243,810

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0901 |     54.128 |   1.4966 |     45.725 |     0.1
    2 |   1.4816 |     45.503 |   1.3816 |     44.579 |     0.3
    3 |   1.3784 |     44.119 |   1.3262 |     43.463 |     0.4
    4 |   1.3207 |     43.127 |   1.2940 |     43.773 |     0.6
    5 |   1.2787 |     41.860 |   1.2901 |     44.424 |     0.7
    6 |   1.2477 |     41.182 |   1.2833 |     43.463 |     0.9
    7 |   1.2132 |     40.002 |   1.2234 |     42.193 |     1.1
    8 |   1.1911 |     40.057 |   1.2239 |     41.976 |     1.2
    9 |   1.1696 |     39.286 |   1.1890 |     41.295 |     1.4
   10 |   1.1452 |     38.740 |   1.1650 |     41.016 |     1.5
   11 |   1.1279 |     38.046 |   1.1914 |     40.428 |     1.7
   12 |   1.1072 |     37.654 |   1.1338 |     39.808 |     1.8
   13 |   1.0844 |     36.883 |   1.1451 |     39.560 |     2.0
   14 |   1.0712 |     36.326 |   1.1489 |     39.405 |     2.1
   15 |   1.0511 |     35.461 |   1.1670 |     39.839 |     2.3
   16 |   1.0320 |     34.595 |   1.1186 |     38.755 |     2.4
   17 |   1.0218 |     34.496 |   1.1456 |     38.879 |     2.6
   18 |   1.0087 |     34.132 |   1.1442 |     39.126 |     2.7
   19 |   0.9875 |     33.052 |   1.1272 |     38.166 |     2.9
   20 |   0.9726 |     32.413 |   1.1626 |     38.724 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 980,258

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7061 |     50.066 |   1.3529 |     45.973 |     0.1
    2 |   1.3469 |     44.781 |   1.3134 |     45.446 |     0.2
    3 |   1.2858 |     43.116 |   1.2513 |     43.432 |     0.4
    4 |   1.2397 |     42.141 |   1.2016 |     41.976 |     0.5
    5 |   1.2000 |     41.016 |   1.1779 |     42.069 |     0.6
    6 |   1.1730 |     40.030 |   1.1419 |     40.366 |     0.7
    7 |   1.1493 |     38.861 |   1.1577 |     40.335 |     0.8
    8 |   1.1189 |     38.228 |   1.1810 |     40.954 |     1.0
    9 |   1.0888 |     37.004 |   1.1173 |     38.290 |     1.1
   10 |   1.0593 |     36.012 |   1.1606 |     39.281 |     1.2
   11 |   1.0349 |     35.014 |   1.1271 |     38.600 |     1.3
   12 |   1.0171 |     34.899 |   1.1066 |     37.887 |     1.4
   13 |   0.9936 |     34.022 |   1.0845 |     36.555 |     1.6
   14 |   0.9564 |     32.534 |   1.1082 |     37.175 |     1.7
   15 |   0.9434 |     32.374 |   1.1046 |     37.794 |     1.8
   16 |   0.9188 |     31.542 |   1.1274 |     37.392 |     1.9
   17 |   0.8867 |     30.605 |   1.1126 |     36.710 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 293,154

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6925 |     63.018 |   2.0483 |     50.279 |     0.1
    2 |   1.9189 |     47.603 |   1.6523 |     46.747 |     0.2
    3 |   1.6613 |     46.203 |   1.5320 |     45.787 |     0.3
    4 |   1.5504 |     45.844 |   1.4685 |     46.530 |     0.4
    5 |   1.4855 |     45.723 |   1.4254 |     46.809 |     0.5
    6 |   1.4383 |     45.486 |   1.3934 |     46.623 |     0.6
    7 |   1.4017 |     44.957 |   1.3696 |     45.725 |     0.7
    8 |   1.3717 |     44.681 |   1.3365 |     45.384 |     0.8
    9 |   1.3438 |     43.761 |   1.3198 |     44.362 |     0.9
   10 |   1.3231 |     43.651 |   1.3090 |     44.857 |     1.0
   11 |   1.2998 |     42.956 |   1.2865 |     44.269 |     1.1
   12 |   1.2854 |     42.697 |   1.2636 |     43.185 |     1.2
   13 |   1.2686 |     42.289 |   1.2534 |     43.309 |     1.3
   14 |   1.2520 |     41.887 |   1.2459 |     43.185 |     1.4
   15 |   1.2435 |     41.562 |   1.2461 |     42.968 |     1.5
   16 |   1.2285 |     41.391 |   1.2462 |     43.278 |     1.6
   17 |   1.2185 |     41.110 |   1.2120 |     41.574 |     1.7
   18 |   1.2095 |     40.807 |   1.2142 |     42.193 |     1.8
   19 |   1.1986 |     40.151 |   1.2017 |     41.945 |     1.9
   20 |   1.1900 |     40.498 |   1.2002 |     41.945 |     2.0
   21 |   1.1800 |     39.964 |   1.2097 |     42.410 |     2.1
   22 |   1.1745 |     39.864 |   1.2168 |     42.565 |     2.2
   23 |   1.1656 |     39.319 |   1.1997 |     41.945 |     2.3
   24 |   1.1544 |     39.346 |   1.1760 |     41.202 |     2.4
   25 |   1.1548 |     39.120 |   1.1858 |     42.069 |     2.5
   26 |   1.1459 |     38.961 |   1.1589 |     40.954 |     2.6
   27 |   1.1361 |     38.801 |   1.1600 |     40.892 |     2.7
   28 |   1.1317 |     38.503 |   1.1735 |     41.233 |     2.8
   29 |   1.1242 |     38.216 |   1.1599 |     40.675 |     2.9
   30 |   1.1162 |     38.029 |   1.1584 |     41.078 |     3.0
   31 |   1.1116 |     37.979 |   1.1677 |     40.768 |     3.1
   32 |   1.1063 |     37.654 |   1.1447 |     40.737 |     3.2
   33 |   1.0973 |     37.191 |   1.1462 |     40.366 |     3.3
   34 |   1.0921 |     37.467 |   1.1527 |     40.613 |     3.4
   35 |   1.0872 |     37.048 |   1.1554 |     40.087 |     3.5
   36 |   1.0853 |     36.960 |   1.1393 |     40.056 |     3.6
   37 |   1.0763 |     36.414 |   1.1318 |     39.281 |     3.7
   38 |   1.0705 |     36.591 |   1.1659 |     40.768 |     3.8
   39 |   1.0664 |     36.337 |   1.1494 |     40.428 |     3.9
   40 |   1.0609 |     36.050 |   1.1390 |     40.025 |     4.0
   41 |   1.0510 |     35.808 |   1.1362 |     39.498 |     4.1
   42 |   1.0462 |     35.510 |   1.1278 |     38.941 |     4.2
   43 |   1.0413 |     35.450 |   1.1374 |     39.529 |     4.3
   44 |   1.0361 |     35.472 |   1.1274 |     39.281 |     4.4
   45 |   1.0315 |     35.169 |   1.1168 |     39.219 |     4.5
   46 |   1.0299 |     35.014 |   1.1226 |     38.971 |     4.6
   47 |   1.0206 |     34.722 |   1.1268 |     38.971 |     4.7
   48 |   1.0171 |     34.276 |   1.1309 |     39.343 |     4.8
   49 |   1.0168 |     34.640 |   1.1500 |     39.498 |     4.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 847,650

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5059 |     46.610 |   1.3116 |     45.012 |     0.1
    2 |   1.2660 |     44.290 |   1.2369 |     44.331 |     0.3
    3 |   1.2133 |     43.067 |   1.1825 |     42.441 |     0.4
    4 |   1.1721 |     41.452 |   1.1761 |     41.140 |     0.5
    5 |   1.1434 |     40.785 |   1.1564 |     41.976 |     0.6
    6 |   1.1243 |     40.239 |   1.1367 |     41.047 |     0.8
    7 |   1.1086 |     40.261 |   1.1283 |     40.335 |     0.9
    8 |   1.0927 |     39.379 |   1.1153 |     40.273 |     1.0
    9 |   1.0770 |     39.115 |   1.1027 |     39.002 |     1.1
   10 |   1.0630 |     38.398 |   1.1157 |     39.808 |     1.3
   11 |   1.0542 |     37.886 |   1.0760 |     38.538 |     1.4
   12 |   1.0425 |     37.627 |   1.0975 |     40.025 |     1.5
   13 |   1.0325 |     37.280 |   1.0707 |     38.786 |     1.7
   14 |   1.0170 |     36.844 |   1.0651 |     39.157 |     1.8
   15 |   1.0117 |     36.750 |   1.0610 |     37.515 |     1.9
   16 |   1.0046 |     36.519 |   1.0390 |     37.732 |     2.0
   17 |   0.9971 |     36.497 |   1.0454 |     36.493 |     2.2
   18 |   0.9886 |     36.238 |   1.0702 |     38.662 |     2.3
   19 |   0.9801 |     36.106 |   1.0710 |     38.352 |     2.4
   20 |   0.9756 |     35.654 |   1.0569 |     38.414 |     2.6
   21 |   0.9627 |     35.235 |   1.0352 |     36.679 |     2.7
   22 |   0.9527 |     34.568 |   1.0445 |     37.515 |     2.8
   23 |   0.9410 |     34.144 |   1.0211 |     35.998 |     2.9
   24 |   0.9386 |     33.846 |   1.0438 |     37.051 |     3.1
   25 |   0.9208 |     33.179 |   1.0463 |     37.608 |     3.2
   26 |   0.9135 |     32.727 |   1.0233 |     36.183 |     3.3
   27 |   0.9007 |     32.567 |   1.0200 |     36.307 |     3.5
   28 |   0.8925 |     32.005 |   1.0081 |     36.648 |     3.6
   29 |   0.8756 |     31.145 |   0.9944 |     35.037 |     3.7
   30 |   0.8635 |     30.528 |   1.0062 |     35.967 |     3.8
   31 |   0.8585 |     30.737 |   0.9841 |     34.944 |     4.0
   32 |   0.8364 |     29.778 |   0.9984 |     35.099 |     4.1
   33 |   0.8274 |     29.459 |   0.9939 |     34.696 |     4.2
   34 |   0.8128 |     28.858 |   1.0106 |     33.860 |     4.4
   35 |   0.8083 |     28.401 |   0.9929 |     34.263 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 235,170

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6563 |     61.618 |   1.9852 |     47.708 |     0.1
    2 |   1.9073 |     46.886 |   1.6521 |     46.221 |     0.2
    3 |   1.6588 |     46.230 |   1.5240 |     46.159 |     0.3
    4 |   1.5488 |     45.999 |   1.4525 |     45.477 |     0.4
    5 |   1.4777 |     45.662 |   1.4081 |     44.672 |     0.5
    6 |   1.4344 |     45.100 |   1.3759 |     44.176 |     0.6
    7 |   1.4024 |     44.869 |   1.3497 |     43.928 |     0.7
    8 |   1.3742 |     44.207 |   1.3313 |     43.061 |     0.7
    9 |   1.3516 |     44.048 |   1.3198 |     44.455 |     0.8
   10 |   1.3324 |     43.794 |   1.3093 |     44.331 |     0.9
   11 |   1.3140 |     43.386 |   1.2899 |     43.897 |     1.0
   12 |   1.2993 |     43.034 |   1.2858 |     43.866 |     1.1
   13 |   1.2826 |     42.774 |   1.2736 |     43.556 |     1.2
   14 |   1.2698 |     42.212 |   1.2628 |     43.525 |     1.3
   15 |   1.2572 |     41.843 |   1.2495 |     42.875 |     1.4
   16 |   1.2391 |     41.336 |   1.2448 |     42.286 |     1.5
   17 |   1.2292 |     41.176 |   1.2540 |     42.999 |     1.6
   18 |   1.2163 |     40.537 |   1.2395 |     42.286 |     1.7
   19 |   1.2062 |     40.515 |   1.2190 |     41.853 |     1.8
   20 |   1.1971 |     40.471 |   1.2089 |     41.760 |     1.9
   21 |   1.1857 |     39.859 |   1.2208 |     42.038 |     2.0
   22 |   1.1798 |     40.074 |   1.2119 |     41.698 |     2.0
   23 |   1.1678 |     39.506 |   1.2039 |     41.512 |     2.1
   24 |   1.1627 |     39.418 |   1.2200 |     42.007 |     2.2
   25 |   1.1511 |     39.049 |   1.2079 |     41.667 |     2.3
   26 |   1.1457 |     39.032 |   1.1774 |     41.202 |     2.4
   27 |   1.1324 |     38.266 |   1.1901 |     41.140 |     2.5
   28 |   1.1270 |     38.294 |   1.1835 |     41.078 |     2.6
   29 |   1.1207 |     38.150 |   1.1769 |     41.326 |     2.7
   30 |   1.1161 |     38.073 |   1.1839 |     41.140 |     2.8
   31 |   1.1059 |     37.506 |   1.1717 |     40.830 |     2.9
   32 |   1.1029 |     37.698 |   1.1639 |     41.109 |     3.0
   33 |   1.0953 |     37.346 |   1.1771 |     40.644 |     3.1
   34 |   1.0905 |     37.169 |   1.1779 |     41.109 |     3.2
   35 |   1.0854 |     36.877 |   1.1686 |     40.737 |     3.3
   36 |   1.0798 |     36.960 |   1.1653 |     40.304 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 285,602

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6669 |     48.562 |   1.3437 |     46.252 |     0.1
    2 |   1.2924 |     43.937 |   1.2632 |     44.765 |     0.3
    3 |   1.2274 |     43.078 |   1.2003 |     42.162 |     0.4
    4 |   1.1799 |     41.821 |   1.1732 |     42.782 |     0.6
    5 |   1.1443 |     40.570 |   1.1525 |     40.613 |     0.7
    6 |   1.1164 |     39.672 |   1.1240 |     40.180 |     0.8
    7 |   1.0904 |     38.834 |   1.0870 |     38.228 |     1.0
    8 |   1.0708 |     38.216 |   1.0777 |     38.693 |     1.1
    9 |   1.0494 |     37.748 |   1.0826 |     39.529 |     1.3
   10 |   1.0321 |     36.927 |   1.0673 |     37.577 |     1.4
   11 |   1.0129 |     36.326 |   1.0550 |     37.113 |     1.5
   12 |   0.9945 |     35.769 |   1.0340 |     36.865 |     1.7
   13 |   0.9760 |     35.218 |   1.0306 |     35.905 |     1.8
   14 |   0.9593 |     34.529 |   1.0169 |     35.471 |     2.0
   15 |   0.9510 |     34.188 |   1.0059 |     35.533 |     2.1
   16 |   0.9260 |     33.256 |   0.9973 |     35.502 |     2.2
   17 |   0.9062 |     32.181 |   1.0013 |     35.533 |     2.4
   18 |   0.8844 |     31.410 |   1.0076 |     34.975 |     2.5
   19 |   0.8738 |     31.129 |   1.0069 |     34.480 |     2.7
   20 |   0.8559 |     30.247 |   0.9799 |     33.860 |     2.8
   21 |   0.8311 |     29.238 |   1.0299 |     35.099 |     2.9
   22 |   0.8175 |     28.902 |   0.9861 |     33.519 |     3.1
   23 |   0.7893 |     28.092 |   1.0197 |     34.603 |     3.2
   24 |   0.7874 |     27.668 |   1.0197 |     34.511 |     3.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 285,602

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7844 |     49.923 |   1.3698 |     46.066 |     0.1
    2 |   1.3714 |     45.833 |   1.3149 |     45.973 |     0.3
    3 |   1.3229 |     45.155 |   1.2673 |     43.773 |     0.5
    4 |   1.2806 |     44.196 |   1.2441 |     43.247 |     0.6
    5 |   1.2545 |     43.921 |   1.2406 |     43.618 |     0.8
    6 |   1.2315 |     43.072 |   1.2060 |     41.760 |     0.9
    7 |   1.2134 |     42.609 |   1.1941 |     42.038 |     1.1
    8 |   1.1922 |     42.108 |   1.1759 |     41.512 |     1.2
    9 |   1.1796 |     41.297 |   1.1552 |     40.551 |     1.4
   10 |   1.1611 |     40.890 |   1.1403 |     41.016 |     1.5
   11 |   1.1531 |     40.399 |   1.1339 |     39.622 |     1.7
   12 |   1.1395 |     39.826 |   1.1206 |     39.033 |     1.8
   13 |   1.1265 |     39.986 |   1.1154 |     39.219 |     2.0
   14 |   1.1074 |     39.115 |   1.1133 |     39.653 |     2.1
   15 |   1.0913 |     38.707 |   1.1174 |     39.467 |     2.3
   16 |   1.0841 |     38.035 |   1.1458 |     40.520 |     2.4
   17 |   1.0639 |     37.577 |   1.1159 |     39.405 |     2.6
   18 |   1.0626 |     37.263 |   1.1155 |     38.910 |     2.8
   19 |   1.0481 |     37.257 |   1.1024 |     38.755 |     2.9
   20 |   1.0335 |     36.535 |   1.1155 |     39.529 |     3.1
   21 |   1.0220 |     36.293 |   1.1031 |     39.405 |     3.2
   22 |   1.0097 |     35.654 |   1.1372 |     39.126 |     3.4
   23 |   1.0012 |     35.516 |   1.1037 |     39.777 |     3.5
   24 |   0.9889 |     35.069 |   1.0911 |     38.228 |     3.7
   25 |   0.9765 |     34.584 |   1.1153 |     39.250 |     3.8
   26 |   0.9626 |     33.967 |   1.1082 |     38.817 |     4.0
   27 |   0.9552 |     33.466 |   1.1318 |     39.281 |     4.1
   28 |   0.9409 |     33.399 |   1.1451 |     38.352 |     4.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 814,370

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2751 |     57.733 |   1.5669 |     45.880 |     0.1
    2 |   1.5281 |     46.241 |   1.4070 |     45.229 |     0.2
    3 |   1.4049 |     45.337 |   1.3393 |     44.052 |     0.3
    4 |   1.3428 |     44.075 |   1.2971 |     44.610 |     0.4
    5 |   1.2975 |     43.149 |   1.2612 |     43.618 |     0.4
    6 |   1.2636 |     42.212 |   1.2399 |     42.100 |     0.5
    7 |   1.2310 |     41.104 |   1.2360 |     42.565 |     0.6
    8 |   1.2112 |     40.812 |   1.2053 |     41.729 |     0.7
    9 |   1.1885 |     40.410 |   1.1822 |     40.861 |     0.8
   10 |   1.1681 |     40.123 |   1.1645 |     40.861 |     0.9
   11 |   1.1515 |     39.269 |   1.1591 |     39.901 |     1.0
   12 |   1.1305 |     38.586 |   1.1664 |     40.056 |     1.1
   13 |   1.1197 |     38.002 |   1.1426 |     40.211 |     1.2
   14 |   1.1088 |     37.864 |   1.1128 |     39.219 |     1.2
   15 |   1.0884 |     37.169 |   1.1275 |     38.755 |     1.3
   16 |   1.0813 |     36.850 |   1.1101 |     39.095 |     1.4
   17 |   1.0638 |     36.348 |   1.1229 |     38.631 |     1.5
   18 |   1.0540 |     36.017 |   1.1094 |     38.848 |     1.6
   19 |   1.0419 |     35.599 |   1.1069 |     38.228 |     1.7
   20 |   1.0303 |     35.185 |   1.0822 |     37.794 |     1.8
   21 |   1.0217 |     35.020 |   1.0870 |     37.918 |     1.9
   22 |   1.0061 |     34.237 |   1.0731 |     37.515 |     2.0
   23 |   1.0018 |     34.149 |   1.0770 |     36.989 |     2.0
   24 |   0.9880 |     33.603 |   1.0673 |     36.772 |     2.1
   25 |   0.9800 |     33.372 |   1.0405 |     35.688 |     2.2
   26 |   0.9649 |     33.091 |   1.0569 |     36.214 |     2.3
   27 |   0.9557 |     32.600 |   1.0392 |     35.595 |     2.4
   28 |   0.9481 |     32.270 |   1.0341 |     35.223 |     2.5
   29 |   0.9286 |     31.729 |   1.0381 |     35.378 |     2.6
   30 |   0.9266 |     31.652 |   1.0517 |     36.214 |     2.7
   31 |   0.9146 |     31.162 |   1.0388 |     35.626 |     2.8
   32 |   0.9025 |     30.605 |   1.0275 |     35.068 |     2.8
   33 |   0.8980 |     30.506 |   1.0278 |     34.696 |     2.9
   34 |   0.8845 |     30.104 |   1.0132 |     34.789 |     3.0
   35 |   0.8763 |     29.927 |   1.0446 |     35.223 |     3.1
   36 |   0.8677 |     29.933 |   1.0056 |     34.108 |     3.2
   37 |   0.8557 |     29.123 |   1.0029 |     34.170 |     3.3
   38 |   0.8518 |     28.687 |   0.9990 |     33.333 |     3.4
   39 |   0.8409 |     28.616 |   1.0278 |     34.851 |     3.5
   40 |   0.8327 |     28.125 |   1.0444 |     34.572 |     3.6
   41 |   0.8236 |     27.894 |   1.0164 |     34.139 |     3.7
   42 |   0.8224 |     28.153 |   1.0311 |     34.263 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 732,130

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6175 |     48.396 |   1.3119 |     44.857 |     0.1
    2 |   1.2881 |     43.144 |   1.2319 |     42.782 |     0.2
    3 |   1.2189 |     41.678 |   1.1887 |     41.047 |     0.3
    4 |   1.1787 |     40.658 |   1.1743 |     43.340 |     0.3
    5 |   1.1338 |     39.286 |   1.1072 |     39.157 |     0.4
    6 |   1.0863 |     36.982 |   1.0823 |     38.321 |     0.5
    7 |   1.0540 |     36.315 |   1.0735 |     37.237 |     0.6
    8 |   1.0329 |     35.499 |   1.0604 |     37.546 |     0.7
    9 |   0.9956 |     34.144 |   1.0506 |     36.245 |     0.8
   10 |   0.9522 |     33.014 |   1.0243 |     36.400 |     0.9
   11 |   0.9438 |     32.457 |   1.0468 |     37.546 |     1.0
   12 |   0.9131 |     31.713 |   1.0290 |     35.998 |     1.1
   13 |   0.8837 |     30.489 |   1.0171 |     35.037 |     1.1
   14 |   0.8619 |     29.657 |   0.9932 |     33.426 |     1.2
   15 |   0.8409 |     28.946 |   1.0256 |     34.418 |     1.3
   16 |   0.8178 |     28.241 |   1.0378 |     34.634 |     1.4
   17 |   0.7794 |     26.929 |   1.0058 |     32.714 |     1.5
   18 |   0.7650 |     26.560 |   0.9866 |     32.776 |     1.6
   19 |   0.7435 |     25.970 |   1.0332 |     34.480 |     1.7
   20 |   0.7198 |     24.895 |   1.0457 |     33.426 |     1.8
   21 |   0.6959 |     24.096 |   1.0347 |     32.807 |     1.8
   22 |   0.6743 |     23.280 |   1.0265 |     32.280 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 582,690

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5247 |     47.007 |   1.2574 |     42.503 |     0.1
    2 |   1.2046 |     41.452 |   1.1783 |     40.954 |     0.2
    3 |   1.1210 |     38.707 |   1.1205 |     39.529 |     0.3
    4 |   1.0655 |     36.717 |   1.0839 |     38.290 |     0.4
    5 |   1.0058 |     34.116 |   1.0553 |     36.214 |     0.5
    6 |   0.9515 |     32.115 |   1.0216 |     34.820 |     0.6
    7 |   0.8956 |     30.429 |   1.0749 |     35.688 |     0.6
    8 |   0.8498 |     29.073 |   1.0181 |     34.480 |     0.7
    9 |   0.7858 |     26.758 |   1.0155 |     33.364 |     0.8
   10 |   0.7358 |     25.182 |   1.0059 |     33.736 |     0.9
   11 |   0.6843 |     23.242 |   1.0298 |     33.024 |     1.0
   12 |   0.6340 |     21.572 |   1.0204 |     32.311 |     1.1
   13 |   0.5894 |     20.018 |   1.0423 |     32.931 |     1.2
   14 |   0.5393 |     18.436 |   1.1153 |     32.621 |     1.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 978,850

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5382 |     47.707 |   1.3094 |     46.252 |     0.1
    2 |   1.2918 |     44.334 |   1.2559 |     44.579 |     0.2
    3 |   1.2383 |     42.940 |   1.2006 |     42.193 |     0.3
    4 |   1.1876 |     41.909 |   1.1649 |     41.605 |     0.4
    5 |   1.1449 |     40.157 |   1.1517 |     41.884 |     0.5
    6 |   1.1271 |     39.583 |   1.1314 |     39.839 |     0.6
    7 |   1.0847 |     38.084 |   1.0925 |     38.228 |     0.6
    8 |   1.0589 |     36.861 |   1.0972 |     38.693 |     0.7
    9 |   1.0335 |     35.830 |   1.0771 |     37.082 |     0.8
   10 |   1.0093 |     35.334 |   1.0419 |     35.874 |     0.9
   11 |   0.9848 |     34.507 |   1.0426 |     36.803 |     1.0
   12 |   0.9681 |     33.857 |   1.0419 |     36.059 |     1.1
   13 |   0.9371 |     32.518 |   1.0676 |     36.555 |     1.2
   14 |   0.9124 |     31.867 |   1.0594 |     36.307 |     1.3
   15 |   0.8974 |     31.184 |   1.0392 |     35.812 |     1.4
   16 |   0.8578 |     30.032 |   1.0379 |     35.502 |     1.5
   17 |   0.8321 |     29.150 |   1.0304 |     33.922 |     1.6
   18 |   0.8179 |     28.555 |   1.0657 |     36.462 |     1.7
   19 |   0.7879 |     27.381 |   1.0766 |     34.170 |     1.8
   20 |   0.7575 |     26.527 |   1.0296 |     33.426 |     1.8
   21 |   0.7438 |     25.854 |   1.0411 |     33.643 |     1.9
   22 |   0.7211 |     24.972 |   1.0528 |     34.418 |     2.0
   23 |   0.7010 |     24.399 |   1.0936 |     34.511 |     2.1
   24 |   0.6747 |     23.887 |   1.0645 |     33.395 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 343,394

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6367 |     47.856 |   1.3378 |     44.207 |     0.1
    2 |   1.2760 |     43.816 |   1.2446 |     43.742 |     0.3
    3 |   1.2104 |     42.455 |   1.2095 |     43.742 |     0.4
    4 |   1.1723 |     42.003 |   1.1852 |     42.627 |     0.6
    5 |   1.1485 |     41.584 |   1.1505 |     41.760 |     0.7
    6 |   1.1289 |     41.176 |   1.1395 |     40.768 |     0.9
    7 |   1.1162 |     40.504 |   1.1356 |     42.100 |     1.0
    8 |   1.1020 |     40.278 |   1.1269 |     39.839 |     1.1
    9 |   1.0969 |     40.526 |   1.1088 |     40.923 |     1.3
   10 |   1.0891 |     40.327 |   1.1260 |     41.450 |     1.4
   11 |   1.0836 |     40.349 |   1.1299 |     40.799 |     1.6
   12 |   1.0768 |     40.112 |   1.1071 |     39.901 |     1.7
   13 |   1.0739 |     40.168 |   1.1030 |     41.419 |     1.9
   14 |   1.0727 |     40.090 |   1.1022 |     40.366 |     2.0
   15 |   1.0681 |     40.184 |   1.1175 |     41.295 |     2.1
   16 |   1.0642 |     40.184 |   1.1001 |     41.078 |     2.3
   17 |   1.0639 |     39.903 |   1.1031 |     41.729 |     2.4
   18 |   1.0614 |     40.085 |   1.1029 |     41.047 |     2.6
   19 |   1.0606 |     39.909 |   1.0882 |     40.830 |     2.7
   20 |   1.0603 |     40.046 |   1.0924 |     40.273 |     2.9
   21 |   1.0591 |     39.517 |   1.0935 |     39.343 |     3.0
   22 |   1.0585 |     39.903 |   1.0948 |     39.994 |     3.1
   23 |   1.0550 |     39.804 |   1.0880 |     39.901 |     3.3
   24 |   1.0523 |     39.716 |   1.0953 |     40.892 |     3.4
   25 |   1.0529 |     39.925 |   1.0908 |     40.737 |     3.6
   26 |   1.0510 |     39.578 |   1.1037 |     39.839 |     3.7
   27 |   1.0538 |     39.947 |   1.0948 |     41.171 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 748,962

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5775 |     48.016 |   1.3336 |     44.796 |     0.1
    2 |   1.3118 |     44.753 |   1.2652 |     44.486 |     0.3
    3 |   1.2580 |     43.965 |   1.2259 |     43.587 |     0.4
    4 |   1.2261 |     43.293 |   1.2198 |     44.176 |     0.5
    5 |   1.2040 |     43.050 |   1.2203 |     44.176 |     0.7
    6 |   1.1883 |     42.113 |   1.2243 |     44.300 |     0.8
    7 |   1.1779 |     42.030 |   1.1734 |     42.441 |     0.9
    8 |   1.1566 |     41.375 |   1.1981 |     43.340 |     1.1
    9 |   1.1499 |     40.895 |   1.3319 |     46.097 |     1.2
   10 |   1.1483 |     41.165 |   1.3197 |     47.119 |     1.3
   11 |   1.1402 |     41.562 |   1.2124 |     42.906 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 814,370

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9679 |     49.802 |   1.5175 |     44.579 |     0.1
    2 |   1.4236 |     44.511 |   1.3721 |     43.680 |     0.2
    3 |   1.3195 |     43.022 |   1.3208 |     43.835 |     0.3
    4 |   1.2604 |     41.711 |   1.2649 |     42.379 |     0.3
    5 |   1.2095 |     40.382 |   1.2372 |     42.286 |     0.4
    6 |   1.1669 |     39.236 |   1.2299 |     41.202 |     0.5
    7 |   1.1374 |     38.580 |   1.1821 |     40.520 |     0.6
    8 |   1.1030 |     37.654 |   1.1547 |     40.366 |     0.7
    9 |   1.0787 |     36.513 |   1.1221 |     37.949 |     0.8
   10 |   1.0490 |     35.075 |   1.1679 |     40.366 |     0.8
   11 |   1.0268 |     34.535 |   1.0874 |     36.803 |     0.9
   12 |   0.9964 |     33.212 |   1.0920 |     37.763 |     1.0
   13 |   0.9714 |     32.391 |   1.0779 |     36.524 |     1.1
   14 |   0.9500 |     31.658 |   1.0656 |     35.874 |     1.2
   15 |   0.9279 |     30.715 |   1.0649 |     36.307 |     1.3
   16 |   0.9004 |     29.696 |   1.0484 |     36.555 |     1.3
   17 |   0.8769 |     28.891 |   1.0589 |     36.090 |     1.4
   18 |   0.8618 |     28.720 |   1.0404 |     35.006 |     1.5
   19 |   0.8417 |     27.910 |   1.0197 |     34.480 |     1.6
   20 |   0.8119 |     26.857 |   1.0224 |     33.953 |     1.7
   21 |   0.7929 |     26.124 |   1.0530 |     35.254 |     1.8
   22 |   0.7778 |     25.876 |   1.0760 |     35.781 |     1.9
   23 |   0.7513 |     24.807 |   1.0361 |     34.665 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6664 |     66.683 |   2.0590 |     49.473 |     0.1
    2 |   1.7883 |     46.263 |   1.6395 |     46.530 |     0.1
    3 |   1.5512 |     45.144 |   1.5168 |     45.508 |     0.2
    4 |   1.4573 |     44.406 |   1.4477 |     44.734 |     0.2
    5 |   1.4014 |     43.574 |   1.4151 |     45.353 |     0.3
    6 |   1.3634 |     43.045 |   1.3775 |     44.796 |     0.3
    7 |   1.3322 |     42.626 |   1.3663 |     44.765 |     0.4
    8 |   1.3092 |     42.460 |   1.3526 |     44.888 |     0.5
    9 |   1.2876 |     42.405 |   1.3489 |     44.455 |     0.5
   10 |   1.2643 |     41.826 |   1.3170 |     44.765 |     0.6
   11 |   1.2456 |     41.551 |   1.2851 |     43.401 |     0.6
   12 |   1.2280 |     41.242 |   1.2838 |     43.247 |     0.7
   13 |   1.2109 |     40.945 |   1.2651 |     42.720 |     0.8
   14 |   1.1956 |     40.553 |   1.2400 |     42.844 |     0.8
   15 |   1.1804 |     40.101 |   1.2298 |     42.317 |     0.9
   16 |   1.1654 |     39.523 |   1.2417 |     42.131 |     0.9
   17 |   1.1519 |     39.049 |   1.2208 |     41.822 |     1.0
   18 |   1.1407 |     38.812 |   1.2039 |     40.954 |     1.0
   19 |   1.1282 |     38.172 |   1.2046 |     41.884 |     1.1
   20 |   1.1153 |     37.676 |   1.1915 |     41.760 |     1.2
   21 |   1.1045 |     37.434 |   1.1712 |     40.954 |     1.2
   22 |   1.0932 |     36.965 |   1.1804 |     41.171 |     1.3
   23 |   1.0793 |     36.563 |   1.1567 |     40.582 |     1.3
   24 |   1.0694 |     36.254 |   1.1638 |     41.388 |     1.4
   25 |   1.0574 |     35.659 |   1.1481 |     40.056 |     1.4
   26 |   1.0445 |     35.240 |   1.1643 |     40.180 |     1.5
   27 |   1.0343 |     34.926 |   1.1423 |     39.994 |     1.6
   28 |   1.0222 |     34.518 |   1.1260 |     39.312 |     1.6
   29 |   1.0161 |     34.298 |   1.1539 |     40.892 |     1.7
   30 |   1.0023 |     33.912 |   1.1468 |     39.560 |     1.7
   31 |   0.9932 |     33.631 |   1.1279 |     39.219 |     1.8
   32 |   0.9805 |     33.080 |   1.1324 |     38.879 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 978,850

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4819 |     47.013 |   1.2969 |     45.012 |     0.1
    2 |   1.2197 |     42.389 |   1.1859 |     42.224 |     0.2
    3 |   1.1418 |     39.925 |   1.1485 |     40.613 |     0.3
    4 |   1.0900 |     38.393 |   1.0976 |     38.662 |     0.3
    5 |   1.0409 |     36.778 |   1.0576 |     36.896 |     0.4
    6 |   1.0074 |     35.588 |   1.0697 |     38.414 |     0.5
    7 |   0.9800 |     34.579 |   1.0410 |     36.710 |     0.6
    8 |   0.9561 |     33.725 |   1.0363 |     36.772 |     0.7
    9 |   0.9277 |     32.485 |   1.0167 |     36.214 |     0.8
   10 |   0.8943 |     31.437 |   1.0214 |     35.502 |     0.9
   11 |   0.8788 |     30.996 |   0.9898 |     34.603 |     1.0
   12 |   0.8513 |     29.993 |   1.0041 |     34.727 |     1.0
   13 |   0.8165 |     28.445 |   1.0163 |     34.418 |     1.1
   14 |   0.7931 |     27.899 |   1.0153 |     34.665 |     1.2
   15 |   0.7582 |     26.637 |   1.0047 |     33.736 |     1.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 292,258

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7385 |     63.701 |   1.9934 |     49.009 |     0.1
    2 |   1.9278 |     46.847 |   1.6424 |     45.880 |     0.2
    3 |   1.6720 |     46.087 |   1.5267 |     45.880 |     0.3
    4 |   1.5623 |     45.899 |   1.4558 |     45.880 |     0.4
    5 |   1.4994 |     45.833 |   1.4153 |     45.880 |     0.4
    6 |   1.4535 |     45.448 |   1.3882 |     46.685 |     0.5
    7 |   1.4221 |     45.547 |   1.3568 |     44.579 |     0.6
    8 |   1.3934 |     45.238 |   1.3371 |     44.083 |     0.7
    9 |   1.3704 |     44.880 |   1.3187 |     44.114 |     0.8
   10 |   1.3497 |     44.687 |   1.3120 |     44.052 |     0.9
   11 |   1.3317 |     44.472 |   1.2913 |     44.083 |     1.0
   12 |   1.3178 |     43.993 |   1.2750 |     43.525 |     1.1
   13 |   1.3004 |     43.844 |   1.2656 |     43.061 |     1.1
   14 |   1.2910 |     43.546 |   1.2575 |     43.247 |     1.2
   15 |   1.2761 |     43.188 |   1.2578 |     44.486 |     1.3
   16 |   1.2712 |     43.039 |   1.2565 |     44.362 |     1.4
   17 |   1.2555 |     42.642 |   1.2462 |     43.804 |     1.5
   18 |   1.2482 |     42.361 |   1.2294 |     42.937 |     1.6
   19 |   1.2392 |     42.163 |   1.2404 |     43.618 |     1.7
   20 |   1.2315 |     41.782 |   1.2257 |     43.185 |     1.8
   21 |   1.2226 |     41.336 |   1.2284 |     43.092 |     1.9
   22 |   1.2165 |     41.275 |   1.2272 |     42.720 |     1.9
   23 |   1.2112 |     40.983 |   1.2274 |     42.658 |     2.0
   24 |   1.2007 |     40.757 |   1.2176 |     42.348 |     2.1
   25 |   1.1958 |     40.515 |   1.2205 |     42.100 |     2.2
   26 |   1.1887 |     40.509 |   1.2231 |     42.441 |     2.3
   27 |   1.1823 |     40.344 |   1.2102 |     41.945 |     2.4
   28 |   1.1755 |     40.057 |   1.2056 |     42.007 |     2.5
   29 |   1.1703 |     39.809 |   1.2189 |     42.348 |     2.6
   30 |   1.1607 |     39.545 |   1.2205 |     42.193 |     2.7
   31 |   1.1608 |     39.473 |   1.1996 |     41.016 |     2.7
   32 |   1.1534 |     39.479 |   1.2045 |     41.574 |     2.8
   33 |   1.1464 |     39.115 |   1.2066 |     41.698 |     2.9
   34 |   1.1455 |     39.357 |   1.2118 |     41.822 |     3.0
   35 |   1.1323 |     38.514 |   1.2004 |     41.202 |     3.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 881,570

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4112 |     61.524 |   1.6305 |     47.119 |     0.1
    2 |   1.5638 |     46.197 |   1.4190 |     45.570 |     0.2
    3 |   1.4211 |     45.762 |   1.3386 |     44.083 |     0.3
    4 |   1.3534 |     44.544 |   1.2912 |     42.937 |     0.4
    5 |   1.3125 |     43.348 |   1.2632 |     42.689 |     0.5
    6 |   1.2784 |     42.642 |   1.2414 |     42.286 |     0.6
    7 |   1.2525 |     41.645 |   1.2333 |     42.379 |     0.7
    8 |   1.2215 |     40.840 |   1.1931 |     40.954 |     0.8
    9 |   1.1991 |     40.256 |   1.1831 |     41.047 |     0.9
   10 |   1.1801 |     39.705 |   1.1835 |     41.450 |     1.0
   11 |   1.1631 |     39.269 |   1.1732 |     41.233 |     1.1
   12 |   1.1480 |     38.795 |   1.1629 |     40.335 |     1.2
   13 |   1.1344 |     38.409 |   1.1459 |     39.963 |     1.3
   14 |   1.1180 |     37.974 |   1.1424 |     39.901 |     1.4
   15 |   1.1065 |     37.594 |   1.1231 |     39.219 |     1.4
   16 |   1.0961 |     37.483 |   1.1209 |     39.374 |     1.5
   17 |   1.0806 |     36.723 |   1.1189 |     39.095 |     1.6
   18 |   1.0652 |     36.155 |   1.1350 |     39.467 |     1.7
   19 |   1.0534 |     35.505 |   1.1041 |     38.507 |     1.8
   20 |   1.0417 |     35.466 |   1.0933 |     36.865 |     1.9
   21 |   1.0306 |     34.667 |   1.0813 |     36.865 |     2.0
   22 |   1.0171 |     34.309 |   1.0872 |     37.732 |     2.1
   23 |   1.0054 |     33.736 |   1.0646 |     36.276 |     2.2
   24 |   0.9944 |     33.333 |   1.0646 |     36.493 |     2.3
   25 |   0.9858 |     33.333 |   1.0444 |     35.936 |     2.4
   26 |   0.9711 |     32.683 |   1.0454 |     35.316 |     2.5
   27 |   0.9575 |     32.248 |   1.0609 |     35.936 |     2.6
   28 |   0.9519 |     31.801 |   1.0669 |     36.183 |     2.7
   29 |   0.9390 |     31.812 |   1.0364 |     34.511 |     2.8
   30 |   0.9240 |     31.035 |   1.0398 |     35.130 |     2.9
   31 |   0.9197 |     30.710 |   1.0261 |     34.634 |     3.0
   32 |   0.9048 |     30.473 |   1.0181 |     34.603 |     3.1
   33 |   0.9002 |     30.142 |   1.0447 |     34.727 |     3.2
   34 |   0.8879 |     29.922 |   1.0313 |     34.325 |     3.3
   35 |   0.8781 |     29.530 |   1.0289 |     34.201 |     3.4
   36 |   0.8613 |     29.040 |   1.0299 |     34.294 |     3.5
   37 |   0.8627 |     29.073 |   1.0086 |     34.634 |     3.6
   38 |   0.8545 |     28.604 |   1.0058 |     33.364 |     3.7
   39 |   0.8408 |     27.772 |   1.0064 |     33.612 |     3.8
   40 |   0.8312 |     27.987 |   1.0214 |     33.953 |     3.9
   41 |   0.8209 |     27.690 |   1.0172 |     33.705 |     4.0
   42 |   0.8186 |     27.337 |   1.0105 |     33.086 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 292,258

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6548 |     47.542 |   1.3404 |     44.486 |     0.1
    2 |   1.2639 |     42.730 |   1.2856 |     43.649 |     0.2
    3 |   1.1899 |     41.226 |   1.1808 |     41.512 |     0.2
    4 |   1.1382 |     39.870 |   1.1325 |     40.861 |     0.3
    5 |   1.0930 |     38.476 |   1.0981 |     38.631 |     0.4
    6 |   1.0444 |     36.585 |   1.0689 |     37.856 |     0.5
    7 |   1.0104 |     35.455 |   1.0688 |     36.617 |     0.6
    8 |   0.9780 |     33.824 |   1.0622 |     37.546 |     0.6
    9 |   0.9441 |     32.556 |   1.0237 |     35.750 |     0.7
   10 |   0.9212 |     32.016 |   1.0294 |     36.090 |     0.8
   11 |   0.8821 |     30.649 |   1.0210 |     35.967 |     0.9
   12 |   0.8551 |     29.707 |   1.0141 |     34.634 |     1.0
   13 |   0.8309 |     28.759 |   0.9796 |     33.302 |     1.1
   14 |   0.7941 |     27.348 |   0.9914 |     33.519 |     1.1
   15 |   0.7689 |     26.416 |   0.9863 |     32.807 |     1.2
   16 |   0.7409 |     25.761 |   0.9853 |     33.240 |     1.3
   17 |   0.7104 |     24.691 |   0.9742 |     32.373 |     1.4
   18 |   0.6929 |     24.030 |   1.0211 |     33.519 |     1.5
   19 |   0.6606 |     23.016 |   1.0326 |     33.922 |     1.5
   20 |   0.6367 |     21.974 |   1.0113 |     32.373 |     1.6
   21 |   0.6155 |     21.059 |   1.0013 |     31.815 |     1.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 327,586

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9618 |     54.834 |   1.4093 |     45.880 |     0.1
    2 |   1.4122 |     46.103 |   1.3549 |     45.477 |     0.2
    3 |   1.3593 |     45.536 |   1.3087 |     44.641 |     0.3
    4 |   1.3207 |     45.023 |   1.2724 |     43.494 |     0.4
    5 |   1.2913 |     44.626 |   1.2481 |     43.556 |     0.6
    6 |   1.2691 |     44.031 |   1.2218 |     44.269 |     0.7
    7 |   1.2453 |     43.695 |   1.2003 |     42.720 |     0.8
    8 |   1.2294 |     43.248 |   1.1851 |     41.574 |     0.9
    9 |   1.2158 |     42.719 |   1.1635 |     41.109 |     1.0
   10 |   1.1979 |     42.086 |   1.1667 |     41.945 |     1.1
   11 |   1.1836 |     41.452 |   1.1623 |     39.994 |     1.2
   12 |   1.1671 |     41.204 |   1.1362 |     39.250 |     1.3
   13 |   1.1598 |     40.658 |   1.1485 |     40.273 |     1.5
   14 |   1.1468 |     40.460 |   1.1237 |     39.529 |     1.6
   15 |   1.1342 |     39.864 |   1.1398 |     39.095 |     1.7
   16 |   1.1204 |     39.616 |   1.1191 |     40.923 |     1.8
   17 |   1.1177 |     39.313 |   1.1333 |     39.281 |     1.9
   18 |   1.1106 |     39.082 |   1.1314 |     39.622 |     2.0
   19 |   1.0957 |     38.365 |   1.0819 |     38.538 |     2.1
   20 |   1.0942 |     38.465 |   1.0991 |     38.383 |     2.3
   21 |   1.0809 |     38.068 |   1.0801 |     38.569 |     2.4
   22 |   1.0752 |     38.233 |   1.0913 |     38.755 |     2.5
   23 |   1.0656 |     37.720 |   1.0823 |     38.321 |     2.6
   24 |   1.0562 |     36.943 |   1.0708 |     37.330 |     2.7
   25 |   1.0506 |     37.219 |   1.0587 |     37.268 |     2.8
   26 |   1.0333 |     36.502 |   1.0575 |     37.577 |     2.9
   27 |   1.0265 |     36.310 |   1.0543 |     37.051 |     3.0
   28 |   1.0266 |     36.017 |   1.0534 |     37.051 |     3.2
   29 |   1.0132 |     35.753 |   1.0689 |     37.763 |     3.3
   30 |   1.0053 |     35.483 |   1.0615 |     36.772 |     3.4
   31 |   0.9937 |     34.816 |   1.0328 |     35.595 |     3.5
   32 |   0.9792 |     34.276 |   1.0532 |     37.299 |     3.6
   33 |   0.9763 |     34.700 |   1.0517 |     36.431 |     3.7
   34 |   0.9633 |     33.796 |   1.0335 |     35.998 |     3.8
   35 |   0.9600 |     33.752 |   1.0350 |     35.564 |     3.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 780,066

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5682 |     47.928 |   1.2999 |     44.796 |     0.1
    2 |   1.2915 |     43.717 |   1.2310 |     43.525 |     0.2
    3 |   1.2312 |     42.345 |   1.1855 |     41.791 |     0.3
    4 |   1.1882 |     40.868 |   1.1506 |     40.489 |     0.4
    5 |   1.1494 |     39.732 |   1.1374 |     40.520 |     0.5
    6 |   1.1181 |     38.630 |   1.1001 |     39.281 |     0.6
    7 |   1.0909 |     38.167 |   1.0808 |     38.445 |     0.7
    8 |   1.0601 |     36.811 |   1.0924 |     39.157 |     0.8
    9 |   1.0393 |     35.802 |   1.0471 |     37.175 |     0.9
   10 |   1.0171 |     35.643 |   1.0697 |     37.144 |     1.0
   11 |   0.9855 |     34.485 |   1.0526 |     36.803 |     1.1
   12 |   0.9596 |     33.554 |   1.0529 |     36.989 |     1.2
   13 |   0.9403 |     32.457 |   1.0490 |     35.285 |     1.3
   14 |   0.9166 |     31.878 |   1.0371 |     36.090 |     1.4
   15 |   0.8931 |     30.930 |   1.0157 |     34.387 |     1.6
   16 |   0.8642 |     30.004 |   1.0606 |     34.944 |     1.7
   17 |   0.8421 |     29.227 |   1.0812 |     35.502 |     1.8
   18 |   0.8211 |     28.345 |   1.0798 |     35.037 |     1.9
   19 |   0.7955 |     27.447 |   1.1023 |     35.440 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 648,482

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1396 |     52.938 |   1.5630 |     45.260 |     0.1
    2 |   1.4554 |     45.332 |   1.3915 |     43.928 |     0.2
    3 |   1.3399 |     43.695 |   1.3224 |     44.486 |     0.3
    4 |   1.2768 |     41.986 |   1.2819 |     42.379 |     0.4
    5 |   1.2292 |     40.559 |   1.2357 |     41.914 |     0.5
    6 |   1.1884 |     39.677 |   1.2112 |     41.419 |     0.6
    7 |   1.1576 |     39.038 |   1.1979 |     40.737 |     0.7
    8 |   1.1281 |     37.985 |   1.1650 |     40.737 |     0.7
    9 |   1.1025 |     37.120 |   1.1454 |     39.653 |     0.8
   10 |   1.0823 |     36.635 |   1.1388 |     39.715 |     0.9
   11 |   1.0583 |     35.698 |   1.1276 |     39.157 |     1.0
   12 |   1.0345 |     34.651 |   1.1218 |     38.662 |     1.1
   13 |   1.0121 |     33.791 |   1.1094 |     38.352 |     1.2
   14 |   0.9911 |     33.438 |   1.0851 |     37.608 |     1.3
   15 |   0.9717 |     32.418 |   1.0900 |     37.515 |     1.4
   16 |   0.9518 |     31.862 |   1.0595 |     36.462 |     1.5
   17 |   0.9344 |     31.448 |   1.0620 |     36.183 |     1.6
   18 |   0.9120 |     30.297 |   1.0561 |     37.268 |     1.7
   19 |   0.8890 |     29.530 |   1.0350 |     35.843 |     1.8
   20 |   0.8734 |     29.200 |   1.0564 |     36.152 |     1.9
   21 |   0.8545 |     28.693 |   1.0621 |     36.772 |     2.0
   22 |   0.8310 |     27.728 |   1.0463 |     36.029 |     2.0
   23 |   0.8130 |     27.094 |   1.0382 |     35.781 |     2.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,047,842

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9820 |     52.651 |   1.4847 |     45.291 |     0.1
    2 |   1.4082 |     44.158 |   1.3709 |     44.114 |     0.3
    3 |   1.3168 |     42.328 |   1.3189 |     42.627 |     0.4
    4 |   1.2551 |     40.691 |   1.2895 |     42.999 |     0.6
    5 |   1.2113 |     39.870 |   1.2817 |     43.371 |     0.7
    6 |   1.1743 |     39.269 |   1.2258 |     41.791 |     0.8
    7 |   1.1385 |     37.869 |   1.2021 |     41.109 |     1.0
    8 |   1.1047 |     36.701 |   1.2107 |     42.658 |     1.1
    9 |   1.0744 |     35.736 |   1.1868 |     40.149 |     1.3
   10 |   1.0449 |     34.965 |   1.2079 |     41.109 |     1.4
   11 |   1.0172 |     33.763 |   1.1572 |     39.591 |     1.6
   12 |   0.9932 |     32.887 |   1.1632 |     39.560 |     1.7
   13 |   0.9637 |     31.680 |   1.1199 |     38.259 |     1.8
   14 |   0.9428 |     31.355 |   1.1110 |     37.515 |     2.0
   15 |   0.9153 |     30.263 |   1.1166 |     37.113 |     2.1
   16 |   0.8922 |     29.624 |   1.1265 |     37.546 |     2.3
   17 |   0.8668 |     28.588 |   1.1002 |     36.648 |     2.4
   18 |   0.8388 |     27.596 |   1.1140 |     36.834 |     2.5
   19 |   0.8251 |     27.728 |   1.1008 |     36.648 |     2.7
   20 |   0.7982 |     26.422 |   1.1233 |     37.392 |     2.8
   21 |   0.7780 |     25.750 |   1.1044 |     35.998 |     3.0
   22 |   0.7495 |     24.664 |   1.0931 |     35.874 |     3.1
   23 |   0.7351 |     24.234 |   1.1303 |     36.152 |     3.3
   24 |   0.7121 |     23.523 |   1.1131 |     36.245 |     3.4
   25 |   0.6878 |     22.696 |   1.1010 |     34.944 |     3.5
   26 |   0.6692 |     21.847 |   1.1299 |     35.843 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 327,586

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7655 |     68.783 |   2.0156 |     46.654 |     0.2
    2 |   1.9000 |     46.842 |   1.6326 |     45.725 |     0.3
    3 |   1.6450 |     46.004 |   1.5250 |     46.654 |     0.5
    4 |   1.5473 |     45.844 |   1.4647 |     45.291 |     0.6
    5 |   1.4889 |     45.916 |   1.4246 |     45.384 |     0.8
    6 |   1.4478 |     45.624 |   1.3895 |     45.322 |     1.0
    7 |   1.4095 |     45.332 |   1.3627 |     44.455 |     1.1
    8 |   1.3867 |     44.985 |   1.3401 |     44.548 |     1.3
    9 |   1.3642 |     44.577 |   1.3246 |     43.680 |     1.5
   10 |   1.3424 |     44.367 |   1.3191 |     44.796 |     1.6
   11 |   1.3233 |     43.783 |   1.3061 |     44.548 |     1.8
   12 |   1.3063 |     43.623 |   1.2950 |     44.888 |     1.9
   13 |   1.2931 |     43.452 |   1.2781 |     43.185 |     2.1
   14 |   1.2775 |     42.587 |   1.2610 |     43.680 |     2.3
   15 |   1.2653 |     42.466 |   1.2514 |     43.154 |     2.4
   16 |   1.2505 |     42.234 |   1.2439 |     42.720 |     2.6
   17 |   1.2434 |     42.008 |   1.2324 |     42.782 |     2.7
   18 |   1.2302 |     41.507 |   1.2258 |     42.503 |     2.9
   19 |   1.2190 |     41.369 |   1.2134 |     41.481 |     3.1
   20 |   1.2113 |     40.961 |   1.2060 |     41.574 |     3.2
   21 |   1.1968 |     40.664 |   1.1917 |     41.109 |     3.4
   22 |   1.1909 |     40.184 |   1.1962 |     41.295 |     3.6
   23 |   1.1858 |     40.294 |   1.1868 |     40.985 |     3.7
   24 |   1.1730 |     39.820 |   1.1739 |     40.551 |     3.9
   25 |   1.1653 |     39.479 |   1.1786 |     41.233 |     4.0
   26 |   1.1576 |     39.457 |   1.1730 |     40.830 |     4.2
   27 |   1.1490 |     38.983 |   1.1656 |     40.799 |     4.4
   28 |   1.1478 |     39.319 |   1.1536 |     40.520 |     4.5
   29 |   1.1350 |     38.817 |   1.1491 |     39.994 |     4.7
   30 |   1.1327 |     38.465 |   1.1579 |     40.675 |     4.8
   31 |   1.1272 |     38.360 |   1.1453 |     40.242 |     5.0
   32 |   1.1172 |     38.079 |   1.1376 |     39.746 |     5.2
   33 |   1.1121 |     37.902 |   1.1488 |     39.777 |     5.3
   34 |   1.1048 |     37.649 |   1.1317 |     39.250 |     5.5
   35 |   1.0999 |     37.235 |   1.1349 |     39.932 |     5.7
   36 |   1.0913 |     37.313 |   1.1274 |     39.188 |     5.8
   37 |   1.0821 |     36.728 |   1.1353 |     39.002 |     6.0
   38 |   1.0843 |     36.772 |   1.1278 |     39.219 |     6.1
   39 |   1.0729 |     36.679 |   1.1034 |     38.197 |     6.3
   40 |   1.0712 |     36.326 |   1.1169 |     38.600 |     6.5
   41 |   1.0647 |     36.436 |   1.1294 |     38.569 |     6.6
   42 |   1.0600 |     35.825 |   1.1197 |     38.755 |     6.8
   43 |   1.0565 |     36.078 |   1.1106 |     38.507 |     6.9
   44 |   1.0498 |     35.560 |   1.0897 |     37.608 |     7.1
   45 |   1.0424 |     35.521 |   1.1096 |     38.228 |     7.3
   46 |   1.0368 |     35.042 |   1.1161 |     38.290 |     7.4
   47 |   1.0347 |     35.180 |   1.0810 |     37.670 |     7.6
   48 |   1.0257 |     34.849 |   1.1023 |     38.197 |     7.7
   49 |   1.0207 |     34.816 |   1.1134 |     38.631 |     7.9
   50 |   1.0146 |     34.629 |   1.0911 |     37.763 |     8.1
   51 |   1.0102 |     34.182 |   1.0936 |     37.701 |     8.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 285,602

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6153 |     63.762 |   2.0188 |     48.017 |     0.1
    2 |   1.7672 |     45.536 |   1.6408 |     45.849 |     0.3
    3 |   1.5544 |     45.481 |   1.5142 |     45.725 |     0.4
    4 |   1.4610 |     45.139 |   1.4465 |     45.198 |     0.6
    5 |   1.3999 |     43.783 |   1.3941 |     43.463 |     0.7
    6 |   1.3526 |     43.122 |   1.3641 |     43.959 |     0.8
    7 |   1.3184 |     42.604 |   1.3245 |     42.999 |     1.0
    8 |   1.2892 |     41.810 |   1.3005 |     42.565 |     1.1
    9 |   1.2652 |     41.143 |   1.2781 |     42.689 |     1.3
   10 |   1.2403 |     40.333 |   1.2604 |     41.171 |     1.4
   11 |   1.2188 |     39.672 |   1.2555 |     42.472 |     1.5
   12 |   1.1974 |     39.424 |   1.2299 |     41.357 |     1.7
   13 |   1.1797 |     38.779 |   1.2198 |     41.450 |     1.8
   14 |   1.1648 |     38.757 |   1.2160 |     40.892 |     2.0
   15 |   1.1460 |     38.062 |   1.2044 |     41.729 |     2.1
   16 |   1.1296 |     37.616 |   1.1820 |     40.985 |     2.3
   17 |   1.1131 |     37.280 |   1.1827 |     40.211 |     2.4
   18 |   1.1010 |     36.954 |   1.1801 |     39.808 |     2.5
   19 |   1.0888 |     36.365 |   1.1596 |     39.281 |     2.7
   20 |   1.0773 |     36.243 |   1.1549 |     39.343 |     2.8
   21 |   1.0598 |     35.786 |   1.1669 |     39.312 |     3.0
   22 |   1.0486 |     34.904 |   1.1225 |     38.166 |     3.1
   23 |   1.0365 |     34.783 |   1.1505 |     39.064 |     3.2
   24 |   1.0263 |     34.265 |   1.1163 |     37.546 |     3.4
   25 |   1.0131 |     34.011 |   1.1392 |     39.405 |     3.5
   26 |   0.9979 |     33.477 |   1.1221 |     38.693 |     3.7
   27 |   0.9850 |     32.942 |   1.1141 |     37.670 |     3.8
   28 |   0.9788 |     32.755 |   1.1105 |     37.515 |     3.9
   29 |   0.9672 |     32.545 |   1.1002 |     37.763 |     4.1
   30 |   0.9540 |     31.829 |   1.1109 |     37.546 |     4.2
   31 |   0.9431 |     31.448 |   1.1270 |     38.259 |     4.4
   32 |   0.9371 |     31.559 |   1.0925 |     37.299 |     4.5
   33 |   0.9251 |     30.859 |   1.0991 |     37.423 |     4.6
   34 |   0.9147 |     30.682 |   1.0960 |     37.423 |     4.8
   35 |   0.9024 |     30.390 |   1.0875 |     36.555 |     4.9
   36 |   0.8965 |     29.784 |   1.0881 |     37.206 |     5.1
   37 |   0.8847 |     29.464 |   1.0869 |     36.648 |     5.2
   38 |   0.8741 |     28.974 |   1.1054 |     37.113 |     5.3
   39 |   0.8644 |     28.676 |   1.1276 |     37.856 |     5.5
   40 |   0.8557 |     28.274 |   1.0914 |     36.276 |     5.6
   41 |   0.8516 |     28.384 |   1.1138 |     36.989 |     5.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 847,650

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2559 |     58.835 |   1.6190 |     45.818 |     0.2
    2 |   1.4734 |     45.117 |   1.4107 |     45.539 |     0.3
    3 |   1.3532 |     43.855 |   1.3323 |     43.928 |     0.5
    4 |   1.3000 |     43.144 |   1.2915 |     43.401 |     0.6
    5 |   1.2625 |     42.367 |   1.2562 |     42.503 |     0.8
    6 |   1.2254 |     41.127 |   1.2312 |     42.348 |     1.0
    7 |   1.1927 |     39.892 |   1.2224 |     42.379 |     1.1
    8 |   1.1623 |     38.845 |   1.1936 |     41.264 |     1.3
    9 |   1.1393 |     38.393 |   1.1699 |     40.458 |     1.4
   10 |   1.1126 |     37.439 |   1.1544 |     39.467 |     1.6
   11 |   1.0872 |     36.662 |   1.1698 |     40.892 |     1.8
   12 |   1.0624 |     35.731 |   1.1420 |     39.498 |     1.9
   13 |   1.0391 |     35.130 |   1.1340 |     39.281 |     2.1
