Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 226,146

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7502 |     64.840 |   2.0726 |     48.728 |     0.1
    2 |   1.9383 |     47.016 |   1.6670 |     45.452 |     0.2
    3 |   1.6629 |     46.094 |   1.5258 |     45.420 |     0.3
    4 |   1.5474 |     45.666 |   1.4478 |     45.293 |     0.3
    5 |   1.4784 |     45.337 |   1.3997 |     43.925 |     0.4
    6 |   1.4315 |     44.997 |   1.3634 |     43.225 |     0.5
    7 |   1.3970 |     44.514 |   1.3337 |     42.398 |     0.6
    8 |   1.3663 |     43.899 |   1.3122 |     42.844 |     0.7
    9 |   1.3383 |     43.450 |   1.2901 |     42.335 |     0.8
   10 |   1.3206 |     43.197 |   1.2799 |     42.430 |     0.9
   11 |   1.2984 |     42.775 |   1.2630 |     42.017 |     1.0
   12 |   1.2830 |     42.550 |   1.2492 |     41.667 |     1.0
   13 |   1.2659 |     42.330 |   1.2381 |     41.730 |     1.1
   14 |   1.2538 |     42.188 |   1.2339 |     41.762 |     1.2
   15 |   1.2390 |     41.990 |   1.2140 |     41.126 |     1.3
   16 |   1.2233 |     41.156 |   1.2127 |     41.730 |     1.4
   17 |   1.2118 |     41.102 |   1.2060 |     40.617 |     1.5
   18 |   1.2005 |     40.586 |   1.1918 |     40.363 |     1.6
   19 |   1.1892 |     40.339 |   1.1999 |     40.744 |     1.7
   20 |   1.1795 |     40.388 |   1.1842 |     40.553 |     1.8
   21 |   1.1681 |     39.922 |   1.1807 |     40.776 |     1.9
   22 |   1.1590 |     39.286 |   1.1763 |     40.585 |     1.9
   23 |   1.1529 |     39.478 |   1.1723 |     40.744 |     2.0
   24 |   1.1417 |     39.203 |   1.1843 |     41.221 |     2.1
   25 |   1.1337 |     38.765 |   1.1577 |     40.076 |     2.2
   26 |   1.1253 |     38.594 |   1.1604 |     39.695 |     2.3
   27 |   1.1178 |     38.243 |   1.1563 |     40.108 |     2.4
   28 |   1.1089 |     38.249 |   1.1490 |     39.567 |     2.5
   29 |   1.1052 |     37.986 |   1.1360 |     39.472 |     2.6
   30 |   1.0969 |     37.832 |   1.1363 |     39.186 |     2.7
   31 |   1.0886 |     37.179 |   1.1289 |     38.709 |     2.7
   32 |   1.0816 |     37.453 |   1.1355 |     39.281 |     2.8
   33 |   1.0744 |     37.014 |   1.1197 |     38.518 |     2.9
   34 |   1.0685 |     36.910 |   1.1400 |     39.059 |     3.0
   35 |   1.0621 |     36.433 |   1.1373 |     39.472 |     3.1
   36 |   1.0581 |     36.175 |   1.1400 |     38.995 |     3.2
   37 |   1.0490 |     36.087 |   1.1369 |     39.090 |     3.3
   38 |   1.0434 |     35.945 |   1.1189 |     38.454 |     3.4
   39 |   1.0373 |     35.648 |   1.1179 |     38.518 |     3.5
   40 |   1.0328 |     35.456 |   1.1218 |     38.899 |     3.6
   41 |   1.0281 |     35.358 |   1.1324 |     38.804 |     3.6
   42 |   1.0223 |     35.029 |   1.1163 |     38.232 |     3.7
   43 |   1.0166 |     35.100 |   1.1245 |     38.613 |     3.8
   44 |   1.0132 |     35.116 |   1.1243 |     38.613 |     3.9
   45 |   1.0053 |     34.491 |   1.1176 |     38.486 |     4.0
   46 |   1.0010 |     34.365 |   1.1106 |     38.009 |     4.1
   47 |   0.9965 |     34.299 |   1.0946 |     37.754 |     4.2
   48 |   0.9890 |     33.915 |   1.1102 |     37.754 |     4.3
   49 |   0.9844 |     33.849 |   1.1025 |     37.913 |     4.4
   50 |   0.9860 |     34.107 |   1.1036 |     38.136 |     4.5
   51 |   0.9750 |     33.388 |   1.1018 |     37.532 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 525,666

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5027 |     59.271 |   1.7446 |     45.388 |     0.1
    2 |   1.7255 |     46.094 |   1.5358 |     45.388 |     0.2
    3 |   1.5636 |     45.661 |   1.4480 |     43.989 |     0.4
    4 |   1.4840 |     45.419 |   1.3981 |     44.434 |     0.5
    5 |   1.4309 |     45.271 |   1.3591 |     44.434 |     0.6
    6 |   1.3948 |     44.574 |   1.3270 |     43.257 |     0.8
    7 |   1.3635 |     44.223 |   1.3083 |     44.434 |     0.9
    8 |   1.3362 |     44.141 |   1.2968 |     43.702 |     1.0
    9 |   1.3103 |     43.274 |   1.2808 |     43.130 |     1.1
   10 |   1.2930 |     43.164 |   1.2590 |     42.144 |     1.3
   11 |   1.2769 |     42.928 |   1.2579 |     42.144 |     1.4
   12 |   1.2594 |     42.594 |   1.2473 |     42.239 |     1.5
   13 |   1.2468 |     41.886 |   1.2388 |     42.080 |     1.6
   14 |   1.2314 |     41.502 |   1.2259 |     41.476 |     1.8
   15 |   1.2231 |     41.244 |   1.2185 |     41.858 |     1.9
   16 |   1.2108 |     40.849 |   1.2060 |     41.190 |     2.0
   17 |   1.1982 |     40.800 |   1.2333 |     41.698 |     2.1
   18 |   1.1867 |     40.443 |   1.2127 |     41.031 |     2.3
   19 |   1.1748 |     39.911 |   1.2016 |     40.872 |     2.4
   20 |   1.1646 |     39.801 |   1.2196 |     41.158 |     2.5
   21 |   1.1630 |     39.587 |   1.2066 |     40.935 |     2.6
   22 |   1.1495 |     39.363 |   1.2007 |     40.712 |     2.8
   23 |   1.1415 |     39.214 |   1.2305 |     41.253 |     2.9
   24 |   1.1328 |     39.022 |   1.2000 |     41.062 |     3.0
   25 |   1.1219 |     38.381 |   1.2059 |     40.808 |     3.1
   26 |   1.1142 |     38.265 |   1.1748 |     40.108 |     3.3
   27 |   1.1060 |     37.881 |   1.1815 |     40.204 |     3.4
   28 |   1.1004 |     38.353 |   1.2146 |     40.712 |     3.5
   29 |   1.0906 |     37.569 |   1.1881 |     40.363 |     3.6
   30 |   1.0839 |     37.146 |   1.1944 |     40.204 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 235,106

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9482 |     54.438 |   1.3850 |     45.229 |     0.1
    2 |   1.3838 |     45.633 |   1.2969 |     44.116 |     0.1
    3 |   1.3148 |     44.377 |   1.2450 |     43.416 |     0.2
    4 |   1.2699 |     43.110 |   1.2264 |     42.748 |     0.3
    5 |   1.2291 |     42.117 |   1.1814 |     41.412 |     0.3
    6 |   1.2023 |     41.590 |   1.1611 |     40.681 |     0.4
    7 |   1.1817 |     40.707 |   1.1780 |     40.076 |     0.5
    8 |   1.1572 |     39.988 |   1.1261 |     38.709 |     0.6
    9 |   1.1376 |     39.236 |   1.1243 |     38.422 |     0.6
   10 |   1.1148 |     38.309 |   1.1363 |     38.995 |     0.7
   11 |   1.1010 |     38.128 |   1.0813 |     36.864 |     0.8
   12 |   1.0763 |     37.124 |   1.0533 |     36.578 |     0.8
   13 |   1.0623 |     36.811 |   1.0744 |     37.723 |     0.9
   14 |   1.0438 |     36.466 |   1.0493 |     36.768 |     1.0
   15 |   1.0256 |     35.232 |   1.0498 |     35.814 |     1.1
   16 |   1.0093 |     34.809 |   1.0536 |     36.291 |     1.1
   17 |   0.9934 |     34.260 |   1.0287 |     35.019 |     1.2
   18 |   0.9801 |     33.662 |   1.0465 |     35.274 |     1.3
   19 |   0.9630 |     33.004 |   1.0400 |     35.242 |     1.3
   20 |   0.9403 |     32.335 |   1.0522 |     35.115 |     1.4
   21 |   0.9295 |     32.110 |   1.0484 |     35.115 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 814,242

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0053 |     52.090 |   1.4874 |     45.261 |     0.1
    2 |   1.4183 |     44.728 |   1.3626 |     44.593 |     0.2
    3 |   1.3359 |     43.367 |   1.3124 |     44.275 |     0.3
    4 |   1.2807 |     42.380 |   1.2694 |     42.621 |     0.4
    5 |   1.2259 |     40.388 |   1.2534 |     42.430 |     0.5
    6 |   1.1790 |     39.258 |   1.2194 |     41.126 |     0.6
    7 |   1.1380 |     38.364 |   1.1912 |     40.108 |     0.7
    8 |   1.1025 |     37.124 |   1.1849 |     39.090 |     0.8
    9 |   1.0720 |     36.170 |   1.1417 |     37.754 |     0.9
   10 |   1.0389 |     35.089 |   1.1414 |     37.754 |     1.0
   11 |   1.0124 |     34.184 |   1.1560 |     37.818 |     1.2
   12 |   0.9838 |     33.438 |   1.1231 |     37.277 |     1.3
   13 |   0.9513 |     31.863 |   1.1542 |     37.850 |     1.4
   14 |   0.9254 |     31.095 |   1.1189 |     37.214 |     1.5
   15 |   0.8976 |     30.283 |   1.1317 |     37.754 |     1.6
   16 |   0.8727 |     29.235 |   1.1887 |     38.104 |     1.7
   17 |   0.8465 |     28.330 |   1.1060 |     36.514 |     1.8
   18 |   0.8247 |     27.787 |   1.1629 |     38.263 |     1.9
   19 |   0.7971 |     26.437 |   1.1162 |     36.705 |     2.0
   20 |   0.7677 |     25.609 |   1.1700 |     37.468 |     2.1
   21 |   0.7443 |     24.654 |   1.1445 |     37.055 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 814,242

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2705 |     57.746 |   1.5540 |     45.515 |     0.1
    2 |   1.5359 |     46.012 |   1.3817 |     44.688 |     0.2
    3 |   1.4100 |     45.117 |   1.3157 |     44.911 |     0.3
    4 |   1.3462 |     44.294 |   1.2721 |     43.193 |     0.5
    5 |   1.2953 |     42.484 |   1.2365 |     41.571 |     0.6
    6 |   1.2586 |     41.732 |   1.2214 |     41.508 |     0.7
    7 |   1.2310 |     40.932 |   1.1967 |     40.903 |     0.8
    8 |   1.2027 |     40.432 |   1.1701 |     39.822 |     0.9
    9 |   1.1781 |     39.747 |   1.1673 |     39.790 |     1.0
   10 |   1.1575 |     38.754 |   1.1494 |     39.059 |     1.1
   11 |   1.1340 |     38.243 |   1.1339 |     39.281 |     1.2
   12 |   1.1145 |     37.558 |   1.1191 |     37.691 |     1.4
   13 |   1.0956 |     37.053 |   1.1167 |     38.073 |     1.5
   14 |   1.0751 |     36.334 |   1.0999 |     37.723 |     1.6
   15 |   1.0610 |     35.402 |   1.0990 |     37.277 |     1.7
   16 |   1.0463 |     35.242 |   1.0864 |     36.800 |     1.8
   17 |   1.0229 |     34.079 |   1.0940 |     36.387 |     1.9
   18 |   1.0052 |     33.805 |   1.0720 |     36.069 |     2.0
   19 |   0.9906 |     33.416 |   1.0699 |     36.514 |     2.2
   20 |   0.9754 |     32.763 |   1.0707 |     36.164 |     2.3
   21 |   0.9610 |     32.335 |   1.0655 |     36.132 |     2.4
   22 |   0.9447 |     31.496 |   1.0556 |     35.496 |     2.5
   23 |   0.9298 |     30.843 |   1.0464 |     35.592 |     2.6
   24 |   0.9201 |     31.375 |   1.0514 |     35.178 |     2.7
   25 |   0.9025 |     30.481 |   1.0665 |     35.687 |     2.8
   26 |   0.8840 |     29.636 |   1.0692 |     35.814 |     3.0
   27 |   0.8782 |     29.641 |   1.0508 |     34.892 |     3.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 458,914

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4378 |     55.272 |   1.7957 |     45.802 |     0.1
    2 |   1.7371 |     46.269 |   1.5640 |     45.165 |     0.2
    3 |   1.5729 |     45.737 |   1.4734 |     44.816 |     0.3
    4 |   1.4925 |     45.326 |   1.4144 |     44.688 |     0.5
    5 |   1.4389 |     44.887 |   1.3795 |     43.957 |     0.6
    6 |   1.3973 |     44.580 |   1.3367 |     43.448 |     0.7
    7 |   1.3672 |     43.773 |   1.3117 |     42.875 |     0.8
    8 |   1.3361 |     43.466 |   1.2990 |     43.289 |     0.9
    9 |   1.3119 |     42.956 |   1.2980 |     43.734 |     1.1
   10 |   1.2902 |     42.512 |   1.2810 |     43.448 |     1.2
   11 |   1.2724 |     41.941 |   1.2638 |     42.971 |     1.3
   12 |   1.2530 |     41.398 |   1.2504 |     42.303 |     1.4
   13 |   1.2386 |     41.332 |   1.2726 |     43.034 |     1.5
   14 |   1.2248 |     40.707 |   1.2541 |     42.748 |     1.6
   15 |   1.2098 |     40.575 |   1.2536 |     42.176 |     1.8
   16 |   1.1954 |     40.196 |   1.2401 |     41.953 |     1.9
   17 |   1.1831 |     39.928 |   1.2583 |     41.826 |     2.0
   18 |   1.1706 |     39.516 |   1.2345 |     41.253 |     2.1
   19 |   1.1614 |     39.428 |   1.2440 |     41.762 |     2.2
   20 |   1.1502 |     39.379 |   1.1979 |     40.808 |     2.3
   21 |   1.1389 |     38.391 |   1.2258 |     41.730 |     2.5
   22 |   1.1305 |     38.474 |   1.1858 |     39.885 |     2.6
   23 |   1.1210 |     38.018 |   1.2006 |     40.712 |     2.7
   24 |   1.1073 |     37.684 |   1.2017 |     40.967 |     2.8
   25 |   1.1015 |     37.519 |   1.2266 |     40.363 |     2.9
   26 |   1.0903 |     37.179 |   1.1719 |     39.249 |     3.0
   27 |   1.0833 |     36.822 |   1.1640 |     39.218 |     3.2
   28 |   1.0712 |     36.477 |   1.1861 |     39.599 |     3.3
   29 |   1.0616 |     36.005 |   1.1903 |     40.299 |     3.4
   30 |   1.0603 |     36.060 |   1.1701 |     38.995 |     3.5
   31 |   1.0471 |     35.385 |   1.1841 |     39.440 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,013,410

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9990 |     52.930 |   1.4798 |     44.943 |     0.2
    2 |   1.4144 |     44.777 |   1.3572 |     43.543 |     0.3
    3 |   1.3285 |     43.515 |   1.3091 |     44.211 |     0.5
    4 |   1.2707 |     42.473 |   1.2629 |     42.748 |     0.7
    5 |   1.2286 |     40.943 |   1.2381 |     42.716 |     0.9
    6 |   1.1878 |     40.125 |   1.2065 |     40.681 |     1.0
    7 |   1.1500 |     39.055 |   1.1943 |     40.617 |     1.2
    8 |   1.1182 |     37.964 |   1.1669 |     39.377 |     1.4
    9 |   1.0898 |     36.801 |   1.1419 |     38.677 |     1.6
   10 |   1.0600 |     35.983 |   1.1259 |     37.977 |     1.7
   11 |   1.0323 |     34.732 |   1.1370 |     38.836 |     1.9
   12 |   1.0081 |     33.827 |   1.1373 |     38.836 |     2.1
   13 |   0.9868 |     33.503 |   1.1255 |     38.740 |     2.3
   14 |   0.9551 |     32.044 |   1.1459 |     39.345 |     2.4
   15 |   0.9381 |     31.496 |   1.1202 |     38.454 |     2.6
   16 |   0.9063 |     30.426 |   1.1276 |     37.659 |     2.8
   17 |   0.8868 |     29.581 |   1.1274 |     37.246 |     3.0
   18 |   0.8666 |     28.835 |   1.1342 |     39.281 |     3.1
   19 |   0.8516 |     28.473 |   1.1212 |     38.422 |     3.3
   20 |   0.8264 |     27.732 |   1.1201 |     37.500 |     3.5
   21 |   0.8072 |     26.931 |   1.1108 |     37.627 |     3.7
   22 |   0.7849 |     26.097 |   1.1235 |     37.277 |     3.8
   23 |   0.7646 |     25.313 |   1.1608 |     37.500 |     4.0
   24 |   0.7481 |     25.340 |   1.1341 |     37.214 |     4.2
   25 |   0.7311 |     24.325 |   1.1802 |     37.818 |     4.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,047,714

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3132 |     59.343 |   1.5606 |     46.151 |     0.1
    2 |   1.5554 |     45.979 |   1.4004 |     45.674 |     0.3
    3 |   1.4352 |     45.677 |   1.3422 |     43.066 |     0.5
    4 |   1.3810 |     45.150 |   1.3152 |     43.702 |     0.6
    5 |   1.3412 |     44.322 |   1.3007 |     43.989 |     0.8
    6 |   1.3106 |     43.691 |   1.2692 |     43.130 |     0.9
    7 |   1.2812 |     42.720 |   1.2566 |     42.875 |     1.1
    8 |   1.2518 |     41.864 |   1.2302 |     42.398 |     1.2
    9 |   1.2274 |     41.124 |   1.2140 |     41.571 |     1.4
   10 |   1.2075 |     40.537 |   1.2352 |     42.271 |     1.5
   11 |   1.1886 |     39.911 |   1.2302 |     41.858 |     1.7
   12 |   1.1700 |     39.450 |   1.1776 |     40.935 |     1.8
   13 |   1.1544 |     39.000 |   1.1912 |     40.331 |     2.0
   14 |   1.1362 |     38.583 |   1.1750 |     40.204 |     2.2
   15 |   1.1192 |     37.931 |   1.1581 |     39.440 |     2.3
   16 |   1.1069 |     37.580 |   1.1447 |     39.567 |     2.5
   17 |   1.0905 |     36.751 |   1.1624 |     39.631 |     2.6
   18 |   1.0783 |     36.384 |   1.1873 |     39.949 |     2.8
   19 |   1.0588 |     35.819 |   1.1536 |     39.090 |     2.9
   20 |   1.0497 |     35.533 |   1.1572 |     39.249 |     3.1
   21 |   1.0351 |     34.776 |   1.1308 |     38.613 |     3.2
   22 |   1.0242 |     34.606 |   1.1475 |     38.295 |     3.4
   23 |   1.0122 |     34.233 |   1.1656 |     38.899 |     3.6
   24 |   0.9946 |     33.509 |   1.1319 |     38.486 |     3.7
   25 |   0.9843 |     33.295 |   1.1164 |     37.691 |     3.9
   26 |   0.9684 |     32.708 |   1.1451 |     38.295 |     4.0
   27 |   0.9576 |     32.467 |   1.1772 |     38.868 |     4.2
   28 |   0.9447 |     32.121 |   1.1381 |     37.945 |     4.3
   29 |   0.9325 |     31.622 |   1.1524 |     38.104 |     4.5
   30 |   0.9231 |     30.996 |   1.1068 |     36.737 |     4.6
   31 |   0.9130 |     31.035 |   1.1303 |     38.073 |     4.8
   32 |   0.9026 |     30.415 |   1.1462 |     37.913 |     5.0
   33 |   0.8880 |     30.294 |   1.1697 |     37.945 |     5.1
   34 |   0.8756 |     29.510 |   1.1267 |     36.387 |     5.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 343,330

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3791 |     55.267 |   1.8057 |     46.088 |     0.1
    2 |   1.6631 |     45.979 |   1.5764 |     46.056 |     0.3
    3 |   1.5198 |     45.600 |   1.4774 |     45.134 |     0.4
    4 |   1.4442 |     44.903 |   1.4212 |     44.943 |     0.6
    5 |   1.3916 |     44.371 |   1.3843 |     44.784 |     0.7
    6 |   1.3514 |     43.718 |   1.3590 |     44.275 |     0.9
    7 |   1.3179 |     42.616 |   1.3404 |     43.989 |     1.0
    8 |   1.2844 |     41.919 |   1.3200 |     42.875 |     1.2
    9 |   1.2590 |     41.497 |   1.3087 |     43.289 |     1.3
   10 |   1.2289 |     40.723 |   1.2637 |     42.048 |     1.5
   11 |   1.2045 |     40.224 |   1.2512 |     41.921 |     1.6
   12 |   1.1849 |     39.659 |   1.2478 |     41.730 |     1.8
   13 |   1.1640 |     39.132 |   1.2369 |     41.126 |     1.9
   14 |   1.1421 |     38.051 |   1.2083 |     40.108 |     2.1
   15 |   1.1247 |     37.794 |   1.2232 |     39.917 |     2.2
   16 |   1.1070 |     37.228 |   1.2069 |     39.949 |     2.3
   17 |   1.0846 |     36.323 |   1.2047 |     40.076 |     2.5
   18 |   1.0700 |     35.989 |   1.1924 |     39.504 |     2.6
   19 |   1.0538 |     35.413 |   1.1704 |     39.218 |     2.8
   20 |   1.0330 |     34.710 |   1.1791 |     39.567 |     2.9
   21 |   1.0198 |     33.838 |   1.1559 |     38.454 |     3.1
   22 |   1.0071 |     33.613 |   1.1783 |     39.313 |     3.2
   23 |   0.9895 |     32.637 |   1.2029 |     39.472 |     3.4
   24 |   0.9710 |     32.209 |   1.1784 |     39.186 |     3.5
   25 |   0.9605 |     32.011 |   1.1813 |     39.059 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 292,194

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7208 |     49.089 |   1.3649 |     45.165 |     0.1
    2 |   1.3650 |     45.628 |   1.2655 |     44.752 |     0.1
    3 |   1.3083 |     44.821 |   1.2415 |     43.416 |     0.2
    4 |   1.2827 |     44.624 |   1.2178 |     43.734 |     0.3
    5 |   1.2570 |     43.878 |   1.2087 |     42.494 |     0.3
    6 |   1.2306 |     43.214 |   1.1681 |     40.744 |     0.4
    7 |   1.2098 |     42.857 |   1.1556 |     40.013 |     0.5
    8 |   1.1993 |     42.309 |   1.1589 |     40.045 |     0.5
    9 |   1.1819 |     41.639 |   1.1349 |     39.536 |     0.6
   10 |   1.1686 |     41.321 |   1.1217 |     39.186 |     0.7
   11 |   1.1516 |     40.432 |   1.1246 |     39.440 |     0.7
   12 |   1.1398 |     40.295 |   1.1435 |     39.726 |     0.8
   13 |   1.1320 |     39.993 |   1.0891 |     38.804 |     0.9
   14 |   1.1161 |     39.555 |   1.1122 |     39.122 |     0.9
   15 |   1.1098 |     39.116 |   1.1030 |     38.931 |     1.0
   16 |   1.0998 |     39.105 |   1.0702 |     37.691 |     1.1
   17 |   1.0871 |     38.858 |   1.0767 |     37.532 |     1.1
   18 |   1.0870 |     38.907 |   1.0700 |     38.263 |     1.2
   19 |   1.0706 |     38.156 |   1.0681 |     37.595 |     1.3
   20 |   1.0662 |     37.733 |   1.0745 |     37.786 |     1.3
   21 |   1.0599 |     37.585 |   1.0650 |     37.564 |     1.4
   22 |   1.0484 |     37.366 |   1.1058 |     37.754 |     1.5
   23 |   1.0488 |     37.190 |   1.0667 |     37.246 |     1.5
   24 |   1.0301 |     36.362 |   1.0375 |     36.832 |     1.6
   25 |   1.0280 |     36.438 |   1.0380 |     36.164 |     1.7
   26 |   1.0206 |     36.137 |   1.0763 |     36.832 |     1.7
   27 |   1.0108 |     35.698 |   1.0503 |     35.751 |     1.8
   28 |   1.0079 |     35.714 |   1.0465 |     36.164 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 978,722

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4910 |     47.383 |   1.2391 |     42.525 |     0.1
    2 |   1.2061 |     41.968 |   1.1746 |     42.589 |     0.2
    3 |   1.1476 |     40.323 |   1.1443 |     39.790 |     0.3
    4 |   1.0986 |     38.732 |   1.1261 |     39.504 |     0.4
    5 |   1.0635 |     38.238 |   1.0861 |     37.754 |     0.4
    6 |   1.0373 |     36.822 |   1.0882 |     37.786 |     0.5
    7 |   1.0070 |     36.164 |   1.0577 |     37.564 |     0.6
    8 |   0.9741 |     34.941 |   1.0430 |     36.069 |     0.7
    9 |   0.9401 |     33.750 |   1.0275 |     36.387 |     0.8
   10 |   0.9226 |     32.944 |   1.0485 |     35.941 |     0.9
   11 |   0.8935 |     32.050 |   1.0653 |     36.196 |     1.0
   12 |   0.8634 |     30.755 |   1.0283 |     36.101 |     1.1
   13 |   0.8329 |     29.658 |   1.0644 |     36.164 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 847,522

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4978 |     47.235 |   1.2720 |     44.529 |     0.2
    2 |   1.2467 |     43.817 |   1.2185 |     45.229 |     0.3
    3 |   1.1987 |     42.939 |   1.1710 |     41.889 |     0.5
    4 |   1.1540 |     41.173 |   1.1586 |     40.617 |     0.7
    5 |   1.1321 |     40.849 |   1.1326 |     40.681 |     0.8
    6 |   1.1051 |     39.955 |   1.1080 |     38.740 |     1.0
    7 |   1.0812 |     38.973 |   1.0944 |     38.963 |     1.1
    8 |   1.0657 |     38.973 |   1.0871 |     39.059 |     1.3
    9 |   1.0555 |     38.611 |   1.0784 |     39.186 |     1.5
   10 |   1.0423 |     37.964 |   1.1033 |     39.281 |     1.6
   11 |   1.0225 |     37.393 |   1.0603 |     38.263 |     1.8
   12 |   1.0032 |     36.417 |   1.0568 |     37.182 |     2.0
   13 |   0.9872 |     35.862 |   1.0345 |     36.196 |     2.1
   14 |   0.9786 |     35.681 |   1.0442 |     35.878 |     2.3
   15 |   0.9602 |     34.738 |   1.0382 |     36.419 |     2.5
   16 |   0.9481 |     33.838 |   1.0494 |     37.532 |     2.6
   17 |   0.9376 |     33.580 |   1.0394 |     36.260 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 881,442

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5797 |     48.420 |   1.2949 |     44.466 |     0.1
    2 |   1.2374 |     43.038 |   1.1974 |     41.953 |     0.2
    3 |   1.1592 |     40.454 |   1.1427 |     39.885 |     0.3
    4 |   1.0916 |     37.887 |   1.1145 |     38.327 |     0.5
    5 |   1.0328 |     36.334 |   1.0637 |     37.182 |     0.6
    6 |   0.9833 |     34.414 |   1.1029 |     38.136 |     0.7
    7 |   0.9423 |     32.686 |   1.0317 |     35.401 |     0.8
    8 |   0.8951 |     31.035 |   1.0104 |     34.510 |     0.9
    9 |   0.8470 |     29.696 |   1.0335 |     34.892 |     1.0
   10 |   0.8027 |     28.231 |   1.0262 |     34.288 |     1.2
   11 |   0.7578 |     26.289 |   1.0349 |     32.761 |     1.3
   12 |   0.7173 |     24.693 |   1.0248 |     34.256 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 425,698

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5082 |     63.545 |   1.7124 |     45.356 |     0.1
    2 |   1.6787 |     46.132 |   1.5137 |     45.197 |     0.2
    3 |   1.5344 |     45.929 |   1.4392 |     45.293 |     0.3
    4 |   1.4611 |     45.798 |   1.3861 |     44.338 |     0.4
    5 |   1.4156 |     44.986 |   1.3530 |     43.957 |     0.5
    6 |   1.3806 |     44.602 |   1.3314 |     43.734 |     0.6
    7 |   1.3479 |     43.850 |   1.3091 |     43.193 |     0.7
    8 |   1.3269 |     43.713 |   1.2875 |     43.416 |     0.8
    9 |   1.3035 |     43.345 |   1.2712 |     43.130 |     0.9
   10 |   1.2798 |     42.385 |   1.2638 |     43.066 |     0.9
   11 |   1.2660 |     42.347 |   1.2556 |     42.335 |     1.0
   12 |   1.2465 |     41.678 |   1.2512 |     42.462 |     1.1
   13 |   1.2292 |     41.754 |   1.2618 |     42.430 |     1.2
   14 |   1.2131 |     40.899 |   1.2134 |     41.444 |     1.3
   15 |   1.1987 |     40.613 |   1.2095 |     40.903 |     1.4
   16 |   1.1864 |     40.092 |   1.2077 |     40.712 |     1.5
   17 |   1.1727 |     39.867 |   1.2093 |     41.094 |     1.5
   18 |   1.1617 |     39.346 |   1.1850 |     39.949 |     1.6
   19 |   1.1496 |     39.171 |   1.1782 |     39.758 |     1.7
   20 |   1.1370 |     38.754 |   1.1808 |     39.663 |     1.8
   21 |   1.1260 |     38.754 |   1.1768 |     39.631 |     1.9
   22 |   1.1186 |     38.189 |   1.1806 |     40.076 |     2.0
   23 |   1.1065 |     38.035 |   1.1592 |     39.536 |     2.0
   24 |   1.0956 |     37.459 |   1.1625 |     39.536 |     2.1
   25 |   1.0912 |     37.267 |   1.1573 |     39.090 |     2.2
   26 |   1.0820 |     36.806 |   1.1413 |     38.995 |     2.3
   27 |   1.0701 |     36.570 |   1.1453 |     39.249 |     2.4
   28 |   1.0613 |     36.510 |   1.1623 |     39.790 |     2.5
   29 |   1.0571 |     36.246 |   1.1382 |     39.408 |     2.5
   30 |   1.0486 |     35.972 |   1.1255 |     38.645 |     2.6
   31 |   1.0340 |     35.363 |   1.1596 |     39.313 |     2.7
   32 |   1.0307 |     34.880 |   1.1401 |     38.772 |     2.8
   33 |   1.0209 |     35.050 |   1.1388 |     39.440 |     2.9
   34 |   1.0177 |     34.738 |   1.1163 |     38.422 |     2.9
   35 |   1.0106 |     34.540 |   1.1463 |     39.122 |     3.0
   36 |   1.0051 |     34.085 |   1.1308 |     38.772 |     3.1
   37 |   0.9952 |     34.052 |   1.1347 |     38.581 |     3.2
   38 |   0.9861 |     33.668 |   1.1216 |     37.150 |     3.3
   39 |   0.9833 |     33.690 |   1.1023 |     37.532 |     3.4
   40 |   0.9704 |     33.136 |   1.1175 |     37.945 |     3.4
   41 |   0.9747 |     33.213 |   1.1378 |     38.327 |     3.5
   42 |   0.9619 |     32.834 |   1.1127 |     37.532 |     3.6
   43 |   0.9533 |     32.505 |   1.1262 |     38.645 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,442,466

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1306 |     54.531 |   1.4976 |     46.151 |     0.2
    2 |   1.4935 |     45.907 |   1.3592 |     44.561 |     0.3
    3 |   1.3933 |     45.002 |   1.2997 |     42.653 |     0.5
    4 |   1.3314 |     43.669 |   1.2642 |     42.303 |     0.6
    5 |   1.2914 |     42.808 |   1.2612 |     42.398 |     0.8
    6 |   1.2624 |     42.314 |   1.2347 |     41.253 |     1.0
    7 |   1.2324 |     41.623 |   1.2408 |     41.985 |     1.1
    8 |   1.2108 |     41.113 |   1.2057 |     41.094 |     1.3
    9 |   1.1911 |     40.531 |   1.2193 |     41.317 |     1.5
   10 |   1.1720 |     40.070 |   1.2081 |     40.617 |     1.6
   11 |   1.1493 |     39.028 |   1.1739 |     39.949 |     1.8
   12 |   1.1385 |     39.055 |   1.1998 |     40.490 |     2.0
   13 |   1.1198 |     38.430 |   1.1617 |     39.377 |     2.1
   14 |   1.1097 |     37.986 |   1.1865 |     39.377 |     2.3
   15 |   1.0937 |     37.091 |   1.1411 |     39.122 |     2.4
   16 |   1.0786 |     36.982 |   1.1392 |     38.518 |     2.6
   17 |   1.0725 |     36.905 |   1.1349 |     38.931 |     2.8
   18 |   1.0457 |     35.731 |   1.1700 |     40.267 |     2.9
   19 |   1.0379 |     35.621 |   1.1151 |     38.422 |     3.1
   20 |   1.0240 |     35.111 |   1.1340 |     38.327 |     3.3
   21 |   1.0113 |     34.359 |   1.1499 |     40.076 |     3.4
   22 |   0.9993 |     33.942 |   1.1240 |     37.818 |     3.6
   23 |   0.9904 |     33.761 |   1.1473 |     38.518 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,047,714

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1158 |     54.548 |   1.5125 |     45.229 |     0.2
    2 |   1.4328 |     44.980 |   1.3609 |     43.511 |     0.4
    3 |   1.3321 |     43.208 |   1.3032 |     41.889 |     0.5
    4 |   1.2730 |     41.892 |   1.2526 |     42.557 |     0.7
    5 |   1.2278 |     40.740 |   1.2218 |     41.953 |     0.9
    6 |   1.1877 |     39.768 |   1.2329 |     41.444 |     1.1
    7 |   1.1540 |     39.050 |   1.1790 |     40.045 |     1.3
    8 |   1.1256 |     38.227 |   1.1892 |     40.458 |     1.4
    9 |   1.0933 |     36.828 |   1.1759 |     39.949 |     1.6
   10 |   1.0715 |     36.696 |   1.1479 |     38.391 |     1.8
   11 |   1.0426 |     35.440 |   1.1791 |     39.218 |     2.0
   12 |   1.0168 |     34.463 |   1.1387 |     39.059 |     2.2
   13 |   0.9920 |     33.580 |   1.1130 |     36.737 |     2.3
   14 |   0.9647 |     32.285 |   1.1079 |     37.373 |     2.5
   15 |   0.9432 |     31.561 |   1.1336 |     38.677 |     2.7
   16 |   0.9194 |     30.826 |   1.1434 |     38.486 |     2.9
   17 |   0.8947 |     30.212 |   1.1237 |     37.659 |     3.1
   18 |   0.8718 |     29.153 |   1.0931 |     36.609 |     3.3
   19 |   0.8461 |     28.083 |   1.1217 |     36.927 |     3.4
   20 |   0.8164 |     27.129 |   1.1218 |     37.150 |     3.6
   21 |   0.7981 |     26.602 |   1.1427 |     36.864 |     3.8
   22 |   0.7728 |     25.730 |   1.0945 |     35.941 |     4.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 392,162

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8171 |     67.320 |   1.9937 |     47.583 |     0.1
    2 |   1.9268 |     47.740 |   1.6000 |     46.915 |     0.2
    3 |   1.6542 |     46.182 |   1.4898 |     45.165 |     0.3
    4 |   1.5480 |     45.913 |   1.4334 |     45.293 |     0.4
    5 |   1.4870 |     45.754 |   1.3957 |     45.674 |     0.5
    6 |   1.4453 |     45.320 |   1.3605 |     43.511 |     0.6
    7 |   1.4152 |     45.134 |   1.3410 |     44.529 |     0.8
    8 |   1.3898 |     45.139 |   1.3250 |     44.307 |     0.9
    9 |   1.3620 |     44.547 |   1.3088 |     43.893 |     1.0
   10 |   1.3484 |     44.267 |   1.2943 |     44.179 |     1.1
   11 |   1.3303 |     44.157 |   1.3020 |     44.084 |     1.2
   12 |   1.3172 |     43.971 |   1.2776 |     43.798 |     1.3
   13 |   1.3003 |     43.159 |   1.2598 |     42.716 |     1.4
   14 |   1.2856 |     42.709 |   1.2587 |     43.480 |     1.5
   15 |   1.2718 |     42.682 |   1.2495 |     42.971 |     1.6
   16 |   1.2603 |     42.292 |   1.2358 |     42.557 |     1.7
   17 |   1.2483 |     42.100 |   1.2460 |     42.207 |     1.8
   18 |   1.2363 |     41.623 |   1.2520 |     42.812 |     1.9
   19 |   1.2337 |     41.694 |   1.2534 |     42.684 |     2.1
   20 |   1.2233 |     41.793 |   1.2220 |     41.349 |     2.2
   21 |   1.2127 |     41.480 |   1.2274 |     41.476 |     2.3
   22 |   1.2056 |     41.124 |   1.2148 |     40.935 |     2.4
   23 |   1.2019 |     40.877 |   1.2194 |     41.412 |     2.5
   24 |   1.1926 |     40.707 |   1.2145 |     41.285 |     2.6
   25 |   1.1812 |     40.520 |   1.2121 |     40.617 |     2.7
   26 |   1.1831 |     40.174 |   1.2200 |     41.317 |     2.8
   27 |   1.1751 |     39.961 |   1.1988 |     40.522 |     2.9
   28 |   1.1700 |     40.185 |   1.2391 |     41.762 |     3.0
   29 |   1.1637 |     39.631 |   1.2334 |     41.444 |     3.1
   30 |   1.1610 |     39.522 |   1.2314 |     41.889 |     3.3
   31 |   1.1527 |     39.275 |   1.1926 |     41.031 |     3.4
   32 |   1.1439 |     39.330 |   1.2275 |     40.999 |     3.5
   33 |   1.1398 |     38.968 |   1.2060 |     41.603 |     3.6
   34 |   1.1366 |     38.891 |   1.2273 |     42.144 |     3.7
   35 |   1.1334 |     38.880 |   1.2169 |     40.712 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 358,946

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5655 |     46.917 |   1.2989 |     43.607 |     0.1
    2 |   1.2628 |     43.137 |   1.2292 |     41.508 |     0.2
    3 |   1.1746 |     40.460 |   1.1672 |     40.108 |     0.3
    4 |   1.1080 |     38.430 |   1.1338 |     38.995 |     0.4
    5 |   1.0490 |     36.565 |   1.0914 |     37.277 |     0.5
    6 |   1.0055 |     34.858 |   1.0622 |     36.800 |     0.5
    7 |   0.9556 |     33.021 |   1.0531 |     35.305 |     0.6
    8 |   0.9119 |     31.534 |   1.0282 |     34.701 |     0.7
    9 |   0.8746 |     30.376 |   1.0093 |     34.733 |     0.8
   10 |   0.8228 |     28.440 |   1.0016 |     33.556 |     0.9
   11 |   0.7837 |     27.074 |   1.0638 |     34.351 |     1.0
   12 |   0.7391 |     25.302 |   1.0513 |     33.270 |     1.1
   13 |   0.6999 |     24.029 |   1.0470 |     32.411 |     1.2
   14 |   0.6565 |     22.433 |   1.0516 |     33.333 |     1.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 276,386

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6947 |     48.475 |   1.3394 |     44.688 |     0.1
    2 |   1.3260 |     44.728 |   1.2482 |     43.766 |     0.1
    3 |   1.2530 |     42.879 |   1.1980 |     40.776 |     0.2
    4 |   1.2015 |     41.294 |   1.1566 |     39.345 |     0.3
    5 |   1.1634 |     40.685 |   1.1516 |     39.281 |     0.4
    6 |   1.1370 |     39.308 |   1.1042 |     37.309 |     0.4
    7 |   1.1019 |     38.046 |   1.0933 |     36.482 |     0.5
    8 |   1.0787 |     37.426 |   1.0902 |     38.454 |     0.6
    9 |   1.0528 |     36.224 |   1.0810 |     37.118 |     0.6
   10 |   1.0239 |     35.391 |   1.0515 |     35.337 |     0.7
   11 |   0.9970 |     34.167 |   1.0610 |     36.260 |     0.8
   12 |   0.9767 |     33.915 |   1.0417 |     34.637 |     0.9
   13 |   0.9545 |     32.845 |   1.0134 |     34.796 |     0.9
   14 |   0.9352 |     31.989 |   1.0554 |     35.019 |     1.0
   15 |   0.9078 |     31.309 |   1.0320 |     33.779 |     1.1
   16 |   0.8910 |     30.722 |   1.0138 |     33.651 |     1.1
   17 |   0.8697 |     29.970 |   0.9942 |     33.238 |     1.2
   18 |   0.8433 |     28.939 |   1.0251 |     33.302 |     1.3
   19 |   0.8256 |     28.319 |   1.0258 |     33.270 |     1.4
   20 |   0.8058 |     27.809 |   1.0275 |     32.761 |     1.4
   21 |   0.7829 |     26.767 |   1.0495 |     33.524 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 327,522

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9426 |     76.591 |   2.4625 |     58.906 |     0.2
    2 |   2.3376 |     56.139 |   1.8975 |     48.537 |     0.3
    3 |   1.9096 |     48.020 |   1.6289 |     45.483 |     0.5
    4 |   1.6847 |     46.527 |   1.5219 |     45.324 |     0.7
    5 |   1.5749 |     46.237 |   1.4561 |     45.420 |     0.8
    6 |   1.5044 |     46.138 |   1.4192 |     45.261 |     1.0
    7 |   1.4669 |     45.891 |   1.3909 |     45.674 |     1.1
    8 |   1.4371 |     45.842 |   1.3716 |     46.660 |     1.3
    9 |   1.4133 |     45.611 |   1.3516 |     44.752 |     1.5
   10 |   1.3932 |     45.375 |   1.3293 |     44.338 |     1.6
   11 |   1.3764 |     45.139 |   1.3321 |     45.070 |     1.8
   12 |   1.3634 |     44.865 |   1.3114 |     44.211 |     2.0
   13 |   1.3478 |     44.673 |   1.2973 |     43.893 |     2.1
   14 |   1.3398 |     44.860 |   1.2809 |     43.575 |     2.3
   15 |   1.3285 |     44.487 |   1.2693 |     43.575 |     2.5
   16 |   1.3144 |     44.415 |   1.2557 |     43.130 |     2.6
   17 |   1.3064 |     43.795 |   1.2553 |     43.130 |     2.8
   18 |   1.2966 |     43.675 |   1.2518 |     42.971 |     3.0
   19 |   1.2877 |     43.170 |   1.2510 |     43.321 |     3.1
   20 |   1.2807 |     43.099 |   1.2363 |     42.875 |     3.3
   21 |   1.2725 |     43.110 |   1.2283 |     41.635 |     3.5
   22 |   1.2618 |     42.885 |   1.2263 |     42.557 |     3.6
   23 |   1.2553 |     42.544 |   1.2187 |     42.430 |     3.8
   24 |   1.2522 |     42.643 |   1.2341 |     42.366 |     3.9
   25 |   1.2387 |     42.352 |   1.2365 |     42.366 |     4.1
   26 |   1.2322 |     42.034 |   1.2253 |     41.985 |     4.3
   27 |   1.2234 |     41.645 |   1.2208 |     41.921 |     4.4
   28 |   1.2211 |     41.508 |   1.2175 |     41.953 |     4.6
   29 |   1.2158 |     41.667 |   1.2268 |     42.303 |     4.8
   30 |   1.2077 |     41.167 |   1.2213 |     41.762 |     4.9
   31 |   1.2067 |     41.239 |   1.2278 |     41.826 |     5.1
   32 |   1.1925 |     40.833 |   1.2074 |     41.444 |     5.3
   33 |   1.1923 |     40.805 |   1.2282 |     41.444 |     5.4
   34 |   1.1825 |     40.339 |   1.2002 |     41.126 |     5.6
   35 |   1.1809 |     40.410 |   1.2258 |     41.412 |     5.7
   36 |   1.1768 |     40.504 |   1.2082 |     40.999 |     5.9
   37 |   1.1687 |     40.087 |   1.2002 |     40.681 |     6.1
   38 |   1.1647 |     40.120 |   1.2173 |     40.999 |     6.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 881,442

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1096 |     54.411 |   1.5328 |     44.752 |     0.1
    2 |   1.4303 |     44.728 |   1.3982 |     45.293 |     0.2
    3 |   1.3306 |     43.214 |   1.3297 |     44.593 |     0.3
    4 |   1.2712 |     42.012 |   1.2753 |     42.748 |     0.4
    5 |   1.2245 |     40.487 |   1.2654 |     42.748 |     0.5
    6 |   1.1869 |     39.670 |   1.2365 |     40.967 |     0.6
    7 |   1.1483 |     38.353 |   1.2230 |     41.094 |     0.6
    8 |   1.1139 |     37.448 |   1.1916 |     40.522 |     0.7
    9 |   1.0831 |     36.274 |   1.1811 |     39.758 |     0.8
   10 |   1.0532 |     35.083 |   1.1764 |     38.581 |     0.9
   11 |   1.0263 |     34.359 |   1.1334 |     37.882 |     1.0
   12 |   0.9946 |     33.081 |   1.1345 |     37.691 |     1.1
   13 |   0.9686 |     32.351 |   1.1488 |     37.595 |     1.2
   14 |   0.9403 |     31.062 |   1.1367 |     36.800 |     1.3
   15 |   0.9100 |     29.987 |   1.1255 |     37.754 |     1.4
   16 |   0.8900 |     29.356 |   1.1483 |     38.232 |     1.5
   17 |   0.8625 |     28.456 |   1.1253 |     36.737 |     1.6
   18 |   0.8390 |     27.743 |   1.1042 |     35.592 |     1.7
   19 |   0.8081 |     26.739 |   1.1187 |     36.387 |     1.8
   20 |   0.7785 |     25.658 |   1.1034 |     36.037 |     1.9
   21 |   0.7572 |     24.995 |   1.1101 |     35.528 |     1.9
   22 |   0.7315 |     24.243 |   1.1311 |     36.196 |     2.0
   23 |   0.6981 |     22.795 |   1.1237 |     35.782 |     2.1
   24 |   0.6785 |     22.208 |   1.1192 |     34.924 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 226,146

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5757 |     60.445 |   1.9809 |     45.706 |     0.1
    2 |   1.7685 |     45.809 |   1.6359 |     45.897 |     0.1
    3 |   1.5645 |     45.639 |   1.5147 |     45.165 |     0.2
    4 |   1.4744 |     45.512 |   1.4461 |     43.861 |     0.2
    5 |   1.4158 |     44.679 |   1.4137 |     44.943 |     0.3
    6 |   1.3742 |     43.581 |   1.3775 |     43.989 |     0.4
    7 |   1.3410 |     43.148 |   1.3440 |     43.607 |     0.4
    8 |   1.3106 |     42.468 |   1.3261 |     43.639 |     0.5
    9 |   1.2854 |     42.078 |   1.3173 |     43.416 |     0.5
   10 |   1.2597 |     41.365 |   1.3058 |     43.098 |     0.6
   11 |   1.2394 |     40.783 |   1.2902 |     42.780 |     0.6
   12 |   1.2184 |     40.295 |   1.2728 |     41.921 |     0.7
   13 |   1.1985 |     39.884 |   1.2439 |     41.062 |     0.8
   14 |   1.1795 |     39.412 |   1.2472 |     41.571 |     0.8
   15 |   1.1638 |     38.710 |   1.2469 |     40.649 |     0.9
   16 |   1.1491 |     38.271 |   1.2378 |     40.840 |     0.9
   17 |   1.1313 |     37.750 |   1.2315 |     40.744 |     1.0
   18 |   1.1200 |     37.453 |   1.2186 |     40.363 |     1.1
   19 |   1.1067 |     36.982 |   1.1998 |     39.790 |     1.1
   20 |   1.0956 |     36.850 |   1.2240 |     40.617 |     1.2
   21 |   1.0805 |     36.285 |   1.1961 |     40.204 |     1.2
   22 |   1.0682 |     35.731 |   1.2147 |     39.726 |     1.3
   23 |   1.0572 |     35.369 |   1.1981 |     39.981 |     1.4
   24 |   1.0437 |     34.908 |   1.1996 |     39.663 |     1.4
   25 |   1.0322 |     34.694 |   1.1676 |     38.550 |     1.5
   26 |   1.0251 |     34.469 |   1.2053 |     39.663 |     1.5
   27 |   1.0112 |     33.739 |   1.1927 |     38.518 |     1.6
   28 |   1.0027 |     33.586 |   1.2072 |     39.790 |     1.7
   29 |   0.9947 |     33.092 |   1.1860 |     39.154 |     1.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 326,626

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9244 |     53.045 |   1.3751 |     45.483 |     0.1
    2 |   1.3953 |     45.430 |   1.3034 |     44.529 |     0.2
    3 |   1.3262 |     44.322 |   1.2505 |     43.480 |     0.2
    4 |   1.2827 |     43.724 |   1.2281 |     42.875 |     0.3
    5 |   1.2513 |     42.972 |   1.2027 |     41.921 |     0.4
    6 |   1.2226 |     42.155 |   1.1822 |     40.999 |     0.5
    7 |   1.1999 |     41.617 |   1.1931 |     41.921 |     0.6
    8 |   1.1810 |     40.811 |   1.1636 |     40.426 |     0.6
    9 |   1.1548 |     40.174 |   1.1333 |     39.408 |     0.7
   10 |   1.1351 |     39.291 |   1.1499 |     39.854 |     0.8
   11 |   1.1200 |     38.743 |   1.1148 |     37.691 |     0.9
   12 |   1.1054 |     38.402 |   1.1247 |     38.200 |     0.9
   13 |   1.0804 |     37.196 |   1.1019 |     38.232 |     1.0
   14 |   1.0605 |     36.548 |   1.1128 |     36.959 |     1.1
   15 |   1.0457 |     36.087 |   1.0810 |     36.260 |     1.2
   16 |   1.0268 |     35.407 |   1.0687 |     36.450 |     1.3
   17 |   1.0076 |     34.683 |   1.0902 |     37.055 |     1.3
   18 |   0.9966 |     34.425 |   1.0680 |     36.005 |     1.4
   19 |   0.9722 |     33.295 |   1.0682 |     35.782 |     1.5
   20 |   0.9572 |     33.004 |   1.0773 |     35.210 |     1.6
   21 |   0.9386 |     32.351 |   1.0612 |     35.496 |     1.7
   22 |   0.9296 |     32.313 |   1.0795 |     35.655 |     1.7
   23 |   0.9063 |     31.150 |   1.0886 |     36.228 |     1.8
   24 |   0.8887 |     30.481 |   1.0883 |     35.433 |     1.9
   25 |   0.8760 |     30.267 |   1.0899 |     36.101 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 648,354

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5280 |     63.397 |   1.6878 |     45.356 |     0.1
    2 |   1.6830 |     46.686 |   1.4496 |     45.165 |     0.2
    3 |   1.5041 |     46.313 |   1.3818 |     46.183 |     0.2
    4 |   1.4298 |     45.918 |   1.3341 |     45.229 |     0.3
    5 |   1.3805 |     45.244 |   1.2856 |     44.084 |     0.4
    6 |   1.3406 |     44.437 |   1.2589 |     42.557 |     0.5
    7 |   1.3094 |     43.658 |   1.2344 |     41.317 |     0.6
    8 |   1.2861 |     42.852 |   1.2158 |     40.935 |     0.7
    9 |   1.2636 |     42.490 |   1.2130 |     40.872 |     0.7
   10 |   1.2463 |     42.127 |   1.1801 |     39.949 |     0.8
   11 |   1.2278 |     41.601 |   1.1804 |     40.299 |     0.9
   12 |   1.2155 |     41.107 |   1.1842 |     40.267 |     1.0
   13 |   1.2042 |     40.997 |   1.1710 |     39.790 |     1.1
   14 |   1.1917 |     40.602 |   1.1736 |     40.267 |     1.1
   15 |   1.1799 |     40.350 |   1.1784 |     40.617 |     1.2
   16 |   1.1738 |     39.862 |   1.1701 |     39.472 |     1.3
   17 |   1.1600 |     39.933 |   1.1473 |     38.740 |     1.4
   18 |   1.1483 |     39.214 |   1.1614 |     39.949 |     1.5
   19 |   1.1430 |     39.099 |   1.1767 |     40.045 |     1.6
   20 |   1.1322 |     38.814 |   1.1582 |     39.599 |     1.6
   21 |   1.1216 |     38.320 |   1.1530 |     39.027 |     1.7
   22 |   1.1181 |     38.337 |   1.1410 |     39.090 |     1.8
   23 |   1.1058 |     38.057 |   1.1469 |     38.613 |     1.9
   24 |   1.0995 |     37.859 |   1.1547 |     38.931 |     2.0
   25 |   1.0930 |     37.629 |   1.1608 |     39.440 |     2.1
   26 |   1.0856 |     37.311 |   1.1558 |     38.868 |     2.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 458,914

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7918 |     50.016 |   1.3701 |     45.006 |     0.2
    2 |   1.3673 |     45.666 |   1.2908 |     44.911 |     0.3
    3 |   1.3103 |     44.761 |   1.2398 |     43.702 |     0.5
    4 |   1.2713 |     44.344 |   1.2082 |     43.098 |     0.7
    5 |   1.2473 |     44.026 |   1.1971 |     42.398 |     0.8
    6 |   1.2299 |     43.647 |   1.1907 |     41.921 |     1.0
    7 |   1.2144 |     43.411 |   1.1668 |     41.190 |     1.1
    8 |   1.2033 |     42.934 |   1.1704 |     41.476 |     1.3
    9 |   1.1921 |     42.841 |   1.1517 |     40.999 |     1.5
   10 |   1.1820 |     42.539 |   1.1469 |     40.808 |     1.6
   11 |   1.1725 |     42.396 |   1.1349 |     40.712 |     1.8
   12 |   1.1665 |     42.407 |   1.1371 |     40.872 |     2.0
   13 |   1.1602 |     42.270 |   1.1379 |     40.999 |     2.1
   14 |   1.1550 |     41.820 |   1.1330 |     41.539 |     2.3
   15 |   1.1491 |     42.084 |   1.1330 |     40.712 |     2.5
   16 |   1.1430 |     41.650 |   1.1284 |     41.635 |     2.6
   17 |   1.1403 |     41.826 |   1.1278 |     40.903 |     2.8
   18 |   1.1397 |     41.842 |   1.1193 |     39.726 |     2.9
   19 |   1.1340 |     41.497 |   1.1196 |     40.681 |     3.1
   20 |   1.1299 |     41.557 |   1.1269 |     41.826 |     3.3
   21 |   1.1227 |     41.365 |   1.1140 |     41.158 |     3.4
   22 |   1.1190 |     41.370 |   1.1178 |     40.394 |     3.6
   23 |   1.1188 |     41.047 |   1.1107 |     39.949 |     3.8
   24 |   1.1132 |     40.948 |   1.1005 |     40.140 |     3.9
   25 |   1.1124 |     40.849 |   1.1039 |     40.108 |     4.1
   26 |   1.1085 |     41.074 |   1.1050 |     39.726 |     4.2
   27 |   1.0961 |     40.065 |   1.1453 |     40.267 |     4.4
   28 |   1.0917 |     39.845 |   1.1096 |     40.458 |     4.6
   29 |   1.0866 |     39.522 |   1.0982 |     39.313 |     4.7
   30 |   1.0764 |     39.406 |   1.1058 |     40.235 |     4.9
   31 |   1.0768 |     39.363 |   1.1174 |     40.712 |     5.1
   32 |   1.0701 |     39.187 |   1.1619 |     41.221 |     5.2
   33 |   1.0662 |     38.874 |   1.1261 |     41.126 |     5.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 847,522

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6206 |     48.420 |   1.3172 |     45.865 |     0.1
    2 |   1.3428 |     45.397 |   1.2650 |     44.179 |     0.3
    3 |   1.2937 |     44.849 |   1.2447 |     44.593 |     0.4
    4 |   1.2655 |     44.591 |   1.2073 |     43.225 |     0.5
    5 |   1.2530 |     44.492 |   1.2111 |     44.688 |     0.7
    6 |   1.2351 |     44.119 |   1.1770 |     41.667 |     0.8
    7 |   1.2138 |     43.093 |   1.1783 |     42.271 |     1.0
    8 |   1.2098 |     42.994 |   1.1646 |     42.176 |     1.1
    9 |   1.1906 |     42.572 |   1.1735 |     42.875 |     1.2
   10 |   1.1880 |     42.561 |   1.1617 |     41.858 |     1.4
   11 |   1.1808 |     42.330 |   1.1516 |     40.204 |     1.5
   12 |   1.1780 |     42.117 |   1.1414 |     39.981 |     1.7
   13 |   1.1678 |     41.623 |   1.1251 |     39.790 |     1.8
   14 |   1.1587 |     41.414 |   1.1368 |     41.412 |     1.9
   15 |   1.1575 |     41.211 |   1.1397 |     39.917 |     2.1
   16 |   1.1499 |     41.316 |   1.1220 |     39.981 |     2.2
   17 |   1.1435 |     40.910 |   1.1298 |     39.758 |     2.3
   18 |   1.1431 |     40.783 |   1.1157 |     39.822 |     2.5
   19 |   1.1359 |     40.943 |   1.1184 |     39.790 |     2.6
   20 |   1.1328 |     40.377 |   1.1148 |     39.790 |     2.8
   21 |   1.1317 |     40.750 |   1.1363 |     40.331 |     2.9
   22 |   1.1321 |     40.586 |   1.0990 |     38.740 |     3.0
   23 |   1.1245 |     40.476 |   1.1209 |     40.140 |     3.2
   24 |   1.1203 |     40.339 |   1.0876 |     38.995 |     3.3
   25 |   1.1186 |     40.065 |   1.1016 |     39.218 |     3.5
   26 |   1.1187 |     40.345 |   1.0983 |     38.772 |     3.6
   27 |   1.1167 |     40.279 |   1.1143 |     39.885 |     3.7
   28 |   1.1150 |     39.955 |   1.1196 |     40.712 |     3.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 779,938

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4454 |     45.962 |   1.2322 |     41.953 |     0.1
    2 |   1.2079 |     42.062 |   1.1787 |     42.271 |     0.2
    3 |   1.1414 |     40.427 |   1.1318 |     39.758 |     0.2
    4 |   1.1061 |     39.478 |   1.1019 |     38.550 |     0.3
    5 |   1.0709 |     38.145 |   1.0735 |     36.768 |     0.4
    6 |   1.0394 |     36.987 |   1.0781 |     38.772 |     0.5
    7 |   1.0154 |     36.449 |   1.0579 |     36.800 |     0.6
    8 |   0.9929 |     35.456 |   1.0601 |     37.691 |     0.6
    9 |   0.9673 |     34.403 |   1.0549 |     37.150 |     0.7
   10 |   0.9412 |     33.470 |   1.0439 |     36.260 |     0.8
   11 |   0.9052 |     31.929 |   1.0462 |     36.514 |     0.9
   12 |   0.8885 |     31.545 |   1.0001 |     34.160 |     1.0
   13 |   0.8595 |     30.118 |   1.0237 |     34.637 |     1.0
   14 |   0.8297 |     29.361 |   1.0149 |     34.510 |     1.1
   15 |   0.8060 |     28.231 |   1.0156 |     33.969 |     1.2
   16 |   0.7880 |     27.639 |   0.9882 |     32.983 |     1.3
   17 |   0.7430 |     25.905 |   1.0229 |     33.906 |     1.4
   18 |   0.7265 |     25.587 |   1.0194 |     32.824 |     1.5
   19 |   0.6888 |     24.199 |   1.0208 |     32.888 |     1.5
   20 |   0.6610 |     22.937 |   1.0037 |     32.761 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 235,106

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6815 |     48.618 |   1.3243 |     45.134 |     0.1
    2 |   1.2947 |     43.757 |   1.2436 |     42.812 |     0.1
    3 |   1.2125 |     41.321 |   1.1935 |     41.953 |     0.2
    4 |   1.1556 |     40.196 |   1.1585 |     40.490 |     0.3
    5 |   1.1104 |     38.891 |   1.1174 |     38.136 |     0.3
    6 |   1.0708 |     36.998 |   1.1039 |     37.214 |     0.4
    7 |   1.0284 |     35.500 |   1.1121 |     38.422 |     0.5
    8 |   0.9905 |     33.580 |   1.0919 |     37.468 |     0.5
    9 |   0.9636 |     32.999 |   1.1024 |     38.200 |     0.6
   10 |   0.9312 |     31.852 |   1.0553 |     36.069 |     0.7
   11 |   0.8862 |     30.228 |   1.1026 |     36.737 |     0.7
   12 |   0.8683 |     29.488 |   1.0484 |     35.655 |     0.8
   13 |   0.8360 |     28.615 |   1.0681 |     35.305 |     0.9
   14 |   0.8223 |     28.034 |   1.0349 |     33.969 |     0.9
   15 |   0.7783 |     26.382 |   1.0349 |     34.542 |     1.0
   16 |   0.7506 |     25.329 |   1.0383 |     34.351 |     1.1
   17 |   0.7211 |     24.457 |   1.0128 |     32.920 |     1.1
   18 |   0.6944 |     23.607 |   1.0445 |     33.651 |     1.2
   19 |   0.6716 |     22.871 |   1.0235 |     33.524 |     1.2
   20 |   0.6551 |     22.460 |   1.0379 |     33.842 |     1.3
   21 |   0.6156 |     21.121 |   1.0567 |     33.047 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 393,570

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6613 |     48.678 |   1.3309 |     43.766 |     0.1
    2 |   1.2905 |     43.965 |   1.2434 |     42.812 |     0.3
    3 |   1.2168 |     43.258 |   1.1872 |     42.144 |     0.5
    4 |   1.1815 |     41.782 |   1.1781 |     42.716 |     0.6
    5 |   1.1438 |     40.213 |   1.1346 |     39.949 |     0.8
    6 |   1.1055 |     39.143 |   1.1316 |     39.885 |     0.9
    7 |   1.0883 |     38.666 |   1.1159 |     39.377 |     1.1
    8 |   1.0624 |     37.991 |   1.1003 |     38.995 |     1.2
    9 |   1.0413 |     37.278 |   1.1286 |     38.963 |     1.4
   10 |   1.0221 |     36.614 |   1.1343 |     39.313 |     1.5
   11 |   1.0013 |     36.038 |   1.1131 |     39.059 |     1.7
   12 |   0.9855 |     35.171 |   1.1011 |     37.977 |     1.8
   13 |   0.9633 |     34.666 |   1.0591 |     38.200 |     2.0
   14 |   0.9552 |     34.376 |   1.1591 |     39.631 |     2.1
   15 |   0.9379 |     33.481 |   1.1179 |     38.232 |     2.3
   16 |   0.9285 |     33.509 |   1.1107 |     38.168 |     2.4
   17 |   0.9050 |     32.428 |   1.0927 |     38.168 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 226,146

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6611 |     65.043 |   2.0330 |     49.237 |     0.1
    2 |   1.9126 |     47.400 |   1.6411 |     46.215 |     0.1
    3 |   1.6432 |     46.116 |   1.5140 |     46.692 |     0.2
    4 |   1.5349 |     46.056 |   1.4480 |     45.388 |     0.2
    5 |   1.4759 |     45.639 |   1.4106 |     45.483 |     0.3
    6 |   1.4343 |     45.595 |   1.3769 |     45.642 |     0.4
    7 |   1.3988 |     45.293 |   1.3472 |     44.784 |     0.4
    8 |   1.3724 |     44.849 |   1.3281 |     44.116 |     0.5
    9 |   1.3487 |     44.284 |   1.3078 |     43.257 |     0.6
   10 |   1.3313 |     43.993 |   1.2983 |     43.639 |     0.6
   11 |   1.3141 |     43.576 |   1.2894 |     43.925 |     0.7
   12 |   1.2979 |     43.406 |   1.2833 |     43.861 |     0.8
   13 |   1.2822 |     42.917 |   1.2587 |     42.971 |     0.8
   14 |   1.2683 |     42.742 |   1.2700 |     43.416 |     0.9
   15 |   1.2564 |     42.314 |   1.2604 |     43.034 |     0.9
   16 |   1.2447 |     42.067 |   1.2482 |     42.844 |     1.0
   17 |   1.2339 |     41.826 |   1.2495 |     42.621 |     1.1
   18 |   1.2226 |     41.348 |   1.2276 |     41.412 |     1.1
   19 |   1.2174 |     41.272 |   1.2263 |     42.494 |     1.2
   20 |   1.2083 |     41.189 |   1.2346 |     41.698 |     1.3
   21 |   1.1982 |     40.855 |   1.2147 |     41.635 |     1.3
   22 |   1.1882 |     40.383 |   1.2230 |     41.794 |     1.4
   23 |   1.1820 |     40.334 |   1.2053 |     41.476 |     1.5
   24 |   1.1738 |     40.366 |   1.2031 |     41.508 |     1.5
   25 |   1.1704 |     39.741 |   1.1886 |     40.744 |     1.6
   26 |   1.1617 |     39.779 |   1.1855 |     41.062 |     1.6
   27 |   1.1550 |     39.483 |   1.1824 |     40.967 |     1.7
   28 |   1.1505 |     39.335 |   1.1846 |     40.808 |     1.8
   29 |   1.1445 |     39.439 |   1.1883 |     40.999 |     1.8
   30 |   1.1390 |     38.858 |   1.1758 |     40.585 |     1.9
   31 |   1.1317 |     39.033 |   1.1884 |     40.712 |     2.0
   32 |   1.1243 |     38.880 |   1.1824 |     40.903 |     2.0
   33 |   1.1188 |     38.375 |   1.1603 |     39.885 |     2.1
   34 |   1.1166 |     38.452 |   1.1715 |     40.776 |     2.1
   35 |   1.1106 |     38.276 |   1.1495 |     39.885 |     2.2
   36 |   1.1027 |     38.051 |   1.1522 |     40.108 |     2.3
   37 |   1.0986 |     37.815 |   1.1638 |     40.394 |     2.3
   38 |   1.0929 |     37.585 |   1.1497 |     40.140 |     2.4
   39 |   1.0909 |     37.591 |   1.1404 |     39.218 |     2.5
   40 |   1.0813 |     37.113 |   1.1339 |     39.059 |     2.5
   41 |   1.0767 |     36.943 |   1.1273 |     39.090 |     2.6
   42 |   1.0773 |     37.305 |   1.1391 |     39.663 |     2.7
   43 |   1.0654 |     36.455 |   1.1482 |     40.108 |     2.7
   44 |   1.0605 |     36.669 |   1.1324 |     38.995 |     2.8
   45 |   1.0559 |     36.131 |   1.1311 |     38.709 |     2.8
   46 |   1.0506 |     35.994 |   1.1223 |     38.454 |     2.9
   47 |   1.0471 |     36.268 |   1.1381 |     39.059 |     3.0
   48 |   1.0420 |     35.632 |   1.1234 |     38.613 |     3.0
   49 |   1.0353 |     35.583 |   1.1388 |     39.090 |     3.1
   50 |   1.0321 |     35.380 |   1.1382 |     39.249 |     3.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,047,714

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5924 |     48.744 |   1.2773 |     43.511 |     0.2
    2 |   1.2529 |     44.086 |   1.1923 |     41.603 |     0.4
    3 |   1.1964 |     42.144 |   1.1596 |     39.790 |     0.5
    4 |   1.1479 |     40.745 |   1.1345 |     39.249 |     0.7
    5 |   1.1226 |     39.840 |   1.1260 |     40.490 |     0.9
    6 |   1.0972 |     39.560 |   1.0918 |     38.073 |     1.1
    7 |   1.0741 |     38.370 |   1.1059 |     39.313 |     1.3
    8 |   1.0514 |     37.914 |   1.0612 |     37.913 |     1.4
    9 |   1.0374 |     37.739 |   1.0714 |     37.627 |     1.6
   10 |   1.0187 |     37.075 |   1.0722 |     38.550 |     1.8
   11 |   1.0101 |     36.307 |   1.0438 |     37.945 |     2.0
   12 |   0.9956 |     36.181 |   1.0391 |     36.927 |     2.2
   13 |   0.9849 |     35.599 |   1.0259 |     36.037 |     2.3
   14 |   0.9669 |     34.837 |   1.0136 |     36.291 |     2.5
   15 |   0.9576 |     34.551 |   1.0213 |     35.973 |     2.7
   16 |   0.9415 |     34.041 |   1.0569 |     36.228 |     2.9
   17 |   0.9420 |     33.898 |   1.0211 |     36.355 |     3.1
   18 |   0.9407 |     34.074 |   1.0494 |     36.101 |     3.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 458,914

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3507 |     54.438 |   1.7423 |     44.879 |     0.1
    2 |   1.6284 |     45.962 |   1.5483 |     45.356 |     0.2
    3 |   1.5052 |     45.233 |   1.4571 |     45.865 |     0.3
    4 |   1.4315 |     44.448 |   1.3963 |     42.971 |     0.4
    5 |   1.3815 |     44.053 |   1.3553 |     42.844 |     0.5
    6 |   1.3452 |     43.548 |   1.3503 |     45.165 |     0.6
    7 |   1.3092 |     43.038 |   1.3382 |     43.734 |     0.7
    8 |   1.2847 |     42.676 |   1.3231 |     44.211 |     0.9
    9 |   1.2570 |     41.765 |   1.2980 |     43.480 |     1.0
   10 |   1.2295 |     40.882 |   1.3024 |     43.480 |     1.1
   11 |   1.2028 |     40.158 |   1.2684 |     41.826 |     1.2
   12 |   1.1788 |     39.544 |   1.2571 |     41.476 |     1.3
   13 |   1.1548 |     38.644 |   1.2198 |     40.490 |     1.4
   14 |   1.1329 |     38.189 |   1.2596 |     40.935 |     1.5
   15 |   1.1118 |     37.371 |   1.2117 |     40.045 |     1.6
   16 |   1.0900 |     36.751 |   1.1777 |     39.408 |     1.7
   17 |   1.0733 |     36.065 |   1.1902 |     39.186 |     1.9
   18 |   1.0535 |     35.544 |   1.1965 |     39.599 |     2.0
   19 |   1.0316 |     34.595 |   1.1760 |     39.122 |     2.1
   20 |   1.0127 |     34.057 |   1.1943 |     39.281 |     2.2
   21 |   0.9956 |     33.575 |   1.2065 |     39.536 |     2.3
   22 |   0.9828 |     33.048 |   1.2049 |     39.345 |     2.4
   23 |   0.9613 |     32.137 |   1.1917 |     39.186 |     2.5
   24 |   0.9440 |     31.803 |   1.1746 |     38.486 |     2.6
   25 |   0.9310 |     31.199 |   1.1867 |     39.059 |     2.7
   26 |   0.9152 |     30.837 |   1.2038 |     38.836 |     2.8
   27 |   0.8999 |     30.453 |   1.1998 |     38.804 |     2.9
   28 |   0.8852 |     29.685 |   1.1783 |     38.581 |     3.0
   29 |   0.8712 |     29.290 |   1.1553 |     37.882 |     3.1
   30 |   0.8562 |     28.571 |   1.1801 |     38.677 |     3.2
   31 |   0.8417 |     28.319 |   1.2186 |     38.772 |     3.3
   32 |   0.8248 |     27.540 |   1.2201 |     38.899 |     3.5
   33 |   0.8094 |     27.057 |   1.1814 |     38.200 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 277,090

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9804 |     54.257 |   1.3944 |     46.024 |     0.1
    2 |   1.4082 |     46.023 |   1.3266 |     45.165 |     0.2
    3 |   1.3401 |     45.030 |   1.2963 |     44.275 |     0.3
    4 |   1.3062 |     44.437 |   1.2612 |     42.844 |     0.4
    5 |   1.2651 |     43.005 |   1.2039 |     41.380 |     0.5
    6 |   1.2328 |     42.352 |   1.2011 |     41.476 |     0.6
    7 |   1.2076 |     41.343 |   1.1938 |     40.140 |     0.7
    8 |   1.1802 |     40.569 |   1.1626 |     39.885 |     0.8
    9 |   1.1560 |     39.714 |   1.1471 |     38.995 |     0.9
   10 |   1.1359 |     38.962 |   1.1297 |     38.709 |     1.0
   11 |   1.1086 |     38.079 |   1.1129 |     37.913 |     1.1
   12 |   1.0864 |     37.366 |   1.0924 |     36.387 |     1.2
   13 |   1.0579 |     36.406 |   1.0978 |     37.691 |     1.3
   14 |   1.0342 |     35.780 |   1.0729 |     36.069 |     1.5
   15 |   1.0123 |     34.584 |   1.0720 |     35.496 |     1.6
   16 |   0.9926 |     34.036 |   1.0796 |     36.864 |     1.7
   17 |   0.9717 |     33.564 |   1.0873 |     36.069 |     1.8
   18 |   0.9590 |     32.851 |   1.0505 |     35.623 |     1.9
   19 |   0.9315 |     32.247 |   1.0888 |     35.560 |     2.0
   20 |   0.9084 |     31.062 |   1.0709 |     36.514 |     2.1
   21 |   0.8883 |     30.475 |   1.0697 |     35.401 |     2.2
   22 |   0.8680 |     30.009 |   1.0512 |     35.496 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,179,298

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6629 |     50.362 |   1.3103 |     44.402 |     0.2
    2 |   1.3331 |     45.798 |   1.2705 |     44.975 |     0.3
    3 |   1.2892 |     45.178 |   1.2438 |     44.052 |     0.5
    4 |   1.2550 |     44.300 |   1.2108 |     42.716 |     0.6
    5 |   1.2277 |     42.939 |   1.1813 |     41.412 |     0.8
    6 |   1.2006 |     42.243 |   1.1641 |     41.317 |     0.9
    7 |   1.1874 |     41.968 |   1.1456 |     40.204 |     1.1
    8 |   1.1747 |     41.985 |   1.1461 |     41.126 |     1.2
    9 |   1.1604 |     41.486 |   1.1327 |     40.585 |     1.4
   10 |   1.1515 |     41.107 |   1.1139 |     39.281 |     1.6
   11 |   1.1354 |     40.383 |   1.1110 |     39.536 |     1.7
   12 |   1.1243 |     40.366 |   1.1087 |     39.281 |     1.9
   13 |   1.1132 |     40.021 |   1.1124 |     40.076 |     2.0
   14 |   1.1031 |     39.736 |   1.0968 |     39.313 |     2.2
   15 |   1.1013 |     39.576 |   1.0965 |     39.027 |     2.3
   16 |   1.0889 |     39.373 |   1.0933 |     38.613 |     2.5
   17 |   1.0828 |     38.978 |   1.0746 |     38.645 |     2.7
   18 |   1.0695 |     38.649 |   1.1007 |     39.981 |     2.8
   19 |   1.0634 |     38.320 |   1.0737 |     38.263 |     3.0
   20 |   1.0615 |     38.326 |   1.0636 |     38.295 |     3.1
   21 |   1.0550 |     38.161 |   1.0717 |     38.136 |     3.3
   22 |   1.0372 |     37.508 |   1.0718 |     39.027 |     3.4
   23 |   1.0343 |     37.168 |   1.0582 |     37.182 |     3.6
   24 |   1.0244 |     37.267 |   1.0614 |     37.564 |     3.7
   25 |   1.0146 |     36.652 |   1.0464 |     37.341 |     3.9
   26 |   1.0050 |     36.433 |   1.0375 |     37.436 |     4.1
   27 |   0.9997 |     36.164 |   1.0372 |     36.196 |     4.2
   28 |   0.9901 |     35.478 |   1.0296 |     36.419 |     4.4
   29 |   0.9781 |     34.826 |   1.0465 |     36.864 |     4.5
   30 |   0.9728 |     34.447 |   1.0190 |     35.687 |     4.7
   31 |   0.9622 |     34.579 |   1.0236 |     35.846 |     4.9
   32 |   0.9577 |     34.271 |   1.0401 |     36.228 |     5.0
   33 |   0.9417 |     33.344 |   1.0654 |     35.941 |     5.2
   34 |   0.9324 |     33.289 |   1.0572 |     36.482 |     5.3
   35 |   0.9264 |     32.873 |   1.0120 |     35.337 |     5.5
   36 |   0.9209 |     32.829 |   1.0309 |     35.592 |     5.6
   37 |   0.9165 |     32.450 |   1.0658 |     36.482 |     5.8
   38 |   0.9076 |     32.088 |   1.0051 |     34.415 |     6.0
   39 |   0.8962 |     31.633 |   1.0296 |     35.751 |     6.1
   40 |   0.8894 |     31.666 |   1.0559 |     35.592 |     6.3
   41 |   0.8893 |     31.441 |   1.0110 |     33.969 |     6.4
   42 |   0.8744 |     30.881 |   1.0178 |     34.319 |     6.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,177,506

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9502 |     51.997 |   1.4302 |     44.720 |     0.1
    2 |   1.3764 |     44.240 |   1.3336 |     43.798 |     0.2
    3 |   1.2895 |     42.682 |   1.2747 |     42.207 |     0.3
    4 |   1.2275 |     40.877 |   1.2562 |     40.744 |     0.5
    5 |   1.1772 |     39.313 |   1.2301 |     41.285 |     0.6
    6 |   1.1401 |     38.594 |   1.1822 |     39.758 |     0.7
    7 |   1.1034 |     37.338 |   1.1925 |     40.490 |     0.8
    8 |   1.0661 |     36.455 |   1.1501 |     38.899 |     0.9
    9 |   1.0330 |     34.968 |   1.1590 |     39.631 |     1.1
   10 |   1.0022 |     33.701 |   1.1285 |     38.168 |     1.2
   11 |   0.9736 |     32.900 |   1.1447 |     38.073 |     1.3
   12 |   0.9477 |     31.726 |   1.1177 |     37.182 |     1.4
   13 |   0.9140 |     30.804 |   1.1013 |     36.991 |     1.5
   14 |   0.8890 |     29.899 |   1.1470 |     37.977 |     1.6
   15 |   0.8636 |     29.043 |   1.1071 |     37.436 |     1.8
   16 |   0.8401 |     28.083 |   1.1196 |     36.387 |     1.9
   17 |   0.8168 |     27.205 |   1.0811 |     35.751 |     2.0
   18 |   0.7924 |     26.295 |   1.1168 |     36.546 |     2.1
   19 |   0.7686 |     25.675 |   1.1253 |     37.150 |     2.2
   20 |   0.7488 |     24.874 |   1.1328 |     36.673 |     2.3
   21 |   0.7146 |     23.639 |   1.1275 |     36.387 |     2.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 327,522

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9949 |     77.842 |   2.4501 |     58.810 |     0.2
    2 |   2.3428 |     55.667 |   1.8565 |     48.537 |     0.3
    3 |   1.8879 |     48.025 |   1.5985 |     46.088 |     0.5
    4 |   1.6703 |     46.330 |   1.5103 |     45.483 |     0.7
    5 |   1.5759 |     46.297 |   1.4589 |     45.420 |     0.8
    6 |   1.5234 |     46.165 |   1.4263 |     45.388 |     1.0
    7 |   1.4837 |     46.001 |   1.4085 |     45.356 |     1.1
    8 |   1.4591 |     46.056 |   1.3876 |     45.388 |     1.3
    9 |   1.4384 |     46.143 |   1.3710 |     45.388 |     1.5
   10 |   1.4179 |     45.940 |   1.3581 |     45.388 |     1.6
   11 |   1.4016 |     45.831 |   1.3420 |     45.642 |     1.8
   12 |   1.3875 |     45.381 |   1.3282 |     44.656 |     2.0
   13 |   1.3759 |     45.233 |   1.3213 |     45.070 |     2.1
   14 |   1.3595 |     45.024 |   1.3068 |     45.134 |     2.3
   15 |   1.3538 |     45.002 |   1.3036 |     43.989 |     2.5
   16 |   1.3414 |     44.492 |   1.2951 |     44.243 |     2.6
   17 |   1.3291 |     44.437 |   1.2781 |     43.830 |     2.8
   18 |   1.3200 |     44.102 |   1.2741 |     42.939 |     3.0
   19 |   1.3109 |     43.910 |   1.2617 |     43.098 |     3.1
   20 |   1.3029 |     43.773 |   1.2528 |     42.653 |     3.3
   21 |   1.2889 |     43.433 |   1.2393 |     42.780 |     3.4
   22 |   1.2853 |     43.450 |   1.2335 |     42.748 |     3.6
   23 |   1.2746 |     43.049 |   1.2305 |     43.003 |     3.8
   24 |   1.2685 |     42.879 |   1.2282 |     42.971 |     3.9
   25 |   1.2575 |     42.550 |   1.2227 |     41.985 |     4.1
   26 |   1.2484 |     42.204 |   1.2126 |     42.048 |     4.3
   27 |   1.2414 |     42.078 |   1.2089 |     41.349 |     4.4
   28 |   1.2340 |     42.012 |   1.2194 |     41.253 |     4.6
   29 |   1.2293 |     41.722 |   1.2178 |     41.889 |     4.8
   30 |   1.2173 |     41.299 |   1.1953 |     40.490 |     4.9
   31 |   1.2113 |     41.080 |   1.1925 |     40.681 |     5.1
   32 |   1.2103 |     41.058 |   1.1957 |     40.553 |     5.2
   33 |   1.2040 |     41.310 |   1.1952 |     40.776 |     5.4
   34 |   1.1917 |     40.575 |   1.2041 |     40.490 |     5.6
   35 |   1.1902 |     40.674 |   1.1951 |     40.013 |     5.7
   36 |   1.1841 |     40.504 |   1.1777 |     39.822 |     5.9
   37 |   1.1810 |     40.756 |   1.1710 |     39.377 |     6.1
   38 |   1.1682 |     40.032 |   1.1865 |     39.440 |     6.2
   39 |   1.1638 |     39.686 |   1.1787 |     38.899 |     6.4
   40 |   1.1651 |     40.207 |   1.1747 |     39.472 |     6.6
   41 |   1.1579 |     39.851 |   1.1711 |     39.090 |     6.7
   42 |   1.1543 |     39.467 |   1.1558 |     38.740 |     6.9
   43 |   1.1479 |     39.368 |   1.1598 |     38.899 |     7.1
   44 |   1.1486 |     39.439 |   1.1638 |     39.027 |     7.2
   45 |   1.1386 |     39.066 |   1.1817 |     39.599 |     7.4
   46 |   1.1313 |     38.644 |   1.1764 |     39.504 |     7.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 226,146

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6098 |     63.189 |   2.0201 |     46.120 |     0.1
    2 |   1.7760 |     46.072 |   1.6353 |     45.579 |     0.1
    3 |   1.5589 |     45.891 |   1.5150 |     45.420 |     0.2
    4 |   1.4671 |     45.534 |   1.4347 |     45.165 |     0.2
    5 |   1.4051 |     44.377 |   1.3890 |     45.293 |     0.3
    6 |   1.3599 |     43.532 |   1.3474 |     44.816 |     0.3
    7 |   1.3229 |     42.824 |   1.3216 |     44.625 |     0.4
    8 |   1.2938 |     42.616 |   1.3021 |     43.130 |     0.5
    9 |   1.2693 |     42.018 |   1.2916 |     43.193 |     0.5
   10 |   1.2472 |     41.546 |   1.2853 |     43.130 |     0.6
   11 |   1.2279 |     41.189 |   1.2856 |     43.225 |     0.6
   12 |   1.2122 |     40.602 |   1.2644 |     42.080 |     0.7
   13 |   1.1952 |     40.558 |   1.2525 |     42.176 |     0.8
   14 |   1.1777 |     39.884 |   1.2434 |     41.826 |     0.8
   15 |   1.1626 |     39.544 |   1.2373 |     41.476 |     0.9
   16 |   1.1457 |     38.776 |   1.2435 |     41.349 |     0.9
   17 |   1.1298 |     38.293 |   1.2080 |     40.872 |     1.0
   18 |   1.1181 |     38.095 |   1.2375 |     41.031 |     1.1
   19 |   1.1048 |     37.497 |   1.2104 |     40.585 |     1.1
   20 |   1.0926 |     37.163 |   1.2115 |     40.458 |     1.2
   21 |   1.0820 |     36.801 |   1.2221 |     40.585 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 898,274

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5889 |     48.716 |   1.3121 |     44.593 |     0.1
    2 |   1.3143 |     45.485 |   1.2454 |     43.670 |     0.3
    3 |   1.2662 |     44.657 |   1.2195 |     43.225 |     0.4
    4 |   1.2397 |     44.569 |   1.1885 |     42.525 |     0.6
    5 |   1.2143 |     43.378 |   1.1746 |     43.575 |     0.7
    6 |   1.2005 |     43.258 |   1.1593 |     41.126 |     0.9
    7 |   1.1826 |     42.780 |   1.1501 |     41.953 |     1.0
    8 |   1.1633 |     41.892 |   1.1490 |     41.158 |     1.1
    9 |   1.1517 |     41.650 |   1.1259 |     39.726 |     1.3
   10 |   1.1395 |     41.398 |   1.1262 |     40.267 |     1.4
   11 |   1.1321 |     41.195 |   1.1122 |     39.695 |     1.6
   12 |   1.1201 |     40.794 |   1.1005 |     39.536 |     1.7
   13 |   1.1142 |     40.498 |   1.1114 |     39.695 |     1.9
   14 |   1.1077 |     40.015 |   1.1105 |     40.140 |     2.0
   15 |   1.1033 |     40.284 |   1.1018 |     39.981 |     2.2
   16 |   1.0956 |     40.048 |   1.1006 |     39.631 |     2.3
   17 |   1.0951 |     40.032 |   1.0932 |     39.726 |     2.4
   18 |   1.0836 |     39.681 |   1.0994 |     39.663 |     2.6
   19 |   1.0831 |     39.851 |   1.1030 |     39.885 |     2.7
   20 |   1.0769 |     39.779 |   1.0862 |     39.345 |     2.9
   21 |   1.0723 |     39.006 |   1.0866 |     39.854 |     3.0
   22 |   1.0642 |     39.022 |   1.0871 |     39.440 |     3.2
   23 |   1.0557 |     38.523 |   1.1302 |     40.363 |     3.3
   24 |   1.0551 |     38.227 |   1.1377 |     40.903 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 393,570

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6326 |     64.653 |   1.9536 |     48.664 |     0.1
    2 |   1.8360 |     47.103 |   1.5726 |     46.374 |     0.2
    3 |   1.5967 |     46.396 |   1.4738 |     45.897 |     0.4
    4 |   1.5073 |     46.001 |   1.4158 |     44.784 |     0.5
    5 |   1.4507 |     45.469 |   1.3829 |     44.975 |     0.6
    6 |   1.4094 |     44.865 |   1.3504 |     43.162 |     0.7
    7 |   1.3781 |     44.421 |   1.3176 |     43.193 |     0.8
    8 |   1.3544 |     44.327 |   1.3132 |     44.338 |     0.9
    9 |   1.3310 |     44.026 |   1.2927 |     43.289 |     1.1
   10 |   1.3142 |     44.108 |   1.2842 |     43.893 |     1.2
   11 |   1.2954 |     43.850 |   1.2630 |     43.066 |     1.3
   12 |   1.2784 |     43.181 |   1.2712 |     44.020 |     1.4
   13 |   1.2659 |     42.709 |   1.2533 |     43.416 |     1.5
   14 |   1.2502 |     42.259 |   1.2569 |     42.716 |     1.7
   15 |   1.2305 |     41.634 |   1.2641 |     42.144 |     1.8
   16 |   1.2240 |     41.387 |   1.2464 |     42.430 |     1.9
   17 |   1.2145 |     41.250 |   1.2572 |     42.271 |     2.0
   18 |   1.2016 |     40.904 |   1.2325 |     41.221 |     2.1
   19 |   1.1902 |     40.921 |   1.2359 |     41.539 |     2.2
   20 |   1.1809 |     40.542 |   1.2213 |     41.158 |     2.4
   21 |   1.1750 |     40.054 |   1.2247 |     41.317 |     2.5
   22 |   1.1607 |     39.708 |   1.2218 |     41.094 |     2.6
   23 |   1.1590 |     39.708 |   1.2561 |     41.953 |     2.7
   24 |   1.1440 |     39.176 |   1.2348 |     41.794 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 292,194

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4985 |     59.952 |   1.8562 |     45.611 |     0.1
    2 |   1.6853 |     45.770 |   1.5728 |     45.356 |     0.1
    3 |   1.5207 |     45.458 |   1.4737 |     45.547 |     0.2
    4 |   1.4420 |     44.536 |   1.4064 |     43.766 |     0.2
    5 |   1.3896 |     44.108 |   1.3668 |     43.384 |     0.3
    6 |   1.3501 |     43.455 |   1.3419 |     43.702 |     0.4
    7 |   1.3171 |     42.660 |   1.3175 |     42.939 |     0.4
    8 |   1.2870 |     41.990 |   1.3040 |     43.352 |     0.5
    9 |   1.2597 |     41.370 |   1.2704 |     42.080 |     0.5
   10 |   1.2369 |     40.899 |   1.2564 |     41.698 |     0.6
   11 |   1.2157 |     40.668 |   1.2537 |     41.508 |     0.7
   12 |   1.1971 |     39.977 |   1.2326 |     41.253 |     0.7
   13 |   1.1804 |     39.664 |   1.2257 |     41.158 |     0.8
   14 |   1.1629 |     39.439 |   1.2305 |     40.872 |     0.9
   15 |   1.1466 |     38.534 |   1.1947 |     40.712 |     0.9
   16 |   1.1305 |     38.309 |   1.1828 |     39.567 |     1.0
   17 |   1.1159 |     37.678 |   1.1779 |     40.013 |     1.0
   18 |   1.0994 |     37.124 |   1.1779 |     40.426 |     1.1
   19 |   1.0886 |     37.004 |   1.1771 |     39.758 |     1.2
   20 |   1.0700 |     36.290 |   1.1519 |     38.772 |     1.2
   21 |   1.0560 |     35.753 |   1.1464 |     39.090 |     1.3
   22 |   1.0453 |     35.561 |   1.1623 |     39.440 |     1.3
   23 |   1.0306 |     35.105 |   1.1593 |     39.472 |     1.4
   24 |   1.0172 |     34.491 |   1.1349 |     39.059 |     1.5
   25 |   1.0014 |     33.750 |   1.1453 |     39.567 |     1.5
   26 |   0.9945 |     33.498 |   1.1373 |     38.899 |     1.6
   27 |   0.9770 |     32.774 |   1.1406 |     39.090 |     1.6
   28 |   0.9678 |     32.329 |   1.1678 |     39.281 |     1.7
   29 |   0.9534 |     31.819 |   1.1273 |     38.168 |     1.8
   30 |   0.9406 |     31.293 |   1.1446 |     38.709 |     1.8
   31 |   0.9305 |     30.969 |   1.1280 |     38.295 |     1.9
   32 |   0.9204 |     30.733 |   1.1308 |     38.422 |     2.0
   33 |   0.9028 |     29.756 |   1.1660 |     39.281 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 779,938

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4512 |     46.555 |   1.2624 |     44.084 |     0.1
    2 |   1.1938 |     41.480 |   1.1516 |     39.822 |     0.2
    3 |   1.1187 |     39.253 |   1.1243 |     38.995 |     0.3
    4 |   1.0574 |     37.020 |   1.0730 |     37.214 |     0.4
    5 |   1.0200 |     35.698 |   1.0413 |     35.910 |     0.5
    6 |   0.9732 |     34.008 |   1.0379 |     37.055 |     0.6
    7 |   0.9234 |     32.088 |   1.0366 |     35.083 |     0.7
    8 |   0.8755 |     30.519 |   1.0088 |     35.337 |     0.8
    9 |   0.8347 |     29.076 |   1.0174 |     34.701 |     0.9
   10 |   0.7902 |     27.425 |   1.0166 |     34.128 |     1.0
   11 |   0.7385 |     25.603 |   1.0235 |     33.492 |     1.1
   12 |   0.6953 |     23.919 |   1.0720 |     35.083 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 847,522

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4817 |     62.201 |   1.6942 |     48.505 |     0.2
    2 |   1.6714 |     46.560 |   1.4362 |     45.102 |     0.3
    3 |   1.4875 |     45.968 |   1.3577 |     44.879 |     0.5
    4 |   1.4138 |     45.650 |   1.3165 |     44.975 |     0.7
    5 |   1.3634 |     44.679 |   1.2940 |     43.511 |     0.9
    6 |   1.3292 |     43.971 |   1.2645 |     42.080 |     1.1
    7 |   1.2980 |     42.704 |   1.2415 |     41.762 |     1.2
    8 |   1.2745 |     42.056 |   1.2196 |     41.253 |     1.4
    9 |   1.2505 |     41.683 |   1.2391 |     41.635 |     1.6
   10 |   1.2295 |     40.871 |   1.1942 |     40.872 |     1.8
   11 |   1.2116 |     40.460 |   1.2258 |     41.221 |     1.9
   12 |   1.1951 |     40.125 |   1.1928 |     40.872 |     2.1
   13 |   1.1785 |     40.054 |   1.1700 |     39.758 |     2.3
   14 |   1.1694 |     39.489 |   1.1730 |     39.504 |     2.5
   15 |   1.1532 |     39.198 |   1.1712 |     39.790 |     2.6
   16 |   1.1406 |     38.770 |   1.1576 |     39.790 |     2.8
   17 |   1.1303 |     38.540 |   1.1387 |     38.613 |     3.0
   18 |   1.1147 |     37.854 |   1.1784 |     38.899 |     3.2
   19 |   1.1059 |     37.728 |   1.1368 |     38.486 |     3.4
   20 |   1.0914 |     37.250 |   1.1942 |     39.981 |     3.5
   21 |   1.0826 |     36.811 |   1.1622 |     38.868 |     3.7
   22 |   1.0688 |     36.493 |   1.1595 |     38.804 |     3.9
   23 |   1.0625 |     36.076 |   1.1437 |     38.963 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 226,146

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7747 |     49.704 |   1.3498 |     44.402 |     0.1
    2 |   1.3530 |     45.112 |   1.2915 |     43.989 |     0.1
    3 |   1.2935 |     43.976 |   1.2431 |     43.130 |     0.2
    4 |   1.2622 |     43.307 |   1.2099 |     41.730 |     0.3
    5 |   1.2380 |     42.588 |   1.1939 |     41.126 |     0.3
    6 |   1.2068 |     41.705 |   1.1786 |     41.190 |     0.4
    7 |   1.1844 |     40.904 |   1.1754 |     39.631 |     0.4
    8 |   1.1689 |     40.526 |   1.1450 |     38.709 |     0.5
    9 |   1.1466 |     40.015 |   1.1797 |     39.567 |     0.6
   10 |   1.1340 |     39.719 |   1.1657 |     39.440 |     0.6
   11 |   1.1213 |     39.116 |   1.1276 |     38.963 |     0.7
   12 |   1.0989 |     38.441 |   1.1135 |     38.740 |     0.8
   13 |   1.0885 |     37.914 |   1.0984 |     38.295 |     0.8
   14 |   1.0675 |     37.563 |   1.1158 |     38.645 |     0.9
   15 |   1.0601 |     37.130 |   1.0984 |     37.850 |     0.9
   16 |   1.0377 |     36.751 |   1.1029 |     37.945 |     1.0
   17 |   1.0319 |     36.356 |   1.1150 |     37.595 |     1.1
   18 |   1.0203 |     35.594 |   1.0969 |     36.864 |     1.1
   19 |   1.0022 |     35.325 |   1.0933 |     36.768 |     1.2
   20 |   0.9997 |     34.886 |   1.0801 |     36.101 |     1.3
   21 |   0.9840 |     34.315 |   1.0856 |     36.419 |     1.3
   22 |   0.9731 |     33.887 |   1.1306 |     37.500 |     1.4
   23 |   0.9617 |     33.822 |   1.1148 |     37.150 |     1.5
   24 |   0.9472 |     32.889 |   1.1414 |     38.009 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 293,090

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7740 |     49.720 |   1.3540 |     44.847 |     0.1
    2 |   1.3614 |     45.447 |   1.2783 |     44.020 |     0.3
    3 |   1.3099 |     45.139 |   1.2356 |     43.830 |     0.4
    4 |   1.2780 |     44.541 |   1.2021 |     42.048 |     0.6
    5 |   1.2488 |     43.801 |   1.1988 |     42.748 |     0.7
    6 |   1.2362 |     43.702 |   1.1747 |     41.667 |     0.9
    7 |   1.2187 |     43.241 |   1.1791 |     42.271 |     1.0
    8 |   1.2048 |     42.753 |   1.1579 |     41.762 |     1.2
    9 |   1.1905 |     42.621 |   1.1592 |     42.398 |     1.3
   10 |   1.1884 |     42.758 |   1.1460 |     42.207 |     1.5
   11 |   1.1772 |     42.517 |   1.1384 |     40.840 |     1.6
   12 |   1.1661 |     42.210 |   1.1412 |     41.349 |     1.8
   13 |   1.1676 |     42.221 |   1.1349 |     41.094 |     1.9
   14 |   1.1598 |     41.914 |   1.1350 |     41.539 |     2.1
   15 |   1.1564 |     42.078 |   1.1199 |     40.744 |     2.2
   16 |   1.1447 |     41.968 |   1.1273 |     40.681 |     2.4
   17 |   1.1454 |     41.870 |   1.1208 |     41.094 |     2.5
   18 |   1.1434 |     41.628 |   1.1252 |     40.840 |     2.7
   19 |   1.1361 |     41.645 |   1.1121 |     40.967 |     2.8
   20 |   1.1312 |     41.573 |   1.1135 |     41.221 |     3.0
   21 |   1.1302 |     41.359 |   1.1120 |     41.412 |     3.1
   22 |   1.1269 |     41.299 |   1.1150 |     40.840 |     3.3
   23 |   1.1253 |     41.348 |   1.1085 |     40.776 |     3.4
   24 |   1.1263 |     41.195 |   1.0979 |     40.140 |     3.6
   25 |   1.1231 |     41.381 |   1.1126 |     40.585 |     3.7
   26 |   1.1189 |     41.365 |   1.1045 |     40.744 |     3.9
   27 |   1.1223 |     41.239 |   1.1061 |     40.108 |     4.0
   28 |   1.1098 |     41.047 |   1.1002 |     40.172 |     4.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 292,194

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5340 |     59.738 |   1.8745 |     46.533 |     0.1
    2 |   1.6995 |     45.973 |   1.5833 |     45.961 |     0.2
    3 |   1.5268 |     45.189 |   1.4718 |     45.229 |     0.2
    4 |   1.4396 |     44.311 |   1.4078 |     42.875 |     0.3
    5 |   1.3830 |     44.086 |   1.3640 |     44.020 |     0.4
    6 |   1.3358 |     43.159 |   1.3352 |     43.289 |     0.5
    7 |   1.3003 |     42.358 |   1.3141 |     42.653 |     0.6
    8 |   1.2731 |     41.804 |   1.3146 |     43.289 |     0.7
    9 |   1.2456 |     40.838 |   1.2676 |     40.999 |     0.7
   10 |   1.2221 |     40.438 |   1.2627 |     40.808 |     0.8
   11 |   1.2006 |     40.262 |   1.2464 |     42.048 |     0.9
   12 |   1.1785 |     39.505 |   1.2378 |     41.762 |     1.0
   13 |   1.1635 |     39.346 |   1.2092 |     40.267 |     1.1
   14 |   1.1475 |     38.940 |   1.1949 |     39.917 |     1.2
   15 |   1.1318 |     38.523 |   1.1861 |     39.822 |     1.2
   16 |   1.1139 |     37.772 |   1.1893 |     39.504 |     1.3
   17 |   1.1014 |     37.514 |   1.1736 |     39.567 |     1.4
   18 |   1.0856 |     36.965 |   1.1927 |     39.822 |     1.5
   19 |   1.0720 |     36.504 |   1.1800 |     39.249 |     1.6
   20 |   1.0601 |     35.884 |   1.1730 |     39.408 |     1.6
   21 |   1.0493 |     35.703 |   1.1780 |     39.377 |     1.7
   22 |   1.0361 |     35.440 |   1.1523 |     38.422 |     1.8
   23 |   1.0233 |     34.650 |   1.1366 |     38.295 |     1.9
   24 |   1.0113 |     34.266 |   1.1584 |     38.709 |     2.0
   25 |   1.0028 |     34.057 |   1.1417 |     38.041 |     2.1
   26 |   0.9879 |     33.608 |   1.1289 |     37.945 |     2.1
   27 |   0.9784 |     33.075 |   1.1251 |     37.786 |     2.2
   28 |   0.9627 |     32.269 |   1.1246 |     37.850 |     2.3
   29 |   0.9548 |     32.329 |   1.1497 |     38.295 |     2.4
   30 |   0.9440 |     31.792 |   1.1438 |     38.868 |     2.5
   31 |   0.9307 |     31.210 |   1.1216 |     38.136 |     2.6
   32 |   0.9194 |     30.903 |   1.1462 |     38.836 |     2.6
   33 |   0.9115 |     30.492 |   1.1308 |     37.945 |     2.7
   34 |   0.9006 |     30.162 |   1.1310 |     37.723 |     2.8
   35 |   0.8874 |     29.630 |   1.1480 |     38.295 |     2.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 358,946

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6790 |     64.363 |   1.9733 |     49.173 |     0.1
    2 |   1.9078 |     47.795 |   1.6005 |     45.420 |     0.2
    3 |   1.6415 |     46.308 |   1.4954 |     45.420 |     0.3
    4 |   1.5438 |     46.066 |   1.4422 |     45.420 |     0.4
    5 |   1.4867 |     45.721 |   1.4056 |     45.420 |     0.5
    6 |   1.4490 |     45.704 |   1.3759 |     45.165 |     0.6
    7 |   1.4152 |     45.512 |   1.3573 |     43.798 |     0.7
    8 |   1.3907 |     45.172 |   1.3570 |     45.324 |     0.8
    9 |   1.3663 |     44.651 |   1.3361 |     45.293 |     0.9
   10 |   1.3455 |     44.437 |   1.3324 |     45.102 |     1.0
   11 |   1.3307 |     44.262 |   1.3104 |     45.611 |     1.1
   12 |   1.3170 |     43.609 |   1.2785 |     43.957 |     1.2
   13 |   1.2985 |     43.099 |   1.2917 |     44.211 |     1.3
   14 |   1.2876 |     43.044 |   1.2698 |     43.766 |     1.4
   15 |   1.2686 |     42.424 |   1.2725 |     43.607 |     1.5
   16 |   1.2600 |     42.380 |   1.2553 |     42.494 |     1.6
   17 |   1.2477 |     42.259 |   1.2744 |     42.653 |     1.7
   18 |   1.2375 |     41.903 |   1.2476 |     42.812 |     1.8
   19 |   1.2250 |     41.568 |   1.2621 |     42.780 |     1.9
   20 |   1.2184 |     41.359 |   1.2540 |     42.366 |     2.0
   21 |   1.2048 |     40.679 |   1.2403 |     41.571 |     2.1
   22 |   1.1996 |     40.608 |   1.2468 |     42.494 |     2.2
   23 |   1.1939 |     40.740 |   1.2395 |     41.858 |     2.3
   24 |   1.1846 |     40.021 |   1.2837 |     42.462 |     2.4
   25 |   1.1794 |     40.279 |   1.2511 |     42.017 |     2.5
   26 |   1.1724 |     40.257 |   1.2362 |     41.858 |     2.6
   27 |   1.1622 |     39.812 |   1.2359 |     41.635 |     2.7
   28 |   1.1590 |     39.708 |   1.2226 |     41.476 |     2.8
   29 |   1.1554 |     39.434 |   1.2258 |     41.539 |     2.9
   30 |   1.1468 |     39.434 |   1.2486 |     41.985 |     2.9
   31 |   1.1392 |     39.187 |   1.2533 |     41.826 |     3.0
   32 |   1.1349 |     38.978 |   1.2190 |     41.094 |     3.1
   33 |   1.1317 |     38.847 |   1.2111 |     41.285 |     3.2
   34 |   1.1242 |     38.633 |   1.2491 |     41.508 |     3.3
   35 |   1.1189 |     38.518 |   1.2108 |     40.776 |     3.4
   36 |   1.1126 |     38.276 |   1.2087 |     40.967 |     3.5
   37 |   1.1065 |     38.145 |   1.2293 |     41.221 |     3.6
   38 |   1.1002 |     38.035 |   1.2608 |     41.571 |     3.7
   39 |   1.0968 |     37.821 |   1.2077 |     40.999 |     3.8
   40 |   1.0898 |     37.673 |   1.2273 |     40.903 |     3.9
   41 |   1.0861 |     37.333 |   1.2300 |     41.031 |     4.0
   42 |   1.0825 |     37.053 |   1.2237 |     40.999 |     4.1
   43 |   1.0755 |     36.905 |   1.2097 |     40.967 |     4.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 392,162

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6422 |     47.877 |   1.3152 |     44.688 |     0.1
    2 |   1.2670 |     43.406 |   1.2269 |     42.653 |     0.3
    3 |   1.2033 |     42.720 |   1.1759 |     40.840 |     0.4
    4 |   1.1667 |     41.837 |   1.1672 |     42.557 |     0.6
    5 |   1.1392 |     41.025 |   1.1705 |     42.653 |     0.7
    6 |   1.1233 |     41.244 |   1.1296 |     40.267 |     0.8
    7 |   1.1131 |     40.816 |   1.1303 |     40.649 |     1.0
    8 |   1.1033 |     40.602 |   1.1185 |     40.172 |     1.1
    9 |   1.0956 |     40.432 |   1.1165 |     40.426 |     1.3
   10 |   1.0896 |     40.531 |   1.1101 |     39.854 |     1.4
   11 |   1.0856 |     40.372 |   1.1100 |     40.903 |     1.5
   12 |   1.0802 |     40.707 |   1.1168 |     40.808 |     1.7
   13 |   1.0793 |     40.487 |   1.1089 |     40.617 |     1.8
   14 |   1.0763 |     40.207 |   1.1007 |     40.426 |     2.0
   15 |   1.0719 |     40.065 |   1.0957 |     39.949 |     2.1
   16 |   1.0693 |     40.196 |   1.0968 |     40.617 |     2.2
   17 |   1.0665 |     39.961 |   1.1004 |     39.663 |     2.4
   18 |   1.0670 |     40.218 |   1.0897 |     39.917 |     2.5
   19 |   1.0644 |     40.213 |   1.0967 |     40.935 |     2.7
   20 |   1.0575 |     39.505 |   1.1075 |     41.126 |     2.8
   21 |   1.0435 |     38.693 |   1.1464 |     41.062 |     2.9
   22 |   1.0314 |     38.287 |   1.1558 |     41.031 |     3.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 779,938

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0521 |     53.895 |   1.4875 |     45.356 |     0.1
    2 |   1.4122 |     44.426 |   1.3527 |     44.434 |     0.2
    3 |   1.3264 |     43.422 |   1.3074 |     43.702 |     0.2
    4 |   1.2767 |     42.550 |   1.2772 |     42.653 |     0.3
    5 |   1.2344 |     41.332 |   1.2641 |     42.366 |     0.4
    6 |   1.1958 |     40.355 |   1.2216 |     40.458 |     0.5
    7 |   1.1631 |     39.406 |   1.1733 |     39.504 |     0.6
    8 |   1.1341 |     38.507 |   1.1746 |     40.522 |     0.6
    9 |   1.1076 |     37.547 |   1.1476 |     39.059 |     0.7
   10 |   1.0843 |     36.674 |   1.1408 |     38.963 |     0.8
   11 |   1.0544 |     35.577 |   1.1427 |     38.645 |     0.9
   12 |   1.0321 |     34.793 |   1.1183 |     37.500 |     1.0
   13 |   1.0063 |     34.014 |   1.0941 |     37.277 |     1.0
   14 |   0.9830 |     33.152 |   1.1024 |     36.514 |     1.1
   15 |   0.9599 |     32.631 |   1.0993 |     36.832 |     1.2
   16 |   0.9381 |     31.589 |   1.0883 |     36.482 |     1.3
   17 |   0.9137 |     30.919 |   1.0931 |     36.800 |     1.4
   18 |   0.8972 |     30.393 |   1.1077 |     37.277 |     1.4
   19 |   0.8735 |     29.383 |   1.1192 |     37.468 |     1.5
   20 |   0.8522 |     28.944 |   1.0908 |     36.323 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 847,522

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5253 |     46.862 |   1.2786 |     43.702 |     0.2
    2 |   1.2696 |     44.146 |   1.2092 |     42.589 |     0.3
    3 |   1.2327 |     43.839 |   1.1757 |     42.653 |     0.5
    4 |   1.1995 |     42.780 |   1.1726 |     41.858 |     0.7
    5 |   1.1750 |     41.881 |   1.1435 |     39.218 |     0.9
    6 |   1.1589 |     40.899 |   1.1383 |     40.076 |     1.1
    7 |   1.1400 |     40.668 |   1.1125 |     39.377 |     1.2
    8 |   1.1286 |     40.827 |   1.1202 |     40.363 |     1.4
    9 |   1.1205 |     40.169 |   1.0942 |     38.963 |     1.6
   10 |   1.1052 |     39.626 |   1.1089 |     39.408 |     1.8
   11 |   1.0979 |     39.439 |   1.0926 |     38.677 |     1.9
   12 |   1.0876 |     39.028 |   1.0907 |     38.645 |     2.1
   13 |   1.0774 |     38.984 |   1.0958 |     39.027 |     2.3
   14 |   1.0763 |     38.858 |   1.0925 |     37.786 |     2.5
   15 |   1.0606 |     38.501 |   1.0687 |     38.486 |     2.6
   16 |   1.0583 |     38.529 |   1.0849 |     38.613 |     2.8
   17 |   1.0499 |     38.134 |   1.0679 |     37.882 |     3.0
   18 |   1.0440 |     37.826 |   1.0688 |     38.677 |     3.2
   19 |   1.0449 |     37.958 |   1.0696 |     37.564 |     3.4
   20 |   1.0405 |     37.766 |   1.0630 |     37.595 |     3.5
   21 |   1.0357 |     37.426 |   1.0589 |     37.913 |     3.7
   22 |   1.0330 |     37.733 |   1.0720 |     38.073 |     3.9
   23 |   1.0322 |     37.629 |   1.0440 |     37.214 |     4.1
   24 |   1.0239 |     37.300 |   1.0619 |     38.550 |     4.2
   25 |   1.0257 |     37.409 |   1.0498 |     37.595 |     4.4
   26 |   1.0184 |     36.938 |   1.0393 |     37.754 |     4.6
   27 |   1.0055 |     36.658 |   1.0474 |     37.659 |     4.8
   28 |   1.0066 |     36.696 |   1.0544 |     37.182 |     4.9
   29 |   0.9985 |     36.203 |   1.0521 |     37.214 |     5.1
   30 |   0.9951 |     36.208 |   1.0495 |     38.327 |     5.3
   31 |   0.9956 |     36.246 |   1.0374 |     37.150 |     5.5
   32 |   0.9866 |     36.082 |   1.0210 |     36.641 |     5.6
   33 |   0.9798 |     35.703 |   1.0354 |     37.500 |     5.8
   34 |   0.9774 |     35.714 |   1.0209 |     36.768 |     6.0
   35 |   0.9731 |     35.627 |   1.0311 |     36.641 |     6.2
   36 |   0.9820 |     35.731 |   1.0380 |     36.832 |     6.3
   37 |   0.9724 |     35.215 |   1.0449 |     36.737 |     6.5
   38 |   0.9619 |     35.045 |   1.0273 |     36.578 |     6.7
   39 |   0.9534 |     34.480 |   1.0184 |     36.069 |     6.9
   40 |   0.9504 |     34.387 |   1.0264 |     35.433 |     7.1
   41 |   0.9446 |     34.200 |   1.0371 |     36.228 |     7.2
   42 |   0.9496 |     34.376 |   1.0227 |     35.878 |     7.4
   43 |   0.9409 |     34.025 |   1.0253 |     35.242 |     7.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 393,570

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9119 |     53.955 |   1.3803 |     45.547 |     0.1
    2 |   1.3913 |     46.061 |   1.3157 |     45.102 |     0.2
    3 |   1.3422 |     45.600 |   1.2903 |     45.452 |     0.4
    4 |   1.3023 |     45.106 |   1.2388 |     43.257 |     0.5
    5 |   1.2696 |     44.393 |   1.2097 |     42.971 |     0.6
    6 |   1.2410 |     43.510 |   1.1944 |     42.462 |     0.7
    7 |   1.2305 |     43.263 |   1.1850 |     41.476 |     0.8
    8 |   1.2113 |     42.572 |   1.1681 |     40.935 |     0.9
    9 |   1.2044 |     42.462 |   1.1708 |     41.444 |     1.1
   10 |   1.1942 |     41.930 |   1.1522 |     39.981 |     1.2
   11 |   1.1855 |     41.700 |   1.1366 |     40.045 |     1.3
   12 |   1.1738 |     41.519 |   1.1354 |     39.917 |     1.4
   13 |   1.1597 |     41.228 |   1.1277 |     39.345 |     1.5
   14 |   1.1543 |     41.222 |   1.1076 |     39.281 |     1.7
   15 |   1.1415 |     40.487 |   1.1103 |     39.536 |     1.8
   16 |   1.1271 |     40.257 |   1.0957 |     38.772 |     1.9
   17 |   1.1204 |     39.939 |   1.0987 |     38.581 |     2.0
   18 |   1.1099 |     39.609 |   1.0875 |     37.277 |     2.1
   19 |   1.1029 |     39.544 |   1.0997 |     38.963 |     2.2
   20 |   1.0963 |     39.044 |   1.0835 |     38.645 |     2.4
   21 |   1.0842 |     38.924 |   1.0851 |     38.073 |     2.5
   22 |   1.0819 |     38.830 |   1.0742 |     38.899 |     2.6
   23 |   1.0759 |     38.518 |   1.0795 |     38.486 |     2.7
   24 |   1.0626 |     37.684 |   1.0829 |     39.027 |     2.8
   25 |   1.0621 |     38.386 |   1.0957 |     39.663 |     2.9
   26 |   1.0537 |     37.832 |   1.1080 |     38.995 |     3.1
Early stopping

