Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 276,258

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6241 |     47.365 |   1.3118 |     43.173 |     0.1
    2 |   1.2618 |     42.987 |   1.2413 |     43.397 |     0.1
    3 |   1.1804 |     40.998 |   1.1854 |     42.981 |     0.2
    4 |   1.1327 |     39.179 |   1.1157 |     39.327 |     0.3
    5 |   1.0671 |     36.840 |   1.0663 |     37.628 |     0.3
    6 |   1.0243 |     35.722 |   1.0386 |     35.769 |     0.4
    7 |   0.9747 |     33.459 |   0.9979 |     35.064 |     0.5
    8 |   0.9361 |     32.391 |   0.9726 |     33.237 |     0.6
    9 |   0.9028 |     31.060 |   0.9656 |     33.141 |     0.6
   10 |   0.8565 |     29.301 |   0.9930 |     33.462 |     0.7
   11 |   0.8083 |     27.597 |   0.9449 |     32.372 |     0.8
   12 |   0.7823 |     26.759 |   0.9367 |     32.179 |     0.8
   13 |   0.7408 |     25.027 |   0.9623 |     32.404 |     0.9
   14 |   0.7110 |     24.266 |   0.9396 |     32.244 |     1.0
   15 |   0.6877 |     23.219 |   0.9824 |     30.737 |     1.1
   16 |   0.6692 |     22.841 |   0.9259 |     30.032 |     1.1
   17 |   0.6245 |     21.302 |   0.9397 |     29.071 |     1.2
   18 |   0.5748 |     19.746 |   1.0033 |     30.737 |     1.3
   19 |   0.5526 |     18.776 |   0.9803 |     31.218 |     1.4
   20 |   0.5079 |     17.138 |   0.9875 |     29.679 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 326,498

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4930 |     59.237 |   1.8667 |     46.987 |     0.1
    2 |   1.6684 |     46.318 |   1.5602 |     45.609 |     0.2
    3 |   1.5103 |     45.485 |   1.4631 |     45.064 |     0.2
    4 |   1.4327 |     44.620 |   1.3970 |     43.462 |     0.3
    5 |   1.3786 |     43.710 |   1.3611 |     43.462 |     0.4
    6 |   1.3448 |     43.217 |   1.3186 |     43.045 |     0.5
    7 |   1.3100 |     42.275 |   1.2925 |     42.212 |     0.6
    8 |   1.2784 |     41.650 |   1.2617 |     41.442 |     0.7
    9 |   1.2489 |     41.185 |   1.2496 |     41.667 |     0.7
   10 |   1.2228 |     40.467 |   1.2135 |     40.897 |     0.8
   11 |   1.2050 |     39.886 |   1.1964 |     40.000 |     0.9
   12 |   1.1826 |     39.683 |   1.1951 |     39.679 |     1.0
   13 |   1.1618 |     38.823 |   1.1577 |     38.462 |     1.1
   14 |   1.1473 |     38.440 |   1.1619 |     39.135 |     1.2
   15 |   1.1307 |     38.078 |   1.1244 |     38.141 |     1.2
   16 |   1.1141 |     37.656 |   1.1327 |     38.846 |     1.3
   17 |   1.0975 |     37.021 |   1.1241 |     37.885 |     1.4
   18 |   1.0792 |     36.467 |   1.1039 |     37.468 |     1.5
   19 |   1.0694 |     36.281 |   1.0735 |     36.667 |     1.5
   20 |   1.0543 |     35.777 |   1.0840 |     36.442 |     1.6
   21 |   1.0432 |     35.108 |   1.0815 |     36.122 |     1.7
   22 |   1.0261 |     34.424 |   1.0465 |     35.256 |     1.8
   23 |   1.0080 |     34.062 |   1.0494 |     35.897 |     1.9
   24 |   0.9962 |     33.624 |   1.0338 |     34.744 |     1.9
   25 |   0.9851 |     33.290 |   1.0344 |     33.974 |     2.0
   26 |   0.9732 |     33.153 |   1.0149 |     34.295 |     2.1
   27 |   0.9536 |     31.931 |   1.0161 |     34.167 |     2.2
   28 |   0.9411 |     31.498 |   1.0088 |     34.135 |     2.3
   29 |   0.9335 |     31.087 |   0.9880 |     33.173 |     2.3
   30 |   0.9163 |     30.594 |   1.0028 |     33.814 |     2.4
   31 |   0.9051 |     30.145 |   0.9866 |     33.365 |     2.5
   32 |   0.8918 |     29.778 |   0.9876 |     33.526 |     2.6
   33 |   0.8771 |     29.356 |   1.0236 |     35.224 |     2.7
   34 |   0.8756 |     29.372 |   0.9733 |     32.949 |     2.7
   35 |   0.8554 |     28.517 |   0.9800 |     33.718 |     2.8
   36 |   0.8501 |     28.512 |   0.9827 |     33.526 |     2.9
   37 |   0.8357 |     27.860 |   0.9582 |     32.724 |     3.0
   38 |   0.8271 |     27.602 |   0.9692 |     32.885 |     3.1
   39 |   0.8154 |     27.104 |   0.9583 |     31.923 |     3.1
   40 |   0.8008 |     26.282 |   0.9548 |     32.436 |     3.2
   41 |   0.7957 |     26.408 |   0.9435 |     31.410 |     3.3
   42 |   0.7949 |     26.561 |   0.9441 |     31.731 |     3.4
   43 |   0.7786 |     26.063 |   0.9716 |     32.340 |     3.5
   44 |   0.7660 |     25.778 |   0.9486 |     31.891 |     3.5
   45 |   0.7566 |     25.060 |   0.9449 |     31.827 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 234,978

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7536 |     49.830 |   1.3631 |     43.846 |     0.1
    2 |   1.3556 |     45.042 |   1.2931 |     42.788 |     0.2
    3 |   1.2841 |     43.283 |   1.2284 |     41.314 |     0.2
    4 |   1.2391 |     42.138 |   1.1861 |     40.865 |     0.3
    5 |   1.1969 |     41.332 |   1.1620 |     40.962 |     0.4
    6 |   1.1640 |     40.352 |   1.1252 |     38.782 |     0.4
    7 |   1.1426 |     39.727 |   1.1036 |     38.846 |     0.5
    8 |   1.1216 |     38.768 |   1.0986 |     37.340 |     0.6
    9 |   1.0956 |     37.985 |   1.0705 |     36.891 |     0.7
   10 |   1.0752 |     36.785 |   1.0817 |     37.179 |     0.8
   11 |   1.0433 |     36.139 |   1.0260 |     34.647 |     0.9
   12 |   1.0276 |     34.900 |   1.0350 |     33.526 |     0.9
   13 |   1.0148 |     34.993 |   1.0287 |     34.968 |     1.0
   14 |   0.9935 |     33.898 |   0.9802 |     33.269 |     1.1
   15 |   0.9697 |     33.552 |   0.9907 |     33.558 |     1.2
   16 |   0.9498 |     32.451 |   0.9753 |     33.269 |     1.3
   17 |   0.9336 |     31.870 |   0.9942 |     33.077 |     1.3
   18 |   0.9201 |     31.432 |   0.9609 |     31.474 |     1.4
   19 |   0.9059 |     30.934 |   0.9770 |     31.891 |     1.5
   20 |   0.8825 |     30.287 |   0.9407 |     31.346 |     1.6
   21 |   0.8603 |     29.630 |   0.9483 |     32.244 |     1.7
   22 |   0.8631 |     29.279 |   0.9531 |     31.186 |     1.7
   23 |   0.8390 |     28.665 |   0.9343 |     30.994 |     1.8
   24 |   0.8312 |     28.178 |   0.9412 |     32.404 |     1.9
   25 |   0.8175 |     28.353 |   0.9373 |     30.994 |     2.0
   26 |   0.8075 |     27.350 |   0.9635 |     30.673 |     2.1
   27 |   0.8025 |     27.570 |   0.9277 |     30.609 |     2.1
   28 |   0.7682 |     26.326 |   0.9612 |     30.897 |     2.2
   29 |   0.7568 |     26.030 |   0.9559 |     30.192 |     2.3
   30 |   0.7397 |     25.066 |   0.9419 |     30.160 |     2.4
   31 |   0.7333 |     25.164 |   0.9296 |     29.679 |     2.4
   32 |   0.7105 |     24.266 |   0.9197 |     29.071 |     2.5
   33 |   0.7078 |     24.101 |   0.9409 |     29.615 |     2.6
   34 |   0.6914 |     23.647 |   0.9512 |     29.744 |     2.7
   35 |   0.6878 |     23.258 |   0.9490 |     30.064 |     2.7
   36 |   0.6619 |     22.507 |   0.9771 |     29.744 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 392,034

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7411 |     49.578 |   1.3464 |     44.199 |     0.2
    2 |   1.3464 |     45.233 |   1.2678 |     42.692 |     0.3
    3 |   1.2884 |     44.297 |   1.2228 |     42.981 |     0.5
    4 |   1.2574 |     43.858 |   1.2053 |     43.333 |     0.7
    5 |   1.2395 |     43.579 |   1.1770 |     41.538 |     0.9
    6 |   1.2240 |     43.283 |   1.1620 |     41.282 |     1.0
    7 |   1.2142 |     43.354 |   1.1497 |     41.474 |     1.2
    8 |   1.1966 |     42.850 |   1.1542 |     42.853 |     1.4
    9 |   1.1929 |     42.872 |   1.1292 |     40.545 |     1.6
   10 |   1.1802 |     42.406 |   1.1249 |     40.929 |     1.7
   11 |   1.1790 |     42.220 |   1.1145 |     40.288 |     1.9
   12 |   1.1648 |     42.121 |   1.1318 |     41.955 |     2.1
   13 |   1.1629 |     42.346 |   1.1060 |     40.737 |     2.2
   14 |   1.1565 |     42.220 |   1.1045 |     40.962 |     2.4
   15 |   1.1496 |     42.132 |   1.1046 |     40.673 |     2.6
   16 |   1.1478 |     41.771 |   1.1007 |     40.032 |     2.7
   17 |   1.1430 |     41.442 |   1.0924 |     40.353 |     2.9
   18 |   1.1410 |     41.574 |   1.0904 |     40.417 |     3.1
   19 |   1.1424 |     41.837 |   1.0845 |     40.096 |     3.2
   20 |   1.1369 |     41.535 |   1.0833 |     39.551 |     3.4
   21 |   1.1271 |     41.217 |   1.0840 |     40.064 |     3.6
   22 |   1.1278 |     41.217 |   1.0837 |     40.705 |     3.7
   23 |   1.1223 |     41.398 |   1.0883 |     39.840 |     3.9
   24 |   1.1221 |     41.080 |   1.0846 |     40.064 |     4.1
   25 |   1.1234 |     41.502 |   1.0805 |     40.769 |     4.2
   26 |   1.1174 |     40.806 |   1.0862 |     40.865 |     4.4
   27 |   1.1189 |     41.119 |   1.0713 |     40.417 |     4.6
   28 |   1.1149 |     41.048 |   1.0774 |     40.449 |     4.7
   29 |   1.1112 |     40.993 |   1.0682 |     39.936 |     4.9
   30 |   1.1112 |     40.971 |   1.0715 |     39.808 |     5.0
   31 |   1.1058 |     41.371 |   1.0808 |     40.160 |     5.2
   32 |   1.1067 |     40.839 |   1.0778 |     40.032 |     5.4
   33 |   1.1028 |     40.774 |   1.0695 |     39.904 |     5.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 648,098

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5838 |     48.247 |   1.3189 |     44.968 |     0.1
    2 |   1.3242 |     44.302 |   1.2378 |     43.077 |     0.2
    3 |   1.2742 |     43.529 |   1.2107 |     42.532 |     0.3
    4 |   1.2333 |     42.713 |   1.1721 |     40.673 |     0.4
    5 |   1.2011 |     41.875 |   1.1408 |     39.679 |     0.5
    6 |   1.1695 |     40.500 |   1.1375 |     40.481 |     0.6
    7 |   1.1493 |     39.798 |   1.1144 |     38.750 |     0.8
    8 |   1.1199 |     38.560 |   1.0873 |     38.333 |     0.9
    9 |   1.1046 |     38.407 |   1.0822 |     37.885 |     1.0
   10 |   1.0761 |     37.092 |   1.0671 |     37.019 |     1.1
   11 |   1.0591 |     36.785 |   1.0653 |     36.571 |     1.2
   12 |   1.0406 |     36.363 |   1.0558 |     35.994 |     1.3
   13 |   1.0244 |     35.240 |   1.0389 |     35.096 |     1.4
   14 |   0.9968 |     34.966 |   1.0354 |     35.288 |     1.5
   15 |   0.9740 |     33.405 |   1.0245 |     34.583 |     1.6
   16 |   0.9675 |     33.355 |   1.0398 |     34.968 |     1.7
   17 |   0.9530 |     33.213 |   0.9993 |     33.782 |     1.9
   18 |   0.9291 |     32.429 |   1.0312 |     34.776 |     2.0
   19 |   0.9090 |     31.843 |   1.0144 |     34.647 |     2.1
   20 |   0.8955 |     31.268 |   1.0471 |     34.103 |     2.2
   21 |   0.8836 |     30.972 |   1.0129 |     33.846 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 276,258

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8609 |     71.899 |   2.1504 |     54.167 |     0.1
    2 |   2.0813 |     50.712 |   1.6880 |     46.250 |     0.2
    3 |   1.7336 |     46.609 |   1.5503 |     46.250 |     0.3
    4 |   1.5990 |     46.313 |   1.4868 |     46.250 |     0.4
    5 |   1.5277 |     45.995 |   1.4456 |     45.801 |     0.5
    6 |   1.4843 |     45.907 |   1.4112 |     45.609 |     0.6
    7 |   1.4551 |     45.951 |   1.3889 |     45.513 |     0.7
    8 |   1.4239 |     45.885 |   1.3591 |     45.417 |     0.8
    9 |   1.3996 |     45.365 |   1.3381 |     45.705 |     0.9
   10 |   1.3803 |     45.354 |   1.3167 |     44.359 |     1.0
   11 |   1.3586 |     44.707 |   1.3037 |     45.224 |     1.1
   12 |   1.3452 |     44.417 |   1.2826 |     43.109 |     1.2
   13 |   1.3361 |     44.203 |   1.2644 |     42.692 |     1.3
   14 |   1.3169 |     44.203 |   1.2549 |     42.853 |     1.4
   15 |   1.3026 |     43.694 |   1.2434 |     42.917 |     1.5
   16 |   1.2942 |     43.831 |   1.2349 |     42.308 |     1.6
   17 |   1.2845 |     43.677 |   1.2261 |     42.147 |     1.7
   18 |   1.2769 |     43.069 |   1.2143 |     41.410 |     1.8
   19 |   1.2604 |     42.927 |   1.2054 |     41.378 |     1.9
   20 |   1.2566 |     42.883 |   1.1959 |     41.218 |     2.0
   21 |   1.2477 |     42.352 |   1.1953 |     40.833 |     2.1
   22 |   1.2401 |     42.231 |   1.1819 |     40.385 |     2.2
   23 |   1.2325 |     42.105 |   1.1813 |     40.288 |     2.4
   24 |   1.2238 |     42.006 |   1.1764 |     40.385 |     2.5
   25 |   1.2206 |     41.749 |   1.1681 |     40.385 |     2.6
   26 |   1.2093 |     41.179 |   1.1682 |     40.160 |     2.7
   27 |   1.2044 |     41.508 |   1.1562 |     40.481 |     2.8
   28 |   1.2002 |     40.960 |   1.1548 |     40.032 |     2.9
   29 |   1.1970 |     41.343 |   1.1497 |     39.872 |     3.0
   30 |   1.1890 |     40.817 |   1.1403 |     39.744 |     3.1
   31 |   1.1824 |     40.702 |   1.1428 |     39.776 |     3.2
   32 |   1.1714 |     40.439 |   1.1308 |     39.583 |     3.3
   33 |   1.1705 |     40.620 |   1.1285 |     39.583 |     3.4
   34 |   1.1781 |     40.105 |   1.1278 |     39.615 |     3.5
   35 |   1.1641 |     40.193 |   1.1222 |     39.263 |     3.6
   36 |   1.1555 |     39.776 |   1.1193 |     39.231 |     3.7
   37 |   1.1517 |     39.809 |   1.1260 |     39.519 |     3.8
   38 |   1.1451 |     39.294 |   1.1226 |     39.103 |     3.9
   39 |   1.1407 |     39.289 |   1.1208 |     39.327 |     4.0
   40 |   1.1426 |     39.415 |   1.1016 |     38.173 |     4.1
   41 |   1.1350 |     39.152 |   1.1113 |     38.782 |     4.2
   42 |   1.1265 |     38.768 |   1.0984 |     38.462 |     4.3
   43 |   1.1281 |     38.861 |   1.0938 |     38.301 |     4.4
   44 |   1.1245 |     38.609 |   1.0936 |     38.429 |     4.5
   45 |   1.1115 |     38.253 |   1.0948 |     37.981 |     4.6
   46 |   1.1132 |     38.308 |   1.0911 |     38.205 |     4.7
   47 |   1.1032 |     37.870 |   1.0943 |     38.365 |     4.8
   48 |   1.1038 |     37.700 |   1.0832 |     38.045 |     4.9
   49 |   1.0972 |     37.678 |   1.0805 |     37.468 |     5.0
   50 |   1.0957 |     37.437 |   1.0770 |     37.724 |     5.1
   51 |   1.0936 |     37.634 |   1.0826 |     37.853 |     5.2
   52 |   1.0949 |     37.437 |   1.0708 |     36.987 |     5.3
   53 |   1.0848 |     37.240 |   1.0696 |     37.308 |     5.4
   54 |   1.0771 |     36.927 |   1.0651 |     37.436 |     5.5
   55 |   1.0765 |     37.114 |   1.0665 |     37.853 |     5.6
   56 |   1.0705 |     36.895 |   1.0743 |     37.436 |     5.7
   57 |   1.0664 |     36.456 |   1.0695 |     37.436 |     5.8
   58 |   1.0685 |     36.697 |   1.0669 |     37.276 |     5.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 392,034

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6114 |     47.524 |   1.3301 |     43.462 |     0.1
    2 |   1.2807 |     44.521 |   1.2146 |     43.301 |     0.3
    3 |   1.2168 |     43.004 |   1.1735 |     42.115 |     0.5
    4 |   1.1716 |     42.143 |   1.1408 |     40.994 |     0.6
    5 |   1.1432 |     40.768 |   1.1159 |     40.321 |     0.8
    6 |   1.1153 |     39.864 |   1.0825 |     39.487 |     0.9
    7 |   1.0930 |     39.601 |   1.0890 |     39.551 |     1.1
    8 |   1.0832 |     39.459 |   1.0551 |     37.628 |     1.2
    9 |   1.0693 |     38.785 |   1.0729 |     38.077 |     1.3
   10 |   1.0545 |     37.914 |   1.0501 |     38.718 |     1.5
   11 |   1.0408 |     37.508 |   1.0336 |     37.532 |     1.6
   12 |   1.0279 |     37.667 |   1.0368 |     37.308 |     1.8
   13 |   1.0126 |     36.878 |   1.0406 |     37.821 |     1.9
   14 |   1.0143 |     36.977 |   1.0249 |     36.859 |     2.1
   15 |   0.9973 |     36.369 |   1.0092 |     36.282 |     2.2
   16 |   0.9846 |     36.210 |   0.9970 |     36.186 |     2.4
   17 |   0.9754 |     35.339 |   0.9832 |     35.705 |     2.5
   18 |   0.9699 |     35.591 |   0.9827 |     35.128 |     2.7
   19 |   0.9533 |     34.566 |   0.9796 |     35.224 |     2.8
   20 |   0.9490 |     34.363 |   0.9704 |     34.904 |     3.0
   21 |   0.9321 |     33.750 |   0.9783 |     35.192 |     3.1
   22 |   0.9135 |     32.742 |   0.9585 |     34.071 |     3.3
   23 |   0.8993 |     32.292 |   0.9490 |     34.263 |     3.4
   24 |   0.8909 |     31.421 |   0.9587 |     33.526 |     3.6
   25 |   0.8845 |     31.542 |   0.9407 |     32.917 |     3.7
   26 |   0.8696 |     31.016 |   0.9430 |     32.981 |     3.9
   27 |   0.8605 |     30.791 |   0.9234 |     32.628 |     4.0
   28 |   0.8408 |     29.547 |   0.9325 |     32.853 |     4.1
   29 |   0.8249 |     29.016 |   0.9152 |     31.571 |     4.3
   30 |   0.8158 |     28.775 |   0.9400 |     32.276 |     4.4
   31 |   0.8156 |     28.720 |   0.9089 |     31.122 |     4.6
   32 |   0.8029 |     28.189 |   0.9096 |     31.635 |     4.7
   33 |   0.7804 |     27.323 |   0.9095 |     31.058 |     4.9
   34 |   0.7703 |     27.071 |   0.9032 |     31.154 |     5.0
   35 |   0.7735 |     27.093 |   0.9122 |     31.186 |     5.2
   36 |   0.7598 |     26.479 |   0.9164 |     30.897 |     5.3
   37 |   0.7384 |     25.909 |   0.9224 |     31.154 |     5.5
   38 |   0.7356 |     25.959 |   0.9224 |     30.609 |     5.6
   39 |   0.7121 |     24.945 |   0.8987 |     29.872 |     5.8
   40 |   0.6983 |     24.222 |   0.9226 |     30.481 |     5.9
   41 |   0.6985 |     24.277 |   0.9452 |     30.737 |     6.1
   42 |   0.6855 |     23.767 |   0.9294 |     30.288 |     6.2
   43 |   0.6755 |     23.510 |   0.9140 |     30.224 |     6.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 898,018

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4479 |     61.938 |   1.7120 |     46.506 |     0.2
    2 |   1.6757 |     46.406 |   1.4573 |     46.282 |     0.4
    3 |   1.5004 |     46.099 |   1.3896 |     45.513 |     0.6
    4 |   1.4318 |     45.776 |   1.3434 |     45.385 |     0.8
    5 |   1.3837 |     45.014 |   1.2987 |     43.237 |     1.0
    6 |   1.3533 |     44.362 |   1.2739 |     42.917 |     1.2
    7 |   1.3268 |     43.940 |   1.2695 |     42.404 |     1.4
    8 |   1.3031 |     43.283 |   1.2381 |     41.154 |     1.5
    9 |   1.2846 |     42.943 |   1.2292 |     40.865 |     1.7
   10 |   1.2629 |     42.154 |   1.2359 |     41.378 |     1.9
   11 |   1.2503 |     41.902 |   1.2255 |     41.314 |     2.1
   12 |   1.2307 |     41.245 |   1.1937 |     40.417 |     2.3
   13 |   1.2136 |     40.724 |   1.1886 |     40.417 |     2.5
   14 |   1.1967 |     40.587 |   1.1751 |     39.615 |     2.7
   15 |   1.1793 |     39.672 |   1.1540 |     39.391 |     2.9
   16 |   1.1725 |     39.787 |   1.1464 |     38.526 |     3.1
   17 |   1.1569 |     39.261 |   1.1403 |     38.526 |     3.3
   18 |   1.1423 |     38.823 |   1.1439 |     38.462 |     3.5
   19 |   1.1273 |     38.505 |   1.1418 |     38.974 |     3.7
   20 |   1.1147 |     37.788 |   1.1195 |     37.500 |     3.8
   21 |   1.1105 |     38.111 |   1.0970 |     37.692 |     4.0
   22 |   1.0950 |     37.410 |   1.1118 |     37.147 |     4.2
   23 |   1.0798 |     36.774 |   1.1103 |     37.147 |     4.4
   24 |   1.0735 |     36.440 |   1.1014 |     37.788 |     4.6
   25 |   1.0628 |     36.188 |   1.1034 |     38.109 |     4.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 292,962

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6870 |     48.658 |   1.3503 |     45.449 |     0.1
    2 |   1.3097 |     44.598 |   1.2569 |     43.333 |     0.2
    3 |   1.2522 |     43.535 |   1.2193 |     42.436 |     0.3
    4 |   1.2133 |     42.226 |   1.1754 |     41.346 |     0.4
    5 |   1.1703 |     41.387 |   1.1545 |     40.128 |     0.5
    6 |   1.1481 |     40.335 |   1.1343 |     40.673 |     0.6
    7 |   1.1228 |     39.579 |   1.1025 |     39.006 |     0.7
    8 |   1.1020 |     39.163 |   1.0997 |     39.199 |     0.8
    9 |   1.0860 |     38.549 |   1.0857 |     38.397 |     0.9
   10 |   1.0707 |     38.116 |   1.0721 |     37.756 |     1.0
   11 |   1.0588 |     37.623 |   1.0854 |     39.840 |     1.1
   12 |   1.0487 |     37.536 |   1.0548 |     37.083 |     1.2
   13 |   1.0312 |     36.818 |   1.1047 |     40.321 |     1.3
   14 |   1.0226 |     36.577 |   1.0256 |     36.250 |     1.4
   15 |   1.0042 |     36.007 |   1.0312 |     36.699 |     1.5
   16 |   0.9963 |     35.536 |   1.0165 |     35.833 |     1.6
   17 |   0.9797 |     35.185 |   1.0592 |     37.596 |     1.7
   18 |   0.9694 |     34.599 |   1.0005 |     34.712 |     1.8
   19 |   0.9454 |     33.689 |   0.9850 |     34.647 |     1.9
   20 |   0.9294 |     32.933 |   1.0165 |     35.705 |     2.0
   21 |   0.9238 |     32.972 |   1.0103 |     35.224 |     2.1
   22 |   0.9092 |     32.435 |   1.0067 |     34.840 |     2.2
   23 |   0.8928 |     31.662 |   0.9527 |     33.077 |     2.3
   24 |   0.8842 |     31.449 |   0.9588 |     34.199 |     2.4
   25 |   0.8801 |     31.103 |   0.9766 |     33.494 |     2.5
   26 |   0.8618 |     30.440 |   0.9518 |     32.885 |     2.6
   27 |   0.8540 |     30.057 |   0.9443 |     32.179 |     2.7
   28 |   0.8290 |     29.389 |   0.9555 |     32.179 |     2.8
   29 |   0.8261 |     29.186 |   0.9345 |     32.276 |     2.9
   30 |   0.8144 |     28.780 |   0.9287 |     31.827 |     3.0
   31 |   0.7941 |     28.134 |   0.9298 |     31.763 |     3.1
   32 |   0.7871 |     27.449 |   0.8965 |     30.256 |     3.2
   33 |   0.7840 |     27.794 |   0.9050 |     30.032 |     3.3
   34 |   0.7769 |     27.301 |   0.9218 |     31.058 |     3.4
   35 |   0.7538 |     26.551 |   0.9192 |     30.481 |     3.5
   36 |   0.7471 |     26.408 |   0.8794 |     30.288 |     3.6
   37 |   0.7423 |     25.937 |   0.9208 |     30.224 |     3.7
   38 |   0.7382 |     25.482 |   0.9138 |     30.128 |     3.8
   39 |   0.7199 |     25.367 |   0.8782 |     29.295 |     3.9
   40 |   0.7039 |     24.556 |   0.9103 |     30.064 |     4.0
   41 |   0.7067 |     24.742 |   0.9010 |     29.231 |     4.1
   42 |   0.7093 |     24.764 |   0.8946 |     29.615 |     4.2
   43 |   0.6922 |     24.293 |   0.9067 |     30.160 |     4.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 779,682

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0938 |     53.550 |   1.5150 |     45.192 |     0.1
    2 |   1.4875 |     45.705 |   1.3785 |     44.872 |     0.2
    3 |   1.3810 |     44.510 |   1.3026 |     43.878 |     0.3
    4 |   1.3236 |     43.272 |   1.2621 |     41.699 |     0.4
    5 |   1.2827 |     42.675 |   1.2346 |     40.385 |     0.6
    6 |   1.2489 |     41.957 |   1.2042 |     40.769 |     0.7
    7 |   1.2231 |     40.889 |   1.1992 |     41.154 |     0.8
    8 |   1.2032 |     40.757 |   1.1765 |     40.288 |     0.9
    9 |   1.1747 |     39.760 |   1.1650 |     39.744 |     1.0
   10 |   1.1560 |     39.130 |   1.1600 |     39.423 |     1.1
   11 |   1.1390 |     38.768 |   1.1263 |     38.782 |     1.2
   12 |   1.1203 |     37.952 |   1.1482 |     39.167 |     1.3
   13 |   1.1067 |     37.464 |   1.1129 |     37.628 |     1.4
   14 |   1.0846 |     36.977 |   1.0925 |     37.596 |     1.5
   15 |   1.0716 |     36.423 |   1.0962 |     37.564 |     1.7
   16 |   1.0597 |     36.095 |   1.0917 |     36.859 |     1.8
   17 |   1.0441 |     35.492 |   1.0756 |     36.603 |     1.9
   18 |   1.0270 |     34.856 |   1.0654 |     36.218 |     2.0
   19 |   1.0023 |     34.194 |   1.0571 |     35.705 |     2.1
   20 |   0.9987 |     33.887 |   1.0465 |     35.545 |     2.2
   21 |   0.9885 |     33.629 |   1.0434 |     35.192 |     2.3
   22 |   0.9691 |     32.484 |   1.0502 |     34.968 |     2.4
   23 |   0.9587 |     32.429 |   1.0316 |     34.071 |     2.5
   24 |   0.9427 |     31.898 |   1.0319 |     33.942 |     2.7
   25 |   0.9354 |     31.569 |   1.0176 |     33.558 |     2.8
   26 |   0.9184 |     31.065 |   1.0145 |     34.071 |     2.9
   27 |   0.8988 |     30.462 |   1.0274 |     33.814 |     3.0
   28 |   0.8861 |     29.871 |   1.0227 |     32.500 |     3.1
   29 |   0.8763 |     29.350 |   1.0285 |     32.532 |     3.2
   30 |   0.8675 |     29.591 |   1.0139 |     33.045 |     3.3
   31 |   0.8546 |     28.687 |   1.0145 |     33.397 |     3.4
   32 |   0.8450 |     28.583 |   1.0068 |     31.987 |     3.5
   33 |   0.8329 |     27.926 |   1.0059 |     32.436 |     3.7
   34 |   0.8193 |     27.257 |   1.0098 |     31.859 |     3.8
   35 |   0.8010 |     27.038 |   1.0427 |     32.821 |     3.9
   36 |   0.7896 |     26.682 |   1.0197 |     32.244 |     4.0
   37 |   0.7828 |     26.244 |   1.0134 |     31.923 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 243,426

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6766 |     49.233 |   1.3516 |     46.058 |     0.1
    2 |   1.3018 |     44.510 |   1.2660 |     44.167 |     0.2
    3 |   1.2525 |     44.044 |   1.2256 |     44.263 |     0.3
    4 |   1.2186 |     43.387 |   1.1950 |     42.564 |     0.4
    5 |   1.2017 |     42.993 |   1.1805 |     43.462 |     0.5
    6 |   1.1789 |     42.532 |   1.1523 |     41.923 |     0.6
    7 |   1.1617 |     42.302 |   1.1499 |     41.538 |     0.7
    8 |   1.1503 |     41.941 |   1.1301 |     41.282 |     0.8
    9 |   1.1374 |     41.234 |   1.1359 |     41.090 |     0.9
   10 |   1.1285 |     41.300 |   1.1164 |     41.699 |     1.0
   11 |   1.1224 |     41.502 |   1.1216 |     41.026 |     1.1
   12 |   1.1161 |     40.856 |   1.1053 |     40.224 |     1.2
   13 |   1.1092 |     40.856 |   1.1183 |     41.699 |     1.3
   14 |   1.1045 |     41.174 |   1.1061 |     40.962 |     1.4
   15 |   1.1006 |     40.571 |   1.1028 |     40.641 |     1.5
   16 |   1.0971 |     40.631 |   1.0931 |     40.385 |     1.6
   17 |   1.0919 |     40.461 |   1.0903 |     40.385 |     1.7
   18 |   1.0907 |     40.845 |   1.0947 |     40.385 |     1.8
   19 |   1.0861 |     40.697 |   1.0839 |     40.288 |     1.9
   20 |   1.0842 |     40.801 |   1.0786 |     39.776 |     1.9
   21 |   1.0811 |     40.396 |   1.0806 |     40.160 |     2.0
   22 |   1.0796 |     40.335 |   1.0820 |     40.000 |     2.1
   23 |   1.0788 |     40.165 |   1.0795 |     39.968 |     2.2
   24 |   1.0780 |     40.439 |   1.0718 |     39.776 |     2.3
   25 |   1.0773 |     39.831 |   1.0671 |     40.353 |     2.4
   26 |   1.0766 |     40.248 |   1.0822 |     40.417 |     2.5
   27 |   1.0721 |     40.149 |   1.0720 |     39.327 |     2.6
   28 |   1.0679 |     39.919 |   1.0699 |     39.872 |     2.7
   29 |   1.0695 |     40.094 |   1.0794 |     40.641 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 285,410

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7370 |     49.063 |   1.3545 |     45.288 |     0.2
    2 |   1.3471 |     45.107 |   1.2891 |     43.814 |     0.3
    3 |   1.2893 |     44.258 |   1.2116 |     41.635 |     0.5
    4 |   1.2376 |     42.593 |   1.1729 |     41.058 |     0.7
    5 |   1.2089 |     42.023 |   1.1501 |     39.904 |     0.8
    6 |   1.1741 |     40.900 |   1.1131 |     39.391 |     1.0
    7 |   1.1537 |     39.859 |   1.0933 |     38.045 |     1.2
    8 |   1.1339 |     39.464 |   1.0941 |     38.365 |     1.3
    9 |   1.1183 |     39.267 |   1.0839 |     38.301 |     1.5
   10 |   1.1049 |     38.801 |   1.0553 |     35.962 |     1.7
   11 |   1.0804 |     38.133 |   1.0544 |     36.827 |     1.8
   12 |   1.0805 |     38.073 |   1.0313 |     36.442 |     2.0
   13 |   1.0644 |     37.448 |   1.0222 |     35.545 |     2.2
   14 |   1.0535 |     36.873 |   1.0257 |     35.513 |     2.3
   15 |   1.0458 |     36.895 |   1.0169 |     36.987 |     2.5
   16 |   1.0260 |     36.078 |   1.0168 |     35.417 |     2.7
   17 |   1.0173 |     35.804 |   1.0118 |     35.481 |     2.8
   18 |   1.0082 |     35.552 |   0.9952 |     34.615 |     3.0
   19 |   0.9881 |     34.670 |   0.9786 |     33.301 |     3.2
   20 |   0.9900 |     34.670 |   0.9722 |     34.103 |     3.3
   21 |   0.9742 |     33.963 |   0.9633 |     34.551 |     3.5
   22 |   0.9549 |     33.465 |   0.9542 |     33.237 |     3.7
   23 |   0.9536 |     33.509 |   0.9541 |     33.269 |     3.8
   24 |   0.9440 |     33.284 |   0.9381 |     32.468 |     4.0
   25 |   0.9229 |     32.681 |   0.9627 |     32.051 |     4.1
   26 |   0.9115 |     32.112 |   0.9503 |     32.051 |     4.3
   27 |   0.9078 |     31.936 |   0.9314 |     31.731 |     4.5
   28 |   0.9038 |     31.602 |   0.9291 |     31.699 |     4.6
   29 |   0.8825 |     31.049 |   0.9263 |     31.474 |     4.8
   30 |   0.8805 |     30.819 |   0.9211 |     30.865 |     5.0
   31 |   0.8717 |     30.835 |   0.9156 |     31.250 |     5.1
   32 |   0.8565 |     29.712 |   0.9315 |     31.699 |     5.3
   33 |   0.8458 |     29.317 |   0.9357 |     31.186 |     5.4
   34 |   0.8348 |     29.219 |   0.9188 |     31.058 |     5.6
   35 |   0.8198 |     28.545 |   0.9225 |     30.994 |     5.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 276,962

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8019 |     70.217 |   2.1683 |     51.378 |     0.1
    2 |   2.0335 |     48.937 |   1.6844 |     46.699 |     0.2
    3 |   1.6962 |     46.225 |   1.5385 |     46.250 |     0.2
    4 |   1.5654 |     45.902 |   1.4753 |     46.538 |     0.3
    5 |   1.5034 |     45.836 |   1.4299 |     45.994 |     0.4
    6 |   1.4625 |     45.546 |   1.4022 |     44.936 |     0.5
    7 |   1.4236 |     45.348 |   1.3688 |     45.481 |     0.6
    8 |   1.3987 |     45.173 |   1.3473 |     45.096 |     0.6
    9 |   1.3764 |     44.707 |   1.3190 |     43.878 |     0.7
   10 |   1.3522 |     44.236 |   1.3004 |     43.750 |     0.8
   11 |   1.3351 |     44.214 |   1.2856 |     43.173 |     0.9
   12 |   1.3178 |     43.535 |   1.2707 |     43.077 |     1.0
   13 |   1.3047 |     43.025 |   1.2622 |     42.949 |     1.1
   14 |   1.2879 |     42.828 |   1.2496 |     42.917 |     1.1
   15 |   1.2705 |     42.324 |   1.2276 |     42.340 |     1.2
   16 |   1.2561 |     42.406 |   1.2178 |     41.891 |     1.3
   17 |   1.2445 |     41.749 |   1.2096 |     41.667 |     1.4
   18 |   1.2311 |     41.738 |   1.1947 |     40.962 |     1.5
   19 |   1.2194 |     41.311 |   1.1834 |     41.122 |     1.5
   20 |   1.2161 |     41.278 |   1.1821 |     40.801 |     1.6
   21 |   1.1989 |     40.965 |   1.1784 |     40.865 |     1.7
   22 |   1.1957 |     40.527 |   1.1647 |     40.224 |     1.8
   23 |   1.1852 |     40.554 |   1.1483 |     39.872 |     1.9
   24 |   1.1800 |     40.450 |   1.1382 |     39.744 |     1.9
   25 |   1.1753 |     40.116 |   1.1621 |     40.449 |     2.0
   26 |   1.1695 |     39.924 |   1.1421 |     40.000 |     2.1
   27 |   1.1597 |     39.815 |   1.1235 |     39.167 |     2.2
   28 |   1.1491 |     39.459 |   1.1261 |     39.679 |     2.3
   29 |   1.1430 |     39.185 |   1.1351 |     39.872 |     2.4
   30 |   1.1326 |     38.977 |   1.1114 |     38.942 |     2.4
   31 |   1.1302 |     38.714 |   1.1329 |     39.038 |     2.5
   32 |   1.1328 |     38.741 |   1.1101 |     38.429 |     2.6
   33 |   1.1181 |     38.270 |   1.0992 |     37.949 |     2.7
   34 |   1.1128 |     37.936 |   1.0904 |     37.853 |     2.8
   35 |   1.1033 |     37.464 |   1.0985 |     38.141 |     2.8
   36 |   1.1001 |     37.607 |   1.0902 |     38.077 |     2.9
   37 |   1.0941 |     37.886 |   1.0902 |     37.788 |     3.0
   38 |   1.0878 |     37.366 |   1.0839 |     37.404 |     3.1
   39 |   1.0870 |     37.163 |   1.0703 |     36.955 |     3.2
   40 |   1.0797 |     36.922 |   1.0822 |     37.532 |     3.2
   41 |   1.0782 |     36.758 |   1.0818 |     37.917 |     3.3
   42 |   1.0695 |     36.648 |   1.0731 |     37.051 |     3.4
   43 |   1.0660 |     36.686 |   1.0601 |     36.955 |     3.5
   44 |   1.0561 |     36.664 |   1.0641 |     37.019 |     3.6
   45 |   1.0548 |     36.226 |   1.0681 |     36.635 |     3.6
   46 |   1.0451 |     35.530 |   1.0506 |     35.994 |     3.7
   47 |   1.0452 |     35.711 |   1.0439 |     35.929 |     3.8
   48 |   1.0428 |     35.996 |   1.0388 |     35.769 |     3.9
   49 |   1.0340 |     35.377 |   1.0586 |     36.603 |     4.0
   50 |   1.0327 |     35.185 |   1.0526 |     35.962 |     4.1
   51 |   1.0278 |     34.774 |   1.0287 |     34.904 |     4.1
   52 |   1.0218 |     34.796 |   1.0327 |     35.128 |     4.2
   53 |   1.0207 |     34.676 |   1.0370 |     35.160 |     4.3
   54 |   1.0139 |     34.528 |   1.0302 |     34.840 |     4.4
   55 |   1.0135 |     34.561 |   1.0295 |     35.160 |     4.5
   56 |   1.0086 |     34.440 |   1.0205 |     35.000 |     4.5
   57 |   1.0037 |     34.336 |   1.0161 |     34.519 |     4.6
   58 |   0.9971 |     33.892 |   1.0171 |     34.455 |     4.7
   59 |   0.9913 |     33.805 |   1.0164 |     34.583 |     4.8
   60 |   0.9861 |     33.624 |   1.0162 |     34.391 |     4.9
   61 |   0.9858 |     33.657 |   1.0024 |     34.295 |     4.9
   62 |   0.9841 |     33.673 |   1.0053 |     34.071 |     5.0
   63 |   0.9845 |     33.607 |   1.0120 |     34.712 |     5.1
   64 |   0.9769 |     33.147 |   1.0062 |     34.327 |     5.2
   65 |   0.9700 |     33.125 |   1.0027 |     33.654 |     5.3
   66 |   0.9677 |     32.731 |   0.9955 |     33.462 |     5.3
   67 |   0.9685 |     32.977 |   0.9913 |     33.141 |     5.4
   68 |   0.9558 |     32.665 |   0.9868 |     33.365 |     5.5
   69 |   0.9610 |     32.429 |   0.9819 |     32.692 |     5.6
   70 |   0.9523 |     32.490 |   0.9918 |     33.269 |     5.7
   71 |   0.9481 |     32.024 |   0.9809 |     32.853 |     5.8
   72 |   0.9456 |     31.892 |   0.9983 |     33.237 |     5.8
   73 |   0.9460 |     31.865 |   0.9871 |     32.500 |     5.9
   74 |   0.9386 |     32.128 |   0.9768 |     32.756 |     6.0
   75 |   0.9317 |     32.002 |   0.9753 |     32.660 |     6.1
   76 |   0.9268 |     31.421 |   0.9734 |     32.628 |     6.2
   77 |   0.9332 |     31.849 |   0.9679 |     32.404 |     6.2
   78 |   0.9285 |     31.465 |   0.9657 |     32.051 |     6.3
   79 |   0.9187 |     31.449 |   0.9791 |     32.724 |     6.4
   80 |   0.9151 |     30.988 |   0.9771 |     32.532 |     6.5
   81 |   0.9154 |     31.251 |   0.9629 |     32.340 |     6.6
   82 |   0.9133 |     31.125 |   0.9692 |     32.244 |     6.7
   83 |   0.9121 |     30.550 |   0.9672 |     32.019 |     6.7
   84 |   0.9041 |     30.577 |   0.9571 |     31.795 |     6.8
   85 |   0.9028 |     30.556 |   0.9524 |     31.538 |     6.9
   86 |   0.9028 |     30.594 |   0.9589 |     31.955 |     7.0
   87 |   0.8930 |     30.134 |   0.9562 |     31.891 |     7.1
   88 |   0.8910 |     30.375 |   0.9595 |     32.147 |     7.1
   89 |   0.8944 |     30.134 |   0.9507 |     31.859 |     7.2
   90 |   0.8864 |     30.035 |   0.9448 |     31.571 |     7.3
   91 |   0.8817 |     30.375 |   0.9445 |     31.635 |     7.4
   92 |   0.8800 |     30.304 |   0.9508 |     31.827 |     7.5
   93 |   0.8776 |     30.002 |   0.9443 |     31.442 |     7.5
   94 |   0.8733 |     29.668 |   0.9464 |     31.635 |     7.6
   95 |   0.8673 |     29.679 |   0.9404 |     31.699 |     7.7
   96 |   0.8664 |     29.372 |   0.9478 |     32.083 |     7.8
   97 |   0.8580 |     29.169 |   0.9578 |     32.115 |     7.9
   98 |   0.8588 |     29.235 |   0.9444 |     31.442 |     7.9
   99 |   0.8574 |     28.890 |   0.9672 |     32.083 |     8.0
  100 |   0.8575 |     29.268 |   0.9390 |     31.186 |     8.1
  101 |   0.8532 |     29.213 |   0.9365 |     31.122 |     8.2
  102 |   0.8421 |     28.501 |   0.9552 |     31.795 |     8.3
  103 |   0.8460 |     28.764 |   0.9479 |     31.731 |     8.4
  104 |   0.8461 |     28.676 |   0.9394 |     31.026 |     8.4
  105 |   0.8447 |     28.638 |   0.9378 |     31.090 |     8.5
  106 |   0.8328 |     28.654 |   0.9359 |     31.154 |     8.6
  107 |   0.8333 |     28.233 |   0.9281 |     30.385 |     8.7
  108 |   0.8318 |     28.156 |   0.9296 |     30.962 |     8.8
  109 |   0.8335 |     28.117 |   0.9371 |     31.571 |     8.8
  110 |   0.8228 |     28.063 |   0.9464 |     31.346 |     8.9
  111 |   0.8214 |     27.876 |   0.9316 |     31.154 |     9.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 978,466

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9801 |     53.112 |   1.4535 |     45.481 |     0.1
    2 |   1.3813 |     43.935 |   1.3203 |     42.532 |     0.2
    3 |   1.3008 |     42.094 |   1.2710 |     41.827 |     0.3
    4 |   1.2422 |     40.867 |   1.2142 |     41.250 |     0.4
    5 |   1.2015 |     40.144 |   1.1905 |     39.647 |     0.5
    6 |   1.1652 |     39.009 |   1.1496 |     38.462 |     0.6
    7 |   1.1339 |     37.974 |   1.1555 |     39.103 |     0.7
    8 |   1.1000 |     37.097 |   1.1128 |     37.756 |     0.7
    9 |   1.0755 |     36.719 |   1.1211 |     37.596 |     0.8
   10 |   1.0532 |     35.410 |   1.0771 |     36.538 |     0.9
   11 |   1.0271 |     34.489 |   1.0594 |     35.577 |     1.0
   12 |   1.0060 |     33.547 |   1.0432 |     35.417 |     1.1
   13 |   0.9722 |     32.594 |   1.0217 |     34.904 |     1.2
   14 |   0.9472 |     31.723 |   1.0132 |     34.744 |     1.3
   15 |   0.9232 |     31.098 |   1.0150 |     34.135 |     1.4
   16 |   0.8970 |     30.106 |   0.9847 |     33.013 |     1.5
   17 |   0.8728 |     29.098 |   0.9773 |     33.429 |     1.6
   18 |   0.8497 |     28.539 |   0.9613 |     31.699 |     1.7
   19 |   0.8288 |     27.635 |   0.9684 |     33.237 |     1.8
   20 |   0.8046 |     26.523 |   0.9647 |     31.058 |     1.9
   21 |   0.7827 |     25.816 |   0.9531 |     31.250 |     2.0
   22 |   0.7535 |     25.148 |   0.9647 |     31.763 |     2.1
   23 |   0.7274 |     24.063 |   0.9495 |     30.577 |     2.2
   24 |   0.6983 |     23.033 |   0.9465 |     30.929 |     2.3
   25 |   0.6819 |     22.507 |   0.9537 |     31.410 |     2.3
   26 |   0.6606 |     21.921 |   0.9351 |     29.936 |     2.4
   27 |   0.6277 |     20.392 |   0.9315 |     29.808 |     2.5
   28 |   0.6060 |     19.932 |   0.9563 |     30.160 |     2.6
   29 |   0.5834 |     19.001 |   0.9809 |     30.385 |     2.7
   30 |   0.5667 |     18.497 |   0.9692 |     30.128 |     2.8
   31 |   0.5401 |     17.242 |   0.9766 |     30.321 |     2.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,013,154

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5408 |     47.507 |   1.2671 |     44.103 |     0.2
    2 |   1.2780 |     44.269 |   1.2419 |     43.494 |     0.4
    3 |   1.2404 |     43.738 |   1.2514 |     46.314 |     0.6
    4 |   1.2193 |     43.765 |   1.1586 |     42.660 |     0.8
    5 |   1.1913 |     42.773 |   1.1490 |     42.372 |     1.0
    6 |   1.1839 |     42.428 |   1.1413 |     42.179 |     1.2
    7 |   1.1707 |     42.280 |   1.1214 |     40.994 |     1.4
    8 |   1.1589 |     42.006 |   1.1351 |     41.923 |     1.6
    9 |   1.1481 |     41.815 |   1.1128 |     41.090 |     1.8
   10 |   1.1406 |     41.776 |   1.1147 |     40.865 |     1.9
   11 |   1.1316 |     41.475 |   1.0977 |     40.705 |     2.1
   12 |   1.1300 |     41.798 |   1.0894 |     41.090 |     2.3
   13 |   1.1246 |     41.661 |   1.0915 |     40.288 |     2.5
   14 |   1.1205 |     41.316 |   1.0813 |     41.058 |     2.7
   15 |   1.1169 |     41.398 |   1.0771 |     41.378 |     2.9
   16 |   1.1109 |     40.867 |   1.0722 |     39.583 |     3.1
   17 |   1.1048 |     41.015 |   1.0779 |     39.904 |     3.3
   18 |   1.1074 |     40.993 |   1.0711 |     39.808 |     3.5
   19 |   1.1093 |     41.404 |   1.0772 |     40.673 |     3.7
   20 |   1.1126 |     41.486 |   1.0859 |     40.994 |     3.9
   21 |   1.1011 |     41.064 |   1.0808 |     40.545 |     4.1
   22 |   1.0981 |     40.434 |   1.0791 |     40.705 |     4.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 234,978

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6809 |     47.567 |   1.3318 |     44.487 |     0.1
    2 |   1.2758 |     42.965 |   1.2296 |     41.346 |     0.1
    3 |   1.1903 |     40.801 |   1.1677 |     40.994 |     0.2
    4 |   1.1308 |     38.938 |   1.0983 |     39.103 |     0.3
    5 |   1.0771 |     37.327 |   1.0739 |     36.891 |     0.3
    6 |   1.0223 |     35.382 |   1.0371 |     35.801 |     0.4
    7 |   0.9794 |     33.865 |   0.9894 |     34.808 |     0.5
    8 |   0.9432 |     32.133 |   1.0000 |     34.391 |     0.5
    9 |   0.9067 |     31.197 |   0.9920 |     34.103 |     0.6
   10 |   0.8546 |     29.016 |   0.9824 |     33.205 |     0.7
   11 |   0.8105 |     27.805 |   0.9589 |     32.083 |     0.7
   12 |   0.7794 |     26.704 |   0.9557 |     32.564 |     0.8
   13 |   0.7265 |     24.408 |   0.9993 |     32.981 |     0.9
   14 |   0.7083 |     23.915 |   1.0185 |     32.115 |     0.9
   15 |   0.6690 |     22.726 |   0.9788 |     31.731 |     1.0
   16 |   0.6217 |     21.231 |   1.0200 |     31.218 |     1.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 847,266

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0790 |     53.254 |   1.5376 |     46.314 |     0.1
    2 |   1.4426 |     45.173 |   1.3841 |     45.256 |     0.3
    3 |   1.3474 |     44.340 |   1.3176 |     43.494 |     0.4
    4 |   1.2965 |     43.256 |   1.2686 |     41.699 |     0.5
    5 |   1.2621 |     41.650 |   1.2440 |     42.051 |     0.7
    6 |   1.2297 |     41.152 |   1.2136 |     41.282 |     0.8
    7 |   1.1981 |     40.171 |   1.1922 |     39.840 |     0.9
    8 |   1.1674 |     39.656 |   1.1685 |     38.558 |     1.1
    9 |   1.1390 |     38.456 |   1.1451 |     38.237 |     1.2
   10 |   1.1088 |     37.158 |   1.1192 |     36.955 |     1.4
   11 |   1.0792 |     36.599 |   1.1163 |     37.147 |     1.5
   12 |   1.0578 |     35.476 |   1.1003 |     37.115 |     1.6
   13 |   1.0327 |     34.703 |   1.0645 |     36.154 |     1.8
   14 |   1.0024 |     33.936 |   1.0585 |     36.122 |     1.9
   15 |   0.9730 |     32.462 |   1.0336 |     34.231 |     2.0
   16 |   0.9516 |     31.580 |   1.0341 |     35.128 |     2.2
   17 |   0.9234 |     30.413 |   1.0090 |     33.109 |     2.3
   18 |   0.9012 |     30.013 |   0.9992 |     33.494 |     2.4
   19 |   0.8757 |     28.841 |   0.9903 |     33.590 |     2.6
   20 |   0.8407 |     27.959 |   1.0020 |     33.173 |     2.7
   21 |   0.8199 |     26.775 |   0.9783 |     32.308 |     2.9
   22 |   0.8046 |     26.463 |   0.9921 |     33.301 |     3.0
   23 |   0.7681 |     25.131 |   0.9949 |     32.724 |     3.1
   24 |   0.7373 |     24.074 |   0.9831 |     32.019 |     3.3
   25 |   0.7164 |     23.493 |   0.9695 |     31.667 |     3.4
   26 |   0.6863 |     22.409 |   1.0036 |     32.019 |     3.5
   27 |   0.6696 |     22.085 |   0.9882 |     32.308 |     3.7
   28 |   0.6359 |     20.705 |   0.9939 |     31.795 |     3.8
   29 |   0.6125 |     19.653 |   0.9884 |     31.699 |     4.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 192,994

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7896 |     69.444 |   2.1575 |     49.199 |     0.1
    2 |   1.8566 |     47.425 |   1.6708 |     46.314 |     0.2
    3 |   1.5807 |     46.011 |   1.5193 |     45.577 |     0.3
    4 |   1.4789 |     45.842 |   1.4448 |     44.551 |     0.3
    5 |   1.4158 |     44.406 |   1.3966 |     45.481 |     0.4
    6 |   1.3783 |     44.088 |   1.3607 |     43.397 |     0.5
    7 |   1.3408 |     43.442 |   1.3275 |     42.885 |     0.6
    8 |   1.3160 |     42.932 |   1.3021 |     42.212 |     0.7
    9 |   1.2893 |     42.423 |   1.2782 |     41.827 |     0.8
   10 |   1.2723 |     41.798 |   1.2616 |     41.827 |     0.9
   11 |   1.2525 |     41.332 |   1.2556 |     41.923 |     0.9
   12 |   1.2365 |     40.982 |   1.2338 |     41.154 |     1.0
   13 |   1.2206 |     40.609 |   1.2236 |     40.801 |     1.1
   14 |   1.2052 |     40.291 |   1.2090 |     41.186 |     1.2
   15 |   1.1921 |     40.018 |   1.2028 |     40.833 |     1.3
   16 |   1.1788 |     39.963 |   1.1839 |     39.904 |     1.4
   17 |   1.1625 |     39.179 |   1.1807 |     40.288 |     1.5
   18 |   1.1546 |     38.960 |   1.1773 |     40.737 |     1.5
   19 |   1.1436 |     38.440 |   1.1528 |     38.462 |     1.6
   20 |   1.1251 |     38.111 |   1.1403 |     37.917 |     1.7
   21 |   1.1138 |     37.656 |   1.1372 |     38.526 |     1.8
   22 |   1.1020 |     37.579 |   1.1254 |     38.269 |     1.9
   23 |   1.0941 |     36.999 |   1.1168 |     37.276 |     2.0
   24 |   1.0865 |     36.938 |   1.1174 |     37.564 |     2.0
   25 |   1.0736 |     36.089 |   1.1039 |     37.596 |     2.1
   26 |   1.0643 |     36.177 |   1.1103 |     36.699 |     2.2
   27 |   1.0569 |     35.771 |   1.0937 |     36.923 |     2.3
   28 |   1.0426 |     35.191 |   1.0754 |     36.090 |     2.4
   29 |   1.0383 |     34.972 |   1.0868 |     36.827 |     2.5
   30 |   1.0335 |     34.950 |   1.0787 |     36.154 |     2.6
   31 |   1.0243 |     34.528 |   1.0697 |     36.186 |     2.6
   32 |   1.0179 |     34.593 |   1.0865 |     36.635 |     2.7
   33 |   1.0055 |     33.755 |   1.0675 |     36.186 |     2.8
   34 |   0.9992 |     33.574 |   1.0611 |     35.801 |     2.9
   35 |   0.9876 |     33.399 |   1.0569 |     35.256 |     3.0
   36 |   0.9844 |     33.180 |   1.0504 |     35.288 |     3.1
   37 |   0.9775 |     33.224 |   1.0420 |     35.641 |     3.1
   38 |   0.9701 |     32.725 |   1.0389 |     35.353 |     3.2
   39 |   0.9665 |     32.522 |   1.0378 |     34.455 |     3.3
   40 |   0.9522 |     31.996 |   1.0342 |     34.872 |     3.4
   41 |   0.9503 |     31.739 |   1.0487 |     35.513 |     3.5
   42 |   0.9449 |     31.673 |   1.0281 |     34.936 |     3.6
   43 |   0.9368 |     31.558 |   1.0309 |     35.224 |     3.6
   44 |   0.9256 |     31.043 |   1.0426 |     35.737 |     3.7
   45 |   0.9322 |     31.087 |   1.0213 |     34.712 |     3.8
   46 |   0.9124 |     30.851 |   1.0382 |     34.904 |     3.9
   47 |   0.9091 |     30.479 |   1.0266 |     34.391 |     4.0
   48 |   0.9052 |     30.265 |   1.0288 |     34.615 |     4.1
   49 |   0.8989 |     30.041 |   1.0229 |     34.808 |     4.1
   50 |   0.8939 |     29.597 |   1.0049 |     34.263 |     4.2
   51 |   0.8876 |     29.695 |   1.0213 |     34.744 |     4.3
   52 |   0.8749 |     29.186 |   1.0422 |     35.192 |     4.4
   53 |   0.8742 |     29.158 |   1.0136 |     34.103 |     4.5
   54 |   0.8673 |     29.186 |   1.0266 |     34.295 |     4.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 343,202

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8331 |     68.743 |   2.1052 |     51.891 |     0.1
    2 |   2.0376 |     49.649 |   1.6395 |     46.603 |     0.2
    3 |   1.7095 |     46.948 |   1.5244 |     45.994 |     0.4
    4 |   1.5886 |     46.439 |   1.4697 |     45.737 |     0.5
    5 |   1.5198 |     46.072 |   1.4350 |     45.769 |     0.6
    6 |   1.4797 |     45.918 |   1.4067 |     45.673 |     0.7
    7 |   1.4471 |     45.809 |   1.3844 |     45.513 |     0.8
    8 |   1.4286 |     46.017 |   1.3576 |     45.032 |     0.9
    9 |   1.4053 |     45.617 |   1.3529 |     45.128 |     1.1
   10 |   1.3883 |     45.381 |   1.3345 |     44.455 |     1.2
   11 |   1.3763 |     45.157 |   1.3261 |     43.910 |     1.3
   12 |   1.3654 |     45.299 |   1.3179 |     44.968 |     1.4
   13 |   1.3555 |     44.954 |   1.3092 |     43.590 |     1.5
   14 |   1.3487 |     44.992 |   1.2984 |     43.173 |     1.7
   15 |   1.3331 |     44.318 |   1.2913 |     44.038 |     1.8
   16 |   1.3275 |     44.127 |   1.2833 |     43.269 |     1.9
   17 |   1.3191 |     43.979 |   1.2738 |     42.853 |     2.0
   18 |   1.3125 |     43.677 |   1.2716 |     43.013 |     2.1
   19 |   1.3064 |     43.431 |   1.2640 |     42.981 |     2.2
   20 |   1.2972 |     43.524 |   1.2647 |     43.333 |     2.4
   21 |   1.2828 |     42.949 |   1.2489 |     42.917 |     2.5
   22 |   1.2790 |     42.938 |   1.2468 |     42.115 |     2.6
   23 |   1.2704 |     42.856 |   1.2466 |     42.212 |     2.7
   24 |   1.2654 |     42.478 |   1.2325 |     42.051 |     2.8
   25 |   1.2613 |     42.264 |   1.2316 |     42.372 |     3.0
   26 |   1.2515 |     42.050 |   1.2217 |     41.442 |     3.1
   27 |   1.2456 |     42.121 |   1.2366 |     41.667 |     3.2
   28 |   1.2371 |     41.891 |   1.2135 |     41.378 |     3.3
   29 |   1.2336 |     41.847 |   1.2139 |     41.538 |     3.4
   30 |   1.2214 |     41.557 |   1.2167 |     41.090 |     3.5
   31 |   1.2236 |     41.700 |   1.2063 |     41.314 |     3.7
   32 |   1.2166 |     41.513 |   1.2137 |     41.218 |     3.8
   33 |   1.2096 |     41.404 |   1.2353 |     41.603 |     3.9
   34 |   1.2019 |     40.856 |   1.2348 |     41.474 |     4.0
   35 |   1.1996 |     40.631 |   1.2201 |     41.571 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 234,978

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6859 |     48.904 |   1.3535 |     44.936 |     0.1
    2 |   1.2800 |     43.124 |   1.2244 |     43.077 |     0.2
    3 |   1.1962 |     41.130 |   1.1644 |     39.455 |     0.3
    4 |   1.1398 |     39.283 |   1.1302 |     39.776 |     0.4
    5 |   1.1064 |     38.533 |   1.0694 |     38.494 |     0.5
    6 |   1.0550 |     36.955 |   1.0822 |     37.885 |     0.5
    7 |   1.0298 |     36.067 |   1.0285 |     35.865 |     0.6
    8 |   0.9993 |     34.895 |   1.0315 |     35.897 |     0.7
    9 |   0.9762 |     34.555 |   1.0265 |     35.449 |     0.8
   10 |   0.9418 |     32.731 |   1.0228 |     36.026 |     0.9
   11 |   0.9199 |     31.865 |   1.0228 |     35.288 |     1.0
   12 |   0.8878 |     30.994 |   0.9807 |     34.006 |     1.1
   13 |   0.8796 |     30.988 |   0.9722 |     33.109 |     1.2
   14 |   0.8550 |     29.947 |   0.9792 |     32.564 |     1.3
   15 |   0.8231 |     28.496 |   0.9801 |     32.628 |     1.4
   16 |   0.8145 |     28.567 |   0.9671 |     31.987 |     1.5
   17 |   0.7683 |     26.731 |   0.9521 |     31.314 |     1.5
   18 |   0.7470 |     25.674 |   0.9737 |     32.147 |     1.6
   19 |   0.7274 |     25.603 |   0.9774 |     31.731 |     1.7
   20 |   0.6989 |     24.359 |   0.9504 |     31.058 |     1.8
   21 |   0.6990 |     24.156 |   0.9365 |     30.160 |     1.9
   22 |   0.6740 |     22.874 |   0.9488 |     29.679 |     2.0
   23 |   0.6733 |     23.554 |   0.9410 |     29.872 |     2.1
   24 |   0.6448 |     22.326 |   0.9847 |     30.449 |     2.2
   25 |   0.6285 |     21.198 |   0.9975 |     31.314 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 813,986

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9477 |     50.794 |   1.4672 |     46.250 |     0.1
    2 |   1.4007 |     44.390 |   1.3316 |     42.821 |     0.2
    3 |   1.3102 |     43.058 |   1.2805 |     42.244 |     0.3
    4 |   1.2585 |     41.645 |   1.2310 |     41.218 |     0.4
    5 |   1.2075 |     40.089 |   1.1815 |     39.263 |     0.5
    6 |   1.1642 |     39.031 |   1.1518 |     38.750 |     0.6
    7 |   1.1347 |     38.281 |   1.1350 |     38.141 |     0.8
    8 |   1.1010 |     37.486 |   1.1008 |     37.115 |     0.9
    9 |   1.0780 |     36.297 |   1.0804 |     36.699 |     1.0
   10 |   1.0496 |     35.317 |   1.0545 |     35.705 |     1.1
   11 |   1.0206 |     34.270 |   1.0549 |     35.577 |     1.2
   12 |   0.9998 |     33.443 |   1.0717 |     36.410 |     1.3
   13 |   0.9843 |     33.098 |   1.0068 |     33.878 |     1.4
   14 |   0.9475 |     31.580 |   0.9941 |     34.583 |     1.5
   15 |   0.9306 |     31.049 |   0.9944 |     33.526 |     1.6
   16 |   0.9048 |     29.898 |   0.9832 |     32.628 |     1.7
   17 |   0.8820 |     29.252 |   0.9778 |     33.429 |     1.8
   18 |   0.8671 |     28.950 |   0.9670 |     32.724 |     2.0
   19 |   0.8389 |     27.789 |   0.9623 |     32.468 |     2.1
   20 |   0.8149 |     26.786 |   0.9463 |     31.923 |     2.2
   21 |   0.7979 |     26.468 |   0.9413 |     31.378 |     2.3
   22 |   0.7723 |     25.701 |   0.9448 |     31.699 |     2.4
   23 |   0.7489 |     24.748 |   0.9311 |     30.833 |     2.5
   24 |   0.7331 |     24.271 |   0.9191 |     30.256 |     2.6
   25 |   0.7082 |     23.373 |   0.9320 |     30.865 |     2.7
   26 |   0.6846 |     22.535 |   0.9397 |     30.449 |     2.8
   27 |   0.6700 |     22.272 |   0.9342 |     30.417 |     2.9
   28 |   0.6423 |     20.853 |   0.9580 |     31.154 |     3.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 525,538

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6325 |     48.395 |   1.3377 |     45.096 |     0.2
    2 |   1.2776 |     44.034 |   1.2447 |     42.179 |     0.3
    3 |   1.2103 |     42.669 |   1.2500 |     44.135 |     0.5
    4 |   1.1802 |     42.362 |   1.1697 |     42.340 |     0.7
    5 |   1.1542 |     41.398 |   1.1383 |     41.378 |     0.8
    6 |   1.1293 |     40.938 |   1.1275 |     40.032 |     1.0
    7 |   1.1238 |     41.124 |   1.1009 |     39.968 |     1.1
    8 |   1.1065 |     40.670 |   1.0892 |     39.455 |     1.3
    9 |   1.1076 |     40.620 |   1.0902 |     40.897 |     1.5
   10 |   1.0887 |     40.456 |   1.0920 |     40.000 |     1.6
   11 |   1.0917 |     40.571 |   1.0849 |     40.192 |     1.8
   12 |   1.0828 |     40.461 |   1.0777 |     40.000 |     2.0
   13 |   1.0883 |     40.730 |   1.0780 |     39.391 |     2.1
   14 |   1.0834 |     40.812 |   1.0831 |     41.154 |     2.3
   15 |   1.0792 |     40.894 |   1.0770 |     40.673 |     2.5
   16 |   1.0761 |     40.565 |   1.0734 |     39.840 |     2.6
   17 |   1.0747 |     40.428 |   1.0722 |     40.192 |     2.8
   18 |   1.0649 |     40.352 |   1.0693 |     39.744 |     3.0
   19 |   1.0697 |     40.374 |   1.0597 |     39.679 |     3.1
   20 |   1.0676 |     39.957 |   1.0676 |     40.449 |     3.3
   21 |   1.0654 |     40.242 |   1.0710 |     40.609 |     3.5
   22 |   1.0619 |     40.264 |   1.0593 |     39.808 |     3.6
   23 |   1.0592 |     40.187 |   1.0646 |     40.096 |     3.8
   24 |   1.0579 |     40.144 |   1.0608 |     39.744 |     3.9
   25 |   1.0585 |     40.379 |   1.0610 |     40.160 |     4.1
   26 |   1.0613 |     40.083 |   1.0584 |     39.487 |     4.3
   27 |   1.0598 |     40.056 |   1.0517 |     39.872 |     4.4
   28 |   1.0552 |     39.864 |   1.0667 |     39.872 |     4.6
   29 |   1.0599 |     40.302 |   1.0599 |     39.327 |     4.8
   30 |   1.0582 |     40.215 |   1.0603 |     40.321 |     4.9
   31 |   1.0498 |     39.579 |   1.0429 |     38.494 |     5.1
   32 |   1.0405 |     38.867 |   1.0420 |     37.917 |     5.3
   33 |   1.0272 |     38.292 |   1.0399 |     37.885 |     5.4
   34 |   1.0268 |     38.018 |   1.0287 |     37.756 |     5.6
   35 |   1.0233 |     37.968 |   1.0298 |     37.308 |     5.7
   36 |   1.0183 |     37.777 |   1.0174 |     38.141 |     5.9
   37 |   1.0074 |     37.568 |   1.0108 |     37.051 |     6.1
   38 |   1.0034 |     37.327 |   1.0372 |     37.436 |     6.2
   39 |   0.9987 |     37.475 |   1.0276 |     37.212 |     6.4
   40 |   0.9883 |     36.862 |   1.0234 |     37.436 |     6.6
   41 |   0.9872 |     36.944 |   1.0075 |     36.763 |     6.7
   42 |   0.9815 |     36.725 |   1.0070 |     36.250 |     6.9
   43 |   0.9732 |     36.144 |   1.0123 |     37.308 |     7.1
   44 |   0.9680 |     36.330 |   1.0048 |     36.827 |     7.2
   45 |   0.9678 |     35.804 |   1.0054 |     37.083 |     7.4
   46 |   0.9636 |     35.991 |   1.0299 |     37.083 |     7.5
   47 |   0.9662 |     36.012 |   0.9911 |     36.442 |     7.7
   48 |   0.9565 |     35.541 |   1.0049 |     36.795 |     7.9
   49 |   0.9526 |     35.278 |   0.9857 |     35.513 |     8.0
   50 |   0.9471 |     35.103 |   1.0069 |     36.538 |     8.2
   51 |   0.9371 |     34.774 |   1.0174 |     36.282 |     8.4
   52 |   0.9338 |     34.774 |   0.9899 |     35.833 |     8.5
   53 |   0.9217 |     34.593 |   0.9984 |     36.346 |     8.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 731,746

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5829 |     47.962 |   1.3154 |     45.513 |     0.1
    2 |   1.2748 |     43.184 |   1.1879 |     41.058 |     0.2
    3 |   1.2009 |     41.847 |   1.1951 |     41.282 |     0.3
    4 |   1.1472 |     39.798 |   1.1497 |     39.071 |     0.5
    5 |   1.1042 |     37.908 |   1.0775 |     37.179 |     0.6
    6 |   1.0626 |     36.522 |   1.0827 |     37.051 |     0.7
    7 |   1.0265 |     35.328 |   1.0443 |     36.378 |     0.8
    8 |   0.9890 |     33.947 |   1.0508 |     36.474 |     0.9
    9 |   0.9587 |     32.928 |   1.0341 |     35.064 |     1.0
   10 |   0.9222 |     32.144 |   1.0306 |     35.064 |     1.1
   11 |   0.8915 |     30.873 |   1.0231 |     33.878 |     1.3
   12 |   0.8506 |     29.739 |   1.0320 |     33.269 |     1.4
   13 |   0.8446 |     29.646 |   1.0245 |     33.109 |     1.5
   14 |   0.7939 |     27.520 |   1.0122 |     33.494 |     1.6
   15 |   0.7751 |     27.098 |   1.0641 |     34.071 |     1.7
   16 |   0.7376 |     25.586 |   1.0232 |     32.564 |     1.8
   17 |   0.7138 |     24.792 |   1.0738 |     32.981 |     2.0
   18 |   0.6799 |     24.156 |   1.0602 |     32.756 |     2.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 327,394

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7969 |     68.058 |   2.0528 |     48.590 |     0.1
    2 |   1.9367 |     47.020 |   1.6341 |     46.250 |     0.2
    3 |   1.6475 |     46.050 |   1.5099 |     46.122 |     0.4
    4 |   1.5379 |     45.726 |   1.4424 |     45.673 |     0.5
    5 |   1.4690 |     45.217 |   1.3905 |     44.487 |     0.6
    6 |   1.4300 |     44.779 |   1.3568 |     43.622 |     0.7
    7 |   1.4005 |     44.554 |   1.3346 |     43.558 |     0.9
    8 |   1.3694 |     43.951 |   1.3126 |     43.237 |     1.0
    9 |   1.3494 |     43.929 |   1.3055 |     44.167 |     1.1
   10 |   1.3342 |     43.869 |   1.2819 |     42.692 |     1.3
   11 |   1.3217 |     43.162 |   1.2626 |     41.603 |     1.4
   12 |   1.3019 |     42.993 |   1.2524 |     41.827 |     1.5
   13 |   1.2918 |     42.521 |   1.2383 |     40.641 |     1.6
   14 |   1.2827 |     42.215 |   1.2305 |     41.026 |     1.8
   15 |   1.2718 |     42.406 |   1.2233 |     41.218 |     1.9
   16 |   1.2583 |     41.820 |   1.2169 |     40.801 |     2.0
   17 |   1.2528 |     41.809 |   1.2059 |     41.026 |     2.1
   18 |   1.2400 |     41.716 |   1.1943 |     40.385 |     2.3
   19 |   1.2295 |     41.239 |   1.1856 |     40.737 |     2.4
   20 |   1.2202 |     41.174 |   1.1682 |     39.776 |     2.5
   21 |   1.2123 |     40.965 |   1.1881 |     40.994 |     2.6
   22 |   1.2043 |     40.730 |   1.1599 |     39.744 |     2.8
   23 |   1.1984 |     40.609 |   1.1651 |     40.417 |     2.9
   24 |   1.1933 |     40.445 |   1.1532 |     39.744 |     3.0
   25 |   1.1811 |     40.286 |   1.1486 |     39.295 |     3.1
   26 |   1.1771 |     39.990 |   1.1280 |     38.141 |     3.2
   27 |   1.1712 |     39.979 |   1.1289 |     38.622 |     3.4
   28 |   1.1632 |     39.727 |   1.1313 |     38.590 |     3.5
   29 |   1.1547 |     39.442 |   1.1243 |     38.462 |     3.6
   30 |   1.1542 |     39.497 |   1.1025 |     37.788 |     3.7
   31 |   1.1466 |     39.431 |   1.1027 |     37.212 |     3.9
   32 |   1.1357 |     39.097 |   1.1151 |     37.885 |     4.0
   33 |   1.1285 |     38.927 |   1.0974 |     37.340 |     4.1
   34 |   1.1261 |     38.697 |   1.1023 |     38.045 |     4.2
   35 |   1.1189 |     38.412 |   1.0986 |     37.564 |     4.4
   36 |   1.1158 |     38.303 |   1.0991 |     38.013 |     4.5
   37 |   1.1109 |     38.363 |   1.0912 |     37.051 |     4.6
   38 |   1.0954 |     37.996 |   1.0895 |     37.788 |     4.7
   39 |   1.0975 |     37.640 |   1.0735 |     36.538 |     4.8
   40 |   1.0874 |     37.212 |   1.0650 |     36.538 |     5.0
   41 |   1.0843 |     37.284 |   1.0638 |     36.571 |     5.1
   42 |   1.0794 |     37.086 |   1.0559 |     36.218 |     5.2
   43 |   1.0732 |     37.064 |   1.0646 |     36.571 |     5.3
   44 |   1.0705 |     36.681 |   1.0618 |     36.154 |     5.4
   45 |   1.0596 |     36.506 |   1.0565 |     36.122 |     5.6
   46 |   1.0541 |     36.084 |   1.0441 |     35.641 |     5.7
   47 |   1.0570 |     36.084 |   1.0411 |     35.897 |     5.8
   48 |   1.0439 |     35.832 |   1.0262 |     34.904 |     6.0
   49 |   1.0418 |     35.525 |   1.0463 |     35.288 |     6.1
   50 |   1.0318 |     35.295 |   1.0456 |     35.673 |     6.2
   51 |   1.0361 |     35.569 |   1.0588 |     36.314 |     6.3
   52 |   1.0311 |     35.070 |   1.0473 |     35.801 |     6.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 358,818

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6955 |     48.806 |   1.3762 |     45.673 |     0.1
    2 |   1.3268 |     44.916 |   1.2458 |     43.526 |     0.2
    3 |   1.2614 |     43.880 |   1.1949 |     41.859 |     0.2
    4 |   1.2273 |     42.790 |   1.1730 |     41.314 |     0.3
    5 |   1.1882 |     41.409 |   1.1408 |     40.192 |     0.4
    6 |   1.1696 |     40.598 |   1.1217 |     38.942 |     0.5
    7 |   1.1405 |     39.656 |   1.0856 |     37.212 |     0.6
    8 |   1.1114 |     38.779 |   1.0642 |     37.724 |     0.6
    9 |   1.0926 |     38.133 |   1.0519 |     36.506 |     0.7
   10 |   1.0712 |     37.601 |   1.0242 |     36.090 |     0.8
   11 |   1.0529 |     36.538 |   1.0230 |     35.609 |     0.9
   12 |   1.0306 |     35.985 |   1.0108 |     34.808 |     0.9
   13 |   1.0107 |     35.240 |   0.9990 |     35.449 |     1.0
   14 |   0.9905 |     34.659 |   0.9831 |     34.423 |     1.1
   15 |   0.9865 |     34.352 |   0.9669 |     33.622 |     1.2
   16 |   0.9548 |     33.536 |   0.9637 |     33.269 |     1.3
   17 |   0.9444 |     32.539 |   0.9591 |     33.013 |     1.3
   18 |   0.9290 |     32.424 |   0.9506 |     32.340 |     1.4
   19 |   0.9163 |     31.646 |   0.9430 |     32.212 |     1.5
   20 |   0.8910 |     30.764 |   0.9267 |     31.699 |     1.6
   21 |   0.8784 |     30.462 |   0.9054 |     30.994 |     1.7
   22 |   0.8571 |     29.668 |   0.9288 |     31.410 |     1.8
   23 |   0.8656 |     30.336 |   0.9128 |     31.795 |     1.8
   24 |   0.8421 |     29.279 |   0.9034 |     30.769 |     1.9
   25 |   0.8237 |     28.183 |   0.9260 |     31.250 |     2.0
   26 |   0.8215 |     28.386 |   0.8953 |     30.769 |     2.1
   27 |   0.7882 |     27.318 |   0.9094 |     30.865 |     2.2
   28 |   0.7713 |     27.027 |   0.9133 |     30.256 |     2.3
   29 |   0.7768 |     26.682 |   0.9052 |     29.808 |     2.3
   30 |   0.7556 |     26.490 |   0.9205 |     30.417 |     2.4
   31 |   0.7495 |     26.107 |   0.8886 |     30.096 |     2.5
   32 |   0.7346 |     25.433 |   0.9048 |     30.385 |     2.6
   33 |   0.7205 |     25.060 |   0.9140 |     29.295 |     2.6
   34 |   0.7045 |     24.370 |   0.9377 |     30.321 |     2.7
   35 |   0.7016 |     24.364 |   0.8955 |     29.263 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 234,978

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8603 |     70.014 |   2.1545 |     51.923 |     0.1
    2 |   2.1309 |     50.805 |   1.7276 |     46.603 |     0.2
    3 |   1.7898 |     47.282 |   1.5793 |     46.603 |     0.3
    4 |   1.6370 |     46.537 |   1.5015 |     46.250 |     0.4
    5 |   1.5539 |     46.159 |   1.4561 |     45.673 |     0.5
    6 |   1.5066 |     45.984 |   1.4209 |     45.673 |     0.6
    7 |   1.4701 |     45.913 |   1.3955 |     45.705 |     0.7
    8 |   1.4351 |     45.792 |   1.3688 |     45.577 |     0.8
    9 |   1.4183 |     45.628 |   1.3508 |     45.032 |     0.9
   10 |   1.3987 |     44.954 |   1.3311 |     44.006 |     1.0
   11 |   1.3803 |     44.987 |   1.3182 |     43.814 |     1.1
   12 |   1.3581 |     44.264 |   1.3034 |     43.237 |     1.2
   13 |   1.3456 |     44.280 |   1.2926 |     43.526 |     1.3
   14 |   1.3344 |     43.940 |   1.2818 |     42.564 |     1.4
   15 |   1.3205 |     43.513 |   1.2651 |     42.244 |     1.5
   16 |   1.3097 |     43.256 |   1.2604 |     42.372 |     1.6
   17 |   1.3074 |     42.932 |   1.2535 |     42.532 |     1.7
   18 |   1.2866 |     42.773 |   1.2451 |     41.827 |     1.8
   19 |   1.2790 |     42.746 |   1.2367 |     42.051 |     1.9
   20 |   1.2741 |     42.335 |   1.2375 |     42.372 |     2.0
   21 |   1.2606 |     42.330 |   1.2230 |     41.635 |     2.1
   22 |   1.2622 |     42.434 |   1.2248 |     41.699 |     2.2
   23 |   1.2527 |     42.039 |   1.2105 |     41.186 |     2.3
   24 |   1.2489 |     42.110 |   1.2059 |     40.769 |     2.4
   25 |   1.2369 |     41.721 |   1.2082 |     41.282 |     2.5
   26 |   1.2325 |     41.721 |   1.2008 |     40.545 |     2.6
   27 |   1.2275 |     41.831 |   1.1878 |     40.385 |     2.7
   28 |   1.2252 |     41.267 |   1.1823 |     40.160 |     2.9
   29 |   1.2191 |     41.404 |   1.1783 |     39.744 |     3.0
   30 |   1.2082 |     40.889 |   1.1953 |     40.417 |     3.1
   31 |   1.2051 |     41.206 |   1.1763 |     40.545 |     3.2
   32 |   1.1988 |     40.489 |   1.1721 |     40.128 |     3.3
   33 |   1.1962 |     40.494 |   1.1694 |     40.064 |     3.4
   34 |   1.1826 |     40.511 |   1.1568 |     39.551 |     3.5
   35 |   1.1851 |     40.012 |   1.1534 |     40.160 |     3.6
   36 |   1.1836 |     40.111 |   1.1470 |     39.327 |     3.7
   37 |   1.1740 |     40.067 |   1.1472 |     39.679 |     3.8
   38 |   1.1655 |     40.144 |   1.1401 |     39.295 |     3.9
   39 |   1.1619 |     40.165 |   1.1455 |     39.263 |     4.0
   40 |   1.1614 |     39.629 |   1.1345 |     39.038 |     4.1
   41 |   1.1509 |     39.464 |   1.1340 |     39.199 |     4.2
   42 |   1.1529 |     39.371 |   1.1326 |     38.782 |     4.3
   43 |   1.1453 |     39.316 |   1.1255 |     38.718 |     4.4
   44 |   1.1435 |     39.196 |   1.1138 |     38.622 |     4.5
   45 |   1.1431 |     39.311 |   1.1201 |     38.654 |     4.6
   46 |   1.1336 |     39.240 |   1.1152 |     38.494 |     4.7
   47 |   1.1307 |     38.642 |   1.1136 |     38.718 |     4.7
   48 |   1.1334 |     38.785 |   1.1096 |     38.013 |     4.8
   49 |   1.1217 |     38.483 |   1.1066 |     38.045 |     4.9
   50 |   1.1188 |     38.560 |   1.1184 |     38.526 |     5.0
   51 |   1.1229 |     38.407 |   1.1094 |     38.045 |     5.1
   52 |   1.1106 |     38.253 |   1.1026 |     38.269 |     5.2
   53 |   1.1124 |     38.527 |   1.0974 |     37.660 |     5.3
   54 |   1.1088 |     38.160 |   1.1035 |     37.500 |     5.4
   55 |   1.1075 |     37.914 |   1.0959 |     37.853 |     5.5
   56 |   1.1011 |     37.667 |   1.0860 |     37.404 |     5.6
   57 |   1.0937 |     37.568 |   1.0902 |     37.596 |     5.7
   58 |   1.0966 |     37.700 |   1.0886 |     37.724 |     5.8
   59 |   1.0917 |     37.360 |   1.0842 |     37.660 |     5.9
   60 |   1.0869 |     37.432 |   1.0867 |     37.821 |     6.0
   61 |   1.0838 |     37.464 |   1.0813 |     36.987 |     6.1
   62 |   1.0848 |     37.355 |   1.0778 |     37.115 |     6.2
   63 |   1.0757 |     36.686 |   1.0783 |     36.987 |     6.3
   64 |   1.0785 |     36.977 |   1.0778 |     37.308 |     6.4
   65 |   1.0712 |     36.697 |   1.0836 |     37.179 |     6.5
   66 |   1.0700 |     36.867 |   1.0775 |     37.019 |     6.6
   67 |   1.0630 |     36.692 |   1.0785 |     37.212 |     6.7
   68 |   1.0593 |     36.292 |   1.0765 |     37.083 |     6.8
   69 |   1.0612 |     36.303 |   1.0726 |     36.603 |     6.9
   70 |   1.0530 |     36.330 |   1.0759 |     36.955 |     7.0
   71 |   1.0501 |     36.237 |   1.0693 |     36.603 |     7.1
   72 |   1.0541 |     35.876 |   1.0678 |     36.699 |     7.2
   73 |   1.0430 |     35.777 |   1.0719 |     36.667 |     7.3
   74 |   1.0450 |     35.782 |   1.0725 |     36.506 |     7.4
   75 |   1.0388 |     35.782 |   1.0647 |     36.346 |     7.5
   76 |   1.0420 |     36.007 |   1.0697 |     36.442 |     7.6
   77 |   1.0356 |     35.700 |   1.0661 |     36.090 |     7.7
   78 |   1.0309 |     35.284 |   1.0788 |     36.731 |     7.8
   79 |   1.0347 |     35.541 |   1.0541 |     35.929 |     7.9
   80 |   1.0261 |     34.939 |   1.0620 |     36.282 |     8.0
   81 |   1.0216 |     35.130 |   1.0699 |     36.474 |     8.1
   82 |   1.0160 |     34.999 |   1.0583 |     36.122 |     8.2
   83 |   1.0201 |     34.818 |   1.0828 |     37.212 |     8.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 358,818

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4525 |     59.889 |   1.8109 |     46.186 |     0.1
    2 |   1.6418 |     45.535 |   1.5522 |     44.904 |     0.2
    3 |   1.4935 |     44.784 |   1.4497 |     44.679 |     0.3
    4 |   1.4218 |     44.302 |   1.3816 |     43.141 |     0.4
    5 |   1.3660 |     43.924 |   1.3341 |     43.814 |     0.5
    6 |   1.3250 |     43.064 |   1.2944 |     43.494 |     0.6
    7 |   1.2949 |     42.587 |   1.2657 |     41.763 |     0.7
    8 |   1.2681 |     41.793 |   1.2439 |     41.635 |     0.8
    9 |   1.2476 |     41.289 |   1.2211 |     40.737 |     0.8
   10 |   1.2205 |     40.916 |   1.2042 |     40.897 |     0.9
   11 |   1.1970 |     40.511 |   1.1799 |     39.359 |     1.0
   12 |   1.1812 |     39.853 |   1.1662 |     39.455 |     1.1
   13 |   1.1643 |     39.393 |   1.1609 |     39.808 |     1.2
   14 |   1.1488 |     39.311 |   1.1436 |     39.038 |     1.3
   15 |   1.1347 |     38.451 |   1.1271 |     38.526 |     1.4
   16 |   1.1200 |     38.001 |   1.1293 |     39.551 |     1.5
   17 |   1.1104 |     38.171 |   1.1062 |     37.981 |     1.6
   18 |   1.0954 |     37.503 |   1.0990 |     39.327 |     1.7
   19 |   1.0840 |     37.043 |   1.0912 |     37.660 |     1.8
   20 |   1.0659 |     36.599 |   1.0775 |     37.436 |     1.9
   21 |   1.0597 |     36.182 |   1.0697 |     37.885 |     2.0
   22 |   1.0494 |     35.947 |   1.0655 |     37.276 |     2.1
   23 |   1.0312 |     35.098 |   1.0504 |     36.827 |     2.2
   24 |   1.0182 |     34.385 |   1.0425 |     36.154 |     2.3
   25 |   1.0098 |     34.232 |   1.0354 |     36.314 |     2.4
   26 |   0.9984 |     33.815 |   1.0335 |     35.673 |     2.5
   27 |   0.9858 |     33.300 |   1.0267 |     35.833 |     2.6
   28 |   0.9747 |     32.692 |   1.0286 |     35.224 |     2.7
   29 |   0.9597 |     32.227 |   1.0359 |     35.288 |     2.8
   30 |   0.9532 |     32.029 |   1.0056 |     34.295 |     2.9
   31 |   0.9487 |     31.712 |   0.9930 |     34.327 |     3.0
   32 |   0.9342 |     31.339 |   1.0054 |     34.551 |     3.1
   33 |   0.9280 |     31.076 |   0.9995 |     33.782 |     3.2
   34 |   0.9088 |     30.660 |   0.9958 |     33.750 |     3.3
   35 |   0.9023 |     30.161 |   0.9893 |     33.622 |     3.4
   36 |   0.8913 |     29.838 |   0.9909 |     33.558 |     3.5
   37 |   0.8806 |     29.805 |   0.9806 |     33.526 |     3.6
   38 |   0.8742 |     29.449 |   0.9624 |     32.692 |     3.7
   39 |   0.8595 |     28.989 |   0.9623 |     32.660 |     3.7
   40 |   0.8539 |     28.616 |   0.9774 |     33.846 |     3.8
   41 |   0.8452 |     28.753 |   0.9603 |     32.404 |     3.9
   42 |   0.8300 |     28.090 |   0.9625 |     32.885 |     4.0
   43 |   0.8234 |     27.827 |   0.9590 |     31.955 |     4.1
   44 |   0.8152 |     27.515 |   0.9561 |     32.500 |     4.2
   45 |   0.8152 |     27.515 |   0.9508 |     32.051 |     4.3
   46 |   0.8006 |     27.027 |   0.9553 |     32.821 |     4.4
   47 |   0.7915 |     26.561 |   0.9662 |     32.917 |     4.5
   48 |   0.7807 |     26.419 |   0.9574 |     32.468 |     4.6
   49 |   0.7773 |     26.178 |   0.9568 |     32.115 |     4.7
   50 |   0.7713 |     25.953 |   0.9488 |     31.795 |     4.8
   51 |   0.7640 |     25.915 |   0.9477 |     31.891 |     4.9
   52 |   0.7498 |     25.312 |   0.9442 |     31.827 |     5.0
   53 |   0.7441 |     25.060 |   0.9538 |     31.795 |     5.1
   54 |   0.7299 |     24.567 |   0.9695 |     32.788 |     5.2
   55 |   0.7257 |     24.523 |   0.9302 |     30.769 |     5.3
   56 |   0.7147 |     23.992 |   0.9465 |     31.667 |     5.4
   57 |   0.7093 |     23.828 |   0.9501 |     31.474 |     5.5
   58 |   0.6980 |     23.784 |   0.9289 |     31.122 |     5.6
   59 |   0.6960 |     23.132 |   0.9466 |     31.122 |     5.7
   60 |   0.6821 |     22.770 |   0.9703 |     32.115 |     5.8
   61 |   0.6694 |     22.600 |   0.9539 |     30.353 |     5.9
   62 |   0.6657 |     22.293 |   0.9416 |     30.737 |     6.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 327,394

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7988 |     50.888 |   1.3905 |     46.218 |     0.1
    2 |   1.3618 |     45.480 |   1.3103 |     45.128 |     0.3
    3 |   1.3008 |     44.061 |   1.2500 |     42.788 |     0.4
    4 |   1.2535 |     43.272 |   1.2330 |     43.429 |     0.5
    5 |   1.2282 |     42.768 |   1.1750 |     40.801 |     0.6
    6 |   1.1987 |     41.721 |   1.1611 |     40.353 |     0.8
    7 |   1.1866 |     41.168 |   1.1535 |     39.808 |     0.9
    8 |   1.1640 |     40.500 |   1.1347 |     40.513 |     1.0
    9 |   1.1423 |     39.930 |   1.1248 |     39.519 |     1.1
   10 |   1.1268 |     39.020 |   1.0912 |     38.622 |     1.3
   11 |   1.1132 |     38.757 |   1.0890 |     38.590 |     1.4
   12 |   1.0943 |     38.023 |   1.0738 |     37.756 |     1.5
   13 |   1.0880 |     38.012 |   1.0674 |     36.859 |     1.6
   14 |   1.0621 |     37.453 |   1.0548 |     37.404 |     1.7
   15 |   1.0473 |     36.818 |   1.0463 |     36.827 |     1.9
   16 |   1.0416 |     36.780 |   1.0457 |     37.051 |     2.0
   17 |   1.0346 |     35.919 |   1.0401 |     37.179 |     2.1
   18 |   1.0116 |     35.454 |   1.0312 |     36.795 |     2.2
   19 |   1.0050 |     35.618 |   1.0401 |     36.474 |     2.3
   20 |   0.9833 |     34.621 |   1.0187 |     35.641 |     2.5
   21 |   0.9750 |     34.210 |   1.0028 |     35.064 |     2.6
   22 |   0.9646 |     33.887 |   1.0276 |     36.154 |     2.7
   23 |   0.9510 |     33.213 |   1.0215 |     36.250 |     2.8
   24 |   0.9395 |     32.846 |   1.0107 |     35.641 |     2.9
   25 |   0.9193 |     32.407 |   0.9960 |     35.481 |     3.1
   26 |   0.9092 |     31.695 |   0.9974 |     35.288 |     3.2
   27 |   0.9099 |     31.679 |   1.0120 |     35.449 |     3.3
   28 |   0.8906 |     31.410 |   1.0087 |     35.032 |     3.4
   29 |   0.8746 |     30.616 |   1.0040 |     35.385 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 978,466

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5020 |     47.414 |   1.3172 |     47.917 |     0.1
    2 |   1.2487 |     43.792 |   1.2298 |     43.045 |     0.2
    3 |   1.1840 |     41.694 |   1.1437 |     39.359 |     0.3
    4 |   1.1311 |     39.930 |   1.1262 |     38.558 |     0.4
    5 |   1.0967 |     38.314 |   1.0805 |     37.917 |     0.5
    6 |   1.0534 |     36.582 |   1.0409 |     36.378 |     0.5
    7 |   1.0201 |     35.426 |   1.0205 |     34.840 |     0.6
    8 |   0.9779 |     33.909 |   1.0439 |     37.179 |     0.7
    9 |   0.9379 |     32.599 |   0.9782 |     33.654 |     0.8
   10 |   0.9050 |     30.917 |   0.9607 |     33.365 |     0.9
   11 |   0.8778 |     30.254 |   1.0169 |     33.910 |     1.0
   12 |   0.8379 |     29.043 |   0.9357 |     30.994 |     1.1
   13 |   0.7988 |     27.202 |   0.9164 |     31.186 |     1.2
   14 |   0.7827 |     26.666 |   0.9066 |     31.250 |     1.3
   15 |   0.7467 |     25.751 |   0.9506 |     32.564 |     1.4
   16 |   0.7138 |     24.611 |   0.9500 |     31.538 |     1.5
   17 |   0.6792 |     23.521 |   0.9417 |     30.321 |     1.6
   18 |   0.6501 |     22.425 |   0.9685 |     30.609 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 898,018

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5238 |     47.978 |   1.2978 |     45.641 |     0.2
    2 |   1.2533 |     44.023 |   1.2191 |     42.981 |     0.4
    3 |   1.2110 |     43.064 |   1.1800 |     42.147 |     0.5
    4 |   1.1771 |     42.598 |   1.1517 |     41.667 |     0.7
    5 |   1.1536 |     41.743 |   1.1449 |     41.314 |     0.9
    6 |   1.1362 |     41.864 |   1.1307 |     40.224 |     1.1
    7 |   1.1268 |     41.513 |   1.1099 |     40.737 |     1.2
    8 |   1.1144 |     41.300 |   1.1137 |     41.410 |     1.4
    9 |   1.1097 |     41.234 |   1.0865 |     40.641 |     1.6
   10 |   1.1045 |     40.878 |   1.0931 |     40.513 |     1.8
   11 |   1.0954 |     40.680 |   1.0875 |     40.449 |     1.9
   12 |   1.0992 |     41.217 |   1.0796 |     40.673 |     2.1
   13 |   1.0952 |     41.300 |   1.0758 |     39.679 |     2.3
   14 |   1.0907 |     40.878 |   1.0782 |     41.154 |     2.5
   15 |   1.0824 |     40.598 |   1.0846 |     41.250 |     2.6
   16 |   1.0848 |     40.856 |   1.0786 |     40.096 |     2.8
   17 |   1.0807 |     40.631 |   1.0744 |     40.801 |     3.0
   18 |   1.0790 |     40.133 |   1.0742 |     40.064 |     3.2
   19 |   1.0753 |     40.352 |   1.0671 |     39.583 |     3.3
   20 |   1.0718 |     40.554 |   1.0681 |     40.256 |     3.5
   21 |   1.0712 |     40.368 |   1.0669 |     40.385 |     3.7
   22 |   1.0689 |     40.363 |   1.0565 |     39.776 |     3.9
   23 |   1.0647 |     40.264 |   1.0693 |     40.321 |     4.0
   24 |   1.0670 |     40.144 |   1.0644 |     39.391 |     4.2
   25 |   1.0633 |     39.738 |   1.1054 |     41.667 |     4.4
   26 |   1.0738 |     40.565 |   1.0593 |     39.840 |     4.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 327,394

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6916 |     49.096 |   1.3468 |     44.679 |     0.1
    2 |   1.3009 |     44.428 |   1.2769 |     45.064 |     0.2
    3 |   1.2323 |     42.976 |   1.2350 |     41.538 |     0.3
    4 |   1.1919 |     42.006 |   1.1520 |     41.635 |     0.4
    5 |   1.1534 |     40.604 |   1.1211 |     39.776 |     0.6
    6 |   1.1277 |     39.722 |   1.0982 |     39.455 |     0.7
    7 |   1.0984 |     38.966 |   1.0663 |     38.205 |     0.8
    8 |   1.0757 |     38.029 |   1.0686 |     37.949 |     0.9
    9 |   1.0547 |     37.864 |   1.0627 |     37.885 |     1.0
   10 |   1.0493 |     37.837 |   1.0302 |     36.538 |     1.1
   11 |   1.0346 |     37.037 |   1.0178 |     35.417 |     1.2
   12 |   1.0152 |     35.908 |   1.0070 |     37.051 |     1.3
   13 |   0.9997 |     35.881 |   1.0133 |     36.090 |     1.4
   14 |   0.9907 |     35.673 |   1.0262 |     37.244 |     1.6
   15 |   0.9694 |     34.796 |   1.0128 |     36.923 |     1.7
   16 |   0.9633 |     34.451 |   0.9716 |     35.224 |     1.8
   17 |   0.9480 |     34.215 |   0.9906 |     35.417 |     1.9
   18 |   0.9308 |     33.229 |   0.9779 |     34.808 |     2.0
   19 |   0.9229 |     33.142 |   0.9808 |     35.481 |     2.1
   20 |   0.9173 |     32.977 |   0.9593 |     34.391 |     2.2
   21 |   0.9020 |     32.369 |   0.9373 |     34.103 |     2.3
   22 |   0.8837 |     31.175 |   0.9968 |     33.622 |     2.4
   23 |   0.8917 |     31.542 |   0.9601 |     34.615 |     2.5
   24 |   0.8622 |     30.528 |   0.9228 |     32.468 |     2.7
   25 |   0.8537 |     30.062 |   0.9515 |     33.205 |     2.8
   26 |   0.8379 |     29.569 |   0.9886 |     33.814 |     2.9
   27 |   0.8467 |     29.695 |   0.9462 |     32.724 |     3.0
   28 |   0.8095 |     28.901 |   0.9509 |     32.372 |     3.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 358,818

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6962 |     49.118 |   1.3342 |     45.481 |     0.1
    2 |   1.3267 |     44.740 |   1.2737 |     44.231 |     0.2
    3 |   1.2668 |     44.105 |   1.2201 |     43.590 |     0.3
    4 |   1.2211 |     42.751 |   1.1773 |     40.865 |     0.4
    5 |   1.1817 |     41.552 |   1.1118 |     38.622 |     0.5
    6 |   1.1535 |     40.834 |   1.1272 |     40.064 |     0.6
    7 |   1.1175 |     39.579 |   1.1077 |     39.391 |     0.7
    8 |   1.1019 |     38.818 |   1.0773 |     38.622 |     0.8
    9 |   1.0799 |     38.034 |   1.0388 |     36.538 |     0.9
   10 |   1.0577 |     37.278 |   1.0364 |     36.635 |     1.0
   11 |   1.0366 |     36.308 |   1.0293 |     36.282 |     1.1
   12 |   1.0157 |     35.777 |   0.9931 |     36.154 |     1.2
   13 |   0.9997 |     35.459 |   0.9957 |     35.064 |     1.3
   14 |   0.9769 |     34.577 |   0.9767 |     34.615 |     1.4
   15 |   0.9649 |     33.520 |   0.9825 |     34.038 |     1.5
   16 |   0.9434 |     32.950 |   0.9478 |     32.564 |     1.6
   17 |   0.9367 |     32.572 |   0.9991 |     34.776 |     1.7
   18 |   0.9101 |     32.051 |   0.9691 |     32.788 |     1.8
   19 |   0.9040 |     31.410 |   0.9541 |     33.301 |     1.9
   20 |   0.8715 |     29.942 |   0.9522 |     32.308 |     2.0
   21 |   0.8584 |     29.838 |   0.9474 |     32.692 |     2.1
   22 |   0.8406 |     29.098 |   0.9141 |     30.737 |     2.2
   23 |   0.8388 |     28.989 |   0.9204 |     30.994 |     2.3
   24 |   0.8166 |     28.643 |   0.9660 |     31.635 |     2.4
   25 |   0.8052 |     27.865 |   0.9095 |     30.545 |     2.5
   26 |   0.7928 |     27.416 |   0.9189 |     30.481 |     2.6
   27 |   0.7813 |     26.819 |   0.9042 |     30.160 |     2.7
   28 |   0.7616 |     26.589 |   0.9325 |     30.641 |     2.8
   29 |   0.7468 |     26.096 |   0.9378 |     29.968 |     2.9
   30 |   0.7257 |     25.241 |   0.9138 |     30.000 |     3.0
   31 |   0.7172 |     25.186 |   0.9440 |     30.385 |     3.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 358,818

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7351 |     67.412 |   1.9575 |     49.615 |     0.1
    2 |   1.8929 |     47.211 |   1.5942 |     45.801 |     0.2
    3 |   1.6349 |     45.984 |   1.4991 |     45.737 |     0.3
    4 |   1.5406 |     46.000 |   1.4473 |     46.250 |     0.4
    5 |   1.4869 |     45.562 |   1.4076 |     45.160 |     0.5
    6 |   1.4473 |     45.644 |   1.3746 |     44.904 |     0.6
    7 |   1.4176 |     44.866 |   1.3525 |     44.776 |     0.7
    8 |   1.3923 |     45.053 |   1.3314 |     44.071 |     0.8
    9 |   1.3801 |     44.631 |   1.3125 |     44.199 |     0.9
   10 |   1.3559 |     44.368 |   1.3057 |     43.654 |     1.0
   11 |   1.3409 |     43.968 |   1.2864 |     42.724 |     1.1
   12 |   1.3308 |     43.645 |   1.2747 |     43.173 |     1.2
   13 |   1.3109 |     43.327 |   1.2585 |     42.756 |     1.3
   14 |   1.3014 |     43.272 |   1.2543 |     42.340 |     1.4
   15 |   1.2904 |     42.921 |   1.2371 |     42.212 |     1.5
   16 |   1.2815 |     42.625 |   1.2350 |     42.340 |     1.6
   17 |   1.2679 |     42.615 |   1.2363 |     42.532 |     1.8
   18 |   1.2608 |     42.467 |   1.2210 |     42.340 |     1.9
   19 |   1.2542 |     42.034 |   1.2132 |     41.955 |     2.0
   20 |   1.2396 |     41.963 |   1.2017 |     41.218 |     2.1
   21 |   1.2311 |     41.754 |   1.1996 |     41.122 |     2.2
   22 |   1.2242 |     41.426 |   1.2004 |     40.865 |     2.3
   23 |   1.2176 |     41.278 |   1.1927 |     40.737 |     2.4
   24 |   1.2077 |     41.261 |   1.1921 |     40.673 |     2.5
   25 |   1.2022 |     40.757 |   1.1797 |     40.513 |     2.6
   26 |   1.1946 |     40.659 |   1.1774 |     40.224 |     2.7
   27 |   1.1906 |     40.335 |   1.1709 |     40.449 |     2.8
   28 |   1.1803 |     40.270 |   1.1605 |     39.872 |     2.9
   29 |   1.1730 |     40.149 |   1.1573 |     40.128 |     3.0
   30 |   1.1734 |     40.259 |   1.1663 |     39.968 |     3.1
   31 |   1.1657 |     39.908 |   1.1451 |     39.359 |     3.2
   32 |   1.1579 |     39.897 |   1.1643 |     40.256 |     3.3
   33 |   1.1595 |     39.705 |   1.1513 |     39.647 |     3.4
   34 |   1.1511 |     39.103 |   1.1568 |     39.872 |     3.5
   35 |   1.1481 |     39.574 |   1.1590 |     39.679 |     3.6
   36 |   1.1414 |     39.371 |   1.1334 |     39.359 |     3.7
   37 |   1.1351 |     39.305 |   1.1474 |     39.391 |     3.8
   38 |   1.1316 |     39.333 |   1.1521 |     38.910 |     3.9
   39 |   1.1330 |     38.872 |   1.1238 |     39.038 |     4.1
   40 |   1.1229 |     38.905 |   1.1326 |     38.718 |     4.2
   41 |   1.1173 |     38.566 |   1.1407 |     38.718 |     4.3
   42 |   1.1199 |     38.571 |   1.0958 |     38.237 |     4.4
   43 |   1.1049 |     37.930 |   1.1252 |     38.526 |     4.5
   44 |   1.1053 |     38.182 |   1.1177 |     38.462 |     4.6
   45 |   1.1006 |     37.974 |   1.1079 |     38.077 |     4.7
   46 |   1.0934 |     37.684 |   1.1079 |     37.981 |     4.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 779,682

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4749 |     46.554 |   1.2703 |     42.436 |     0.1
    2 |   1.2247 |     42.395 |   1.1677 |     41.378 |     0.2
    3 |   1.1535 |     40.691 |   1.1101 |     38.878 |     0.3
    4 |   1.1040 |     38.451 |   1.0701 |     37.596 |     0.4
    5 |   1.0478 |     36.796 |   1.0454 |     36.282 |     0.5
    6 |   1.0000 |     35.361 |   1.0308 |     36.186 |     0.6
    7 |   0.9639 |     33.766 |   0.9869 |     34.295 |     0.7
    8 |   0.9093 |     31.679 |   1.0014 |     35.096 |     0.8
    9 |   0.8912 |     31.054 |   0.9800 |     34.679 |     0.9
   10 |   0.8419 |     29.772 |   1.0157 |     35.032 |     1.0
   11 |   0.8241 |     28.512 |   0.9837 |     33.462 |     1.2
   12 |   0.7912 |     27.613 |   1.0367 |     34.103 |     1.3
   13 |   0.7720 |     26.501 |   0.9821 |     32.917 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 979,874

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5737 |     48.614 |   1.3301 |     43.782 |     0.1
    2 |   1.2490 |     42.872 |   1.2163 |     41.635 |     0.2
    3 |   1.1873 |     41.404 |   1.1675 |     41.346 |     0.3
    4 |   1.1335 |     39.618 |   1.1052 |     38.590 |     0.4
    5 |   1.0695 |     37.086 |   1.1043 |     38.558 |     0.5
    6 |   1.0249 |     35.832 |   1.1250 |     37.949 |     0.6
    7 |   1.0470 |     36.040 |   1.0215 |     35.256 |     0.7
    8 |   0.9679 |     33.372 |   1.0352 |     35.641 |     0.8
    9 |   0.9109 |     31.799 |   1.0305 |     34.615 |     0.9
   10 |   0.8680 |     30.134 |   1.0534 |     34.968 |     1.0
   11 |   0.8514 |     29.361 |   0.9975 |     33.494 |     1.1
   12 |   0.8240 |     28.320 |   0.9880 |     32.821 |     1.3
   13 |   0.7703 |     26.353 |   0.9927 |     32.628 |     1.4
   14 |   0.7584 |     26.479 |   1.0009 |     33.077 |     1.5
   15 |   0.6944 |     24.217 |   1.0234 |     33.654 |     1.6
   16 |   0.7024 |     24.244 |   1.0114 |     32.532 |     1.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 748,578

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5133 |     47.178 |   1.3199 |     45.192 |     0.1
    2 |   1.2722 |     44.581 |   1.2294 |     43.269 |     0.3
    3 |   1.2169 |     43.113 |   1.1972 |     42.628 |     0.4
    4 |   1.1886 |     42.253 |   1.1649 |     42.532 |     0.5
    5 |   1.1600 |     41.946 |   1.1349 |     40.962 |     0.7
    6 |   1.1343 |     40.505 |   1.1387 |     42.404 |     0.8
    7 |   1.1228 |     40.297 |   1.1152 |     39.487 |     1.0
    8 |   1.0997 |     39.689 |   1.0987 |     39.583 |     1.1
    9 |   1.0965 |     39.535 |   1.0781 |     39.583 |     1.2
   10 |   1.0852 |     39.223 |   1.0572 |     37.756 |     1.4
   11 |   1.0673 |     38.407 |   1.0563 |     37.885 |     1.5
   12 |   1.0637 |     38.588 |   1.0611 |     38.814 |     1.7
   13 |   1.0538 |     38.220 |   1.0541 |     38.045 |     1.8
   14 |   1.0516 |     38.029 |   1.0458 |     38.397 |     1.9
   15 |   1.0436 |     37.760 |   1.0345 |     37.500 |     2.1
   16 |   1.0149 |     36.714 |   1.0373 |     37.756 |     2.2
   17 |   1.0200 |     37.086 |   1.0483 |     38.141 |     2.4
   18 |   1.0092 |     36.823 |   1.0229 |     35.609 |     2.5
   19 |   1.0066 |     36.456 |   1.0215 |     35.994 |     2.6
   20 |   0.9887 |     36.067 |   1.0066 |     35.865 |     2.8
   21 |   0.9894 |     36.160 |   1.0089 |     36.314 |     2.9
   22 |   0.9924 |     35.766 |   1.0055 |     36.987 |     3.0
   23 |   0.9859 |     35.760 |   1.0052 |     37.083 |     3.2
   24 |   0.9774 |     35.470 |   0.9975 |     35.609 |     3.3
   25 |   0.9656 |     35.026 |   1.0134 |     35.865 |     3.5
   26 |   0.9600 |     34.845 |   0.9905 |     34.423 |     3.6
   27 |   0.9539 |     34.780 |   0.9937 |     34.904 |     3.7
   28 |   0.9502 |     34.626 |   0.9744 |     34.615 |     3.9
   29 |   0.9513 |     34.572 |   0.9957 |     34.968 |     4.0
   30 |   0.9424 |     34.330 |   0.9953 |     36.186 |     4.2
   31 |   0.9411 |     34.040 |   0.9778 |     35.032 |     4.3
   32 |   0.9320 |     34.139 |   0.9856 |     35.769 |     4.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,243,426

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3515 |     59.226 |   1.5997 |     46.250 |     0.2
    2 |   1.5972 |     46.444 |   1.4335 |     46.250 |     0.3
    3 |   1.4717 |     46.132 |   1.3703 |     44.744 |     0.5
    4 |   1.4145 |     45.946 |   1.3405 |     45.513 |     0.6
    5 |   1.3799 |     44.959 |   1.3095 |     43.654 |     0.8
    6 |   1.3430 |     44.505 |   1.2800 |     42.981 |     1.0
    7 |   1.3260 |     44.286 |   1.2647 |     43.237 |     1.1
    8 |   1.2975 |     43.299 |   1.2520 |     43.301 |     1.3
    9 |   1.2799 |     42.538 |   1.2572 |     42.917 |     1.5
   10 |   1.2690 |     42.499 |   1.2429 |     41.987 |     1.6
   11 |   1.2516 |     42.193 |   1.2198 |     42.244 |     1.8
   12 |   1.2317 |     41.354 |   1.2031 |     40.994 |     2.0
   13 |   1.2224 |     41.530 |   1.1726 |     39.327 |     2.1
   14 |   1.2036 |     40.505 |   1.1637 |     40.128 |     2.3
   15 |   1.1934 |     40.407 |   1.1599 |     39.679 |     2.4
   16 |   1.1790 |     40.242 |   1.1422 |     38.782 |     2.6
   17 |   1.1724 |     39.924 |   1.1420 |     39.263 |     2.8
   18 |   1.1585 |     39.009 |   1.1454 |     38.814 |     2.9
   19 |   1.1449 |     38.878 |   1.1826 |     39.615 |     3.1
   20 |   1.1383 |     38.779 |   1.1563 |     39.103 |     3.3
   21 |   1.1125 |     38.034 |   1.1374 |     38.109 |     3.4
   22 |   1.1063 |     37.558 |   1.1338 |     37.724 |     3.6
   23 |   1.0917 |     37.064 |   1.1081 |     37.244 |     3.7
   24 |   1.0769 |     36.621 |   1.0991 |     36.571 |     3.9
   25 |   1.0767 |     36.555 |   1.1107 |     37.532 |     4.1
   26 |   1.0657 |     36.171 |   1.0950 |     36.635 |     4.2
   27 |   1.0472 |     35.328 |   1.1239 |     37.340 |     4.4
   28 |   1.0377 |     35.043 |   1.0696 |     35.577 |     4.6
   29 |   1.0250 |     34.796 |   1.1090 |     36.154 |     4.7
   30 |   1.0160 |     34.363 |   1.1323 |     36.603 |     4.9
   31 |   1.0006 |     34.089 |   1.1061 |     36.122 |     5.0
   32 |   1.0021 |     33.794 |   1.0898 |     35.801 |     5.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,177,250

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3510 |     59.511 |   1.5704 |     45.737 |     0.1
    2 |   1.5800 |     46.335 |   1.4214 |     45.865 |     0.2
    3 |   1.4621 |     46.181 |   1.3723 |     44.840 |     0.3
    4 |   1.4083 |     45.398 |   1.3278 |     44.872 |     0.4
    5 |   1.3745 |     45.003 |   1.3008 |     44.647 |     0.5
    6 |   1.3449 |     44.160 |   1.2776 |     43.590 |     0.7
    7 |   1.3176 |     43.946 |   1.2594 |     43.013 |     0.8
    8 |   1.2997 |     43.414 |   1.2380 |     42.083 |     0.9
    9 |   1.2769 |     42.888 |   1.2241 |     42.083 |     1.0
   10 |   1.2578 |     42.401 |   1.2100 |     41.442 |     1.1
   11 |   1.2389 |     42.012 |   1.2109 |     42.244 |     1.2
   12 |   1.2268 |     41.946 |   1.2034 |     41.442 |     1.3
   13 |   1.2161 |     41.650 |   1.1803 |     40.385 |     1.4
   14 |   1.2019 |     40.653 |   1.1601 |     39.936 |     1.5
   15 |   1.1889 |     40.500 |   1.2034 |     40.321 |     1.6
   16 |   1.1739 |     40.094 |   1.1507 |     39.615 |     1.7
   17 |   1.1650 |     39.985 |   1.1562 |     39.231 |     1.8
   18 |   1.1546 |     39.552 |   1.1784 |     39.840 |     1.9
   19 |   1.1440 |     38.916 |   1.1569 |     39.359 |     2.1
   20 |   1.1264 |     38.730 |   1.1746 |     40.481 |     2.2
   21 |   1.1229 |     38.582 |   1.1334 |     39.583 |     2.3
   22 |   1.1037 |     38.264 |   1.1229 |     38.654 |     2.4
   23 |   1.1002 |     38.067 |   1.1517 |     39.615 |     2.5
   24 |   1.0886 |     37.914 |   1.1283 |     38.718 |     2.6
   25 |   1.0745 |     36.818 |   1.1285 |     38.558 |     2.7
   26 |   1.0729 |     36.610 |   1.1176 |     37.821 |     2.8
   27 |   1.0569 |     36.380 |   1.1005 |     37.756 |     2.9
   28 |   1.0521 |     36.034 |   1.0889 |     37.821 |     3.0
   29 |   1.0453 |     36.012 |   1.0767 |     37.244 |     3.1
   30 |   1.0379 |     35.519 |   1.0902 |     36.955 |     3.2
   31 |   1.0197 |     35.125 |   1.0825 |     36.955 |     3.4
   32 |   1.0136 |     34.309 |   1.1162 |     38.013 |     3.5
   33 |   1.0046 |     34.298 |   1.0873 |     36.923 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 813,986

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2496 |     57.413 |   1.5520 |     45.737 |     0.1
    2 |   1.5229 |     46.022 |   1.4036 |     44.936 |     0.2
    3 |   1.4107 |     45.316 |   1.3350 |     43.942 |     0.4
    4 |   1.3535 |     43.946 |   1.2838 |     43.494 |     0.5
    5 |   1.3107 |     43.480 |   1.2443 |     42.756 |     0.6
    6 |   1.2751 |     42.560 |   1.2168 |     40.929 |     0.7
    7 |   1.2432 |     41.716 |   1.2018 |     41.442 |     0.8
    8 |   1.2196 |     41.524 |   1.1589 |     39.615 |     0.9
    9 |   1.1984 |     40.785 |   1.1617 |     40.096 |     1.1
   10 |   1.1790 |     40.494 |   1.1353 |     38.942 |     1.2
   11 |   1.1649 |     39.974 |   1.1292 |     39.199 |     1.3
   12 |   1.1505 |     39.568 |   1.1074 |     38.429 |     1.4
   13 |   1.1312 |     39.300 |   1.0976 |     38.109 |     1.5
   14 |   1.1159 |     38.440 |   1.0814 |     37.981 |     1.7
   15 |   1.1067 |     38.215 |   1.0951 |     37.981 |     1.8
   16 |   1.0914 |     37.596 |   1.0892 |     37.179 |     1.9
   17 |   1.0855 |     37.481 |   1.0632 |     35.994 |     2.0
   18 |   1.0748 |     36.889 |   1.0600 |     36.026 |     2.1
   19 |   1.0545 |     36.549 |   1.0479 |     36.090 |     2.2
   20 |   1.0422 |     35.651 |   1.0565 |     36.314 |     2.4
   21 |   1.0321 |     35.180 |   1.0409 |     35.128 |     2.5
   22 |   1.0258 |     35.037 |   1.0323 |     35.160 |     2.6
   23 |   1.0101 |     34.741 |   1.0115 |     34.455 |     2.7
   24 |   1.0001 |     34.456 |   1.0280 |     34.391 |     2.8
   25 |   0.9834 |     33.826 |   1.0221 |     34.327 |     3.0
   26 |   0.9751 |     33.284 |   1.0232 |     34.167 |     3.1
   27 |   0.9672 |     33.032 |   1.0092 |     33.750 |     3.2
   28 |   0.9506 |     32.358 |   1.0049 |     33.462 |     3.3
   29 |   0.9413 |     31.881 |   0.9892 |     33.013 |     3.4
   30 |   0.9301 |     31.695 |   0.9920 |     33.205 |     3.5
   31 |   0.9210 |     31.262 |   0.9914 |     33.365 |     3.7
   32 |   0.9095 |     30.868 |   0.9862 |     32.756 |     3.8
   33 |   0.8956 |     30.917 |   0.9745 |     32.372 |     3.9
   34 |   0.8893 |     29.931 |   0.9842 |     32.628 |     4.0
   35 |   0.8825 |     29.920 |   0.9836 |     32.756 |     4.1
   36 |   0.8713 |     29.810 |   0.9794 |     32.532 |     4.3
   37 |   0.8656 |     29.284 |   0.9657 |     31.923 |     4.4
   38 |   0.8517 |     28.720 |   1.0053 |     33.974 |     4.5
   39 |   0.8465 |     28.561 |   0.9723 |     32.212 |     4.6
   40 |   0.8305 |     28.145 |   0.9804 |     32.308 |     4.7
   41 |   0.8129 |     27.723 |   0.9871 |     32.692 |     4.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 292,962

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5950 |     59.654 |   1.9940 |     46.378 |     0.1
    2 |   1.8781 |     46.466 |   1.6404 |     46.250 |     0.2
    3 |   1.6343 |     45.940 |   1.5192 |     45.321 |     0.3
    4 |   1.5327 |     45.650 |   1.4510 |     45.609 |     0.4
    5 |   1.4737 |     45.354 |   1.4077 |     45.000 |     0.5
    6 |   1.4353 |     45.020 |   1.3796 |     44.038 |     0.6
    7 |   1.4039 |     44.340 |   1.3509 |     42.981 |     0.8
    8 |   1.3806 |     44.072 |   1.3260 |     42.564 |     0.9
    9 |   1.3524 |     43.995 |   1.3046 |     42.564 |     1.0
   10 |   1.3404 |     43.579 |   1.2914 |     42.660 |     1.1
   11 |   1.3243 |     43.519 |   1.2764 |     42.179 |     1.2
   12 |   1.3025 |     43.025 |   1.2618 |     41.667 |     1.3
   13 |   1.2896 |     42.751 |   1.2513 |     41.538 |     1.4
   14 |   1.2771 |     42.609 |   1.2306 |     40.897 |     1.5
   15 |   1.2643 |     42.143 |   1.2265 |     40.769 |     1.6
   16 |   1.2522 |     41.815 |   1.2171 |     40.481 |     1.7
   17 |   1.2430 |     41.672 |   1.2105 |     41.090 |     1.8
   18 |   1.2320 |     41.382 |   1.1889 |     39.840 |     1.9
   19 |   1.2236 |     40.954 |   1.1812 |     39.455 |     2.1
   20 |   1.2146 |     41.015 |   1.1834 |     39.904 |     2.2
   21 |   1.2013 |     40.642 |   1.1673 |     39.808 |     2.3
   22 |   1.1965 |     40.609 |   1.1769 |     39.840 |     2.4
   23 |   1.1860 |     40.100 |   1.1560 |     39.679 |     2.5
   24 |   1.1775 |     40.089 |   1.1432 |     39.167 |     2.6
   25 |   1.1698 |     40.007 |   1.1482 |     39.263 |     2.7
   26 |   1.1578 |     39.470 |   1.1338 |     39.295 |     2.8
   27 |   1.1509 |     39.146 |   1.1217 |     38.269 |     2.9
   28 |   1.1419 |     39.250 |   1.1305 |     38.622 |     3.0
   29 |   1.1375 |     38.861 |   1.1053 |     37.949 |     3.1
   30 |   1.1293 |     38.522 |   1.1102 |     38.462 |     3.2
   31 |   1.1198 |     38.281 |   1.0956 |     37.404 |     3.4
   32 |   1.1192 |     38.171 |   1.0878 |     37.051 |     3.5
   33 |   1.1154 |     38.199 |   1.1023 |     37.788 |     3.6
   34 |   1.1030 |     37.744 |   1.0874 |     36.699 |     3.7
   35 |   1.1010 |     37.722 |   1.0775 |     36.506 |     3.8
   36 |   1.0928 |     37.048 |   1.0978 |     37.404 |     3.9
   37 |   1.0845 |     36.955 |   1.0678 |     36.635 |     4.0
   38 |   1.0770 |     37.048 |   1.0902 |     36.635 |     4.1
   39 |   1.0771 |     36.938 |   1.0630 |     36.122 |     4.2
   40 |   1.0687 |     36.440 |   1.0674 |     36.122 |     4.3
   41 |   1.0587 |     36.495 |   1.0678 |     36.186 |     4.4
   42 |   1.0529 |     36.078 |   1.0749 |     36.410 |     4.5
   43 |   1.0481 |     35.695 |   1.0653 |     36.667 |     4.6
   44 |   1.0440 |     35.777 |   1.0490 |     36.282 |     4.8
   45 |   1.0402 |     35.278 |   1.0448 |     35.865 |     4.9
   46 |   1.0402 |     35.470 |   1.0416 |     35.609 |     5.0
   47 |   1.0276 |     35.229 |   1.0454 |     36.250 |     5.1
   48 |   1.0283 |     34.856 |   1.0411 |     35.449 |     5.2
   49 |   1.0205 |     34.429 |   1.0361 |     35.705 |     5.3
   50 |   1.0161 |     34.659 |   1.0344 |     35.545 |     5.4
   51 |   1.0105 |     34.829 |   1.0417 |     35.353 |     5.5
   52 |   1.0070 |     34.259 |   1.0232 |     35.096 |     5.6
   53 |   1.0020 |     34.402 |   1.0293 |     35.096 |     5.7
   54 |   0.9968 |     34.089 |   1.0178 |     35.096 |     5.8
   55 |   0.9880 |     33.826 |   1.0132 |     34.615 |     5.9
   56 |   0.9908 |     33.931 |   1.0135 |     34.904 |     6.0
   57 |   0.9859 |     33.668 |   1.0043 |     33.942 |     6.2
   58 |   0.9736 |     33.081 |   1.0025 |     34.167 |     6.3
   59 |   0.9696 |     33.191 |   1.0256 |     34.647 |     6.4
   60 |   0.9671 |     33.443 |   1.0098 |     34.103 |     6.5
   61 |   0.9720 |     33.081 |   1.0039 |     33.974 |     6.6
   62 |   0.9630 |     32.747 |   1.0047 |     34.423 |     6.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 979,874

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0163 |     53.906 |   1.4751 |     45.160 |     0.1
    2 |   1.4011 |     44.105 |   1.3498 |     43.269 |     0.2
    3 |   1.3100 |     42.905 |   1.3008 |     44.006 |     0.3
    4 |   1.2608 |     41.743 |   1.2431 |     41.314 |     0.4
    5 |   1.2199 |     40.511 |   1.2222 |     41.218 |     0.5
    6 |   1.1853 |     39.798 |   1.1704 |     39.327 |     0.6
    7 |   1.1456 |     38.637 |   1.1503 |     38.333 |     0.7
    8 |   1.1133 |     38.226 |   1.1005 |     38.109 |     0.8
    9 |   1.0807 |     36.938 |   1.0974 |     37.244 |     0.9
   10 |   1.0543 |     35.980 |   1.0712 |     36.186 |     1.0
   11 |   1.0249 |     34.829 |   1.0718 |     36.058 |     1.1
   12 |   1.0079 |     33.931 |   1.0281 |     35.321 |     1.2
   13 |   0.9864 |     33.235 |   1.0117 |     34.103 |     1.3
   14 |   0.9573 |     31.860 |   1.0049 |     34.295 |     1.4
   15 |   0.9379 |     31.279 |   0.9961 |     33.622 |     1.5
   16 |   0.9092 |     30.397 |   0.9864 |     33.237 |     1.6
   17 |   0.8901 |     29.531 |   0.9791 |     32.372 |     1.7
   18 |   0.8688 |     28.846 |   0.9566 |     31.474 |     1.8
   19 |   0.8490 |     28.348 |   0.9784 |     32.660 |     1.9
   20 |   0.8347 |     27.970 |   0.9632 |     32.276 |     2.0
   21 |   0.8079 |     26.726 |   0.9450 |     31.506 |     2.1
   22 |   0.7836 |     25.838 |   0.9312 |     30.545 |     2.2
   23 |   0.7632 |     24.995 |   0.9121 |     30.224 |     2.3
   24 |   0.7406 |     24.332 |   0.9331 |     30.609 |     2.4
   25 |   0.7286 |     23.921 |   0.9221 |     29.840 |     2.5
   26 |   0.7045 |     23.028 |   0.8921 |     29.808 |     2.6
   27 |   0.6842 |     22.545 |   0.9062 |     29.487 |     2.7
   28 |   0.6721 |     21.899 |   0.9138 |     29.135 |     2.8
   29 |   0.6530 |     21.357 |   0.9325 |     29.551 |     2.9
   30 |   0.6347 |     20.628 |   0.9346 |     29.872 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,243,426

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4969 |     47.146 |   1.2603 |     42.981 |     0.1
    2 |   1.2479 |     43.480 |   1.1933 |     42.115 |     0.3
    3 |   1.1976 |     42.571 |   1.1563 |     41.346 |     0.4
    4 |   1.1635 |     42.160 |   1.1630 |     43.237 |     0.6
    5 |   1.1551 |     41.743 |   1.1332 |     40.769 |     0.7
    6 |   1.1374 |     41.623 |   1.1456 |     41.667 |     0.9
    7 |   1.1314 |     41.239 |   1.1050 |     40.609 |     1.0
    8 |   1.1115 |     41.130 |   1.0733 |     40.160 |     1.2
    9 |   1.0887 |     39.650 |   1.0708 |     39.904 |     1.3
   10 |   1.0846 |     39.842 |   1.0596 |     39.423 |     1.5
   11 |   1.0670 |     39.338 |   1.0545 |     38.045 |     1.6
   12 |   1.0581 |     38.314 |   1.0552 |     38.718 |     1.8
   13 |   1.0611 |     38.664 |   1.0464 |     37.981 |     1.9
   14 |   1.0463 |     38.555 |   1.0475 |     37.788 |     2.1
   15 |   1.0496 |     38.631 |   1.0564 |     38.013 |     2.3
   16 |   1.0472 |     38.615 |   1.0437 |     37.853 |     2.4
   17 |   1.0557 |     39.207 |   1.0481 |     39.038 |     2.5
   18 |   1.0414 |     38.478 |   1.0464 |     38.782 |     2.7
   19 |   1.0528 |     38.977 |   1.1273 |     40.577 |     2.8
   20 |   1.0448 |     38.440 |   1.0254 |     37.724 |     3.0
   21 |   1.0390 |     38.823 |   1.0441 |     38.365 |     3.1
   22 |   1.0262 |     38.111 |   1.0257 |     38.750 |     3.3
   23 |   1.0267 |     38.368 |   1.0319 |     39.135 |     3.4
   24 |   1.0165 |     37.755 |   1.0487 |     38.141 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 731,746

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2990 |     59.276 |   1.5818 |     46.250 |     0.1
    2 |   1.5535 |     45.726 |   1.4076 |     45.288 |     0.2
    3 |   1.4290 |     45.151 |   1.3348 |     43.333 |     0.3
    4 |   1.3681 |     44.187 |   1.2884 |     42.596 |     0.4
    5 |   1.3241 |     43.820 |   1.2559 |     42.404 |     0.5
    6 |   1.2865 |     42.795 |   1.2262 |     41.058 |     0.6
    7 |   1.2559 |     41.864 |   1.1940 |     39.712 |     0.7
    8 |   1.2369 |     41.458 |   1.1817 |     39.487 |     0.7
    9 |   1.2128 |     40.834 |   1.1604 |     38.654 |     0.8
   10 |   1.1935 |     40.675 |   1.1617 |     39.423 |     0.9
   11 |   1.1774 |     40.237 |   1.1419 |     38.590 |     1.0
   12 |   1.1587 |     39.256 |   1.1188 |     38.109 |     1.1
   13 |   1.1502 |     39.492 |   1.1385 |     38.750 |     1.2
   14 |   1.1333 |     39.075 |   1.0973 |     37.564 |     1.3
   15 |   1.1201 |     38.390 |   1.0787 |     36.795 |     1.4
   16 |   1.1064 |     37.525 |   1.0920 |     37.660 |     1.5
   17 |   1.0962 |     37.415 |   1.0877 |     37.436 |     1.6
   18 |   1.0851 |     37.141 |   1.0619 |     35.769 |     1.7
   19 |   1.0759 |     36.538 |   1.0603 |     35.994 |     1.8
   20 |   1.0593 |     36.626 |   1.0431 |     35.962 |     1.9
   21 |   1.0510 |     35.996 |   1.0755 |     36.827 |     2.0
   22 |   1.0448 |     35.525 |   1.0269 |     34.872 |     2.1
   23 |   1.0241 |     35.026 |   1.0429 |     35.513 |     2.2
   24 |   1.0208 |     34.719 |   1.0416 |     35.449 |     2.2
   25 |   1.0078 |     34.818 |   1.0205 |     34.327 |     2.3
   26 |   1.0008 |     33.865 |   1.0174 |     34.263 |     2.4
   27 |   0.9907 |     33.679 |   1.0116 |     33.910 |     2.5
   28 |   0.9861 |     33.679 |   1.0074 |     33.109 |     2.6
   29 |   0.9716 |     33.114 |   1.0095 |     33.878 |     2.7
   30 |   0.9642 |     32.911 |   0.9996 |     33.718 |     2.8
   31 |   0.9514 |     32.588 |   1.0089 |     33.494 |     2.9
   32 |   0.9429 |     32.117 |   1.0039 |     33.686 |     3.0
   33 |   0.9391 |     32.084 |   0.9905 |     32.532 |     3.1
   34 |   0.9290 |     31.410 |   0.9793 |     32.340 |     3.2
   35 |   0.9231 |     31.301 |   0.9941 |     33.205 |     3.3
   36 |   0.9087 |     31.027 |   0.9940 |     32.949 |     3.4
   37 |   0.9094 |     30.857 |   0.9786 |     31.859 |     3.5
   38 |   0.8936 |     29.827 |   0.9881 |     32.564 |     3.6
   39 |   0.8852 |     30.298 |   0.9832 |     32.179 |     3.7
   40 |   0.8744 |     29.805 |   0.9772 |     32.212 |     3.7
   41 |   0.8697 |     29.915 |   0.9646 |     31.923 |     3.8
   42 |   0.8626 |     29.378 |   0.9675 |     31.635 |     3.9
   43 |   0.8534 |     29.279 |   0.9788 |     32.019 |     4.0
   44 |   0.8454 |     28.983 |   0.9637 |     31.667 |     4.1
   45 |   0.8346 |     28.879 |   0.9693 |     31.538 |     4.2
   46 |   0.8283 |     28.161 |   0.9828 |     31.603 |     4.3
   47 |   0.8196 |     28.150 |   0.9595 |     31.314 |     4.4
   48 |   0.8145 |     27.487 |   0.9645 |     31.763 |     4.5
   49 |   0.8087 |     27.531 |   0.9516 |     31.154 |     4.6
   50 |   0.8051 |     27.520 |   0.9619 |     31.026 |     4.7
   51 |   0.7955 |     27.104 |   0.9679 |     31.314 |     4.8
   52 |   0.7955 |     27.285 |   0.9567 |     30.673 |     4.9
   53 |   0.7812 |     26.468 |   0.9408 |     30.577 |     5.0
   54 |   0.7720 |     26.183 |   0.9341 |     29.808 |     5.1
   55 |   0.7639 |     26.123 |   0.9445 |     30.160 |     5.2
   56 |   0.7494 |     25.121 |   0.9497 |     30.128 |     5.2
   57 |   0.7505 |     25.301 |   0.9649 |     31.218 |     5.3
   58 |   0.7388 |     25.005 |   0.9521 |     30.673 |     5.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 979,874

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5268 |     47.671 |   1.3102 |     44.679 |     0.1
    2 |   1.2395 |     42.834 |   1.2301 |     41.250 |     0.2
    3 |   1.1612 |     40.730 |   1.1296 |     39.135 |     0.4
    4 |   1.1076 |     38.215 |   1.0911 |     38.237 |     0.5
    5 |   1.0529 |     36.193 |   1.0485 |     35.897 |     0.6
    6 |   0.9906 |     34.089 |   1.0924 |     38.365 |     0.7
    7 |   0.9590 |     33.092 |   1.0167 |     35.705 |     0.8
    8 |   0.9292 |     31.816 |   0.9867 |     33.686 |     1.0
    9 |   0.8704 |     29.460 |   0.9790 |     33.205 |     1.1
   10 |   0.8189 |     28.243 |   0.9877 |     33.654 |     1.2
   11 |   0.7743 |     27.005 |   0.9806 |     32.949 |     1.3
   12 |   0.7181 |     24.288 |   1.0280 |     32.724 |     1.4
   13 |   0.6905 |     23.055 |   1.0113 |     33.045 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 458,786

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6656 |     48.373 |   1.3635 |     45.224 |     0.1
    2 |   1.3410 |     45.299 |   1.2755 |     45.064 |     0.2
    3 |   1.2786 |     44.297 |   1.2223 |     43.654 |     0.4
    4 |   1.2454 |     43.990 |   1.2045 |     42.019 |     0.5
    5 |   1.2159 |     43.387 |   1.1658 |     41.635 |     0.6
    6 |   1.2003 |     43.075 |   1.1550 |     41.474 |     0.7
    7 |   1.1830 |     42.565 |   1.1344 |     41.058 |     0.8
    8 |   1.1761 |     42.615 |   1.1261 |     42.019 |     1.0
    9 |   1.1560 |     41.694 |   1.1038 |     39.391 |     1.1
   10 |   1.1383 |     41.371 |   1.1033 |     40.577 |     1.2
   11 |   1.1346 |     41.042 |   1.0741 |     38.910 |     1.3
   12 |   1.1228 |     40.686 |   1.0952 |     39.327 |     1.4
   13 |   1.1189 |     40.522 |   1.0663 |     39.231 |     1.6
   14 |   1.1002 |     39.979 |   1.0618 |     38.622 |     1.7
   15 |   1.0938 |     39.902 |   1.0440 |     38.205 |     1.8
   16 |   1.0799 |     39.404 |   1.0428 |     38.077 |     1.9
   17 |   1.0761 |     38.741 |   1.0409 |     37.372 |     2.0
   18 |   1.0699 |     38.757 |   1.0462 |     38.045 |     2.2
   19 |   1.0683 |     38.757 |   1.0357 |     37.436 |     2.3
   20 |   1.0543 |     38.451 |   1.0234 |     37.532 |     2.4
   21 |   1.0481 |     38.034 |   1.0147 |     37.340 |     2.5
   22 |   1.0419 |     38.083 |   1.0145 |     36.987 |     2.6
   23 |   1.0337 |     37.826 |   1.0144 |     36.827 |     2.8
   24 |   1.0282 |     37.519 |   0.9965 |     36.891 |     2.9
   25 |   1.0183 |     37.152 |   1.0091 |     36.859 |     3.0
   26 |   1.0134 |     36.714 |   0.9978 |     36.410 |     3.1
   27 |   1.0080 |     36.895 |   1.0051 |     35.994 |     3.2
   28 |   1.0009 |     36.610 |   0.9641 |     34.103 |     3.4
   29 |   0.9927 |     35.717 |   0.9852 |     35.577 |     3.5
   30 |   0.9792 |     35.952 |   0.9618 |     33.686 |     3.6
   31 |   0.9636 |     35.092 |   0.9651 |     35.032 |     3.7
   32 |   0.9607 |     34.665 |   0.9577 |     34.359 |     3.8
   33 |   0.9616 |     34.758 |   0.9669 |     34.872 |     4.0
   34 |   0.9598 |     34.939 |   0.9484 |     34.006 |     4.1
   35 |   0.9468 |     34.117 |   0.9395 |     33.782 |     4.2
   36 |   0.9413 |     33.963 |   0.9501 |     34.583 |     4.3
   37 |   0.9366 |     33.657 |   0.9398 |     33.750 |     4.5
   38 |   0.9407 |     33.865 |   0.9668 |     33.878 |     4.6
   39 |   0.9247 |     33.202 |   0.9385 |     34.263 |     4.7
   40 |   0.9173 |     32.983 |   0.9390 |     33.526 |     4.8
   41 |   0.9231 |     32.692 |   0.9351 |     33.974 |     4.9
   42 |   0.9131 |     32.802 |   0.9260 |     32.308 |     5.1
   43 |   0.9096 |     32.588 |   0.9356 |     32.468 |     5.2
   44 |   0.9055 |     32.418 |   0.9144 |     32.212 |     5.3
   45 |   0.8933 |     31.903 |   0.9380 |     33.750 |     5.4
   46 |   0.8974 |     32.139 |   0.9286 |     32.853 |     5.5
   47 |   0.8874 |     31.503 |   0.9435 |     33.590 |     5.7
   48 |   0.8840 |     31.816 |   0.9462 |     33.718 |     5.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 326,498

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7269 |     49.797 |   1.3658 |     45.449 |     0.1
    2 |   1.3514 |     45.288 |   1.2784 |     44.103 |     0.2
    3 |   1.2763 |     43.666 |   1.2495 |     44.359 |     0.2
    4 |   1.2362 |     42.642 |   1.1869 |     42.404 |     0.3
    5 |   1.1923 |     41.343 |   1.1567 |     39.808 |     0.4
    6 |   1.1579 |     40.198 |   1.1285 |     38.942 |     0.5
    7 |   1.1381 |     39.618 |   1.1172 |     39.135 |     0.6
    8 |   1.1175 |     38.697 |   1.1081 |     37.756 |     0.7
    9 |   1.0919 |     37.766 |   1.0633 |     35.865 |     0.7
   10 |   1.0749 |     37.404 |   1.0422 |     36.314 |     0.8
   11 |   1.0507 |     36.029 |   1.0024 |     33.942 |     0.9
   12 |   1.0271 |     35.169 |   1.0082 |     33.654 |     1.0
   13 |   1.0071 |     34.835 |   0.9871 |     34.327 |     1.1
   14 |   0.9892 |     34.298 |   0.9780 |     33.237 |     1.2
   15 |   0.9666 |     33.377 |   0.9440 |     32.244 |     1.2
   16 |   0.9448 |     32.517 |   0.9543 |     32.821 |     1.3
   17 |   0.9268 |     31.838 |   0.9324 |     31.699 |     1.4
   18 |   0.9041 |     30.534 |   0.9499 |     32.917 |     1.5
   19 |   0.8934 |     30.380 |   0.9180 |     30.994 |     1.6
   20 |   0.8806 |     30.030 |   0.9266 |     30.321 |     1.6
   21 |   0.8519 |     29.246 |   0.8995 |     30.513 |     1.7
   22 |   0.8477 |     28.808 |   0.9416 |     31.603 |     1.8
   23 |   0.8397 |     28.769 |   0.9091 |     30.064 |     1.9
   24 |   0.8165 |     27.937 |   0.8908 |     30.288 |     2.0
   25 |   0.7882 |     26.846 |   0.9041 |     29.583 |     2.1
   26 |   0.7762 |     26.677 |   0.9361 |     30.385 |     2.1
   27 |   0.7790 |     26.775 |   0.8926 |     29.487 |     2.2
   28 |   0.7448 |     25.696 |   0.8870 |     29.776 |     2.3
   29 |   0.7262 |     24.693 |   0.8977 |     29.487 |     2.4
   30 |   0.7141 |     24.523 |   0.8885 |     28.494 |     2.5
   31 |   0.6906 |     23.811 |   0.9265 |     28.141 |     2.5
   32 |   0.6799 |     23.439 |   0.9035 |     27.821 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 292,962

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6271 |     61.002 |   1.9675 |     48.718 |     0.1
    2 |   1.8753 |     46.762 |   1.6410 |     46.250 |     0.2
    3 |   1.6522 |     46.220 |   1.5165 |     45.801 |     0.3
    4 |   1.5361 |     46.077 |   1.4455 |     45.769 |     0.4
    5 |   1.4718 |     45.518 |   1.3995 |     46.090 |     0.5
    6 |   1.4284 |     45.157 |   1.3642 |     44.038 |     0.6
    7 |   1.3972 |     44.844 |   1.3387 |     43.974 |     0.7
    8 |   1.3740 |     44.549 |   1.3168 |     43.846 |     0.9
    9 |   1.3517 |     44.357 |   1.2997 |     43.878 |     1.0
   10 |   1.3305 |     43.792 |   1.2827 |     43.109 |     1.1
   11 |   1.3173 |     43.645 |   1.2678 |     42.917 |     1.2
   12 |   1.3001 |     43.595 |   1.2603 |     42.981 |     1.3
   13 |   1.2863 |     43.069 |   1.2437 |     41.827 |     1.4
   14 |   1.2791 |     42.790 |   1.2356 |     42.564 |     1.5
   15 |   1.2706 |     42.494 |   1.2282 |     42.179 |     1.6
   16 |   1.2597 |     42.647 |   1.2230 |     42.019 |     1.7
   17 |   1.2533 |     42.160 |   1.2192 |     42.019 |     1.8
   18 |   1.2383 |     42.220 |   1.2129 |     41.442 |     1.9
   19 |   1.2290 |     41.842 |   1.2036 |     41.346 |     2.0
   20 |   1.2219 |     41.732 |   1.1901 |     40.833 |     2.1
   21 |   1.2100 |     41.278 |   1.1781 |     40.513 |     2.2
   22 |   1.2089 |     41.283 |   1.1895 |     41.250 |     2.4
   23 |   1.2016 |     40.987 |   1.1956 |     40.865 |     2.5
   24 |   1.1929 |     40.768 |   1.1893 |     41.474 |     2.6
   25 |   1.1890 |     40.752 |   1.1797 |     40.801 |     2.7
   26 |   1.1796 |     40.291 |   1.1625 |     40.160 |     2.8
   27 |   1.1766 |     40.330 |   1.1602 |     39.647 |     2.9
   28 |   1.1666 |     40.198 |   1.1543 |     39.647 |     3.0
   29 |   1.1649 |     40.050 |   1.1570 |     39.808 |     3.1
   30 |   1.1576 |     39.711 |   1.1403 |     39.776 |     3.2
   31 |   1.1489 |     39.530 |   1.1307 |     38.590 |     3.3
   32 |   1.1486 |     39.815 |   1.1281 |     39.038 |     3.4
   33 |   1.1411 |     39.240 |   1.1249 |     39.263 |     3.5
   34 |   1.1343 |     39.349 |   1.1291 |     39.006 |     3.6
   35 |   1.1273 |     39.344 |   1.1414 |     39.199 |     3.8
   36 |   1.1219 |     38.500 |   1.1099 |     38.846 |     3.9
   37 |   1.1153 |     38.686 |   1.1041 |     39.038 |     4.0
   38 |   1.1139 |     38.538 |   1.1214 |     38.974 |     4.1
   39 |   1.1062 |     38.188 |   1.1232 |     39.423 |     4.2
   40 |   1.1056 |     38.516 |   1.0971 |     38.237 |     4.3
   41 |   1.0901 |     37.766 |   1.0865 |     37.949 |     4.4
   42 |   1.0935 |     37.777 |   1.1129 |     39.231 |     4.5
   43 |   1.0846 |     37.393 |   1.0810 |     38.013 |     4.6
   44 |   1.0802 |     37.273 |   1.0867 |     37.596 |     4.7
   45 |   1.0768 |     37.273 |   1.0845 |     37.949 |     4.8
   46 |   1.0700 |     36.906 |   1.0806 |     37.596 |     4.9
   47 |   1.0610 |     36.637 |   1.0776 |     37.276 |     5.0
   48 |   1.0692 |     36.681 |   1.0739 |     37.244 |     5.2
   49 |   1.0580 |     36.182 |   1.0503 |     36.378 |     5.3
   50 |   1.0509 |     36.637 |   1.0614 |     36.218 |     5.4
   51 |   1.0464 |     35.985 |   1.0509 |     36.186 |     5.5
   52 |   1.0447 |     35.810 |   1.0566 |     36.763 |     5.6
   53 |   1.0400 |     36.243 |   1.0755 |     36.859 |     5.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 192,994

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8189 |     68.442 |   2.2450 |     53.814 |     0.1
    2 |   2.1837 |     50.657 |   1.7760 |     48.526 |     0.1
    3 |   1.8241 |     47.304 |   1.5994 |     46.859 |     0.2
    4 |   1.6607 |     46.263 |   1.5207 |     45.737 |     0.3
    5 |   1.5668 |     46.148 |   1.4702 |     45.769 |     0.3
    6 |   1.5139 |     46.110 |   1.4332 |     45.769 |     0.4
    7 |   1.4732 |     46.231 |   1.4029 |     45.641 |     0.4
    8 |   1.4412 |     45.820 |   1.3797 |     45.449 |     0.5
    9 |   1.4150 |     45.611 |   1.3589 |     45.481 |     0.6
   10 |   1.3972 |     45.480 |   1.3338 |     44.776 |     0.6
   11 |   1.3765 |     45.206 |   1.3188 |     44.263 |     0.7
   12 |   1.3605 |     44.839 |   1.3003 |     43.846 |     0.8
   13 |   1.3436 |     44.302 |   1.2950 |     43.878 |     0.8
   14 |   1.3299 |     44.581 |   1.2814 |     43.782 |     0.9
   15 |   1.3154 |     43.968 |   1.2696 |     43.686 |     1.0
   16 |   1.3067 |     43.990 |   1.2571 |     43.173 |     1.0
   17 |   1.3014 |     43.875 |   1.2596 |     43.718 |     1.1
   18 |   1.2998 |     44.066 |   1.2458 |     42.404 |     1.2
   19 |   1.2825 |     43.475 |   1.2384 |     42.917 |     1.2
   20 |   1.2749 |     43.601 |   1.2329 |     42.404 |     1.3
   21 |   1.2717 |     43.332 |   1.2285 |     42.628 |     1.3
   22 |   1.2626 |     43.053 |   1.2196 |     42.788 |     1.4
   23 |   1.2567 |     42.982 |   1.2138 |     42.756 |     1.5
   24 |   1.2519 |     42.812 |   1.2042 |     42.115 |     1.5
   25 |   1.2455 |     42.341 |   1.2125 |     42.115 |     1.6
   26 |   1.2378 |     42.308 |   1.1855 |     40.994 |     1.7
   27 |   1.2285 |     41.908 |   1.2086 |     42.276 |     1.7
   28 |   1.2260 |     41.891 |   1.1953 |     41.282 |     1.8
   29 |   1.2214 |     41.628 |   1.1821 |     41.378 |     1.9
   30 |   1.2194 |     42.138 |   1.1883 |     41.378 |     1.9
   31 |   1.2064 |     41.557 |   1.1803 |     41.282 |     2.0
   32 |   1.2024 |     41.300 |   1.1797 |     40.641 |     2.1
   33 |   1.2007 |     41.448 |   1.1642 |     40.577 |     2.1
   34 |   1.1960 |     41.234 |   1.1714 |     40.865 |     2.2
   35 |   1.1985 |     41.497 |   1.1749 |     40.737 |     2.2
   36 |   1.1936 |     41.031 |   1.1535 |     40.417 |     2.3
   37 |   1.1905 |     40.982 |   1.1707 |     40.577 |     2.4
   38 |   1.1855 |     40.812 |   1.1660 |     40.609 |     2.4
   39 |   1.1793 |     40.511 |   1.1584 |     40.256 |     2.5
   40 |   1.1759 |     40.374 |   1.1559 |     40.449 |     2.6
   41 |   1.1766 |     40.735 |   1.1528 |     40.160 |     2.6
   42 |   1.1721 |     40.483 |   1.1447 |     40.160 |     2.7
   43 |   1.1691 |     40.565 |   1.1576 |     39.936 |     2.8
   44 |   1.1649 |     40.341 |   1.1369 |     40.288 |     2.8
   45 |   1.1619 |     40.198 |   1.1493 |     40.192 |     2.9
   46 |   1.1612 |     40.363 |   1.1559 |     40.353 |     2.9
   47 |   1.1600 |     40.220 |   1.1406 |     39.776 |     3.0
   48 |   1.1515 |     39.722 |   1.1153 |     39.391 |     3.1
   49 |   1.1545 |     39.804 |   1.1294 |     39.712 |     3.1
   50 |   1.1505 |     40.215 |   1.1325 |     39.551 |     3.2
   51 |   1.1416 |     39.798 |   1.1319 |     39.615 |     3.3
   52 |   1.1420 |     39.661 |   1.1347 |     39.647 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 358,818

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6057 |     47.830 |   1.3129 |     44.359 |     0.1
    2 |   1.2497 |     42.631 |   1.1873 |     41.154 |     0.2
    3 |   1.1631 |     40.489 |   1.1197 |     38.686 |     0.3
    4 |   1.1042 |     38.659 |   1.0906 |     37.981 |     0.4
    5 |   1.0639 |     37.306 |   1.0348 |     36.827 |     0.5
    6 |   1.0200 |     35.432 |   1.0276 |     36.218 |     0.6
    7 |   0.9819 |     34.325 |   1.0345 |     36.154 |     0.7
    8 |   0.9416 |     32.829 |   1.0084 |     35.577 |     0.8
    9 |   0.9023 |     31.657 |   0.9847 |     33.750 |     0.8
   10 |   0.8688 |     30.276 |   0.9588 |     32.853 |     0.9
   11 |   0.8376 |     29.186 |   1.0169 |     34.391 |     1.0
   12 |   0.8167 |     28.413 |   0.9518 |     31.186 |     1.1
   13 |   0.7540 |     26.123 |   0.9695 |     32.179 |     1.2
   14 |   0.7342 |     25.362 |   0.9773 |     31.442 |     1.3
   15 |   0.7050 |     24.529 |   0.9776 |     31.699 |     1.4
   16 |   0.6519 |     22.491 |   0.9967 |     32.372 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 43 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 898,018

Training started
X_train.shape: torch.Size([3042, 702])
Y_train.shape: torch.Size([3042, 7])
X_dev.shape: torch.Size([520, 467])
Y_dev.shape: torch.Size([520, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6372 |     49.458 |   1.3156 |     43.878 |     0.1
    2 |   1.3004 |     44.954 |   1.2441 |     44.583 |     0.3
    3 |   1.2608 |     44.680 |   1.2065 |     43.654 |     0.4
    4 |   1.2304 |     43.677 |   1.1828 |     42.276 |     0.6
    5 |   1.2135 |     43.524 |   1.1581 |     42.692 |     0.7
    6 |   1.1933 |     43.080 |   1.1517 |     41.442 |     0.9
    7 |   1.1879 |     42.779 |   1.1402 |     42.051 |     1.0
    8 |   1.1735 |     42.330 |   1.1140 |     40.769 |     1.2
    9 |   1.1605 |     42.456 |   1.1305 |     41.699 |     1.3
   10 |   1.1609 |     42.269 |   1.1256 |     41.346 |     1.5
   11 |   1.1476 |     41.705 |   1.1090 |     40.353 |     1.6
   12 |   1.1413 |     41.639 |   1.0997 |     40.513 |     1.8
   13 |   1.1401 |     41.924 |   1.1070 |     40.224 |     1.9
   14 |   1.1325 |     41.869 |   1.0903 |     41.506 |     2.1
   15 |   1.1257 |     42.006 |   1.0952 |     40.545 |     2.2
   16 |   1.1305 |     41.880 |   1.0819 |     40.256 |     2.4
   17 |   1.1239 |     41.212 |   1.1101 |     39.968 |     2.5
   18 |   1.1280 |     41.656 |   1.0932 |     41.026 |     2.7
   19 |   1.1194 |     41.130 |   1.0916 |     40.321 |     2.8
   20 |   1.1164 |     41.497 |   1.0801 |     39.263 |     3.0
   21 |   1.1150 |     41.382 |   1.0803 |     41.314 |     3.1
   22 |   1.1101 |     41.234 |   1.0806 |     40.160 |     3.3
   23 |   1.1097 |     41.239 |   1.0789 |     39.872 |     3.4
   24 |   1.0987 |     40.889 |   1.0748 |     40.577 |     3.6
   25 |   1.1019 |     40.943 |   1.0698 |     39.840 |     3.7
   26 |   1.1014 |     40.867 |   1.0622 |     40.160 |     3.9
   27 |   1.0874 |     40.242 |   1.0675 |     40.321 |     4.0
   28 |   1.0859 |     40.209 |   1.0473 |     38.365 |     4.2
   29 |   1.0761 |     39.853 |   1.0532 |     40.032 |     4.3
   30 |   1.0772 |     38.927 |   1.0484 |     39.744 |     4.5
   31 |   1.0683 |     39.004 |   1.0382 |     37.660 |     4.6
   32 |   1.0701 |     39.355 |   1.0477 |     39.423 |     4.8
   33 |   1.0645 |     38.253 |   1.0583 |     38.686 |     4.9
   34 |   1.0575 |     38.812 |   1.0531 |     38.686 |     5.1
   35 |   1.0502 |     38.412 |   1.0595 |     38.718 |     5.2
Early stopping

