Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 425,634

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5600 |     61.216 |   1.8203 |     47.474 |     0.1
    2 |   1.7370 |     46.243 |   1.5597 |     45.256 |     0.2
    3 |   1.5618 |     45.724 |   1.4676 |     45.287 |     0.2
    4 |   1.4769 |     45.129 |   1.4081 |     43.777 |     0.3
    5 |   1.4238 |     44.649 |   1.3686 |     43.315 |     0.4
    6 |   1.3814 |     44.240 |   1.3377 |     43.869 |     0.5
    7 |   1.3509 |     44.020 |   1.3136 |     42.914 |     0.5
    8 |   1.3233 |     43.286 |   1.2957 |     42.760 |     0.6
    9 |   1.3009 |     42.817 |   1.2790 |     42.421 |     0.7
   10 |   1.2785 |     42.420 |   1.2482 |     40.912 |     0.8
   11 |   1.2608 |     41.956 |   1.2524 |     42.298 |     0.9
   12 |   1.2438 |     41.520 |   1.2340 |     42.113 |     0.9
   13 |   1.2278 |     41.504 |   1.2119 |     41.004 |     1.0
   14 |   1.2119 |     40.897 |   1.1991 |     40.665 |     1.1
   15 |   1.2006 |     40.676 |   1.2053 |     41.436 |     1.2
   16 |   1.1876 |     40.522 |   1.1915 |     40.357 |     1.3
   17 |   1.1779 |     39.882 |   1.1827 |     40.665 |     1.3
   18 |   1.1670 |     40.092 |   1.1650 |     40.357 |     1.4
   19 |   1.1539 |     39.242 |   1.1776 |     41.097 |     1.5
   20 |   1.1447 |     39.231 |   1.1809 |     40.635 |     1.6
   21 |   1.1366 |     38.950 |   1.1469 |     39.803 |     1.7
   22 |   1.1302 |     38.696 |   1.1468 |     39.310 |     1.7
   23 |   1.1206 |     38.194 |   1.1428 |     39.433 |     1.8
   24 |   1.1065 |     37.736 |   1.1388 |     40.173 |     1.9
   25 |   1.0996 |     37.752 |   1.1389 |     39.649 |     2.0
   26 |   1.0905 |     37.460 |   1.1248 |     39.156 |     2.1
   27 |   1.0857 |     37.129 |   1.1509 |     39.310 |     2.1
   28 |   1.0748 |     36.666 |   1.1210 |     38.632 |     2.2
   29 |   1.0712 |     36.892 |   1.1355 |     39.649 |     2.3
   30 |   1.0589 |     36.213 |   1.1215 |     38.509 |     2.4
   31 |   1.0540 |     35.998 |   1.1105 |     38.324 |     2.5
   32 |   1.0436 |     35.375 |   1.1256 |     38.478 |     2.5
   33 |   1.0349 |     35.038 |   1.1081 |     37.954 |     2.6
   34 |   1.0308 |     35.275 |   1.1136 |     37.523 |     2.7
   35 |   1.0235 |     34.955 |   1.1117 |     37.739 |     2.8
   36 |   1.0170 |     34.613 |   1.0991 |     37.431 |     2.9
   37 |   1.0121 |     34.442 |   1.0935 |     37.369 |     2.9
   38 |   1.0025 |     33.968 |   1.0952 |     36.784 |     3.0
   39 |   0.9949 |     33.764 |   1.0773 |     36.845 |     3.1
   40 |   0.9908 |     33.631 |   1.0841 |     36.784 |     3.2
   41 |   0.9794 |     33.322 |   1.0887 |     36.845 |     3.3
   42 |   0.9776 |     33.118 |   1.1113 |     37.153 |     3.3
   43 |   0.9675 |     32.583 |   1.0837 |     36.845 |     3.4
   44 |   0.9687 |     33.008 |   1.0715 |     36.044 |     3.5
   45 |   0.9545 |     32.699 |   1.0807 |     36.815 |     3.6
   46 |   0.9527 |     32.627 |   1.0638 |     36.414 |     3.7
   47 |   0.9442 |     32.175 |   1.0565 |     35.860 |     3.7
   48 |   0.9424 |     32.087 |   1.0815 |     36.630 |     3.8
   49 |   0.9326 |     31.811 |   1.0638 |     35.675 |     3.9
   50 |   0.9305 |     31.915 |   1.0809 |     36.630 |     4.0
   51 |   0.9216 |     31.695 |   1.0722 |     36.322 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 277,026

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6411 |     47.959 |   1.3408 |     44.732 |     0.1
    2 |   1.2710 |     42.707 |   1.2448 |     42.945 |     0.1
    3 |   1.1917 |     41.052 |   1.1642 |     39.895 |     0.2
    4 |   1.1331 |     39.231 |   1.1533 |     39.803 |     0.3
    5 |   1.0826 |     37.239 |   1.1119 |     38.632 |     0.4
    6 |   1.0393 |     36.164 |   1.1021 |     37.708 |     0.4
    7 |   1.0074 |     34.961 |   1.0616 |     36.168 |     0.5
    8 |   0.9747 |     33.764 |   1.0431 |     35.459 |     0.6
    9 |   0.9320 |     32.120 |   1.0253 |     35.274 |     0.6
   10 |   0.8942 |     30.652 |   1.0348 |     35.151 |     0.7
   11 |   0.8571 |     29.488 |   1.0245 |     33.826 |     0.8
   12 |   0.8290 |     28.445 |   1.0016 |     32.902 |     0.8
   13 |   0.7975 |     27.265 |   1.0148 |     33.333 |     0.9
   14 |   0.7529 |     25.560 |   1.0277 |     33.611 |     1.0
   15 |   0.7250 |     24.440 |   0.9934 |     31.978 |     1.1
   16 |   0.6946 |     24.026 |   1.0769 |     34.288 |     1.1
   17 |   0.6758 |     22.895 |   1.0301 |     32.656 |     1.2
   18 |   0.6353 |     21.742 |   1.0546 |     33.118 |     1.3
   19 |   0.6105 |     20.749 |   1.0545 |     33.333 |     1.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 847,394

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4964 |     46.922 |   1.2946 |     45.071 |     0.2
    2 |   1.2341 |     43.501 |   1.2106 |     43.715 |     0.3
    3 |   1.1818 |     42.116 |   1.1727 |     41.097 |     0.5
    4 |   1.1479 |     41.278 |   1.1480 |     41.651 |     0.6
    5 |   1.1284 |     40.858 |   1.1382 |     41.497 |     0.8
    6 |   1.1081 |     40.246 |   1.1279 |     41.590 |     1.0
    7 |   1.0918 |     39.391 |   1.1088 |     40.080 |     1.1
    8 |   1.0744 |     38.718 |   1.0962 |     40.327 |     1.3
    9 |   1.0628 |     38.448 |   1.0989 |     40.850 |     1.4
   10 |   1.0457 |     37.990 |   1.0747 |     39.125 |     1.6
   11 |   1.0351 |     37.885 |   1.0692 |     38.694 |     1.7
   12 |   1.0209 |     37.179 |   1.0602 |     38.447 |     1.9
   13 |   1.0116 |     36.980 |   1.0428 |     37.585 |     2.1
   14 |   1.0005 |     36.704 |   1.0369 |     36.907 |     2.2
   15 |   0.9886 |     35.866 |   1.0475 |     37.492 |     2.4
   16 |   0.9888 |     36.191 |   1.0219 |     36.907 |     2.5
   17 |   0.9768 |     35.573 |   1.0234 |     36.876 |     2.7
   18 |   0.9629 |     34.933 |   1.0147 |     37.061 |     2.9
   19 |   0.9542 |     34.702 |   1.0195 |     35.983 |     3.0
   20 |   0.9491 |     34.326 |   1.0183 |     36.784 |     3.2
   21 |   0.9556 |     34.862 |   1.0174 |     37.277 |     3.3
   22 |   0.9466 |     34.216 |   1.0044 |     36.661 |     3.5
   23 |   0.9376 |     33.962 |   1.0163 |     36.014 |     3.7
   24 |   0.9265 |     33.802 |   1.0051 |     35.551 |     3.8
   25 |   0.9378 |     33.951 |   1.0223 |     37.431 |     4.0
   26 |   0.9488 |     34.867 |   0.9946 |     35.613 |     4.1
   27 |   0.9201 |     33.576 |   0.9840 |     34.350 |     4.3
   28 |   0.9113 |     33.091 |   0.9950 |     34.935 |     4.5
   29 |   0.9022 |     32.743 |   0.9887 |     34.997 |     4.6
   30 |   0.8979 |     32.440 |   0.9979 |     36.014 |     4.8
   31 |   0.9037 |     32.771 |   1.0154 |     35.397 |     4.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 277,026

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7976 |     50.905 |   1.3421 |     43.746 |     0.1
    2 |   1.2731 |     42.927 |   1.2662 |     43.068 |     0.1
    3 |   1.1814 |     40.202 |   1.1866 |     40.080 |     0.2
    4 |   1.1106 |     37.968 |   1.1133 |     38.016 |     0.3
    5 |   1.0502 |     36.064 |   1.0849 |     37.400 |     0.4
    6 |   1.0076 |     34.624 |   1.0598 |     36.999 |     0.4
    7 |   0.9500 |     32.666 |   1.0837 |     37.061 |     0.5
    8 |   0.9152 |     31.436 |   1.0594 |     37.369 |     0.6
    9 |   0.8616 |     29.902 |   1.0248 |     35.059 |     0.6
   10 |   0.8226 |     28.258 |   1.0699 |     36.291 |     0.7
   11 |   0.7840 |     26.796 |   1.0548 |     34.658 |     0.8
   12 |   0.7375 |     25.334 |   1.0441 |     34.904 |     0.9
   13 |   0.7006 |     23.739 |   1.0274 |     33.980 |     0.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 779,810

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9041 |     50.265 |   1.4889 |     45.225 |     0.1
    2 |   1.4034 |     44.373 |   1.3592 |     43.685 |     0.2
    3 |   1.3107 |     42.773 |   1.2922 |     43.099 |     0.3
    4 |   1.2495 |     41.322 |   1.2675 |     42.052 |     0.4
    5 |   1.2026 |     40.130 |   1.2237 |     40.665 |     0.5
    6 |   1.1682 |     39.424 |   1.2071 |     41.528 |     0.6
    7 |   1.1392 |     38.707 |   1.1624 |     39.341 |     0.7
    8 |   1.1096 |     37.570 |   1.1801 |     40.111 |     0.8
    9 |   1.0866 |     36.671 |   1.1640 |     39.002 |     0.9
   10 |   1.0583 |     35.833 |   1.1382 |     38.540 |     1.0
   11 |   1.0317 |     34.977 |   1.1119 |     37.954 |     1.1
   12 |   1.0064 |     33.846 |   1.1115 |     37.677 |     1.1
   13 |   0.9843 |     32.986 |   1.0847 |     36.845 |     1.2
   14 |   0.9583 |     32.158 |   1.0919 |     36.691 |     1.3
   15 |   0.9344 |     31.237 |   1.0883 |     36.815 |     1.4
   16 |   0.9145 |     30.625 |   1.1060 |     38.016 |     1.5
   17 |   0.8857 |     29.438 |   1.0785 |     36.383 |     1.6
   18 |   0.8724 |     29.174 |   1.0869 |     36.537 |     1.7
   19 |   0.8464 |     28.164 |   1.0630 |     35.613 |     1.8
   20 |   0.8234 |     27.281 |   1.0656 |     34.874 |     1.9
   21 |   0.8046 |     26.829 |   1.0634 |     36.075 |     2.0
   22 |   0.7819 |     26.084 |   1.0552 |     34.843 |     2.1
   23 |   0.7571 |     24.931 |   1.0813 |     36.044 |     2.2
   24 |   0.7376 |     24.407 |   1.0781 |     35.551 |     2.3
   25 |   0.7223 |     24.092 |   1.0482 |     34.319 |     2.4
   26 |   0.6974 |     23.210 |   1.0858 |     35.274 |     2.5
   27 |   0.6786 |     22.277 |   1.0679 |     35.644 |     2.6
   28 |   0.6594 |     21.891 |   1.0557 |     34.227 |     2.7
   29 |   0.6417 |     21.036 |   1.1056 |     35.551 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,179,170

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9767 |     52.907 |   1.4672 |     45.040 |     0.2
    2 |   1.3962 |     44.318 |   1.3367 |     43.654 |     0.4
    3 |   1.3114 |     43.203 |   1.2919 |     42.637 |     0.5
    4 |   1.2511 |     41.267 |   1.2732 |     43.099 |     0.7
    5 |   1.2074 |     40.527 |   1.2537 |     42.421 |     0.9
    6 |   1.1683 |     39.385 |   1.2090 |     40.604 |     1.1
    7 |   1.1310 |     38.790 |   1.1727 |     40.142 |     1.2
    8 |   1.1047 |     37.598 |   1.1625 |     39.341 |     1.4
    9 |   1.0755 |     36.588 |   1.1352 |     38.879 |     1.6
   10 |   1.0415 |     35.071 |   1.1485 |     38.571 |     1.8
   11 |   1.0142 |     34.040 |   1.1275 |     38.786 |     2.0
   12 |   0.9831 |     32.572 |   1.1564 |     39.125 |     2.1
   13 |   0.9594 |     32.020 |   1.1491 |     38.632 |     2.3
   14 |   0.9308 |     30.933 |   1.1217 |     37.184 |     2.5
   15 |   0.9013 |     30.227 |   1.1210 |     37.616 |     2.7
   16 |   0.8808 |     29.383 |   1.0616 |     35.613 |     2.9
   17 |   0.8480 |     28.015 |   1.1163 |     36.445 |     3.0
   18 |   0.8242 |     27.347 |   1.1049 |     36.414 |     3.2
   19 |   0.7985 |     26.349 |   1.0791 |     35.829 |     3.4
   20 |   0.7741 |     25.582 |   1.1177 |     36.044 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 582,434

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1343 |     53.349 |   1.5421 |     46.087 |     0.1
    2 |   1.4449 |     44.875 |   1.3911 |     44.054 |     0.2
    3 |   1.3483 |     43.336 |   1.3306 |     43.099 |     0.3
    4 |   1.2948 |     42.740 |   1.3024 |     44.116 |     0.4
    5 |   1.2552 |     41.487 |   1.2663 |     42.452 |     0.5
    6 |   1.2177 |     40.439 |   1.2339 |     41.128 |     0.6
    7 |   1.1857 |     39.876 |   1.2275 |     41.158 |     0.6
    8 |   1.1549 |     39.043 |   1.1928 |     39.556 |     0.7
    9 |   1.1267 |     38.199 |   1.1787 |     39.741 |     0.8
   10 |   1.1022 |     37.405 |   1.1492 |     38.571 |     0.9
   11 |   1.0757 |     36.301 |   1.1416 |     38.386 |     1.0
   12 |   1.0526 |     35.557 |   1.1408 |     38.601 |     1.1
   13 |   1.0276 |     34.492 |   1.1278 |     38.386 |     1.2
   14 |   1.0060 |     33.780 |   1.1105 |     37.800 |     1.3
   15 |   0.9819 |     33.057 |   1.1103 |     37.831 |     1.4
   16 |   0.9615 |     32.224 |   1.0975 |     37.061 |     1.5
   17 |   0.9455 |     31.298 |   1.0884 |     36.753 |     1.6
   18 |   0.9185 |     30.547 |   1.0900 |     36.661 |     1.7
   19 |   0.9026 |     29.951 |   1.0689 |     35.367 |     1.8
   20 |   0.8846 |     29.510 |   1.0633 |     35.921 |     1.8
   21 |   0.8709 |     28.903 |   1.0857 |     36.876 |     1.9
   22 |   0.8489 |     28.059 |   1.0661 |     35.397 |     2.0
   23 |   0.8312 |     27.458 |   1.0770 |     35.367 |     2.1
   24 |   0.8138 |     26.945 |   1.0817 |     36.075 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 235,042

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6837 |     48.604 |   1.3149 |     43.654 |     0.1
    2 |   1.2638 |     43.010 |   1.2326 |     42.113 |     0.1
    3 |   1.1859 |     40.583 |   1.1840 |     41.035 |     0.2
    4 |   1.1225 |     38.707 |   1.1519 |     39.649 |     0.3
    5 |   1.0808 |     37.079 |   1.1156 |     38.386 |     0.3
    6 |   1.0307 |     35.535 |   1.0635 |     36.476 |     0.4
    7 |   0.9832 |     33.775 |   1.0572 |     35.644 |     0.4
    8 |   0.9451 |     32.368 |   1.0611 |     36.075 |     0.5
    9 |   0.9024 |     30.768 |   1.0617 |     36.352 |     0.6
   10 |   0.8628 |     29.538 |   1.0482 |     34.596 |     0.6
   11 |   0.8176 |     27.971 |   1.0274 |     34.288 |     0.7
   12 |   0.7875 |     26.796 |   1.0343 |     34.196 |     0.8
   13 |   0.7398 |     25.450 |   1.0133 |     32.717 |     0.8
   14 |   0.6994 |     24.048 |   1.0494 |     34.134 |     0.9
   15 |   0.6651 |     22.741 |   1.0687 |     34.720 |     1.0
   16 |   0.6360 |     21.626 |   1.0384 |     32.471 |     1.0
   17 |   0.5926 |     20.164 |   1.1261 |     34.781 |     1.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 648,226

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2085 |     55.936 |   1.5752 |     45.656 |     0.1
    2 |   1.5507 |     46.088 |   1.4183 |     45.194 |     0.2
    3 |   1.4297 |     45.189 |   1.3660 |     45.718 |     0.2
    4 |   1.3641 |     44.295 |   1.3176 |     43.931 |     0.3
    5 |   1.3206 |     43.137 |   1.2891 |     43.685 |     0.4
    6 |   1.2889 |     42.745 |   1.2729 |     43.376 |     0.5
    7 |   1.2572 |     41.967 |   1.2496 |     42.298 |     0.6
    8 |   1.2348 |     41.653 |   1.2462 |     42.452 |     0.6
    9 |   1.2111 |     41.145 |   1.2127 |     40.943 |     0.7
   10 |   1.1942 |     40.616 |   1.2455 |     42.391 |     0.8
   11 |   1.1792 |     40.252 |   1.2299 |     42.206 |     0.9
   12 |   1.1621 |     39.645 |   1.1834 |     41.035 |     1.0
   13 |   1.1422 |     39.247 |   1.1780 |     40.327 |     1.0
   14 |   1.1297 |     39.049 |   1.1679 |     40.203 |     1.1
   15 |   1.1164 |     38.492 |   1.1483 |     40.173 |     1.2
   16 |   1.1024 |     37.874 |   1.1657 |     39.803 |     1.3
   17 |   1.0921 |     37.620 |   1.1462 |     39.680 |     1.4
   18 |   1.0770 |     37.294 |   1.1650 |     40.111 |     1.4
   19 |   1.0638 |     36.489 |   1.1164 |     38.417 |     1.5
   20 |   1.0485 |     35.998 |   1.1565 |     38.971 |     1.6
   21 |   1.0369 |     35.413 |   1.1451 |     39.217 |     1.7
   22 |   1.0289 |     35.049 |   1.1228 |     37.893 |     1.8
   23 |   1.0136 |     34.624 |   1.1525 |     39.156 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 425,634

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2154 |     55.368 |   1.6718 |     45.687 |     0.1
    2 |   1.5624 |     45.570 |   1.4956 |     44.640 |     0.1
    3 |   1.4494 |     44.461 |   1.4255 |     44.331 |     0.2
    4 |   1.3861 |     43.573 |   1.3760 |     43.623 |     0.3
    5 |   1.3425 |     43.214 |   1.3427 |     44.270 |     0.4
    6 |   1.2993 |     42.210 |   1.3196 |     43.592 |     0.4
    7 |   1.2654 |     41.476 |   1.3014 |     42.884 |     0.5
    8 |   1.2353 |     40.698 |   1.2669 |     42.452 |     0.6
    9 |   1.2106 |     40.207 |   1.2625 |     41.898 |     0.7
   10 |   1.1882 |     39.689 |   1.2320 |     41.004 |     0.7
   11 |   1.1644 |     39.253 |   1.2112 |     40.789 |     0.8
   12 |   1.1459 |     38.696 |   1.2082 |     40.696 |     0.9
   13 |   1.1227 |     37.774 |   1.1933 |     39.895 |     1.0
   14 |   1.1041 |     37.493 |   1.1914 |     40.234 |     1.0
   15 |   1.0813 |     36.572 |   1.1640 |     39.063 |     1.1
   16 |   1.0686 |     35.954 |   1.1833 |     40.203 |     1.2
   17 |   1.0486 |     35.253 |   1.1501 |     38.232 |     1.3
   18 |   1.0301 |     34.624 |   1.1575 |     39.033 |     1.3
   19 |   1.0148 |     34.183 |   1.1306 |     37.800 |     1.4
   20 |   0.9978 |     33.620 |   1.1189 |     37.277 |     1.5
   21 |   0.9847 |     33.002 |   1.1058 |     36.999 |     1.6
   22 |   0.9650 |     32.202 |   1.1146 |     37.338 |     1.6
   23 |   0.9505 |     31.513 |   1.1031 |     36.753 |     1.7
   24 |   0.9366 |     31.248 |   1.1032 |     36.815 |     1.8
   25 |   0.9193 |     30.453 |   1.1257 |     37.431 |     1.9
   26 |   0.8988 |     29.825 |   1.0707 |     35.367 |     1.9
   27 |   0.8849 |     29.323 |   1.0736 |     34.781 |     2.0
   28 |   0.8749 |     29.058 |   1.0923 |     36.075 |     2.1
   29 |   0.8526 |     28.390 |   1.1040 |     36.229 |     2.2
   30 |   0.8442 |     28.109 |   1.0847 |     35.151 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 748,706

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5107 |     60.135 |   1.7584 |     45.687 |     0.1
    2 |   1.7044 |     46.602 |   1.4905 |     45.625 |     0.3
    3 |   1.5150 |     46.111 |   1.4058 |     45.656 |     0.4
    4 |   1.4444 |     45.906 |   1.3820 |     45.071 |     0.5
    5 |   1.4028 |     45.597 |   1.3599 |     44.886 |     0.7
    6 |   1.3730 |     45.018 |   1.3375 |     44.948 |     0.8
    7 |   1.3486 |     44.731 |   1.3299 |     44.393 |     0.9
    8 |   1.3258 |     43.920 |   1.3101 |     44.023 |     1.1
    9 |   1.3051 |     43.490 |   1.3024 |     43.962 |     1.2
   10 |   1.2859 |     43.076 |   1.2848 |     43.407 |     1.3
   11 |   1.2688 |     42.431 |   1.2690 |     44.085 |     1.5
   12 |   1.2488 |     41.719 |   1.2515 |     43.346 |     1.6
   13 |   1.2332 |     41.653 |   1.2555 |     43.130 |     1.7
   14 |   1.2176 |     41.156 |   1.2478 |     42.822 |     1.9
   15 |   1.2044 |     40.638 |   1.2318 |     42.545 |     2.0
   16 |   1.1935 |     40.367 |   1.2161 |     41.405 |     2.1
   17 |   1.1760 |     39.650 |   1.2120 |     41.898 |     2.3
   18 |   1.1621 |     39.110 |   1.2180 |     42.083 |     2.4
   19 |   1.1525 |     39.115 |   1.2112 |     41.405 |     2.5
   20 |   1.1375 |     38.210 |   1.2074 |     41.097 |     2.7
   21 |   1.1203 |     38.045 |   1.2136 |     41.343 |     2.8
   22 |   1.1136 |     37.835 |   1.1929 |     40.357 |     2.9
   23 |   1.0960 |     37.074 |   1.2216 |     40.912 |     3.1
   24 |   1.0867 |     36.643 |   1.1967 |     39.988 |     3.2
   25 |   1.0762 |     36.472 |   1.2204 |     40.850 |     3.3
   26 |   1.0623 |     36.324 |   1.2142 |     40.635 |     3.5
   27 |   1.0563 |     35.899 |   1.1862 |     39.864 |     3.6
   28 |   1.0390 |     35.535 |   1.2108 |     40.327 |     3.7
   29 |   1.0375 |     35.198 |   1.2190 |     39.957 |     3.9
   30 |   1.0232 |     34.878 |   1.2092 |     39.988 |     4.0
   31 |   1.0120 |     34.586 |   1.1967 |     39.895 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 881,314

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1196 |     53.878 |   1.5433 |     44.855 |     0.1
    2 |   1.4330 |     44.086 |   1.3962 |     46.057 |     0.2
    3 |   1.3153 |     42.315 |   1.3498 |     44.578 |     0.3
    4 |   1.2580 |     41.212 |   1.2912 |     42.545 |     0.4
    5 |   1.2104 |     40.301 |   1.2590 |     42.144 |     0.6
    6 |   1.1718 |     39.374 |   1.2415 |     41.867 |     0.7
    7 |   1.1370 |     38.089 |   1.1970 |     40.450 |     0.8
    8 |   1.1106 |     37.410 |   1.1764 |     39.957 |     0.9
    9 |   1.0802 |     36.434 |   1.1411 |     38.725 |     1.0
   10 |   1.0449 |     35.027 |   1.1531 |     39.464 |     1.1
   11 |   1.0203 |     34.095 |   1.1489 |     39.248 |     1.2
   12 |   0.9883 |     32.848 |   1.1558 |     38.786 |     1.3
   13 |   0.9600 |     32.368 |   1.1305 |     37.123 |     1.4
   14 |   0.9352 |     31.187 |   1.1197 |     36.876 |     1.6
   15 |   0.9124 |     30.156 |   1.0919 |     36.075 |     1.7
   16 |   0.8865 |     29.372 |   1.0961 |     36.260 |     1.8
   17 |   0.8600 |     28.567 |   1.0735 |     35.274 |     1.9
   18 |   0.8369 |     27.678 |   1.0827 |     34.812 |     2.0
   19 |   0.8164 |     27.193 |   1.1109 |     36.198 |     2.1
   20 |   0.7925 |     26.205 |   1.0700 |     34.627 |     2.2
   21 |   0.7682 |     25.389 |   1.0543 |     34.535 |     2.3
   22 |   0.7451 |     24.550 |   1.1038 |     35.521 |     2.5
   23 |   0.7206 |     23.447 |   1.1199 |     35.644 |     2.6
   24 |   0.7071 |     23.199 |   1.0617 |     33.949 |     2.7
   25 |   0.6786 |     22.134 |   1.0929 |     34.658 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,013,282

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6464 |     49.531 |   1.3457 |     45.102 |     0.1
    2 |   1.3527 |     45.857 |   1.3019 |     45.132 |     0.3
    3 |   1.3043 |     44.775 |   1.2493 |     43.346 |     0.4
    4 |   1.2771 |     44.384 |   1.2390 |     43.161 |     0.6
    5 |   1.2487 |     43.953 |   1.2295 |     43.222 |     0.7
    6 |   1.2360 |     43.722 |   1.2032 |     43.007 |     0.9
    7 |   1.2156 |     43.142 |   1.1870 |     42.052 |     1.0
    8 |   1.1985 |     42.243 |   1.1654 |     41.343 |     1.2
    9 |   1.1816 |     41.918 |   1.1482 |     40.912 |     1.3
   10 |   1.1684 |     41.349 |   1.1287 |     39.464 |     1.4
   11 |   1.1602 |     41.349 |   1.1252 |     40.819 |     1.6
   12 |   1.1519 |     41.184 |   1.1275 |     39.988 |     1.7
   13 |   1.1433 |     40.969 |   1.1155 |     40.481 |     1.9
   14 |   1.1383 |     40.610 |   1.1125 |     40.049 |     2.0
   15 |   1.1307 |     40.180 |   1.0958 |     39.710 |     2.2
   16 |   1.1222 |     40.252 |   1.1085 |     39.310 |     2.3
   17 |   1.1116 |     40.031 |   1.1163 |     40.327 |     2.5
   18 |   1.1118 |     39.794 |   1.0937 |     39.187 |     2.6
   19 |   1.1041 |     39.419 |   1.0953 |     39.864 |     2.7
   20 |   1.0997 |     39.402 |   1.0815 |     39.217 |     2.9
   21 |   1.0950 |     39.435 |   1.0915 |     41.004 |     3.0
   22 |   1.0874 |     39.115 |   1.0833 |     40.018 |     3.2
   23 |   1.0845 |     39.407 |   1.0720 |     39.002 |     3.3
   24 |   1.0774 |     39.143 |   1.0719 |     39.649 |     3.5
   25 |   1.0776 |     38.961 |   1.0727 |     39.094 |     3.6
   26 |   1.0753 |     38.928 |   1.0935 |     40.419 |     3.8
   27 |   1.0820 |     39.281 |   1.0737 |     39.094 |     3.9
   28 |   1.0813 |     38.867 |   1.1020 |     40.912 |     4.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 243,490

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9531 |     74.799 |   2.3048 |     50.462 |     0.1
    2 |   2.2325 |     51.495 |   1.8047 |     48.829 |     0.2
    3 |   1.8490 |     47.821 |   1.5949 |     47.813 |     0.3
    4 |   1.6645 |     46.469 |   1.5087 |     45.379 |     0.4
    5 |   1.5711 |     46.149 |   1.4638 |     46.149 |     0.5
    6 |   1.5156 |     46.044 |   1.4267 |     45.132 |     0.6
    7 |   1.4790 |     46.022 |   1.4037 |     45.502 |     0.7
    8 |   1.4473 |     45.967 |   1.3862 |     46.057 |     0.8
    9 |   1.4263 |     45.647 |   1.3695 |     44.208 |     0.9
   10 |   1.4078 |     45.609 |   1.3583 |     44.085 |     1.0
   11 |   1.3923 |     45.035 |   1.3525 |     44.732 |     1.1
   12 |   1.3780 |     44.908 |   1.3441 |     44.609 |     1.2
   13 |   1.3669 |     44.665 |   1.3307 |     44.239 |     1.3
   14 |   1.3549 |     44.809 |   1.3278 |     44.455 |     1.4
   15 |   1.3402 |     44.406 |   1.3199 |     44.177 |     1.5
   16 |   1.3339 |     44.439 |   1.3056 |     43.592 |     1.6
   17 |   1.3237 |     44.163 |   1.3035 |     44.886 |     1.7
   18 |   1.3096 |     43.970 |   1.3039 |     44.886 |     1.8
   19 |   1.3069 |     43.904 |   1.2990 |     44.547 |     1.9
   20 |   1.2983 |     43.931 |   1.2985 |     44.732 |     2.0
   21 |   1.2845 |     43.176 |   1.2909 |     44.486 |     2.1
   22 |   1.2826 |     43.656 |   1.2859 |     43.962 |     2.2
   23 |   1.2756 |     43.098 |   1.2917 |     44.331 |     2.3
   24 |   1.2675 |     42.949 |   1.2879 |     44.239 |     2.4
   25 |   1.2627 |     43.060 |   1.2903 |     44.331 |     2.5
   26 |   1.2550 |     42.817 |   1.2754 |     43.746 |     2.6
   27 |   1.2517 |     42.740 |   1.2804 |     43.685 |     2.7
   28 |   1.2415 |     42.514 |   1.2638 |     43.407 |     2.8
   29 |   1.2392 |     42.365 |   1.2525 |     42.976 |     2.9
   30 |   1.2341 |     42.260 |   1.2714 |     43.500 |     3.0
   31 |   1.2303 |     41.929 |   1.2589 |     42.606 |     3.1
   32 |   1.2244 |     41.907 |   1.2197 |     41.436 |     3.2
   33 |   1.2209 |     41.840 |   1.2531 |     42.237 |     3.3
   34 |   1.2066 |     41.151 |   1.2343 |     41.590 |     3.4
   35 |   1.2015 |     41.173 |   1.2412 |     41.559 |     3.5
   36 |   1.2048 |     41.311 |   1.2298 |     41.744 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 814,114

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5755 |     48.339 |   1.3064 |     44.455 |     0.1
    2 |   1.2686 |     43.534 |   1.2064 |     41.343 |     0.2
    3 |   1.1961 |     41.322 |   1.1584 |     40.758 |     0.3
    4 |   1.1496 |     40.042 |   1.1562 |     41.128 |     0.4
    5 |   1.1085 |     38.608 |   1.1044 |     38.170 |     0.6
    6 |   1.0802 |     37.603 |   1.1048 |     39.372 |     0.7
    7 |   1.0390 |     35.684 |   1.0714 |     37.585 |     0.8
    8 |   1.0103 |     35.264 |   1.0567 |     36.969 |     0.9
    9 |   0.9754 |     34.006 |   1.0711 |     36.414 |     1.0
   10 |   0.9499 |     33.080 |   1.0559 |     36.599 |     1.1
   11 |   0.9201 |     31.877 |   1.0709 |     36.014 |     1.2
   12 |   0.8855 |     30.740 |   1.0414 |     34.812 |     1.3
   13 |   0.8498 |     29.477 |   1.0658 |     35.059 |     1.4
   14 |   0.8362 |     29.394 |   1.0674 |     34.874 |     1.6
   15 |   0.7936 |     27.414 |   1.0754 |     35.490 |     1.7
   16 |   0.7814 |     26.713 |   1.0661 |     34.535 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 226,082

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7412 |     49.255 |   1.3482 |     44.270 |     0.1
    2 |   1.3442 |     44.632 |   1.2821 |     44.116 |     0.2
    3 |   1.2825 |     43.187 |   1.2355 |     42.606 |     0.3
    4 |   1.2375 |     42.271 |   1.2135 |     40.789 |     0.3
    5 |   1.2010 |     41.454 |   1.1870 |     40.203 |     0.4
    6 |   1.1743 |     40.351 |   1.1778 |     39.895 |     0.5
    7 |   1.1496 |     39.667 |   1.1461 |     40.080 |     0.6
    8 |   1.1180 |     38.872 |   1.1523 |     38.786 |     0.7
    9 |   1.1031 |     37.995 |   1.1214 |     37.954 |     0.8
   10 |   1.0710 |     37.118 |   1.0999 |     37.431 |     0.9
   11 |   1.0531 |     36.213 |   1.0758 |     36.938 |     0.9
   12 |   1.0288 |     35.242 |   1.0814 |     36.753 |     1.0
   13 |   1.0034 |     34.542 |   1.1044 |     37.184 |     1.1
   14 |   0.9897 |     34.095 |   1.1102 |     36.876 |     1.2
   15 |   0.9727 |     33.206 |   1.0854 |     36.014 |     1.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,044,770

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5621 |     47.870 |   1.3281 |     44.578 |     0.1
    2 |   1.3306 |     45.366 |   1.2940 |     44.301 |     0.3
    3 |   1.2842 |     44.693 |   1.2511 |     44.023 |     0.4
    4 |   1.2586 |     44.373 |   1.2132 |     43.222 |     0.6
    5 |   1.2307 |     43.832 |   1.1886 |     41.620 |     0.7
    6 |   1.2146 |     43.374 |   1.1787 |     43.407 |     0.9
    7 |   1.2035 |     42.999 |   1.1765 |     43.592 |     1.0
    8 |   1.1908 |     42.861 |   1.1657 |     42.914 |     1.1
    9 |   1.1768 |     42.315 |   1.1506 |     41.128 |     1.3
   10 |   1.1720 |     42.552 |   1.1427 |     41.559 |     1.4
   11 |   1.1655 |     42.133 |   1.1547 |     41.651 |     1.6
   12 |   1.1618 |     42.133 |   1.1357 |     41.990 |     1.7
   13 |   1.1508 |     42.023 |   1.1270 |     42.021 |     1.9
   14 |   1.1461 |     41.614 |   1.1269 |     41.559 |     2.0
   15 |   1.1435 |     41.851 |   1.1225 |     41.497 |     2.1
   16 |   1.1414 |     41.885 |   1.1311 |     41.528 |     2.3
   17 |   1.1404 |     41.901 |   1.1188 |     41.220 |     2.4
   18 |   1.1333 |     41.223 |   1.1047 |     40.850 |     2.6
   19 |   1.1270 |     41.581 |   1.1028 |     40.727 |     2.7
   20 |   1.1256 |     41.151 |   1.1213 |     41.929 |     2.9
   21 |   1.1263 |     41.515 |   1.1152 |     41.466 |     3.0
   22 |   1.1220 |     41.554 |   1.1136 |     41.158 |     3.1
   23 |   1.1205 |     41.438 |   1.1055 |     41.774 |     3.3
   24 |   1.1163 |     41.057 |   1.1024 |     41.436 |     3.4
   25 |   1.1124 |     40.798 |   1.0988 |     40.542 |     3.6
   26 |   1.1047 |     40.555 |   1.1384 |     42.699 |     3.7
   27 |   1.0942 |     39.744 |   1.1626 |     42.853 |     3.9
   28 |   1.0935 |     39.612 |   1.1375 |     42.421 |     4.0
   29 |   1.0860 |     39.270 |   1.1800 |     42.668 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 393,506

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5749 |     60.074 |   1.8858 |     47.412 |     0.1
    2 |   1.8380 |     46.762 |   1.6327 |     47.104 |     0.2
    3 |   1.6285 |     45.984 |   1.5193 |     45.502 |     0.4
    4 |   1.5341 |     45.769 |   1.4581 |     45.287 |     0.5
    5 |   1.4737 |     45.465 |   1.4263 |     46.827 |     0.6
    6 |   1.4307 |     45.636 |   1.3901 |     45.441 |     0.7
    7 |   1.3969 |     45.013 |   1.3562 |     44.886 |     0.8
    8 |   1.3751 |     44.715 |   1.3458 |     44.732 |     0.9
    9 |   1.3481 |     43.898 |   1.3348 |     45.009 |     1.1
   10 |   1.3341 |     43.953 |   1.3088 |     43.808 |     1.2
   11 |   1.3089 |     43.325 |   1.3028 |     43.808 |     1.3
   12 |   1.2940 |     42.856 |   1.2892 |     43.038 |     1.4
   13 |   1.2796 |     42.822 |   1.2875 |     43.315 |     1.5
   14 |   1.2677 |     42.320 |   1.2650 |     42.853 |     1.6
   15 |   1.2504 |     42.006 |   1.2425 |     41.898 |     1.8
   16 |   1.2370 |     41.824 |   1.2470 |     42.083 |     1.9
   17 |   1.2245 |     41.482 |   1.2207 |     40.943 |     2.0
   18 |   1.2153 |     41.052 |   1.2104 |     40.450 |     2.1
   19 |   1.2004 |     40.787 |   1.2261 |     41.312 |     2.2
   20 |   1.1924 |     40.847 |   1.2160 |     40.943 |     2.3
   21 |   1.1808 |     40.114 |   1.2128 |     41.128 |     2.5
   22 |   1.1758 |     39.976 |   1.2070 |     41.651 |     2.6
   23 |   1.1653 |     39.573 |   1.1957 |     40.850 |     2.7
   24 |   1.1569 |     39.623 |   1.1897 |     40.604 |     2.8
   25 |   1.1489 |     39.303 |   1.1812 |     40.203 |     2.9
   26 |   1.1373 |     38.696 |   1.1704 |     39.957 |     3.0
   27 |   1.1340 |     38.812 |   1.1827 |     40.357 |     3.1
   28 |   1.1230 |     38.083 |   1.1539 |     39.772 |     3.3
   29 |   1.1185 |     38.310 |   1.1624 |     39.895 |     3.4
   30 |   1.1113 |     37.780 |   1.1556 |     39.680 |     3.5
   31 |   1.1003 |     37.278 |   1.1465 |     39.526 |     3.6
   32 |   1.0974 |     37.747 |   1.1484 |     39.402 |     3.7
   33 |   1.0901 |     37.454 |   1.1382 |     39.464 |     3.8
   34 |   1.0801 |     36.941 |   1.1406 |     39.125 |     4.0
   35 |   1.0785 |     37.035 |   1.1576 |     39.094 |     4.1
   36 |   1.0727 |     36.610 |   1.1294 |     38.447 |     4.2
   37 |   1.0651 |     36.671 |   1.1229 |     38.663 |     4.3
   38 |   1.0577 |     36.020 |   1.1252 |     38.447 |     4.4
   39 |   1.0530 |     36.059 |   1.1039 |     37.770 |     4.5
   40 |   1.0463 |     35.496 |   1.1220 |     37.985 |     4.7
   41 |   1.0427 |     35.380 |   1.1137 |     38.355 |     4.8
   42 |   1.0325 |     35.463 |   1.1278 |     38.324 |     4.9
   43 |   1.0291 |     35.099 |   1.1015 |     37.770 |     5.0
   44 |   1.0206 |     35.137 |   1.1166 |     37.677 |     5.1
   45 |   1.0178 |     34.685 |   1.1204 |     38.170 |     5.2
   46 |   1.0155 |     34.790 |   1.1004 |     37.030 |     5.4
   47 |   1.0048 |     34.415 |   1.1013 |     36.876 |     5.5
   48 |   1.0052 |     34.354 |   1.0899 |     36.999 |     5.6
   49 |   0.9986 |     33.907 |   1.0957 |     37.246 |     5.7
   50 |   0.9956 |     34.001 |   1.0985 |     37.092 |     5.8
   51 |   0.9871 |     33.720 |   1.1115 |     37.092 |     5.9
   52 |   0.9792 |     33.091 |   1.1156 |     37.554 |     6.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 898,146

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6640 |     49.652 |   1.3513 |     45.625 |     0.2
    2 |   1.3582 |     45.796 |   1.3068 |     45.225 |     0.4
    3 |   1.3035 |     45.151 |   1.2513 |     44.424 |     0.5
    4 |   1.2668 |     44.489 |   1.2377 |     44.054 |     0.7
    5 |   1.2331 |     43.644 |   1.2112 |     42.545 |     0.9
    6 |   1.2150 |     43.198 |   1.1813 |     41.066 |     1.1
    7 |   1.2048 |     43.032 |   1.1834 |     41.312 |     1.3
    8 |   1.1866 |     42.238 |   1.1538 |     41.836 |     1.4
    9 |   1.1685 |     41.763 |   1.1669 |     41.590 |     1.6
   10 |   1.1580 |     41.322 |   1.1335 |     41.004 |     1.8
   11 |   1.1457 |     41.040 |   1.1561 |     39.618 |     2.0
   12 |   1.1442 |     40.996 |   1.1279 |     40.173 |     2.2
   13 |   1.1312 |     40.665 |   1.1286 |     40.604 |     2.3
   14 |   1.1222 |     40.191 |   1.1280 |     40.481 |     2.5
   15 |   1.1167 |     40.218 |   1.1115 |     39.372 |     2.7
   16 |   1.1026 |     39.821 |   1.1169 |     39.618 |     2.9
   17 |   1.1018 |     40.047 |   1.1075 |     39.926 |     3.1
   18 |   1.0923 |     39.303 |   1.1003 |     41.035 |     3.2
   19 |   1.0929 |     39.761 |   1.0999 |     39.495 |     3.4
   20 |   1.0838 |     39.110 |   1.0845 |     38.786 |     3.6
   21 |   1.0762 |     38.723 |   1.0825 |     39.279 |     3.8
   22 |   1.0703 |     38.745 |   1.0766 |     39.402 |     4.0
   23 |   1.0693 |     38.624 |   1.0734 |     38.909 |     4.1
   24 |   1.0586 |     38.558 |   1.0747 |     38.632 |     4.3
   25 |   1.0554 |     37.995 |   1.0738 |     38.293 |     4.5
   26 |   1.0523 |     37.962 |   1.0852 |     38.848 |     4.7
   27 |   1.0442 |     37.813 |   1.0642 |     38.909 |     4.9
   28 |   1.0336 |     37.350 |   1.0628 |     38.201 |     5.0
   29 |   1.0312 |     37.261 |   1.0626 |     38.170 |     5.2
   30 |   1.0261 |     37.090 |   1.0262 |     36.876 |     5.4
   31 |   1.0140 |     36.450 |   1.0508 |     37.893 |     5.6
   32 |   1.0155 |     36.632 |   1.0536 |     38.108 |     5.8
   33 |   1.0091 |     36.373 |   1.0506 |     37.800 |     5.9
   34 |   1.0034 |     36.186 |   1.0486 |     37.954 |     6.1
   35 |   1.0010 |     36.324 |   1.0230 |     36.476 |     6.3
   36 |   0.9987 |     35.695 |   1.0354 |     37.092 |     6.5
   37 |   0.9922 |     35.755 |   1.0466 |     36.969 |     6.7
   38 |   0.9895 |     35.557 |   1.0380 |     36.938 |     6.9
   39 |   0.9878 |     35.540 |   1.0297 |     36.599 |     7.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,044,770

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5330 |     47.738 |   1.3073 |     45.102 |     0.2
    2 |   1.3033 |     45.068 |   1.2646 |     45.687 |     0.4
    3 |   1.2614 |     44.224 |   1.2171 |     43.007 |     0.5
    4 |   1.2294 |     43.821 |   1.1930 |     41.836 |     0.7
    5 |   1.2157 |     43.198 |   1.1816 |     42.606 |     0.9
    6 |   1.1930 |     43.016 |   1.1638 |     42.329 |     1.1
    7 |   1.1837 |     42.839 |   1.1532 |     42.083 |     1.3
    8 |   1.1736 |     42.359 |   1.1513 |     43.068 |     1.4
    9 |   1.1633 |     42.127 |   1.1564 |     41.990 |     1.6
   10 |   1.1546 |     42.061 |   1.1338 |     40.881 |     1.8
   11 |   1.1477 |     42.067 |   1.1355 |     41.682 |     2.0
   12 |   1.1419 |     41.691 |   1.1269 |     41.590 |     2.2
   13 |   1.1330 |     41.929 |   1.1390 |     41.805 |     2.3
   14 |   1.1342 |     41.918 |   1.1185 |     41.251 |     2.5
   15 |   1.1268 |     41.372 |   1.1212 |     41.528 |     2.7
   16 |   1.1229 |     41.372 |   1.1211 |     42.514 |     2.9
   17 |   1.1171 |     41.261 |   1.1176 |     41.805 |     3.1
   18 |   1.1222 |     41.239 |   1.1093 |     39.926 |     3.2
   19 |   1.1136 |     40.897 |   1.1103 |     40.727 |     3.4
   20 |   1.1137 |     40.781 |   1.1060 |     41.312 |     3.6
   21 |   1.1100 |     41.013 |   1.0983 |     40.142 |     3.8
   22 |   1.1086 |     41.063 |   1.1203 |     40.912 |     4.0
   23 |   1.1087 |     40.792 |   1.1059 |     41.097 |     4.1
   24 |   1.1025 |     40.798 |   1.1031 |     40.943 |     4.3
   25 |   1.0982 |     40.401 |   1.1070 |     41.990 |     4.5
   26 |   1.0914 |     40.086 |   1.0951 |     39.710 |     4.7
   27 |   1.0852 |     39.838 |   1.1015 |     40.296 |     4.9
   28 |   1.0790 |     39.457 |   1.0710 |     38.971 |     5.0
   29 |   1.0730 |     39.214 |   1.1081 |     40.789 |     5.2
   30 |   1.0673 |     38.944 |   1.1220 |     42.452 |     5.4
   31 |   1.0615 |     38.905 |   1.0711 |     39.125 |     5.6
   32 |   1.0581 |     38.536 |   1.1132 |     40.542 |     5.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 525,602

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6846 |     48.461 |   1.3492 |     45.163 |     0.1
    2 |   1.3196 |     44.786 |   1.2574 |     44.331 |     0.2
    3 |   1.2558 |     43.705 |   1.2092 |     40.758 |     0.4
    4 |   1.2064 |     42.365 |   1.1800 |     41.374 |     0.5
    5 |   1.1757 |     41.162 |   1.1399 |     39.957 |     0.6
    6 |   1.1498 |     40.401 |   1.1234 |     39.772 |     0.7
    7 |   1.1334 |     40.070 |   1.1094 |     39.402 |     0.8
    8 |   1.1102 |     39.512 |   1.1218 |     39.002 |     1.0
    9 |   1.0870 |     38.475 |   1.0948 |     38.879 |     1.1
   10 |   1.0778 |     38.117 |   1.1012 |     38.817 |     1.2
   11 |   1.0632 |     37.603 |   1.0714 |     37.739 |     1.3
   12 |   1.0519 |     37.190 |   1.0464 |     36.938 |     1.4
   13 |   1.0355 |     36.285 |   1.0319 |     36.106 |     1.6
   14 |   1.0178 |     35.673 |   1.0294 |     35.397 |     1.7
   15 |   1.0064 |     35.341 |   1.0221 |     36.198 |     1.8
   16 |   0.9933 |     35.424 |   1.0012 |     35.490 |     1.9
   17 |   0.9798 |     34.475 |   1.0513 |     37.585 |     2.0
   18 |   0.9712 |     34.205 |   1.0106 |     34.966 |     2.2
   19 |   0.9469 |     33.217 |   0.9764 |     34.104 |     2.3
   20 |   0.9457 |     33.234 |   0.9837 |     34.966 |     2.4
   21 |   0.9308 |     32.820 |   0.9811 |     34.473 |     2.5
   22 |   0.9173 |     32.583 |   0.9683 |     33.980 |     2.7
   23 |   0.9020 |     31.590 |   0.9823 |     34.011 |     2.8
   24 |   0.8914 |     31.176 |   0.9893 |     34.781 |     2.9
   25 |   0.8786 |     30.972 |   0.9610 |     32.933 |     3.0
   26 |   0.8600 |     30.200 |   0.9831 |     34.134 |     3.1
   27 |   0.8507 |     29.863 |   0.9648 |     32.840 |     3.3
   28 |   0.8319 |     29.289 |   0.9717 |     32.532 |     3.4
   29 |   0.8217 |     28.909 |   1.0395 |     33.333 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 243,490

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8691 |     66.600 |   2.2298 |     48.799 |     0.1
    2 |   2.0496 |     47.495 |   1.7264 |     46.488 |     0.3
    3 |   1.7084 |     46.094 |   1.5506 |     46.211 |     0.4
    4 |   1.5666 |     45.746 |   1.4727 |     46.026 |     0.6
    5 |   1.4921 |     45.564 |   1.4256 |     45.964 |     0.7
    6 |   1.4425 |     45.239 |   1.3895 |     45.502 |     0.9
    7 |   1.4065 |     44.792 |   1.3610 |     45.379 |     1.0
    8 |   1.3775 |     44.047 |   1.3416 |     44.763 |     1.2
    9 |   1.3562 |     43.931 |   1.3169 |     43.192 |     1.3
   10 |   1.3348 |     43.369 |   1.3054 |     43.192 |     1.5
   11 |   1.3140 |     42.867 |   1.2886 |     42.668 |     1.6
   12 |   1.3008 |     42.889 |   1.2788 |     43.161 |     1.7
   13 |   1.2815 |     42.370 |   1.2667 |     42.329 |     1.9
   14 |   1.2694 |     42.061 |   1.2542 |     41.959 |     2.0
   15 |   1.2561 |     42.116 |   1.2500 |     42.514 |     2.2
   16 |   1.2392 |     41.532 |   1.2366 |     41.343 |     2.3
   17 |   1.2262 |     40.974 |   1.2350 |     41.374 |     2.5
   18 |   1.2182 |     40.776 |   1.2269 |     41.251 |     2.6
   19 |   1.2072 |     40.577 |   1.2146 |     41.128 |     2.8
   20 |   1.1953 |     40.218 |   1.2013 |     41.035 |     2.9
   21 |   1.1895 |     40.147 |   1.1924 |     40.173 |     3.0
   22 |   1.1782 |     39.794 |   1.1942 |     40.881 |     3.2
   23 |   1.1707 |     39.821 |   1.1942 |     40.419 |     3.3
   24 |   1.1656 |     39.545 |   1.1876 |     40.296 |     3.5
   25 |   1.1567 |     39.518 |   1.1809 |     40.357 |     3.6
   26 |   1.1484 |     39.203 |   1.1812 |     40.727 |     3.8
   27 |   1.1405 |     38.652 |   1.1788 |     39.864 |     3.9
   28 |   1.1385 |     39.093 |   1.1695 |     40.542 |     4.1
   29 |   1.1332 |     38.585 |   1.1837 |     40.819 |     4.2
   30 |   1.1221 |     38.337 |   1.1672 |     39.556 |     4.4
   31 |   1.1161 |     38.232 |   1.1487 |     38.755 |     4.5
   32 |   1.1087 |     37.681 |   1.1603 |     39.279 |     4.6
   33 |   1.1036 |     37.868 |   1.1634 |     39.556 |     4.8
   34 |   1.0967 |     37.471 |   1.1598 |     38.879 |     4.9
   35 |   1.0887 |     37.410 |   1.1504 |     39.187 |     5.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 285,474

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8550 |     68.631 |   2.1894 |     49.538 |     0.1
    2 |   2.1304 |     49.553 |   1.7188 |     46.149 |     0.2
    3 |   1.7683 |     46.541 |   1.5665 |     45.995 |     0.3
    4 |   1.6181 |     46.039 |   1.4961 |     45.471 |     0.4
    5 |   1.5447 |     46.111 |   1.4558 |     45.225 |     0.5
    6 |   1.5005 |     45.940 |   1.4311 |     45.379 |     0.6
    7 |   1.4696 |     46.077 |   1.4113 |     44.578 |     0.7
    8 |   1.4413 |     45.597 |   1.3949 |     45.009 |     0.9
    9 |   1.4256 |     45.708 |   1.3843 |     45.625 |     1.0
   10 |   1.4076 |     45.597 |   1.3705 |     45.471 |     1.1
   11 |   1.3900 |     45.520 |   1.3631 |     45.471 |     1.2
   12 |   1.3724 |     45.024 |   1.3473 |     45.564 |     1.3
   13 |   1.3605 |     44.930 |   1.3303 |     44.763 |     1.4
   14 |   1.3487 |     44.566 |   1.3340 |     45.132 |     1.5
   15 |   1.3357 |     44.417 |   1.3098 |     43.931 |     1.6
   16 |   1.3259 |     44.318 |   1.3104 |     44.301 |     1.7
   17 |   1.3140 |     44.042 |   1.3137 |     44.763 |     1.8
   18 |   1.3052 |     43.887 |   1.2967 |     44.393 |     1.9
   19 |   1.3007 |     43.661 |   1.2923 |     43.376 |     2.0
   20 |   1.2865 |     43.291 |   1.2931 |     43.592 |     2.1
   21 |   1.2795 |     43.087 |   1.3007 |     43.376 |     2.2
   22 |   1.2730 |     42.955 |   1.2945 |     44.116 |     2.4
   23 |   1.2644 |     42.740 |   1.2623 |     42.113 |     2.5
   24 |   1.2567 |     42.381 |   1.2758 |     42.945 |     2.6
   25 |   1.2502 |     42.122 |   1.2619 |     41.374 |     2.7
   26 |   1.2452 |     42.138 |   1.2681 |     42.452 |     2.8
   27 |   1.2420 |     41.703 |   1.2828 |     42.421 |     2.9
   28 |   1.2308 |     41.625 |   1.2503 |     41.682 |     3.0
   29 |   1.2290 |     41.691 |   1.2460 |     41.713 |     3.1
   30 |   1.2178 |     41.399 |   1.2715 |     42.452 |     3.2
   31 |   1.2183 |     41.504 |   1.2481 |     42.329 |     3.3
   32 |   1.2095 |     41.167 |   1.2644 |     42.421 |     3.4
   33 |   1.2067 |     41.305 |   1.2477 |     41.898 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,177,378

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9037 |     51.981 |   1.4656 |     43.931 |     0.1
    2 |   1.3804 |     43.904 |   1.3609 |     43.993 |     0.2
    3 |   1.2909 |     42.514 |   1.2915 |     43.099 |     0.3
    4 |   1.2304 |     40.952 |   1.2410 |     41.744 |     0.5
    5 |   1.1836 |     39.904 |   1.2118 |     40.819 |     0.6
    6 |   1.1367 |     38.602 |   1.2044 |     41.436 |     0.7
    7 |   1.1011 |     37.460 |   1.1583 |     39.094 |     0.8
    8 |   1.0652 |     36.495 |   1.1297 |     38.879 |     0.9
    9 |   1.0312 |     34.702 |   1.1250 |     38.817 |     1.0
   10 |   0.9948 |     33.212 |   1.1200 |     37.924 |     1.2
   11 |   0.9648 |     32.362 |   1.0844 |     37.061 |     1.3
   12 |   0.9336 |     31.447 |   1.0636 |     35.582 |     1.4
   13 |   0.9010 |     30.029 |   1.0704 |     35.613 |     1.5
   14 |   0.8702 |     28.749 |   1.0666 |     35.767 |     1.6
   15 |   0.8414 |     28.048 |   1.0703 |     34.874 |     1.7
   16 |   0.8109 |     27.221 |   1.0531 |     34.750 |     1.8
   17 |   0.7781 |     25.748 |   1.0189 |     33.087 |     2.0
   18 |   0.7504 |     24.743 |   1.0200 |     33.611 |     2.1
   19 |   0.7165 |     23.866 |   1.0521 |     34.073 |     2.2
   20 |   0.6925 |     22.873 |   1.0910 |     33.980 |     2.3
   21 |   0.6656 |     22.018 |   1.0239 |     32.810 |     2.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 425,634

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8071 |     69.811 |   2.0508 |     48.768 |     0.1
    2 |   1.9748 |     48.041 |   1.6426 |     46.765 |     0.2
    3 |   1.6870 |     46.557 |   1.5283 |     46.149 |     0.2
    4 |   1.5724 |     46.182 |   1.4600 |     46.149 |     0.3
    5 |   1.5056 |     45.774 |   1.4171 |     44.578 |     0.4
    6 |   1.4601 |     45.233 |   1.3818 |     44.824 |     0.5
    7 |   1.4253 |     44.908 |   1.3549 |     43.623 |     0.6
    8 |   1.3962 |     44.847 |   1.3380 |     43.623 |     0.6
    9 |   1.3743 |     44.213 |   1.3185 |     43.099 |     0.7
   10 |   1.3514 |     43.937 |   1.3024 |     42.976 |     0.8
   11 |   1.3341 |     43.915 |   1.2906 |     42.699 |     0.9
   12 |   1.3192 |     43.711 |   1.2917 |     43.068 |     1.0
   13 |   1.2981 |     43.016 |   1.2770 |     42.884 |     1.1
   14 |   1.2905 |     43.010 |   1.2629 |     42.545 |     1.1
   15 |   1.2747 |     42.436 |   1.2568 |     42.853 |     1.2
   16 |   1.2649 |     42.127 |   1.2495 |     42.637 |     1.3
   17 |   1.2553 |     41.934 |   1.2511 |     42.976 |     1.4
   18 |   1.2447 |     41.912 |   1.2414 |     41.898 |     1.5
   19 |   1.2337 |     41.377 |   1.2191 |     41.651 |     1.5
   20 |   1.2263 |     41.471 |   1.2313 |     42.421 |     1.6
   21 |   1.2180 |     41.465 |   1.2183 |     42.021 |     1.7
   22 |   1.2087 |     40.897 |   1.2046 |     41.374 |     1.8
   23 |   1.1981 |     40.588 |   1.2165 |     42.144 |     1.9
   24 |   1.1904 |     40.279 |   1.1974 |     41.374 |     1.9
   25 |   1.1880 |     40.577 |   1.2105 |     41.466 |     2.0
   26 |   1.1788 |     39.926 |   1.2096 |     41.590 |     2.1
   27 |   1.1743 |     39.948 |   1.1861 |     41.066 |     2.2
   28 |   1.1675 |     39.716 |   1.1863 |     41.035 |     2.3
   29 |   1.1632 |     39.452 |   1.1917 |     40.789 |     2.3
   30 |   1.1527 |     39.236 |   1.1679 |     40.481 |     2.4
   31 |   1.1522 |     39.352 |   1.1676 |     40.450 |     2.5
   32 |   1.1434 |     39.159 |   1.1838 |     40.388 |     2.6
   33 |   1.1400 |     39.099 |   1.1603 |     40.111 |     2.7
   34 |   1.1337 |     38.696 |   1.1750 |     40.203 |     2.8
   35 |   1.1263 |     38.690 |   1.1649 |     39.649 |     2.8
   36 |   1.1264 |     38.856 |   1.1557 |     39.803 |     2.9
   37 |   1.1127 |     38.122 |   1.1669 |     40.450 |     3.0
   38 |   1.1096 |     38.310 |   1.1485 |     39.495 |     3.1
   39 |   1.1073 |     37.841 |   1.1391 |     39.063 |     3.2
   40 |   1.1031 |     37.576 |   1.1488 |     39.310 |     3.2
   41 |   1.0948 |     37.493 |   1.1677 |     39.803 |     3.3
   42 |   1.0901 |     37.410 |   1.1461 |     39.433 |     3.4
   43 |   1.0882 |     37.355 |   1.1549 |     39.556 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,013,282

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5680 |     48.510 |   1.3156 |     46.611 |     0.2
    2 |   1.2983 |     45.233 |   1.2588 |     44.270 |     0.4
    3 |   1.2319 |     43.446 |   1.1868 |     42.606 |     0.5
    4 |   1.1984 |     42.403 |   1.1792 |     42.267 |     0.7
    5 |   1.1726 |     41.383 |   1.1501 |     41.929 |     0.9
    6 |   1.1526 |     41.046 |   1.1365 |     40.912 |     1.1
    7 |   1.1384 |     40.721 |   1.1518 |     41.436 |     1.3
    8 |   1.1217 |     39.948 |   1.1075 |     39.710 |     1.5
    9 |   1.1082 |     39.700 |   1.0967 |     38.755 |     1.6
   10 |   1.0901 |     38.867 |   1.0952 |     39.063 |     1.8
   11 |   1.0768 |     38.806 |   1.0828 |     39.125 |     2.0
   12 |   1.0680 |     38.635 |   1.0634 |     38.232 |     2.2
   13 |   1.0573 |     38.017 |   1.0699 |     38.232 |     2.4
   14 |   1.0543 |     37.863 |   1.0649 |     38.108 |     2.6
   15 |   1.0440 |     37.659 |   1.0534 |     39.279 |     2.8
   16 |   1.0352 |     37.752 |   1.0497 |     38.201 |     2.9
   17 |   1.0278 |     37.355 |   1.0669 |     38.786 |     3.1
   18 |   1.0225 |     36.853 |   1.0337 |     37.123 |     3.3
   19 |   1.0158 |     36.417 |   1.0682 |     38.386 |     3.5
   20 |   1.0132 |     36.610 |   1.0328 |     37.153 |     3.7
   21 |   0.9961 |     36.042 |   1.0156 |     35.983 |     3.8
   22 |   0.9864 |     35.546 |   1.0004 |     36.168 |     4.0
   23 |   0.9831 |     35.717 |   1.0021 |     36.106 |     4.2
   24 |   0.9765 |     35.375 |   1.0112 |     36.599 |     4.4
   25 |   0.9762 |     35.209 |   1.0155 |     36.198 |     4.6
   26 |   0.9654 |     35.104 |   1.0080 |     36.106 |     4.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 978,594

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2044 |     54.303 |   1.5497 |     46.149 |     0.1
    2 |   1.5751 |     46.265 |   1.4230 |     46.057 |     0.2
    3 |   1.4565 |     45.846 |   1.3643 |     43.931 |     0.3
    4 |   1.3913 |     44.814 |   1.3371 |     44.578 |     0.5
    5 |   1.3541 |     44.262 |   1.2975 |     43.993 |     0.6
    6 |   1.3193 |     43.777 |   1.2773 |     43.376 |     0.7
    7 |   1.2925 |     43.126 |   1.2816 |     43.900 |     0.8
    8 |   1.2669 |     42.365 |   1.2522 |     42.514 |     0.9
    9 |   1.2446 |     41.874 |   1.2359 |     41.898 |     1.0
   10 |   1.2247 |     41.305 |   1.2284 |     41.405 |     1.1
   11 |   1.2079 |     40.533 |   1.1955 |     40.173 |     1.3
   12 |   1.1895 |     40.070 |   1.1947 |     40.727 |     1.4
   13 |   1.1700 |     39.772 |   1.2059 |     40.604 |     1.5
   14 |   1.1618 |     39.407 |   1.1870 |     40.018 |     1.6
   15 |   1.1493 |     38.878 |   1.1764 |     39.926 |     1.7
   16 |   1.1285 |     38.403 |   1.1892 |     39.988 |     1.8
   17 |   1.1216 |     38.100 |   1.1696 |     39.279 |     1.9
   18 |   1.1087 |     38.034 |   1.1596 |     39.002 |     2.1
   19 |   1.0977 |     37.626 |   1.1486 |     38.324 |     2.2
   20 |   1.0830 |     37.190 |   1.1446 |     38.386 |     2.3
   21 |   1.0778 |     37.146 |   1.1396 |     38.262 |     2.4
   22 |   1.0642 |     36.175 |   1.1036 |     37.061 |     2.5
   23 |   1.0586 |     36.318 |   1.1334 |     37.862 |     2.6
   24 |   1.0378 |     35.485 |   1.1337 |     38.540 |     2.7
   25 |   1.0339 |     35.673 |   1.1372 |     37.954 |     2.9
   26 |   1.0252 |     35.281 |   1.1722 |     38.509 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 425,634

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2093 |     54.038 |   1.7307 |     46.272 |     0.1
    2 |   1.6025 |     45.443 |   1.5432 |     44.978 |     0.2
    3 |   1.4722 |     44.257 |   1.4494 |     44.794 |     0.3
    4 |   1.3977 |     43.142 |   1.3935 |     43.962 |     0.4
    5 |   1.3461 |     42.436 |   1.3648 |     44.486 |     0.5
    6 |   1.3042 |     41.863 |   1.3265 |     43.808 |     0.6
    7 |   1.2695 |     41.372 |   1.2890 |     42.083 |     0.7
    8 |   1.2378 |     40.721 |   1.2684 |     42.083 |     0.8
    9 |   1.2134 |     40.141 |   1.2897 |     42.021 |     0.9
   10 |   1.1831 |     39.452 |   1.2147 |     40.789 |     1.0
   11 |   1.1599 |     38.530 |   1.1980 |     40.203 |     1.1
   12 |   1.1375 |     38.078 |   1.1898 |     39.680 |     1.2
   13 |   1.1199 |     37.576 |   1.1964 |     39.741 |     1.3
   14 |   1.1048 |     37.272 |   1.1836 |     39.372 |     1.4
   15 |   1.0850 |     36.914 |   1.1596 |     39.310 |     1.5
   16 |   1.0674 |     36.307 |   1.1324 |     37.831 |     1.6
   17 |   1.0478 |     35.463 |   1.1406 |     38.386 |     1.7
   18 |   1.0301 |     34.735 |   1.1086 |     37.924 |     1.8
   19 |   1.0167 |     34.277 |   1.1095 |     37.030 |     1.9
   20 |   0.9972 |     33.576 |   1.1052 |     37.400 |     2.0
   21 |   0.9827 |     33.129 |   1.0919 |     36.969 |     2.1
   22 |   0.9733 |     33.030 |   1.1006 |     37.215 |     2.2
   23 |   0.9521 |     32.031 |   1.1156 |     37.862 |     2.3
   24 |   0.9396 |     31.590 |   1.1157 |     37.338 |     2.4
   25 |   0.9308 |     31.491 |   1.0780 |     36.815 |     2.5
   26 |   0.9148 |     30.785 |   1.1120 |     36.784 |     2.6
   27 |   0.9009 |     30.018 |   1.1129 |     36.445 |     2.7
   28 |   0.8842 |     29.527 |   1.0745 |     35.428 |     2.8
   29 |   0.8752 |     29.118 |   1.0610 |     35.890 |     2.9
   30 |   0.8626 |     28.953 |   1.0900 |     35.551 |     3.0
   31 |   0.8537 |     28.832 |   1.0632 |     35.736 |     3.1
   32 |   0.8369 |     27.717 |   1.0595 |     35.213 |     3.2
   33 |   0.8239 |     27.469 |   1.0720 |     35.182 |     3.3
   34 |   0.8150 |     27.386 |   1.0716 |     35.397 |     3.4
   35 |   0.8000 |     26.559 |   1.0780 |     35.182 |     3.5
   36 |   0.7938 |     26.581 |   1.0753 |     35.767 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 748,706

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4180 |     59.042 |   1.7201 |     46.888 |     0.1
    2 |   1.6172 |     46.149 |   1.4386 |     45.225 |     0.3
    3 |   1.4428 |     44.958 |   1.3740 |     45.009 |     0.4
    4 |   1.3737 |     44.135 |   1.3328 |     44.147 |     0.5
    5 |   1.3303 |     43.435 |   1.3028 |     43.900 |     0.7
    6 |   1.2957 |     42.618 |   1.2820 |     43.007 |     0.8
    7 |   1.2651 |     41.989 |   1.2725 |     42.421 |     0.9
    8 |   1.2443 |     41.565 |   1.2711 |     43.099 |     1.1
    9 |   1.2221 |     41.173 |   1.2192 |     40.758 |     1.2
   10 |   1.2009 |     40.274 |   1.1974 |     39.495 |     1.3
   11 |   1.1804 |     39.672 |   1.1998 |     40.234 |     1.5
   12 |   1.1644 |     39.038 |   1.1997 |     40.388 |     1.6
   13 |   1.1474 |     38.591 |   1.1694 |     39.372 |     1.8
   14 |   1.1314 |     38.580 |   1.1479 |     38.971 |     1.9
   15 |   1.1156 |     37.581 |   1.1692 |     39.495 |     2.0
   16 |   1.1010 |     36.864 |   1.1653 |     40.296 |     2.2
   17 |   1.0863 |     36.682 |   1.1549 |     39.710 |     2.3
   18 |   1.0694 |     36.114 |   1.1348 |     38.232 |     2.4
   19 |   1.0541 |     35.529 |   1.1271 |     38.447 |     2.6
   20 |   1.0395 |     34.911 |   1.1280 |     38.632 |     2.7
   21 |   1.0285 |     34.696 |   1.1355 |     38.262 |     2.8
   22 |   1.0148 |     34.100 |   1.1349 |     38.632 |     3.0
   23 |   0.9989 |     33.852 |   1.1248 |     38.571 |     3.1
   24 |   0.9812 |     32.975 |   1.1181 |     38.170 |     3.2
   25 |   0.9778 |     33.080 |   1.0922 |     36.969 |     3.4
   26 |   0.9596 |     32.451 |   1.1311 |     38.355 |     3.5
   27 |   0.9488 |     31.982 |   1.1359 |     38.540 |     3.7
   28 |   0.9358 |     31.309 |   1.1089 |     36.876 |     3.8
   29 |   0.9249 |     30.829 |   1.1505 |     38.571 |     3.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 243,490

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8300 |     50.403 |   1.3710 |     45.379 |     0.1
    2 |   1.3693 |     45.465 |   1.3218 |     44.301 |     0.3
    3 |   1.3149 |     44.786 |   1.2735 |     43.746 |     0.4
    4 |   1.2784 |     44.163 |   1.2550 |     44.886 |     0.6
    5 |   1.2513 |     43.534 |   1.2265 |     43.931 |     0.7
    6 |   1.2313 |     43.661 |   1.2113 |     42.452 |     0.9
    7 |   1.2197 |     43.810 |   1.2129 |     42.884 |     1.0
    8 |   1.2128 |     43.391 |   1.2060 |     43.500 |     1.2
    9 |   1.1965 |     42.916 |   1.1927 |     43.099 |     1.3
   10 |   1.1915 |     42.718 |   1.1859 |     42.514 |     1.5
   11 |   1.1794 |     42.541 |   1.1716 |     42.329 |     1.6
   12 |   1.1751 |     42.199 |   1.1790 |     41.867 |     1.8
   13 |   1.1656 |     41.962 |   1.1570 |     42.329 |     1.9
   14 |   1.1580 |     41.465 |   1.1477 |     41.220 |     2.1
   15 |   1.1472 |     41.145 |   1.1426 |     42.083 |     2.2
   16 |   1.1374 |     40.461 |   1.1733 |     42.298 |     2.3
   17 |   1.1358 |     40.643 |   1.1723 |     41.436 |     2.5
   18 |   1.1228 |     40.246 |   1.1431 |     41.497 |     2.6
   19 |   1.1221 |     40.500 |   1.1700 |     41.929 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,013,282

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5049 |     47.026 |   1.2723 |     44.116 |     0.2
    2 |   1.2482 |     44.036 |   1.2206 |     43.222 |     0.3
    3 |   1.1894 |     42.502 |   1.1823 |     42.421 |     0.5
    4 |   1.1509 |     41.785 |   1.1573 |     43.038 |     0.7
    5 |   1.1337 |     41.349 |   1.1298 |     43.561 |     0.8
    6 |   1.1112 |     40.726 |   1.1171 |     40.912 |     1.0
    7 |   1.0939 |     39.694 |   1.0973 |     39.926 |     1.2
    8 |   1.0744 |     39.242 |   1.0908 |     39.372 |     1.4
    9 |   1.0591 |     38.475 |   1.0925 |     40.080 |     1.5
   10 |   1.0519 |     38.596 |   1.0884 |     39.279 |     1.7
   11 |   1.0396 |     37.979 |   1.0673 |     38.879 |     1.9
   12 |   1.0285 |     37.774 |   1.0469 |     37.708 |     2.0
   13 |   1.0228 |     37.443 |   1.0520 |     37.585 |     2.2
   14 |   1.0103 |     36.991 |   1.0429 |     37.739 |     2.4
   15 |   0.9978 |     36.759 |   1.0762 |     38.694 |     2.6
   16 |   0.9856 |     36.081 |   1.0388 |     36.969 |     2.7
   17 |   0.9740 |     35.529 |   1.0600 |     37.893 |     2.9
   18 |   0.9617 |     35.446 |   1.0608 |     36.907 |     3.1
   19 |   0.9467 |     34.426 |   1.0326 |     37.400 |     3.2
   20 |   0.9368 |     34.321 |   1.0222 |     36.568 |     3.4
   21 |   0.9359 |     34.238 |   1.0176 |     36.075 |     3.6
   22 |   0.9241 |     33.714 |   1.0745 |     37.123 |     3.8
   23 |   0.9115 |     33.195 |   1.0347 |     35.829 |     3.9
   24 |   0.8925 |     32.114 |   1.0367 |     35.767 |     4.1
   25 |   0.8871 |     32.015 |   0.9920 |     33.703 |     4.3
   26 |   0.8713 |     31.402 |   0.9843 |     34.073 |     4.4
   27 |   0.8641 |     31.237 |   1.0277 |     34.442 |     4.6
   28 |   0.8495 |     30.371 |   1.0118 |     35.213 |     4.8
   29 |   0.8351 |     30.001 |   1.0262 |     34.935 |     5.0
   30 |   0.8162 |     29.256 |   1.0370 |     34.689 |     5.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 582,434

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5874 |     47.777 |   1.3144 |     44.640 |     0.1
    2 |   1.3011 |     44.417 |   1.2387 |     43.099 |     0.2
    3 |   1.2439 |     42.778 |   1.2279 |     41.559 |     0.2
    4 |   1.2039 |     41.482 |   1.1824 |     40.142 |     0.3
    5 |   1.1721 |     40.544 |   1.1439 |     39.526 |     0.4
    6 |   1.1413 |     39.424 |   1.1250 |     38.755 |     0.5
    7 |   1.1174 |     38.718 |   1.1138 |     38.725 |     0.6
    8 |   1.0889 |     38.072 |   1.0959 |     37.123 |     0.6
    9 |   1.0746 |     37.344 |   1.1060 |     38.078 |     0.7
   10 |   1.0423 |     36.130 |   1.1055 |     37.862 |     0.8
   11 |   1.0200 |     35.198 |   1.0713 |     37.246 |     0.9
   12 |   0.9997 |     34.420 |   1.0908 |     38.016 |     1.0
   13 |   0.9772 |     33.857 |   1.0763 |     36.630 |     1.0
   14 |   0.9618 |     33.157 |   1.0883 |     37.307 |     1.1
   15 |   0.9378 |     32.566 |   1.1124 |     36.445 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 458,850

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5264 |     61.404 |   1.8335 |     48.706 |     0.2
    2 |   1.7639 |     46.712 |   1.5770 |     45.718 |     0.3
    3 |   1.5882 |     46.077 |   1.4869 |     45.595 |     0.5
    4 |   1.5011 |     45.614 |   1.4320 |     44.978 |     0.7
    5 |   1.4456 |     45.366 |   1.3919 |     44.301 |     0.8
    6 |   1.4019 |     44.516 |   1.3552 |     43.931 |     1.0
    7 |   1.3686 |     44.411 |   1.3323 |     43.777 |     1.1
    8 |   1.3399 |     43.953 |   1.3048 |     42.452 |     1.3
    9 |   1.3154 |     43.633 |   1.2847 |     42.052 |     1.5
   10 |   1.2920 |     42.993 |   1.2679 |     42.483 |     1.6
   11 |   1.2727 |     42.387 |   1.2501 |     41.867 |     1.8
   12 |   1.2544 |     42.122 |   1.2444 |     42.144 |     2.0
   13 |   1.2367 |     41.344 |   1.2604 |     43.438 |     2.1
   14 |   1.2209 |     41.256 |   1.2436 |     41.713 |     2.3
   15 |   1.2092 |     40.897 |   1.2220 |     41.405 |     2.5
   16 |   1.1928 |     40.367 |   1.2233 |     41.774 |     2.6
   17 |   1.1830 |     40.064 |   1.2041 |     40.758 |     2.8
   18 |   1.1726 |     39.777 |   1.2016 |     41.128 |     2.9
   19 |   1.1612 |     39.286 |   1.1894 |     41.004 |     3.1
   20 |   1.1508 |     39.220 |   1.2007 |     41.251 |     3.3
   21 |   1.1376 |     38.701 |   1.1837 |     40.357 |     3.4
   22 |   1.1263 |     38.420 |   1.1717 |     40.111 |     3.6
   23 |   1.1225 |     38.265 |   1.1812 |     40.111 |     3.8
   24 |   1.1123 |     37.819 |   1.1692 |     40.111 |     3.9
   25 |   1.1052 |     37.868 |   1.1683 |     39.957 |     4.1
   26 |   1.0949 |     37.283 |   1.1572 |     39.187 |     4.3
   27 |   1.0847 |     37.383 |   1.1438 |     39.372 |     4.4
   28 |   1.0776 |     36.649 |   1.1807 |     39.649 |     4.6
   29 |   1.0682 |     36.522 |   1.1692 |     38.940 |     4.8
   30 |   1.0650 |     36.318 |   1.1502 |     38.879 |     4.9
   31 |   1.0540 |     35.976 |   1.1552 |     39.002 |     5.1
   32 |   1.0470 |     35.860 |   1.1277 |     37.585 |     5.2
   33 |   1.0402 |     35.446 |   1.1278 |     37.862 |     5.4
   34 |   1.0315 |     35.319 |   1.1684 |     39.125 |     5.6
   35 |   1.0235 |     34.823 |   1.1273 |     38.201 |     5.7
   36 |   1.0143 |     34.387 |   1.1639 |     39.002 |     5.9
   37 |   1.0128 |     34.558 |   1.1697 |     39.217 |     6.1
   38 |   1.0007 |     34.216 |   1.1294 |     37.893 |     6.2
   39 |   0.9947 |     33.852 |   1.1092 |     36.938 |     6.4
   40 |   0.9915 |     33.852 |   1.1380 |     37.616 |     6.6
   41 |   0.9833 |     33.532 |   1.1484 |     38.047 |     6.7
   42 |   0.9736 |     33.151 |   1.1442 |     37.708 |     6.9
   43 |   0.9665 |     32.997 |   1.1407 |     37.862 |     7.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 847,394

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5477 |     47.424 |   1.3053 |     43.869 |     0.2
    2 |   1.2751 |     44.042 |   1.2288 |     43.993 |     0.3
    3 |   1.2277 |     43.540 |   1.1925 |     42.083 |     0.5
    4 |   1.2070 |     43.407 |   1.1796 |     42.452 |     0.7
    5 |   1.1793 |     42.569 |   1.1611 |     41.744 |     0.9
    6 |   1.1673 |     42.188 |   1.1420 |     41.189 |     1.1
    7 |   1.1516 |     41.835 |   1.1395 |     41.035 |     1.2
    8 |   1.1393 |     41.482 |   1.1419 |     42.329 |     1.4
    9 |   1.1377 |     41.559 |   1.1373 |     41.066 |     1.6
   10 |   1.1287 |     41.118 |   1.1230 |     40.573 |     1.8
   11 |   1.1154 |     40.505 |   1.1085 |     40.819 |     1.9
   12 |   1.1048 |     40.152 |   1.1040 |     41.898 |     2.1
   13 |   1.1018 |     40.296 |   1.0992 |     40.296 |     2.3
   14 |   1.0925 |     39.457 |   1.0899 |     38.909 |     2.5
   15 |   1.0830 |     39.474 |   1.0896 |     39.649 |     2.6
   16 |   1.0741 |     39.137 |   1.1027 |     39.464 |     2.8
   17 |   1.0702 |     39.071 |   1.0743 |     38.016 |     3.0
   18 |   1.0621 |     38.712 |   1.0697 |     38.879 |     3.2
   19 |   1.0524 |     38.470 |   1.0655 |     39.063 |     3.4
   20 |   1.0496 |     38.006 |   1.0726 |     39.495 |     3.5
   21 |   1.0450 |     38.012 |   1.0874 |     39.680 |     3.7
   22 |   1.0388 |     37.863 |   1.1010 |     39.495 |     3.9
   23 |   1.0357 |     37.504 |   1.0911 |     39.741 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 277,026

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9754 |     53.994 |   1.4010 |     44.917 |     0.1
    2 |   1.3950 |     45.548 |   1.3321 |     45.009 |     0.2
    3 |   1.3261 |     44.411 |   1.2856 |     44.147 |     0.3
    4 |   1.2735 |     43.043 |   1.2730 |     43.715 |     0.4
    5 |   1.2289 |     42.000 |   1.2554 |     42.606 |     0.5
    6 |   1.2004 |     40.969 |   1.1889 |     41.097 |     0.6
    7 |   1.1675 |     40.196 |   1.1816 |     40.974 |     0.7
    8 |   1.1379 |     39.308 |   1.1677 |     39.033 |     0.8
    9 |   1.1146 |     38.663 |   1.1182 |     38.940 |     0.9
   10 |   1.0964 |     37.830 |   1.1162 |     38.478 |     1.0
   11 |   1.0797 |     37.118 |   1.1512 |     39.433 |     1.1
   12 |   1.0553 |     36.478 |   1.0841 |     36.599 |     1.3
   13 |   1.0354 |     35.375 |   1.0858 |     37.585 |     1.4
   14 |   1.0158 |     35.033 |   1.0920 |     37.554 |     1.5
   15 |   0.9936 |     34.023 |   1.0721 |     36.445 |     1.6
   16 |   0.9706 |     33.173 |   1.0523 |     35.952 |     1.7
   17 |   0.9595 |     32.809 |   1.0882 |     36.168 |     1.8
   18 |   0.9454 |     32.379 |   1.0469 |     35.397 |     1.9
   19 |   0.9261 |     31.882 |   1.0731 |     35.551 |     2.0
   20 |   0.9093 |     31.204 |   1.0823 |     35.952 |     2.1
   21 |   0.8957 |     30.608 |   1.0565 |     34.904 |     2.2
   22 |   0.8710 |     30.288 |   1.0620 |     35.305 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 980,002

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5932 |     48.742 |   1.3291 |     45.071 |     0.1
    2 |   1.2950 |     44.152 |   1.2452 |     42.853 |     0.2
    3 |   1.2183 |     42.238 |   1.1861 |     40.635 |     0.4
    4 |   1.1718 |     40.588 |   1.1500 |     40.049 |     0.5
    5 |   1.1263 |     39.187 |   1.1260 |     38.355 |     0.6
    6 |   1.0776 |     37.228 |   1.0867 |     37.585 |     0.7
    7 |   1.0404 |     36.125 |   1.1028 |     37.184 |     0.8
    8 |   1.0047 |     34.856 |   1.0596 |     37.338 |     1.0
    9 |   0.9655 |     33.405 |   1.0691 |     36.414 |     1.1
   10 |   0.9379 |     32.544 |   1.0371 |     34.997 |     1.2
   11 |   0.9054 |     31.253 |   1.0487 |     35.059 |     1.3
   12 |   0.8672 |     29.797 |   1.0533 |     35.428 |     1.5
   13 |   0.8226 |     28.214 |   1.0550 |     35.028 |     1.6
   14 |   0.8008 |     27.579 |   1.0382 |     33.641 |     1.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 525,602

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7267 |     49.222 |   1.3665 |     45.595 |     0.2
    2 |   1.3404 |     45.300 |   1.2994 |     44.424 |     0.3
    3 |   1.2776 |     44.279 |   1.2469 |     43.500 |     0.5
    4 |   1.2433 |     43.573 |   1.2063 |     42.884 |     0.7
    5 |   1.2090 |     42.811 |   1.1669 |     41.651 |     0.9
    6 |   1.1783 |     41.857 |   1.1544 |     40.758 |     1.0
    7 |   1.1576 |     40.958 |   1.1358 |     41.097 |     1.2
    8 |   1.1324 |     39.738 |   1.1289 |     41.651 |     1.4
    9 |   1.1167 |     39.584 |   1.1086 |     39.526 |     1.5
   10 |   1.1061 |     39.485 |   1.0888 |     39.217 |     1.7
   11 |   1.0872 |     38.668 |   1.1006 |     39.402 |     1.9
   12 |   1.0753 |     38.288 |   1.0694 |     37.677 |     2.1
   13 |   1.0660 |     38.503 |   1.0649 |     38.324 |     2.2
   14 |   1.0497 |     37.322 |   1.0814 |     38.047 |     2.4
   15 |   1.0407 |     37.521 |   1.0795 |     38.725 |     2.6
   16 |   1.0279 |     37.052 |   1.0888 |     38.139 |     2.7
   17 |   1.0194 |     36.544 |   1.0563 |     37.153 |     2.9
   18 |   1.0087 |     35.948 |   1.0724 |     38.170 |     3.1
   19 |   0.9988 |     35.860 |   1.0351 |     36.352 |     3.3
   20 |   0.9880 |     35.457 |   1.0338 |     36.506 |     3.4
   21 |   0.9805 |     35.126 |   1.0332 |     35.829 |     3.6
   22 |   0.9745 |     34.784 |   1.0868 |     38.047 |     3.8
   23 |   0.9675 |     34.531 |   1.0351 |     36.383 |     3.9
   24 |   0.9507 |     33.885 |   1.0227 |     35.243 |     4.1
   25 |   0.9490 |     33.951 |   1.0331 |     36.722 |     4.3
   26 |   0.9416 |     33.868 |   1.0564 |     36.661 |     4.4
   27 |   0.9305 |     32.925 |   1.0282 |     35.459 |     4.6
   28 |   0.9198 |     32.743 |   1.0841 |     36.722 |     4.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 393,506

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6610 |     48.378 |   1.3324 |     45.040 |     0.1
    2 |   1.2791 |     44.080 |   1.2291 |     43.253 |     0.2
    3 |   1.2160 |     42.927 |   1.1935 |     41.436 |     0.3
    4 |   1.1728 |     41.559 |   1.1643 |     41.466 |     0.4
    5 |   1.1433 |     40.864 |   1.1410 |     41.374 |     0.5
    6 |   1.1207 |     39.965 |   1.1210 |     40.542 |     0.7
    7 |   1.0988 |     39.352 |   1.1142 |     39.895 |     0.8
    8 |   1.0768 |     38.541 |   1.0801 |     38.879 |     0.9
    9 |   1.0505 |     37.477 |   1.0892 |     39.433 |     1.0
   10 |   1.0330 |     36.886 |   1.0661 |     38.201 |     1.1
   11 |   1.0177 |     36.572 |   1.0699 |     38.232 |     1.2
   12 |   1.0003 |     35.926 |   1.0477 |     37.954 |     1.3
   13 |   0.9861 |     35.540 |   1.0535 |     36.938 |     1.4
   14 |   0.9786 |     35.292 |   1.0796 |     38.201 |     1.5
   15 |   0.9593 |     34.199 |   1.0620 |     37.215 |     1.6
   16 |   0.9514 |     33.918 |   1.0503 |     35.921 |     1.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 358,882

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3275 |     53.421 |   1.7819 |     46.334 |     0.1
    2 |   1.6382 |     45.702 |   1.5673 |     45.225 |     0.1
    3 |   1.5041 |     44.704 |   1.4762 |     44.085 |     0.2
    4 |   1.4316 |     43.667 |   1.4143 |     42.945 |     0.3
    5 |   1.3789 |     43.220 |   1.3702 |     42.545 |     0.3
    6 |   1.3385 |     42.580 |   1.3410 |     43.746 |     0.4
    7 |   1.2999 |     42.017 |   1.3222 |     43.099 |     0.5
    8 |   1.2695 |     41.592 |   1.3002 |     43.222 |     0.5
    9 |   1.2401 |     40.549 |   1.2936 |     43.654 |     0.6
   10 |   1.2145 |     40.218 |   1.2534 |     41.867 |     0.7
   11 |   1.1888 |     39.203 |   1.2468 |     41.497 |     0.8
   12 |   1.1699 |     38.905 |   1.2386 |     42.113 |     0.8
   13 |   1.1480 |     38.183 |   1.2084 |     40.142 |     0.9
   14 |   1.1304 |     37.934 |   1.2029 |     41.220 |     1.0
   15 |   1.1118 |     37.300 |   1.2049 |     40.696 |     1.0
   16 |   1.0937 |     36.544 |   1.1954 |     40.727 |     1.1
   17 |   1.0753 |     35.904 |   1.2203 |     40.819 |     1.2
   18 |   1.0620 |     35.573 |   1.1595 |     39.187 |     1.2
   19 |   1.0471 |     35.347 |   1.1386 |     38.909 |     1.3
   20 |   1.0287 |     34.326 |   1.1632 |     39.526 |     1.4
   21 |   1.0158 |     33.841 |   1.1647 |     39.341 |     1.4
   22 |   1.0020 |     33.587 |   1.1753 |     40.203 |     1.5
   23 |   0.9898 |     33.069 |   1.1568 |     39.372 |     1.6
   24 |   0.9781 |     32.809 |   1.1211 |     37.985 |     1.6
   25 |   0.9600 |     32.048 |   1.1329 |     38.201 |     1.7
   26 |   0.9471 |     31.573 |   1.1690 |     38.909 |     1.8
   27 |   0.9351 |     31.358 |   1.1530 |     39.156 |     1.8
   28 |   0.9236 |     30.658 |   1.1607 |     38.632 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 343,266

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8392 |     51.352 |   1.3838 |     45.287 |     0.1
    2 |   1.3734 |     45.432 |   1.2970 |     43.469 |     0.2
    3 |   1.3102 |     44.472 |   1.2548 |     43.130 |     0.3
    4 |   1.2679 |     43.628 |   1.2275 |     42.545 |     0.4
    5 |   1.2437 |     43.016 |   1.1939 |     41.374 |     0.5
    6 |   1.2176 |     42.354 |   1.2028 |     41.158 |     0.7
    7 |   1.2003 |     41.614 |   1.1766 |     41.128 |     0.8
    8 |   1.1760 |     40.991 |   1.1743 |     40.573 |     0.9
    9 |   1.1620 |     40.511 |   1.1402 |     39.587 |     1.0
   10 |   1.1471 |     40.075 |   1.1127 |     38.540 |     1.1
   11 |   1.1400 |     40.097 |   1.1283 |     40.450 |     1.2
   12 |   1.1252 |     39.545 |   1.1044 |     38.478 |     1.3
   13 |   1.1101 |     38.823 |   1.0859 |     38.632 |     1.4
   14 |   1.1011 |     38.475 |   1.0990 |     38.047 |     1.5
   15 |   1.0911 |     38.459 |   1.0843 |     38.262 |     1.7
   16 |   1.0857 |     38.094 |   1.0740 |     37.770 |     1.8
   17 |   1.0777 |     37.670 |   1.0699 |     37.369 |     1.9
   18 |   1.0718 |     37.747 |   1.0902 |     38.232 |     2.0
   19 |   1.0669 |     37.565 |   1.0869 |     38.386 |     2.1
   20 |   1.0516 |     36.925 |   1.0707 |     37.123 |     2.2
   21 |   1.0452 |     36.666 |   1.0458 |     36.322 |     2.3
   22 |   1.0365 |     36.428 |   1.0446 |     36.044 |     2.4
   23 |   1.0292 |     36.169 |   1.0503 |     36.537 |     2.5
   24 |   1.0226 |     35.827 |   1.0229 |     36.106 |     2.6
   25 |   1.0175 |     35.711 |   1.0442 |     36.291 |     2.8
   26 |   1.0057 |     35.391 |   1.0493 |     35.983 |     2.9
   27 |   1.0025 |     35.308 |   1.0284 |     35.521 |     3.0
   28 |   0.9929 |     34.806 |   1.0301 |     35.274 |     3.1
   29 |   0.9847 |     34.679 |   0.9994 |     34.658 |     3.2
   30 |   0.9764 |     34.481 |   1.0341 |     36.198 |     3.3
   31 |   0.9757 |     34.177 |   0.9996 |     34.196 |     3.4
   32 |   0.9723 |     34.045 |   1.0236 |     36.198 |     3.5
   33 |   0.9621 |     33.708 |   0.9789 |     34.196 |     3.6
   34 |   0.9564 |     33.521 |   1.0339 |     35.644 |     3.8
   35 |   0.9425 |     33.405 |   1.0396 |     34.935 |     3.9
   36 |   0.9451 |     32.991 |   1.0089 |     35.582 |     4.0
   37 |   0.9425 |     32.958 |   1.0047 |     34.750 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 458,850

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6575 |     48.091 |   1.3532 |     44.978 |     0.1
    2 |   1.3174 |     44.621 |   1.2799 |     44.824 |     0.2
    3 |   1.2546 |     43.953 |   1.2192 |     42.914 |     0.3
    4 |   1.2220 |     43.347 |   1.1906 |     43.438 |     0.5
    5 |   1.2016 |     42.927 |   1.1751 |     42.421 |     0.6
    6 |   1.1825 |     42.227 |   1.1781 |     42.853 |     0.7
    7 |   1.1683 |     41.929 |   1.1489 |     42.083 |     0.8
    8 |   1.1578 |     42.006 |   1.1423 |     42.113 |     0.9
    9 |   1.1422 |     41.421 |   1.1369 |     41.929 |     1.0
   10 |   1.1365 |     41.840 |   1.1318 |     41.528 |     1.1
   11 |   1.1277 |     41.228 |   1.1230 |     41.959 |     1.3
   12 |   1.1225 |     41.079 |   1.1129 |     40.850 |     1.4
   13 |   1.1124 |     40.610 |   1.1054 |     40.943 |     1.5
   14 |   1.1065 |     40.003 |   1.0978 |     39.988 |     1.6
   15 |   1.0960 |     40.075 |   1.0776 |     39.495 |     1.7
   16 |   1.0844 |     39.634 |   1.0784 |     38.817 |     1.8
   17 |   1.0746 |     39.065 |   1.0790 |     40.049 |     1.9
   18 |   1.0679 |     38.547 |   1.0794 |     38.725 |     2.1
   19 |   1.0643 |     38.558 |   1.0688 |     38.694 |     2.2
   20 |   1.0598 |     38.475 |   1.0619 |     38.601 |     2.3
   21 |   1.0546 |     38.409 |   1.0583 |     38.355 |     2.4
   22 |   1.0497 |     38.205 |   1.0657 |     38.601 |     2.5
   23 |   1.0483 |     38.392 |   1.0637 |     39.217 |     2.6
   24 |   1.0433 |     37.846 |   1.0514 |     38.601 |     2.8
   25 |   1.0361 |     37.979 |   1.0621 |     38.786 |     2.9
   26 |   1.0273 |     37.515 |   1.0489 |     38.016 |     3.0
   27 |   1.0219 |     37.410 |   1.0435 |     37.400 |     3.1
   28 |   1.0225 |     37.421 |   1.0345 |     37.492 |     3.2
   29 |   1.0097 |     36.941 |   1.0528 |     38.417 |     3.3
   30 |   1.0104 |     36.925 |   1.0286 |     37.092 |     3.4
   31 |   1.0042 |     36.875 |   1.0321 |     37.277 |     3.6
   32 |   0.9985 |     36.831 |   1.0203 |     36.876 |     3.7
   33 |   0.9949 |     36.445 |   1.0206 |     37.184 |     3.8
   34 |   0.9892 |     36.125 |   1.0339 |     37.554 |     3.9
   35 |   0.9829 |     35.877 |   1.0262 |     36.876 |     4.0
   36 |   0.9825 |     35.959 |   1.0256 |     38.016 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 978,594

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4766 |     46.844 |   1.2773 |     44.116 |     0.1
    2 |   1.2185 |     42.442 |   1.2045 |     44.147 |     0.2
    3 |   1.1381 |     39.849 |   1.1335 |     40.511 |     0.3
    4 |   1.0883 |     38.558 |   1.0975 |     39.372 |     0.4
    5 |   1.0496 |     37.052 |   1.0634 |     37.985 |     0.5
    6 |   1.0171 |     35.992 |   1.0502 |     36.938 |     0.6
    7 |   0.9804 |     34.619 |   1.0640 |     37.954 |     0.7
    8 |   0.9542 |     33.449 |   1.0307 |     35.521 |     0.9
    9 |   0.9264 |     32.440 |   1.0342 |     36.137 |     1.0
   10 |   0.8927 |     31.612 |   1.0467 |     34.843 |     1.1
   11 |   0.8652 |     30.575 |   0.9611 |     33.210 |     1.2
   12 |   0.8334 |     29.317 |   0.9886 |     34.412 |     1.3
   13 |   0.7977 |     27.910 |   0.9836 |     33.179 |     1.4
   14 |   0.7726 |     27.066 |   0.9966 |     33.303 |     1.5
   15 |   0.7455 |     26.167 |   1.0125 |     34.104 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 1,013,282

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6545 |     49.106 |   1.3489 |     46.734 |     0.2
    2 |   1.3415 |     45.553 |   1.2767 |     45.564 |     0.4
    3 |   1.2929 |     44.753 |   1.2374 |     43.654 |     0.6
    4 |   1.2606 |     44.632 |   1.2189 |     43.130 |     0.8
    5 |   1.2370 |     43.749 |   1.1927 |     43.192 |     1.0
    6 |   1.2167 |     43.473 |   1.1848 |     42.945 |     1.2
    7 |   1.1961 |     43.065 |   1.1709 |     42.637 |     1.4
    8 |   1.1922 |     43.054 |   1.1646 |     43.438 |     1.5
    9 |   1.1825 |     42.701 |   1.1421 |     41.251 |     1.7
   10 |   1.1631 |     42.640 |   1.1383 |     42.606 |     1.9
   11 |   1.1580 |     42.326 |   1.1330 |     41.220 |     2.1
   12 |   1.1521 |     42.166 |   1.1419 |     41.744 |     2.3
   13 |   1.1439 |     41.945 |   1.1199 |     42.144 |     2.5
   14 |   1.1392 |     41.736 |   1.1242 |     41.528 |     2.7
   15 |   1.1328 |     41.603 |   1.1295 |     41.189 |     2.9
   16 |   1.1310 |     41.570 |   1.1090 |     41.374 |     3.1
   17 |   1.1252 |     41.178 |   1.1079 |     40.080 |     3.2
   18 |   1.1225 |     41.460 |   1.1108 |     41.128 |     3.4
   19 |   1.1178 |     41.134 |   1.1026 |     40.665 |     3.6
   20 |   1.1127 |     41.333 |   1.1068 |     41.128 |     3.8
   21 |   1.1139 |     41.234 |   1.1048 |     41.251 |     4.0
   22 |   1.1099 |     41.079 |   1.1034 |     40.357 |     4.2
   23 |   1.1087 |     40.985 |   1.1121 |     41.497 |     4.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 392,098

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7165 |     49.553 |   1.3433 |     46.118 |     0.1
    2 |   1.3261 |     45.266 |   1.2611 |     43.746 |     0.2
    3 |   1.2663 |     43.992 |   1.2157 |     43.376 |     0.3
    4 |   1.2225 |     43.341 |   1.1958 |     42.514 |     0.4
    5 |   1.2041 |     43.231 |   1.1855 |     43.993 |     0.6
    6 |   1.1863 |     42.668 |   1.1758 |     43.654 |     0.7
    7 |   1.1726 |     42.034 |   1.1610 |     42.083 |     0.8
    8 |   1.1652 |     42.227 |   1.1500 |     41.590 |     0.9
    9 |   1.1574 |     42.072 |   1.1509 |     42.483 |     1.0
   10 |   1.1493 |     41.813 |   1.1318 |     40.974 |     1.1
   11 |   1.1407 |     41.791 |   1.1452 |     42.329 |     1.2
   12 |   1.1382 |     41.570 |   1.1286 |     41.405 |     1.3
   13 |   1.1313 |     41.223 |   1.1214 |     41.343 |     1.5
   14 |   1.1245 |     41.018 |   1.1186 |     41.220 |     1.6
   15 |   1.1249 |     41.548 |   1.1076 |     40.388 |     1.7
   16 |   1.1181 |     41.178 |   1.1105 |     41.405 |     1.8
   17 |   1.1131 |     41.151 |   1.1150 |     41.035 |     1.9
   18 |   1.1099 |     41.090 |   1.1143 |     41.774 |     2.0
   19 |   1.1085 |     40.798 |   1.1026 |     40.974 |     2.1
   20 |   1.1008 |     40.864 |   1.1062 |     40.142 |     2.2
   21 |   1.1001 |     40.588 |   1.0976 |     40.111 |     2.3
   22 |   1.0868 |     39.727 |   1.1067 |     39.864 |     2.4
   23 |   1.0847 |     39.380 |   1.0895 |     39.094 |     2.6
   24 |   1.0738 |     39.087 |   1.1073 |     40.450 |     2.7
   25 |   1.0654 |     38.928 |   1.0924 |     39.125 |     2.8
   26 |   1.0609 |     38.674 |   1.1442 |     41.004 |     2.9
   27 |   1.0526 |     38.094 |   1.1363 |     41.158 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 393,506

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6793 |     66.076 |   1.9210 |     46.334 |     0.2
    2 |   1.8309 |     46.712 |   1.5838 |     45.256 |     0.3
    3 |   1.6028 |     45.868 |   1.4833 |     45.533 |     0.5
    4 |   1.5045 |     45.283 |   1.4260 |     44.824 |     0.7
    5 |   1.4451 |     44.825 |   1.3852 |     43.685 |     0.8
    6 |   1.4021 |     44.472 |   1.3531 |     44.640 |     1.0
    7 |   1.3711 |     44.147 |   1.3241 |     43.192 |     1.2
    8 |   1.3416 |     43.970 |   1.3095 |     43.962 |     1.3
    9 |   1.3174 |     43.093 |   1.2779 |     43.007 |     1.5
   10 |   1.2944 |     42.806 |   1.2682 |     42.699 |     1.7
   11 |   1.2744 |     42.420 |   1.2596 |     42.853 |     1.9
   12 |   1.2558 |     41.736 |   1.2563 |     43.099 |     2.0
   13 |   1.2416 |     41.598 |   1.2478 |     42.421 |     2.2
   14 |   1.2268 |     41.195 |   1.2442 |     42.545 |     2.4
   15 |   1.2145 |     41.184 |   1.2323 |     42.237 |     2.5
   16 |   1.1999 |     40.489 |   1.2139 |     41.343 |     2.7
   17 |   1.1933 |     40.301 |   1.2240 |     41.559 |     2.9
   18 |   1.1830 |     39.816 |   1.2293 |     41.528 |     3.0
   19 |   1.1736 |     39.667 |   1.2136 |     41.682 |     3.2
   20 |   1.1605 |     39.176 |   1.2128 |     41.713 |     3.4
   21 |   1.1570 |     39.148 |   1.2000 |     40.881 |     3.5
   22 |   1.1481 |     38.850 |   1.2267 |     42.298 |     3.7
   23 |   1.1400 |     39.121 |   1.1878 |     40.850 |     3.9
   24 |   1.1312 |     38.657 |   1.1921 |     40.912 |     4.1
   25 |   1.1216 |     38.039 |   1.1966 |     40.665 |     4.2
   26 |   1.1161 |     37.581 |   1.2168 |     41.744 |     4.4
   27 |   1.1062 |     37.261 |   1.1973 |     40.819 |     4.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 235,042

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6429 |     47.567 |   1.3206 |     42.575 |     0.1
    2 |   1.2626 |     42.183 |   1.2370 |     42.545 |     0.2
    3 |   1.1814 |     40.820 |   1.1556 |     40.173 |     0.3
    4 |   1.1148 |     38.608 |   1.1236 |     38.817 |     0.4
    5 |   1.0597 |     36.715 |   1.0819 |     38.232 |     0.4
    6 |   1.0184 |     35.513 |   1.0537 |     36.506 |     0.5
    7 |   0.9753 |     33.951 |   1.0541 |     36.969 |     0.6
    8 |   0.9394 |     32.616 |   1.0134 |     35.767 |     0.7
    9 |   0.9040 |     31.386 |   1.0504 |     36.075 |     0.8
   10 |   0.8792 |     30.431 |   1.0041 |     34.227 |     0.9
   11 |   0.8331 |     28.683 |   1.0016 |     34.381 |     1.0
   12 |   0.8116 |     28.186 |   0.9920 |     33.118 |     1.1
   13 |   0.7852 |     26.807 |   0.9933 |     33.919 |     1.1
   14 |   0.7485 |     25.676 |   1.0007 |     33.395 |     1.2
   15 |   0.7114 |     24.523 |   1.0027 |     33.303 |     1.3
   16 |   0.6780 |     23.232 |   0.9971 |     33.518 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 458,850

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6975 |     63.395 |   1.9286 |     47.135 |     0.1
    2 |   1.8977 |     46.795 |   1.6116 |     47.104 |     0.2
    3 |   1.6585 |     46.260 |   1.5113 |     45.841 |     0.3
    4 |   1.5584 |     46.160 |   1.4622 |     45.102 |     0.5
    5 |   1.5000 |     45.912 |   1.4246 |     45.040 |     0.6
    6 |   1.4560 |     45.515 |   1.3941 |     44.516 |     0.7
    7 |   1.4219 |     45.206 |   1.3718 |     44.085 |     0.8
    8 |   1.3928 |     44.913 |   1.3493 |     44.301 |     0.9
    9 |   1.3720 |     44.439 |   1.3372 |     44.239 |     1.0
   10 |   1.3495 |     43.948 |   1.3177 |     43.469 |     1.2
   11 |   1.3323 |     43.976 |   1.3257 |     43.746 |     1.3
   12 |   1.3135 |     43.413 |   1.3104 |     44.054 |     1.4
   13 |   1.2995 |     43.120 |   1.3096 |     43.623 |     1.5
   14 |   1.2814 |     42.696 |   1.2761 |     43.407 |     1.6
   15 |   1.2677 |     42.403 |   1.2738 |     43.007 |     1.8
   16 |   1.2568 |     42.232 |   1.2495 |     42.760 |     1.9
   17 |   1.2495 |     41.824 |   1.2509 |     42.391 |     2.0
   18 |   1.2364 |     41.703 |   1.2525 |     42.421 |     2.1
   19 |   1.2249 |     41.388 |   1.2191 |     41.405 |     2.2
   20 |   1.2197 |     41.195 |   1.2493 |     42.021 |     2.4
   21 |   1.2059 |     40.941 |   1.2334 |     41.620 |     2.5
   22 |   1.1966 |     40.831 |   1.2067 |     41.343 |     2.6
   23 |   1.1939 |     40.555 |   1.1933 |     41.220 |     2.7
   24 |   1.1820 |     40.246 |   1.2026 |     40.850 |     2.8
   25 |   1.1758 |     40.246 |   1.1809 |     40.388 |     2.9
   26 |   1.1665 |     39.937 |   1.1982 |     40.789 |     3.1
   27 |   1.1621 |     39.738 |   1.1885 |     40.696 |     3.2
   28 |   1.1555 |     39.738 |   1.1660 |     39.988 |     3.3
   29 |   1.1476 |     39.523 |   1.1720 |     40.111 |     3.5
   30 |   1.1465 |     39.363 |   1.1676 |     39.772 |     3.6
   31 |   1.1323 |     38.905 |   1.1770 |     40.049 |     3.7
   32 |   1.1281 |     38.768 |   1.1474 |     38.909 |     3.8
   33 |   1.1245 |     38.608 |   1.1710 |     39.372 |     4.0
   34 |   1.1162 |     38.282 |   1.1590 |     39.217 |     4.1
   35 |   1.1128 |     38.194 |   1.1631 |     39.279 |     4.2
   36 |   1.1054 |     37.835 |   1.1604 |     38.879 |     4.3
   37 |   1.1029 |     37.945 |   1.1421 |     38.940 |     4.4
   38 |   1.0925 |     37.609 |   1.1445 |     38.725 |     4.6
   39 |   1.0901 |     37.598 |   1.1606 |     39.310 |     4.7
   40 |   1.0808 |     36.699 |   1.1576 |     39.063 |     4.8
   41 |   1.0785 |     36.859 |   1.1403 |     38.201 |     4.9
   42 |   1.0711 |     36.803 |   1.1268 |     37.862 |     5.0
   43 |   1.0651 |     36.461 |   1.1482 |     38.663 |     5.2
   44 |   1.0651 |     36.572 |   1.1348 |     37.954 |     5.3
   45 |   1.0613 |     36.235 |   1.1287 |     38.509 |     5.4
   46 |   1.0505 |     36.015 |   1.1310 |     37.739 |     5.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 235,042

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9528 |     74.313 |   2.2270 |     54.251 |     0.1
    2 |   2.1866 |     51.192 |   1.7246 |     47.258 |     0.2
    3 |   1.7949 |     46.927 |   1.5552 |     45.656 |     0.3
    4 |   1.6328 |     46.331 |   1.4869 |     45.625 |     0.4
    5 |   1.5502 |     46.088 |   1.4471 |     44.978 |     0.5
    6 |   1.5025 |     45.962 |   1.4218 |     44.886 |     0.6
    7 |   1.4679 |     45.746 |   1.4065 |     45.040 |     0.7
    8 |   1.4422 |     45.597 |   1.3822 |     44.640 |     0.8
    9 |   1.4236 |     45.564 |   1.3738 |     45.410 |     0.9
   10 |   1.4009 |     45.355 |   1.3560 |     45.656 |     1.0
   11 |   1.3835 |     44.946 |   1.3395 |     44.917 |     1.1
   12 |   1.3660 |     44.875 |   1.3197 |     44.578 |     1.2
   13 |   1.3506 |     44.257 |   1.3084 |     44.516 |     1.3
   14 |   1.3354 |     43.976 |   1.3043 |     44.270 |     1.4
   15 |   1.3205 |     43.854 |   1.2826 |     43.469 |     1.5
   16 |   1.3112 |     43.418 |   1.2798 |     43.962 |     1.6
   17 |   1.2962 |     43.104 |   1.2649 |     42.945 |     1.7
   18 |   1.2892 |     42.900 |   1.2547 |     42.606 |     1.8
   19 |   1.2791 |     42.944 |   1.2476 |     41.620 |     1.9
   20 |   1.2706 |     42.613 |   1.2463 |     42.452 |     2.0
   21 |   1.2629 |     42.387 |   1.2406 |     42.514 |     2.1
   22 |   1.2519 |     42.061 |   1.2335 |     42.452 |     2.2
   23 |   1.2474 |     41.907 |   1.2316 |     42.606 |     2.4
   24 |   1.2361 |     41.868 |   1.2243 |     41.405 |     2.5
   25 |   1.2341 |     41.785 |   1.2169 |     41.312 |     2.6
   26 |   1.2226 |     41.261 |   1.2074 |     41.066 |     2.7
   27 |   1.2207 |     41.305 |   1.2000 |     40.665 |     2.8
   28 |   1.2149 |     41.311 |   1.2045 |     41.251 |     2.9
   29 |   1.2057 |     40.732 |   1.2006 |     40.912 |     3.0
   30 |   1.1998 |     40.660 |   1.1953 |     40.974 |     3.1
   31 |   1.1939 |     40.605 |   1.1891 |     40.573 |     3.2
   32 |   1.1893 |     40.456 |   1.1896 |     40.419 |     3.3
   33 |   1.1795 |     40.108 |   1.1811 |     40.635 |     3.4
   34 |   1.1732 |     40.009 |   1.1829 |     40.696 |     3.5
   35 |   1.1712 |     40.042 |   1.1708 |     39.803 |     3.6
   36 |   1.1641 |     40.053 |   1.1803 |     40.388 |     3.7
   37 |   1.1587 |     39.545 |   1.1785 |     40.450 |     3.8
   38 |   1.1522 |     39.628 |   1.1665 |     39.680 |     3.9
   39 |   1.1508 |     39.474 |   1.1802 |     40.511 |     4.0
   40 |   1.1458 |     39.330 |   1.1888 |     40.789 |     4.1
   41 |   1.1420 |     39.060 |   1.1685 |     40.142 |     4.2
   42 |   1.1425 |     39.043 |   1.1656 |     39.834 |     4.3
   43 |   1.1309 |     38.817 |   1.1604 |     39.988 |     4.4
   44 |   1.1324 |     38.977 |   1.1639 |     39.556 |     4.5
   45 |   1.1277 |     38.751 |   1.1690 |     39.156 |     4.6
   46 |   1.1196 |     38.508 |   1.1629 |     39.310 |     4.7
   47 |   1.1158 |     38.596 |   1.1573 |     39.433 |     4.8
   48 |   1.1121 |     38.061 |   1.1582 |     39.372 |     4.9
   49 |   1.1106 |     38.194 |   1.1573 |     39.372 |     5.0
   50 |   1.1046 |     37.670 |   1.1534 |     38.755 |     5.1
   51 |   1.1021 |     37.808 |   1.1514 |     38.725 |     5.2
   52 |   1.0989 |     37.719 |   1.1689 |     39.279 |     5.3
   53 |   1.0972 |     37.681 |   1.1569 |     39.063 |     5.4
   54 |   1.0864 |     37.432 |   1.1505 |     38.540 |     5.5
   55 |   1.0905 |     37.350 |   1.1384 |     38.755 |     5.6
   56 |   1.0816 |     37.079 |   1.1567 |     38.293 |     5.7
   57 |   1.0772 |     36.903 |   1.1406 |     38.509 |     5.8
   58 |   1.0749 |     36.886 |   1.1431 |     38.170 |     5.9
   59 |   1.0724 |     36.688 |   1.1351 |     38.417 |     6.0
   60 |   1.0700 |     36.627 |   1.1318 |     38.540 |     6.1
   61 |   1.0679 |     36.445 |   1.1350 |     38.540 |     6.2
   62 |   1.0657 |     36.335 |   1.1367 |     38.601 |     6.3
   63 |   1.0565 |     36.053 |   1.1345 |     38.170 |     6.4
   64 |   1.0555 |     35.937 |   1.1299 |     37.862 |     6.5
   65 |   1.0495 |     35.954 |   1.1374 |     38.047 |     6.6
   66 |   1.0474 |     35.998 |   1.1321 |     38.108 |     6.7
   67 |   1.0428 |     35.821 |   1.1362 |     37.708 |     6.8
   68 |   1.0437 |     35.717 |   1.1276 |     37.831 |     6.9
   69 |   1.0401 |     35.513 |   1.1280 |     38.108 |     7.0
   70 |   1.0360 |     35.706 |   1.1346 |     38.447 |     7.1
   71 |   1.0334 |     35.397 |   1.1293 |     37.708 |     7.2
   72 |   1.0296 |     35.341 |   1.1340 |     37.800 |     7.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 458,850

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2855 |     55.980 |   1.7252 |     45.533 |     0.1
    2 |   1.5950 |     45.625 |   1.5257 |     45.102 |     0.2
    3 |   1.4661 |     44.748 |   1.4322 |     43.869 |     0.3
    4 |   1.3944 |     43.650 |   1.3814 |     43.315 |     0.5
    5 |   1.3460 |     42.966 |   1.3517 |     42.822 |     0.6
    6 |   1.3054 |     42.127 |   1.3334 |     43.746 |     0.7
    7 |   1.2762 |     41.725 |   1.2934 |     43.376 |     0.8
    8 |   1.2464 |     41.162 |   1.2827 |     43.438 |     0.9
    9 |   1.2197 |     40.599 |   1.2842 |     43.192 |     1.0
   10 |   1.1966 |     39.865 |   1.2496 |     42.113 |     1.1
   11 |   1.1743 |     38.977 |   1.2386 |     41.867 |     1.2
   12 |   1.1499 |     38.503 |   1.2298 |     41.158 |     1.4
   13 |   1.1280 |     37.692 |   1.2053 |     40.943 |     1.5
   14 |   1.1166 |     37.598 |   1.1642 |     39.217 |     1.6
   15 |   1.0872 |     36.472 |   1.1930 |     40.234 |     1.7
   16 |   1.0702 |     35.926 |   1.1965 |     40.203 |     1.8
   17 |   1.0548 |     35.463 |   1.1914 |     40.542 |     1.9
   18 |   1.0358 |     34.806 |   1.1570 |     38.786 |     2.0
   19 |   1.0252 |     34.547 |   1.1478 |     38.632 |     2.1
   20 |   1.0027 |     33.482 |   1.1491 |     38.293 |     2.2
   21 |   0.9894 |     33.173 |   1.1684 |     39.125 |     2.4
   22 |   0.9733 |     32.572 |   1.1269 |     38.262 |     2.5
   23 |   0.9592 |     32.423 |   1.1301 |     37.677 |     2.6
   24 |   0.9485 |     31.860 |   1.1717 |     38.786 |     2.7
   25 |   0.9317 |     31.132 |   1.1522 |     38.201 |     2.8
   26 |   0.9206 |     30.713 |   1.1308 |     37.862 |     2.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 44 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 814,114

Training started
X_train.shape: torch.Size([3021, 702])
Y_train.shape: torch.Size([3021, 7])
X_dev.shape: torch.Size([541, 250])
Y_dev.shape: torch.Size([541, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9907 |     50.392 |   1.5324 |     46.149 |     0.1
    2 |   1.4385 |     45.101 |   1.4077 |     44.732 |     0.2
    3 |   1.3381 |     43.170 |   1.3400 |     44.177 |     0.3
    4 |   1.2760 |     41.647 |   1.3230 |     43.654 |     0.4
    5 |   1.2269 |     40.384 |   1.2691 |     42.545 |     0.5
    6 |   1.1872 |     39.656 |   1.2546 |     42.452 |     0.6
    7 |   1.1557 |     38.768 |   1.2029 |     41.189 |     0.7
    8 |   1.1291 |     38.376 |   1.2085 |     40.943 |     0.8
    9 |   1.1016 |     37.394 |   1.1610 |     39.710 |     1.0
   10 |   1.0721 |     36.555 |   1.1708 |     40.111 |     1.1
   11 |   1.0492 |     35.728 |   1.1268 |     39.680 |     1.2
   12 |   1.0240 |     35.066 |   1.1177 |     38.540 |     1.3
   13 |   1.0071 |     34.348 |   1.1061 |     38.262 |     1.4
   14 |   0.9740 |     33.223 |   1.0932 |     37.338 |     1.5
   15 |   0.9521 |     31.938 |   1.1058 |     38.078 |     1.6
   16 |   0.9355 |     31.612 |   1.0959 |     38.478 |     1.7
   17 |   0.9075 |     30.779 |   1.0883 |     37.862 |     1.8
   18 |   0.8845 |     29.521 |   1.0992 |     37.616 |     1.9
   19 |   0.8635 |     28.820 |   1.0839 |     37.585 |     2.0
   20 |   0.8410 |     28.307 |   1.0717 |     36.168 |     2.1
   21 |   0.8229 |     27.612 |   1.0604 |     36.106 |     2.2
   22 |   0.7987 |     26.890 |   1.0652 |     35.921 |     2.3
   23 |   0.7817 |     26.090 |   1.1015 |     36.661 |     2.4
   24 |   0.7685 |     25.577 |   1.0453 |     35.243 |     2.6
   25 |   0.7454 |     24.931 |   1.0899 |     36.876 |     2.7
   26 |   0.7265 |     24.286 |   1.0781 |     36.661 |     2.8
   27 |   0.7060 |     23.298 |   1.0545 |     35.428 |     2.9
   28 |   0.6851 |     23.000 |   1.1233 |     37.030 |     3.0
Early stopping

