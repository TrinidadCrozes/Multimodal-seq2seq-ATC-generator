Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 343,265

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7393 |     49.978 |   1.3626 |     46.834 |     0.1
    2 |   1.3382 |     44.766 |   1.2737 |     45.220 |     0.2
    3 |   1.2750 |     43.807 |   1.2230 |     44.072 |     0.3
    4 |   1.2333 |     43.223 |   1.1877 |     42.644 |     0.4
    5 |   1.2033 |     42.463 |   1.1742 |     43.017 |     0.5
    6 |   1.1830 |     41.598 |   1.1619 |     42.241 |     0.6
    7 |   1.1650 |     41.201 |   1.1591 |     41.589 |     0.8
    8 |   1.1558 |     40.645 |   1.1258 |     40.689 |     0.9
    9 |   1.1358 |     40.171 |   1.1220 |     40.255 |     1.0
   10 |   1.1292 |     40.116 |   1.1185 |     40.410 |     1.1
   11 |   1.1174 |     39.752 |   1.1043 |     39.230 |     1.2
   12 |   1.1085 |     39.460 |   1.0978 |     39.479 |     1.3
   13 |   1.1008 |     39.085 |   1.0845 |     39.292 |     1.4
   14 |   1.0866 |     38.854 |   1.0869 |     39.354 |     1.5
   15 |   1.0786 |     38.408 |   1.0713 |     39.479 |     1.6
   16 |   1.0642 |     38.088 |   1.0647 |     37.865 |     1.7
   17 |   1.0568 |     37.747 |   1.0440 |     37.027 |     1.8
   18 |   1.0523 |     37.890 |   1.0375 |     37.523 |     2.0
   19 |   1.0364 |     37.058 |   1.0329 |     36.778 |     2.1
   20 |   1.0282 |     37.157 |   1.0256 |     36.313 |     2.2
   21 |   1.0175 |     36.424 |   1.0245 |     36.996 |     2.3
   22 |   1.0091 |     35.592 |   1.0223 |     36.096 |     2.4
   23 |   0.9983 |     35.493 |   1.0350 |     36.809 |     2.5
   24 |   0.9961 |     35.691 |   1.0043 |     34.606 |     2.6
   25 |   0.9800 |     35.091 |   1.0007 |     35.382 |     2.7
   26 |   0.9757 |     34.815 |   0.9997 |     34.978 |     2.8
   27 |   0.9734 |     34.479 |   0.9894 |     34.823 |     2.9
   28 |   0.9581 |     34.298 |   0.9864 |     34.358 |     3.1
   29 |   0.9562 |     33.758 |   0.9775 |     34.420 |     3.2
   30 |   0.9566 |     34.006 |   0.9691 |     33.892 |     3.3
   31 |   0.9409 |     33.273 |   0.9688 |     33.892 |     3.4
   32 |   0.9307 |     32.832 |   0.9746 |     33.861 |     3.5
   33 |   0.9292 |     32.837 |   0.9733 |     33.644 |     3.6
   34 |   0.9225 |     32.612 |   0.9580 |     33.799 |     3.7
   35 |   0.9165 |     32.187 |   0.9620 |     33.178 |     3.8
   36 |   0.9041 |     32.116 |   0.9621 |     33.054 |     3.9
   37 |   0.9026 |     32.193 |   0.9585 |     33.644 |     4.1
   38 |   0.8944 |     31.818 |   0.9626 |     33.830 |     4.2
   39 |   0.8857 |     31.565 |   0.9554 |     32.464 |     4.3
   40 |   0.8755 |     31.135 |   0.9540 |     32.930 |     4.4
   41 |   0.8686 |     30.705 |   0.9546 |     32.526 |     4.5
   42 |   0.8605 |     30.331 |   0.9609 |     31.906 |     4.6
   43 |   0.8610 |     30.562 |   0.9426 |     32.247 |     4.7
   44 |   0.8426 |     29.989 |   0.9809 |     32.744 |     4.8
   45 |   0.8391 |     29.405 |   0.9595 |     32.278 |     4.9
   46 |   0.8341 |     29.405 |   0.9551 |     32.030 |     5.0
   47 |   0.8295 |     29.581 |   0.9502 |     31.502 |     5.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 980,001

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2519 |     57.174 |   1.5519 |     46.586 |     0.1
    2 |   1.5288 |     45.669 |   1.4034 |     45.220 |     0.2
    3 |   1.4117 |     44.865 |   1.3430 |     44.507 |     0.3
    4 |   1.3558 |     43.873 |   1.3015 |     43.824 |     0.4
    5 |   1.3094 |     43.014 |   1.2593 |     43.203 |     0.5
    6 |   1.2791 |     42.424 |   1.2408 |     42.644 |     0.6
    7 |   1.2516 |     41.691 |   1.2197 |     42.520 |     0.7
    8 |   1.2248 |     41.229 |   1.2167 |     43.575 |     0.8
    9 |   1.2045 |     40.766 |   1.1950 |     41.651 |     0.9
   10 |   1.1843 |     40.204 |   1.1808 |     40.782 |     1.0
   11 |   1.1688 |     39.785 |   1.1818 |     41.806 |     1.1
   12 |   1.1545 |     39.410 |   1.1516 |     40.317 |     1.2
   13 |   1.1384 |     38.926 |   1.1826 |     41.217 |     1.3
   14 |   1.1205 |     38.303 |   1.1662 |     40.720 |     1.4
   15 |   1.1083 |     38.066 |   1.1833 |     40.906 |     1.5
   16 |   1.0911 |     37.047 |   1.1459 |     40.689 |     1.6
   17 |   1.0819 |     37.129 |   1.1541 |     40.192 |     1.7
   18 |   1.0653 |     36.474 |   1.1227 |     39.013 |     1.8
   19 |   1.0514 |     35.851 |   1.1191 |     39.013 |     1.9
   20 |   1.0394 |     35.300 |   1.1249 |     39.075 |     2.0
   21 |   1.0226 |     34.595 |   1.1329 |     39.013 |     2.1
   22 |   1.0133 |     34.507 |   1.1268 |     38.516 |     2.2
   23 |   0.9977 |     34.143 |   1.1217 |     38.237 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 293,025

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7351 |     48.727 |   1.3722 |     45.686 |     0.1
    2 |   1.3360 |     44.904 |   1.2822 |     45.996 |     0.2
    3 |   1.2837 |     44.645 |   1.2385 |     44.817 |     0.3
    4 |   1.2417 |     43.251 |   1.1859 |     41.527 |     0.4
    5 |   1.2084 |     41.917 |   1.1904 |     41.651 |     0.5
    6 |   1.1870 |     41.609 |   1.1939 |     41.558 |     0.6
    7 |   1.1661 |     41.069 |   1.1266 |     39.448 |     0.7
    8 |   1.1508 |     40.463 |   1.1313 |     40.782 |     0.8
    9 |   1.1298 |     39.725 |   1.1048 |     39.603 |     0.9
   10 |   1.1177 |     39.482 |   1.0987 |     40.223 |     1.0
   11 |   1.1083 |     39.543 |   1.0982 |     39.541 |     1.1
   12 |   1.0943 |     38.474 |   1.0860 |     39.479 |     1.2
   13 |   1.0885 |     38.760 |   1.0863 |     38.765 |     1.3
   14 |   1.0736 |     37.989 |   1.0874 |     39.199 |     1.4
   15 |   1.0635 |     37.664 |   1.0774 |     39.230 |     1.6
   16 |   1.0565 |     37.906 |   1.0790 |     38.703 |     1.7
   17 |   1.0451 |     37.284 |   1.0700 |     38.330 |     1.8
   18 |   1.0373 |     36.953 |   1.0494 |     37.089 |     1.9
   19 |   1.0258 |     36.408 |   1.0308 |     37.275 |     2.0
   20 |   1.0177 |     36.160 |   1.0263 |     37.027 |     2.1
   21 |   1.0084 |     35.895 |   1.0374 |     37.244 |     2.2
   22 |   1.0032 |     35.796 |   1.0523 |     37.772 |     2.3
   23 |   0.9945 |     35.240 |   1.0303 |     36.965 |     2.4
   24 |   0.9862 |     35.102 |   1.0251 |     36.002 |     2.5
   25 |   0.9795 |     34.810 |   1.0421 |     36.282 |     2.6
   26 |   0.9680 |     34.281 |   1.0300 |     36.220 |     2.7
   27 |   0.9574 |     33.912 |   1.0128 |     35.506 |     2.8
   28 |   0.9512 |     33.680 |   1.0151 |     35.878 |     2.9
   29 |   0.9439 |     33.339 |   0.9989 |     35.196 |     3.0
   30 |   0.9282 |     32.964 |   1.0147 |     34.544 |     3.1
   31 |   0.9245 |     32.650 |   0.9932 |     34.420 |     3.2
   32 |   0.9195 |     32.281 |   1.0009 |     34.451 |     3.3
   33 |   0.9044 |     31.956 |   1.0023 |     34.792 |     3.4
   34 |   0.9052 |     31.857 |   0.9911 |     34.513 |     3.5
   35 |   0.8845 |     31.019 |   1.0036 |     33.706 |     3.6
   36 |   0.8832 |     30.981 |   1.0026 |     34.078 |     3.7
   37 |   0.8696 |     31.152 |   0.9962 |     33.923 |     3.8
   38 |   0.8575 |     30.237 |   0.9837 |     33.271 |     3.9
   39 |   0.8498 |     29.686 |   0.9994 |     33.830 |     4.0
   40 |   0.8440 |     29.311 |   1.0094 |     33.923 |     4.1
   41 |   0.8302 |     29.306 |   1.0077 |     33.644 |     4.2
   42 |   0.8253 |     29.085 |   0.9868 |     33.954 |     4.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 343,265

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7779 |     50.507 |   1.3858 |     46.741 |     0.2
    2 |   1.3812 |     45.873 |   1.2944 |     45.779 |     0.3
    3 |   1.3167 |     44.744 |   1.2527 |     45.220 |     0.5
    4 |   1.2849 |     44.683 |   1.2237 |     44.258 |     0.6
    5 |   1.2549 |     44.044 |   1.2158 |     43.700 |     0.8
    6 |   1.2410 |     43.901 |   1.1888 |     43.637 |     0.9
    7 |   1.2209 |     43.300 |   1.1917 |     43.886 |     1.1
    8 |   1.2095 |     43.240 |   1.1713 |     42.737 |     1.3
    9 |   1.1948 |     42.551 |   1.1683 |     43.265 |     1.4
   10 |   1.1855 |     42.485 |   1.1603 |     41.806 |     1.6
   11 |   1.1816 |     42.391 |   1.1540 |     41.837 |     1.7
   12 |   1.1720 |     41.890 |   1.1438 |     41.962 |     1.9
   13 |   1.1659 |     42.281 |   1.1362 |     41.217 |     2.1
   14 |   1.1617 |     41.741 |   1.1290 |     41.713 |     2.2
   15 |   1.1518 |     41.565 |   1.1399 |     42.148 |     2.4
   16 |   1.1506 |     41.515 |   1.1239 |     41.248 |     2.5
   17 |   1.1411 |     41.466 |   1.1261 |     41.527 |     2.7
   18 |   1.1411 |     41.625 |   1.1297 |     41.930 |     2.9
   19 |   1.1362 |     41.157 |   1.1233 |     41.465 |     3.0
   20 |   1.1294 |     41.609 |   1.1196 |     41.030 |     3.2
   21 |   1.1282 |     41.207 |   1.1131 |     41.341 |     3.3
   22 |   1.1256 |     41.251 |   1.1082 |     40.627 |     3.5
   23 |   1.1236 |     40.893 |   1.1158 |     41.620 |     3.6
   24 |   1.1223 |     40.970 |   1.1086 |     41.124 |     3.8
   25 |   1.1168 |     40.871 |   1.1001 |     41.372 |     4.0
   26 |   1.1177 |     41.267 |   1.1154 |     41.372 |     4.1
   27 |   1.1126 |     40.799 |   1.1008 |     41.092 |     4.3
   28 |   1.1114 |     40.887 |   1.0966 |     40.658 |     4.4
   29 |   1.1071 |     40.766 |   1.1000 |     40.937 |     4.6
   30 |   1.1070 |     40.898 |   1.1012 |     41.558 |     4.8
   31 |   1.0985 |     40.386 |   1.0918 |     39.758 |     4.9
   32 |   1.0908 |     39.691 |   1.0974 |     40.844 |     5.1
   33 |   1.0815 |     39.350 |   1.0896 |     40.503 |     5.2
   34 |   1.0810 |     39.085 |   1.0939 |     40.037 |     5.4
   35 |   1.0741 |     38.898 |   1.0753 |     39.448 |     5.5
   36 |   1.0674 |     38.871 |   1.0972 |     40.006 |     5.7
   37 |   1.0643 |     38.639 |   1.0870 |     39.789 |     5.9
   38 |   1.0560 |     38.380 |   1.0922 |     40.099 |     6.0
   39 |   1.0497 |     38.149 |   1.0968 |     40.410 |     6.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 327,457

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6985 |     64.083 |   2.0341 |     49.752 |     0.2
    2 |   1.9221 |     47.868 |   1.6342 |     47.238 |     0.3
    3 |   1.6551 |     46.309 |   1.5167 |     47.145 |     0.5
    4 |   1.5455 |     45.835 |   1.4714 |     46.772 |     0.7
    5 |   1.4863 |     45.537 |   1.4162 |     46.555 |     0.8
    6 |   1.4445 |     45.510 |   1.3892 |     45.779 |     1.0
    7 |   1.4101 |     44.716 |   1.3652 |     45.748 |     1.1
    8 |   1.3861 |     44.479 |   1.3426 |     45.096 |     1.3
    9 |   1.3670 |     44.270 |   1.3227 |     44.755 |     1.5
   10 |   1.3469 |     44.061 |   1.3122 |     44.941 |     1.6
   11 |   1.3296 |     43.939 |   1.2930 |     43.824 |     1.8
   12 |   1.3141 |     43.763 |   1.2778 |     43.948 |     2.0
   13 |   1.2995 |     43.278 |   1.2677 |     43.544 |     2.1
   14 |   1.2863 |     42.848 |   1.2551 |     42.520 |     2.3
   15 |   1.2761 |     42.843 |   1.2457 |     42.644 |     2.5
   16 |   1.2662 |     42.336 |   1.2471 |     42.986 |     2.6
   17 |   1.2508 |     41.846 |   1.2262 |     42.148 |     2.8
   18 |   1.2414 |     41.928 |   1.2224 |     42.272 |     3.0
   19 |   1.2349 |     41.708 |   1.2162 |     42.086 |     3.1
   20 |   1.2233 |     41.339 |   1.2109 |     41.527 |     3.3
   21 |   1.2151 |     40.931 |   1.1945 |     41.372 |     3.4
   22 |   1.2097 |     41.129 |   1.1857 |     40.999 |     3.6
   23 |   1.1992 |     40.953 |   1.1838 |     40.844 |     3.8
   24 |   1.1918 |     40.749 |   1.1785 |     41.030 |     3.9
   25 |   1.1818 |     40.033 |   1.1676 |     40.844 |     4.1
   26 |   1.1732 |     40.584 |   1.1586 |     40.037 |     4.3
   27 |   1.1644 |     39.961 |   1.1615 |     40.286 |     4.4
   28 |   1.1595 |     39.736 |   1.1543 |     40.099 |     4.6
   29 |   1.1508 |     39.708 |   1.1466 |     39.106 |     4.8
   30 |   1.1441 |     39.317 |   1.1393 |     39.385 |     4.9
   31 |   1.1403 |     39.118 |   1.1340 |     39.261 |     5.1
   32 |   1.1309 |     38.562 |   1.1305 |     38.765 |     5.3
   33 |   1.1249 |     38.534 |   1.1298 |     39.230 |     5.4
   34 |   1.1155 |     38.512 |   1.1248 |     38.703 |     5.6
   35 |   1.1102 |     38.132 |   1.1212 |     38.113 |     5.7
   36 |   1.1076 |     37.945 |   1.1209 |     38.206 |     5.9
   37 |   1.0969 |     37.565 |   1.1147 |     38.547 |     6.1
   38 |   1.0942 |     37.449 |   1.1153 |     38.485 |     6.2
   39 |   1.0937 |     37.725 |   1.1076 |     37.865 |     6.4
   40 |   1.0843 |     37.493 |   1.1000 |     38.020 |     6.6
   41 |   1.0766 |     36.860 |   1.1074 |     37.958 |     6.7
   42 |   1.0688 |     36.788 |   1.0960 |     37.927 |     6.9
   43 |   1.0663 |     36.705 |   1.0978 |     37.616 |     7.1
   44 |   1.0582 |     36.237 |   1.0966 |     37.741 |     7.2
   45 |   1.0484 |     36.220 |   1.0901 |     37.213 |     7.4
   46 |   1.0474 |     35.802 |   1.0988 |     37.865 |     7.6
   47 |   1.0389 |     35.587 |   1.0941 |     37.275 |     7.7
   48 |   1.0349 |     35.664 |   1.0964 |     37.554 |     7.9
   49 |   1.0404 |     35.796 |   1.0895 |     37.089 |     8.0
   50 |   1.0285 |     35.405 |   1.0875 |     36.996 |     8.2
   51 |   1.0275 |     35.449 |   1.0845 |     36.809 |     8.4
   52 |   1.0227 |     34.915 |   1.0914 |     37.306 |     8.5
   53 |   1.0130 |     34.716 |   1.0953 |     37.741 |     8.7
   54 |   1.0092 |     34.623 |   1.1029 |     37.958 |     8.9
   55 |   1.0072 |     34.457 |   1.1042 |     37.896 |     9.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 525,601

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6842 |     49.041 |   1.3524 |     46.648 |     0.1
    2 |   1.3233 |     44.926 |   1.2506 |     44.693 |     0.2
    3 |   1.2560 |     43.939 |   1.2107 |     42.800 |     0.4
    4 |   1.2275 |     43.179 |   1.1867 |     42.768 |     0.5
    5 |   1.2005 |     42.523 |   1.1800 |     42.613 |     0.6
    6 |   1.1818 |     42.127 |   1.1532 |     41.868 |     0.7
    7 |   1.1674 |     41.620 |   1.1317 |     41.248 |     0.9
    8 |   1.1485 |     40.964 |   1.1206 |     40.565 |     1.0
    9 |   1.1279 |     40.320 |   1.1061 |     39.323 |     1.1
   10 |   1.1122 |     39.521 |   1.0977 |     39.261 |     1.2
   11 |   1.1006 |     39.284 |   1.0984 |     39.323 |     1.3
   12 |   1.0960 |     39.289 |   1.0855 |     39.448 |     1.5
   13 |   1.0888 |     39.521 |   1.0784 |     39.261 |     1.6
   14 |   1.0706 |     38.617 |   1.0621 |     38.765 |     1.7
   15 |   1.0636 |     38.540 |   1.0683 |     38.392 |     1.8
   16 |   1.0558 |     38.320 |   1.0498 |     38.299 |     2.0
   17 |   1.0481 |     37.884 |   1.0657 |     38.889 |     2.1
   18 |   1.0358 |     37.901 |   1.0461 |     38.423 |     2.2
   19 |   1.0311 |     37.284 |   1.0341 |     38.020 |     2.3
   20 |   1.0263 |     37.366 |   1.0335 |     37.865 |     2.5
   21 |   1.0099 |     36.584 |   1.0255 |     37.244 |     2.6
   22 |   1.0089 |     36.408 |   1.0220 |     36.313 |     2.7
   23 |   0.9950 |     35.725 |   1.0146 |     37.058 |     2.8
   24 |   0.9928 |     36.127 |   1.0169 |     36.685 |     3.0
   25 |   0.9857 |     35.857 |   0.9998 |     35.909 |     3.1
   26 |   0.9782 |     35.262 |   1.0055 |     36.127 |     3.2
   27 |   0.9681 |     35.135 |   1.0133 |     36.406 |     3.3
   28 |   0.9623 |     34.749 |   1.0124 |     36.530 |     3.5
   29 |   0.9629 |     34.777 |   1.0102 |     36.220 |     3.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 1,013,281

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1633 |     53.796 |   1.5481 |     46.276 |     0.2
    2 |   1.5182 |     45.791 |   1.4026 |     46.151 |     0.4
    3 |   1.4099 |     44.567 |   1.3415 |     44.134 |     0.6
    4 |   1.3474 |     43.466 |   1.2982 |     44.165 |     0.8
    5 |   1.3066 |     42.733 |   1.2571 |     43.172 |     1.0
    6 |   1.2721 |     42.116 |   1.2430 |     43.296 |     1.1
    7 |   1.2371 |     41.537 |   1.2312 |     42.768 |     1.3
    8 |   1.2139 |     40.948 |   1.2039 |     41.930 |     1.5
    9 |   1.1911 |     39.829 |   1.2124 |     42.334 |     1.7
   10 |   1.1704 |     39.377 |   1.1680 |     40.161 |     1.9
   11 |   1.1524 |     38.639 |   1.1635 |     40.255 |     2.1
   12 |   1.1283 |     38.143 |   1.1544 |     40.348 |     2.3
   13 |   1.1142 |     37.983 |   1.1432 |     39.975 |     2.5
   14 |   1.0965 |     37.377 |   1.1343 |     39.665 |     2.6
   15 |   1.0822 |     36.793 |   1.1058 |     37.989 |     2.8
   16 |   1.0606 |     36.391 |   1.1225 |     38.299 |     3.0
   17 |   1.0473 |     35.521 |   1.1015 |     37.368 |     3.2
   18 |   1.0285 |     34.953 |   1.1104 |     37.958 |     3.4
   19 |   1.0147 |     34.446 |   1.1040 |     37.989 |     3.6
   20 |   1.0023 |     34.176 |   1.0661 |     36.282 |     3.8
   21 |   0.9910 |     33.510 |   1.0964 |     37.337 |     4.0
   22 |   0.9720 |     33.047 |   1.1034 |     37.430 |     4.1
   23 |   0.9575 |     32.727 |   1.0788 |     36.592 |     4.3
   24 |   0.9441 |     31.658 |   1.0817 |     36.158 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 847,393

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1663 |     55.168 |   1.5687 |     46.555 |     0.2
    2 |   1.4636 |     45.047 |   1.3976 |     45.003 |     0.3
    3 |   1.3535 |     43.306 |   1.3299 |     44.538 |     0.5
    4 |   1.2886 |     41.829 |   1.2753 |     43.296 |     0.6
    5 |   1.2398 |     40.678 |   1.2312 |     41.589 |     0.8
    6 |   1.1980 |     39.791 |   1.1989 |     41.217 |     1.0
    7 |   1.1617 |     39.003 |   1.1767 |     39.789 |     1.1
    8 |   1.1266 |     37.763 |   1.1604 |     40.037 |     1.3
    9 |   1.0946 |     36.485 |   1.1231 |     38.485 |     1.5
   10 |   1.0672 |     35.906 |   1.1143 |     37.865 |     1.6
   11 |   1.0374 |     34.601 |   1.0955 |     37.368 |     1.8
   12 |   1.0127 |     34.088 |   1.1071 |     37.741 |     2.0
   13 |   0.9830 |     32.397 |   1.0776 |     36.747 |     2.1
   14 |   0.9579 |     31.664 |   1.0796 |     37.151 |     2.3
   15 |   0.9331 |     30.854 |   1.0710 |     35.909 |     2.4
   16 |   0.9065 |     29.906 |   1.0426 |     34.823 |     2.6
   17 |   0.8803 |     28.821 |   1.0375 |     34.916 |     2.8
   18 |   0.8542 |     27.802 |   1.0541 |     35.196 |     2.9
   19 |   0.8320 |     27.399 |   1.0190 |     34.451 |     3.1
   20 |   0.8049 |     26.512 |   1.0291 |     34.482 |     3.3
   21 |   0.7792 |     25.730 |   1.0313 |     34.109 |     3.4
   22 |   0.7569 |     25.234 |   1.0231 |     33.551 |     3.6
   23 |   0.7351 |     24.105 |   1.0527 |     34.171 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,044,769

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5006 |     46.601 |   1.2863 |     44.910 |     0.1
    2 |   1.2861 |     44.623 |   1.2338 |     43.824 |     0.3
    3 |   1.2339 |     43.526 |   1.2169 |     43.017 |     0.4
    4 |   1.1987 |     42.760 |   1.1725 |     42.737 |     0.6
    5 |   1.1720 |     41.581 |   1.1467 |     41.651 |     0.7
    6 |   1.1476 |     40.722 |   1.1148 |     40.751 |     0.9
    7 |   1.1216 |     40.253 |   1.1130 |     40.813 |     1.0
    8 |   1.1112 |     40.237 |   1.1043 |     39.882 |     1.2
    9 |   1.0896 |     39.229 |   1.1017 |     39.820 |     1.3
   10 |   1.0787 |     39.008 |   1.1181 |     40.503 |     1.4
   11 |   1.0682 |     38.496 |   1.0876 |     39.479 |     1.6
   12 |   1.0544 |     37.912 |   1.0715 |     39.603 |     1.7
   13 |   1.0457 |     37.477 |   1.0610 |     38.175 |     1.9
   14 |   1.0266 |     36.628 |   1.0437 |     37.958 |     2.0
   15 |   1.0111 |     36.474 |   1.0459 |     37.058 |     2.2
   16 |   1.0031 |     36.402 |   1.0375 |     37.027 |     2.3
   17 |   0.9947 |     35.741 |   1.0313 |     36.654 |     2.5
   18 |   0.9848 |     35.471 |   1.0255 |     36.840 |     2.6
   19 |   0.9691 |     34.986 |   1.0567 |     37.120 |     2.8
   20 |   0.9557 |     34.391 |   1.0104 |     36.127 |     2.9
   21 |   0.9414 |     33.901 |   0.9979 |     35.009 |     3.0
   22 |   0.9371 |     33.697 |   1.0080 |     35.227 |     3.2
   23 |   0.9213 |     32.970 |   1.0306 |     36.375 |     3.3
   24 |   0.9143 |     32.887 |   0.9891 |     33.892 |     3.5
   25 |   0.8996 |     32.028 |   0.9957 |     34.544 |     3.6
   26 |   0.8954 |     31.758 |   1.0097 |     34.078 |     3.8
   27 |   0.8865 |     31.350 |   1.0021 |     34.606 |     3.9
   28 |   0.8674 |     30.672 |   0.9817 |     32.930 |     4.1
   29 |   0.8601 |     30.645 |   0.9798 |     33.209 |     4.2
   30 |   0.8545 |     30.231 |   1.0061 |     33.457 |     4.4
   31 |   0.8448 |     29.758 |   1.0056 |     33.830 |     4.5
   32 |   0.8390 |     29.862 |   1.0060 |     33.209 |     4.7
   33 |   0.8214 |     28.700 |   1.0043 |     33.457 |     4.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 731,873

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0925 |     53.444 |   1.5404 |     46.586 |     0.1
    2 |   1.4377 |     44.617 |   1.3761 |     46.151 |     0.2
    3 |   1.3266 |     43.278 |   1.3101 |     43.234 |     0.3
    4 |   1.2684 |     41.658 |   1.2539 |     41.620 |     0.3
    5 |   1.2235 |     40.573 |   1.2249 |     42.148 |     0.4
    6 |   1.1848 |     39.488 |   1.1908 |     40.161 |     0.5
    7 |   1.1541 |     38.810 |   1.1645 |     40.317 |     0.6
    8 |   1.1219 |     37.747 |   1.1430 |     39.044 |     0.7
    9 |   1.0904 |     36.617 |   1.1263 |     37.306 |     0.8
   10 |   1.0687 |     35.890 |   1.0979 |     36.778 |     0.9
   11 |   1.0419 |     35.025 |   1.0785 |     36.344 |     0.9
   12 |   1.0149 |     34.116 |   1.0611 |     36.437 |     1.0
   13 |   0.9907 |     32.959 |   1.0708 |     36.313 |     1.1
   14 |   0.9635 |     32.088 |   1.0669 |     35.382 |     1.2
   15 |   0.9431 |     31.240 |   1.0366 |     34.730 |     1.3
   16 |   0.9166 |     30.248 |   1.0391 |     34.947 |     1.4
   17 |   0.8956 |     29.702 |   1.0156 |     33.551 |     1.4
   18 |   0.8714 |     28.628 |   1.0015 |     33.271 |     1.5
   19 |   0.8491 |     27.967 |   1.0164 |     32.651 |     1.6
   20 |   0.8258 |     27.030 |   1.0022 |     32.464 |     1.7
   21 |   0.8062 |     26.606 |   1.0151 |     32.992 |     1.8
   22 |   0.7844 |     25.708 |   0.9928 |     31.999 |     1.9
   23 |   0.7600 |     24.711 |   0.9899 |     32.216 |     2.0
   24 |   0.7376 |     24.050 |   0.9861 |     31.347 |     2.0
   25 |   0.7201 |     23.548 |   0.9796 |     31.378 |     2.1
   26 |   0.7013 |     23.019 |   1.0030 |     32.185 |     2.2
   27 |   0.6731 |     21.846 |   0.9933 |     31.750 |     2.3
   28 |   0.6603 |     21.405 |   0.9761 |     31.316 |     2.4
   29 |   0.6362 |     20.353 |   1.0081 |     31.223 |     2.5
   30 |   0.6180 |     19.697 |   1.0053 |     31.378 |     2.6
   31 |   0.6009 |     19.074 |   1.0234 |     31.626 |     2.6
   32 |   0.5802 |     18.579 |   1.0463 |     31.719 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 193,057

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9966 |     76.441 |   2.3750 |     50.807 |     0.1
    2 |   2.2298 |     50.529 |   1.7775 |     47.145 |     0.1
    3 |   1.8144 |     46.606 |   1.5774 |     46.927 |     0.2
    4 |   1.6368 |     46.077 |   1.4961 |     46.741 |     0.2
    5 |   1.5491 |     45.840 |   1.4474 |     46.741 |     0.3
    6 |   1.4955 |     45.912 |   1.4196 |     46.648 |     0.4
    7 |   1.4551 |     45.543 |   1.3854 |     46.462 |     0.4
    8 |   1.4268 |     45.592 |   1.3687 |     46.089 |     0.5
    9 |   1.4054 |     45.168 |   1.3463 |     45.500 |     0.6
   10 |   1.3894 |     45.124 |   1.3322 |     44.693 |     0.6
   11 |   1.3704 |     44.799 |   1.3212 |     45.127 |     0.7
   12 |   1.3539 |     44.567 |   1.3100 |     44.817 |     0.7
   13 |   1.3475 |     44.463 |   1.2966 |     44.724 |     0.8
   14 |   1.3333 |     44.099 |   1.2853 |     44.351 |     0.9
   15 |   1.3214 |     44.044 |   1.2768 |     44.258 |     0.9
   16 |   1.3059 |     43.504 |   1.2652 |     44.258 |     1.0
   17 |   1.3038 |     43.758 |   1.2633 |     44.382 |     1.1
   18 |   1.2875 |     43.185 |   1.2533 |     43.731 |     1.1
   19 |   1.2844 |     43.118 |   1.2438 |     44.538 |     1.2
   20 |   1.2743 |     42.876 |   1.2397 |     43.731 |     1.2
   21 |   1.2696 |     42.942 |   1.2292 |     43.824 |     1.3
   22 |   1.2640 |     42.843 |   1.2264 |     42.893 |     1.4
   23 |   1.2551 |     42.639 |   1.2222 |     42.893 |     1.4
   24 |   1.2489 |     42.380 |   1.2129 |     42.489 |     1.5
   25 |   1.2396 |     42.022 |   1.2141 |     42.986 |     1.5
   26 |   1.2338 |     42.160 |   1.2080 |     42.458 |     1.6
   27 |   1.2272 |     41.780 |   1.2033 |     42.458 |     1.7
   28 |   1.2237 |     41.736 |   1.2039 |     42.489 |     1.7
   29 |   1.2148 |     41.466 |   1.2161 |     42.365 |     1.8
   30 |   1.2165 |     41.344 |   1.2003 |     42.458 |     1.9
   31 |   1.2102 |     41.730 |   1.1943 |     41.930 |     1.9
   32 |   1.2040 |     41.135 |   1.1929 |     42.117 |     2.0
   33 |   1.1988 |     41.025 |   1.1932 |     41.930 |     2.0
   34 |   1.1924 |     40.788 |   1.1873 |     41.682 |     2.1
   35 |   1.1889 |     40.848 |   1.1849 |     41.341 |     2.2
   36 |   1.1843 |     40.898 |   1.1905 |     41.558 |     2.2
   37 |   1.1774 |     40.562 |   1.1853 |     41.279 |     2.3
   38 |   1.1723 |     40.149 |   1.1831 |     41.341 |     2.4
   39 |   1.1698 |     40.336 |   1.1785 |     41.061 |     2.4
   40 |   1.1652 |     40.138 |   1.1860 |     41.682 |     2.5
   41 |   1.1640 |     40.105 |   1.1874 |     41.403 |     2.5
   42 |   1.1562 |     39.983 |   1.1794 |     41.279 |     2.6
   43 |   1.1550 |     39.620 |   1.1850 |     41.372 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 293,025

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6267 |     47.631 |   1.3536 |     47.269 |     0.1
    2 |   1.2929 |     43.840 |   1.2625 |     44.724 |     0.2
    3 |   1.2198 |     42.215 |   1.2034 |     42.148 |     0.3
    4 |   1.1723 |     41.014 |   1.1478 |     41.155 |     0.4
    5 |   1.1278 |     40.055 |   1.1318 |     39.696 |     0.5
    6 |   1.1011 |     39.052 |   1.1198 |     39.603 |     0.6
    7 |   1.0794 |     38.419 |   1.1088 |     39.510 |     0.7
    8 |   1.0536 |     37.388 |   1.1063 |     39.479 |     0.8
    9 |   1.0424 |     37.300 |   1.0821 |     37.523 |     0.9
   10 |   1.0180 |     36.683 |   1.0458 |     36.158 |     0.9
   11 |   0.9971 |     35.344 |   1.0446 |     36.809 |     1.0
   12 |   0.9839 |     34.815 |   1.0153 |     35.040 |     1.1
   13 |   0.9637 |     34.154 |   1.0201 |     35.568 |     1.2
   14 |   0.9452 |     33.267 |   1.0090 |     34.606 |     1.3
   15 |   0.9299 |     32.534 |   0.9899 |     33.644 |     1.4
   16 |   0.9192 |     32.441 |   0.9990 |     34.482 |     1.5
   17 |   0.9051 |     31.956 |   0.9749 |     33.302 |     1.6
   18 |   0.8842 |     30.876 |   0.9759 |     33.302 |     1.7
   19 |   0.8756 |     30.375 |   0.9645 |     33.333 |     1.8
   20 |   0.8533 |     29.862 |   0.9883 |     34.109 |     1.9
   21 |   0.8455 |     29.565 |   0.9796 |     33.954 |     2.0
   22 |   0.8311 |     28.898 |   0.9802 |     32.775 |     2.1
   23 |   0.8196 |     28.766 |   0.9892 |     33.116 |     2.2
   24 |   0.8039 |     27.945 |   0.9418 |     31.440 |     2.3
   25 |   0.7935 |     27.967 |   0.9414 |     30.757 |     2.4
   26 |   0.7890 |     27.664 |   0.9386 |     31.347 |     2.5
   27 |   0.7682 |     27.085 |   0.9862 |     32.837 |     2.6
   28 |   0.7572 |     26.270 |   0.9731 |     33.023 |     2.7
   29 |   0.7450 |     26.050 |   0.9927 |     32.930 |     2.8
   30 |   0.7442 |     25.851 |   0.9548 |     31.595 |     2.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,047,585

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5522 |     48.237 |   1.2794 |     43.979 |     0.2
    2 |   1.2346 |     43.366 |   1.2036 |     43.079 |     0.4
    3 |   1.1734 |     41.785 |   1.1654 |     41.682 |     0.5
    4 |   1.1432 |     40.931 |   1.1527 |     41.341 |     0.7
    5 |   1.1095 |     39.449 |   1.1371 |     39.882 |     0.9
    6 |   1.0774 |     38.661 |   1.0970 |     38.982 |     1.1
    7 |   1.0549 |     37.686 |   1.0772 |     37.803 |     1.3
    8 |   1.0407 |     37.493 |   1.0897 |     38.610 |     1.4
    9 |   1.0122 |     36.347 |   1.0842 |     38.672 |     1.6
   10 |   1.0014 |     35.741 |   1.0728 |     36.872 |     1.8
   11 |   0.9853 |     35.014 |   1.0434 |     36.872 |     2.0
   12 |   0.9761 |     34.970 |   1.0249 |     36.313 |     2.2
   13 |   0.9541 |     34.320 |   1.0596 |     36.685 |     2.3
   14 |   0.9536 |     34.116 |   1.0276 |     35.785 |     2.5
   15 |   0.9477 |     33.780 |   1.0186 |     35.506 |     2.7
   16 |   0.9262 |     32.975 |   1.0257 |     35.475 |     2.9
   17 |   0.9154 |     32.645 |   1.0435 |     36.251 |     3.0
   18 |   0.9007 |     32.099 |   1.0135 |     35.506 |     3.2
   19 |   0.8827 |     31.273 |   1.0005 |     34.047 |     3.4
   20 |   0.8657 |     30.623 |   1.0309 |     35.444 |     3.6
   21 |   0.8611 |     30.771 |   0.9787 |     33.364 |     3.8
   22 |   0.8539 |     30.231 |   0.9868 |     33.892 |     3.9
   23 |   0.8349 |     29.317 |   1.0064 |     34.140 |     4.1
   24 |   0.8361 |     29.377 |   1.0092 |     35.133 |     4.3
   25 |   0.8377 |     29.736 |   0.9898 |     33.457 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 980,001

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0046 |     51.791 |   1.4881 |     46.617 |     0.1
    2 |   1.4094 |     44.606 |   1.3694 |     45.593 |     0.2
    3 |   1.3055 |     42.485 |   1.2888 |     44.972 |     0.3
    4 |   1.2448 |     40.920 |   1.2273 |     41.558 |     0.5
    5 |   1.1938 |     39.570 |   1.2025 |     41.403 |     0.6
    6 |   1.1590 |     39.014 |   1.1745 |     40.130 |     0.7
    7 |   1.1205 |     37.912 |   1.1404 |     38.610 |     0.8
    8 |   1.0911 |     36.981 |   1.1204 |     38.703 |     0.9
    9 |   1.0547 |     35.708 |   1.1048 |     38.144 |     1.0
   10 |   1.0281 |     34.534 |   1.0595 |     35.506 |     1.1
   11 |   1.0039 |     33.906 |   1.0639 |     36.282 |     1.3
   12 |   0.9719 |     32.523 |   1.0397 |     35.723 |     1.4
   13 |   0.9458 |     31.543 |   1.0212 |     34.730 |     1.5
   14 |   0.9168 |     30.645 |   1.0238 |     34.016 |     1.6
   15 |   0.8873 |     29.427 |   1.0185 |     34.233 |     1.7
   16 |   0.8618 |     28.402 |   1.0169 |     33.799 |     1.8
   17 |   0.8362 |     27.653 |   1.0207 |     34.016 |     1.9
   18 |   0.8097 |     26.738 |   0.9963 |     33.520 |     2.1
   19 |   0.7843 |     25.857 |   1.0205 |     33.613 |     2.2
   20 |   0.7615 |     25.405 |   1.0096 |     33.861 |     2.3
   21 |   0.7371 |     23.939 |   1.0214 |     33.892 |     2.4
   22 |   0.7081 |     23.339 |   0.9931 |     32.806 |     2.5
   23 |   0.6890 |     22.760 |   0.9869 |     32.402 |     2.6
   24 |   0.6660 |     21.851 |   0.9765 |     31.937 |     2.7
   25 |   0.6409 |     20.694 |   1.0116 |     32.495 |     2.8
   26 |   0.6234 |     20.022 |   1.0250 |     32.651 |     3.0
   27 |   0.5952 |     19.339 |   1.0324 |     33.271 |     3.1
   28 |   0.5714 |     18.590 |   1.0167 |     31.782 |     3.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 277,025

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7811 |     68.160 |   2.1273 |     54.966 |     0.1
    2 |   2.1006 |     51.030 |   1.7009 |     47.052 |     0.2
    3 |   1.7646 |     46.799 |   1.5651 |     46.741 |     0.3
    4 |   1.6231 |     46.028 |   1.4889 |     46.338 |     0.4
    5 |   1.5468 |     45.879 |   1.4527 |     46.648 |     0.5
    6 |   1.5025 |     45.774 |   1.4212 |     46.493 |     0.6
    7 |   1.4645 |     45.895 |   1.4001 |     46.679 |     0.7
    8 |   1.4399 |     45.355 |   1.3803 |     46.617 |     0.8
    9 |   1.4202 |     45.504 |   1.3629 |     46.586 |     0.9
   10 |   1.4062 |     45.146 |   1.3508 |     46.524 |     1.0
   11 |   1.3915 |     45.322 |   1.3384 |     46.120 |     1.1
   12 |   1.3767 |     45.124 |   1.3271 |     45.624 |     1.2
   13 |   1.3603 |     44.760 |   1.3129 |     45.345 |     1.3
   14 |   1.3544 |     44.579 |   1.3023 |     45.500 |     1.4
   15 |   1.3384 |     44.430 |   1.2898 |     45.407 |     1.5
   16 |   1.3271 |     44.209 |   1.2771 |     43.669 |     1.6
   17 |   1.3191 |     44.006 |   1.2795 |     43.886 |     1.8
   18 |   1.3046 |     43.675 |   1.2615 |     42.706 |     1.9
   19 |   1.2974 |     43.818 |   1.2482 |     42.924 |     2.0
   20 |   1.2860 |     43.157 |   1.2445 |     42.924 |     2.1
   21 |   1.2772 |     43.190 |   1.2314 |     42.737 |     2.2
   22 |   1.2700 |     43.152 |   1.2254 |     43.017 |     2.3
   23 |   1.2635 |     43.047 |   1.2245 |     43.079 |     2.4
   24 |   1.2574 |     42.986 |   1.2215 |     42.831 |     2.5
   25 |   1.2497 |     42.413 |   1.2126 |     42.955 |     2.6
   26 |   1.2416 |     42.545 |   1.2178 |     42.924 |     2.7
   27 |   1.2401 |     42.353 |   1.2069 |     42.800 |     2.8
   28 |   1.2284 |     42.061 |   1.1972 |     42.117 |     2.9
   29 |   1.2276 |     42.127 |   1.2041 |     42.893 |     3.0
   30 |   1.2218 |     42.011 |   1.1963 |     42.831 |     3.1
   31 |   1.2126 |     41.647 |   1.1919 |     42.303 |     3.2
   32 |   1.2066 |     41.152 |   1.1800 |     41.248 |     3.3
   33 |   1.2012 |     40.722 |   1.1882 |     42.055 |     3.4
   34 |   1.1943 |     41.036 |   1.1731 |     41.186 |     3.5
   35 |   1.1901 |     40.700 |   1.1749 |     40.968 |     3.6
   36 |   1.1865 |     40.832 |   1.1653 |     40.689 |     3.7
   37 |   1.1816 |     40.579 |   1.1603 |     40.565 |     3.8
   38 |   1.1735 |     40.408 |   1.1608 |     40.565 |     3.9
   39 |   1.1685 |     39.989 |   1.1748 |     41.217 |     4.0
   40 |   1.1689 |     40.198 |   1.1711 |     41.403 |     4.1
   41 |   1.1609 |     39.857 |   1.1598 |     41.061 |     4.2
   42 |   1.1587 |     39.802 |   1.1578 |     40.596 |     4.3
   43 |   1.1524 |     39.526 |   1.1561 |     40.937 |     4.4
   44 |   1.1471 |     39.080 |   1.1509 |     40.875 |     4.5
   45 |   1.1418 |     39.399 |   1.1527 |     40.441 |     4.6
   46 |   1.1417 |     39.284 |   1.1370 |     39.789 |     4.7
   47 |   1.1345 |     38.882 |   1.1456 |     40.255 |     4.8
   48 |   1.1308 |     38.865 |   1.1377 |     39.975 |     4.9
   49 |   1.1287 |     38.628 |   1.1436 |     40.068 |     5.0
   50 |   1.1223 |     38.567 |   1.1353 |     39.975 |     5.2
   51 |   1.1195 |     38.716 |   1.1385 |     39.851 |     5.3
   52 |   1.1182 |     38.711 |   1.1370 |     40.192 |     5.4
   53 |   1.1116 |     38.105 |   1.1347 |     40.068 |     5.5
   54 |   1.1027 |     38.006 |   1.1322 |     40.099 |     5.6
   55 |   1.1046 |     38.220 |   1.1253 |     39.230 |     5.7
   56 |   1.0977 |     37.846 |   1.1116 |     38.889 |     5.8
   57 |   1.0982 |     37.675 |   1.1101 |     38.610 |     5.9
   58 |   1.0953 |     37.526 |   1.1326 |     39.448 |     6.0
   59 |   1.0860 |     37.388 |   1.1021 |     38.144 |     6.1
   60 |   1.0830 |     37.333 |   1.1182 |     38.392 |     6.2
   61 |   1.0850 |     37.322 |   1.1233 |     39.199 |     6.3
   62 |   1.0806 |     37.058 |   1.1108 |     38.920 |     6.4
   63 |   1.0758 |     37.102 |   1.1128 |     38.858 |     6.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,044,769

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4887 |     46.705 |   1.2625 |     43.079 |     0.2
    2 |   1.2327 |     43.289 |   1.1822 |     42.955 |     0.3
    3 |   1.1748 |     42.309 |   1.1609 |     42.334 |     0.5
    4 |   1.1446 |     41.581 |   1.1523 |     41.310 |     0.7
    5 |   1.1321 |     41.399 |   1.1309 |     41.217 |     0.8
    6 |   1.1191 |     41.019 |   1.1405 |     41.713 |     1.0
    7 |   1.1071 |     40.893 |   1.1160 |     41.155 |     1.2
    8 |   1.0974 |     40.876 |   1.1094 |     40.999 |     1.3
    9 |   1.0922 |     40.474 |   1.1029 |     40.999 |     1.5
   10 |   1.0846 |     40.248 |   1.1016 |     41.092 |     1.7
   11 |   1.0852 |     40.573 |   1.0976 |     41.186 |     1.8
   12 |   1.0811 |     40.264 |   1.0945 |     41.030 |     2.0
   13 |   1.0731 |     39.972 |   1.1094 |     41.806 |     2.2
   14 |   1.0725 |     40.441 |   1.0975 |     41.030 |     2.4
   15 |   1.0708 |     40.017 |   1.0903 |     40.317 |     2.5
   16 |   1.0716 |     40.204 |   1.0926 |     40.627 |     2.7
   17 |   1.0664 |     40.204 |   1.0879 |     40.596 |     2.9
   18 |   1.0656 |     39.824 |   1.0891 |     41.372 |     3.0
   19 |   1.0635 |     39.912 |   1.0821 |     39.913 |     3.2
   20 |   1.0636 |     39.961 |   1.0922 |     40.441 |     3.4
   21 |   1.0621 |     39.857 |   1.0924 |     41.341 |     3.5
   22 |   1.0653 |     40.375 |   1.0896 |     41.186 |     3.7
   23 |   1.0607 |     40.209 |   1.0771 |     40.223 |     3.9
   24 |   1.0618 |     39.835 |   1.0890 |     40.999 |     4.0
   25 |   1.0610 |     40.182 |   1.0788 |     40.037 |     4.2
   26 |   1.0588 |     40.000 |   1.0824 |     41.341 |     4.4
   27 |   1.0584 |     40.055 |   1.0869 |     41.124 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 731,873

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6404 |     48.981 |   1.3854 |     47.083 |     0.1
    2 |   1.3141 |     43.989 |   1.2507 |     44.569 |     0.2
    3 |   1.2376 |     42.501 |   1.2144 |     41.993 |     0.3
    4 |   1.1870 |     40.562 |   1.1634 |     40.161 |     0.4
    5 |   1.1456 |     39.333 |   1.1400 |     39.354 |     0.6
    6 |   1.1127 |     38.171 |   1.1216 |     38.734 |     0.7
    7 |   1.0810 |     36.815 |   1.1171 |     38.516 |     0.8
    8 |   1.0445 |     36.050 |   1.0778 |     36.313 |     0.9
    9 |   1.0257 |     35.394 |   1.0771 |     36.934 |     1.0
   10 |   0.9950 |     34.441 |   1.0476 |     35.506 |     1.1
   11 |   0.9550 |     32.716 |   1.0633 |     35.289 |     1.2
   12 |   0.9364 |     32.347 |   1.0627 |     35.661 |     1.3
   13 |   0.9065 |     31.438 |   1.0470 |     35.258 |     1.5
   14 |   0.8866 |     30.237 |   1.0364 |     34.202 |     1.6
   15 |   0.8495 |     29.438 |   1.0580 |     35.382 |     1.7
   16 |   0.8343 |     29.069 |   1.0796 |     34.885 |     1.8
   17 |   0.7975 |     27.322 |   1.0763 |     35.102 |     1.9
   18 |   0.7744 |     26.975 |   1.0867 |     34.823 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,179,169

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5135 |     47.642 |   1.2887 |     45.096 |     0.1
    2 |   1.2624 |     43.824 |   1.2292 |     43.700 |     0.3
    3 |   1.2136 |     43.069 |   1.2052 |     42.862 |     0.4
    4 |   1.1839 |     42.336 |   1.1824 |     41.248 |     0.6
    5 |   1.1546 |     41.168 |   1.1594 |     41.248 |     0.7
    6 |   1.1277 |     40.028 |   1.1424 |     39.882 |     0.9
    7 |   1.1094 |     39.421 |   1.1204 |     40.037 |     1.0
    8 |   1.0926 |     39.146 |   1.1219 |     40.255 |     1.2
    9 |   1.0778 |     38.573 |   1.1067 |     40.565 |     1.3
   10 |   1.0746 |     38.964 |   1.0940 |     40.255 |     1.5
   11 |   1.0641 |     38.331 |   1.0917 |     39.168 |     1.6
   12 |   1.0496 |     38.011 |   1.0746 |     38.734 |     1.8
   13 |   1.0417 |     37.736 |   1.0810 |     39.665 |     1.9
   14 |   1.0357 |     37.796 |   1.0696 |     39.013 |     2.1
   15 |   1.0243 |     37.245 |   1.0534 |     38.516 |     2.2
   16 |   1.0180 |     37.515 |   1.0631 |     39.448 |     2.4
   17 |   1.0118 |     36.826 |   1.0504 |     39.199 |     2.5
   18 |   1.0017 |     36.523 |   1.0489 |     38.299 |     2.7
   19 |   0.9986 |     36.826 |   1.0673 |     38.144 |     2.8
   20 |   0.9948 |     36.402 |   1.0625 |     37.958 |     3.0
   21 |   0.9795 |     35.653 |   1.0283 |     36.840 |     3.1
   22 |   0.9657 |     35.267 |   1.0462 |     38.206 |     3.2
   23 |   0.9618 |     34.893 |   1.0295 |     37.585 |     3.4
   24 |   0.9472 |     34.744 |   0.9958 |     35.320 |     3.5
   25 |   0.9402 |     33.824 |   1.0233 |     37.058 |     3.7
   26 |   0.9343 |     33.631 |   0.9878 |     35.289 |     3.8
   27 |   0.9229 |     33.262 |   0.9860 |     36.282 |     4.0
   28 |   0.9008 |     32.612 |   0.9839 |     35.320 |     4.1
   29 |   0.9011 |     32.545 |   1.0231 |     36.344 |     4.3
   30 |   0.8895 |     32.044 |   0.9640 |     33.209 |     4.4
   31 |   0.8791 |     31.614 |   0.9799 |     34.358 |     4.6
   32 |   0.8729 |     31.190 |   0.9745 |     33.737 |     4.7
   33 |   0.8568 |     30.755 |   0.9663 |     32.744 |     4.9
   34 |   0.8525 |     30.639 |   0.9772 |     33.768 |     5.0
   35 |   0.8473 |     30.463 |   0.9585 |     33.147 |     5.2
   36 |   0.8402 |     30.287 |   0.9314 |     33.147 |     5.3
   37 |   0.8295 |     29.961 |   0.9465 |     31.968 |     5.5
   38 |   0.8151 |     29.234 |   0.9553 |     33.116 |     5.6
   39 |   0.8029 |     28.634 |   0.9416 |     32.557 |     5.7
   40 |   0.8016 |     28.749 |   0.9793 |     32.930 |     5.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 226,081

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7913 |     67.796 |   2.0689 |     49.628 |     0.1
    2 |   1.9994 |     48.237 |   1.6492 |     46.741 |     0.2
    3 |   1.6937 |     46.253 |   1.5267 |     46.276 |     0.3
    4 |   1.5730 |     45.923 |   1.4685 |     46.648 |     0.4
    5 |   1.5101 |     45.725 |   1.4323 |     46.679 |     0.4
    6 |   1.4651 |     45.780 |   1.4020 |     46.648 |     0.5
    7 |   1.4382 |     45.785 |   1.3816 |     46.214 |     0.6
    8 |   1.4114 |     45.118 |   1.3605 |     46.089 |     0.7
    9 |   1.3914 |     45.262 |   1.3414 |     46.865 |     0.8
   10 |   1.3760 |     45.058 |   1.3330 |     46.338 |     0.9
   11 |   1.3615 |     44.799 |   1.3223 |     45.127 |     1.0
   12 |   1.3464 |     44.601 |   1.3108 |     44.755 |     1.1
   13 |   1.3330 |     44.380 |   1.2920 |     44.382 |     1.1
   14 |   1.3226 |     44.050 |   1.2778 |     44.693 |     1.2
   15 |   1.3078 |     43.719 |   1.2763 |     44.817 |     1.3
   16 |   1.2991 |     43.444 |   1.2666 |     44.631 |     1.4
   17 |   1.2885 |     43.377 |   1.2644 |     44.289 |     1.5
   18 |   1.2792 |     42.893 |   1.2531 |     44.413 |     1.6
   19 |   1.2695 |     42.678 |   1.2314 |     43.669 |     1.7
   20 |   1.2612 |     42.727 |   1.2231 |     42.986 |     1.8
   21 |   1.2550 |     42.402 |   1.2240 |     43.141 |     1.9
   22 |   1.2498 |     42.540 |   1.2167 |     42.303 |     1.9
   23 |   1.2399 |     42.094 |   1.2088 |     41.806 |     2.0
   24 |   1.2321 |     41.686 |   1.2021 |     41.558 |     2.1
   25 |   1.2268 |     41.554 |   1.2026 |     41.806 |     2.2
   26 |   1.2196 |     41.730 |   1.1970 |     41.962 |     2.3
   27 |   1.2126 |     41.355 |   1.1977 |     41.527 |     2.4
   28 |   1.2082 |     41.030 |   1.1836 |     41.061 |     2.5
   29 |   1.1987 |     41.052 |   1.1834 |     41.434 |     2.5
   30 |   1.1936 |     40.606 |   1.1675 |     40.999 |     2.6
   31 |   1.1921 |     40.700 |   1.1746 |     41.248 |     2.7
   32 |   1.1811 |     40.556 |   1.1596 |     40.658 |     2.8
   33 |   1.1793 |     40.275 |   1.1739 |     41.496 |     2.9
   34 |   1.1731 |     40.198 |   1.1552 |     40.875 |     3.0
   35 |   1.1666 |     39.879 |   1.1649 |     41.030 |     3.1
   36 |   1.1650 |     39.945 |   1.1635 |     41.092 |     3.2
   37 |   1.1604 |     40.110 |   1.1507 |     40.348 |     3.3
   38 |   1.1534 |     39.355 |   1.1436 |     40.161 |     3.3
   39 |   1.1455 |     39.245 |   1.1496 |     40.317 |     3.4
   40 |   1.1451 |     39.339 |   1.1488 |     40.379 |     3.5
   41 |   1.1372 |     39.085 |   1.1360 |     39.913 |     3.6
   42 |   1.1322 |     38.887 |   1.1441 |     39.789 |     3.7
   43 |   1.1314 |     38.804 |   1.1349 |     39.665 |     3.8
   44 |   1.1219 |     38.617 |   1.1481 |     39.758 |     3.9
   45 |   1.1184 |     38.397 |   1.1412 |     39.758 |     4.0
   46 |   1.1131 |     38.083 |   1.1403 |     39.851 |     4.0
   47 |   1.1071 |     37.928 |   1.1438 |     40.348 |     4.1
   48 |   1.1058 |     38.320 |   1.1216 |     38.672 |     4.2
   49 |   1.1010 |     37.769 |   1.1236 |     39.075 |     4.3
   50 |   1.0953 |     37.614 |   1.1291 |     39.013 |     4.4
   51 |   1.0886 |     37.719 |   1.1421 |     39.820 |     4.5
   52 |   1.0885 |     37.383 |   1.1235 |     38.796 |     4.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 425,633

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4658 |     59.355 |   1.7779 |     46.741 |     0.1
    2 |   1.7063 |     45.658 |   1.5492 |     46.120 |     0.2
    3 |   1.5518 |     45.278 |   1.4595 |     45.500 |     0.3
    4 |   1.4684 |     44.689 |   1.4047 |     45.189 |     0.4
    5 |   1.4111 |     44.314 |   1.3527 |     44.041 |     0.5
    6 |   1.3725 |     43.807 |   1.3231 |     44.165 |     0.6
    7 |   1.3414 |     43.477 |   1.3026 |     43.917 |     0.7
    8 |   1.3173 |     43.129 |   1.2809 |     43.389 |     0.9
    9 |   1.2930 |     42.760 |   1.2589 |     42.706 |     1.0
   10 |   1.2742 |     42.545 |   1.2418 |     42.489 |     1.1
   11 |   1.2547 |     41.901 |   1.2344 |     42.800 |     1.2
   12 |   1.2362 |     41.339 |   1.2114 |     42.086 |     1.3
   13 |   1.2216 |     41.190 |   1.2092 |     41.868 |     1.4
   14 |   1.2071 |     40.887 |   1.1909 |     41.372 |     1.5
   15 |   1.1928 |     40.187 |   1.1706 |     40.130 |     1.6
   16 |   1.1853 |     40.028 |   1.1655 |     39.882 |     1.7
   17 |   1.1714 |     39.736 |   1.1488 |     39.541 |     1.8
   18 |   1.1593 |     39.471 |   1.1499 |     39.727 |     1.9
   19 |   1.1468 |     39.152 |   1.1471 |     39.354 |     2.0
   20 |   1.1391 |     38.799 |   1.1232 |     38.920 |     2.1
   21 |   1.1275 |     38.369 |   1.1285 |     39.044 |     2.3
   22 |   1.1149 |     38.182 |   1.1212 |     38.734 |     2.4
   23 |   1.1035 |     37.675 |   1.0957 |     38.144 |     2.5
   24 |   1.0975 |     37.680 |   1.1104 |     38.268 |     2.6
   25 |   1.0889 |     37.383 |   1.1015 |     38.392 |     2.7
   26 |   1.0781 |     36.926 |   1.0898 |     37.834 |     2.8
   27 |   1.0668 |     36.689 |   1.0858 |     37.896 |     2.9
   28 |   1.0597 |     36.220 |   1.0837 |     37.523 |     3.0
   29 |   1.0525 |     36.110 |   1.0661 |     36.872 |     3.1
   30 |   1.0477 |     36.072 |   1.0759 |     36.840 |     3.2
   31 |   1.0437 |     36.088 |   1.0599 |     36.530 |     3.3
   32 |   1.0319 |     35.328 |   1.0604 |     36.654 |     3.4
   33 |   1.0218 |     35.030 |   1.0714 |     37.306 |     3.5
   34 |   1.0146 |     34.904 |   1.0467 |     35.537 |     3.6
   35 |   1.0068 |     34.584 |   1.0690 |     36.654 |     3.8
   36 |   1.0027 |     34.187 |   1.0686 |     36.251 |     3.9
   37 |   1.0007 |     34.314 |   1.0643 |     36.623 |     4.0
   38 |   0.9900 |     33.890 |   1.0326 |     34.947 |     4.1
   39 |   0.9798 |     33.449 |   1.0459 |     35.351 |     4.2
   40 |   0.9757 |     33.427 |   1.0664 |     36.437 |     4.3
   41 |   0.9631 |     33.152 |   1.0448 |     35.723 |     4.4
   42 |   0.9628 |     32.832 |   1.0652 |     35.971 |     4.5
   43 |   0.9578 |     32.799 |   1.0262 |     34.420 |     4.6
   44 |   0.9502 |     32.353 |   1.0405 |     35.071 |     4.7
   45 |   0.9445 |     32.105 |   1.0215 |     34.109 |     4.8
   46 |   0.9394 |     31.978 |   1.0355 |     34.699 |     4.9
   47 |   0.9297 |     31.829 |   1.0313 |     34.264 |     5.1
   48 |   0.9244 |     31.680 |   1.0469 |     35.320 |     5.2
   49 |   0.9245 |     31.493 |   1.0138 |     33.923 |     5.3
   50 |   0.9169 |     31.344 |   1.0414 |     35.258 |     5.4
   51 |   0.9121 |     30.981 |   1.0388 |     35.351 |     5.5
   52 |   0.8972 |     30.645 |   0.9984 |     33.644 |     5.6
   53 |   0.8969 |     30.661 |   1.0112 |     33.892 |     5.7
   54 |   0.8912 |     30.567 |   1.0200 |     34.637 |     5.8
   55 |   0.8837 |     30.110 |   1.0192 |     34.264 |     5.9
   56 |   0.8796 |     29.879 |   1.0116 |     33.737 |     6.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 392,097

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5810 |     47.003 |   1.3236 |     44.475 |     0.1
    2 |   1.2826 |     43.818 |   1.2520 |     44.569 |     0.2
    3 |   1.2197 |     43.284 |   1.1935 |     43.637 |     0.3
    4 |   1.1824 |     42.176 |   1.1642 |     43.358 |     0.4
    5 |   1.1588 |     41.846 |   1.1583 |     42.272 |     0.5
    6 |   1.1426 |     41.444 |   1.1372 |     41.434 |     0.6
    7 |   1.1236 |     40.909 |   1.1393 |     41.775 |     0.7
    8 |   1.1115 |     40.893 |   1.1264 |     41.993 |     0.8
    9 |   1.1046 |     40.617 |   1.1206 |     41.993 |     0.9
   10 |   1.1002 |     40.584 |   1.1036 |     40.503 |     1.0
   11 |   1.0876 |     40.132 |   1.1030 |     40.223 |     1.1
   12 |   1.0853 |     40.353 |   1.0971 |     41.341 |     1.2
   13 |   1.0832 |     40.176 |   1.1119 |     41.434 |     1.3
   14 |   1.0798 |     40.490 |   1.1021 |     41.434 |     1.4
   15 |   1.0793 |     40.386 |   1.0925 |     40.813 |     1.5
   16 |   1.0730 |     40.270 |   1.1012 |     41.403 |     1.6
   17 |   1.0713 |     40.132 |   1.0981 |     40.906 |     1.7
   18 |   1.0712 |     40.303 |   1.0876 |     41.279 |     1.8
   19 |   1.0663 |     39.950 |   1.0940 |     41.248 |     1.9
   20 |   1.0643 |     40.154 |   1.0875 |     40.875 |     2.0
   21 |   1.0633 |     39.741 |   1.0889 |     40.534 |     2.1
   22 |   1.0631 |     40.198 |   1.0939 |     41.372 |     2.2
   23 |   1.0634 |     40.011 |   1.0795 |     40.906 |     2.3
   24 |   1.0632 |     40.176 |   1.0907 |     40.782 |     2.4
   25 |   1.0582 |     39.807 |   1.0833 |     40.751 |     2.5
   26 |   1.0571 |     40.187 |   1.0790 |     40.037 |     2.6
   27 |   1.0562 |     39.807 |   1.0886 |     41.061 |     2.7
   28 |   1.0412 |     38.915 |   1.0758 |     39.696 |     2.8
   29 |   1.0326 |     38.364 |   1.0800 |     39.199 |     2.9
   30 |   1.0216 |     37.884 |   1.0837 |     39.013 |     3.0
   31 |   1.0127 |     37.686 |   1.0610 |     38.610 |     3.1
   32 |   1.0055 |     37.383 |   1.0964 |     40.099 |     3.2
   33 |   1.0006 |     36.975 |   1.0663 |     39.323 |     3.3
   34 |   0.9916 |     36.799 |   1.0965 |     40.906 |     3.4
   35 |   0.9813 |     36.182 |   1.0915 |     39.510 |     3.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 226,081

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6172 |     64.441 |   1.9693 |     48.727 |     0.1
    2 |   1.8540 |     46.821 |   1.6246 |     46.586 |     0.1
    3 |   1.6201 |     45.928 |   1.5121 |     46.462 |     0.2
    4 |   1.5226 |     45.620 |   1.4527 |     46.648 |     0.3
    5 |   1.4651 |     45.366 |   1.4144 |     46.648 |     0.3
    6 |   1.4251 |     45.284 |   1.3759 |     46.586 |     0.4
    7 |   1.3916 |     44.705 |   1.3467 |     46.462 |     0.4
    8 |   1.3650 |     44.397 |   1.3248 |     45.655 |     0.5
    9 |   1.3438 |     43.950 |   1.3021 |     44.972 |     0.6
   10 |   1.3259 |     43.537 |   1.2862 |     44.600 |     0.6
   11 |   1.3087 |     43.036 |   1.2719 |     43.017 |     0.7
   12 |   1.2901 |     42.474 |   1.2540 |     42.893 |     0.8
   13 |   1.2780 |     42.215 |   1.2496 |     43.420 |     0.8
   14 |   1.2674 |     42.248 |   1.2330 |     42.986 |     0.9
   15 |   1.2520 |     41.846 |   1.2255 |     42.272 |     1.0
   16 |   1.2410 |     41.493 |   1.2201 |     41.496 |     1.0
   17 |   1.2270 |     41.146 |   1.2069 |     41.620 |     1.1
   18 |   1.2220 |     41.344 |   1.2001 |     41.744 |     1.1
   19 |   1.2096 |     40.953 |   1.1938 |     41.403 |     1.2
   20 |   1.2008 |     40.804 |   1.1918 |     41.341 |     1.3
   21 |   1.1940 |     40.738 |   1.1894 |     41.465 |     1.3
   22 |   1.1845 |     40.672 |   1.1762 |     40.596 |     1.4
   23 |   1.1794 |     40.264 |   1.1886 |     41.620 |     1.5
   24 |   1.1668 |     40.154 |   1.1770 |     41.403 |     1.5
   25 |   1.1640 |     40.215 |   1.1702 |     41.186 |     1.6
   26 |   1.1548 |     39.868 |   1.1471 |     39.789 |     1.7
   27 |   1.1535 |     40.033 |   1.1560 |     39.851 |     1.7
   28 |   1.1433 |     39.399 |   1.1634 |     39.758 |     1.8
   29 |   1.1391 |     39.421 |   1.1527 |     40.441 |     1.8
   30 |   1.1382 |     39.466 |   1.1461 |     39.696 |     1.9
   31 |   1.1300 |     38.997 |   1.1306 |     39.013 |     2.0
   32 |   1.1246 |     39.152 |   1.1407 |     39.913 |     2.0
   33 |   1.1178 |     38.964 |   1.1514 |     39.975 |     2.1
   34 |   1.1156 |     38.573 |   1.1432 |     39.882 |     2.2
   35 |   1.1085 |     37.983 |   1.1109 |     38.547 |     2.2
   36 |   1.1053 |     38.292 |   1.1196 |     39.044 |     2.3
   37 |   1.0975 |     37.879 |   1.1126 |     38.765 |     2.4
   38 |   1.0943 |     37.994 |   1.1215 |     39.292 |     2.4
   39 |   1.0872 |     37.366 |   1.1130 |     38.516 |     2.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 235,041

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7089 |     49.493 |   1.3543 |     45.003 |     0.1
    2 |   1.2731 |     42.424 |   1.2226 |     42.489 |     0.1
    3 |   1.1830 |     40.507 |   1.1639 |     41.527 |     0.2
    4 |   1.1201 |     38.485 |   1.1390 |     39.510 |     0.3
    5 |   1.0605 |     36.501 |   1.1179 |     39.137 |     0.3
    6 |   1.0124 |     34.617 |   1.0859 |     36.406 |     0.4
    7 |   0.9678 |     33.107 |   1.0467 |     35.630 |     0.5
    8 |   0.9158 |     31.493 |   1.0170 |     33.892 |     0.5
    9 |   0.8653 |     29.471 |   1.0493 |     35.568 |     0.6
   10 |   0.8273 |     28.275 |   1.0175 |     33.271 |     0.7
   11 |   0.7820 |     26.595 |   1.0132 |     33.892 |     0.7
   12 |   0.7351 |     25.091 |   1.0333 |     33.364 |     0.8
   13 |   0.6939 |     23.752 |   1.0170 |     32.899 |     0.9
   14 |   0.6507 |     22.017 |   1.0203 |     31.906 |     0.9
   15 |   0.6178 |     21.168 |   1.0377 |     32.837 |     1.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 326,561

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7559 |     49.928 |   1.3649 |     45.934 |     0.1
    2 |   1.3353 |     44.843 |   1.2734 |     44.848 |     0.2
    3 |   1.2505 |     43.019 |   1.2134 |     42.955 |     0.3
    4 |   1.1980 |     41.361 |   1.1591 |     40.689 |     0.4
    5 |   1.1634 |     40.331 |   1.1397 |     39.913 |     0.5
    6 |   1.1282 |     39.273 |   1.1048 |     39.727 |     0.6
    7 |   1.0889 |     37.510 |   1.0813 |     37.865 |     0.7
    8 |   1.0609 |     36.551 |   1.1174 |     39.510 |     0.8
    9 |   1.0403 |     36.055 |   1.0564 |     36.872 |     0.9
   10 |   1.0017 |     34.893 |   1.0763 |     37.120 |     1.0
   11 |   0.9856 |     34.039 |   1.0307 |     35.971 |     1.1
   12 |   0.9592 |     33.212 |   1.0089 |     35.444 |     1.3
   13 |   0.9389 |     32.540 |   1.0142 |     34.761 |     1.4
   14 |   0.9269 |     32.331 |   1.0201 |     34.482 |     1.5
   15 |   0.8985 |     31.140 |   1.0254 |     34.730 |     1.6
   16 |   0.8771 |     30.298 |   1.0239 |     33.985 |     1.7
   17 |   0.8570 |     29.791 |   0.9799 |     33.116 |     1.8
   18 |   0.8406 |     28.909 |   0.9988 |     33.240 |     1.9
   19 |   0.8156 |     28.231 |   0.9986 |     33.271 |     2.0
   20 |   0.8028 |     27.895 |   1.0108 |     33.116 |     2.1
   21 |   0.7847 |     26.937 |   1.0131 |     33.364 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,243,553

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5737 |     48.628 |   1.2837 |     45.624 |     0.1
    2 |   1.2840 |     44.826 |   1.2256 |     44.507 |     0.3
    3 |   1.2237 |     42.860 |   1.1822 |     42.862 |     0.5
    4 |   1.1875 |     41.989 |   1.1524 |     41.279 |     0.6
    5 |   1.1616 |     41.107 |   1.1392 |     41.061 |     0.8
    6 |   1.1355 |     40.540 |   1.1350 |     40.472 |     0.9
    7 |   1.1204 |     39.835 |   1.1064 |     40.441 |     1.1
    8 |   1.1018 |     39.190 |   1.1053 |     38.951 |     1.2
    9 |   1.0920 |     39.157 |   1.1004 |     39.851 |     1.4
   10 |   1.0813 |     38.672 |   1.0782 |     39.106 |     1.5
   11 |   1.0677 |     38.309 |   1.0717 |     38.703 |     1.7
   12 |   1.0589 |     38.127 |   1.0955 |     38.020 |     1.8
   13 |   1.0515 |     38.077 |   1.0712 |     39.230 |     2.0
   14 |   1.0435 |     38.397 |   1.0739 |     39.603 |     2.2
   15 |   1.0280 |     37.361 |   1.0586 |     37.834 |     2.3
   16 |   1.0267 |     37.058 |   1.0571 |     37.865 |     2.5
   17 |   1.0130 |     36.876 |   1.0425 |     37.709 |     2.6
   18 |   1.0061 |     36.424 |   1.0525 |     37.647 |     2.8
   19 |   0.9941 |     36.044 |   1.0634 |     38.889 |     2.9
   20 |   0.9874 |     35.807 |   1.0440 |     37.523 |     3.1
   21 |   0.9787 |     35.554 |   1.0401 |     37.337 |     3.2
   22 |   0.9741 |     35.080 |   1.0215 |     37.306 |     3.4
   23 |   0.9649 |     35.190 |   1.0103 |     35.878 |     3.5
   24 |   0.9587 |     34.727 |   1.0307 |     36.561 |     3.7
   25 |   0.9482 |     34.452 |   1.0786 |     38.144 |     3.9
   26 |   0.9446 |     34.215 |   1.0084 |     36.220 |     4.0
   27 |   0.9332 |     33.906 |   1.0169 |     35.692 |     4.2
   28 |   0.9178 |     33.096 |   1.0252 |     35.537 |     4.3
   29 |   0.9108 |     33.052 |   1.0443 |     36.778 |     4.5
   30 |   0.9065 |     32.793 |   1.0036 |     35.754 |     4.6
   31 |   0.9011 |     32.716 |   1.0223 |     36.158 |     4.8
   32 |   0.8929 |     32.281 |   1.0154 |     35.320 |     4.9
   33 |   0.8860 |     31.818 |   1.0096 |     35.444 |     5.1
   34 |   0.8812 |     31.983 |   0.9987 |     36.158 |     5.2
   35 |   0.8584 |     31.025 |   0.9872 |     34.668 |     5.4
   36 |   0.8631 |     31.096 |   0.9982 |     35.102 |     5.5
   37 |   0.8519 |     30.556 |   1.0102 |     35.196 |     5.7
   38 |   0.8345 |     29.939 |   0.9990 |     33.737 |     5.9
   39 |   0.8306 |     29.758 |   1.0139 |     33.799 |     6.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 343,265

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6708 |     64.033 |   1.9259 |     48.014 |     0.1
    2 |   1.8251 |     46.716 |   1.5985 |     46.741 |     0.2
    3 |   1.6021 |     45.658 |   1.4963 |     46.648 |     0.3
    4 |   1.5119 |     45.769 |   1.4342 |     46.648 |     0.4
    5 |   1.4543 |     45.284 |   1.3933 |     46.182 |     0.6
    6 |   1.4143 |     44.942 |   1.3652 |     45.469 |     0.7
    7 |   1.3808 |     44.336 |   1.3390 |     44.351 |     0.8
    8 |   1.3581 |     44.006 |   1.3194 |     44.103 |     0.9
    9 |   1.3366 |     43.625 |   1.2938 |     43.420 |     1.0
   10 |   1.3166 |     42.953 |   1.3003 |     44.631 |     1.1
   11 |   1.2948 |     42.507 |   1.2729 |     43.048 |     1.2
   12 |   1.2807 |     42.209 |   1.2636 |     43.420 |     1.3
   13 |   1.2638 |     41.444 |   1.2450 |     42.148 |     1.4
   14 |   1.2454 |     41.179 |   1.2442 |     42.644 |     1.6
   15 |   1.2353 |     41.234 |   1.2363 |     42.800 |     1.7
   16 |   1.2221 |     41.146 |   1.2093 |     41.092 |     1.8
   17 |   1.2097 |     40.380 |   1.1947 |     40.720 |     1.9
   18 |   1.1999 |     40.303 |   1.1845 |     40.223 |     2.0
   19 |   1.1830 |     39.625 |   1.1825 |     40.534 |     2.1
   20 |   1.1768 |     39.537 |   1.1857 |     40.223 |     2.2
   21 |   1.1706 |     39.185 |   1.1897 |     40.472 |     2.3
   22 |   1.1533 |     38.981 |   1.1599 |     39.354 |     2.4
   23 |   1.1499 |     38.810 |   1.1529 |     39.385 |     2.6
   24 |   1.1383 |     38.446 |   1.1515 |     39.292 |     2.7
   25 |   1.1332 |     38.231 |   1.1721 |     40.130 |     2.8
   26 |   1.1236 |     37.994 |   1.1617 |     39.696 |     2.9
   27 |   1.1179 |     37.769 |   1.1460 |     39.230 |     3.0
   28 |   1.1067 |     37.510 |   1.1429 |     38.951 |     3.1
   29 |   1.1000 |     37.124 |   1.1474 |     39.417 |     3.2
   30 |   1.0943 |     37.003 |   1.1558 |     39.944 |     3.3
   31 |   1.0824 |     36.738 |   1.1414 |     39.075 |     3.4
   32 |   1.0796 |     36.573 |   1.1299 |     38.672 |     3.6
   33 |   1.0705 |     36.380 |   1.1014 |     37.213 |     3.7
   34 |   1.0646 |     36.110 |   1.1366 |     38.765 |     3.8
   35 |   1.0588 |     35.912 |   1.1165 |     38.082 |     3.9
   36 |   1.0540 |     35.939 |   1.1160 |     38.082 |     4.0
   37 |   1.0420 |     35.317 |   1.1321 |     38.827 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 980,001

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5062 |     62.601 |   1.6418 |     46.741 |     0.1
    2 |   1.6403 |     46.358 |   1.4422 |     46.741 |     0.2
    3 |   1.4816 |     45.928 |   1.3867 |     46.058 |     0.3
    4 |   1.4191 |     45.405 |   1.3393 |     45.313 |     0.4
    5 |   1.3797 |     44.716 |   1.3239 |     44.662 |     0.5
    6 |   1.3520 |     44.171 |   1.3013 |     44.910 |     0.6
    7 |   1.3317 |     43.763 |   1.2786 |     43.979 |     0.7
    8 |   1.3097 |     43.140 |   1.2956 |     44.693 |     0.8
    9 |   1.2919 |     42.810 |   1.2701 |     44.165 |     0.9
   10 |   1.2733 |     42.512 |   1.2689 |     44.010 |     1.0
   11 |   1.2623 |     42.424 |   1.2349 |     43.048 |     1.1
   12 |   1.2472 |     41.813 |   1.2448 |     43.079 |     1.2
   13 |   1.2327 |     41.399 |   1.2152 |     42.117 |     1.3
   14 |   1.2194 |     41.047 |   1.1959 |     40.658 |     1.4
   15 |   1.2045 |     40.534 |   1.1990 |     41.465 |     1.5
   16 |   1.1899 |     40.127 |   1.1570 |     40.006 |     1.6
   17 |   1.1769 |     40.011 |   1.1752 |     40.006 |     1.7
   18 |   1.1678 |     39.636 |   1.1827 |     40.130 |     1.8
   19 |   1.1617 |     39.284 |   1.1706 |     40.937 |     1.9
   20 |   1.1471 |     39.152 |   1.1551 |     39.354 |     2.0
   21 |   1.1329 |     38.804 |   1.1564 |     39.944 |     2.1
   22 |   1.1217 |     38.314 |   1.1474 |     39.665 |     2.2
   23 |   1.1179 |     38.336 |   1.1630 |     39.696 |     2.3
   24 |   1.1094 |     37.680 |   1.1571 |     39.758 |     2.4
   25 |   1.0979 |     38.121 |   1.1215 |     38.734 |     2.5
   26 |   1.0875 |     37.129 |   1.1241 |     38.610 |     2.6
   27 |   1.0807 |     36.744 |   1.0998 |     38.299 |     2.7
   28 |   1.0697 |     36.573 |   1.1104 |     38.796 |     2.8
   29 |   1.0611 |     36.446 |   1.1101 |     38.268 |     2.9
   30 |   1.0522 |     35.978 |   1.0895 |     37.368 |     3.0
   31 |   1.0476 |     35.840 |   1.1011 |     37.585 |     3.1
   32 |   1.0344 |     35.405 |   1.0984 |     37.089 |     3.2
   33 |   1.0313 |     35.063 |   1.0898 |     36.654 |     3.3
   34 |   1.0216 |     34.782 |   1.1307 |     37.492 |     3.4
   35 |   1.0101 |     34.072 |   1.0807 |     36.903 |     3.5
   36 |   1.0038 |     34.033 |   1.0902 |     36.561 |     3.6
   37 |   0.9981 |     34.292 |   1.0978 |     36.530 |     3.7
   38 |   0.9875 |     33.763 |   1.1171 |     37.337 |     3.8
   39 |   0.9812 |     33.179 |   1.0802 |     35.909 |     3.9
   40 |   0.9708 |     32.893 |   1.1046 |     36.840 |     4.0
   41 |   0.9648 |     32.810 |   1.0719 |     35.599 |     4.1
   42 |   0.9589 |     32.617 |   1.0998 |     36.437 |     4.2
   43 |   0.9549 |     32.760 |   1.0890 |     36.220 |     4.3
   44 |   0.9440 |     32.050 |   1.0946 |     36.313 |     4.4
   45 |   0.9349 |     31.719 |   1.0808 |     35.878 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,044,769

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1422 |     54.479 |   1.5333 |     46.710 |     0.1
    2 |   1.4947 |     45.614 |   1.3923 |     46.369 |     0.3
    3 |   1.4011 |     44.871 |   1.3422 |     45.903 |     0.4
    4 |   1.3474 |     44.066 |   1.2975 |     43.669 |     0.6
    5 |   1.3077 |     43.526 |   1.2603 |     43.917 |     0.7
    6 |   1.2697 |     42.066 |   1.2530 |     43.700 |     0.9
    7 |   1.2358 |     41.366 |   1.2123 |     41.962 |     1.0
    8 |   1.2108 |     40.733 |   1.1844 |     41.248 |     1.2
    9 |   1.1842 |     39.879 |   1.1663 |     40.223 |     1.3
   10 |   1.1633 |     39.096 |   1.1608 |     39.789 |     1.5
   11 |   1.1403 |     38.733 |   1.1706 |     40.223 |     1.6
   12 |   1.1222 |     38.011 |   1.1451 |     39.727 |     1.7
   13 |   1.1031 |     37.570 |   1.1447 |     40.317 |     1.9
   14 |   1.0898 |     36.821 |   1.1071 |     38.237 |     2.0
   15 |   1.0696 |     36.490 |   1.1455 |     39.044 |     2.2
   16 |   1.0535 |     35.818 |   1.1352 |     39.013 |     2.3
   17 |   1.0343 |     35.273 |   1.1214 |     38.175 |     2.5
   18 |   1.0163 |     34.298 |   1.1245 |     38.889 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 277,025

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8900 |     52.309 |   1.3954 |     46.369 |     0.1
    2 |   1.3872 |     45.521 |   1.3126 |     46.462 |     0.2
    3 |   1.3290 |     44.683 |   1.2705 |     44.134 |     0.3
    4 |   1.2951 |     44.220 |   1.2704 |     45.282 |     0.4
    5 |   1.2602 |     43.416 |   1.2237 |     43.420 |     0.5
    6 |   1.2236 |     42.446 |   1.1972 |     43.358 |     0.6
    7 |   1.1969 |     41.537 |   1.2120 |     42.272 |     0.7
    8 |   1.1800 |     40.584 |   1.1632 |     41.217 |     0.8
    9 |   1.1551 |     40.006 |   1.1499 |     40.627 |     0.9
   10 |   1.1302 |     39.234 |   1.1444 |     39.634 |     1.0
   11 |   1.1134 |     38.749 |   1.1574 |     40.658 |     1.1
   12 |   1.1007 |     37.884 |   1.1361 |     38.982 |     1.2
   13 |   1.0835 |     37.680 |   1.1049 |     38.392 |     1.3
   14 |   1.0680 |     36.854 |   1.0954 |     38.268 |     1.4
   15 |   1.0455 |     35.934 |   1.1144 |     38.454 |     1.5
   16 |   1.0274 |     35.427 |   1.0998 |     37.834 |     1.7
   17 |   1.0075 |     34.650 |   1.0939 |     37.772 |     1.8
   18 |   0.9928 |     34.127 |   1.0816 |     36.934 |     1.9
   19 |   0.9770 |     33.598 |   1.0880 |     35.847 |     2.0
   20 |   0.9676 |     33.284 |   1.0710 |     36.002 |     2.1
   21 |   0.9409 |     32.116 |   1.0766 |     36.406 |     2.2
   22 |   0.9262 |     31.543 |   1.0835 |     36.685 |     2.3
   23 |   0.9130 |     31.433 |   1.0660 |     35.909 |     2.4
   24 |   0.8925 |     31.003 |   1.1155 |     35.816 |     2.5
   25 |   0.8813 |     30.259 |   1.0745 |     35.413 |     2.6
   26 |   0.8608 |     29.763 |   1.1139 |     35.227 |     2.7
   27 |   0.8513 |     29.218 |   1.0968 |     35.568 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 235,041

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7350 |     48.904 |   1.3481 |     45.872 |     0.1
    2 |   1.3256 |     44.353 |   1.2515 |     44.569 |     0.2
    3 |   1.2421 |     42.738 |   1.1880 |     41.030 |     0.3
    4 |   1.1875 |     40.926 |   1.1586 |     40.627 |     0.4
    5 |   1.1525 |     39.581 |   1.1435 |     40.534 |     0.5
    6 |   1.1203 |     38.893 |   1.1177 |     38.579 |     0.6
    7 |   1.0958 |     37.675 |   1.0878 |     37.337 |     0.7
    8 |   1.0688 |     37.129 |   1.0732 |     37.616 |     0.8
    9 |   1.0432 |     36.000 |   1.0797 |     37.523 |     0.8
   10 |   1.0119 |     35.036 |   1.0548 |     36.158 |     0.9
   11 |   0.9852 |     33.466 |   1.0381 |     35.537 |     1.0
   12 |   0.9582 |     32.777 |   1.0480 |     36.158 |     1.1
   13 |   0.9397 |     32.033 |   1.0394 |     35.568 |     1.2
   14 |   0.9100 |     31.146 |   1.0578 |     35.909 |     1.3
   15 |   0.8982 |     30.777 |   1.0185 |     33.675 |     1.4
   16 |   0.8656 |     29.355 |   1.0490 |     34.761 |     1.5
   17 |   0.8407 |     28.689 |   1.0105 |     33.892 |     1.6
   18 |   0.8263 |     28.193 |   1.0196 |     34.295 |     1.7
   19 |   0.7976 |     27.058 |   1.0035 |     33.644 |     1.8
   20 |   0.7750 |     26.452 |   1.0173 |     33.209 |     1.9
   21 |   0.7471 |     25.658 |   1.0174 |     33.240 |     2.0
   22 |   0.7317 |     25.025 |   1.0217 |     33.147 |     2.1
   23 |   0.7168 |     24.667 |   1.0716 |     34.264 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 327,457

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8734 |     73.107 |   2.3170 |     56.518 |     0.2
    2 |   2.2111 |     52.650 |   1.7579 |     47.238 |     0.3
    3 |   1.8155 |     46.815 |   1.5850 |     46.803 |     0.5
    4 |   1.6498 |     46.237 |   1.5152 |     46.772 |     0.7
    5 |   1.5618 |     46.105 |   1.4617 |     46.648 |     0.8
    6 |   1.5105 |     45.928 |   1.4282 |     46.617 |     1.0
    7 |   1.4742 |     45.978 |   1.4070 |     46.400 |     1.2
    8 |   1.4448 |     45.499 |   1.3917 |     45.872 |     1.3
    9 |   1.4221 |     45.537 |   1.3750 |     45.717 |     1.5
   10 |   1.4082 |     45.355 |   1.3526 |     45.965 |     1.6
   11 |   1.3873 |     45.041 |   1.3329 |     45.407 |     1.8
   12 |   1.3720 |     44.937 |   1.3283 |     45.686 |     2.0
   13 |   1.3584 |     44.540 |   1.3114 |     44.631 |     2.1
   14 |   1.3410 |     43.868 |   1.2980 |     45.345 |     2.3
   15 |   1.3309 |     43.686 |   1.2866 |     44.165 |     2.5
   16 |   1.3173 |     43.543 |   1.2733 |     44.103 |     2.6
   17 |   1.3043 |     43.267 |   1.2667 |     43.731 |     2.8
   18 |   1.2976 |     43.212 |   1.2516 |     43.606 |     3.0
   19 |   1.2887 |     43.118 |   1.2544 |     43.420 |     3.1
   20 |   1.2790 |     42.573 |   1.2488 |     43.141 |     3.3
   21 |   1.2682 |     42.408 |   1.2427 |     42.924 |     3.5
   22 |   1.2590 |     42.033 |   1.2197 |     41.993 |     3.6
   23 |   1.2541 |     41.912 |   1.2326 |     42.396 |     3.8
   24 |   1.2465 |     42.006 |   1.2254 |     41.993 |     4.0
   25 |   1.2390 |     41.488 |   1.2091 |     42.272 |     4.1
   26 |   1.2335 |     41.350 |   1.2116 |     42.365 |     4.3
   27 |   1.2257 |     41.240 |   1.2041 |     41.775 |     4.4
   28 |   1.2213 |     41.223 |   1.2034 |     41.775 |     4.6
   29 |   1.2146 |     41.025 |   1.2134 |     41.403 |     4.8
   30 |   1.2082 |     41.052 |   1.1885 |     41.310 |     4.9
   31 |   1.2041 |     40.661 |   1.1827 |     40.534 |     5.1
   32 |   1.1974 |     40.799 |   1.2022 |     41.341 |     5.3
   33 |   1.1900 |     40.408 |   1.1799 |     40.627 |     5.4
   34 |   1.1874 |     40.259 |   1.1870 |     40.658 |     5.6
   35 |   1.1826 |     40.061 |   1.1751 |     40.875 |     5.8
   36 |   1.1755 |     39.989 |   1.1767 |     40.658 |     5.9
   37 |   1.1682 |     39.515 |   1.1895 |     40.844 |     6.1
   38 |   1.1625 |     39.460 |   1.1784 |     40.968 |     6.3
   39 |   1.1555 |     39.251 |   1.1644 |     40.286 |     6.4
   40 |   1.1491 |     38.986 |   1.1571 |     39.696 |     6.6
   41 |   1.1483 |     38.793 |   1.1774 |     40.782 |     6.7
   42 |   1.1484 |     39.256 |   1.1607 |     40.317 |     6.9
   43 |   1.1416 |     38.727 |   1.1707 |     40.441 |     7.1
   44 |   1.1335 |     38.760 |   1.1796 |     40.627 |     7.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 292,129

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6441 |     47.961 |   1.3392 |     45.251 |     0.1
    2 |   1.3107 |     44.083 |   1.2554 |     43.544 |     0.1
    3 |   1.2469 |     42.854 |   1.1984 |     42.862 |     0.2
    4 |   1.1993 |     41.747 |   1.1837 |     42.955 |     0.3
    5 |   1.1676 |     40.810 |   1.1390 |     40.503 |     0.3
    6 |   1.1338 |     39.774 |   1.1103 |     38.827 |     0.4
    7 |   1.1116 |     38.981 |   1.0944 |     38.206 |     0.5
    8 |   1.0816 |     37.405 |   1.0682 |     37.647 |     0.5
    9 |   1.0602 |     36.975 |   1.0513 |     37.151 |     0.6
   10 |   1.0384 |     36.292 |   1.0497 |     36.282 |     0.7
   11 |   1.0185 |     35.273 |   1.0320 |     35.196 |     0.7
   12 |   0.9967 |     34.590 |   1.0245 |     35.692 |     0.8
   13 |   0.9779 |     34.160 |   1.0157 |     36.034 |     0.8
   14 |   0.9627 |     33.961 |   0.9920 |     34.047 |     0.9
   15 |   0.9440 |     32.937 |   0.9870 |     34.575 |     1.0
   16 |   0.9223 |     32.022 |   0.9895 |     33.333 |     1.0
   17 |   0.9016 |     31.267 |   0.9695 |     32.806 |     1.1
   18 |   0.8839 |     30.689 |   0.9808 |     33.023 |     1.2
   19 |   0.8748 |     29.994 |   0.9808 |     33.954 |     1.2
   20 |   0.8484 |     29.179 |   0.9732 |     33.613 |     1.3
   21 |   0.8314 |     28.490 |   0.9518 |     32.154 |     1.4
   22 |   0.8216 |     28.556 |   0.9331 |     30.975 |     1.4
   23 |   0.7996 |     27.355 |   0.9527 |     31.037 |     1.5
   24 |   0.7866 |     27.273 |   0.9238 |     30.726 |     1.6
   25 |   0.7636 |     26.573 |   0.9444 |     31.099 |     1.6
   26 |   0.7501 |     25.642 |   0.9517 |     31.750 |     1.7
   27 |   0.7446 |     25.835 |   0.9549 |     31.037 |     1.8
   28 |   0.7128 |     24.606 |   0.9452 |     31.502 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 847,393

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1927 |     54.738 |   1.5561 |     46.803 |     0.2
    2 |   1.5204 |     45.736 |   1.3947 |     46.896 |     0.4
    3 |   1.4091 |     45.102 |   1.3324 |     45.251 |     0.5
    4 |   1.3543 |     44.193 |   1.2965 |     44.227 |     0.7
    5 |   1.3115 |     43.427 |   1.2530 |     42.179 |     0.9
    6 |   1.2790 |     42.485 |   1.2270 |     42.551 |     1.1
    7 |   1.2495 |     41.625 |   1.2070 |     42.086 |     1.2
    8 |   1.2207 |     40.727 |   1.1915 |     40.255 |     1.4
    9 |   1.1992 |     40.320 |   1.1877 |     40.379 |     1.6
   10 |   1.1750 |     39.813 |   1.1550 |     38.703 |     1.8
   11 |   1.1572 |     39.025 |   1.1596 |     40.348 |     2.0
   12 |   1.1344 |     38.463 |   1.1519 |     39.727 |     2.1
   13 |   1.1181 |     37.890 |   1.1304 |     38.454 |     2.3
   14 |   1.1013 |     37.388 |   1.1176 |     37.896 |     2.5
   15 |   1.0822 |     36.584 |   1.1408 |     38.516 |     2.7
   16 |   1.0658 |     36.066 |   1.1408 |     39.106 |     2.8
   17 |   1.0472 |     35.537 |   1.1268 |     38.392 |     3.0
   18 |   1.0416 |     35.449 |   1.1210 |     37.678 |     3.2
   19 |   1.0249 |     34.832 |   1.1077 |     37.585 |     3.4
   20 |   1.0063 |     34.154 |   1.1033 |     37.337 |     3.6
   21 |   0.9940 |     33.642 |   1.1022 |     37.244 |     3.7
   22 |   0.9798 |     33.300 |   1.1237 |     37.647 |     3.9
   23 |   0.9689 |     32.793 |   1.1147 |     37.865 |     4.1
   24 |   0.9513 |     32.320 |   1.1317 |     38.051 |     4.3
   25 |   0.9403 |     31.730 |   1.1110 |     37.647 |     4.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 293,025

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7630 |     50.275 |   1.3662 |     46.307 |     0.1
    2 |   1.3524 |     45.129 |   1.2827 |     45.065 |     0.3
    3 |   1.2984 |     44.331 |   1.2387 |     44.382 |     0.5
    4 |   1.2634 |     43.702 |   1.2161 |     43.389 |     0.6
    5 |   1.2316 |     43.366 |   1.1951 |     43.048 |     0.8
    6 |   1.2144 |     42.656 |   1.1725 |     42.179 |     0.9
    7 |   1.1951 |     42.033 |   1.1558 |     41.651 |     1.1
    8 |   1.1782 |     41.416 |   1.1491 |     40.968 |     1.2
    9 |   1.1618 |     41.080 |   1.1308 |     39.665 |     1.4
   10 |   1.1485 |     40.446 |   1.1176 |     39.758 |     1.5
   11 |   1.1336 |     40.110 |   1.1207 |     40.099 |     1.7
   12 |   1.1214 |     39.471 |   1.1007 |     37.647 |     1.8
   13 |   1.1087 |     39.339 |   1.1062 |     39.572 |     2.0
   14 |   1.0952 |     38.408 |   1.0791 |     37.896 |     2.1
   15 |   1.0809 |     37.835 |   1.1060 |     39.479 |     2.3
   16 |   1.0776 |     38.099 |   1.0731 |     38.268 |     2.4
   17 |   1.0681 |     37.526 |   1.0718 |     37.772 |     2.6
   18 |   1.0556 |     37.306 |   1.0429 |     37.461 |     2.7
   19 |   1.0464 |     37.146 |   1.0443 |     37.585 |     2.9
   20 |   1.0324 |     36.298 |   1.0477 |     36.809 |     3.0
   21 |   1.0242 |     35.912 |   1.0410 |     37.058 |     3.2
   22 |   1.0124 |     35.592 |   1.0292 |     36.344 |     3.3
   23 |   1.0025 |     35.328 |   1.0421 |     36.654 |     3.5
   24 |   0.9877 |     34.986 |   1.0243 |     36.530 |     3.6
   25 |   0.9884 |     34.865 |   1.0255 |     36.251 |     3.8
   26 |   0.9743 |     34.325 |   1.0356 |     36.778 |     3.9
   27 |   0.9665 |     34.176 |   1.0089 |     35.382 |     4.1
   28 |   0.9490 |     33.504 |   1.0251 |     36.251 |     4.2
   29 |   0.9388 |     32.942 |   1.0132 |     35.661 |     4.4
   30 |   0.9306 |     32.926 |   1.0393 |     36.685 |     4.5
   31 |   0.9173 |     32.590 |   1.0640 |     37.120 |     4.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 235,041

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6387 |     47.620 |   1.3264 |     45.003 |     0.1
    2 |   1.2700 |     42.997 |   1.2202 |     41.372 |     0.1
    3 |   1.1893 |     40.667 |   1.1797 |     40.999 |     0.2
    4 |   1.1330 |     38.959 |   1.1515 |     39.230 |     0.3
    5 |   1.0928 |     38.116 |   1.0975 |     37.989 |     0.3
    6 |   1.0538 |     36.375 |   1.0948 |     37.244 |     0.4
    7 |   1.0147 |     35.085 |   1.0641 |     36.468 |     0.5
    8 |   0.9788 |     33.708 |   1.0312 |     35.320 |     0.5
    9 |   0.9496 |     33.052 |   1.0200 |     34.575 |     0.6
   10 |   0.9099 |     31.510 |   1.0106 |     35.071 |     0.6
   11 |   0.8773 |     29.846 |   0.9863 |     33.302 |     0.7
   12 |   0.8397 |     28.959 |   0.9928 |     33.054 |     0.8
   13 |   0.8136 |     28.006 |   0.9823 |     33.054 |     0.8
   14 |   0.7797 |     26.700 |   0.9847 |     32.247 |     0.9
   15 |   0.7487 |     25.515 |   0.9921 |     33.395 |     1.0
   16 |   0.7363 |     25.278 |   0.9842 |     32.123 |     1.0
   17 |   0.7011 |     24.353 |   0.9979 |     33.395 |     1.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 358,881

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6712 |     48.303 |   1.3328 |     44.600 |     0.1
    2 |   1.2632 |     42.837 |   1.2040 |     41.310 |     0.1
    3 |   1.1791 |     40.992 |   1.1776 |     42.086 |     0.2
    4 |   1.1239 |     39.410 |   1.1154 |     38.703 |     0.3
    5 |   1.0780 |     37.967 |   1.0889 |     37.368 |     0.3
    6 |   1.0322 |     36.110 |   1.0735 |     36.934 |     0.4
    7 |   0.9987 |     35.014 |   1.0360 |     36.561 |     0.5
    8 |   0.9602 |     33.477 |   1.0603 |     36.282 |     0.5
    9 |   0.9259 |     32.309 |   1.0286 |     35.164 |     0.6
   10 |   0.8854 |     31.030 |   1.0181 |     34.730 |     0.7
   11 |   0.8498 |     29.190 |   1.0000 |     33.457 |     0.7
   12 |   0.8095 |     28.231 |   1.0134 |     33.426 |     0.8
   13 |   0.7687 |     26.391 |   1.0143 |     33.706 |     0.9
   14 |   0.7218 |     25.030 |   0.9916 |     32.278 |     1.0
   15 |   0.6863 |     23.763 |   1.0443 |     33.457 |     1.0
   16 |   0.6490 |     22.755 |   1.0016 |     32.371 |     1.1
   17 |   0.6097 |     20.882 |   1.0396 |     32.961 |     1.2
   18 |   0.5771 |     20.094 |   1.0361 |     32.464 |     1.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 326,561

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4503 |     57.554 |   1.8006 |     46.958 |     0.1
    2 |   1.6335 |     45.625 |   1.5556 |     46.089 |     0.2
    3 |   1.4875 |     44.342 |   1.4602 |     45.686 |     0.3
    4 |   1.4109 |     43.179 |   1.3923 |     44.382 |     0.4
    5 |   1.3560 |     42.441 |   1.3643 |     44.041 |     0.5
    6 |   1.3155 |     41.851 |   1.3341 |     42.924 |     0.6
    7 |   1.2816 |     41.460 |   1.2897 |     42.675 |     0.7
    8 |   1.2557 |     41.107 |   1.2794 |     43.172 |     0.8
    9 |   1.2256 |     40.220 |   1.2411 |     42.334 |     0.9
   10 |   1.2017 |     39.796 |   1.2161 |     40.099 |     1.0
   11 |   1.1769 |     38.937 |   1.2289 |     41.651 |     1.1
   12 |   1.1614 |     38.529 |   1.1940 |     40.037 |     1.2
   13 |   1.1379 |     38.066 |   1.1874 |     39.944 |     1.3
   14 |   1.1183 |     37.355 |   1.1675 |     39.230 |     1.4
   15 |   1.1044 |     37.190 |   1.1460 |     38.330 |     1.5
   16 |   1.0877 |     36.143 |   1.1472 |     38.796 |     1.5
   17 |   1.0701 |     35.741 |   1.1322 |     38.113 |     1.6
   18 |   1.0555 |     35.328 |   1.1340 |     37.461 |     1.7
   19 |   1.0398 |     34.931 |   1.1242 |     37.275 |     1.8
   20 |   1.0263 |     34.408 |   1.1149 |     37.430 |     1.9
   21 |   1.0132 |     33.923 |   1.1415 |     37.927 |     2.0
   22 |   1.0034 |     33.846 |   1.1224 |     37.430 |     2.1
   23 |   0.9880 |     33.240 |   1.1187 |     37.834 |     2.2
   24 |   0.9767 |     32.606 |   1.0981 |     36.561 |     2.3
   25 |   0.9632 |     32.435 |   1.1125 |     36.778 |     2.4
   26 |   0.9551 |     32.165 |   1.0825 |     36.654 |     2.5
   27 |   0.9403 |     31.394 |   1.0987 |     36.220 |     2.6
   28 |   0.9240 |     30.843 |   1.1154 |     37.182 |     2.7
   29 |   0.9145 |     30.485 |   1.0901 |     36.282 |     2.8
   30 |   0.9096 |     30.545 |   1.0939 |     36.468 |     2.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,442,337

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5266 |     47.548 |   1.2994 |     45.158 |     0.1
    2 |   1.2593 |     44.033 |   1.2372 |     44.910 |     0.3
    3 |   1.1969 |     41.840 |   1.1919 |     42.986 |     0.4
    4 |   1.1574 |     40.986 |   1.1612 |     41.248 |     0.6
    5 |   1.1248 |     40.061 |   1.1497 |     41.030 |     0.8
    6 |   1.1114 |     39.780 |   1.1153 |     40.503 |     0.9
    7 |   1.0893 |     39.603 |   1.1205 |     40.596 |     1.1
    8 |   1.0720 |     39.047 |   1.0850 |     39.696 |     1.2
    9 |   1.0586 |     38.264 |   1.0943 |     39.789 |     1.4
   10 |   1.0413 |     38.165 |   1.0621 |     38.268 |     1.5
   11 |   1.0230 |     37.576 |   1.0751 |     38.796 |     1.7
   12 |   1.0099 |     36.705 |   1.0554 |     37.772 |     1.8
   13 |   0.9952 |     36.116 |   1.0377 |     36.716 |     2.0
   14 |   0.9846 |     35.620 |   1.0495 |     36.623 |     2.1
   15 |   0.9734 |     35.322 |   1.0478 |     36.530 |     2.3
   16 |   0.9587 |     34.904 |   1.0020 |     34.761 |     2.4
   17 |   0.9475 |     34.534 |   1.0079 |     36.220 |     2.6
   18 |   0.9392 |     33.862 |   1.0175 |     35.847 |     2.7
   19 |   0.9175 |     33.036 |   0.9822 |     33.954 |     2.9
   20 |   0.9126 |     32.441 |   0.9892 |     34.109 |     3.0
   21 |   0.8941 |     31.774 |   1.0056 |     35.940 |     3.2
   22 |   0.8775 |     31.140 |   0.9797 |     33.644 |     3.4
   23 |   0.8602 |     30.705 |   1.0005 |     34.637 |     3.5
   24 |   0.8514 |     30.138 |   0.9661 |     33.706 |     3.7
   25 |   0.8228 |     29.003 |   0.9910 |     34.016 |     3.8
   26 |   0.8121 |     28.777 |   0.9622 |     32.775 |     4.0
   27 |   0.8018 |     28.325 |   0.9514 |     32.775 |     4.1
   28 |   0.7904 |     27.769 |   0.9636 |     32.588 |     4.3
   29 |   0.7718 |     26.992 |   0.9574 |     32.185 |     4.4
   30 |   0.7521 |     26.463 |   0.9380 |     31.068 |     4.6
   31 |   0.7452 |     26.457 |   0.9483 |     31.068 |     4.7
   32 |   0.7336 |     25.846 |   0.9407 |     30.881 |     4.9
   33 |   0.7134 |     25.036 |   0.9421 |     30.912 |     5.0
   34 |   0.6975 |     24.601 |   0.9356 |     30.850 |     5.2
   35 |   0.6793 |     23.989 |   0.9581 |     31.130 |     5.3
   36 |   0.6688 |     23.543 |   0.9542 |     31.037 |     5.5
   37 |   0.6489 |     22.887 |   0.9482 |     30.757 |     5.6
   38 |   0.6352 |     22.028 |   0.9558 |     30.757 |     5.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 748,705

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6032 |     48.039 |   1.3185 |     45.965 |     0.2
    2 |   1.3111 |     44.815 |   1.2459 |     43.917 |     0.3
    3 |   1.2517 |     43.003 |   1.2528 |     42.613 |     0.5
    4 |   1.2157 |     42.375 |   1.1803 |     41.279 |     0.7
    5 |   1.1848 |     41.603 |   1.1672 |     40.565 |     0.9
    6 |   1.1638 |     40.876 |   1.1776 |     41.496 |     1.0
    7 |   1.1490 |     40.595 |   1.1557 |     40.875 |     1.2
    8 |   1.1263 |     39.884 |   1.1318 |     40.130 |     1.4
    9 |   1.1079 |     39.025 |   1.1231 |     39.851 |     1.6
   10 |   1.1016 |     39.025 |   1.1471 |     41.806 |     1.7
   11 |   1.0913 |     38.617 |   1.1150 |     39.603 |     1.9
   12 |   1.0800 |     38.309 |   1.1170 |     39.479 |     2.1
   13 |   1.0704 |     37.989 |   1.0981 |     39.696 |     2.3
   14 |   1.0565 |     37.620 |   1.1201 |     39.882 |     2.4
   15 |   1.0419 |     37.245 |   1.1079 |     40.223 |     2.6
   16 |   1.0289 |     36.562 |   1.1049 |     39.199 |     2.8
   17 |   1.0255 |     36.369 |   1.1327 |     38.423 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 358,881

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7054 |     48.667 |   1.3682 |     45.872 |     0.1
    2 |   1.3531 |     44.953 |   1.2912 |     45.065 |     0.1
    3 |   1.2838 |     43.366 |   1.2603 |     44.196 |     0.2
    4 |   1.2377 |     42.468 |   1.2029 |     43.048 |     0.3
    5 |   1.2014 |     41.708 |   1.1730 |     41.434 |     0.4
    6 |   1.1743 |     40.766 |   1.1522 |     40.099 |     0.4
    7 |   1.1479 |     40.231 |   1.1694 |     40.813 |     0.5
    8 |   1.1231 |     39.041 |   1.1035 |     38.579 |     0.6
    9 |   1.1010 |     38.358 |   1.0956 |     37.958 |     0.7
   10 |   1.0805 |     37.152 |   1.0822 |     37.120 |     0.7
   11 |   1.0606 |     36.887 |   1.0876 |     37.896 |     0.8
   12 |   1.0441 |     36.617 |   1.0625 |     36.654 |     0.9
   13 |   1.0252 |     35.791 |   1.0739 |     37.151 |     1.0
   14 |   1.0067 |     34.799 |   1.0177 |     34.854 |     1.0
   15 |   0.9909 |     34.105 |   1.0217 |     34.606 |     1.1
   16 |   0.9737 |     33.587 |   1.0335 |     36.282 |     1.2
   17 |   0.9571 |     33.047 |   1.0524 |     36.065 |     1.2
   18 |   0.9343 |     32.209 |   1.0034 |     34.327 |     1.3
   19 |   0.9188 |     31.752 |   1.0169 |     33.644 |     1.4
   20 |   0.9087 |     31.355 |   1.0689 |     35.940 |     1.5
   21 |   0.8898 |     30.512 |   1.0739 |     35.413 |     1.5
   22 |   0.8777 |     30.518 |   1.0015 |     33.426 |     1.6
   23 |   0.8555 |     28.975 |   0.9961 |     33.644 |     1.7
   24 |   0.8440 |     29.328 |   1.0310 |     33.706 |     1.8
   25 |   0.8261 |     28.264 |   1.0139 |     33.271 |     1.8
   26 |   0.8122 |     28.061 |   1.0460 |     34.885 |     1.9
   27 |   0.8048 |     27.796 |   1.0363 |     33.582 |     2.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,179,169

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5248 |     47.835 |   1.3055 |     45.593 |     0.2
    2 |   1.2635 |     44.369 |   1.2279 |     44.320 |     0.4
    3 |   1.1961 |     42.419 |   1.2003 |     42.768 |     0.5
    4 |   1.1458 |     40.612 |   1.1697 |     42.675 |     0.7
    5 |   1.1105 |     39.383 |   1.1378 |     40.968 |     0.9
    6 |   1.0858 |     38.556 |   1.1028 |     38.858 |     1.1
    7 |   1.0552 |     37.928 |   1.0650 |     38.547 |     1.3
    8 |   1.0374 |     37.168 |   1.0890 |     38.330 |     1.5
    9 |   1.0174 |     36.496 |   1.0520 |     36.965 |     1.6
   10 |   1.0040 |     36.198 |   1.0393 |     36.530 |     1.8
   11 |   0.9858 |     35.769 |   1.0434 |     36.778 |     2.0
   12 |   0.9783 |     35.163 |   1.0528 |     38.423 |     2.2
   13 |   0.9642 |     35.080 |   1.0365 |     36.313 |     2.4
   14 |   0.9497 |     34.028 |   1.0245 |     36.251 |     2.5
   15 |   0.9368 |     33.686 |   1.0056 |     35.723 |     2.7
   16 |   0.9164 |     32.887 |   1.0063 |     36.127 |     2.9
   17 |   0.9232 |     33.322 |   0.9982 |     34.792 |     3.1
   18 |   0.9052 |     32.171 |   1.0150 |     35.258 |     3.3
   19 |   0.9026 |     32.402 |   1.0371 |     35.133 |     3.5
   20 |   0.8969 |     32.303 |   1.0138 |     35.723 |     3.6
   21 |   0.8793 |     31.774 |   0.9768 |     33.861 |     3.8
   22 |   0.8647 |     31.052 |   1.0046 |     34.699 |     4.0
   23 |   0.8574 |     30.771 |   0.9990 |     34.513 |     4.2
   24 |   0.8433 |     30.006 |   1.0035 |     34.575 |     4.4
   25 |   0.8296 |     29.653 |   1.0050 |     34.916 |     4.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 648,225

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2340 |     55.730 |   1.5765 |     46.865 |     0.1
    2 |   1.5280 |     45.322 |   1.4106 |     45.655 |     0.2
    3 |   1.4101 |     44.479 |   1.3393 |     45.034 |     0.3
    4 |   1.3528 |     43.614 |   1.3056 |     44.569 |     0.4
    5 |   1.3092 |     42.738 |   1.2565 |     42.924 |     0.5
    6 |   1.2731 |     41.725 |   1.2383 |     42.551 |     0.6
    7 |   1.2444 |     41.394 |   1.2169 |     41.713 |     0.7
    8 |   1.2209 |     40.645 |   1.2002 |     41.993 |     0.8
    9 |   1.1973 |     40.176 |   1.1729 |     40.534 |     0.9
   10 |   1.1785 |     39.917 |   1.1727 |     40.658 |     1.0
   11 |   1.1584 |     39.300 |   1.1552 |     39.820 |     1.1
   12 |   1.1414 |     38.915 |   1.1532 |     39.913 |     1.2
   13 |   1.1267 |     38.242 |   1.1438 |     39.789 |     1.3
   14 |   1.1114 |     38.171 |   1.1395 |     39.665 |     1.4
   15 |   1.1030 |     37.818 |   1.1160 |     39.261 |     1.5
   16 |   1.0811 |     36.738 |   1.1228 |     39.075 |     1.6
   17 |   1.0751 |     36.909 |   1.0931 |     38.392 |     1.7
   18 |   1.0604 |     36.463 |   1.1151 |     39.106 |     1.8
   19 |   1.0500 |     36.000 |   1.0839 |     36.934 |     1.9
   20 |   1.0370 |     35.873 |   1.0970 |     38.423 |     2.0
   21 |   1.0242 |     34.799 |   1.0750 |     37.120 |     2.1
   22 |   1.0141 |     34.391 |   1.0670 |     37.089 |     2.2
   23 |   1.0089 |     34.534 |   1.0661 |     37.306 |     2.4
   24 |   0.9926 |     33.736 |   1.0630 |     36.530 |     2.5
   25 |   0.9829 |     33.455 |   1.0602 |     36.282 |     2.6
   26 |   0.9742 |     33.135 |   1.0721 |     36.251 |     2.7
   27 |   0.9685 |     33.278 |   1.0453 |     36.034 |     2.8
   28 |   0.9502 |     32.342 |   1.0387 |     35.692 |     2.9
   29 |   0.9431 |     32.259 |   1.0278 |     35.475 |     3.0
   30 |   0.9318 |     31.895 |   1.0735 |     36.406 |     3.1
   31 |   0.9207 |     31.526 |   1.0541 |     35.692 |     3.2
   32 |   0.9054 |     30.716 |   1.0358 |     35.723 |     3.3
   33 |   0.9035 |     30.782 |   1.0355 |     34.916 |     3.4
   34 |   0.8931 |     30.452 |   1.0177 |     34.327 |     3.5
   35 |   0.8878 |     30.176 |   1.0171 |     34.544 |     3.6
   36 |   0.8795 |     30.149 |   1.0261 |     34.140 |     3.7
   37 |   0.8668 |     29.444 |   1.0237 |     34.420 |     3.8
   38 |   0.8537 |     28.964 |   1.0403 |     35.133 |     3.9
   39 |   0.8478 |     28.837 |   1.0285 |     33.830 |     4.0
   40 |   0.8415 |     28.689 |   1.0120 |     34.078 |     4.1
   41 |   0.8280 |     28.209 |   1.0192 |     33.675 |     4.2
   42 |   0.8225 |     28.187 |   1.0284 |     34.140 |     4.3
   43 |   0.8114 |     27.421 |   1.0190 |     33.582 |     4.4
   44 |   0.8086 |     27.416 |   1.0434 |     34.823 |     4.5
   45 |   0.7958 |     27.096 |   1.0089 |     32.868 |     4.6
   46 |   0.7871 |     26.507 |   1.0357 |     33.271 |     4.7
   47 |   0.7759 |     26.347 |   1.0292 |     33.240 |     4.8
   48 |   0.7743 |     26.198 |   1.0277 |     33.613 |     4.9
   49 |   0.7652 |     25.956 |   1.0328 |     33.737 |     5.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 978,593

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5382 |     48.055 |   1.3119 |     46.369 |     0.1
    2 |   1.2353 |     42.650 |   1.2066 |     42.241 |     0.2
    3 |   1.1524 |     40.121 |   1.1397 |     38.547 |     0.3
    4 |   1.0952 |     38.215 |   1.1040 |     37.554 |     0.4
    5 |   1.0478 |     36.711 |   1.0965 |     38.610 |     0.5
    6 |   1.0092 |     35.300 |   1.0458 |     34.947 |     0.6
    7 |   0.9576 |     33.620 |   1.0213 |     35.133 |     0.8
    8 |   0.9261 |     32.325 |   0.9841 |     34.078 |     0.9
    9 |   0.8781 |     30.689 |   0.9725 |     32.154 |     1.0
   10 |   0.8445 |     29.410 |   0.9643 |     32.185 |     1.1
   11 |   0.8004 |     27.664 |   0.9567 |     32.526 |     1.2
   12 |   0.7725 |     27.135 |   0.9973 |     32.154 |     1.3
   13 |   0.7325 |     25.537 |   0.9412 |     31.099 |     1.4
   14 |   0.6991 |     24.287 |   0.9714 |     31.875 |     1.5
   15 |   0.6598 |     22.854 |   0.9680 |     32.185 |     1.6
   16 |   0.6221 |     21.763 |   0.9747 |     31.347 |     1.7
   17 |   0.5873 |     20.446 |   1.0097 |     31.688 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 525,601

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6078 |     48.083 |   1.3224 |     45.127 |     0.1
    2 |   1.2718 |     43.421 |   1.2256 |     43.482 |     0.2
    3 |   1.2081 |     42.512 |   1.1989 |     42.737 |     0.3
    4 |   1.1725 |     41.928 |   1.1675 |     42.334 |     0.5
    5 |   1.1459 |     41.196 |   1.1419 |     41.310 |     0.6
    6 |   1.1201 |     40.468 |   1.1234 |     41.930 |     0.7
    7 |   1.0943 |     39.322 |   1.1145 |     40.937 |     0.8
    8 |   1.0773 |     38.997 |   1.0838 |     39.665 |     0.9
    9 |   1.0521 |     38.116 |   1.0850 |     39.199 |     1.0
   10 |   1.0414 |     37.725 |   1.0682 |     38.206 |     1.1
   11 |   1.0151 |     36.860 |   1.0567 |     38.144 |     1.3
   12 |   1.0011 |     36.088 |   1.0575 |     37.585 |     1.4
   13 |   0.9812 |     35.372 |   1.0284 |     36.778 |     1.5
   14 |   0.9724 |     34.898 |   1.0461 |     37.585 |     1.6
   15 |   0.9508 |     34.270 |   1.0115 |     35.630 |     1.7
   16 |   0.9300 |     33.267 |   0.9863 |     34.947 |     1.8
   17 |   0.9145 |     32.612 |   0.9825 |     34.730 |     1.9
   18 |   0.8981 |     32.127 |   0.9851 |     34.544 |     2.0
   19 |   0.8882 |     31.691 |   0.9853 |     34.482 |     2.2
   20 |   0.8784 |     31.477 |   0.9777 |     35.040 |     2.3
   21 |   0.8617 |     30.975 |   0.9858 |     33.799 |     2.4
   22 |   0.8512 |     30.397 |   0.9744 |     33.582 |     2.5
   23 |   0.8350 |     29.587 |   0.9813 |     34.854 |     2.6
   24 |   0.8188 |     28.860 |   0.9748 |     33.457 |     2.7
   25 |   0.7947 |     27.994 |   0.9878 |     34.389 |     2.8
   26 |   0.7834 |     27.736 |   0.9524 |     32.185 |     3.0
   27 |   0.7627 |     26.970 |   0.9443 |     31.875 |     3.1
   28 |   0.7490 |     26.832 |   0.9458 |     31.161 |     3.2
   29 |   0.7416 |     26.121 |   0.9637 |     32.340 |     3.3
   30 |   0.7171 |     25.471 |   0.9659 |     32.402 |     3.4
   31 |   0.7037 |     24.964 |   0.9883 |     32.092 |     3.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,442,337

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2963 |     58.292 |   1.5555 |     46.741 |     0.2
    2 |   1.5728 |     46.187 |   1.4183 |     46.741 |     0.3
    3 |   1.4517 |     45.433 |   1.3690 |     45.624 |     0.5
    4 |   1.4006 |     44.727 |   1.3349 |     45.003 |     0.6
    5 |   1.3631 |     44.474 |   1.3256 |     45.996 |     0.8
    6 |   1.3353 |     43.818 |   1.2890 |     45.189 |     1.0
    7 |   1.3130 |     43.493 |   1.2649 |     44.724 |     1.1
    8 |   1.2910 |     43.245 |   1.2611 |     44.444 |     1.3
    9 |   1.2692 |     42.562 |   1.2545 |     43.824 |     1.5
   10 |   1.2560 |     42.171 |   1.2221 |     42.893 |     1.6
   11 |   1.2350 |     41.636 |   1.2307 |     42.862 |     1.8
   12 |   1.2185 |     41.361 |   1.2016 |     42.551 |     2.0
   13 |   1.1985 |     40.551 |   1.2652 |     43.079 |     2.1
   14 |   1.1847 |     40.099 |   1.2156 |     42.458 |     2.3
   15 |   1.1655 |     39.713 |   1.2240 |     42.117 |     2.4
   16 |   1.1543 |     39.322 |   1.2028 |     41.558 |     2.6
   17 |   1.1398 |     38.612 |   1.1848 |     41.341 |     2.8
   18 |   1.1222 |     38.116 |   1.1450 |     38.982 |     2.9
   19 |   1.1129 |     38.028 |   1.2016 |     40.006 |     3.1
   20 |   1.0973 |     37.559 |   1.1772 |     39.758 |     3.3
   21 |   1.0834 |     37.140 |   1.1476 |     39.510 |     3.4
   22 |   1.0728 |     36.672 |   1.1508 |     38.858 |     3.6
   23 |   1.0597 |     36.121 |   1.1398 |     38.299 |     3.8
   24 |   1.0484 |     35.829 |   1.1494 |     38.610 |     3.9
   25 |   1.0326 |     35.383 |   1.1424 |     37.865 |     4.1
   26 |   1.0222 |     35.008 |   1.1681 |     38.268 |     4.2
   27 |   1.0131 |     34.882 |   1.1874 |     38.268 |     4.4
   28 |   0.9984 |     33.945 |   1.1218 |     36.685 |     4.6
   29 |   0.9886 |     33.796 |   1.0867 |     36.158 |     4.7
   30 |   0.9786 |     33.300 |   1.1556 |     37.523 |     4.9
   31 |   0.9643 |     32.876 |   1.1206 |     36.623 |     5.1
   32 |   0.9499 |     32.353 |   1.1913 |     37.896 |     5.2
   33 |   0.9443 |     32.270 |   1.1532 |     37.244 |     5.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 779,809

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1082 |     54.132 |   1.5217 |     46.648 |     0.1
    2 |   1.4921 |     45.366 |   1.3874 |     45.841 |     0.2
    3 |   1.3919 |     44.325 |   1.3280 |     44.724 |     0.3
    4 |   1.3376 |     43.499 |   1.2942 |     44.320 |     0.4
    5 |   1.2970 |     42.700 |   1.2578 |     43.606 |     0.5
    6 |   1.2631 |     41.873 |   1.2256 |     42.613 |     0.6
    7 |   1.2361 |     41.124 |   1.2068 |     41.124 |     0.7
    8 |   1.2068 |     40.248 |   1.1875 |     41.217 |     0.9
    9 |   1.1869 |     39.912 |   1.1780 |     41.124 |     1.0
   10 |   1.1629 |     39.300 |   1.1510 |     40.006 |     1.1
   11 |   1.1461 |     38.854 |   1.1448 |     39.882 |     1.2
   12 |   1.1277 |     38.463 |   1.1126 |     38.579 |     1.3
   13 |   1.1059 |     37.532 |   1.1338 |     39.261 |     1.4
   14 |   1.0886 |     36.953 |   1.1269 |     39.075 |     1.5
   15 |   1.0722 |     36.650 |   1.1155 |     38.796 |     1.6
   16 |   1.0591 |     35.774 |   1.0818 |     37.306 |     1.7
   17 |   1.0429 |     35.317 |   1.0993 |     38.113 |     1.8
   18 |   1.0294 |     34.909 |   1.0650 |     36.530 |     1.9
   19 |   1.0068 |     33.791 |   1.1008 |     37.803 |     2.0
   20 |   0.9977 |     33.862 |   1.0555 |     36.623 |     2.1
   21 |   0.9825 |     33.085 |   1.0729 |     36.809 |     2.2
   22 |   0.9662 |     32.694 |   1.0794 |     36.903 |     2.3
   23 |   0.9561 |     32.105 |   1.0812 |     36.996 |     2.4
   24 |   0.9449 |     31.928 |   1.0538 |     36.561 |     2.6
   25 |   0.9307 |     31.427 |   1.0626 |     36.406 |     2.7
   26 |   0.9163 |     31.058 |   1.0721 |     36.809 |     2.8
   27 |   0.9090 |     30.694 |   1.0761 |     36.344 |     2.9
   28 |   0.8962 |     30.132 |   1.0588 |     35.009 |     3.0
   29 |   0.8825 |     29.702 |   1.0512 |     35.506 |     3.1
   30 |   0.8718 |     29.394 |   1.0672 |     35.692 |     3.2
   31 |   0.8611 |     29.080 |   1.0354 |     34.637 |     3.3
   32 |   0.8495 |     28.810 |   1.0512 |     34.947 |     3.4
   33 |   0.8376 |     28.573 |   1.0362 |     34.420 |     3.5
   34 |   0.8287 |     28.160 |   1.0284 |     34.544 |     3.6
   35 |   0.8113 |     27.493 |   1.0314 |     34.047 |     3.7
   36 |   0.8002 |     27.256 |   1.0496 |     34.140 |     3.8
   37 |   0.7901 |     26.595 |   1.0419 |     34.264 |     3.9
   38 |   0.7871 |     26.716 |   1.0319 |     33.457 |     4.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 393,505

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6647 |     48.590 |   1.3311 |     44.910 |     0.1
    2 |   1.2708 |     43.675 |   1.2225 |     43.669 |     0.3
    3 |   1.2085 |     42.292 |   1.2000 |     43.017 |     0.5
    4 |   1.1688 |     41.736 |   1.1693 |     42.831 |     0.6
    5 |   1.1451 |     41.344 |   1.1330 |     41.030 |     0.8
    6 |   1.1223 |     40.463 |   1.1137 |     39.634 |     0.9
    7 |   1.1010 |     39.300 |   1.0996 |     39.230 |     1.1
    8 |   1.0820 |     39.014 |   1.0910 |     39.820 |     1.2
    9 |   1.0688 |     38.556 |   1.0872 |     39.354 |     1.4
   10 |   1.0529 |     37.895 |   1.0886 |     38.361 |     1.5
   11 |   1.0421 |     37.609 |   1.0763 |     38.951 |     1.7
   12 |   1.0285 |     37.377 |   1.0733 |     38.392 |     1.8
   13 |   1.0238 |     37.185 |   1.0615 |     39.385 |     2.0
   14 |   1.0144 |     37.091 |   1.0557 |     38.796 |     2.2
   15 |   1.0069 |     36.534 |   1.0658 |     39.975 |     2.3
   16 |   1.0006 |     36.490 |   1.0909 |     38.982 |     2.5
   17 |   0.9952 |     36.556 |   1.0523 |     37.772 |     2.6
   18 |   0.9867 |     36.000 |   1.0793 |     39.261 |     2.8
   19 |   0.9775 |     35.747 |   1.1203 |     38.889 |     2.9
   20 |   0.9712 |     35.554 |   1.0790 |     39.075 |     3.1
   21 |   0.9674 |     35.675 |   1.1161 |     39.106 |     3.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 358,881

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7091 |     67.229 |   1.9359 |     47.176 |     0.1
    2 |   1.9043 |     46.843 |   1.6226 |     46.741 |     0.1
    3 |   1.6596 |     45.994 |   1.5130 |     46.741 |     0.2
    4 |   1.5537 |     45.840 |   1.4500 |     46.741 |     0.3
    5 |   1.4908 |     45.708 |   1.4097 |     46.865 |     0.4
    6 |   1.4462 |     45.493 |   1.3746 |     46.462 |     0.4
    7 |   1.4147 |     45.118 |   1.3468 |     45.686 |     0.5
    8 |   1.3867 |     44.920 |   1.3246 |     45.872 |     0.6
    9 |   1.3641 |     44.468 |   1.3087 |     45.407 |     0.7
   10 |   1.3442 |     44.419 |   1.2871 |     44.351 |     0.7
   11 |   1.3276 |     43.873 |   1.2791 |     43.917 |     0.8
   12 |   1.3140 |     43.769 |   1.2607 |     43.669 |     0.9
   13 |   1.2959 |     43.289 |   1.2536 |     43.886 |     1.0
   14 |   1.2880 |     42.804 |   1.2482 |     43.793 |     1.0
   15 |   1.2774 |     42.612 |   1.2334 |     43.451 |     1.1
   16 |   1.2652 |     42.193 |   1.2467 |     43.606 |     1.2
   17 |   1.2518 |     42.143 |   1.2333 |     43.575 |     1.3
   18 |   1.2425 |     41.576 |   1.2226 |     42.551 |     1.3
   19 |   1.2315 |     41.565 |   1.2308 |     42.862 |     1.4
   20 |   1.2234 |     41.488 |   1.2035 |     42.024 |     1.5
   21 |   1.2136 |     40.997 |   1.2110 |     42.148 |     1.6
   22 |   1.2081 |     41.025 |   1.1886 |     41.558 |     1.6
   23 |   1.2007 |     40.992 |   1.1895 |     41.279 |     1.7
   24 |   1.1911 |     40.298 |   1.2097 |     42.117 |     1.8
   25 |   1.1843 |     40.595 |   1.1901 |     41.434 |     1.8
   26 |   1.1767 |     39.983 |   1.1944 |     41.527 |     1.9
   27 |   1.1725 |     40.176 |   1.1732 |     41.186 |     2.0
   28 |   1.1668 |     39.824 |   1.1873 |     41.061 |     2.1
   29 |   1.1568 |     39.504 |   1.1944 |     40.720 |     2.1
   30 |   1.1554 |     39.587 |   1.1671 |     40.782 |     2.2
   31 |   1.1494 |     39.394 |   1.1732 |     40.534 |     2.3
   32 |   1.1429 |     39.069 |   1.1869 |     40.689 |     2.4
   33 |   1.1379 |     39.223 |   1.2006 |     41.465 |     2.4
   34 |   1.1327 |     38.915 |   1.1659 |     40.317 |     2.5
   35 |   1.1274 |     38.661 |   1.1670 |     40.844 |     2.6
   36 |   1.1242 |     39.036 |   1.1594 |     40.410 |     2.7
   37 |   1.1171 |     38.226 |   1.1685 |     40.503 |     2.7
   38 |   1.1115 |     38.496 |   1.1594 |     40.379 |     2.8
   39 |   1.1039 |     38.242 |   1.1315 |     39.975 |     2.9
   40 |   1.1038 |     38.127 |   1.1495 |     39.634 |     3.0
   41 |   1.1000 |     38.033 |   1.1704 |     40.751 |     3.0
   42 |   1.0968 |     37.581 |   1.1554 |     40.503 |     3.1
   43 |   1.0843 |     37.449 |   1.1605 |     40.596 |     3.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 193,057

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7442 |     49.499 |   1.3557 |     46.089 |     0.1
    2 |   1.3428 |     44.799 |   1.2790 |     45.189 |     0.1
    3 |   1.2828 |     43.609 |   1.2278 |     42.675 |     0.2
    4 |   1.2387 |     42.435 |   1.2102 |     42.551 |     0.2
    5 |   1.2023 |     41.713 |   1.1573 |     42.024 |     0.3
    6 |   1.1766 |     40.738 |   1.1448 |     40.565 |     0.4
    7 |   1.1464 |     40.061 |   1.1740 |     41.651 |     0.4
    8 |   1.1297 |     39.444 |   1.1119 |     39.479 |     0.5
    9 |   1.1049 |     38.650 |   1.0861 |     38.982 |     0.6
   10 |   1.0884 |     38.143 |   1.0808 |     38.206 |     0.6
   11 |   1.0695 |     37.554 |   1.0572 |     37.616 |     0.7
   12 |   1.0577 |     37.311 |   1.0566 |     37.989 |     0.7
   13 |   1.0381 |     36.187 |   1.0536 |     37.275 |     0.8
   14 |   1.0318 |     36.116 |   1.0233 |     36.313 |     0.9
   15 |   1.0144 |     35.118 |   1.0189 |     35.692 |     0.9
   16 |   0.9939 |     34.501 |   1.0010 |     35.320 |     1.0
   17 |   0.9857 |     34.204 |   0.9875 |     34.420 |     1.1
   18 |   0.9717 |     33.532 |   0.9801 |     33.706 |     1.1
   19 |   0.9572 |     33.339 |   0.9875 |     34.451 |     1.2
   20 |   0.9433 |     32.876 |   0.9986 |     34.171 |     1.2
   21 |   0.9332 |     32.171 |   0.9807 |     33.116 |     1.3
   22 |   0.9158 |     31.774 |   0.9741 |     32.775 |     1.4
   23 |   0.9046 |     31.455 |   0.9613 |     32.682 |     1.4
   24 |   0.8905 |     30.612 |   0.9815 |     33.147 |     1.5
   25 |   0.8850 |     30.738 |   0.9708 |     32.992 |     1.5
   26 |   0.8760 |     30.116 |   0.9378 |     31.409 |     1.6
   27 |   0.8623 |     29.614 |   0.9460 |     31.750 |     1.7
   28 |   0.8505 |     29.521 |   0.9558 |     31.719 |     1.7
   29 |   0.8394 |     29.074 |   0.9444 |     31.533 |     1.8
   30 |   0.8312 |     28.590 |   0.9609 |     32.588 |     1.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,177,377

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4963 |     46.634 |   1.2826 |     44.910 |     0.1
    2 |   1.2203 |     41.934 |   1.2264 |     43.731 |     0.2
    3 |   1.1593 |     40.463 |   1.2153 |     41.868 |     0.3
    4 |   1.1160 |     39.295 |   1.1179 |     39.541 |     0.4
    5 |   1.0737 |     38.022 |   1.0862 |     39.230 |     0.5
    6 |   1.0346 |     36.501 |   1.0784 |     37.958 |     0.6
    7 |   1.0084 |     35.493 |   1.0609 |     38.423 |     0.7
    8 |   0.9749 |     34.342 |   1.0489 |     37.461 |     0.8
    9 |   0.9387 |     33.223 |   1.0406 |     37.523 |     0.9
   10 |   0.9119 |     31.989 |   1.0478 |     35.847 |     1.0
   11 |   0.8848 |     30.942 |   1.0372 |     36.034 |     1.1
   12 |   0.8531 |     29.983 |   1.0754 |     37.027 |     1.2
   13 |   0.8275 |     29.791 |   1.0446 |     35.661 |     1.3
   14 |   0.8015 |     28.320 |   1.0251 |     34.482 |     1.4
   15 |   0.7734 |     27.328 |   1.0539 |     34.823 |     1.5
   16 |   0.7515 |     26.639 |   1.0498 |     34.606 |     1.6
   17 |   0.7003 |     24.623 |   1.0945 |     34.761 |     1.7
   18 |   0.6750 |     23.901 |   1.0489 |     35.630 |     1.7
Early stopping

