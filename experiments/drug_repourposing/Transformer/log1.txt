Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 458,978

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6879 |     63.187 |   2.0034 |     48.941 |     0.2
    2 |   1.9319 |     47.407 |   1.6701 |     47.072 |     0.3
    3 |   1.6798 |     46.234 |   1.5516 |     46.573 |     0.5
    4 |   1.5680 |     46.008 |   1.4735 |     45.234 |     0.6
    5 |   1.5020 |     45.744 |   1.4460 |     45.981 |     0.8
    6 |   1.4565 |     45.474 |   1.4171 |     45.981 |     1.0
    7 |   1.4155 |     45.006 |   1.3849 |     45.639 |     1.1
    8 |   1.3918 |     44.951 |   1.3604 |     45.296 |     1.3
    9 |   1.3694 |     44.566 |   1.3424 |     45.389 |     1.5
   10 |   1.3472 |     44.020 |   1.3134 |     44.455 |     1.6
   11 |   1.3304 |     43.723 |   1.3198 |     45.389 |     1.8
   12 |   1.3110 |     43.519 |   1.3067 |     44.673 |     2.0
   13 |   1.2923 |     43.151 |   1.2971 |     44.642 |     2.1
   14 |   1.2819 |     42.754 |   1.2663 |     43.801 |     2.3
   15 |   1.2654 |     42.358 |   1.2646 |     43.333 |     2.5
   16 |   1.2549 |     42.159 |   1.2576 |     42.991 |     2.6
   17 |   1.2448 |     42.071 |   1.2505 |     42.648 |     2.8
   18 |   1.2351 |     41.895 |   1.2285 |     42.025 |     3.0
   19 |   1.2228 |     41.223 |   1.2541 |     42.773 |     3.1
   20 |   1.2136 |     41.080 |   1.2519 |     42.461 |     3.3
   21 |   1.2077 |     40.987 |   1.2432 |     42.399 |     3.5
   22 |   1.1995 |     40.871 |   1.2248 |     41.589 |     3.6
   23 |   1.1950 |     40.612 |   1.2267 |     41.869 |     3.8
   24 |   1.1849 |     40.436 |   1.2426 |     42.212 |     4.0
   25 |   1.1797 |     40.183 |   1.2241 |     41.651 |     4.1
   26 |   1.1702 |     39.687 |   1.2252 |     41.558 |     4.3
   27 |   1.1611 |     39.406 |   1.2331 |     42.243 |     4.5
   28 |   1.1578 |     39.786 |   1.2202 |     41.682 |     4.6
   29 |   1.1491 |     38.933 |   1.2321 |     41.963 |     4.8
   30 |   1.1399 |     38.867 |   1.2480 |     41.963 |     5.0
   31 |   1.1367 |     38.988 |   1.2407 |     41.931 |     5.1
   32 |   1.1325 |     38.773 |   1.2260 |     41.153 |     5.3
   33 |   1.1274 |     38.630 |   1.2078 |     41.090 |     5.5
   34 |   1.1163 |     38.162 |   1.2279 |     41.371 |     5.7
   35 |   1.1104 |     38.184 |   1.2298 |     41.464 |     5.8
   36 |   1.1051 |     37.870 |   1.2144 |     40.717 |     6.0
   37 |   1.1014 |     37.656 |   1.1879 |     40.312 |     6.2
   38 |   1.0960 |     37.545 |   1.1905 |     40.498 |     6.3
   39 |   1.0916 |     37.397 |   1.1917 |     39.969 |     6.5
   40 |   1.0847 |     37.254 |   1.1814 |     40.062 |     6.7
   41 |   1.0779 |     37.138 |   1.1975 |     39.969 |     6.8
   42 |   1.0739 |     37.055 |   1.1892 |     40.062 |     7.0
   43 |   1.0734 |     36.664 |   1.1754 |     39.657 |     7.2
   44 |   1.0615 |     36.659 |   1.1869 |     39.844 |     7.3
   45 |   1.0563 |     36.246 |   1.1878 |     40.187 |     7.5
   46 |   1.0536 |     36.086 |   1.1876 |     39.813 |     7.7
   47 |   1.0532 |     36.235 |   1.1932 |     40.218 |     7.8
   48 |   1.0427 |     35.784 |   1.1711 |     40.031 |     8.0
   49 |   1.0406 |     35.695 |   1.1756 |     39.938 |     8.2
   50 |   1.0326 |     35.277 |   1.1674 |     39.564 |     8.3
   51 |   1.0230 |     35.327 |   1.1898 |     40.249 |     8.5
   52 |   1.0233 |     35.249 |   1.1818 |     39.875 |     8.7
   53 |   1.0163 |     35.024 |   1.1917 |     39.533 |     8.8
   54 |   1.0128 |     34.561 |   1.1868 |     40.125 |     9.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 881,570

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7559 |     51.459 |   1.3720 |     44.642 |     0.1
    2 |   1.3306 |     44.461 |   1.2799 |     43.146 |     0.2
    3 |   1.2693 |     42.875 |   1.2088 |     41.620 |     0.3
    4 |   1.2222 |     41.713 |   1.1848 |     40.935 |     0.4
    5 |   1.1886 |     41.031 |   1.1748 |     39.969 |     0.5
    6 |   1.1601 |     39.566 |   1.1605 |     39.377 |     0.6
    7 |   1.1340 |     39.307 |   1.1394 |     38.816 |     0.7
    8 |   1.1038 |     37.898 |   1.1209 |     38.287 |     0.8
    9 |   1.0863 |     37.171 |   1.1346 |     38.162 |     0.9
   10 |   1.0631 |     36.664 |   1.1296 |     38.131 |     1.0
   11 |   1.0393 |     36.026 |   1.1282 |     37.134 |     1.1
   12 |   1.0214 |     35.167 |   1.1068 |     37.103 |     1.2
   13 |   0.9941 |     34.231 |   1.1483 |     37.103 |     1.3
   14 |   0.9822 |     34.198 |   1.1109 |     36.698 |     1.4
   15 |   0.9533 |     32.854 |   1.1360 |     36.760 |     1.5
   16 |   0.9481 |     32.689 |   1.1387 |     37.009 |     1.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 978,850

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9055 |     51.189 |   1.4685 |     45.670 |     0.1
    2 |   1.3815 |     43.591 |   1.3625 |     44.673 |     0.2
    3 |   1.2934 |     42.380 |   1.2962 |     42.741 |     0.3
    4 |   1.2319 |     40.926 |   1.2539 |     41.776 |     0.4
    5 |   1.1853 |     39.693 |   1.2116 |     41.713 |     0.4
    6 |   1.1422 |     38.702 |   1.2131 |     40.654 |     0.5
    7 |   1.1080 |     37.650 |   1.1876 |     40.000 |     0.6
    8 |   1.0790 |     37.033 |   1.1307 |     38.224 |     0.7
    9 |   1.0472 |     35.651 |   1.1494 |     39.190 |     0.8
   10 |   1.0162 |     34.633 |   1.1025 |     37.539 |     0.9
   11 |   0.9914 |     33.559 |   1.1185 |     37.913 |     1.0
   12 |   0.9632 |     32.618 |   1.0848 |     36.760 |     1.1
   13 |   0.9419 |     31.753 |   1.0895 |     37.009 |     1.2
   14 |   0.9137 |     30.723 |   1.0922 |     36.386 |     1.3
   15 |   0.8878 |     29.969 |   1.0937 |     36.044 |     1.4
   16 |   0.8609 |     28.664 |   1.0342 |     34.579 |     1.5
   17 |   0.8403 |     28.119 |   1.0487 |     34.704 |     1.5
   18 |   0.8127 |     27.095 |   1.0562 |     35.327 |     1.6
   19 |   0.7892 |     26.198 |   1.0445 |     34.891 |     1.7
   20 |   0.7661 |     25.614 |   1.0703 |     35.234 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 243,618

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6671 |     47.561 |   1.3377 |     44.548 |     0.1
    2 |   1.2859 |     43.652 |   1.2656 |     44.486 |     0.3
    3 |   1.2179 |     42.892 |   1.1964 |     42.243 |     0.4
    4 |   1.1782 |     41.796 |   1.1799 |     42.087 |     0.6
    5 |   1.1486 |     41.097 |   1.1488 |     41.807 |     0.7
    6 |   1.1171 |     39.462 |   1.1353 |     40.031 |     0.8
    7 |   1.0958 |     38.663 |   1.1147 |     39.502 |     1.0
    8 |   1.0720 |     37.925 |   1.1060 |     40.000 |     1.1
    9 |   1.0590 |     37.336 |   1.0993 |     39.346 |     1.2
   10 |   1.0391 |     36.753 |   1.0717 |     37.321 |     1.4
   11 |   1.0235 |     36.285 |   1.0651 |     37.975 |     1.5
   12 |   1.0036 |     35.453 |   1.0567 |     36.947 |     1.7
   13 |   0.9845 |     34.787 |   1.0570 |     37.508 |     1.8
   14 |   0.9692 |     34.258 |   1.0464 |     36.854 |     1.9
   15 |   0.9566 |     34.055 |   1.0456 |     36.231 |     2.1
   16 |   0.9366 |     33.168 |   1.0543 |     36.760 |     2.2
   17 |   0.9135 |     32.249 |   1.0155 |     35.389 |     2.4
   18 |   0.9052 |     32.050 |   1.0264 |     36.947 |     2.5
   19 |   0.8854 |     31.571 |   1.0195 |     35.701 |     2.6
   20 |   0.8695 |     30.487 |   1.0048 |     34.579 |     2.8
   21 |   0.8512 |     29.958 |   1.0365 |     35.670 |     2.9
   22 |   0.8331 |     29.386 |   1.0484 |     35.670 |     3.0
   23 |   0.8251 |     29.110 |   1.0151 |     35.016 |     3.2
   24 |   0.7972 |     27.849 |   1.0180 |     34.579 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 458,978

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7526 |     49.251 |   1.3717 |     45.701 |     0.1
    2 |   1.3547 |     45.133 |   1.3179 |     47.196 |     0.2
    3 |   1.3049 |     44.555 |   1.2522 |     44.019 |     0.3
    4 |   1.2747 |     44.125 |   1.2364 |     44.642 |     0.5
    5 |   1.2540 |     44.131 |   1.2170 |     42.586 |     0.6
    6 |   1.2310 |     43.497 |   1.1894 |     43.302 |     0.7
    7 |   1.2219 |     43.657 |   1.1742 |     41.838 |     0.8
    8 |   1.2020 |     42.914 |   1.1557 |     41.651 |     0.9
    9 |   1.1911 |     42.270 |   1.1438 |     41.464 |     1.1
   10 |   1.1739 |     42.198 |   1.1416 |     40.280 |     1.2
   11 |   1.1662 |     41.614 |   1.1341 |     39.875 |     1.3
   12 |   1.1558 |     40.998 |   1.1117 |     39.003 |     1.4
   13 |   1.1363 |     40.695 |   1.1114 |     40.249 |     1.5
   14 |   1.1261 |     39.919 |   1.1120 |     39.315 |     1.6
   15 |   1.1165 |     39.841 |   1.1035 |     39.439 |     1.8
   16 |   1.1024 |     39.693 |   1.0951 |     39.346 |     1.9
   17 |   1.0910 |     39.054 |   1.0996 |     40.093 |     2.0
   18 |   1.0872 |     39.181 |   1.0819 |     39.003 |     2.1
   19 |   1.0737 |     38.294 |   1.0647 |     38.660 |     2.2
   20 |   1.0627 |     37.914 |   1.1004 |     39.502 |     2.4
   21 |   1.0507 |     37.969 |   1.0763 |     39.190 |     2.5
   22 |   1.0407 |     37.623 |   1.0762 |     39.065 |     2.6
   23 |   1.0353 |     37.072 |   1.0851 |     39.533 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 393,634

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8829 |     51.856 |   1.4163 |     45.576 |     0.1
    2 |   1.3898 |     45.727 |   1.3147 |     44.143 |     0.2
    3 |   1.3328 |     45.001 |   1.2713 |     43.146 |     0.4
    4 |   1.2909 |     44.422 |   1.2472 |     43.769 |     0.5
    5 |   1.2592 |     43.442 |   1.2126 |     43.022 |     0.6
    6 |   1.2381 |     43.459 |   1.2004 |     42.025 |     0.7
    7 |   1.2178 |     42.694 |   1.1738 |     41.090 |     0.8
    8 |   1.2025 |     41.741 |   1.1778 |     40.592 |     1.0
    9 |   1.1875 |     41.444 |   1.1664 |     41.340 |     1.1
   10 |   1.1782 |     41.543 |   1.1430 |     40.592 |     1.2
   11 |   1.1646 |     40.987 |   1.1368 |     39.252 |     1.3
   12 |   1.1527 |     40.579 |   1.1315 |     40.810 |     1.4
   13 |   1.1405 |     40.183 |   1.1253 |     40.249 |     1.6
   14 |   1.1363 |     39.996 |   1.1274 |     40.187 |     1.7
   15 |   1.1190 |     39.731 |   1.1102 |     39.595 |     1.8
   16 |   1.1160 |     39.484 |   1.0961 |     38.785 |     1.9
   17 |   1.0977 |     38.641 |   1.0949 |     38.972 |     2.0
   18 |   1.0942 |     38.889 |   1.0869 |     38.006 |     2.2
   19 |   1.0822 |     38.503 |   1.0722 |     37.664 |     2.3
   20 |   1.0726 |     38.074 |   1.0758 |     37.819 |     2.4
   21 |   1.0664 |     37.903 |   1.0655 |     38.162 |     2.5
   22 |   1.0537 |     37.804 |   1.0614 |     38.100 |     2.7
   23 |   1.0475 |     37.342 |   1.0670 |     37.103 |     2.8
   24 |   1.0421 |     37.033 |   1.0522 |     37.072 |     2.9
   25 |   1.0304 |     36.659 |   1.0548 |     37.009 |     3.0
   26 |   1.0202 |     36.488 |   1.0830 |     38.131 |     3.1
   27 |   1.0154 |     36.048 |   1.0584 |     37.259 |     3.3
   28 |   1.0030 |     35.437 |   1.0803 |     37.601 |     3.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,177,634

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5398 |     48.227 |   1.2691 |     43.053 |     0.1
    2 |   1.2237 |     42.462 |   1.1942 |     42.118 |     0.2
    3 |   1.1475 |     40.221 |   1.1304 |     39.377 |     0.3
    4 |   1.0932 |     38.052 |   1.1142 |     39.128 |     0.4
    5 |   1.0541 |     36.290 |   1.0796 |     37.757 |     0.5
    6 |   1.0129 |     34.847 |   1.0859 |     37.601 |     0.6
    7 |   0.9800 |     33.933 |   1.0432 |     36.168 |     0.7
    8 |   0.9449 |     32.700 |   1.0284 |     34.891 |     0.8
    9 |   0.9046 |     31.390 |   1.0280 |     34.050 |     0.9
   10 |   0.8643 |     29.975 |   1.0347 |     35.234 |     1.0
   11 |   0.8314 |     29.022 |   1.0200 |     34.704 |     1.1
   12 |   0.7983 |     27.629 |   1.0173 |     32.960 |     1.2
   13 |   0.7585 |     26.027 |   1.0166 |     33.738 |     1.3
   14 |   0.7163 |     24.524 |   1.0037 |     33.271 |     1.4
   15 |   0.6697 |     23.180 |   1.0079 |     34.112 |     1.5
   16 |   0.6413 |     22.288 |   1.0690 |     32.960 |     1.6
   17 |   0.6086 |     20.862 |   1.0699 |     32.368 |     1.7
   18 |   0.5606 |     19.007 |   1.1187 |     32.960 |     1.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 243,618

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.9710 |     75.454 |   2.4557 |     64.735 |     0.1
    2 |   2.3224 |     54.983 |   1.9140 |     48.816 |     0.2
    3 |   1.8987 |     48.051 |   1.6269 |     46.791 |     0.3
    4 |   1.6730 |     46.179 |   1.5337 |     46.791 |     0.4
    5 |   1.5723 |     45.898 |   1.4898 |     46.791 |     0.5
    6 |   1.5151 |     45.810 |   1.4514 |     46.636 |     0.6
    7 |   1.4777 |     45.463 |   1.4231 |     46.262 |     0.7
    8 |   1.4494 |     45.584 |   1.4084 |     45.514 |     0.8
    9 |   1.4271 |     45.287 |   1.3975 |     46.168 |     0.9
   10 |   1.4105 |     45.232 |   1.3767 |     46.137 |     1.0
   11 |   1.3899 |     44.973 |   1.3635 |     45.421 |     1.1
   12 |   1.3763 |     44.483 |   1.3577 |     45.763 |     1.2
   13 |   1.3618 |     44.378 |   1.3440 |     45.171 |     1.3
   14 |   1.3475 |     44.076 |   1.3382 |     44.579 |     1.4
   15 |   1.3360 |     44.114 |   1.3215 |     44.330 |     1.5
   16 |   1.3221 |     43.409 |   1.3225 |     44.299 |     1.6
   17 |   1.3114 |     43.211 |   1.3063 |     43.988 |     1.7
   18 |   1.3025 |     43.239 |   1.3097 |     43.925 |     1.9
   19 |   1.2903 |     42.996 |   1.3095 |     43.801 |     2.0
   20 |   1.2810 |     42.660 |   1.2908 |     43.146 |     2.1
   21 |   1.2693 |     42.627 |   1.2877 |     43.022 |     2.2
   22 |   1.2657 |     42.413 |   1.3044 |     43.209 |     2.3
   23 |   1.2591 |     42.104 |   1.3114 |     43.520 |     2.4
   24 |   1.2518 |     42.176 |   1.3220 |     44.019 |     2.5
   25 |   1.2435 |     41.879 |   1.3311 |     43.956 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 292,258

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5570 |     59.520 |   1.9661 |     46.075 |     0.1
    2 |   1.7318 |     45.667 |   1.6282 |     46.417 |     0.2
    3 |   1.5311 |     44.676 |   1.5047 |     45.016 |     0.3
    4 |   1.4407 |     43.591 |   1.4511 |     45.452 |     0.3
    5 |   1.3815 |     42.870 |   1.4063 |     44.891 |     0.4
    6 |   1.3398 |     42.330 |   1.3790 |     44.424 |     0.5
    7 |   1.3001 |     41.614 |   1.3623 |     43.240 |     0.6
    8 |   1.2663 |     40.915 |   1.3395 |     43.209 |     0.7
    9 |   1.2371 |     40.414 |   1.3008 |     42.773 |     0.8
   10 |   1.2112 |     39.770 |   1.2665 |     41.807 |     0.8
   11 |   1.1889 |     39.390 |   1.2556 |     40.810 |     0.9
   12 |   1.1657 |     38.894 |   1.2337 |     40.623 |     1.0
   13 |   1.1448 |     38.272 |   1.2126 |     39.844 |     1.1
   14 |   1.1263 |     37.661 |   1.2091 |     40.530 |     1.2
   15 |   1.1127 |     37.397 |   1.1969 |     39.813 |     1.3
   16 |   1.0916 |     36.593 |   1.1977 |     40.093 |     1.4
   17 |   1.0759 |     36.152 |   1.1727 |     39.190 |     1.4
   18 |   1.0602 |     35.657 |   1.1652 |     39.751 |     1.5
   19 |   1.0457 |     35.244 |   1.1841 |     40.280 |     1.6
   20 |   1.0299 |     34.638 |   1.1588 |     39.097 |     1.7
   21 |   1.0168 |     34.000 |   1.1572 |     39.252 |     1.8
   22 |   1.0024 |     33.504 |   1.1600 |     39.283 |     1.9
   23 |   0.9933 |     33.245 |   1.1234 |     38.224 |     2.0
   24 |   0.9786 |     32.865 |   1.1409 |     38.318 |     2.0
   25 |   0.9629 |     32.133 |   1.1393 |     38.006 |     2.1
   26 |   0.9541 |     31.984 |   1.1388 |     38.349 |     2.2
   27 |   0.9455 |     31.896 |   1.1322 |     38.069 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 978,850

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5990 |     48.519 |   1.3513 |     44.829 |     0.1
    2 |   1.3206 |     44.224 |   1.2600 |     42.523 |     0.2
    3 |   1.2683 |     43.415 |   1.2317 |     42.617 |     0.3
    4 |   1.2171 |     41.609 |   1.2061 |     41.246 |     0.4
    5 |   1.1857 |     40.998 |   1.1865 |     40.498 |     0.5
    6 |   1.1507 |     40.243 |   1.1777 |     40.779 |     0.6
    7 |   1.1210 |     38.845 |   1.1672 |     41.246 |     0.7
    8 |   1.0892 |     37.914 |   1.1784 |     40.841 |     0.8
    9 |   1.0697 |     37.226 |   1.1633 |     39.221 |     0.9
   10 |   1.0439 |     36.609 |   1.1649 |     39.844 |     1.0
   11 |   1.0257 |     35.602 |   1.1348 |     38.692 |     1.1
   12 |   0.9996 |     34.737 |   1.1747 |     39.377 |     1.2
   13 |   0.9749 |     34.038 |   1.1624 |     38.660 |     1.2
   14 |   0.9543 |     32.898 |   1.1662 |     37.788 |     1.3
   15 |   0.9322 |     32.419 |   1.0825 |     36.791 |     1.4
   16 |   0.9208 |     32.150 |   1.1069 |     36.573 |     1.5
   17 |   0.9000 |     31.362 |   1.1400 |     36.760 |     1.6
   18 |   0.8749 |     30.002 |   1.0638 |     35.421 |     1.7
   19 |   0.8504 |     29.567 |   1.1392 |     36.698 |     1.8
   20 |   0.8410 |     28.895 |   1.1411 |     36.760 |     1.9
   21 |   0.8107 |     27.910 |   1.1505 |     35.171 |     2.0
   22 |   0.7907 |     27.569 |   1.1562 |     37.009 |     2.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 343,394

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6554 |     48.409 |   1.3343 |     44.393 |     0.1
    2 |   1.2730 |     43.371 |   1.2426 |     43.240 |     0.2
    3 |   1.2029 |     42.099 |   1.1823 |     42.305 |     0.3
    4 |   1.1543 |     40.623 |   1.1564 |     41.682 |     0.4
    5 |   1.1191 |     39.280 |   1.1587 |     42.087 |     0.5
    6 |   1.0999 |     39.428 |   1.0996 |     38.847 |     0.6
    7 |   1.0769 |     38.492 |   1.0767 |     38.723 |     0.7
    8 |   1.0512 |     37.545 |   1.0796 |     38.847 |     0.8
    9 |   1.0364 |     37.083 |   1.0720 |     38.100 |     0.9
   10 |   1.0105 |     36.015 |   1.0551 |     37.040 |     1.0
   11 |   0.9873 |     35.293 |   1.0553 |     37.134 |     1.2
   12 |   0.9716 |     34.649 |   1.0361 |     36.449 |     1.3
   13 |   0.9574 |     34.038 |   1.0197 |     35.202 |     1.4
   14 |   0.9383 |     33.388 |   1.0137 |     35.763 |     1.5
   15 |   0.9181 |     32.607 |   1.0502 |     36.885 |     1.6
   16 |   0.9030 |     31.841 |   1.0200 |     36.168 |     1.7
   17 |   0.8909 |     31.483 |   0.9881 |     34.019 |     1.8
   18 |   0.8650 |     30.371 |   0.9918 |     34.206 |     1.9
   19 |   0.8584 |     30.338 |   1.0000 |     34.268 |     2.0
   20 |   0.8260 |     28.846 |   0.9829 |     33.956 |     2.1
   21 |   0.8154 |     28.334 |   0.9718 |     32.461 |     2.2
   22 |   0.7971 |     27.712 |   0.9723 |     32.773 |     2.3
   23 |   0.7827 |     27.574 |   0.9600 |     33.146 |     2.4
   24 |   0.7709 |     26.963 |   0.9509 |     32.274 |     2.5
   25 |   0.7467 |     26.187 |   0.9737 |     32.928 |     2.6
   26 |   0.7281 |     25.228 |   0.9885 |     33.801 |     2.7
   27 |   0.7053 |     24.463 |   0.9720 |     32.555 |     2.8
   28 |   0.6823 |     23.665 |   0.9541 |     31.589 |     2.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 1,047,842

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6096 |     49.180 |   1.3196 |     43.925 |     0.2
    2 |   1.2593 |     44.125 |   1.2045 |     43.364 |     0.4
    3 |   1.2019 |     42.914 |   1.2027 |     44.174 |     0.5
    4 |   1.1711 |     41.884 |   1.1639 |     41.153 |     0.7
    5 |   1.1465 |     40.849 |   1.1688 |     43.084 |     0.9
    6 |   1.1294 |     40.596 |   1.1327 |     40.810 |     1.1
    7 |   1.0979 |     39.137 |   1.1081 |     39.533 |     1.3
    8 |   1.0819 |     39.071 |   1.1101 |     39.969 |     1.5
    9 |   1.0708 |     38.790 |   1.0879 |     40.156 |     1.6
   10 |   1.0572 |     38.162 |   1.0656 |     38.474 |     1.8
   11 |   1.0370 |     37.292 |   1.0868 |     39.346 |     2.0
   12 |   1.0225 |     36.907 |   1.0485 |     38.006 |     2.2
   13 |   1.0084 |     36.455 |   1.0271 |     37.383 |     2.4
   14 |   0.9913 |     35.745 |   1.0443 |     38.629 |     2.6
   15 |   0.9887 |     35.971 |   1.0485 |     37.290 |     2.7
   16 |   0.9688 |     35.106 |   1.0216 |     36.075 |     2.9
   17 |   0.9604 |     34.936 |   1.0181 |     36.978 |     3.1
   18 |   0.9464 |     34.335 |   1.0142 |     37.072 |     3.3
   19 |   0.9366 |     34.220 |   1.0085 |     35.607 |     3.5
   20 |   0.9262 |     33.763 |   1.0125 |     36.916 |     3.7
   21 |   0.9190 |     33.306 |   1.0149 |     37.134 |     3.8
   22 |   0.9068 |     32.673 |   0.9897 |     35.171 |     4.0
   23 |   0.8874 |     32.094 |   0.9830 |     34.299 |     4.2
   24 |   0.8802 |     31.797 |   1.0089 |     35.763 |     4.4
   25 |   0.8637 |     31.021 |   0.9809 |     34.922 |     4.6
   26 |   0.8563 |     31.081 |   0.9773 |     34.704 |     4.8
   27 |   0.8429 |     30.278 |   0.9936 |     35.140 |     5.0
   28 |   0.8364 |     29.821 |   0.9784 |     34.704 |     5.1
   29 |   0.8239 |     29.705 |   0.9614 |     33.302 |     5.3
   30 |   0.8106 |     28.835 |   0.9672 |     33.676 |     5.5
   31 |   0.7951 |     28.334 |   0.9684 |     33.396 |     5.7
   32 |   0.7819 |     27.981 |   0.9726 |     33.583 |     5.9
   33 |   0.7743 |     27.409 |   0.9635 |     32.897 |     6.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 393,634

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7843 |     50.463 |   1.3852 |     46.386 |     0.2
    2 |   1.3483 |     45.270 |   1.2855 |     45.140 |     0.3
    3 |   1.2872 |     44.505 |   1.2367 |     43.583 |     0.5
    4 |   1.2400 |     43.525 |   1.2042 |     42.710 |     0.7
    5 |   1.2125 |     43.173 |   1.1771 |     42.056 |     0.8
    6 |   1.1918 |     42.749 |   1.1665 |     42.679 |     1.0
    7 |   1.1776 |     41.923 |   1.1568 |     41.745 |     1.2
    8 |   1.1599 |     41.983 |   1.1542 |     41.153 |     1.4
    9 |   1.1524 |     41.631 |   1.1371 |     40.872 |     1.5
   10 |   1.1469 |     41.471 |   1.1199 |     40.436 |     1.7
   11 |   1.1368 |     41.378 |   1.1217 |     41.277 |     1.9
   12 |   1.1277 |     40.981 |   1.1075 |     39.969 |     2.0
   13 |   1.1238 |     41.284 |   1.1080 |     40.841 |     2.2
   14 |   1.1156 |     40.921 |   1.1095 |     40.125 |     2.4
   15 |   1.1056 |     39.952 |   1.0995 |     38.816 |     2.6
   16 |   1.0956 |     39.544 |   1.0924 |     38.567 |     2.7
   17 |   1.0883 |     39.302 |   1.0907 |     40.498 |     2.9
   18 |   1.0830 |     39.307 |   1.0847 |     38.536 |     3.1
   19 |   1.0692 |     38.817 |   1.0710 |     39.439 |     3.2
   20 |   1.0681 |     38.592 |   1.0671 |     38.100 |     3.4
   21 |   1.0592 |     38.201 |   1.0905 |     39.564 |     3.6
   22 |   1.0483 |     37.661 |   1.0585 |     38.349 |     3.8
   23 |   1.0422 |     37.947 |   1.0569 |     38.754 |     3.9
   24 |   1.0386 |     37.529 |   1.0616 |     38.037 |     4.1
   25 |   1.0326 |     37.529 |   1.0646 |     38.941 |     4.3
   26 |   1.0253 |     37.353 |   1.0451 |     38.536 |     4.4
   27 |   1.0163 |     37.072 |   1.0603 |     38.536 |     4.6
   28 |   1.0130 |     36.940 |   1.0396 |     37.944 |     4.8
   29 |   1.0039 |     36.554 |   1.0393 |     38.567 |     5.0
   30 |   0.9910 |     36.257 |   1.0476 |     38.006 |     5.1
   31 |   0.9853 |     35.745 |   1.0461 |     37.321 |     5.3
   32 |   0.9777 |     35.398 |   1.0147 |     37.103 |     5.5
   33 |   0.9702 |     35.310 |   1.0145 |     36.355 |     5.6
   34 |   0.9589 |     35.035 |   1.0248 |     37.134 |     5.8
   35 |   0.9576 |     34.534 |   1.0069 |     36.075 |     6.0
   36 |   0.9477 |     34.451 |   0.9905 |     35.389 |     6.1
   37 |   0.9398 |     34.011 |   0.9958 |     35.732 |     6.3
   38 |   0.9313 |     33.862 |   0.9914 |     34.829 |     6.5
   39 |   0.9276 |     33.713 |   1.0160 |     35.826 |     6.7
   40 |   0.9167 |     33.064 |   0.9904 |     35.483 |     6.8
   41 |   0.9123 |     32.959 |   1.0060 |     36.199 |     7.0
   42 |   0.9064 |     32.920 |   0.9769 |     34.174 |     7.2
   43 |   0.8929 |     32.056 |   0.9707 |     34.112 |     7.3
   44 |   0.8877 |     31.957 |   0.9727 |     33.894 |     7.5
   45 |   0.8739 |     31.357 |   0.9901 |     34.548 |     7.7
   46 |   0.8704 |     31.313 |   0.9640 |     33.769 |     7.8
   47 |   0.8693 |     31.059 |   0.9627 |     32.928 |     8.0
   48 |   0.8548 |     30.889 |   0.9899 |     34.704 |     8.2
   49 |   0.8544 |     30.624 |   0.9716 |     33.645 |     8.3
   50 |   0.8458 |     30.178 |   0.9640 |     33.271 |     8.5
   51 |   0.8420 |     30.079 |   0.9593 |     33.022 |     8.7
   52 |   0.8260 |     29.600 |   0.9815 |     34.517 |     8.9
   53 |   0.8210 |     29.281 |   0.9826 |     33.271 |     9.0
   54 |   0.8184 |     29.297 |   0.9888 |     34.143 |     9.2
   55 |   0.8096 |     28.962 |   0.9668 |     33.645 |     9.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 292,258

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5896 |     47.192 |   1.3392 |     44.673 |     0.1
    2 |   1.2509 |     42.517 |   1.2400 |     42.710 |     0.2
    3 |   1.1701 |     40.287 |   1.1666 |     40.125 |     0.3
    4 |   1.1174 |     39.071 |   1.1752 |     41.745 |     0.3
    5 |   1.0706 |     37.832 |   1.1059 |     38.037 |     0.4
    6 |   1.0276 |     35.916 |   1.0689 |     37.165 |     0.5
    7 |   0.9906 |     34.693 |   1.0666 |     36.262 |     0.6
    8 |   0.9559 |     33.399 |   1.0571 |     36.324 |     0.7
    9 |   0.9160 |     31.770 |   1.0328 |     34.984 |     0.8
   10 |   0.8816 |     30.663 |   1.0888 |     36.355 |     0.8
   11 |   0.8453 |     29.259 |   1.0332 |     34.081 |     0.9
   12 |   0.8045 |     27.497 |   0.9866 |     33.053 |     1.0
   13 |   0.7749 |     26.561 |   1.0551 |     34.860 |     1.1
   14 |   0.7385 |     25.603 |   1.0560 |     34.860 |     1.2
   15 |   0.7033 |     24.320 |   1.0394 |     34.143 |     1.3
   16 |   0.6676 |     22.993 |   1.0607 |     34.206 |     1.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 292,258

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6271 |     63.347 |   1.9126 |     47.695 |     0.1
    2 |   1.8680 |     47.396 |   1.6035 |     45.732 |     0.1
    3 |   1.6388 |     46.333 |   1.5055 |     45.763 |     0.2
    4 |   1.5419 |     45.887 |   1.4565 |     45.763 |     0.3
    5 |   1.4845 |     45.711 |   1.4194 |     45.794 |     0.3
    6 |   1.4451 |     45.645 |   1.3896 |     45.265 |     0.4
    7 |   1.4110 |     45.028 |   1.3615 |     44.922 |     0.5
    8 |   1.3865 |     44.582 |   1.3405 |     44.050 |     0.5
    9 |   1.3637 |     44.340 |   1.3247 |     43.551 |     0.6
   10 |   1.3437 |     43.756 |   1.3155 |     43.427 |     0.7
   11 |   1.3268 |     43.552 |   1.2964 |     43.209 |     0.7
   12 |   1.3100 |     43.244 |   1.2967 |     43.146 |     0.8
   13 |   1.3001 |     43.073 |   1.2754 |     42.586 |     0.9
   14 |   1.2840 |     42.545 |   1.2751 |     42.586 |     0.9
   15 |   1.2756 |     42.440 |   1.2658 |     41.838 |     1.0
   16 |   1.2627 |     42.407 |   1.2521 |     41.931 |     1.1
   17 |   1.2546 |     42.281 |   1.2491 |     42.181 |     1.1
   18 |   1.2447 |     42.115 |   1.2409 |     41.900 |     1.2
   19 |   1.2356 |     41.515 |   1.2502 |     42.150 |     1.3
   20 |   1.2279 |     41.345 |   1.2351 |     41.931 |     1.3
   21 |   1.2210 |     41.168 |   1.2336 |     41.651 |     1.4
   22 |   1.2143 |     40.739 |   1.2328 |     41.713 |     1.5
   23 |   1.2079 |     40.893 |   1.2182 |     41.215 |     1.5
   24 |   1.1981 |     40.711 |   1.2329 |     41.090 |     1.6
   25 |   1.1897 |     40.530 |   1.2222 |     41.308 |     1.7
   26 |   1.1857 |     39.919 |   1.2364 |     41.713 |     1.7
   27 |   1.1781 |     40.260 |   1.2286 |     41.371 |     1.8
   28 |   1.1776 |     40.106 |   1.2179 |     40.530 |     1.9
   29 |   1.1681 |     39.808 |   1.2376 |     41.277 |     1.9
   30 |   1.1632 |     39.764 |   1.2284 |     41.308 |     2.0
   31 |   1.1600 |     39.539 |   1.2380 |     41.121 |     2.1
   32 |   1.1519 |     39.495 |   1.2223 |     40.935 |     2.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 582,690

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4395 |     59.470 |   1.7199 |     46.106 |     0.1
    2 |   1.6866 |     46.647 |   1.4837 |     45.794 |     0.2
    3 |   1.5109 |     46.107 |   1.4048 |     45.919 |     0.2
    4 |   1.4334 |     45.292 |   1.3559 |     44.766 |     0.3
    5 |   1.3827 |     44.802 |   1.3252 |     44.486 |     0.4
    6 |   1.3489 |     44.433 |   1.2951 |     43.178 |     0.5
    7 |   1.3262 |     43.630 |   1.2807 |     43.894 |     0.6
    8 |   1.2981 |     43.184 |   1.2660 |     42.555 |     0.7
    9 |   1.2806 |     42.908 |   1.2459 |     41.869 |     0.7
   10 |   1.2611 |     42.275 |   1.2504 |     42.461 |     0.8
   11 |   1.2432 |     42.253 |   1.2433 |     41.869 |     0.9
   12 |   1.2279 |     41.334 |   1.2244 |     41.153 |     1.0
   13 |   1.2158 |     41.400 |   1.2304 |     41.900 |     1.1
   14 |   1.2058 |     41.102 |   1.2216 |     41.402 |     1.2
   15 |   1.1898 |     40.326 |   1.2377 |     41.807 |     1.2
   16 |   1.1838 |     40.100 |   1.2130 |     41.059 |     1.3
   17 |   1.1713 |     40.023 |   1.2214 |     41.059 |     1.4
   18 |   1.1610 |     39.500 |   1.2385 |     41.558 |     1.5
   19 |   1.1473 |     39.252 |   1.2003 |     40.343 |     1.6
   20 |   1.1406 |     39.247 |   1.2345 |     40.935 |     1.6
   21 |   1.1284 |     38.520 |   1.1880 |     39.626 |     1.7
   22 |   1.1226 |     38.443 |   1.1946 |     40.498 |     1.8
   23 |   1.1100 |     38.162 |   1.2176 |     40.561 |     1.9
   24 |   1.1060 |     37.975 |   1.1826 |     40.561 |     2.0
   25 |   1.0969 |     37.424 |   1.2220 |     40.654 |     2.1
   26 |   1.0846 |     37.160 |   1.1840 |     39.751 |     2.1
   27 |   1.0854 |     37.490 |   1.1972 |     39.844 |     2.2
   28 |   1.0699 |     36.725 |   1.1907 |     39.377 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 326,690

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6983 |     64.470 |   1.9691 |     45.919 |     0.1
    2 |   1.8451 |     46.647 |   1.6160 |     45.763 |     0.2
    3 |   1.6150 |     46.014 |   1.5184 |     45.670 |     0.2
    4 |   1.5217 |     45.656 |   1.4585 |     45.607 |     0.3
    5 |   1.4658 |     45.551 |   1.4225 |     45.265 |     0.4
    6 |   1.4247 |     45.160 |   1.3838 |     44.642 |     0.5
    7 |   1.3894 |     44.720 |   1.3559 |     44.174 |     0.6
    8 |   1.3637 |     44.334 |   1.3321 |     44.143 |     0.7
    9 |   1.3341 |     43.668 |   1.3150 |     44.237 |     0.7
   10 |   1.3164 |     43.068 |   1.2936 |     44.019 |     0.8
   11 |   1.3001 |     42.694 |   1.2822 |     43.427 |     0.9
   12 |   1.2790 |     42.159 |   1.2800 |     43.614 |     1.0
   13 |   1.2645 |     41.719 |   1.2581 |     42.897 |     1.1
   14 |   1.2490 |     41.603 |   1.2618 |     43.053 |     1.2
   15 |   1.2351 |     41.669 |   1.2487 |     42.555 |     1.2
   16 |   1.2208 |     40.970 |   1.2466 |     42.773 |     1.3
   17 |   1.2091 |     40.821 |   1.2346 |     42.181 |     1.4
   18 |   1.2002 |     40.475 |   1.2455 |     42.523 |     1.5
   19 |   1.1873 |     40.376 |   1.2321 |     42.368 |     1.6
   20 |   1.1826 |     40.502 |   1.2270 |     41.713 |     1.7
   21 |   1.1714 |     40.073 |   1.2008 |     41.184 |     1.7
   22 |   1.1648 |     39.808 |   1.2202 |     41.745 |     1.8
   23 |   1.1569 |     39.742 |   1.1977 |     41.340 |     1.9
   24 |   1.1489 |     39.439 |   1.2078 |     41.807 |     2.0
   25 |   1.1425 |     39.467 |   1.2032 |     40.903 |     2.1
   26 |   1.1329 |     39.060 |   1.1894 |     40.997 |     2.2
   27 |   1.1259 |     38.718 |   1.1796 |     40.405 |     2.2
   28 |   1.1200 |     38.548 |   1.1821 |     40.156 |     2.3
   29 |   1.1121 |     38.327 |   1.1989 |     40.966 |     2.4
   30 |   1.1071 |     37.942 |   1.1802 |     40.530 |     2.5
   31 |   1.0984 |     37.755 |   1.1801 |     40.374 |     2.6
   32 |   1.0929 |     37.545 |   1.1779 |     40.000 |     2.7
   33 |   1.0879 |     37.358 |   1.1752 |     40.156 |     2.7
   34 |   1.0779 |     37.132 |   1.1690 |     40.218 |     2.8
   35 |   1.0727 |     36.835 |   1.1637 |     39.751 |     2.9
   36 |   1.0680 |     36.560 |   1.1717 |     39.813 |     3.0
   37 |   1.0657 |     37.028 |   1.1898 |     40.125 |     3.1
   38 |   1.0573 |     36.345 |   1.1526 |     39.533 |     3.2
   39 |   1.0522 |     36.026 |   1.1670 |     39.875 |     3.2
   40 |   1.0454 |     35.954 |   1.1726 |     39.751 |     3.3
   41 |   1.0421 |     35.651 |   1.1521 |     39.034 |     3.4
   42 |   1.0370 |     35.602 |   1.1361 |     38.941 |     3.5
   43 |   1.0282 |     35.233 |   1.1550 |     39.252 |     3.6
   44 |   1.0240 |     34.925 |   1.1661 |     38.816 |     3.6
   45 |   1.0205 |     35.266 |   1.1628 |     39.097 |     3.7
   46 |   1.0132 |     34.677 |   1.1513 |     38.629 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.2
Trainable parameters: 326,690

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.8932 |     74.397 |   2.3326 |     58.100 |     0.1
    2 |   2.2065 |     53.105 |   1.7567 |     45.857 |     0.2
    3 |   1.7913 |     46.570 |   1.5772 |     45.732 |     0.3
    4 |   1.6195 |     46.063 |   1.5020 |     45.701 |     0.4
    5 |   1.5394 |     46.058 |   1.4610 |     45.701 |     0.5
    6 |   1.4969 |     45.865 |   1.4288 |     45.576 |     0.7
    7 |   1.4584 |     45.959 |   1.4071 |     45.545 |     0.8
    8 |   1.4378 |     45.832 |   1.3848 |     45.202 |     0.9
    9 |   1.4108 |     45.204 |   1.3653 |     45.265 |     1.0
   10 |   1.3921 |     45.281 |   1.3482 |     44.860 |     1.1
   11 |   1.3730 |     44.830 |   1.3431 |     44.766 |     1.2
   12 |   1.3567 |     44.395 |   1.3209 |     44.424 |     1.3
   13 |   1.3404 |     44.037 |   1.3155 |     44.237 |     1.4
   14 |   1.3275 |     44.076 |   1.3033 |     44.143 |     1.5
   15 |   1.3160 |     43.481 |   1.2881 |     44.081 |     1.6
   16 |   1.3015 |     43.448 |   1.2897 |     44.019 |     1.7
   17 |   1.2907 |     43.283 |   1.2751 |     43.801 |     1.9
   18 |   1.2859 |     43.106 |   1.2680 |     42.960 |     2.0
   19 |   1.2712 |     42.451 |   1.2629 |     42.773 |     2.1
   20 |   1.2579 |     42.391 |   1.2540 |     43.209 |     2.2
   21 |   1.2518 |     42.187 |   1.2423 |     42.991 |     2.3
   22 |   1.2398 |     41.488 |   1.2274 |     42.150 |     2.4
   23 |   1.2339 |     41.780 |   1.2245 |     42.056 |     2.5
   24 |   1.2289 |     41.747 |   1.2319 |     41.869 |     2.6
   25 |   1.2177 |     41.036 |   1.2107 |     41.745 |     2.7
   26 |   1.2115 |     41.174 |   1.2076 |     41.028 |     2.8
   27 |   1.2022 |     40.915 |   1.1999 |     41.090 |     3.0
   28 |   1.1971 |     40.695 |   1.2113 |     41.526 |     3.1
   29 |   1.1888 |     40.348 |   1.2130 |     41.371 |     3.2
   30 |   1.1815 |     40.254 |   1.1933 |     41.246 |     3.3
   31 |   1.1769 |     40.238 |   1.2090 |     41.246 |     3.4
   32 |   1.1719 |     39.737 |   1.1783 |     40.436 |     3.5
   33 |   1.1642 |     39.500 |   1.1761 |     40.498 |     3.6
   34 |   1.1563 |     39.484 |   1.1825 |     40.156 |     3.7
   35 |   1.1546 |     39.241 |   1.2010 |     40.810 |     3.8
   36 |   1.1495 |     39.280 |   1.1783 |     40.498 |     3.9
   37 |   1.1431 |     39.065 |   1.1628 |     39.969 |     4.1
   38 |   1.1343 |     38.503 |   1.1925 |     40.935 |     4.2
   39 |   1.1288 |     38.514 |   1.1975 |     40.654 |     4.3
   40 |   1.1221 |     38.063 |   1.1871 |     40.685 |     4.4
   41 |   1.1246 |     38.542 |   1.2083 |     41.121 |     4.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 881,570

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3700 |     59.740 |   1.6295 |     45.763 |     0.1
    2 |   1.5769 |     45.733 |   1.4275 |     44.361 |     0.3
    3 |   1.4287 |     45.127 |   1.3538 |     45.140 |     0.4
    4 |   1.3619 |     44.494 |   1.3190 |     44.766 |     0.5
    5 |   1.3181 |     43.613 |   1.2850 |     44.517 |     0.6
    6 |   1.2810 |     42.848 |   1.2479 |     42.523 |     0.8
    7 |   1.2488 |     42.071 |   1.2682 |     44.081 |     0.9
    8 |   1.2248 |     41.405 |   1.2338 |     42.118 |     1.0
    9 |   1.1954 |     40.794 |   1.2086 |     41.495 |     1.1
   10 |   1.1729 |     39.952 |   1.2099 |     41.246 |     1.3
   11 |   1.1540 |     39.434 |   1.1965 |     40.685 |     1.4
   12 |   1.1342 |     39.043 |   1.1901 |     41.028 |     1.5
   13 |   1.1134 |     37.991 |   1.1843 |     41.090 |     1.7
   14 |   1.0972 |     37.474 |   1.1858 |     40.997 |     1.8
   15 |   1.0768 |     36.802 |   1.1716 |     39.782 |     1.9
   16 |   1.0648 |     36.037 |   1.1754 |     39.813 |     2.1
   17 |   1.0478 |     35.800 |   1.1521 |     39.844 |     2.2
   18 |   1.0349 |     34.809 |   1.1393 |     39.408 |     2.3
   19 |   1.0206 |     34.737 |   1.1666 |     39.377 |     2.4
   20 |   1.0044 |     34.214 |   1.1366 |     38.505 |     2.6
   21 |   0.9941 |     33.504 |   1.1361 |     37.944 |     2.7
   22 |   0.9784 |     33.289 |   1.1452 |     37.913 |     2.8
   23 |   0.9650 |     32.287 |   1.1225 |     37.321 |     3.0
   24 |   0.9521 |     32.260 |   1.1277 |     37.383 |     3.1
   25 |   0.9380 |     31.401 |   1.1085 |     36.916 |     3.2
   26 |   0.9243 |     30.960 |   1.1403 |     37.632 |     3.3
   27 |   0.9163 |     31.081 |   1.1137 |     36.511 |     3.5
   28 |   0.8991 |     30.074 |   1.1086 |     36.417 |     3.6
   29 |   0.8887 |     30.145 |   1.1169 |     36.386 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,013,538

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4101 |     58.969 |   1.6700 |     46.760 |     0.2
    2 |   1.6339 |     46.465 |   1.4729 |     46.573 |     0.3
    3 |   1.4866 |     45.815 |   1.4013 |     45.857 |     0.5
    4 |   1.4127 |     44.802 |   1.3629 |     45.296 |     0.6
    5 |   1.3740 |     44.290 |   1.3476 |     45.109 |     0.8
    6 |   1.3409 |     43.536 |   1.3134 |     44.455 |     0.9
    7 |   1.3120 |     43.178 |   1.3158 |     44.143 |     1.1
    8 |   1.2894 |     42.660 |   1.3156 |     43.832 |     1.2
    9 |   1.2690 |     42.231 |   1.2977 |     42.835 |     1.4
   10 |   1.2527 |     41.592 |   1.2834 |     42.773 |     1.6
   11 |   1.2366 |     41.389 |   1.2898 |     43.053 |     1.7
   12 |   1.2163 |     41.042 |   1.2959 |     42.773 |     1.9
   13 |   1.2042 |     40.888 |   1.2509 |     42.336 |     2.0
   14 |   1.1915 |     40.530 |   1.2947 |     42.991 |     2.2
   15 |   1.1807 |     39.913 |   1.2609 |     42.305 |     2.3
   16 |   1.1618 |     39.676 |   1.2639 |     41.620 |     2.5
   17 |   1.1501 |     39.269 |   1.2719 |     41.495 |     2.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 235,170

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7730 |     65.912 |   2.1220 |     47.757 |     0.1
    2 |   1.9812 |     46.867 |   1.6772 |     45.763 |     0.2
    3 |   1.6723 |     45.755 |   1.5446 |     45.763 |     0.3
    4 |   1.5558 |     45.837 |   1.4808 |     45.763 |     0.4
    5 |   1.4929 |     45.524 |   1.4401 |     45.545 |     0.5
    6 |   1.4499 |     45.380 |   1.4021 |     44.984 |     0.6
    7 |   1.4165 |     45.177 |   1.3751 |     44.798 |     0.7
    8 |   1.3902 |     44.962 |   1.3538 |     44.393 |     0.8
    9 |   1.3642 |     44.505 |   1.3350 |     44.143 |     0.9
   10 |   1.3456 |     44.312 |   1.3162 |     43.832 |     1.0
   11 |   1.3261 |     43.899 |   1.2965 |     43.302 |     1.1
   12 |   1.3124 |     43.861 |   1.2880 |     43.489 |     1.2
   13 |   1.2967 |     43.134 |   1.2693 |     43.302 |     1.3
   14 |   1.2760 |     42.963 |   1.2536 |     43.053 |     1.4
   15 |   1.2621 |     42.490 |   1.2512 |     43.707 |     1.5
   16 |   1.2496 |     41.989 |   1.2361 |     43.146 |     1.6
   17 |   1.2376 |     41.587 |   1.2314 |     43.240 |     1.7
   18 |   1.2273 |     41.526 |   1.2192 |     42.617 |     1.8
   19 |   1.2120 |     41.312 |   1.2136 |     42.804 |     1.9
   20 |   1.2102 |     41.014 |   1.2012 |     41.651 |     2.0
   21 |   1.1979 |     40.585 |   1.1968 |     42.336 |     2.1
   22 |   1.1896 |     40.298 |   1.1897 |     41.495 |     2.2
   23 |   1.1819 |     40.221 |   1.1699 |     40.903 |     2.3
   24 |   1.1733 |     39.974 |   1.1848 |     41.558 |     2.4
   25 |   1.1666 |     40.029 |   1.1767 |     41.402 |     2.5
   26 |   1.1581 |     39.808 |   1.1725 |     40.966 |     2.6
   27 |   1.1487 |     39.489 |   1.1546 |     40.498 |     2.7
   28 |   1.1429 |     38.960 |   1.1505 |     40.530 |     2.8
   29 |   1.1431 |     39.517 |   1.1546 |     40.218 |     2.9
   30 |   1.1320 |     38.713 |   1.1520 |     40.062 |     3.0
   31 |   1.1267 |     38.603 |   1.1441 |     39.377 |     3.1
   32 |   1.1191 |     38.228 |   1.1378 |     39.283 |     3.2
   33 |   1.1126 |     37.936 |   1.1419 |     39.221 |     3.3
   34 |   1.1051 |     37.881 |   1.1399 |     39.346 |     3.4
   35 |   1.1007 |     37.859 |   1.1112 |     38.411 |     3.5
   36 |   1.0970 |     37.645 |   1.1162 |     38.037 |     3.6
   37 |   1.0956 |     37.859 |   1.1149 |     38.006 |     3.7
   38 |   1.0842 |     37.077 |   1.1144 |     38.162 |     3.8
   39 |   1.0820 |     36.962 |   1.1185 |     38.349 |     3.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,243,810

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9747 |     51.575 |   1.4839 |     44.829 |     0.1
    2 |   1.3983 |     44.411 |   1.3717 |     43.520 |     0.3
    3 |   1.3161 |     43.294 |   1.3051 |     42.835 |     0.4
    4 |   1.2555 |     41.708 |   1.2587 |     42.336 |     0.6
    5 |   1.2125 |     40.023 |   1.2361 |     42.555 |     0.7
    6 |   1.1716 |     39.197 |   1.2008 |     40.280 |     0.9
    7 |   1.1347 |     37.969 |   1.1894 |     40.717 |     1.0
    8 |   1.1030 |     36.824 |   1.1744 |     40.530 |     1.2
    9 |   1.0802 |     36.709 |   1.1554 |     39.844 |     1.3
   10 |   1.0398 |     34.936 |   1.1719 |     39.502 |     1.5
   11 |   1.0133 |     34.286 |   1.1681 |     39.221 |     1.6
   12 |   0.9858 |     33.273 |   1.0991 |     37.788 |     1.8
   13 |   0.9572 |     32.205 |   1.1324 |     37.913 |     1.9
   14 |   0.9321 |     31.081 |   1.1130 |     36.729 |     2.1
   15 |   0.8991 |     29.953 |   1.1318 |     38.411 |     2.3
   16 |   0.8736 |     29.039 |   1.0828 |     36.417 |     2.4
   17 |   0.8503 |     27.893 |   1.1132 |     36.542 |     2.6
   18 |   0.8189 |     27.029 |   1.1510 |     37.009 |     2.7
   19 |   0.7970 |     26.390 |   1.0890 |     35.826 |     2.9
   20 |   0.7730 |     25.388 |   1.1429 |     36.636 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 343,394

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6345 |     62.444 |   1.9735 |     46.791 |     0.2
    2 |   1.8375 |     46.041 |   1.6275 |     45.576 |     0.3
    3 |   1.6148 |     45.738 |   1.5220 |     45.265 |     0.5
    4 |   1.5189 |     45.287 |   1.4676 |     46.449 |     0.7
    5 |   1.4600 |     45.111 |   1.4264 |     46.760 |     0.8
    6 |   1.4150 |     44.345 |   1.3913 |     44.891 |     1.0
    7 |   1.3812 |     44.009 |   1.3518 |     45.047 |     1.1
    8 |   1.3506 |     43.635 |   1.3260 |     44.143 |     1.3
    9 |   1.3227 |     43.084 |   1.3014 |     43.863 |     1.5
   10 |   1.3028 |     42.815 |   1.2984 |     43.427 |     1.6
   11 |   1.2842 |     42.407 |   1.2647 |     42.835 |     1.8
   12 |   1.2643 |     41.835 |   1.2574 |     42.741 |     2.0
   13 |   1.2507 |     41.647 |   1.2501 |     42.835 |     2.1
   14 |   1.2369 |     41.234 |   1.2486 |     42.773 |     2.3
   15 |   1.2213 |     40.877 |   1.2427 |     42.025 |     2.5
   16 |   1.2152 |     41.075 |   1.2521 |     42.212 |     2.6
   17 |   1.2054 |     40.855 |   1.2281 |     41.869 |     2.8
   18 |   1.1933 |     40.508 |   1.2106 |     40.872 |     3.0
   19 |   1.1850 |     40.320 |   1.2100 |     41.745 |     3.1
   20 |   1.1751 |     39.715 |   1.2173 |     41.713 |     3.3
   21 |   1.1666 |     39.902 |   1.1945 |     41.059 |     3.4
   22 |   1.1554 |     39.208 |   1.1711 |     39.688 |     3.6
   23 |   1.1489 |     39.076 |   1.1928 |     40.903 |     3.8
   24 |   1.1413 |     39.384 |   1.2039 |     41.308 |     3.9
   25 |   1.1286 |     38.691 |   1.1736 |     40.685 |     4.1
   26 |   1.1253 |     38.911 |   1.1954 |     41.153 |     4.3
   27 |   1.1152 |     38.327 |   1.1641 |     40.374 |     4.4
   28 |   1.1060 |     37.931 |   1.1552 |     39.315 |     4.6
   29 |   1.1002 |     38.052 |   1.1670 |     40.343 |     4.8
   30 |   1.0896 |     37.485 |   1.1542 |     40.000 |     4.9
   31 |   1.0839 |     37.364 |   1.1540 |     40.062 |     5.1
   32 |   1.0769 |     36.989 |   1.1696 |     40.717 |     5.2
   33 |   1.0677 |     36.764 |   1.1513 |     39.751 |     5.4
   34 |   1.0619 |     36.494 |   1.1443 |     39.657 |     5.6
   35 |   1.0541 |     36.301 |   1.1790 |     40.280 |     5.7
   36 |   1.0474 |     35.866 |   1.1294 |     39.315 |     5.9
   37 |   1.0423 |     35.839 |   1.1545 |     40.187 |     6.1
   38 |   1.0376 |     35.569 |   1.1557 |     39.564 |     6.2
   39 |   1.0257 |     35.007 |   1.1448 |     39.377 |     6.4
   40 |   1.0243 |     35.112 |   1.1638 |     39.533 |     6.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 648,482

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.4759 |     46.047 |   1.2634 |     43.115 |     0.1
    2 |   1.1966 |     41.317 |   1.2074 |     42.866 |     0.2
    3 |   1.1231 |     39.291 |   1.1433 |     39.813 |     0.2
    4 |   1.0597 |     36.582 |   1.0946 |     38.131 |     0.3
    5 |   1.0010 |     34.534 |   1.0611 |     36.760 |     0.4
    6 |   0.9518 |     33.019 |   1.0544 |     35.639 |     0.5
    7 |   0.9097 |     31.004 |   1.0215 |     34.953 |     0.6
    8 |   0.8578 |     29.677 |   1.0243 |     34.455 |     0.6
    9 |   0.8098 |     27.926 |   1.0307 |     33.832 |     0.7
   10 |   0.7638 |     25.878 |   1.0455 |     33.614 |     0.8
   11 |   0.7159 |     24.507 |   1.0495 |     34.143 |     0.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 392,226

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6964 |     48.893 |   1.3627 |     44.735 |     0.1
    2 |   1.3466 |     45.078 |   1.2711 |     43.271 |     0.2
    3 |   1.2868 |     44.527 |   1.2341 |     43.645 |     0.3
    4 |   1.2492 |     43.558 |   1.2019 |     42.305 |     0.4
    5 |   1.2246 |     42.760 |   1.1839 |     43.738 |     0.6
    6 |   1.2016 |     42.352 |   1.1607 |     40.717 |     0.7
    7 |   1.1884 |     41.719 |   1.1741 |     42.150 |     0.8
    8 |   1.1730 |     41.372 |   1.1619 |     42.430 |     0.9
    9 |   1.1703 |     41.400 |   1.1546 |     40.343 |     1.0
   10 |   1.1571 |     40.755 |   1.1345 |     39.688 |     1.1
   11 |   1.1505 |     40.552 |   1.1353 |     40.249 |     1.2
   12 |   1.1391 |     40.210 |   1.1088 |     38.879 |     1.3
   13 |   1.1313 |     40.023 |   1.1252 |     39.657 |     1.5
   14 |   1.1167 |     39.550 |   1.1037 |     39.003 |     1.6
   15 |   1.1144 |     39.775 |   1.1224 |     40.966 |     1.7
   16 |   1.1036 |     39.748 |   1.0920 |     39.626 |     1.8
   17 |   1.0941 |     39.005 |   1.1175 |     39.283 |     1.9
   18 |   1.0923 |     39.076 |   1.0940 |     39.283 |     2.0
   19 |   1.0873 |     38.988 |   1.1067 |     39.969 |     2.1
   20 |   1.0754 |     38.592 |   1.1058 |     40.062 |     2.2
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6027 |     63.225 |   2.0025 |     47.383 |     0.1
    2 |   1.7758 |     46.311 |   1.6491 |     46.449 |     0.1
    3 |   1.5674 |     45.678 |   1.5297 |     45.701 |     0.2
    4 |   1.4782 |     45.623 |   1.4611 |     46.573 |     0.3
    5 |   1.4169 |     44.957 |   1.4112 |     44.112 |     0.3
    6 |   1.3726 |     43.822 |   1.3775 |     43.956 |     0.4
    7 |   1.3372 |     43.321 |   1.3422 |     43.707 |     0.5
    8 |   1.3099 |     42.930 |   1.3329 |     44.984 |     0.6
    9 |   1.2867 |     42.204 |   1.3042 |     43.396 |     0.6
   10 |   1.2660 |     41.642 |   1.2884 |     43.115 |     0.7
   11 |   1.2479 |     41.069 |   1.2796 |     42.804 |     0.8
   12 |   1.2307 |     40.844 |   1.2541 |     41.620 |     0.8
   13 |   1.2171 |     40.491 |   1.2554 |     41.340 |     0.9
   14 |   1.2008 |     40.392 |   1.2659 |     42.118 |     1.0
   15 |   1.1884 |     40.172 |   1.2404 |     41.464 |     1.1
   16 |   1.1749 |     39.627 |   1.2438 |     41.900 |     1.1
   17 |   1.1603 |     39.236 |   1.2308 |     40.935 |     1.2
   18 |   1.1427 |     38.905 |   1.2147 |     40.810 |     1.3
   19 |   1.1290 |     38.300 |   1.1980 |     40.498 |     1.3
   20 |   1.1162 |     38.151 |   1.2154 |     40.374 |     1.4
   21 |   1.1075 |     37.799 |   1.2072 |     39.626 |     1.4
   22 |   1.0920 |     37.292 |   1.2029 |     40.125 |     1.5
   23 |   1.0839 |     37.055 |   1.1734 |     39.315 |     1.6
   24 |   1.0724 |     36.538 |   1.1784 |     39.688 |     1.6
   25 |   1.0603 |     36.257 |   1.1596 |     39.221 |     1.7
   26 |   1.0525 |     35.960 |   1.1866 |     39.751 |     1.8
   27 |   1.0401 |     35.293 |   1.1852 |     39.907 |     1.8
   28 |   1.0328 |     35.194 |   1.1574 |     38.941 |     1.9
   29 |   1.0208 |     34.578 |   1.1620 |     39.252 |     1.9
   30 |   1.0111 |     34.236 |   1.1642 |     38.629 |     2.0
   31 |   1.0057 |     34.220 |   1.1578 |     38.193 |     2.1
   32 |   0.9969 |     33.878 |   1.1561 |     38.536 |     2.1
   33 |   0.9872 |     33.333 |   1.1480 |     38.162 |     2.2
   34 |   0.9807 |     32.992 |   1.1538 |     38.037 |     2.3
   35 |   0.9705 |     32.491 |   1.1575 |     37.850 |     2.3
   36 |   0.9613 |     32.337 |   1.1275 |     37.321 |     2.4
   37 |   0.9571 |     32.414 |   1.1445 |     37.477 |     2.5
   38 |   0.9459 |     31.962 |   1.1406 |     37.570 |     2.5
   39 |   0.9361 |     31.307 |   1.1366 |     36.947 |     2.6
   40 |   0.9291 |     31.291 |   1.1558 |     37.632 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 1,179,426

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6898 |     49.807 |   1.4005 |     45.763 |     0.2
    2 |   1.3808 |     46.333 |   1.3219 |     45.857 |     0.3
    3 |   1.3360 |     45.915 |   1.3099 |     44.393 |     0.5
    4 |   1.2991 |     45.034 |   1.2715 |     43.956 |     0.7
    5 |   1.2824 |     44.500 |   1.2625 |     45.109 |     0.8
    6 |   1.2594 |     44.384 |   1.2107 |     44.206 |     1.0
    7 |   1.2417 |     44.241 |   1.2049 |     42.648 |     1.2
    8 |   1.2288 |     43.701 |   1.1954 |     43.427 |     1.3
    9 |   1.2116 |     43.173 |   1.1832 |     42.305 |     1.5
   10 |   1.1994 |     43.233 |   1.1642 |     41.433 |     1.7
   11 |   1.1887 |     42.446 |   1.1516 |     41.651 |     1.8
   12 |   1.1830 |     42.749 |   1.1559 |     41.620 |     2.0
   13 |   1.1759 |     42.336 |   1.1533 |     42.960 |     2.1
   14 |   1.1714 |     42.215 |   1.1372 |     42.430 |     2.3
   15 |   1.1585 |     41.994 |   1.1217 |     41.184 |     2.5
   16 |   1.1557 |     42.121 |   1.1349 |     41.090 |     2.6
   17 |   1.1519 |     41.967 |   1.1174 |     40.561 |     2.8
   18 |   1.1498 |     42.016 |   1.1260 |     43.053 |     3.0
   19 |   1.1420 |     41.350 |   1.1261 |     41.153 |     3.1
   20 |   1.1404 |     42.077 |   1.1205 |     41.184 |     3.3
   21 |   1.1350 |     41.631 |   1.1160 |     40.498 |     3.5
   22 |   1.1348 |     41.664 |   1.1225 |     42.243 |     3.6
   23 |   1.1278 |     41.383 |   1.1130 |     41.963 |     3.8
   24 |   1.1238 |     41.135 |   1.1002 |     40.903 |     4.0
   25 |   1.1231 |     41.031 |   1.1107 |     41.090 |     4.1
   26 |   1.1189 |     41.317 |   1.1102 |     42.274 |     4.3
   27 |   1.1075 |     40.166 |   1.1340 |     41.713 |     4.5
   28 |   1.0952 |     39.544 |   1.0921 |     38.972 |     4.6
   29 |   1.0940 |     39.368 |   1.1105 |     41.402 |     4.8
   30 |   1.0863 |     39.417 |   1.1224 |     41.308 |     4.9
   31 |   1.0780 |     38.762 |   1.0966 |     40.717 |     5.1
   32 |   1.0775 |     38.988 |   1.1186 |     40.872 |     5.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 226,210

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7887 |     50.259 |   1.3704 |     46.698 |     0.1
    2 |   1.3590 |     45.155 |   1.2899 |     43.240 |     0.1
    3 |   1.2962 |     43.949 |   1.2458 |     43.302 |     0.2
    4 |   1.2502 |     42.644 |   1.2151 |     41.713 |     0.3
    5 |   1.2183 |     41.719 |   1.1848 |     40.623 |     0.3
    6 |   1.1840 |     40.954 |   1.1677 |     40.062 |     0.4
    7 |   1.1661 |     40.596 |   1.1474 |     38.816 |     0.5
    8 |   1.1454 |     39.335 |   1.1325 |     38.847 |     0.6
    9 |   1.1282 |     39.093 |   1.1501 |     38.442 |     0.6
   10 |   1.1137 |     38.663 |   1.1214 |     38.972 |     0.7
   11 |   1.0949 |     38.085 |   1.1297 |     38.162 |     0.8
   12 |   1.0756 |     37.606 |   1.0948 |     37.383 |     0.9
   13 |   1.0693 |     37.204 |   1.1165 |     38.349 |     0.9
   14 |   1.0469 |     36.356 |   1.0740 |     36.573 |     1.0
   15 |   1.0334 |     35.872 |   1.0898 |     37.352 |     1.1
   16 |   1.0180 |     35.448 |   1.0993 |     37.196 |     1.1
   17 |   1.0036 |     34.798 |   1.0496 |     36.262 |     1.2
   18 |   0.9881 |     34.170 |   1.0785 |     36.044 |     1.3
   19 |   0.9844 |     34.247 |   1.0813 |     36.137 |     1.4
   20 |   0.9651 |     33.361 |   1.0557 |     35.452 |     1.4
   21 |   0.9532 |     32.926 |   1.0913 |     37.103 |     1.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 392,226

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7378 |     49.554 |   1.3589 |     45.265 |     0.1
    2 |   1.3458 |     45.078 |   1.2729 |     44.642 |     0.2
    3 |   1.2809 |     43.415 |   1.2284 |     42.835 |     0.4
    4 |   1.2449 |     42.974 |   1.1974 |     42.025 |     0.5
    5 |   1.2203 |     42.633 |   1.1873 |     41.277 |     0.6
    6 |   1.2007 |     41.774 |   1.1667 |     41.059 |     0.7
    7 |   1.1854 |     41.460 |   1.1451 |     41.277 |     0.8
    8 |   1.1699 |     40.992 |   1.1520 |     41.121 |     0.9
    9 |   1.1569 |     40.640 |   1.1288 |     40.280 |     1.1
   10 |   1.1479 |     40.618 |   1.1263 |     40.000 |     1.2
   11 |   1.1439 |     40.309 |   1.1381 |     40.156 |     1.3
   12 |   1.1297 |     39.952 |   1.1242 |     40.000 |     1.4
   13 |   1.1253 |     39.511 |   1.0908 |     39.595 |     1.6
   14 |   1.1193 |     39.566 |   1.1171 |     40.218 |     1.7
   15 |   1.1071 |     39.517 |   1.0947 |     39.315 |     1.8
   16 |   1.0992 |     38.718 |   1.0913 |     39.097 |     1.9
   17 |   1.0919 |     38.801 |   1.1013 |     40.187 |     2.1
   18 |   1.0834 |     38.492 |   1.0821 |     38.723 |     2.2
   19 |   1.0721 |     38.311 |   1.0942 |     39.875 |     2.3
   20 |   1.0742 |     38.278 |   1.0848 |     39.159 |     2.4
   21 |   1.0611 |     37.573 |   1.0671 |     37.819 |     2.5
   22 |   1.0605 |     37.634 |   1.0788 |     38.162 |     2.7
   23 |   1.0516 |     37.430 |   1.0846 |     38.941 |     2.8
   24 |   1.0453 |     37.518 |   1.0655 |     38.847 |     2.9
   25 |   1.0439 |     37.188 |   1.0808 |     38.816 |     3.0
   26 |   1.0343 |     36.907 |   1.0906 |     38.131 |     3.2
   27 |   1.0311 |     36.868 |   1.0803 |     37.882 |     3.3
   28 |   1.0215 |     36.373 |   1.0906 |     38.629 |     3.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,047,842

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2966 |     58.457 |   1.6279 |     46.791 |     0.2
    2 |   1.5594 |     46.036 |   1.4308 |     46.822 |     0.3
    3 |   1.4246 |     44.879 |   1.3818 |     45.732 |     0.5
    4 |   1.3604 |     43.756 |   1.3402 |     44.673 |     0.7
    5 |   1.3220 |     43.316 |   1.3236 |     44.455 |     0.9
    6 |   1.2856 |     42.787 |   1.3399 |     44.735 |     1.1
    7 |   1.2554 |     41.614 |   1.2856 |     43.396 |     1.2
    8 |   1.2331 |     41.152 |   1.2771 |     42.025 |     1.4
    9 |   1.2138 |     40.662 |   1.2943 |     43.146 |     1.6
   10 |   1.1935 |     40.183 |   1.2595 |     41.931 |     1.8
   11 |   1.1736 |     39.935 |   1.2508 |     41.340 |     1.9
   12 |   1.1573 |     39.197 |   1.2321 |     41.277 |     2.1
   13 |   1.1414 |     39.170 |   1.2525 |     41.402 |     2.3
   14 |   1.1227 |     38.195 |   1.2471 |     41.371 |     2.5
   15 |   1.1062 |     37.656 |   1.2363 |     41.059 |     2.7
   16 |   1.0900 |     36.956 |   1.2661 |     41.090 |     2.8
   17 |   1.0776 |     37.132 |   1.2212 |     40.280 |     3.0
   18 |   1.0635 |     36.141 |   1.2418 |     40.841 |     3.2
   19 |   1.0516 |     35.734 |   1.2443 |     41.215 |     3.4
   20 |   1.0322 |     35.426 |   1.1882 |     39.875 |     3.6
   21 |   1.0213 |     34.655 |   1.2477 |     40.405 |     3.7
   22 |   1.0058 |     34.143 |   1.2418 |     40.000 |     3.9
   23 |   0.9990 |     34.203 |   1.2104 |     39.938 |     4.1
   24 |   0.9791 |     33.185 |   1.1535 |     38.069 |     4.3
   25 |   0.9621 |     32.816 |   1.1996 |     39.907 |     4.4
   26 |   0.9536 |     32.078 |   1.2019 |     39.564 |     4.6
   27 |   0.9380 |     31.830 |   1.1844 |     38.754 |     4.8
   28 |   0.9287 |     31.153 |   1.2133 |     39.315 |     5.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 343,394

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5476 |     62.119 |   1.9755 |     49.221 |     0.2
    2 |   1.7440 |     46.195 |   1.6347 |     46.667 |     0.3
    3 |   1.5424 |     45.265 |   1.5125 |     45.483 |     0.5
    4 |   1.4492 |     44.643 |   1.4365 |     44.112 |     0.6
    5 |   1.3855 |     43.437 |   1.3941 |     44.486 |     0.8
    6 |   1.3401 |     42.831 |   1.3578 |     44.424 |     1.0
    7 |   1.2996 |     41.758 |   1.3401 |     44.206 |     1.2
    8 |   1.2676 |     41.174 |   1.3176 |     43.925 |     1.3
    9 |   1.2361 |     40.414 |   1.2964 |     43.333 |     1.5
   10 |   1.2099 |     39.957 |   1.2789 |     42.617 |     1.7
   11 |   1.1858 |     39.401 |   1.2612 |     42.461 |     1.9
   12 |   1.1628 |     38.812 |   1.2625 |     41.526 |     2.1
   13 |   1.1397 |     38.024 |   1.2399 |     41.682 |     2.2
   14 |   1.1222 |     37.898 |   1.2263 |     41.277 |     2.4
   15 |   1.1026 |     37.011 |   1.2128 |     41.121 |     2.6
   16 |   1.0851 |     36.571 |   1.2035 |     39.907 |     2.7
   17 |   1.0720 |     36.202 |   1.1959 |     40.093 |     2.9
   18 |   1.0507 |     35.255 |   1.1996 |     39.782 |     3.1
   19 |   1.0350 |     34.677 |   1.1850 |     40.249 |     3.3
   20 |   1.0211 |     34.038 |   1.1902 |     39.720 |     3.4
   21 |   1.0021 |     33.366 |   1.1649 |     39.283 |     3.6
   22 |   0.9891 |     32.986 |   1.1741 |     39.065 |     3.7
   23 |   0.9789 |     32.441 |   1.1336 |     37.664 |     3.9
   24 |   0.9613 |     31.643 |   1.1492 |     38.598 |     4.1
   25 |   0.9433 |     31.236 |   1.1414 |     38.411 |     4.2
   26 |   0.9311 |     30.757 |   1.1361 |     37.882 |     4.4
   27 |   0.9131 |     30.360 |   1.1233 |     37.196 |     4.6
   28 |   0.9024 |     29.776 |   1.1053 |     37.259 |     4.8
   29 |   0.8866 |     29.127 |   1.1410 |     38.162 |     5.0
   30 |   0.8715 |     28.719 |   1.1397 |     38.100 |     5.1
   31 |   0.8648 |     28.758 |   1.1424 |     38.162 |     5.3
   32 |   0.8422 |     27.756 |   1.1544 |     37.695 |     5.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 326,690

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8610 |     51.465 |   1.4135 |     45.670 |     0.1
    2 |   1.3917 |     45.513 |   1.3496 |     45.389 |     0.2
    3 |   1.3236 |     44.323 |   1.2906 |     44.579 |     0.3
    4 |   1.2715 |     42.985 |   1.2558 |     43.022 |     0.3
    5 |   1.2371 |     41.895 |   1.2047 |     41.776 |     0.4
    6 |   1.2105 |     41.383 |   1.2503 |     41.963 |     0.5
    7 |   1.1813 |     40.491 |   1.2103 |     41.838 |     0.6
    8 |   1.1580 |     39.930 |   1.1576 |     40.031 |     0.7
    9 |   1.1406 |     39.280 |   1.1942 |     40.623 |     0.8
   10 |   1.1191 |     38.619 |   1.1625 |     39.003 |     0.9
   11 |   1.0956 |     37.755 |   1.1244 |     38.660 |     0.9
   12 |   1.0788 |     37.611 |   1.1911 |     39.377 |     1.0
   13 |   1.0546 |     36.466 |   1.1300 |     38.754 |     1.1
   14 |   1.0417 |     35.877 |   1.1181 |     36.262 |     1.2
   15 |   1.0224 |     35.134 |   1.1160 |     37.103 |     1.3
   16 |   1.0020 |     34.567 |   1.1719 |     38.006 |     1.4
   17 |   0.9864 |     33.669 |   1.1446 |     37.601 |     1.5
   18 |   0.9773 |     33.950 |   1.1085 |     36.854 |     1.6
   19 |   0.9603 |     33.008 |   1.1367 |     36.293 |     1.7
   20 |   0.9355 |     32.364 |   1.0894 |     36.044 |     1.8
   21 |   0.9190 |     31.880 |   1.1001 |     36.604 |     1.9
   22 |   0.8952 |     30.795 |   1.0772 |     35.732 |     1.9
   23 |   0.8828 |     30.118 |   1.1180 |     35.421 |     2.0
   24 |   0.8699 |     30.112 |   1.1695 |     37.009 |     2.1
   25 |   0.8577 |     29.898 |   1.0970 |     35.202 |     2.2
   26 |   0.8473 |     29.286 |   1.1493 |     36.542 |     2.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 343,394

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8261 |     51.101 |   1.3871 |     45.389 |     0.1
    2 |   1.3678 |     45.777 |   1.3043 |     43.769 |     0.2
    3 |   1.3111 |     44.813 |   1.2624 |     43.956 |     0.4
    4 |   1.2795 |     43.668 |   1.2276 |     42.461 |     0.5
    5 |   1.2524 |     43.134 |   1.2050 |     41.931 |     0.6
    6 |   1.2353 |     42.771 |   1.1994 |     42.710 |     0.7
    7 |   1.2175 |     42.385 |   1.1783 |     41.526 |     0.8
    8 |   1.2024 |     42.220 |   1.1779 |     41.433 |     1.0
    9 |   1.1888 |     41.835 |   1.1580 |     40.623 |     1.1
   10 |   1.1769 |     41.240 |   1.1457 |     40.717 |     1.2
   11 |   1.1641 |     40.810 |   1.1540 |     40.187 |     1.3
   12 |   1.1514 |     40.431 |   1.1234 |     39.844 |     1.5
   13 |   1.1397 |     40.205 |   1.1212 |     39.907 |     1.6
   14 |   1.1272 |     39.627 |   1.1002 |     38.754 |     1.7
   15 |   1.1161 |     39.346 |   1.0889 |     38.692 |     1.8
   16 |   1.1026 |     39.252 |   1.1104 |     39.159 |     1.9
   17 |   1.1025 |     39.236 |   1.0859 |     37.477 |     2.1
   18 |   1.0875 |     38.481 |   1.0984 |     38.567 |     2.2
   19 |   1.0830 |     38.228 |   1.0721 |     36.449 |     2.3
   20 |   1.0700 |     37.562 |   1.0620 |     37.757 |     2.4
   21 |   1.0599 |     37.402 |   1.0643 |     37.695 |     2.5
   22 |   1.0583 |     37.766 |   1.0417 |     37.040 |     2.6
   23 |   1.0436 |     36.890 |   1.0484 |     36.573 |     2.8
   24 |   1.0439 |     36.780 |   1.0460 |     36.760 |     2.9
   25 |   1.0280 |     36.130 |   1.0302 |     36.137 |     3.0
   26 |   1.0210 |     35.894 |   1.0505 |     36.978 |     3.1
   27 |   1.0104 |     35.728 |   1.0266 |     35.701 |     3.2
   28 |   1.0135 |     36.059 |   1.0319 |     36.386 |     3.4
   29 |   1.0009 |     35.618 |   1.0174 |     34.984 |     3.5
   30 |   0.9912 |     35.315 |   1.0364 |     36.480 |     3.6
   31 |   0.9837 |     34.743 |   1.0380 |     36.168 |     3.7
   32 |   0.9779 |     34.308 |   1.0217 |     36.417 |     3.8
   33 |   0.9776 |     34.424 |   1.0182 |     35.576 |     3.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.2
Trainable parameters: 748,962

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4047 |     59.002 |   1.7038 |     45.950 |     0.1
    2 |   1.6695 |     46.647 |   1.4668 |     45.763 |     0.3
    3 |   1.4869 |     45.815 |   1.3999 |     45.109 |     0.4
    4 |   1.4137 |     44.990 |   1.3542 |     44.829 |     0.6
    5 |   1.3657 |     44.351 |   1.3122 |     43.707 |     0.7
    6 |   1.3277 |     43.503 |   1.2944 |     43.738 |     0.9
    7 |   1.3001 |     42.947 |   1.2506 |     42.305 |     1.0
    8 |   1.2722 |     42.308 |   1.2472 |     42.492 |     1.2
    9 |   1.2521 |     41.774 |   1.2305 |     42.212 |     1.3
   10 |   1.2329 |     41.312 |   1.2388 |     42.399 |     1.4
   11 |   1.2172 |     41.174 |   1.2260 |     42.212 |     1.6
   12 |   1.2017 |     40.590 |   1.2280 |     41.651 |     1.7
   13 |   1.1916 |     40.453 |   1.1911 |     40.997 |     1.9
   14 |   1.1800 |     39.682 |   1.2368 |     40.966 |     2.0
   15 |   1.1725 |     39.671 |   1.1843 |     40.779 |     2.2
   16 |   1.1576 |     39.137 |   1.1958 |     41.121 |     2.3
   17 |   1.1449 |     38.773 |   1.2118 |     41.433 |     2.5
   18 |   1.1404 |     38.900 |   1.2058 |     40.810 |     2.6
   19 |   1.1286 |     38.289 |   1.1964 |     40.374 |     2.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 980,258

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.9864 |     51.800 |   1.5255 |     45.545 |     0.1
    2 |   1.4171 |     44.323 |   1.3980 |     46.106 |     0.2
    3 |   1.3207 |     42.578 |   1.3398 |     43.832 |     0.3
    4 |   1.2579 |     40.904 |   1.2839 |     43.209 |     0.4
    5 |   1.2120 |     39.990 |   1.2736 |     42.679 |     0.5
    6 |   1.1718 |     39.164 |   1.2325 |     41.246 |     0.6
    7 |   1.1365 |     38.046 |   1.2147 |     40.436 |     0.7
    8 |   1.1060 |     37.204 |   1.2116 |     41.153 |     0.8
    9 |   1.0790 |     36.218 |   1.1831 |     40.654 |     0.9
   10 |   1.0510 |     35.354 |   1.1679 |     39.097 |     1.0
   11 |   1.0201 |     34.187 |   1.1437 |     38.100 |     1.1
   12 |   0.9996 |     33.416 |   1.1411 |     38.037 |     1.2
   13 |   0.9726 |     32.469 |   1.1476 |     38.287 |     1.3
   14 |   0.9469 |     31.781 |   1.1338 |     38.131 |     1.4
   15 |   0.9233 |     30.641 |   1.1022 |     36.417 |     1.5
   16 |   0.8950 |     29.798 |   1.1214 |     36.449 |     1.6
   17 |   0.8798 |     29.341 |   1.1018 |     36.231 |     1.7
   18 |   0.8536 |     28.554 |   1.1206 |     36.822 |     1.8
   19 |   0.8297 |     27.937 |   1.0857 |     35.607 |     1.9
   20 |   0.8044 |     26.737 |   1.0981 |     35.670 |     2.0
   21 |   0.7843 |     26.115 |   1.1245 |     36.075 |     2.1
   22 |   0.7644 |     25.619 |   1.0633 |     34.268 |     2.2
   23 |   0.7331 |     24.281 |   1.0874 |     35.047 |     2.3
   24 |   0.7112 |     23.367 |   1.0803 |     34.984 |     2.4
   25 |   0.6893 |     22.960 |   1.1160 |     34.829 |     2.5
   26 |   0.6663 |     21.897 |   1.0652 |     33.676 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 285,602

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.8069 |     51.046 |   1.3732 |     44.611 |     0.1
    2 |   1.3520 |     45.138 |   1.2908 |     43.676 |     0.2
    3 |   1.2837 |     43.839 |   1.2343 |     42.617 |     0.4
    4 |   1.2342 |     42.721 |   1.1874 |     41.651 |     0.5
    5 |   1.2043 |     42.099 |   1.1802 |     43.458 |     0.6
    6 |   1.1749 |     41.185 |   1.1477 |     41.121 |     0.7
    7 |   1.1485 |     39.952 |   1.1176 |     39.252 |     0.8
    8 |   1.1358 |     39.687 |   1.1376 |     40.218 |     0.9
    9 |   1.1127 |     39.230 |   1.1216 |     39.439 |     1.0
   10 |   1.0962 |     38.404 |   1.0823 |     38.380 |     1.1
   11 |   1.0780 |     38.068 |   1.0842 |     38.131 |     1.3
   12 |   1.0717 |     37.766 |   1.0615 |     38.380 |     1.4
   13 |   1.0469 |     36.670 |   1.0607 |     36.324 |     1.5
   14 |   1.0236 |     35.954 |   1.0516 |     36.012 |     1.6
   15 |   1.0190 |     35.833 |   1.0423 |     35.950 |     1.7
   16 |   0.9960 |     34.341 |   1.0503 |     37.321 |     1.8
   17 |   0.9806 |     34.451 |   1.0505 |     36.293 |     1.9
   18 |   0.9600 |     33.350 |   1.0307 |     35.358 |     2.1
   19 |   0.9409 |     33.097 |   1.0173 |     35.794 |     2.2
   20 |   0.9256 |     32.039 |   0.9990 |     34.611 |     2.3
   21 |   0.9118 |     31.797 |   1.0323 |     35.670 |     2.4
   22 |   0.8988 |     31.092 |   1.0378 |     34.704 |     2.5
   23 |   0.8774 |     30.652 |   1.0118 |     34.642 |     2.6
   24 |   0.8678 |     30.355 |   1.0236 |     34.984 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 1,047,842

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1513 |     55.704 |   1.5519 |     45.763 |     0.1
    2 |   1.4391 |     44.659 |   1.4150 |     45.109 |     0.3
    3 |   1.3407 |     43.184 |   1.3401 |     44.081 |     0.4
    4 |   1.2816 |     42.016 |   1.3276 |     44.237 |     0.6
    5 |   1.2408 |     41.102 |   1.2750 |     43.178 |     0.8
    6 |   1.1992 |     40.282 |   1.2578 |     42.243 |     0.9
    7 |   1.1710 |     39.572 |   1.2165 |     41.745 |     1.1
    8 |   1.1408 |     38.894 |   1.2264 |     42.150 |     1.2
    9 |   1.1084 |     37.452 |   1.1908 |     40.748 |     1.4
   10 |   1.0827 |     36.802 |   1.1441 |     38.847 |     1.5
   11 |   1.0567 |     35.651 |   1.1399 |     37.913 |     1.7
   12 |   1.0288 |     34.847 |   1.1934 |     40.654 |     1.8
   13 |   1.0059 |     33.867 |   1.1957 |     38.567 |     2.0
   14 |   0.9830 |     32.953 |   1.1056 |     36.324 |     2.1
   15 |   0.9546 |     31.676 |   1.1759 |     37.944 |     2.3
   16 |   0.9341 |     31.456 |   1.1148 |     36.667 |     2.4
   17 |   0.9153 |     30.322 |   1.1425 |     37.040 |     2.6
   18 |   0.8846 |     29.237 |   1.1349 |     36.480 |     2.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 648,482

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2498 |     56.767 |   1.5875 |     45.701 |     0.1
    2 |   1.5391 |     45.931 |   1.4287 |     46.106 |     0.2
    3 |   1.4188 |     45.072 |   1.3610 |     44.611 |     0.3
    4 |   1.3597 |     44.048 |   1.3203 |     44.268 |     0.4
    5 |   1.3144 |     43.178 |   1.2872 |     43.551 |     0.5
    6 |   1.2766 |     42.572 |   1.2572 |     42.617 |     0.7
    7 |   1.2470 |     41.972 |   1.2379 |     41.807 |     0.8
    8 |   1.2229 |     40.871 |   1.2333 |     41.900 |     0.9
    9 |   1.2014 |     40.651 |   1.2261 |     42.087 |     1.0
   10 |   1.1795 |     40.062 |   1.1988 |     41.340 |     1.1
   11 |   1.1640 |     39.473 |   1.1756 |     40.592 |     1.2
   12 |   1.1463 |     38.806 |   1.1713 |     40.000 |     1.3
   13 |   1.1307 |     38.548 |   1.1726 |     40.343 |     1.4
   14 |   1.1144 |     38.096 |   1.1524 |     39.564 |     1.5
   15 |   1.1004 |     37.468 |   1.1556 |     39.439 |     1.6
   16 |   1.0873 |     37.099 |   1.1392 |     38.754 |     1.8
   17 |   1.0726 |     36.780 |   1.1329 |     38.660 |     1.9
   18 |   1.0663 |     36.362 |   1.1682 |     39.533 |     2.0
   19 |   1.0490 |     36.169 |   1.1257 |     37.788 |     2.1
   20 |   1.0364 |     35.327 |   1.1214 |     37.664 |     2.2
   21 |   1.0206 |     34.666 |   1.1111 |     37.632 |     2.3
   22 |   1.0101 |     34.269 |   1.1245 |     38.567 |     2.4
   23 |   0.9998 |     33.867 |   1.1057 |     36.978 |     2.5
   24 |   0.9836 |     33.510 |   1.1158 |     36.822 |     2.6
   25 |   0.9684 |     32.772 |   1.1200 |     37.165 |     2.7
   26 |   0.9630 |     32.772 |   1.1065 |     37.072 |     2.8
   27 |   0.9549 |     32.276 |   1.1048 |     36.822 |     2.9
   28 |   0.9390 |     32.128 |   1.1111 |     37.009 |     3.0
   29 |   0.9298 |     31.505 |   1.1286 |     37.352 |     3.1
   30 |   0.9172 |     31.026 |   1.1367 |     36.916 |     3.2
   31 |   0.9087 |     30.966 |   1.0978 |     36.075 |     3.3
   32 |   0.8937 |     30.564 |   1.1074 |     36.044 |     3.4
   33 |   0.8855 |     29.969 |   1.0947 |     35.919 |     3.5
   34 |   0.8761 |     29.677 |   1.0917 |     35.701 |     3.7
   35 |   0.8641 |     29.127 |   1.1066 |     35.607 |     3.8
   36 |   0.8560 |     29.011 |   1.1194 |     35.514 |     3.9
   37 |   0.8449 |     28.664 |   1.1181 |     35.483 |     4.0
   38 |   0.8344 |     28.306 |   1.1098 |     35.794 |     4.1
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 276,450

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.7339 |     49.240 |   1.3794 |     44.953 |     0.1
    2 |   1.3364 |     44.268 |   1.2998 |     43.956 |     0.1
    3 |   1.2600 |     42.605 |   1.2169 |     41.900 |     0.2
    4 |   1.2024 |     41.003 |   1.1878 |     41.215 |     0.3
    5 |   1.1648 |     40.254 |   1.2115 |     41.963 |     0.4
    6 |   1.1362 |     38.905 |   1.1374 |     39.439 |     0.4
    7 |   1.0992 |     37.738 |   1.1168 |     39.408 |     0.5
    8 |   1.0743 |     36.912 |   1.0954 |     37.882 |     0.6
    9 |   1.0439 |     36.059 |   1.0902 |     36.854 |     0.7
   10 |   1.0260 |     35.123 |   1.0762 |     36.978 |     0.7
   11 |   0.9935 |     33.906 |   1.0800 |     36.293 |     0.8
   12 |   0.9739 |     33.620 |   1.0362 |     35.109 |     0.9
   13 |   0.9499 |     32.634 |   1.0405 |     34.984 |     0.9
   14 |   0.9170 |     31.472 |   1.0681 |     35.763 |     1.0
   15 |   0.9020 |     31.203 |   1.0519 |     35.296 |     1.1
   16 |   0.8792 |     30.239 |   1.0039 |     32.897 |     1.2
   17 |   0.8533 |     29.259 |   1.0464 |     34.393 |     1.2
   18 |   0.8333 |     28.565 |   1.0383 |     34.268 |     1.3
   19 |   0.8199 |     28.268 |   1.0302 |     34.393 |     1.4
   20 |   0.7973 |     27.453 |   1.0183 |     32.804 |     1.4
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 293,154

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7541 |     64.679 |   2.0776 |     48.879 |     0.1
    2 |   1.8970 |     47.445 |   1.6349 |     47.103 |     0.2
    3 |   1.6255 |     46.080 |   1.5203 |     45.452 |     0.3
    4 |   1.5258 |     45.661 |   1.4633 |     45.670 |     0.4
    5 |   1.4688 |     45.237 |   1.4199 |     45.171 |     0.5
    6 |   1.4259 |     44.979 |   1.3882 |     45.639 |     0.6
    7 |   1.3951 |     44.285 |   1.3644 |     44.611 |     0.7
    8 |   1.3681 |     43.641 |   1.3389 |     43.676 |     0.8
    9 |   1.3397 |     43.255 |   1.3182 |     43.271 |     0.9
   10 |   1.3215 |     42.820 |   1.3142 |     43.614 |     1.0
   11 |   1.3044 |     42.600 |   1.2974 |     43.178 |     1.1
   12 |   1.2873 |     42.066 |   1.2780 |     42.897 |     1.2
   13 |   1.2708 |     41.890 |   1.2631 |     42.586 |     1.3
   14 |   1.2610 |     41.769 |   1.2627 |     42.368 |     1.5
   15 |   1.2483 |     41.653 |   1.2486 |     42.586 |     1.6
   16 |   1.2329 |     40.970 |   1.2380 |     42.212 |     1.7
   17 |   1.2231 |     40.684 |   1.2226 |     41.371 |     1.8
   18 |   1.2116 |     40.453 |   1.2345 |     42.150 |     1.9
   19 |   1.2051 |     40.183 |   1.2359 |     42.087 |     2.0
   20 |   1.1945 |     39.836 |   1.2123 |     41.526 |     2.1
   21 |   1.1829 |     39.753 |   1.2085 |     40.966 |     2.2
   22 |   1.1790 |     39.566 |   1.1998 |     40.966 |     2.3
   23 |   1.1678 |     39.302 |   1.1979 |     40.903 |     2.4
   24 |   1.1588 |     39.197 |   1.1705 |     40.654 |     2.5
   25 |   1.1523 |     38.994 |   1.1686 |     40.561 |     2.6
   26 |   1.1473 |     38.889 |   1.1801 |     40.249 |     2.7
   27 |   1.1394 |     38.779 |   1.1688 |     39.720 |     2.8
   28 |   1.1312 |     38.140 |   1.1736 |     40.405 |     2.9
   29 |   1.1245 |     38.046 |   1.1568 |     39.813 |     3.0
   30 |   1.1150 |     37.969 |   1.1412 |     39.782 |     3.1
   31 |   1.1101 |     37.793 |   1.1632 |     39.938 |     3.2
   32 |   1.1032 |     37.347 |   1.1453 |     39.003 |     3.3
   33 |   1.0946 |     37.314 |   1.1461 |     39.034 |     3.4
   34 |   1.0879 |     36.808 |   1.1574 |     39.533 |     3.5
   35 |   1.0857 |     37.121 |   1.1361 |     39.128 |     3.6
   36 |   1.0757 |     36.466 |   1.1372 |     38.879 |     3.8
   37 |   1.0706 |     36.301 |   1.1375 |     38.692 |     3.9
   38 |   1.0641 |     36.092 |   1.1347 |     39.315 |     4.0
   39 |   1.0546 |     35.563 |   1.1254 |     38.474 |     4.1
   40 |   1.0536 |     35.635 |   1.1176 |     38.411 |     4.2
   41 |   1.0468 |     35.448 |   1.1308 |     38.629 |     4.3
   42 |   1.0422 |     35.304 |   1.1202 |     38.037 |     4.4
   43 |   1.0327 |     35.024 |   1.1064 |     37.445 |     4.5
   44 |   1.0243 |     34.715 |   1.1233 |     38.287 |     4.6
   45 |   1.0237 |     34.644 |   1.0995 |     37.227 |     4.7
   46 |   1.0204 |     34.726 |   1.1070 |     37.352 |     4.8
   47 |   1.0150 |     34.055 |   1.1112 |     37.757 |     4.9
   48 |   1.0061 |     33.851 |   1.1201 |     38.162 |     5.0
   49 |   1.0024 |     33.994 |   1.1127 |     37.414 |     5.1
   50 |   0.9977 |     33.713 |   1.0895 |     36.978 |     5.2
   51 |   0.9907 |     33.493 |   1.0843 |     36.978 |     5.3
   52 |   0.9881 |     33.554 |   1.1037 |     37.072 |     5.4
   53 |   0.9819 |     33.190 |   1.1278 |     38.037 |     5.5
   54 |   0.9742 |     32.794 |   1.0933 |     37.040 |     5.6
   55 |   0.9704 |     32.893 |   1.0820 |     36.822 |     5.7
   56 |   0.9630 |     32.353 |   1.1046 |     37.352 |     5.9
   57 |   0.9593 |     32.480 |   1.0895 |     36.386 |     6.0
   58 |   0.9518 |     32.045 |   1.0947 |     36.729 |     6.1
   59 |   0.9488 |     32.100 |   1.0785 |     36.168 |     6.2
   60 |   0.9425 |     31.924 |   1.0921 |     37.040 |     6.3
   61 |   0.9426 |     31.863 |   1.1126 |     38.224 |     6.4
   62 |   0.9398 |     31.434 |   1.0926 |     37.352 |     6.5
   63 |   0.9275 |     31.610 |   1.1080 |     37.508 |     6.6
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 64
Encoder layers: 4
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 898,402

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5344 |     47.379 |   1.2870 |     46.542 |     0.2
    2 |   1.2528 |     43.751 |   1.2515 |     45.078 |     0.3
    3 |   1.2052 |     42.672 |   1.2122 |     43.364 |     0.5
    4 |   1.1595 |     41.570 |   1.1591 |     42.243 |     0.7
    5 |   1.1278 |     39.847 |   1.1270 |     39.688 |     0.9
    6 |   1.0988 |     38.922 |   1.1286 |     41.963 |     1.0
    7 |   1.0750 |     38.305 |   1.1048 |     39.315 |     1.2
    8 |   1.0533 |     37.716 |   1.0845 |     38.505 |     1.4
    9 |   1.0311 |     36.670 |   1.0732 |     38.287 |     1.6
   10 |   1.0170 |     36.565 |   1.0541 |     38.442 |     1.7
   11 |   1.0009 |     35.899 |   1.0603 |     38.224 |     1.9
   12 |   0.9868 |     35.442 |   1.0469 |     38.162 |     2.1
   13 |   0.9759 |     34.770 |   1.0402 |     37.445 |     2.2
   14 |   0.9587 |     34.743 |   1.0282 |     37.134 |     2.4
   15 |   0.9521 |     34.396 |   1.0337 |     36.075 |     2.6
   16 |   0.9398 |     34.011 |   1.0302 |     36.386 |     2.8
   17 |   0.9308 |     33.388 |   0.9974 |     36.168 |     2.9
   18 |   0.9033 |     32.375 |   1.0153 |     36.324 |     3.1
   19 |   0.9058 |     32.463 |   1.0076 |     35.763 |     3.3
   20 |   0.9011 |     32.419 |   0.9988 |     35.763 |     3.5
   21 |   0.8786 |     31.191 |   0.9914 |     34.206 |     3.6
   22 |   0.8675 |     31.054 |   0.9718 |     33.925 |     3.8
   23 |   0.8583 |     30.597 |   0.9863 |     35.576 |     4.0
   24 |   0.8610 |     31.059 |   0.9770 |     33.551 |     4.1
   25 |   0.8420 |     30.195 |   0.9715 |     33.333 |     4.3
   26 |   0.8277 |     29.865 |   0.9724 |     34.393 |     4.5
   27 |   0.8156 |     29.341 |   0.9848 |     33.707 |     4.7
   28 |   0.8177 |     29.606 |   0.9710 |     34.735 |     4.8
   29 |   0.8106 |     28.692 |   0.9700 |     33.925 |     5.0
   30 |   0.7945 |     28.306 |   0.9882 |     34.455 |     5.2
   31 |   0.7763 |     27.657 |   0.9544 |     32.617 |     5.4
   32 |   0.7696 |     27.690 |   0.9951 |     33.614 |     5.5
   33 |   0.7755 |     27.574 |   0.9852 |     33.894 |     5.7
   34 |   0.7488 |     26.517 |   0.9802 |     33.053 |     5.9
   35 |   0.7407 |     26.154 |   0.9575 |     32.804 |     6.0
   36 |   0.7324 |     26.176 |   0.9542 |     31.745 |     6.2
   37 |   0.7195 |     25.542 |   0.9719 |     33.146 |     6.4
   38 |   0.7263 |     25.851 |   0.9858 |     32.897 |     6.6
   39 |   0.7161 |     25.570 |   0.9595 |     32.648 |     6.7
   40 |   0.6992 |     25.328 |   0.9866 |     33.115 |     6.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 277,154

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.7543 |     67.129 |   2.0659 |     48.879 |     0.1
    2 |   1.9256 |     47.484 |   1.6386 |     46.324 |     0.2
    3 |   1.6417 |     46.168 |   1.5223 |     45.732 |     0.3
    4 |   1.5344 |     45.766 |   1.4568 |     45.670 |     0.4
    5 |   1.4722 |     45.612 |   1.4161 |     45.296 |     0.5
    6 |   1.4302 |     45.127 |   1.3844 |     44.735 |     0.6
    7 |   1.3968 |     44.676 |   1.3570 |     44.361 |     0.7
    8 |   1.3678 |     44.263 |   1.3385 |     43.178 |     0.8
    9 |   1.3463 |     43.745 |   1.3155 |     43.427 |     0.9
   10 |   1.3238 |     43.729 |   1.3095 |     44.237 |     1.0
   11 |   1.3071 |     43.167 |   1.2886 |     44.206 |     1.1
   12 |   1.2904 |     42.627 |   1.2783 |     43.769 |     1.3
   13 |   1.2710 |     42.187 |   1.2648 |     43.302 |     1.4
   14 |   1.2575 |     41.785 |   1.2614 |     43.520 |     1.5
   15 |   1.2442 |     41.323 |   1.2549 |     43.209 |     1.6
   16 |   1.2330 |     41.130 |   1.2496 |     42.897 |     1.7
   17 |   1.2234 |     40.866 |   1.2411 |     42.710 |     1.8
   18 |   1.2110 |     40.827 |   1.2312 |     42.679 |     1.9
   19 |   1.1993 |     40.282 |   1.2376 |     42.274 |     2.0
   20 |   1.1928 |     40.409 |   1.2233 |     41.776 |     2.1
   21 |   1.1818 |     40.122 |   1.2149 |     41.277 |     2.2
   22 |   1.1760 |     39.792 |   1.2192 |     41.464 |     2.3
   23 |   1.1628 |     39.302 |   1.2173 |     41.246 |     2.4
   24 |   1.1571 |     39.329 |   1.2093 |     41.246 |     2.5
   25 |   1.1444 |     38.938 |   1.2204 |     40.748 |     2.6
   26 |   1.1451 |     39.076 |   1.2006 |     40.903 |     2.7
   27 |   1.1371 |     38.680 |   1.1984 |     40.685 |     2.8
   28 |   1.1282 |     38.597 |   1.1886 |     40.498 |     2.9
   29 |   1.1203 |     38.113 |   1.1960 |     40.748 |     3.0
   30 |   1.1131 |     37.843 |   1.1772 |     40.062 |     3.1
   31 |   1.1071 |     37.507 |   1.1883 |     40.218 |     3.2
   32 |   1.0993 |     37.534 |   1.1653 |     40.062 |     3.3
   33 |   1.0979 |     37.331 |   1.1969 |     40.405 |     3.4
   34 |   1.0939 |     37.683 |   1.1827 |     40.343 |     3.5
   35 |   1.0785 |     36.852 |   1.1689 |     39.595 |     3.6
   36 |   1.0760 |     36.720 |   1.1793 |     40.498 |     3.7
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 3
Attention heads: 4
Activation: relu
Dropout: 0.0
Trainable parameters: 814,370

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1385 |     53.893 |   1.5269 |     45.171 |     0.1
    2 |   1.4105 |     44.164 |   1.3750 |     44.704 |     0.2
    3 |   1.3128 |     42.853 |   1.3341 |     44.579 |     0.3
    4 |   1.2560 |     41.433 |   1.2915 |     44.050 |     0.4
    5 |   1.2132 |     40.431 |   1.2594 |     42.835 |     0.5
    6 |   1.1758 |     39.786 |   1.2347 |     41.371 |     0.6
    7 |   1.1454 |     38.911 |   1.2245 |     41.558 |     0.7
    8 |   1.1143 |     37.694 |   1.1667 |     39.408 |     0.8
    9 |   1.0914 |     37.199 |   1.1888 |     39.875 |     0.9
   10 |   1.0633 |     36.108 |   1.1522 |     39.221 |     1.1
   11 |   1.0433 |     35.486 |   1.1530 |     39.283 |     1.2
   12 |   1.0193 |     34.633 |   1.1316 |     38.442 |     1.3
   13 |   0.9980 |     33.554 |   1.1380 |     39.097 |     1.4
   14 |   0.9772 |     32.992 |   1.1305 |     38.847 |     1.5
   15 |   0.9536 |     32.155 |   1.1041 |     37.539 |     1.6
   16 |   0.9331 |     31.236 |   1.1648 |     38.536 |     1.7
   17 |   0.9156 |     30.652 |   1.0998 |     36.511 |     1.8
   18 |   0.8917 |     29.611 |   1.1299 |     38.474 |     1.9
   19 |   0.8666 |     28.956 |   1.1081 |     36.542 |     2.0
   20 |   0.8564 |     28.532 |   1.1118 |     36.137 |     2.1
   21 |   0.8307 |     27.684 |   1.0923 |     35.483 |     2.2
   22 |   0.8105 |     26.467 |   1.1251 |     36.386 |     2.3
   23 |   0.7913 |     26.269 |   1.1174 |     35.234 |     2.4
   24 |   0.7679 |     25.311 |   1.0841 |     35.140 |     2.5
   25 |   0.7502 |     24.738 |   1.0981 |     34.829 |     2.6
   26 |   0.7246 |     24.105 |   1.1108 |     35.047 |     2.8
   27 |   0.7081 |     23.373 |   1.1094 |     35.047 |     2.9
   28 |   0.6883 |     22.492 |   1.1220 |     34.766 |     3.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 3
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 978,850

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1419 |     55.165 |   1.5129 |     45.265 |     0.1
    2 |   1.4872 |     45.865 |   1.3997 |     44.891 |     0.2
    3 |   1.3868 |     44.472 |   1.3307 |     44.143 |     0.3
    4 |   1.3289 |     43.486 |   1.3027 |     43.427 |     0.4
    5 |   1.2838 |     42.143 |   1.2741 |     42.991 |     0.5
    6 |   1.2447 |     41.438 |   1.2420 |     42.928 |     0.6
    7 |   1.2175 |     40.519 |   1.2320 |     42.087 |     0.7
    8 |   1.1927 |     40.205 |   1.2074 |     41.651 |     0.8
    9 |   1.1712 |     39.522 |   1.1949 |     41.371 |     0.9
   10 |   1.1464 |     38.944 |   1.2155 |     41.495 |     1.0
   11 |   1.1277 |     38.415 |   1.1554 |     39.283 |     1.0
   12 |   1.1113 |     37.870 |   1.1853 |     40.530 |     1.1
   13 |   1.0898 |     36.879 |   1.1674 |     39.003 |     1.2
   14 |   1.0740 |     36.196 |   1.1277 |     37.975 |     1.3
   15 |   1.0545 |     35.574 |   1.1098 |     37.695 |     1.4
   16 |   1.0406 |     35.035 |   1.1132 |     37.664 |     1.5
   17 |   1.0220 |     34.836 |   1.0847 |     36.542 |     1.6
   18 |   1.0057 |     33.917 |   1.0855 |     37.259 |     1.7
   19 |   0.9877 |     33.262 |   1.0737 |     36.854 |     1.8
   20 |   0.9752 |     32.684 |   1.0641 |     35.919 |     1.9
   21 |   0.9658 |     32.799 |   1.0651 |     36.199 |     2.0
   22 |   0.9533 |     32.496 |   1.0555 |     35.421 |     2.1
   23 |   0.9354 |     31.335 |   1.0814 |     36.199 |     2.2
   24 |   0.9214 |     31.302 |   1.0689 |     35.234 |     2.3
   25 |   0.9124 |     30.883 |   1.0590 |     35.140 |     2.4
   26 |   0.8995 |     29.870 |   1.0723 |     35.421 |     2.5
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 847,650

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5486 |     47.495 |   1.3167 |     44.766 |     0.1
    2 |   1.2977 |     44.709 |   1.2534 |     44.455 |     0.3
    3 |   1.2430 |     44.015 |   1.2156 |     43.614 |     0.4
    4 |   1.2157 |     43.415 |   1.1923 |     43.333 |     0.6
    5 |   1.1911 |     43.073 |   1.1793 |     43.271 |     0.7
    6 |   1.1853 |     42.666 |   1.1590 |     41.090 |     0.8
    7 |   1.1671 |     42.115 |   1.1468 |     42.150 |     1.0
    8 |   1.1585 |     42.077 |   1.1443 |     41.807 |     1.1
    9 |   1.1555 |     42.077 |   1.1298 |     40.997 |     1.3
   10 |   1.1462 |     41.983 |   1.1319 |     41.028 |     1.4
   11 |   1.1415 |     41.603 |   1.1185 |     40.997 |     1.5
   12 |   1.1388 |     41.653 |   1.1157 |     40.498 |     1.7
   13 |   1.1363 |     41.730 |   1.1165 |     40.935 |     1.8
   14 |   1.1347 |     41.554 |   1.1222 |     41.558 |     2.0
   15 |   1.1278 |     41.433 |   1.1172 |     41.340 |     2.1
   16 |   1.1220 |     41.069 |   1.1058 |     41.308 |     2.2
   17 |   1.1200 |     41.130 |   1.1125 |     40.405 |     2.4
   18 |   1.1180 |     41.047 |   1.1011 |     40.343 |     2.5
   19 |   1.1152 |     40.948 |   1.1093 |     41.277 |     2.7
   20 |   1.1145 |     41.009 |   1.1044 |     42.368 |     2.8
   21 |   1.1084 |     40.866 |   1.1014 |     41.900 |     3.0
   22 |   1.1046 |     40.541 |   1.0957 |     41.433 |     3.1
   23 |   1.0979 |     40.089 |   1.0855 |     40.748 |     3.2
   24 |   1.0869 |     39.478 |   1.0965 |     39.595 |     3.4
   25 |   1.0789 |     39.087 |   1.0992 |     39.626 |     3.5
   26 |   1.0786 |     39.280 |   1.1205 |     41.184 |     3.7
   27 |   1.0676 |     38.911 |   1.1265 |     41.900 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 4
Decoder layers: 2
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,045,026

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.5310 |     47.346 |   1.3199 |     44.361 |     0.1
    2 |   1.2837 |     44.433 |   1.2510 |     45.109 |     0.3
    3 |   1.2461 |     44.087 |   1.2019 |     41.900 |     0.4
    4 |   1.2141 |     43.481 |   1.1834 |     42.336 |     0.6
    5 |   1.1903 |     42.908 |   1.1693 |     42.118 |     0.7
    6 |   1.1788 |     42.270 |   1.1364 |     41.371 |     0.9
    7 |   1.1605 |     42.093 |   1.1378 |     41.963 |     1.0
    8 |   1.1551 |     41.851 |   1.1190 |     41.308 |     1.2
    9 |   1.1428 |     41.791 |   1.1260 |     42.181 |     1.3
   10 |   1.1378 |     41.873 |   1.1181 |     41.558 |     1.5
   11 |   1.1303 |     41.152 |   1.1140 |     40.935 |     1.6
   12 |   1.1279 |     41.521 |   1.1119 |     41.495 |     1.8
   13 |   1.1209 |     40.954 |   1.1039 |     40.872 |     1.9
   14 |   1.1212 |     40.860 |   1.1140 |     42.430 |     2.1
   15 |   1.1163 |     41.345 |   1.1179 |     42.960 |     2.2
   16 |   1.1132 |     41.091 |   1.1107 |     40.779 |     2.4
   17 |   1.1138 |     40.981 |   1.1061 |     40.405 |     2.5
   18 |   1.1070 |     40.739 |   1.0989 |     40.561 |     2.6
   19 |   1.1040 |     40.486 |   1.1013 |     40.561 |     2.8
   20 |   1.0996 |     40.557 |   1.0990 |     40.654 |     2.9
   21 |   1.1025 |     40.508 |   1.1000 |     41.402 |     3.1
   22 |   1.1023 |     40.706 |   1.0958 |     40.685 |     3.2
   23 |   1.0965 |     40.574 |   1.0911 |     40.997 |     3.4
   24 |   1.0942 |     40.667 |   1.0981 |     40.810 |     3.5
   25 |   1.0916 |     40.513 |   1.0948 |     41.526 |     3.7
   26 |   1.0922 |     40.761 |   1.0884 |     40.312 |     3.8
   27 |   1.0896 |     40.376 |   1.0869 |     40.748 |     4.0
   28 |   1.0912 |     40.888 |   1.0865 |     41.090 |     4.1
   29 |   1.0885 |     40.777 |   1.0950 |     40.187 |     4.3
   30 |   1.0895 |     40.232 |   1.0829 |     42.087 |     4.4
   31 |   1.0846 |     40.552 |   1.0825 |     41.526 |     4.6
   32 |   1.0829 |     40.447 |   1.0873 |     40.748 |     4.7
   33 |   1.0857 |     40.612 |   1.0827 |     40.467 |     4.9
   34 |   1.0832 |     40.342 |   1.0921 |     41.246 |     5.0
   35 |   1.0840 |     40.353 |   1.0873 |     40.280 |     5.2
   36 |   1.0769 |     40.243 |   1.0802 |     40.125 |     5.3
   37 |   1.0770 |     39.819 |   1.0838 |     42.212 |     5.4
   38 |   1.0793 |     40.662 |   1.0824 |     40.872 |     5.6
   39 |   1.0766 |     40.364 |   1.0772 |     40.187 |     5.7
   40 |   1.0763 |     40.249 |   1.0793 |     40.374 |     5.9
   41 |   1.0786 |     40.662 |   1.0753 |     40.031 |     6.0
   42 |   1.0766 |     40.254 |   1.0750 |     40.156 |     6.2
   43 |   1.0713 |     40.216 |   1.0727 |     40.343 |     6.3
   44 |   1.0717 |     40.232 |   1.0844 |     40.498 |     6.5
   45 |   1.0760 |     40.645 |   1.0762 |     41.308 |     6.6
   46 |   1.0747 |     40.161 |   1.0817 |     41.931 |     6.8
   47 |   1.0733 |     40.139 |   1.0793 |     40.872 |     6.9
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 64
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 277,154

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6500 |     47.588 |   1.3484 |     44.548 |     0.1
    2 |   1.2521 |     42.231 |   1.2510 |     42.274 |     0.1
    3 |   1.1683 |     39.869 |   1.1683 |     40.779 |     0.2
    4 |   1.1035 |     37.898 |   1.1380 |     38.536 |     0.3
    5 |   1.0638 |     36.549 |   1.0938 |     37.664 |     0.4
    6 |   1.0138 |     34.616 |   1.0847 |     37.290 |     0.4
    7 |   0.9765 |     33.212 |   1.0696 |     36.262 |     0.5
    8 |   0.9298 |     31.676 |   1.0455 |     35.452 |     0.6
    9 |   0.8818 |     29.821 |   1.0226 |     34.766 |     0.7
   10 |   0.8505 |     28.829 |   1.0602 |     35.327 |     0.7
   11 |   0.8167 |     27.447 |   1.0248 |     34.517 |     0.8
   12 |   0.7741 |     26.253 |   1.0512 |     34.330 |     0.9
   13 |   0.7334 |     24.959 |   1.0523 |     34.891 |     1.0
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 64
Feedforward dimension: 128
Encoder layers: 4
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.0
Trainable parameters: 393,634

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   1.6843 |     48.937 |   1.3633 |     44.735 |     0.1
    2 |   1.2809 |     43.514 |   1.2612 |     45.016 |     0.2
    3 |   1.2133 |     42.655 |   1.2104 |     44.611 |     0.3
    4 |   1.1813 |     42.104 |   1.1765 |     41.682 |     0.4
    5 |   1.1565 |     41.658 |   1.1734 |     42.274 |     0.5
    6 |   1.1389 |     41.190 |   1.1442 |     41.153 |     0.7
    7 |   1.1232 |     40.623 |   1.1337 |     41.308 |     0.8
    8 |   1.1152 |     40.750 |   1.1275 |     40.997 |     0.9
    9 |   1.1024 |     40.563 |   1.1355 |     41.433 |     1.0
   10 |   1.0958 |     40.161 |   1.1203 |     42.274 |     1.1
   11 |   1.0936 |     40.309 |   1.1052 |     40.343 |     1.2
   12 |   1.0832 |     40.287 |   1.1102 |     42.212 |     1.3
   13 |   1.0815 |     40.111 |   1.1043 |     40.280 |     1.4
   14 |   1.0804 |     40.012 |   1.0983 |     40.436 |     1.5
   15 |   1.0761 |     40.298 |   1.0954 |     40.872 |     1.7
   16 |   1.0720 |     40.205 |   1.0919 |     40.093 |     1.8
   17 |   1.0684 |     40.051 |   1.0951 |     41.931 |     1.9
   18 |   1.0691 |     40.238 |   1.0966 |     41.526 |     2.0
   19 |   1.0676 |     40.001 |   1.0885 |     40.810 |     2.1
   20 |   1.0665 |     40.194 |   1.0833 |     40.280 |     2.2
   21 |   1.0626 |     39.919 |   1.0868 |     40.654 |     2.3
   22 |   1.0614 |     39.957 |   1.0848 |     40.685 |     2.4
   23 |   1.0629 |     40.100 |   1.0925 |     40.467 |     2.5
   24 |   1.0616 |     39.720 |   1.0822 |     40.903 |     2.6
   25 |   1.0584 |     39.621 |   1.0816 |     40.374 |     2.8
   26 |   1.0523 |     39.517 |   1.0776 |     39.875 |     2.9
   27 |   1.0440 |     38.641 |   1.1064 |     41.745 |     3.0
   28 |   1.0325 |     38.393 |   1.1621 |     41.246 |     3.1
   29 |   1.0247 |     37.727 |   1.1139 |     40.966 |     3.2
   30 |   1.0170 |     37.749 |   1.0960 |     41.340 |     3.3
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 128
Encoder layers: 2
Decoder layers: 2
Attention heads: 4
Activation: relu
Dropout: 0.1
Trainable parameters: 648,482

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2198 |     53.838 |   1.5758 |     45.639 |     0.1
    2 |   1.5303 |     45.810 |   1.4260 |     45.296 |     0.2
    3 |   1.4133 |     44.857 |   1.3626 |     45.514 |     0.3
    4 |   1.3522 |     43.586 |   1.3131 |     44.330 |     0.4
    5 |   1.3076 |     43.134 |   1.2863 |     43.988 |     0.5
    6 |   1.2688 |     42.259 |   1.2534 |     43.053 |     0.6
    7 |   1.2364 |     41.438 |   1.2363 |     42.430 |     0.7
    8 |   1.2093 |     40.656 |   1.2167 |     41.682 |     0.8
    9 |   1.1851 |     39.985 |   1.1843 |     40.592 |     0.9
   10 |   1.1684 |     39.792 |   1.1955 |     40.654 |     1.0
   11 |   1.1466 |     39.109 |   1.1986 |     40.654 |     1.1
   12 |   1.1266 |     38.052 |   1.1661 |     39.875 |     1.2
   13 |   1.1141 |     38.195 |   1.1910 |     40.779 |     1.3
   14 |   1.1008 |     37.529 |   1.1481 |     38.567 |     1.4
   15 |   1.0815 |     36.962 |   1.1335 |     38.754 |     1.5
   16 |   1.0657 |     36.174 |   1.1654 |     39.502 |     1.7
   17 |   1.0502 |     35.987 |   1.1360 |     38.162 |     1.8
   18 |   1.0327 |     35.150 |   1.1279 |     38.318 |     1.9
   19 |   1.0206 |     34.627 |   1.1418 |     37.913 |     2.0
   20 |   1.0055 |     34.082 |   1.1120 |     36.698 |     2.1
   21 |   0.9898 |     33.625 |   1.1294 |     37.259 |     2.2
   22 |   0.9758 |     32.838 |   1.1183 |     37.383 |     2.3
   23 |   0.9618 |     32.645 |   1.1189 |     37.134 |     2.4
   24 |   0.9491 |     32.359 |   1.1075 |     36.604 |     2.5
   25 |   0.9352 |     31.671 |   1.1008 |     35.888 |     2.6
   26 |   0.9243 |     31.098 |   1.1089 |     36.168 |     2.7
   27 |   0.9081 |     30.795 |   1.1020 |     36.729 |     2.8
   28 |   0.8967 |     30.355 |   1.1026 |     35.576 |     2.9
   29 |   0.8807 |     29.721 |   1.0939 |     35.327 |     3.0
   30 |   0.8663 |     29.044 |   1.1006 |     35.763 |     3.1
   31 |   0.8569 |     28.697 |   1.1432 |     36.542 |     3.2
   32 |   0.8391 |     28.191 |   1.0944 |     35.826 |     3.3
   33 |   0.8334 |     27.855 |   1.0776 |     35.047 |     3.4
   34 |   0.8220 |     27.613 |   1.1066 |     36.168 |     3.5
   35 |   0.8155 |     27.277 |   1.0897 |     35.140 |     3.6
   36 |   0.7966 |     26.655 |   1.1019 |     35.109 |     3.7
   37 |   0.7863 |     26.473 |   1.1149 |     34.860 |     3.8
Early stopping

Model: Seq2Seq Transformer
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Max sequence length: 800
Embedding dimension: 128
Feedforward dimension: 256
Encoder layers: 2
Decoder layers: 4
Attention heads: 2
Activation: relu
Dropout: 0.1
Trainable parameters: 1,177,634

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.0001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1402 |     55.385 |   1.5050 |     45.857 |     0.1
    2 |   1.4726 |     45.380 |   1.4007 |     46.604 |     0.2
    3 |   1.3813 |     44.466 |   1.3439 |     45.265 |     0.3
    4 |   1.3221 |     43.189 |   1.3015 |     44.548 |     0.4
    5 |   1.2767 |     42.187 |   1.2520 |     43.115 |     0.5
    6 |   1.2390 |     41.499 |   1.2259 |     41.464 |     0.6
    7 |   1.2079 |     40.623 |   1.2441 |     42.866 |     0.7
    8 |   1.1898 |     40.458 |   1.1921 |     41.090 |     0.8
    9 |   1.1620 |     39.390 |   1.1817 |     40.717 |     0.9
   10 |   1.1417 |     38.823 |   1.1965 |     39.782 |     1.0
   11 |   1.1200 |     38.239 |   1.2198 |     40.717 |     1.1
   12 |   1.0998 |     37.254 |   1.2036 |     40.312 |     1.3
   13 |   1.0878 |     37.154 |   1.1697 |     39.502 |     1.4
   14 |   1.0684 |     36.400 |   1.1729 |     39.283 |     1.5
   15 |   1.0548 |     36.053 |   1.1333 |     38.567 |     1.6
   16 |   1.0386 |     35.569 |   1.1248 |     38.598 |     1.7
   17 |   1.0221 |     34.528 |   1.1543 |     39.034 |     1.8
   18 |   1.0117 |     34.704 |   1.1419 |     38.536 |     1.9
   19 |   0.9995 |     34.187 |   1.1390 |     38.816 |     2.0
   20 |   0.9857 |     33.559 |   1.1797 |     39.408 |     2.1
Early stopping

