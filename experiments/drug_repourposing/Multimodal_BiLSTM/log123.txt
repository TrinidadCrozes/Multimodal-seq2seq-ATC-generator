Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 669,954

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2035 |     60.012 |   1.5713 |     45.350 |     0.0
    2 |   1.4590 |     46.197 |   1.3973 |     45.350 |     0.0
    3 |   1.3834 |     46.020 |   1.3523 |     44.757 |     0.1
    4 |   1.3368 |     45.222 |   1.3027 |     44.039 |     0.1
    5 |   1.3021 |     43.918 |   1.2793 |     42.104 |     0.1
    6 |   1.2566 |     42.168 |   1.2365 |     40.730 |     0.1
    7 |   1.2190 |     41.045 |   1.1927 |     39.232 |     0.1
    8 |   1.1790 |     39.988 |   1.1635 |     38.233 |     0.1
    9 |   1.1375 |     38.645 |   1.1592 |     37.266 |     0.2
   10 |   1.1033 |     37.439 |   1.1030 |     36.236 |     0.2
   11 |   1.0620 |     36.295 |   1.0796 |     36.080 |     0.2
   12 |   1.0239 |     34.979 |   1.0510 |     34.894 |     0.2
   13 |   0.9774 |     33.432 |   1.0397 |     34.301 |     0.2
   14 |   0.9396 |     31.798 |   1.0004 |     32.147 |     0.2
   15 |   0.9067 |     30.763 |   0.9957 |     31.804 |     0.3
   16 |   0.8611 |     28.638 |   0.9766 |     31.866 |     0.3
   17 |   0.8266 |     27.438 |   0.9546 |     31.211 |     0.3
   18 |   0.7942 |     26.244 |   0.9409 |     30.306 |     0.3
   19 |   0.7560 |     24.763 |   0.9601 |     30.587 |     0.3
   20 |   0.7277 |     23.800 |   0.9302 |     28.870 |     0.3
   21 |   0.6950 |     22.743 |   0.9154 |     28.090 |     0.4
   22 |   0.6718 |     22.248 |   0.9015 |     28.496 |     0.4
   23 |   0.6389 |     20.982 |   0.9105 |     27.996 |     0.4
   24 |   0.6035 |     19.523 |   0.9119 |     27.278 |     0.4
   25 |   0.5838 |     19.083 |   0.9208 |     27.747 |     0.4
   26 |   0.5639 |     18.329 |   0.9245 |     27.185 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 2,587,170

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5539 |     68.665 |   1.9699 |     58.708 |     0.1
    2 |   1.7770 |     50.270 |   1.5928 |     45.350 |     0.2
    3 |   1.5200 |     46.202 |   1.4610 |     45.350 |     0.2
    4 |   1.4421 |     46.219 |   1.4197 |     45.350 |     0.3
    5 |   1.4181 |     46.125 |   1.4050 |     45.350 |     0.4
    6 |   1.4060 |     46.109 |   1.3960 |     45.818 |     0.5
    7 |   1.3998 |     46.219 |   1.3897 |     45.350 |     0.5
    8 |   1.3949 |     46.120 |   1.3880 |     45.350 |     0.6
    9 |   1.3921 |     46.098 |   1.3842 |     45.350 |     0.7
   10 |   1.3884 |     45.965 |   1.3815 |     45.350 |     0.8
   11 |   1.3838 |     45.960 |   1.3735 |     44.444 |     0.8
   12 |   1.3700 |     45.443 |   1.3578 |     44.164 |     0.9
   13 |   1.3561 |     44.727 |   1.3448 |     43.727 |     1.0
   14 |   1.3470 |     44.650 |   1.3354 |     43.165 |     1.1
   15 |   1.3409 |     44.479 |   1.3318 |     43.321 |     1.2
   16 |   1.3321 |     44.342 |   1.3251 |     43.383 |     1.2
   17 |   1.3291 |     44.243 |   1.3217 |     43.102 |     1.3
   18 |   1.3233 |     44.254 |   1.3198 |     42.946 |     1.4
   19 |   1.3193 |     43.863 |   1.3145 |     42.821 |     1.5
   20 |   1.3109 |     43.791 |   1.3067 |     42.634 |     1.6
   21 |   1.3092 |     44.022 |   1.3086 |     43.134 |     1.6
   22 |   1.3014 |     43.670 |   1.3032 |     42.572 |     1.7
   23 |   1.2981 |     43.643 |   1.3079 |     42.884 |     1.8
   24 |   1.2983 |     43.588 |   1.2977 |     42.572 |     1.9
   25 |   1.2926 |     43.483 |   1.3017 |     42.665 |     2.0
   26 |   1.2871 |     43.478 |   1.2968 |     42.447 |     2.0
   27 |   1.2833 |     43.296 |   1.2912 |     42.353 |     2.1
   28 |   1.2807 |     42.812 |   1.2892 |     42.197 |     2.2
   29 |   1.2713 |     42.773 |   1.2865 |     42.478 |     2.3
   30 |   1.2712 |     42.795 |   1.2882 |     42.447 |     2.3
   31 |   1.2690 |     42.894 |   1.2817 |     42.104 |     2.4
   32 |   1.2772 |     43.103 |   1.2798 |     41.916 |     2.5
   33 |   1.2661 |     42.569 |   1.2804 |     41.885 |     2.6
   34 |   1.2568 |     42.377 |   1.2717 |     41.542 |     2.7
   35 |   1.2763 |     43.070 |   1.2744 |     41.511 |     2.7
   36 |   1.2623 |     42.817 |   1.2716 |     41.667 |     2.8
   37 |   1.2575 |     42.553 |   1.2721 |     41.511 |     2.9
   38 |   1.2585 |     42.613 |   1.2716 |     41.604 |     3.0
   39 |   1.2515 |     42.366 |   1.2658 |     41.635 |     3.1
   40 |   1.2484 |     42.113 |   1.2659 |     41.542 |     3.2
   41 |   1.2414 |     42.206 |   1.2556 |     41.386 |     3.2
   42 |   1.2396 |     42.046 |   1.2576 |     41.074 |     3.3
   43 |   1.2462 |     42.212 |   1.2702 |     41.854 |     3.4
   44 |   1.2365 |     41.920 |   1.2565 |     41.635 |     3.5
   45 |   1.2349 |     42.063 |   1.2543 |     41.292 |     3.6
   46 |   1.2350 |     41.755 |   1.2577 |     41.292 |     3.6
   47 |   1.2327 |     42.008 |   1.2589 |     41.854 |     3.7
   48 |   1.2258 |     41.975 |   1.2513 |     41.011 |     3.8
   49 |   1.2215 |     41.914 |   1.2507 |     41.199 |     3.9
   50 |   1.2183 |     41.469 |   1.2485 |     41.386 |     4.0
   51 |   1.2172 |     41.557 |   1.2360 |     40.574 |     4.0
   52 |   1.2098 |     41.265 |   1.2366 |     40.543 |     4.1
   53 |   1.2053 |     41.078 |   1.2497 |     41.105 |     4.2
   54 |   1.2038 |     41.188 |   1.2380 |     41.323 |     4.3
   55 |   1.2002 |     40.913 |   1.2471 |     41.355 |     4.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 359,586

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5398 |     68.010 |   1.9949 |     57.397 |     0.0
    2 |   1.7729 |     50.550 |   1.5655 |     45.350 |     0.0
    3 |   1.4948 |     46.131 |   1.4355 |     45.318 |     0.1
    4 |   1.4192 |     46.020 |   1.3914 |     45.131 |     0.1
    5 |   1.3792 |     45.354 |   1.3527 |     43.945 |     0.1
    6 |   1.3426 |     44.336 |   1.3205 |     43.071 |     0.1
    7 |   1.3099 |     43.588 |   1.2930 |     41.729 |     0.2
    8 |   1.2828 |     42.905 |   1.2693 |     40.918 |     0.2
    9 |   1.2521 |     41.766 |   1.2396 |     40.012 |     0.2
   10 |   1.2230 |     40.874 |   1.2150 |     39.513 |     0.2
   11 |   1.1960 |     39.812 |   1.1959 |     39.076 |     0.2
   12 |   1.1693 |     39.113 |   1.2002 |     38.702 |     0.3
   13 |   1.1590 |     38.667 |   1.1697 |     38.046 |     0.3
   14 |   1.1270 |     37.704 |   1.1470 |     37.172 |     0.3
   15 |   1.0987 |     36.471 |   1.1179 |     36.298 |     0.3
   16 |   1.0726 |     36.003 |   1.0983 |     35.581 |     0.3
   17 |   1.0490 |     34.803 |   1.0962 |     35.424 |     0.4
   18 |   1.0225 |     33.834 |   1.0807 |     34.738 |     0.4
   19 |   0.9982 |     32.981 |   1.0628 |     34.551 |     0.4
   20 |   0.9777 |     32.106 |   1.0388 |     33.365 |     0.4
   21 |   0.9547 |     31.055 |   1.0276 |     32.772 |     0.5
   22 |   0.9243 |     30.378 |   1.0214 |     32.022 |     0.5
   23 |   0.9067 |     29.739 |   1.0110 |     32.272 |     0.5
   24 |   0.8882 |     28.952 |   0.9932 |     30.899 |     0.5
   25 |   0.8639 |     28.137 |   0.9857 |     31.149 |     0.5
   26 |   0.8477 |     27.477 |   0.9813 |     31.211 |     0.6
   27 |   0.8283 |     26.860 |   0.9610 |     30.462 |     0.6
   28 |   0.8116 |     26.459 |   0.9473 |     29.838 |     0.6
   29 |   0.7841 |     25.209 |   0.9413 |     29.463 |     0.6
   30 |   0.7654 |     24.714 |   0.9380 |     28.714 |     0.7
   31 |   0.7456 |     23.987 |   0.9361 |     28.995 |     0.7
   32 |   0.7268 |     23.547 |   0.9309 |     28.964 |     0.7
   33 |   0.7298 |     23.800 |   0.9190 |     28.340 |     0.7
   34 |   0.7064 |     22.875 |   0.9210 |     28.745 |     0.7
   35 |   0.6815 |     22.061 |   0.9278 |     29.182 |     0.8
   36 |   0.6687 |     21.631 |   0.9212 |     28.152 |     0.8
   37 |   0.6470 |     20.729 |   0.9240 |     28.059 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 383,202

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2488 |     61.030 |   1.5823 |     45.381 |     0.0
    2 |   1.4482 |     45.646 |   1.3586 |     42.978 |     0.0
    3 |   1.3271 |     43.714 |   1.2845 |     41.667 |     0.0
    4 |   1.2535 |     41.380 |   1.2381 |     40.449 |     0.1
    5 |   1.1925 |     39.520 |   1.1883 |     38.983 |     0.1
    6 |   1.1376 |     37.918 |   1.1387 |     37.734 |     0.1
    7 |   1.0772 |     35.953 |   1.1041 |     36.642 |     0.1
    8 |   1.0246 |     33.565 |   1.0554 |     34.270 |     0.1
    9 |   0.9684 |     31.407 |   1.0140 |     32.366 |     0.1
   10 |   0.9115 |     29.822 |   0.9987 |     32.553 |     0.1
   11 |   0.8545 |     27.614 |   0.9632 |     31.242 |     0.1
   12 |   0.7993 |     25.688 |   0.9438 |     29.806 |     0.2
   13 |   0.7510 |     23.905 |   0.9278 |     29.276 |     0.2
   14 |   0.7113 |     22.655 |   0.9080 |     27.528 |     0.2
   15 |   0.6650 |     21.004 |   0.8999 |     28.121 |     0.2
   16 |   0.6265 |     19.854 |   0.8721 |     27.091 |     0.2
   17 |   0.5819 |     18.351 |   0.8714 |     26.748 |     0.2
   18 |   0.5472 |     17.118 |   0.8825 |     27.154 |     0.2
   19 |   0.5125 |     15.896 |   0.8655 |     25.999 |     0.3
   20 |   0.4843 |     15.318 |   0.8570 |     25.624 |     0.3
   21 |   0.4554 |     14.041 |   0.8722 |     26.186 |     0.3
   22 |   0.4258 |     13.221 |   0.8793 |     25.562 |     0.3
   23 |   0.3968 |     12.318 |   0.8884 |     25.468 |     0.3
   24 |   0.3706 |     11.443 |   0.8766 |     24.064 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 217,250

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4676 |     65.626 |   1.8115 |     48.252 |     0.0
    2 |   1.6070 |     47.551 |   1.4538 |     45.225 |     0.0
    3 |   1.4069 |     45.217 |   1.3556 |     43.134 |     0.0
    4 |   1.3236 |     43.169 |   1.2855 |     41.042 |     0.0
    5 |   1.2695 |     41.815 |   1.2471 |     39.919 |     0.1
    6 |   1.2212 |     40.362 |   1.2101 |     39.451 |     0.1
    7 |   1.1816 |     39.487 |   1.1790 |     38.764 |     0.1
    8 |   1.1430 |     38.127 |   1.1546 |     37.360 |     0.1
    9 |   1.1082 |     37.186 |   1.1287 |     36.423 |     0.1
   10 |   1.0692 |     35.480 |   1.0868 |     34.769 |     0.1
   11 |   1.0284 |     33.702 |   1.0675 |     33.958 |     0.1
   12 |   0.9913 |     32.100 |   1.0518 |     33.895 |     0.2
   13 |   0.9584 |     30.967 |   1.0323 |     32.865 |     0.2
   14 |   0.9212 |     29.524 |   1.0122 |     32.491 |     0.2
   15 |   0.8889 |     28.352 |   0.9882 |     31.086 |     0.2
   16 |   0.8550 |     27.185 |   0.9830 |     31.679 |     0.2
   17 |   0.8239 |     25.925 |   0.9718 |     30.774 |     0.2
   18 |   0.7953 |     25.292 |   0.9599 |     30.243 |     0.2
   19 |   0.7627 |     23.982 |   0.9376 |     29.900 |     0.2
   20 |   0.7377 |     23.057 |   0.9498 |     30.368 |     0.3
   21 |   0.7211 |     22.661 |   0.9397 |     29.588 |     0.3
   22 |   0.6869 |     21.494 |   0.9215 |     29.182 |     0.3
   23 |   0.6626 |     20.343 |   0.9137 |     28.402 |     0.3
   24 |   0.6404 |     19.986 |   0.9149 |     28.745 |     0.3
   25 |   0.6268 |     19.463 |   0.9070 |     27.996 |     0.3
   26 |   0.6020 |     18.786 |   0.9192 |     28.808 |     0.3
   27 |   0.5816 |     17.993 |   0.9179 |     28.464 |     0.3
   28 |   0.5699 |     17.366 |   0.9144 |     28.121 |     0.4
   29 |   0.5498 |     17.184 |   0.9014 |     27.278 |     0.4
   30 |   0.5256 |     16.391 |   0.9087 |     27.185 |     0.4
   31 |   0.5130 |     15.736 |   0.9229 |     27.185 |     0.4
   32 |   0.4979 |     15.329 |   0.9159 |     26.623 |     0.4
   33 |   0.4869 |     15.258 |   0.9137 |     27.528 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 439,970

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5677 |     68.312 |   2.0256 |     58.708 |     0.0
    2 |   1.7910 |     50.429 |   1.5960 |     45.350 |     0.0
    3 |   1.5193 |     46.120 |   1.4638 |     45.350 |     0.1
    4 |   1.4441 |     46.213 |   1.4211 |     45.350 |     0.1
    5 |   1.4103 |     46.109 |   1.3960 |     45.350 |     0.1
    6 |   1.3827 |     45.877 |   1.3692 |     44.913 |     0.1
    7 |   1.3574 |     45.057 |   1.3491 |     44.257 |     0.1
    8 |   1.3372 |     44.523 |   1.3209 |     42.322 |     0.2
    9 |   1.3080 |     42.905 |   1.2939 |     41.948 |     0.2
   10 |   1.2799 |     42.591 |   1.2756 |     41.042 |     0.2
   11 |   1.2572 |     41.309 |   1.2621 |     40.012 |     0.2
   12 |   1.2347 |     40.659 |   1.2505 |     39.638 |     0.2
   13 |   1.2133 |     39.927 |   1.2358 |     39.607 |     0.3
   14 |   1.1993 |     39.443 |   1.2175 |     39.576 |     0.3
   15 |   1.1765 |     39.030 |   1.1969 |     38.826 |     0.3
   16 |   1.1574 |     38.628 |   1.1910 |     38.109 |     0.3
   17 |   1.1347 |     37.819 |   1.1868 |     38.140 |     0.3
   18 |   1.1142 |     37.627 |   1.1706 |     37.640 |     0.4
   19 |   1.0892 |     37.071 |   1.1539 |     37.578 |     0.4
   20 |   1.0683 |     36.542 |   1.1537 |     37.016 |     0.4
   21 |   1.0434 |     35.733 |   1.1409 |     37.328 |     0.4
   22 |   1.0183 |     35.051 |   1.1272 |     36.423 |     0.4
   23 |   0.9992 |     34.060 |   1.1136 |     35.705 |     0.5
   24 |   0.9751 |     33.157 |   1.1144 |     35.924 |     0.5
   25 |   0.9582 |     32.469 |   1.0938 |     35.081 |     0.5
   26 |   0.9264 |     31.159 |   1.0778 |     33.895 |     0.5
   27 |   0.8919 |     29.750 |   1.0684 |     33.677 |     0.5
   28 |   0.8686 |     28.847 |   1.0671 |     33.427 |     0.6
   29 |   0.8494 |     27.857 |   1.0731 |     33.614 |     0.6
   30 |   0.8295 |     27.405 |   1.0758 |     34.051 |     0.6
   31 |   0.8092 |     26.558 |   1.0568 |     33.052 |     0.6
   32 |   0.7884 |     25.919 |   1.0432 |     32.241 |     0.6
   33 |   0.7638 |     24.752 |   1.0407 |     32.303 |     0.7
   34 |   0.7569 |     24.934 |   1.0542 |     32.241 |     0.7
   35 |   0.7266 |     23.729 |   1.0422 |     31.866 |     0.7
   36 |   0.7132 |     23.118 |   1.0411 |     31.898 |     0.7
   37 |   0.6932 |     22.402 |   1.0470 |     31.429 |     0.7
   38 |   0.6749 |     21.598 |   1.0366 |     31.180 |     0.8
   39 |   0.6546 |     21.263 |   1.0414 |     31.960 |     0.8
   40 |   0.6369 |     20.200 |   1.0328 |     31.086 |     0.8
   41 |   0.6098 |     19.314 |   1.0576 |     32.179 |     0.8
   42 |   0.6121 |     19.562 |   1.0555 |     31.804 |     0.8
   43 |   0.5976 |     19.017 |   1.0498 |     30.805 |     0.9
   44 |   0.5737 |     18.395 |   1.0368 |     30.368 |     0.9
   45 |   0.5538 |     17.498 |   1.0309 |     29.338 |     0.9
   46 |   0.5502 |     17.179 |   1.0651 |     31.586 |     0.9
   47 |   0.5157 |     15.990 |   1.0668 |     30.400 |     0.9
   48 |   0.5102 |     15.841 |   1.0574 |     30.493 |     1.0
   49 |   0.4926 |     15.401 |   1.0974 |     31.242 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 691,138

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3059 |     62.891 |   1.6903 |     48.689 |     0.0
    2 |   1.5118 |     46.736 |   1.4118 |     45.350 |     0.0
    3 |   1.3916 |     45.465 |   1.3548 |     44.039 |     0.1
    4 |   1.3364 |     44.055 |   1.2998 |     42.478 |     0.1
    5 |   1.2879 |     43.417 |   1.2594 |     41.792 |     0.1
    6 |   1.2433 |     42.013 |   1.2218 |     40.574 |     0.1
    7 |   1.2146 |     40.747 |   1.2000 |     38.983 |     0.2
    8 |   1.1781 |     39.515 |   1.1834 |     38.889 |     0.2
    9 |   1.1482 |     38.573 |   1.1569 |     37.609 |     0.2
   10 |   1.1171 |     37.847 |   1.1553 |     37.328 |     0.2
   11 |   1.0912 |     36.509 |   1.1238 |     36.142 |     0.2
   12 |   1.0580 |     35.414 |   1.1029 |     36.080 |     0.3
   13 |   1.0327 |     34.506 |   1.0832 |     35.112 |     0.3
   14 |   1.0011 |     33.614 |   1.0667 |     34.769 |     0.3
   15 |   0.9656 |     32.365 |   1.0610 |     34.238 |     0.3
   16 |   0.9349 |     31.066 |   1.0406 |     33.302 |     0.3
   17 |   0.9117 |     30.515 |   1.0397 |     33.208 |     0.4
   18 |   0.8729 |     29.062 |   1.0289 |     33.177 |     0.4
   19 |   0.8396 |     27.614 |   1.0226 |     31.617 |     0.4
   20 |   0.8156 |     26.982 |   0.9984 |     31.960 |     0.4
   21 |   0.7877 |     25.859 |   1.0136 |     31.492 |     0.4
   22 |   0.7649 |     25.132 |   1.0156 |     31.866 |     0.5
   23 |   0.7512 |     24.246 |   0.9783 |     30.587 |     0.5
   24 |   0.7017 |     22.820 |   0.9844 |     30.275 |     0.5
   25 |   0.6832 |     22.352 |   0.9829 |     29.276 |     0.5
   26 |   0.6552 |     21.301 |   0.9775 |     30.337 |     0.6
   27 |   0.6354 |     20.806 |   0.9610 |     28.340 |     0.6
   28 |   0.6164 |     20.217 |   0.9927 |     29.744 |     0.6
   29 |   0.5925 |     19.022 |   0.9743 |     28.808 |     0.6
   30 |   0.5661 |     18.081 |   0.9814 |     29.588 |     0.6
   31 |   0.5505 |     17.960 |   0.9827 |     28.027 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 933,346

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3061 |     63.414 |   1.7069 |     48.283 |     0.0
    2 |   1.5310 |     46.631 |   1.4325 |     45.350 |     0.0
    3 |   1.4166 |     46.175 |   1.3982 |     44.819 |     0.0
    4 |   1.3864 |     45.993 |   1.3560 |     44.351 |     0.1
    5 |   1.3481 |     44.446 |   1.3250 |     42.821 |     0.1
    6 |   1.3065 |     43.456 |   1.2882 |     42.228 |     0.1
    7 |   1.2718 |     42.509 |   1.2587 |     40.824 |     0.1
    8 |   1.2370 |     41.738 |   1.2312 |     40.512 |     0.1
    9 |   1.2005 |     40.472 |   1.1993 |     39.170 |     0.1
   10 |   1.1659 |     39.487 |   1.2035 |     39.576 |     0.2
   11 |   1.1406 |     38.661 |   1.1621 |     38.421 |     0.2
   12 |   1.1089 |     37.913 |   1.1705 |     39.170 |     0.2
   13 |   1.0850 |     36.939 |   1.1203 |     36.673 |     0.2
   14 |   1.0396 |     35.744 |   1.1040 |     36.829 |     0.2
   15 |   1.0190 |     34.775 |   1.1140 |     36.454 |     0.2
   16 |   0.9880 |     33.697 |   1.0953 |     36.236 |     0.3
   17 |   0.9547 |     32.244 |   1.0844 |     34.925 |     0.3
   18 |   0.9280 |     31.126 |   1.0729 |     34.395 |     0.3
   19 |   0.9005 |     29.734 |   1.0763 |     34.176 |     0.3
   20 |   0.8720 |     28.869 |   1.0712 |     34.707 |     0.3
   21 |   0.8308 |     27.202 |   1.0660 |     33.677 |     0.3
   22 |   0.7927 |     25.892 |   1.0576 |     33.552 |     0.4
   23 |   0.7718 |     25.154 |   1.0539 |     32.740 |     0.4
   24 |   0.7404 |     24.108 |   1.0584 |     33.552 |     0.4
   25 |   0.7057 |     22.628 |   1.0501 |     32.772 |     0.4
   26 |   0.6740 |     21.736 |   1.0594 |     32.179 |     0.4
   27 |   0.6483 |     20.619 |   1.0264 |     32.272 |     0.4
   28 |   0.6224 |     19.446 |   1.0408 |     30.868 |     0.5
   29 |   0.5939 |     18.665 |   1.0301 |     30.556 |     0.5
   30 |   0.5616 |     17.663 |   1.0509 |     30.462 |     0.5
   31 |   0.5394 |     17.035 |   1.0554 |     30.243 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,140,866

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3379 |     63.683 |   1.6980 |     48.283 |     0.0
    2 |   1.5165 |     46.631 |   1.4263 |     45.350 |     0.0
    3 |   1.4101 |     46.175 |   1.3867 |     45.381 |     0.1
    4 |   1.3758 |     45.520 |   1.3475 |     44.788 |     0.1
    5 |   1.3308 |     44.518 |   1.3021 |     43.664 |     0.1
    6 |   1.2829 |     43.329 |   1.2612 |     42.946 |     0.1
    7 |   1.2461 |     42.624 |   1.2306 |     41.105 |     0.2
    8 |   1.2156 |     41.270 |   1.2201 |     39.981 |     0.2
    9 |   1.1852 |     40.401 |   1.1978 |     39.201 |     0.2
   10 |   1.1671 |     39.382 |   1.1874 |     39.732 |     0.2
   11 |   1.1380 |     38.849 |   1.1641 |     38.639 |     0.3
   12 |   1.1121 |     37.698 |   1.1435 |     37.640 |     0.3
   13 |   1.0947 |     37.208 |   1.1438 |     37.328 |     0.3
   14 |   1.0661 |     36.080 |   1.1211 |     36.767 |     0.3
   15 |   1.0371 |     35.337 |   1.1066 |     35.986 |     0.4
   16 |   1.0209 |     34.577 |   1.0871 |     35.393 |     0.4
   17 |   0.9923 |     33.774 |   1.0955 |     35.050 |     0.4
   18 |   0.9723 |     33.014 |   1.0623 |     34.644 |     0.4
   19 |   0.9585 |     32.409 |   1.0679 |     34.176 |     0.5
   20 |   0.9284 |     31.104 |   1.0603 |     35.112 |     0.5
   21 |   0.8985 |     30.047 |   1.0679 |     34.363 |     0.5
   22 |   0.8867 |     29.646 |   1.0333 |     33.396 |     0.5
   23 |   0.8520 |     28.490 |   1.0348 |     32.834 |     0.6
   24 |   0.8344 |     27.681 |   1.0343 |     32.522 |     0.6
   25 |   0.8118 |     26.789 |   1.0251 |     32.522 |     0.6
   26 |   0.7875 |     26.211 |   1.0122 |     31.461 |     0.6
   27 |   0.7670 |     25.424 |   1.0175 |     32.459 |     0.7
   28 |   0.7453 |     24.334 |   1.0095 |     31.273 |     0.7
   29 |   0.7186 |     23.673 |   1.0064 |     30.243 |     0.7
   30 |   0.7196 |     23.635 |   1.0224 |     31.211 |     0.7
   31 |   0.6896 |     22.507 |   1.0077 |     30.805 |     0.8
   32 |   0.6696 |     21.764 |   1.0077 |     29.963 |     0.8
   33 |   0.6525 |     21.285 |   1.0041 |     29.963 |     0.8
   34 |   0.6366 |     20.597 |   1.0164 |     29.619 |     0.8
   35 |   0.6165 |     20.041 |   1.0234 |     29.619 |     0.9
   36 |   0.5999 |     19.606 |   1.0342 |     29.838 |     0.9
   37 |   0.5792 |     18.720 |   1.0157 |     28.995 |     0.9
   38 |   0.5865 |     18.835 |   1.0037 |     28.777 |     0.9
   39 |   0.5657 |     18.670 |   1.0281 |     29.557 |     1.0
   40 |   0.5413 |     17.470 |   1.0216 |     28.777 |     1.0
   41 |   0.5290 |     17.013 |   1.0230 |     28.558 |     1.0
   42 |   0.5110 |     16.342 |   1.0364 |     28.589 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 552,034

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2312 |     60.728 |   1.6152 |     45.412 |     0.0
    2 |   1.4769 |     46.164 |   1.4093 |     45.194 |     0.0
    3 |   1.3889 |     45.729 |   1.3431 |     42.790 |     0.0
    4 |   1.3189 |     43.533 |   1.2839 |     42.291 |     0.1
    5 |   1.2632 |     41.909 |   1.2382 |     40.730 |     0.1
    6 |   1.2225 |     40.880 |   1.2066 |     38.826 |     0.1
    7 |   1.1848 |     39.652 |   1.1681 |     37.859 |     0.1
    8 |   1.1357 |     38.359 |   1.1458 |     37.859 |     0.1
    9 |   1.0853 |     36.950 |   1.1160 |     37.235 |     0.1
   10 |   1.0372 |     35.194 |   1.0923 |     36.017 |     0.1
   11 |   0.9847 |     33.355 |   1.0641 |     34.738 |     0.1
   12 |   0.9395 |     31.611 |   1.0463 |     33.302 |     0.2
   13 |   0.8838 |     29.502 |   1.0193 |     32.210 |     0.2
   14 |   0.8294 |     27.670 |   1.0062 |     32.054 |     0.2
   15 |   0.7799 |     25.578 |   0.9944 |     29.744 |     0.2
   16 |   0.7277 |     23.701 |   1.0000 |     30.368 |     0.2
   17 |   0.6806 |     21.890 |   0.9887 |     29.151 |     0.2
   18 |   0.6463 |     20.591 |   0.9806 |     29.775 |     0.2
   19 |   0.5966 |     18.885 |   0.9842 |     30.025 |     0.2
   20 |   0.5639 |     17.768 |   0.9791 |     29.619 |     0.3
   21 |   0.5063 |     15.709 |   0.9793 |     27.684 |     0.3
   22 |   0.4672 |     14.476 |   1.0020 |     27.747 |     0.3
   23 |   0.4427 |     13.513 |   0.9950 |     27.747 |     0.3
   24 |   0.4128 |     12.467 |   1.0084 |     26.904 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 748,834

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2677 |     61.317 |   1.6465 |     48.283 |     0.0
    2 |   1.4896 |     46.274 |   1.4131 |     45.350 |     0.0
    3 |   1.3988 |     45.745 |   1.3711 |     45.069 |     0.1
    4 |   1.3569 |     44.804 |   1.3399 |     44.007 |     0.1
    5 |   1.3244 |     44.177 |   1.3080 |     42.665 |     0.1
    6 |   1.2876 |     43.032 |   1.2785 |     41.885 |     0.1
    7 |   1.2535 |     41.903 |   1.2484 |     40.075 |     0.1
    8 |   1.2193 |     40.962 |   1.2064 |     39.513 |     0.1
    9 |   1.1794 |     39.674 |   1.1839 |     39.669 |     0.2
   10 |   1.1465 |     38.810 |   1.1647 |     38.390 |     0.2
   11 |   1.1112 |     37.467 |   1.1335 |     37.266 |     0.2
   12 |   1.0747 |     36.168 |   1.1045 |     35.674 |     0.2
   13 |   1.0357 |     34.682 |   1.0899 |     35.705 |     0.2
   14 |   0.9990 |     33.515 |   1.0882 |     34.988 |     0.2
   15 |   0.9711 |     32.403 |   1.0645 |     34.363 |     0.3
   16 |   0.9288 |     30.867 |   1.0334 |     33.864 |     0.3
   17 |   0.8867 |     29.673 |   1.0187 |     33.365 |     0.3
   18 |   0.8574 |     28.583 |   1.0027 |     33.302 |     0.3
   19 |   0.8191 |     27.389 |   1.0087 |     32.054 |     0.3
   20 |   0.7831 |     26.029 |   0.9931 |     31.617 |     0.3
   21 |   0.7407 |     24.510 |   0.9921 |     31.367 |     0.4
   22 |   0.7194 |     23.833 |   0.9772 |     30.275 |     0.4
   23 |   0.6957 |     22.804 |   0.9779 |     30.712 |     0.4
   24 |   0.6649 |     22.006 |   0.9838 |     30.899 |     0.4
   25 |   0.6244 |     20.432 |   0.9755 |     29.588 |     0.4
   26 |   0.5940 |     19.347 |   0.9870 |     30.056 |     0.4
   27 |   0.5766 |     18.802 |   0.9772 |     29.557 |     0.5
   28 |   0.5544 |     17.999 |   0.9982 |     29.276 |     0.5
   29 |   0.5299 |     17.179 |   0.9777 |     28.496 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 637,762

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3435 |     63.535 |   1.6835 |     48.283 |     0.0
    2 |   1.5092 |     46.802 |   1.4192 |     45.350 |     0.0
    3 |   1.4114 |     46.169 |   1.3960 |     45.162 |     0.0
    4 |   1.3863 |     46.252 |   1.3719 |     45.131 |     0.1
    5 |   1.3528 |     44.964 |   1.3207 |     43.602 |     0.1
    6 |   1.3100 |     44.055 |   1.2827 |     42.260 |     0.1
    7 |   1.2735 |     43.489 |   1.2566 |     41.823 |     0.1
    8 |   1.2482 |     43.136 |   1.2245 |     41.417 |     0.1
    9 |   1.2220 |     42.316 |   1.2157 |     40.605 |     0.1
   10 |   1.2001 |     41.557 |   1.2020 |     41.042 |     0.1
   11 |   1.1816 |     40.720 |   1.1854 |     40.543 |     0.1
   12 |   1.1623 |     40.048 |   1.1622 |     39.576 |     0.2
   13 |   1.1369 |     39.344 |   1.1589 |     38.670 |     0.2
   14 |   1.1084 |     38.414 |   1.1324 |     37.921 |     0.2
   15 |   1.0882 |     37.528 |   1.1266 |     37.953 |     0.2
   16 |   1.0670 |     36.873 |   1.1118 |     36.610 |     0.2
   17 |   1.0408 |     35.722 |   1.1185 |     36.486 |     0.2
   18 |   1.0273 |     35.375 |   1.0884 |     35.674 |     0.2
   19 |   1.0078 |     34.517 |   1.0865 |     34.956 |     0.3
   20 |   0.9810 |     33.438 |   1.0687 |     34.426 |     0.3
   21 |   0.9567 |     32.585 |   1.0526 |     34.270 |     0.3
   22 |   0.9414 |     31.622 |   1.0605 |     34.332 |     0.3
   23 |   0.9160 |     31.104 |   1.0393 |     33.833 |     0.3
   24 |   0.8957 |     30.383 |   1.0108 |     32.397 |     0.3
   25 |   0.8735 |     29.464 |   1.0395 |     32.990 |     0.3
   26 |   0.8568 |     28.969 |   1.0205 |     33.115 |     0.3
   27 |   0.8266 |     27.664 |   1.0144 |     32.428 |     0.4
   28 |   0.8047 |     26.624 |   1.0066 |     31.305 |     0.4
   29 |   0.7936 |     26.134 |   0.9803 |     30.493 |     0.4
   30 |   0.7700 |     25.622 |   0.9916 |     31.149 |     0.4
   31 |   0.7481 |     24.884 |   0.9918 |     30.119 |     0.4
   32 |   0.7300 |     23.927 |   0.9759 |     29.900 |     0.4
   33 |   0.7049 |     23.167 |   0.9786 |     29.120 |     0.4
   34 |   0.6887 |     22.474 |   0.9939 |     29.713 |     0.5
   35 |   0.6668 |     21.813 |   0.9657 |     28.964 |     0.5
   36 |   0.6461 |     21.037 |   0.9814 |     28.995 |     0.5
   37 |   0.6315 |     20.833 |   0.9814 |     28.839 |     0.5
   38 |   0.6204 |     20.371 |   0.9491 |     27.809 |     0.5
   39 |   0.6030 |     19.661 |   0.9553 |     28.059 |     0.5
   40 |   0.5844 |     18.901 |   0.9759 |     27.778 |     0.5
   41 |   0.5668 |     18.312 |   0.9847 |     28.308 |     0.5
   42 |   0.5594 |     18.351 |   0.9857 |     27.372 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 527,330

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6080 |     70.178 |   1.9765 |     58.708 |     0.0
    2 |   1.7550 |     50.407 |   1.5657 |     45.350 |     0.0
    3 |   1.4998 |     46.208 |   1.4479 |     45.350 |     0.1
    4 |   1.4349 |     46.186 |   1.4138 |     45.350 |     0.1
    5 |   1.4131 |     46.186 |   1.4032 |     45.350 |     0.1
    6 |   1.4036 |     46.125 |   1.3942 |     45.662 |     0.1
    7 |   1.3970 |     46.158 |   1.3879 |     45.350 |     0.1
    8 |   1.3903 |     46.136 |   1.3833 |     45.350 |     0.1
    9 |   1.3848 |     46.202 |   1.3772 |     45.350 |     0.2
   10 |   1.3769 |     46.180 |   1.3663 |     45.350 |     0.2
   11 |   1.3669 |     45.993 |   1.3536 |     43.883 |     0.2
   12 |   1.3502 |     45.052 |   1.3431 |     44.476 |     0.2
   13 |   1.3327 |     44.595 |   1.3239 |     44.039 |     0.2
   14 |   1.3186 |     44.270 |   1.3183 |     43.009 |     0.3
   15 |   1.3099 |     43.929 |   1.3082 |     42.978 |     0.3
   16 |   1.2984 |     43.643 |   1.2953 |     42.790 |     0.3
   17 |   1.2883 |     43.208 |   1.2918 |     42.541 |     0.3
   18 |   1.2792 |     42.889 |   1.2836 |     41.760 |     0.3
   19 |   1.2671 |     42.564 |   1.2680 |     40.730 |     0.4
   20 |   1.2531 |     42.019 |   1.2659 |     41.292 |     0.4
   21 |   1.2457 |     41.711 |   1.2537 |     40.481 |     0.4
   22 |   1.2288 |     41.182 |   1.2331 |     40.075 |     0.4
   23 |   1.2188 |     40.979 |   1.2310 |     40.387 |     0.4
   24 |   1.2035 |     40.582 |   1.2159 |     40.012 |     0.5
   25 |   1.1895 |     40.170 |   1.2010 |     39.357 |     0.5
   26 |   1.1758 |     40.065 |   1.1867 |     39.419 |     0.5
   27 |   1.1654 |     39.482 |   1.1850 |     38.546 |     0.5
   28 |   1.1489 |     39.091 |   1.1782 |     38.920 |     0.5
   29 |   1.1482 |     39.124 |   1.1816 |     38.764 |     0.5
   30 |   1.1298 |     38.804 |   1.1603 |     38.452 |     0.6
   31 |   1.1184 |     38.144 |   1.1576 |     38.421 |     0.6
   32 |   1.1140 |     37.951 |   1.1490 |     38.390 |     0.6
   33 |   1.1009 |     37.907 |   1.1458 |     37.547 |     0.6
   34 |   1.0908 |     37.021 |   1.1417 |     37.890 |     0.6
   35 |   1.0764 |     36.707 |   1.1278 |     37.516 |     0.7
   36 |   1.0675 |     36.162 |   1.1406 |     37.640 |     0.7
   37 |   1.0711 |     36.333 |   1.1261 |     37.297 |     0.7
   38 |   1.0547 |     35.491 |   1.1093 |     36.767 |     0.7
   39 |   1.0407 |     35.342 |   1.1103 |     35.955 |     0.7
   40 |   1.0349 |     35.320 |   1.1126 |     36.673 |     0.8
   41 |   1.0227 |     34.786 |   1.1138 |     36.579 |     0.8
   42 |   1.0131 |     34.544 |   1.1053 |     36.392 |     0.8
   43 |   1.0063 |     34.264 |   1.1004 |     36.548 |     0.8
   44 |   0.9934 |     33.944 |   1.0875 |     35.643 |     0.8
   45 |   0.9773 |     33.438 |   1.0918 |     36.174 |     0.9
   46 |   0.9774 |     33.300 |   1.0861 |     35.674 |     0.9
   47 |   0.9627 |     32.981 |   1.0961 |     35.518 |     0.9
   48 |   0.9581 |     32.497 |   1.0855 |     35.549 |     0.9
   49 |   0.9463 |     32.045 |   1.0777 |     35.737 |     0.9
   50 |   0.9374 |     32.062 |   1.0714 |     35.237 |     0.9
   51 |   0.9327 |     31.853 |   1.0680 |     34.863 |     1.0
   52 |   0.9249 |     31.071 |   1.0566 |     34.488 |     1.0
   53 |   0.9088 |     30.735 |   1.0658 |     34.613 |     1.0
   54 |   0.8943 |     30.174 |   1.0614 |     34.020 |     1.0
   55 |   0.8943 |     30.025 |   1.0545 |     33.864 |     1.0
   56 |   0.8831 |     29.695 |   1.0461 |     32.959 |     1.1
   57 |   0.8758 |     29.535 |   1.0532 |     33.833 |     1.1
   58 |   0.8711 |     29.227 |   1.0608 |     33.614 |     1.1
   59 |   0.8644 |     28.996 |   1.0461 |     34.051 |     1.1
   60 |   0.8622 |     28.814 |   1.0505 |     33.614 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,046,402

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5014 |     67.338 |   1.9898 |     54.775 |     0.0
    2 |   1.8120 |     51.519 |   1.6195 |     45.350 |     0.1
    3 |   1.5379 |     46.125 |   1.4650 |     45.162 |     0.1
    4 |   1.4439 |     45.839 |   1.4077 |     44.351 |     0.1
    5 |   1.3943 |     44.534 |   1.3635 |     43.040 |     0.2
    6 |   1.3550 |     43.901 |   1.3330 |     42.322 |     0.2
    7 |   1.3233 |     43.164 |   1.3150 |     41.854 |     0.3
    8 |   1.3034 |     42.768 |   1.2996 |     41.511 |     0.3
    9 |   1.2826 |     42.162 |   1.2899 |     41.136 |     0.3
   10 |   1.2653 |     41.672 |   1.2709 |     40.918 |     0.4
   11 |   1.2453 |     40.962 |   1.2564 |     40.418 |     0.4
   12 |   1.2269 |     40.577 |   1.2445 |     40.574 |     0.4
   13 |   1.2047 |     40.015 |   1.2240 |     39.607 |     0.5
   14 |   1.1850 |     39.553 |   1.2069 |     39.076 |     0.5
   15 |   1.1562 |     38.386 |   1.1826 |     37.890 |     0.6
   16 |   1.1301 |     37.109 |   1.1768 |     37.672 |     0.6
   17 |   1.1106 |     36.801 |   1.1572 |     36.954 |     0.6
   18 |   1.0940 |     35.959 |   1.1504 |     36.860 |     0.7
   19 |   1.0731 |     35.194 |   1.1192 |     35.830 |     0.7
   20 |   1.0444 |     34.352 |   1.1103 |     34.988 |     0.7
   21 |   1.0288 |     33.757 |   1.1045 |     35.612 |     0.8
   22 |   1.0057 |     32.634 |   1.0966 |     35.393 |     0.8
   23 |   0.9912 |     32.431 |   1.0799 |     34.644 |     0.9
   24 |   0.9975 |     32.618 |   1.0932 |     34.863 |     0.9
   25 |   0.9869 |     32.249 |   1.0820 |     34.457 |     0.9
   26 |   0.9585 |     31.297 |   1.0610 |     33.645 |     1.0
   27 |   0.9330 |     30.658 |   1.0516 |     32.865 |     1.0
   28 |   0.9118 |     29.921 |   1.0478 |     32.928 |     1.0
   29 |   0.9070 |     29.734 |   1.0450 |     32.959 |     1.1
   30 |   0.8888 |     28.908 |   1.0353 |     32.022 |     1.1
   31 |   0.8716 |     28.385 |   1.0404 |     32.678 |     1.2
   32 |   0.8600 |     28.049 |   1.0316 |     31.898 |     1.2
   33 |   0.8398 |     26.893 |   1.0287 |     32.865 |     1.2
   34 |   0.8339 |     27.224 |   1.0352 |     32.428 |     1.3
   35 |   0.8173 |     26.437 |   1.0159 |     31.835 |     1.3
   36 |   0.8016 |     26.404 |   1.0143 |     31.773 |     1.3
   37 |   0.7951 |     25.870 |   1.0164 |     31.648 |     1.4
   38 |   0.7742 |     25.154 |   1.0223 |     31.523 |     1.4
   39 |   0.7688 |     25.083 |   1.0105 |     31.492 |     1.5
   40 |   0.7690 |     25.275 |   1.0089 |     31.305 |     1.5
   41 |   0.7553 |     24.450 |   1.0199 |     31.273 |     1.5
   42 |   0.7472 |     24.615 |   1.0087 |     30.181 |     1.6
   43 |   0.7239 |     23.437 |   1.0059 |     31.242 |     1.6
   44 |   0.7156 |     23.569 |   1.0189 |     31.086 |     1.6
   45 |   0.7108 |     23.294 |   1.0211 |     30.899 |     1.7
   46 |   0.7036 |     23.002 |   0.9977 |     30.275 |     1.7
   47 |   0.6867 |     22.319 |   0.9977 |     30.618 |     1.8
   48 |   0.6828 |     22.562 |   0.9931 |     30.025 |     1.8
   49 |   0.6833 |     22.556 |   1.0064 |     31.055 |     1.8
   50 |   0.6846 |     22.419 |   0.9999 |     29.151 |     1.9
   51 |   0.6620 |     21.637 |   0.9985 |     29.900 |     1.9
   52 |   0.6466 |     21.477 |   1.0064 |     30.462 |     1.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 593,986

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0676 |     56.682 |   1.4894 |     45.162 |     0.0
    2 |   1.3921 |     44.677 |   1.3134 |     42.072 |     0.0
    3 |   1.2687 |     41.546 |   1.2262 |     40.044 |     0.1
    4 |   1.1773 |     38.771 |   1.1405 |     37.516 |     0.1
    5 |   1.1011 |     36.372 |   1.0920 |     35.705 |     0.1
    6 |   1.0227 |     33.509 |   1.0429 |     32.990 |     0.1
    7 |   0.9642 |     31.275 |   0.9993 |     32.116 |     0.1
    8 |   0.8997 |     28.704 |   0.9710 |     30.899 |     0.2
    9 |   0.8351 |     26.503 |   0.9304 |     30.056 |     0.2
   10 |   0.7779 |     24.769 |   0.9168 |     28.901 |     0.2
   11 |   0.7325 |     22.947 |   0.8947 |     27.903 |     0.2
   12 |   0.6792 |     21.560 |   0.8715 |     27.996 |     0.3
   13 |   0.6346 |     20.112 |   0.8631 |     26.529 |     0.3
   14 |   0.5943 |     18.824 |   0.8514 |     25.999 |     0.3
   15 |   0.5534 |     17.201 |   0.8613 |     26.561 |     0.3
   16 |   0.5290 |     16.342 |   0.8496 |     25.749 |     0.3
   17 |   0.4990 |     15.560 |   0.8550 |     25.999 |     0.4
   18 |   0.4687 |     14.509 |   0.8635 |     25.905 |     0.4
   19 |   0.4334 |     13.469 |   0.8619 |     25.843 |     0.4
   20 |   0.4004 |     12.351 |   0.8451 |     25.000 |     0.4
   21 |   0.3830 |     11.867 |   0.8448 |     24.750 |     0.4
   22 |   0.3694 |     11.504 |   0.8710 |     24.938 |     0.5
   23 |   0.3496 |     10.557 |   0.8649 |     25.406 |     0.5
   24 |   0.3340 |     10.607 |   0.8895 |     25.125 |     0.5
   25 |   0.3109 |      9.555 |   0.8779 |     24.719 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,711,170

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5230 |     67.195 |   2.0515 |     58.115 |     0.1
    2 |   1.8485 |     52.070 |   1.6240 |     45.537 |     0.1
    3 |   1.5423 |     46.147 |   1.4749 |     45.350 |     0.2
    4 |   1.4517 |     46.081 |   1.4185 |     45.350 |     0.2
    5 |   1.4129 |     45.839 |   1.3892 |     44.788 |     0.3
    6 |   1.3761 |     44.677 |   1.3495 |     42.915 |     0.3
    7 |   1.3440 |     43.962 |   1.3235 |     42.946 |     0.4
    8 |   1.3167 |     43.235 |   1.3113 |     42.228 |     0.5
    9 |   1.2933 |     42.525 |   1.2966 |     42.135 |     0.5
   10 |   1.2789 |     42.360 |   1.2817 |     41.323 |     0.6
   11 |   1.2538 |     41.639 |   1.2715 |     40.855 |     0.6
   12 |   1.2381 |     41.408 |   1.2438 |     40.481 |     0.7
   13 |   1.2133 |     40.599 |   1.2213 |     40.200 |     0.7
   14 |   1.1841 |     39.960 |   1.2001 |     39.014 |     0.8
   15 |   1.1645 |     39.157 |   1.1837 |     38.795 |     0.8
   16 |   1.1402 |     38.265 |   1.1625 |     38.452 |     0.9
   17 |   1.1241 |     37.638 |   1.1494 |     37.640 |     1.0
   18 |   1.1087 |     36.828 |   1.1444 |     37.484 |     1.0
   19 |   1.0878 |     36.229 |   1.1382 |     37.890 |     1.1
   20 |   1.0720 |     35.546 |   1.1307 |     36.548 |     1.1
   21 |   1.0553 |     34.869 |   1.1312 |     37.297 |     1.2
   22 |   1.0419 |     34.473 |   1.1101 |     35.362 |     1.2
   23 |   1.0251 |     33.878 |   1.1004 |     35.986 |     1.3
   24 |   1.0073 |     33.432 |   1.0803 |     35.237 |     1.4
   25 |   0.9927 |     32.728 |   1.0909 |     35.050 |     1.4
   26 |   0.9846 |     32.255 |   1.0820 |     35.487 |     1.5
   27 |   0.9742 |     32.045 |   1.0622 |     34.956 |     1.5
   28 |   0.9571 |     31.319 |   1.0578 |     33.864 |     1.6
   29 |   0.9537 |     31.319 |   1.0571 |     34.519 |     1.6
   30 |   0.9328 |     30.609 |   1.0368 |     33.427 |     1.7
   31 |   0.9090 |     29.613 |   1.0346 |     32.803 |     1.8
   32 |   0.8953 |     29.139 |   1.0306 |     32.928 |     1.8
   33 |   0.8889 |     29.436 |   1.0231 |     32.522 |     1.9
   34 |   0.8755 |     28.622 |   1.0242 |     32.896 |     1.9
   35 |   0.8726 |     28.506 |   1.0219 |     32.740 |     2.0
   36 |   0.8594 |     28.286 |   1.0151 |     32.584 |     2.1
   37 |   0.8481 |     27.780 |   0.9959 |     32.522 |     2.1
   38 |   0.8400 |     27.493 |   1.0189 |     32.834 |     2.2
   39 |   0.8352 |     27.796 |   1.0006 |     31.866 |     2.2
   40 |   0.8254 |     27.130 |   0.9894 |     31.710 |     2.3
   41 |   0.8094 |     26.860 |   0.9826 |     30.930 |     2.3
   42 |   0.7971 |     26.123 |   0.9925 |     31.429 |     2.4
   43 |   0.7793 |     25.644 |   0.9894 |     31.835 |     2.5
   44 |   0.7702 |     25.193 |   0.9831 |     31.586 |     2.5
   45 |   0.7605 |     24.796 |   0.9637 |     30.836 |     2.6
   46 |   0.7469 |     24.488 |   0.9722 |     31.180 |     2.6
   47 |   0.7459 |     24.549 |   0.9694 |     30.774 |     2.7
   48 |   0.7361 |     24.185 |   0.9688 |     30.462 |     2.7
   49 |   0.7290 |     23.899 |   0.9578 |     30.275 |     2.8
   50 |   0.7293 |     24.273 |   0.9716 |     31.055 |     2.9
   51 |   0.7150 |     23.387 |   0.9642 |     30.805 |     2.9
   52 |   0.7110 |     23.145 |   0.9770 |     30.899 |     3.0
   53 |   0.7060 |     23.475 |   0.9759 |     30.368 |     3.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 673,666

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2793 |     62.929 |   1.6474 |     45.443 |     0.0
    2 |   1.4956 |     46.142 |   1.4178 |     45.350 |     0.0
    3 |   1.3996 |     45.580 |   1.3687 |     44.164 |     0.1
    4 |   1.3573 |     44.732 |   1.3386 |     43.508 |     0.1
    5 |   1.3265 |     44.171 |   1.3079 |     42.541 |     0.1
    6 |   1.3005 |     43.147 |   1.2897 |     42.072 |     0.1
    7 |   1.2747 |     42.421 |   1.2669 |     41.479 |     0.2
    8 |   1.2396 |     41.546 |   1.2432 |     40.980 |     0.2
    9 |   1.1960 |     40.230 |   1.1922 |     38.951 |     0.2
   10 |   1.1660 |     39.652 |   1.1797 |     38.670 |     0.2
   11 |   1.1367 |     38.667 |   1.1549 |     37.203 |     0.2
   12 |   1.0990 |     37.241 |   1.1428 |     36.891 |     0.3
   13 |   1.0754 |     36.790 |   1.1153 |     36.423 |     0.3
   14 |   1.0369 |     35.249 |   1.0896 |     35.331 |     0.3
   15 |   0.9970 |     33.625 |   1.0830 |     34.426 |     0.3
   16 |   0.9777 |     33.014 |   1.0572 |     35.331 |     0.4
   17 |   0.9341 |     31.220 |   1.0467 |     34.426 |     0.4
   18 |   0.9040 |     30.223 |   1.0389 |     33.333 |     0.4
   19 |   0.8690 |     29.128 |   0.9964 |     32.147 |     0.4
   20 |   0.8369 |     27.906 |   0.9996 |     31.398 |     0.5
   21 |   0.8110 |     26.624 |   1.0021 |     31.586 |     0.5
   22 |   0.7772 |     25.820 |   0.9886 |     31.180 |     0.5
   23 |   0.7488 |     24.752 |   0.9962 |     32.366 |     0.5
   24 |   0.7176 |     23.646 |   0.9653 |     30.119 |     0.6
   25 |   0.6906 |     22.892 |   0.9619 |     30.212 |     0.6
   26 |   0.6758 |     22.297 |   0.9598 |     29.338 |     0.6
   27 |   0.6491 |     21.351 |   0.9690 |     29.869 |     0.6
   28 |   0.6247 |     20.443 |   0.9816 |     29.744 |     0.6
   29 |   0.5966 |     19.276 |   0.9591 |     28.714 |     0.7
   30 |   0.5630 |     18.367 |   0.9777 |     28.839 |     0.7
   31 |   0.5494 |     17.597 |   0.9590 |     28.652 |     0.7
   32 |   0.5318 |     17.569 |   0.9529 |     27.903 |     0.7
   33 |   0.5017 |     16.171 |   0.9681 |     28.184 |     0.7
   34 |   0.4874 |     15.814 |   0.9329 |     27.278 |     0.8
   35 |   0.4593 |     14.784 |   0.9472 |     27.060 |     0.8
   36 |   0.4415 |     14.151 |   0.9700 |     26.935 |     0.8
   37 |   0.4310 |     14.047 |   0.9724 |     27.809 |     0.8
   38 |   0.4147 |     13.590 |   0.9813 |     26.748 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 879,074

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4760 |     67.024 |   1.9459 |     54.401 |     0.0
    2 |   1.7184 |     48.503 |   1.5401 |     45.350 |     0.1
    3 |   1.4760 |     46.114 |   1.4276 |     45.350 |     0.1
    4 |   1.4070 |     46.026 |   1.3813 |     45.350 |     0.1
    5 |   1.3711 |     45.052 |   1.3527 |     43.102 |     0.2
    6 |   1.3296 |     43.582 |   1.3064 |     41.979 |     0.2
    7 |   1.2907 |     42.327 |   1.2813 |     41.011 |     0.2
    8 |   1.2616 |     41.678 |   1.2548 |     40.169 |     0.2
    9 |   1.2325 |     40.659 |   1.2393 |     39.139 |     0.3
   10 |   1.1974 |     39.036 |   1.2008 |     38.733 |     0.3
   11 |   1.1632 |     37.962 |   1.1834 |     38.140 |     0.3
   12 |   1.1332 |     37.340 |   1.1571 |     37.484 |     0.4
   13 |   1.1027 |     36.603 |   1.1284 |     36.486 |     0.4
   14 |   1.0677 |     35.552 |   1.1194 |     36.923 |     0.4
   15 |   1.0410 |     34.605 |   1.1092 |     35.643 |     0.5
   16 |   1.0070 |     32.998 |   1.0753 |     34.769 |     0.5
   17 |   0.9747 |     31.539 |   1.0646 |     34.051 |     0.5
   18 |   0.9386 |     30.565 |   1.0480 |     33.552 |     0.5
   19 |   0.9155 |     29.315 |   1.0345 |     32.678 |     0.6
   20 |   0.8875 |     28.704 |   1.0212 |     31.804 |     0.6
   21 |   0.8717 |     27.978 |   1.0037 |     31.898 |     0.6
   22 |   0.8390 |     26.882 |   1.0063 |     31.367 |     0.7
   23 |   0.8175 |     26.404 |   1.0117 |     31.773 |     0.7
   24 |   0.7845 |     24.912 |   1.0105 |     30.930 |     0.7
   25 |   0.7588 |     24.020 |   0.9863 |     30.774 |     0.7
   26 |   0.7406 |     23.475 |   0.9869 |     30.712 |     0.8
   27 |   0.7158 |     22.688 |   0.9735 |     30.400 |     0.8
   28 |   0.6882 |     21.808 |   0.9784 |     30.212 |     0.8
   29 |   0.6767 |     21.433 |   0.9863 |     30.025 |     0.9
   30 |   0.6504 |     20.437 |   0.9558 |     29.494 |     0.9
   31 |   0.6300 |     19.854 |   0.9684 |     29.994 |     0.9
   32 |   0.6119 |     19.364 |   0.9633 |     29.026 |     1.0
   33 |   0.5972 |     18.896 |   0.9670 |     29.245 |     1.0
   34 |   0.5764 |     18.263 |   0.9648 |     28.464 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 420,706

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5845 |     69.347 |   2.0184 |     58.739 |     0.0
    2 |   1.8127 |     51.646 |   1.6089 |     45.381 |     0.0
    3 |   1.5218 |     46.219 |   1.4525 |     45.350 |     0.1
    4 |   1.4362 |     46.131 |   1.4079 |     45.350 |     0.1
    5 |   1.4076 |     46.169 |   1.3889 |     45.350 |     0.1
    6 |   1.3753 |     46.076 |   1.3522 |     44.663 |     0.1
    7 |   1.3469 |     45.228 |   1.3249 |     44.725 |     0.2
    8 |   1.3192 |     44.925 |   1.2947 |     43.352 |     0.2
    9 |   1.2936 |     44.210 |   1.2869 |     43.258 |     0.2
   10 |   1.2756 |     43.555 |   1.2650 |     42.665 |     0.2
   11 |   1.2542 |     42.845 |   1.2509 |     41.885 |     0.2
   12 |   1.2296 |     41.859 |   1.2119 |     39.981 |     0.3
   13 |   1.1977 |     40.863 |   1.1977 |     40.605 |     0.3
   14 |   1.1809 |     40.626 |   1.1786 |     39.607 |     0.3
   15 |   1.1535 |     39.283 |   1.1516 |     37.235 |     0.3
   16 |   1.1323 |     38.430 |   1.1433 |     37.765 |     0.3
   17 |   1.1106 |     37.605 |   1.1258 |     37.047 |     0.4
   18 |   1.0893 |     36.895 |   1.1121 |     36.236 |     0.4
   19 |   1.0630 |     35.541 |   1.0883 |     35.268 |     0.4
   20 |   1.0453 |     35.139 |   1.0888 |     35.112 |     0.4
   21 |   1.0195 |     33.966 |   1.0782 |     35.456 |     0.4
   22 |   0.9989 |     33.218 |   1.0613 |     34.675 |     0.5
   23 |   0.9894 |     33.141 |   1.0424 |     34.114 |     0.5
   24 |   0.9645 |     32.095 |   1.0239 |     33.396 |     0.5
   25 |   0.9472 |     31.522 |   1.0378 |     33.989 |     0.5
   26 |   0.9243 |     30.559 |   1.0353 |     33.739 |     0.5
   27 |   0.9094 |     30.157 |   1.0189 |     33.021 |     0.6
   28 |   0.8975 |     29.844 |   1.0073 |     32.709 |     0.6
   29 |   0.8764 |     28.974 |   0.9950 |     31.898 |     0.6
   30 |   0.8530 |     28.203 |   0.9899 |     31.648 |     0.6
   31 |   0.8514 |     28.044 |   0.9784 |     32.179 |     0.7
   32 |   0.8320 |     27.191 |   0.9833 |     31.710 |     0.7
   33 |   0.8136 |     26.706 |   0.9887 |     32.491 |     0.7
   34 |   0.7937 |     26.189 |   0.9772 |     31.367 |     0.7
   35 |   0.7774 |     25.440 |   0.9915 |     31.149 |     0.7
   36 |   0.7689 |     24.950 |   0.9690 |     30.400 |     0.8
   37 |   0.7591 |     24.747 |   0.9811 |     31.305 |     0.8
   38 |   0.7496 |     24.549 |   0.9808 |     30.587 |     0.8
   39 |   0.7306 |     23.574 |   0.9545 |     29.401 |     0.8
   40 |   0.7208 |     23.393 |   0.9504 |     30.119 |     0.8
   41 |   0.7120 |     22.809 |   0.9684 |     29.213 |     0.9
   42 |   0.6966 |     22.369 |   0.9595 |     29.838 |     0.9
   43 |   0.6827 |     21.940 |   0.9472 |     29.057 |     0.9
   44 |   0.6832 |     22.077 |   0.9497 |     29.307 |     0.9
   45 |   0.6706 |     21.527 |   0.9538 |     29.120 |     0.9
   46 |   0.6606 |     21.565 |   0.9585 |     29.151 |     1.0
   47 |   0.6502 |     20.850 |   0.9478 |     28.870 |     1.0
   48 |   0.6436 |     20.602 |   0.9401 |     28.340 |     1.0
   49 |   0.6301 |     20.437 |   0.9252 |     28.121 |     1.0
   50 |   0.6129 |     19.837 |   0.9511 |     28.340 |     1.1
   51 |   0.6018 |     19.259 |   0.9661 |     28.121 |     1.1
   52 |   0.5920 |     19.028 |   0.9506 |     27.528 |     1.1
   53 |   0.5947 |     19.281 |   0.9499 |     28.340 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 823,234

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3109 |     62.351 |   1.6846 |     48.283 |     0.0
    2 |   1.5099 |     46.587 |   1.4233 |     45.350 |     0.0
    3 |   1.4103 |     46.042 |   1.3893 |     45.318 |     0.1
    4 |   1.3732 |     45.597 |   1.3413 |     44.538 |     0.1
    5 |   1.3425 |     45.140 |   1.3202 |     44.007 |     0.1
    6 |   1.3112 |     44.501 |   1.2907 |     43.227 |     0.1
    7 |   1.2664 |     43.213 |   1.2634 |     42.541 |     0.2
    8 |   1.2360 |     42.393 |   1.2247 |     40.543 |     0.2
    9 |   1.2048 |     40.984 |   1.2065 |     39.201 |     0.2
   10 |   1.1734 |     40.307 |   1.1698 |     38.452 |     0.2
   11 |   1.1445 |     38.937 |   1.1623 |     38.046 |     0.2
   12 |   1.1214 |     37.770 |   1.1517 |     37.453 |     0.3
   13 |   1.0788 |     36.350 |   1.1200 |     36.454 |     0.3
   14 |   1.0461 |     35.073 |   1.1207 |     36.111 |     0.3
   15 |   1.0159 |     34.313 |   1.0907 |     34.956 |     0.3
   16 |   0.9805 |     32.662 |   1.0675 |     34.332 |     0.3
   17 |   0.9602 |     32.354 |   1.0844 |     35.050 |     0.4
   18 |   0.9444 |     31.836 |   1.0503 |     35.019 |     0.4
   19 |   0.9066 |     30.361 |   1.0472 |     33.801 |     0.4
   20 |   0.8831 |     29.354 |   1.0282 |     32.959 |     0.4
   21 |   0.8477 |     27.994 |   1.0401 |     32.335 |     0.5
   22 |   0.8333 |     27.273 |   1.0345 |     32.335 |     0.5
   23 |   0.8011 |     26.073 |   1.0156 |     32.865 |     0.5
   24 |   0.7830 |     25.600 |   1.0094 |     31.180 |     0.5
   25 |   0.7582 |     24.631 |   1.0149 |     31.742 |     0.5
   26 |   0.7402 |     24.180 |   1.0044 |     31.024 |     0.6
   27 |   0.7145 |     23.453 |   1.0063 |     30.524 |     0.6
   28 |   0.6935 |     22.507 |   0.9900 |     30.087 |     0.6
   29 |   0.6748 |     21.659 |   0.9920 |     29.463 |     0.6
   30 |   0.6500 |     21.076 |   1.0031 |     29.557 |     0.7
   31 |   0.6308 |     20.305 |   0.9885 |     29.463 |     0.7
   32 |   0.6109 |     19.672 |   0.9945 |     29.213 |     0.7
   33 |   0.5974 |     19.039 |   1.0073 |     28.277 |     0.7
   34 |   0.5754 |     18.406 |   0.9969 |     28.496 |     0.7
   35 |   0.5530 |     17.393 |   1.0030 |     28.558 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 383,202

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2536 |     61.003 |   1.5634 |     45.381 |     0.0
    2 |   1.4293 |     45.057 |   1.3375 |     42.665 |     0.0
    3 |   1.2980 |     42.492 |   1.2729 |     40.949 |     0.0
    4 |   1.2239 |     40.236 |   1.1975 |     38.920 |     0.1
    5 |   1.1544 |     37.968 |   1.1481 |     37.297 |     0.1
    6 |   1.1019 |     36.240 |   1.1054 |     35.799 |     0.1
    7 |   1.0404 |     34.142 |   1.0673 |     34.551 |     0.1
    8 |   0.9886 |     32.282 |   1.0275 |     33.302 |     0.1
    9 |   0.9365 |     30.312 |   0.9979 |     32.834 |     0.1
   10 |   0.8959 |     29.238 |   0.9712 |     30.868 |     0.1
   11 |   0.8393 |     27.471 |   0.9511 |     30.119 |     0.1
   12 |   0.7951 |     25.897 |   0.9500 |     30.618 |     0.2
   13 |   0.7512 |     23.949 |   0.9198 |     29.057 |     0.2
   14 |   0.7097 |     22.870 |   0.8977 |     28.402 |     0.2
   15 |   0.6715 |     21.780 |   0.8846 |     27.372 |     0.2
   16 |   0.6294 |     19.997 |   0.8680 |     26.280 |     0.2
   17 |   0.5888 |     18.571 |   0.8654 |     26.373 |     0.2
   18 |   0.5568 |     17.762 |   0.8755 |     27.091 |     0.2
   19 |   0.5235 |     16.452 |   0.8712 |     25.936 |     0.2
   20 |   0.4885 |     15.302 |   0.8629 |     26.124 |     0.3
   21 |   0.4611 |     14.509 |   0.8871 |     26.498 |     0.3
   22 |   0.4387 |     13.623 |   0.8628 |     25.531 |     0.3
   23 |   0.4145 |     12.907 |   0.8756 |     25.718 |     0.3
   24 |   0.3911 |     12.159 |   0.8817 |     25.375 |     0.3
   25 |   0.3641 |     11.278 |   0.8997 |     25.187 |     0.3
   26 |   0.3466 |     10.909 |   0.9041 |     25.531 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 2,378,274

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3199 |     64.212 |   1.6979 |     48.283 |     0.1
    2 |   1.5217 |     46.472 |   1.4336 |     45.350 |     0.1
    3 |   1.4180 |     46.208 |   1.4220 |     45.880 |     0.2
    4 |   1.4012 |     46.131 |   1.3923 |     45.350 |     0.2
    5 |   1.3953 |     46.114 |   1.3846 |     45.318 |     0.3
    6 |   1.3889 |     46.109 |   1.3819 |     45.350 |     0.3
    7 |   1.3750 |     45.949 |   1.3618 |     45.037 |     0.4
    8 |   1.3470 |     44.980 |   1.3167 |     43.414 |     0.4
    9 |   1.3083 |     44.171 |   1.2882 |     43.165 |     0.5
   10 |   1.2717 |     43.081 |   1.2694 |     42.634 |     0.6
   11 |   1.2462 |     42.828 |   1.2382 |     42.104 |     0.6
   12 |   1.2300 |     42.063 |   1.2214 |     40.449 |     0.7
   13 |   1.2087 |     41.518 |   1.2002 |     39.700 |     0.7
   14 |   1.1935 |     40.841 |   1.1977 |     40.044 |     0.8
   15 |   1.1806 |     40.092 |   1.1889 |     40.325 |     0.8
   16 |   1.1757 |     40.291 |   1.1936 |     39.295 |     0.9
   17 |   1.1580 |     39.784 |   1.1741 |     39.232 |     1.0
   18 |   1.1409 |     38.959 |   1.1682 |     38.639 |     1.0
   19 |   1.1253 |     38.491 |   1.1560 |     39.357 |     1.1
   20 |   1.1028 |     37.373 |   1.1393 |     37.484 |     1.1
   21 |   1.0885 |     37.016 |   1.1326 |     37.203 |     1.2
   22 |   1.0744 |     36.416 |   1.1258 |     37.453 |     1.2
   23 |   1.0681 |     36.278 |   1.1188 |     37.578 |     1.3
   24 |   1.0602 |     36.118 |   1.1343 |     39.326 |     1.3
   25 |   1.0403 |     35.353 |   1.1021 |     37.328 |     1.4
   26 |   1.0136 |     34.489 |   1.0989 |     36.517 |     1.5
   27 |   0.9941 |     33.724 |   1.0807 |     35.861 |     1.5
   28 |   0.9795 |     32.799 |   1.0828 |     35.581 |     1.6
   29 |   0.9698 |     32.777 |   1.0771 |     35.393 |     1.6
   30 |   0.9527 |     32.244 |   1.0285 |     34.270 |     1.7
   31 |   0.9184 |     30.994 |   1.0497 |     34.956 |     1.7
   32 |   0.9191 |     31.027 |   1.0475 |     35.237 |     1.8
   33 |   0.9076 |     30.669 |   1.0384 |     34.301 |     1.9
   34 |   0.8869 |     29.899 |   1.0293 |     34.332 |     1.9
   35 |   0.8598 |     29.068 |   0.9879 |     32.709 |     2.0
   36 |   0.8368 |     27.879 |   0.9771 |     31.429 |     2.0
   37 |   0.8259 |     27.537 |   0.9823 |     32.116 |     2.1
   38 |   0.8153 |     27.466 |   1.0066 |     31.773 |     2.1
   39 |   0.7843 |     26.084 |   0.9846 |     31.523 |     2.2
   40 |   0.7601 |     25.182 |   0.9934 |     31.242 |     2.3
   41 |   0.7576 |     25.138 |   0.9729 |     30.587 |     2.3
   42 |   0.7597 |     25.424 |   0.9911 |     31.398 |     2.4
   43 |   0.7346 |     24.114 |   0.9626 |     30.212 |     2.4
   44 |   0.7219 |     23.971 |   0.9707 |     29.494 |     2.5
   45 |   0.6971 |     22.749 |   0.9553 |     30.150 |     2.5
   46 |   0.6766 |     22.380 |   0.9537 |     29.370 |     2.6
   47 |   0.7042 |     23.569 |   0.9671 |     29.650 |     2.6
   48 |   0.6760 |     22.358 |   0.9602 |     29.432 |     2.7
   49 |   0.6589 |     21.896 |   0.9710 |     30.649 |     2.8
   50 |   0.6453 |     21.384 |   0.9175 |     28.246 |     2.8
   51 |   0.6225 |     20.525 |   0.9388 |     28.402 |     2.9
   52 |   0.6363 |     20.872 |   0.9709 |     29.619 |     2.9
   53 |   0.6190 |     20.432 |   0.9508 |     28.589 |     3.0
   54 |   0.5907 |     19.254 |   0.9424 |     28.402 |     3.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,046,402

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5453 |     67.030 |   2.0356 |     53.277 |     0.0
    2 |   1.8156 |     50.925 |   1.6060 |     45.350 |     0.1
    3 |   1.5199 |     46.169 |   1.4538 |     45.350 |     0.1
    4 |   1.4350 |     46.169 |   1.4098 |     44.725 |     0.2
    5 |   1.4029 |     45.668 |   1.3843 |     44.288 |     0.2
    6 |   1.3704 |     44.865 |   1.3567 |     43.321 |     0.2
    7 |   1.3351 |     43.549 |   1.3258 |     42.884 |     0.3
    8 |   1.3053 |     42.586 |   1.3068 |     42.665 |     0.3
    9 |   1.2793 |     42.008 |   1.2926 |     42.072 |     0.3
   10 |   1.2569 |     41.375 |   1.2621 |     41.323 |     0.4
   11 |   1.2330 |     41.067 |   1.2559 |     41.074 |     0.4
   12 |   1.2083 |     40.368 |   1.2304 |     39.919 |     0.5
   13 |   1.1839 |     39.432 |   1.2080 |     39.576 |     0.5
   14 |   1.1504 |     37.935 |   1.1741 |     37.828 |     0.5
   15 |   1.1250 |     37.324 |   1.1676 |     36.829 |     0.6
   16 |   1.1047 |     36.091 |   1.1532 |     37.079 |     0.6
   17 |   1.0712 |     35.260 |   1.1346 |     36.361 |     0.7
   18 |   1.0524 |     34.731 |   1.1058 |     35.050 |     0.7
   19 |   1.0245 |     33.878 |   1.1045 |     35.300 |     0.7
   20 |   1.0044 |     33.306 |   1.0968 |     34.800 |     0.8
   21 |   0.9882 |     32.601 |   1.0808 |     34.894 |     0.8
   22 |   0.9697 |     31.825 |   1.0754 |     34.457 |     0.8
   23 |   0.9599 |     31.831 |   1.0695 |     34.145 |     0.9
   24 |   0.9283 |     30.405 |   1.0702 |     34.800 |     0.9
   25 |   0.9126 |     29.888 |   1.0644 |     34.332 |     1.0
   26 |   0.8972 |     29.475 |   1.0371 |     33.115 |     1.0
   27 |   0.8741 |     28.380 |   1.0333 |     33.521 |     1.0
   28 |   0.8649 |     28.033 |   1.0370 |     33.052 |     1.1
   29 |   0.8362 |     26.838 |   1.0224 |     33.271 |     1.1
   30 |   0.8305 |     27.042 |   1.0081 |     32.210 |     1.2
   31 |   0.8077 |     26.365 |   1.0256 |     32.085 |     1.2
   32 |   0.7999 |     25.864 |   1.0010 |     31.710 |     1.2
   33 |   0.7805 |     25.501 |   0.9977 |     31.242 |     1.3
   34 |   0.7637 |     24.692 |   1.0026 |     31.429 |     1.3
   35 |   0.7479 |     23.789 |   0.9920 |     30.649 |     1.3
   36 |   0.7383 |     23.965 |   1.0199 |     31.648 |     1.4
   37 |   0.7273 |     23.376 |   1.0103 |     31.492 |     1.4
   38 |   0.7091 |     22.875 |   1.0019 |     30.618 |     1.5
   39 |   0.7050 |     22.908 |   0.9859 |     29.744 |     1.5
   40 |   0.6974 |     22.820 |   0.9874 |     30.181 |     1.5
   41 |   0.6744 |     21.697 |   0.9930 |     29.838 |     1.6
   42 |   0.6573 |     21.125 |   0.9896 |     29.775 |     1.6
   43 |   0.6491 |     20.883 |   0.9862 |     30.275 |     1.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,079,682

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6163 |     69.540 |   2.0606 |     58.708 |     0.0
    2 |   1.8177 |     51.244 |   1.6108 |     45.350 |     0.1
    3 |   1.5326 |     46.142 |   1.4700 |     45.350 |     0.1
    4 |   1.4489 |     46.197 |   1.4303 |     45.350 |     0.2
    5 |   1.4214 |     46.142 |   1.4073 |     45.350 |     0.2
    6 |   1.4084 |     46.120 |   1.5054 |     47.191 |     0.2
    7 |   1.4019 |     46.120 |   1.3923 |     45.350 |     0.3
    8 |   1.3972 |     46.131 |   1.3914 |     45.350 |     0.3
    9 |   1.3948 |     46.153 |   1.3896 |     45.225 |     0.3
   10 |   1.3921 |     46.175 |   1.3870 |     45.350 |     0.4
   11 |   1.3914 |     46.114 |   1.3842 |     45.350 |     0.4
   12 |   1.3871 |     46.125 |   1.3834 |     45.350 |     0.5
   13 |   1.3853 |     46.131 |   1.3779 |     45.381 |     0.5
   14 |   1.3781 |     46.048 |   1.3733 |     45.350 |     0.5
   15 |   1.3638 |     45.376 |   1.3476 |     43.945 |     0.6
   16 |   1.3414 |     44.760 |   1.3363 |     43.664 |     0.6
   17 |   1.3261 |     44.281 |   1.3211 |     43.446 |     0.7
   18 |   1.3127 |     44.397 |   1.3103 |     42.697 |     0.7
   19 |   1.2978 |     43.830 |   1.3114 |     42.915 |     0.7
   20 |   1.2899 |     43.775 |   1.2961 |     43.102 |     0.8
   21 |   1.2759 |     42.916 |   1.2928 |     42.572 |     0.8
   22 |   1.2668 |     42.707 |   1.2763 |     42.322 |     0.9
   23 |   1.2663 |     43.186 |   1.2924 |     42.697 |     0.9
   24 |   1.2555 |     42.377 |   1.2700 |     41.511 |     0.9
   25 |   1.2435 |     41.997 |   1.2741 |     41.916 |     1.0
   26 |   1.2284 |     41.276 |   1.2595 |     41.635 |     1.0
   27 |   1.2189 |     41.232 |   1.2489 |     41.604 |     1.0
   28 |   1.2071 |     40.874 |   1.2439 |     40.949 |     1.1
   29 |   1.1982 |     40.467 |   1.2436 |     40.325 |     1.1
   30 |   1.1877 |     40.010 |   1.2440 |     41.074 |     1.2
   31 |   1.1810 |     39.878 |   1.2339 |     41.042 |     1.2
   32 |   1.1755 |     39.619 |   1.2310 |     40.605 |     1.2
   33 |   1.1638 |     39.338 |   1.2259 |     40.574 |     1.3
   34 |   1.1536 |     39.206 |   1.2151 |     40.356 |     1.3
   35 |   1.1464 |     39.355 |   1.2075 |     40.169 |     1.4
   36 |   1.1346 |     38.595 |   1.2148 |     39.981 |     1.4
   37 |   1.1230 |     38.359 |   1.1979 |     39.732 |     1.4
   38 |   1.1261 |     38.210 |   1.2078 |     39.825 |     1.5
   39 |   1.1094 |     37.775 |   1.2002 |     39.232 |     1.5
   40 |   1.1049 |     37.445 |   1.1828 |     38.546 |     1.6
   41 |   1.0927 |     37.208 |   1.1787 |     38.452 |     1.6
   42 |   1.0877 |     36.751 |   1.1794 |     38.077 |     1.6
   43 |   1.0781 |     36.366 |   1.1650 |     37.016 |     1.7
   44 |   1.0565 |     35.518 |   1.1610 |     37.953 |     1.7
   45 |   1.0435 |     34.996 |   1.1554 |     36.735 |     1.7
   46 |   1.0283 |     34.748 |   1.1549 |     37.516 |     1.8
   47 |   1.0364 |     34.908 |   1.1671 |     37.859 |     1.8
   48 |   1.0233 |     34.357 |   1.1532 |     37.484 |     1.9
   49 |   1.0203 |     34.038 |   1.1346 |     37.110 |     1.9
   50 |   0.9974 |     33.498 |   1.1384 |     36.923 |     1.9
   51 |   1.0075 |     34.032 |   1.1377 |     36.798 |     2.0
   52 |   0.9959 |     33.179 |   1.1296 |     36.860 |     2.0
   53 |   0.9836 |     32.783 |   1.1126 |     35.861 |     2.1
   54 |   0.9782 |     32.711 |   1.1314 |     36.236 |     2.1
   55 |   0.9603 |     32.359 |   1.1122 |     34.956 |     2.1
   56 |   0.9532 |     31.952 |   1.1268 |     35.924 |     2.2
   57 |   0.9420 |     31.319 |   1.1307 |     35.955 |     2.2
   58 |   0.9267 |     30.812 |   1.1205 |     35.424 |     2.2
   59 |   0.9268 |     30.686 |   1.1190 |     35.456 |     2.3
   60 |   0.9127 |     30.427 |   1.1119 |     35.175 |     2.3
   61 |   0.9103 |     30.130 |   1.1212 |     34.956 |     2.4
   62 |   0.9053 |     30.036 |   1.1098 |     34.675 |     2.4
   63 |   0.8991 |     29.756 |   1.1252 |     35.456 |     2.4
   64 |   0.8937 |     29.800 |   1.1125 |     35.300 |     2.5
   65 |   0.8754 |     29.134 |   1.1169 |     35.300 |     2.5
   66 |   0.8722 |     28.941 |   1.1196 |     35.206 |     2.6
   67 |   0.8734 |     29.156 |   1.1035 |     34.114 |     2.6
   68 |   0.8595 |     28.457 |   1.1024 |     34.675 |     2.6
   69 |   0.8467 |     28.341 |   1.1060 |     34.551 |     2.7
   70 |   0.8379 |     27.807 |   1.0998 |     34.207 |     2.7
   71 |   0.8277 |     27.427 |   1.1063 |     34.145 |     2.7
   72 |   0.8236 |     27.185 |   1.1081 |     34.332 |     2.8
   73 |   0.8267 |     27.543 |   1.0979 |     33.302 |     2.8
   74 |   0.8223 |     27.548 |   1.1117 |     34.925 |     2.9
   75 |   0.8382 |     27.587 |   1.1160 |     34.988 |     2.9
   76 |   0.8120 |     26.904 |   1.1028 |     33.770 |     2.9
   77 |   0.7872 |     26.216 |   1.0965 |     33.833 |     3.0
   78 |   0.7851 |     25.870 |   1.0979 |     33.677 |     3.0
   79 |   0.7712 |     25.969 |   1.1076 |     33.770 |     3.1
   80 |   0.7830 |     26.404 |   1.0953 |     34.207 |     3.1
   81 |   0.7683 |     25.743 |   1.1050 |     34.145 |     3.1
   82 |   0.7684 |     25.705 |   1.0943 |     33.552 |     3.2
   83 |   0.7845 |     25.875 |   1.0977 |     33.958 |     3.2
   84 |   0.7574 |     25.286 |   1.0979 |     33.240 |     3.3
   85 |   0.7489 |     25.105 |   1.0850 |     33.645 |     3.3
   86 |   0.7429 |     24.807 |   1.1054 |     33.521 |     3.3
   87 |   0.7454 |     24.686 |   1.1238 |     34.894 |     3.4
   88 |   0.7525 |     25.154 |   1.1238 |     34.207 |     3.4
   89 |   0.7245 |     24.235 |   1.1205 |     34.738 |     3.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 515,298

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2498 |     60.117 |   1.6511 |     48.283 |     0.0
    2 |   1.4895 |     46.235 |   1.4081 |     45.225 |     0.0
    3 |   1.3837 |     45.079 |   1.3513 |     43.134 |     0.0
    4 |   1.3273 |     43.780 |   1.2954 |     42.322 |     0.1
    5 |   1.2799 |     42.696 |   1.2682 |     40.949 |     0.1
    6 |   1.2383 |     41.546 |   1.2340 |     40.231 |     0.1
    7 |   1.2023 |     40.285 |   1.1997 |     38.733 |     0.1
    8 |   1.1628 |     38.722 |   1.1762 |     38.608 |     0.1
    9 |   1.1240 |     37.682 |   1.1576 |     37.953 |     0.1
   10 |   1.0889 |     36.559 |   1.1551 |     37.360 |     0.1
   11 |   1.0527 |     35.364 |   1.1057 |     35.893 |     0.2
   12 |   1.0113 |     33.834 |   1.1005 |     35.112 |     0.2
   13 |   0.9692 |     32.469 |   1.0631 |     34.207 |     0.2
   14 |   0.9225 |     30.757 |   1.0543 |     33.240 |     0.2
   15 |   0.8839 |     29.321 |   1.0646 |     33.895 |     0.2
   16 |   0.8405 |     27.664 |   1.0332 |     32.740 |     0.2
   17 |   0.7915 |     26.051 |   1.0246 |     32.834 |     0.2
   18 |   0.7457 |     24.141 |   0.9890 |     31.117 |     0.2
   19 |   0.6997 |     22.457 |   0.9939 |     30.556 |     0.3
   20 |   0.6540 |     20.558 |   1.0146 |     30.993 |     0.3
   21 |   0.6072 |     19.055 |   0.9945 |     29.869 |     0.3
   22 |   0.5743 |     17.878 |   1.0054 |     30.680 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 1,147,170

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5818 |     68.973 |   1.9719 |     58.708 |     0.0
    2 |   1.7580 |     49.538 |   1.5825 |     45.350 |     0.1
    3 |   1.5073 |     46.114 |   1.4481 |     45.350 |     0.1
    4 |   1.4343 |     46.120 |   1.4159 |     45.350 |     0.1
    5 |   1.4122 |     46.125 |   1.3994 |     45.350 |     0.2
    6 |   1.4021 |     46.120 |   1.3973 |     45.350 |     0.2
    7 |   1.3938 |     46.120 |   1.3853 |     45.350 |     0.3
    8 |   1.3863 |     46.114 |   1.3770 |     45.350 |     0.3
    9 |   1.3743 |     45.938 |   1.3626 |     44.600 |     0.3
   10 |   1.3576 |     45.035 |   1.3439 |     44.164 |     0.4
   11 |   1.3422 |     44.617 |   1.3341 |     43.352 |     0.4
   12 |   1.3287 |     44.446 |   1.3380 |     43.851 |     0.4
   13 |   1.3220 |     44.149 |   1.3238 |     42.915 |     0.5
   14 |   1.3109 |     43.857 |   1.3131 |     43.009 |     0.5
   15 |   1.3019 |     43.588 |   1.3079 |     42.603 |     0.6
   16 |   1.2931 |     43.400 |   1.3015 |     42.665 |     0.6
   17 |   1.2879 |     43.312 |   1.2935 |     42.509 |     0.6
   18 |   1.2809 |     42.850 |   1.2951 |     42.665 |     0.7
   19 |   1.2784 |     42.911 |   1.2911 |     41.479 |     0.7
   20 |   1.2660 |     42.426 |   1.2829 |     41.760 |     0.8
   21 |   1.2560 |     42.041 |   1.2793 |     41.823 |     0.8
   22 |   1.2515 |     41.859 |   1.2739 |     41.542 |     0.8
   23 |   1.2428 |     41.502 |   1.2775 |     41.355 |     0.9
   24 |   1.2439 |     41.623 |   1.2756 |     41.542 |     0.9
   25 |   1.2349 |     41.452 |   1.2607 |     41.136 |     0.9
   26 |   1.2318 |     41.001 |   1.2581 |     40.918 |     1.0
   27 |   1.2210 |     40.830 |   1.2475 |     40.231 |     1.0
   28 |   1.2149 |     40.395 |   1.2467 |     40.793 |     1.1
   29 |   1.2121 |     40.434 |   1.2423 |     40.449 |     1.1
   30 |   1.2042 |     40.357 |   1.2444 |     40.262 |     1.1
   31 |   1.1966 |     40.230 |   1.2442 |     40.387 |     1.2
   32 |   1.1890 |     39.938 |   1.2315 |     39.950 |     1.2
   33 |   1.1897 |     39.883 |   1.2285 |     40.012 |     1.2
   34 |   1.1799 |     39.680 |   1.2240 |     40.387 |     1.3
   35 |   1.1670 |     39.448 |   1.2120 |     40.668 |     1.3
   36 |   1.1628 |     39.327 |   1.2170 |     39.919 |     1.4
   37 |   1.1579 |     38.997 |   1.2242 |     40.387 |     1.4
   38 |   1.1526 |     38.981 |   1.2053 |     39.201 |     1.4
   39 |   1.1423 |     38.771 |   1.1939 |     39.700 |     1.5
   40 |   1.1328 |     38.414 |   1.1895 |     39.263 |     1.5
   41 |   1.1142 |     37.500 |   1.1925 |     39.170 |     1.6
   42 |   1.1114 |     37.318 |   1.1824 |     38.140 |     1.6
   43 |   1.0974 |     36.614 |   1.1837 |     39.232 |     1.6
   44 |   1.1036 |     36.718 |   1.1928 |     38.826 |     1.7
   45 |   1.0951 |     36.636 |   1.1855 |     39.607 |     1.7
   46 |   1.0870 |     36.212 |   1.1671 |     38.577 |     1.7
   47 |   1.0680 |     35.574 |   1.1703 |     37.797 |     1.8
   48 |   1.0607 |     35.276 |   1.1821 |     37.797 |     1.8
   49 |   1.0611 |     35.254 |   1.1638 |     37.672 |     1.9
   50 |   1.0491 |     34.792 |   1.1601 |     36.891 |     1.9
   51 |   1.0349 |     34.269 |   1.1555 |     37.297 |     1.9
   52 |   1.0249 |     34.203 |   1.1625 |     37.734 |     2.0
   53 |   1.0119 |     33.746 |   1.1607 |     37.703 |     2.0
   54 |   1.0090 |     33.664 |   1.1665 |     38.077 |     2.1
   55 |   1.0076 |     33.537 |   1.1459 |     37.016 |     2.1
   56 |   1.0060 |     33.350 |   1.1523 |     36.330 |     2.1
   57 |   0.9934 |     32.810 |   1.1385 |     36.704 |     2.2
   58 |   0.9787 |     32.596 |   1.1421 |     36.642 |     2.2
   59 |   0.9768 |     32.414 |   1.1404 |     36.767 |     2.2
   60 |   0.9588 |     31.726 |   1.1389 |     36.080 |     2.3
   61 |   0.9616 |     31.930 |   1.1274 |     36.423 |     2.3
   62 |   0.9493 |     31.412 |   1.1282 |     36.642 |     2.4
   63 |   0.9472 |     31.467 |   1.1401 |     37.203 |     2.4
   64 |   0.9414 |     31.077 |   1.1419 |     36.673 |     2.4
   65 |   0.9319 |     30.906 |   1.1401 |     36.923 |     2.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 2,465,986

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6191 |     70.894 |   2.0450 |     58.708 |     0.1
    2 |   1.8386 |     51.712 |   1.6317 |     45.350 |     0.2
    3 |   1.5352 |     46.175 |   1.4653 |     45.350 |     0.2
    4 |   1.4464 |     46.208 |   1.4284 |     45.350 |     0.3
    5 |   1.4211 |     46.164 |   1.4068 |     45.350 |     0.4
    6 |   1.4088 |     46.131 |   1.3983 |     45.350 |     0.5
    7 |   1.4019 |     46.136 |   1.3941 |     45.350 |     0.6
    8 |   1.3955 |     46.208 |   1.3862 |     45.350 |     0.6
    9 |   1.3887 |     46.125 |   1.3774 |     45.350 |     0.7
   10 |   1.3784 |     45.459 |   1.3652 |     44.039 |     0.8
   11 |   1.3640 |     44.958 |   1.3589 |     44.413 |     0.9
   12 |   1.3554 |     44.958 |   1.3481 |     44.039 |     1.0
   13 |   1.3482 |     44.909 |   1.3397 |     43.945 |     1.0
   14 |   1.3415 |     44.744 |   1.3345 |     44.132 |     1.1
   15 |   1.3423 |     44.843 |   1.3331 |     43.571 |     1.2
   16 |   1.3371 |     44.793 |   1.3306 |     44.039 |     1.3
   17 |   1.3281 |     44.545 |   1.3265 |     43.446 |     1.4
   18 |   1.3217 |     44.732 |   1.3200 |     43.695 |     1.4
   19 |   1.3181 |     44.534 |   1.3206 |     43.446 |     1.5
   20 |   1.3121 |     44.490 |   1.3106 |     42.509 |     1.6
   21 |   1.3076 |     44.199 |   1.3147 |     42.790 |     1.7
   22 |   1.3066 |     44.011 |   1.3021 |     42.322 |     1.8
   23 |   1.3005 |     43.857 |   1.2953 |     42.291 |     1.8
   24 |   1.2967 |     43.725 |   1.2996 |     42.166 |     1.9
   25 |   1.2911 |     43.384 |   1.2984 |     42.353 |     2.0
   26 |   1.2918 |     43.318 |   1.2999 |     42.634 |     2.1
   27 |   1.2864 |     43.417 |   1.2909 |     42.041 |     2.2
   28 |   1.2822 |     43.092 |   1.2889 |     42.478 |     2.2
   29 |   1.2808 |     42.993 |   1.2918 |     42.322 |     2.3
   30 |   1.2792 |     43.026 |   1.2903 |     42.478 |     2.4
   31 |   1.2778 |     43.191 |   1.2935 |     42.603 |     2.5
   32 |   1.2774 |     43.147 |   1.2871 |     41.948 |     2.5
   33 |   1.2863 |     43.246 |   1.2858 |     41.479 |     2.6
   34 |   1.2741 |     42.861 |   1.2792 |     41.823 |     2.7
   35 |   1.2682 |     42.531 |   1.2766 |     41.948 |     2.8
   36 |   1.2649 |     42.300 |   1.2785 |     41.885 |     2.9
   37 |   1.2636 |     42.448 |   1.2650 |     41.292 |     2.9
   38 |   1.2588 |     42.272 |   1.2824 |     41.948 |     3.0
   39 |   1.2596 |     42.349 |   1.2673 |     41.448 |     3.1
   40 |   1.2543 |     42.300 |   1.2706 |     41.729 |     3.2
   41 |   1.2516 |     42.212 |   1.2626 |     41.448 |     3.3
   42 |   1.2468 |     42.085 |   1.2645 |     41.042 |     3.3
   43 |   1.2505 |     42.079 |   1.2595 |     41.230 |     3.4
   44 |   1.2409 |     41.898 |   1.2510 |     40.824 |     3.5
   45 |   1.2402 |     41.936 |   1.2574 |     41.479 |     3.6
   46 |   1.2358 |     41.848 |   1.2494 |     40.793 |     3.7
   47 |   1.2361 |     41.650 |   1.2536 |     41.074 |     3.7
   48 |   1.2301 |     41.325 |   1.2576 |     41.760 |     3.8
   49 |   1.2318 |     41.749 |   1.2422 |     40.762 |     3.9
   50 |   1.2279 |     41.678 |   1.2569 |     41.448 |     4.0
   51 |   1.2353 |     41.788 |   1.2536 |     40.886 |     4.1
   52 |   1.2260 |     41.672 |   1.2489 |     41.199 |     4.1
   53 |   1.2248 |     41.722 |   1.2423 |     40.574 |     4.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 2,485,474

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5452 |     68.136 |   2.0158 |     53.745 |     0.1
    2 |   1.8077 |     51.040 |   1.5955 |     45.350 |     0.2
    3 |   1.5191 |     46.202 |   1.4567 |     45.350 |     0.3
    4 |   1.4392 |     46.175 |   1.4158 |     45.350 |     0.3
    5 |   1.4149 |     46.235 |   1.4011 |     45.350 |     0.4
    6 |   1.3984 |     46.169 |   1.3818 |     45.350 |     0.5
    7 |   1.3805 |     46.009 |   1.3673 |     44.757 |     0.6
    8 |   1.3687 |     45.866 |   1.3567 |     44.476 |     0.7
    9 |   1.3548 |     45.542 |   1.3445 |     44.600 |     0.7
   10 |   1.3433 |     45.619 |   1.3327 |     44.632 |     0.8
   11 |   1.3305 |     45.410 |   1.3116 |     44.476 |     0.9
   12 |   1.3196 |     45.250 |   1.3035 |     43.945 |     1.0
   13 |   1.3052 |     44.925 |   1.2930 |     43.321 |     1.1
   14 |   1.2852 |     43.907 |   1.2659 |     42.915 |     1.1
   15 |   1.2700 |     43.434 |   1.2494 |     41.417 |     1.2
   16 |   1.2558 |     42.927 |   1.2405 |     41.729 |     1.3
   17 |   1.2468 |     42.652 |   1.2416 |     42.385 |     1.4
   18 |   1.2329 |     42.052 |   1.2130 |     40.106 |     1.5
   19 |   1.2217 |     42.090 |   1.2195 |     40.512 |     1.5
   20 |   1.2149 |     41.678 |   1.2136 |     40.793 |     1.6
   21 |   1.2062 |     41.375 |   1.1978 |     40.418 |     1.7
   22 |   1.1963 |     40.995 |   1.2020 |     39.919 |     1.8
   23 |   1.1801 |     40.313 |   1.1783 |     38.795 |     1.9
   24 |   1.1632 |     39.515 |   1.1709 |     38.296 |     2.0
   25 |   1.1544 |     39.349 |   1.1688 |     39.201 |     2.0
   26 |   1.1449 |     39.058 |   1.1511 |     38.233 |     2.1
   27 |   1.1290 |     38.309 |   1.1513 |     37.703 |     2.2
   28 |   1.1229 |     37.968 |   1.1359 |     37.890 |     2.3
   29 |   1.1124 |     37.500 |   1.1450 |     38.015 |     2.4
   30 |   1.0957 |     37.104 |   1.1280 |     36.860 |     2.4
   31 |   1.0953 |     37.049 |   1.1361 |     37.578 |     2.5
   32 |   1.0850 |     36.630 |   1.1154 |     36.798 |     2.6
   33 |   1.0653 |     35.893 |   1.1001 |     36.049 |     2.7
   34 |   1.0512 |     35.463 |   1.0914 |     35.300 |     2.8
   35 |   1.0481 |     34.897 |   1.1035 |     35.674 |     2.9
   36 |   1.0451 |     35.370 |   1.0887 |     35.144 |     3.0
   37 |   1.0303 |     34.621 |   1.0806 |     35.268 |     3.1
   38 |   1.0285 |     34.913 |   1.0756 |     34.457 |     3.2
   39 |   1.0089 |     33.713 |   1.0734 |     35.268 |     3.3
   40 |   1.0003 |     33.476 |   1.0704 |     34.519 |     3.3
   41 |   0.9998 |     33.438 |   1.0707 |     34.738 |     3.4
   42 |   0.9804 |     32.755 |   1.0537 |     34.051 |     3.5
   43 |   0.9753 |     32.535 |   1.0434 |     33.583 |     3.6
   44 |   0.9649 |     32.282 |   1.0451 |     33.614 |     3.7
   45 |   0.9592 |     32.293 |   1.0145 |     33.458 |     3.8
   46 |   0.9464 |     31.649 |   1.0417 |     33.895 |     3.9
   47 |   0.9445 |     31.710 |   1.0468 |     33.677 |     4.0
   48 |   0.9397 |     31.522 |   1.0209 |     33.302 |     4.0
   49 |   0.9319 |     31.159 |   1.0244 |     32.615 |     4.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 473,250

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6303 |     67.938 |   2.0403 |     58.708 |     0.0
    2 |   1.8023 |     50.996 |   1.5865 |     45.350 |     0.1
    3 |   1.5116 |     46.142 |   1.4506 |     45.350 |     0.1
    4 |   1.4367 |     46.279 |   1.4164 |     45.350 |     0.1
    5 |   1.4143 |     46.120 |   1.4007 |     45.318 |     0.1
    6 |   1.4044 |     46.197 |   1.3937 |     45.318 |     0.2
    7 |   1.3961 |     46.175 |   1.3895 |     45.350 |     0.2
    8 |   1.3876 |     46.158 |   1.3786 |     45.350 |     0.2
    9 |   1.3746 |     46.109 |   1.3652 |     45.350 |     0.3
   10 |   1.3565 |     45.877 |   1.3393 |     44.975 |     0.3
   11 |   1.3384 |     45.542 |   1.3250 |     44.351 |     0.3
   12 |   1.3301 |     45.459 |   1.3219 |     44.569 |     0.3
   13 |   1.3194 |     45.162 |   1.3018 |     44.195 |     0.4
   14 |   1.3033 |     44.837 |   1.2918 |     43.633 |     0.4
   15 |   1.2790 |     43.896 |   1.2657 |     42.166 |     0.4
   16 |   1.2561 |     42.977 |   1.2501 |     41.604 |     0.5
   17 |   1.2317 |     42.487 |   1.2259 |     40.387 |     0.5
   18 |   1.2173 |     41.705 |   1.2251 |     41.448 |     0.5
   19 |   1.2072 |     41.617 |   1.2113 |     40.293 |     0.5
   20 |   1.1854 |     40.946 |   1.1986 |     39.888 |     0.5
   21 |   1.1689 |     40.076 |   1.1832 |     39.576 |     0.6
   22 |   1.1573 |     39.812 |   1.1718 |     39.201 |     0.6
   23 |   1.1387 |     38.942 |   1.1785 |     38.826 |     0.6
   24 |   1.1238 |     38.568 |   1.1561 |     38.951 |     0.6
   25 |   1.1115 |     38.381 |   1.1474 |     38.202 |     0.7
   26 |   1.0906 |     37.588 |   1.1330 |     38.046 |     0.7
   27 |   1.0829 |     37.318 |   1.1221 |     37.547 |     0.7
   28 |   1.0695 |     36.531 |   1.1243 |     37.516 |     0.7
   29 |   1.0549 |     36.355 |   1.1112 |     37.079 |     0.8
   30 |   1.0354 |     35.645 |   1.0938 |     35.768 |     0.8
   31 |   1.0195 |     34.985 |   1.0974 |     36.423 |     0.8
   32 |   1.0094 |     34.544 |   1.0769 |     36.049 |     0.8
   33 |   1.0005 |     33.889 |   1.0925 |     35.955 |     0.8
   34 |   0.9869 |     33.719 |   1.0685 |     35.300 |     0.9
   35 |   0.9738 |     32.998 |   1.0701 |     35.705 |     0.9
   36 |   0.9613 |     32.590 |   1.0536 |     35.019 |     0.9
   37 |   0.9446 |     31.974 |   1.0554 |     34.582 |     0.9
   38 |   0.9380 |     31.787 |   1.0497 |     34.301 |     1.0
   39 |   0.9246 |     31.352 |   1.0593 |     34.644 |     1.0
   40 |   0.9184 |     31.088 |   1.0354 |     33.801 |     1.0
   41 |   0.9056 |     30.576 |   1.0492 |     33.489 |     1.0
   42 |   0.8915 |     30.025 |   1.0399 |     33.365 |     1.1
   43 |   0.8855 |     29.783 |   1.0376 |     33.614 |     1.1
   44 |   0.8729 |     29.431 |   1.0321 |     33.396 |     1.1
   45 |   0.8639 |     28.958 |   1.0226 |     32.740 |     1.2
   46 |   0.8519 |     28.754 |   1.0196 |     32.647 |     1.2
   47 |   0.8422 |     28.545 |   1.0334 |     32.865 |     1.2
   48 |   0.8373 |     27.934 |   1.0191 |     32.647 |     1.2
   49 |   0.8287 |     27.862 |   1.0292 |     32.522 |     1.3
   50 |   0.8233 |     27.928 |   1.0169 |     32.272 |     1.3
   51 |   0.8118 |     27.323 |   1.0063 |     31.336 |     1.3
   52 |   0.7963 |     26.431 |   1.0167 |     32.335 |     1.4
   53 |   0.7976 |     26.844 |   1.0290 |     32.740 |     1.4
   54 |   0.7918 |     26.596 |   1.0095 |     31.398 |     1.4
   55 |   0.7880 |     26.101 |   0.9937 |     30.774 |     1.4
   56 |   0.7743 |     26.040 |   1.0031 |     30.836 |     1.4
   57 |   0.7636 |     25.429 |   0.9955 |     30.680 |     1.5
   58 |   0.7595 |     25.220 |   0.9957 |     30.649 |     1.5
   59 |   0.7529 |     24.846 |   1.0124 |     31.492 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 2,732,482

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1775 |     59.374 |   1.6023 |     45.350 |     0.1
    2 |   1.4781 |     46.103 |   1.4071 |     45.350 |     0.2
    3 |   1.3923 |     45.520 |   1.3701 |     43.883 |     0.2
    4 |   1.3499 |     44.254 |   1.3318 |     42.353 |     0.3
    5 |   1.3209 |     43.775 |   1.3026 |     42.104 |     0.4
    6 |   1.2886 |     42.679 |   1.2857 |     41.261 |     0.5
    7 |   1.2643 |     41.942 |   1.2614 |     41.042 |     0.6
    8 |   1.2347 |     40.814 |   1.2331 |     39.607 |     0.7
    9 |   1.2049 |     39.718 |   1.2206 |     39.576 |     0.8
   10 |   1.1813 |     38.815 |   1.2067 |     38.858 |     0.9
   11 |   1.1538 |     38.414 |   1.1911 |     38.483 |     1.0
   12 |   1.1333 |     37.489 |   1.1658 |     37.797 |     1.1
   13 |   1.1032 |     36.449 |   1.1511 |     36.829 |     1.2
   14 |   1.0807 |     36.118 |   1.1360 |     36.392 |     1.3
   15 |   1.0519 |     34.764 |   1.1192 |     36.517 |     1.4
   16 |   1.0332 |     34.098 |   1.1068 |     36.205 |     1.5
   17 |   1.0070 |     33.207 |   1.0805 |     34.863 |     1.6
   18 |   0.9870 |     32.519 |   1.0873 |     34.800 |     1.7
   19 |   0.9716 |     32.304 |   1.0687 |     34.395 |     1.8
   20 |   0.9430 |     31.440 |   1.0592 |     34.457 |     1.9
   21 |   0.9220 |     30.680 |   1.0470 |     34.395 |     2.0
   22 |   0.9086 |     30.493 |   1.0200 |     33.146 |     2.1
   23 |   0.8828 |     29.310 |   1.0330 |     33.739 |     2.1
   24 |   0.8578 |     28.517 |   1.0127 |     33.177 |     2.2
   25 |   0.8359 |     27.813 |   1.0159 |     33.177 |     2.3
   26 |   0.8192 |     27.328 |   1.0034 |     33.115 |     2.4
   27 |   0.8043 |     27.020 |   0.9983 |     31.991 |     2.5
   28 |   0.7818 |     26.321 |   1.0036 |     32.303 |     2.6
   29 |   0.7701 |     25.859 |   0.9829 |     31.586 |     2.7
   30 |   0.7631 |     25.473 |   0.9950 |     32.210 |     2.7
   31 |   0.7441 |     25.138 |   0.9777 |     30.899 |     2.8
   32 |   0.7248 |     24.499 |   0.9593 |     30.836 |     2.9
   33 |   0.7111 |     23.844 |   0.9896 |     31.367 |     3.0
   34 |   0.7069 |     23.685 |   0.9679 |     30.150 |     3.1
   35 |   0.6794 |     22.650 |   0.9623 |     29.963 |     3.2
   36 |   0.6685 |     22.138 |   0.9736 |     30.524 |     3.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 2,526,050

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5457 |     67.784 |   1.9966 |     58.708 |     0.1
    2 |   1.7699 |     50.710 |   1.5740 |     45.350 |     0.2
    3 |   1.5057 |     46.131 |   1.4532 |     45.350 |     0.2
    4 |   1.4397 |     46.109 |   1.4198 |     45.350 |     0.3
    5 |   1.4173 |     46.125 |   1.4058 |     45.350 |     0.4
    6 |   1.4063 |     46.219 |   1.3983 |     45.662 |     0.5
    7 |   1.3999 |     46.208 |   1.3935 |     45.350 |     0.6
    8 |   1.3967 |     46.120 |   1.3885 |     45.350 |     0.7
    9 |   1.3927 |     46.252 |   1.3863 |     45.350 |     0.7
   10 |   1.3910 |     46.125 |   1.3843 |     45.350 |     0.8
   11 |   1.3792 |     45.778 |   1.3692 |     44.039 |     0.9
   12 |   1.3619 |     44.903 |   1.3510 |     43.945 |     1.0
   13 |   1.3479 |     44.815 |   1.3355 |     43.851 |     1.1
   14 |   1.3391 |     44.529 |   1.3313 |     43.633 |     1.1
   15 |   1.3288 |     44.578 |   1.3195 |     43.727 |     1.2
   16 |   1.3229 |     44.540 |   1.3172 |     43.508 |     1.3
   17 |   1.3155 |     44.265 |   1.3153 |     42.946 |     1.4
   18 |   1.3149 |     44.155 |   1.3116 |     43.196 |     1.5
   19 |   1.3034 |     43.890 |   1.3043 |     42.946 |     1.6
   20 |   1.2935 |     43.742 |   1.2897 |     43.165 |     1.7
   21 |   1.2900 |     43.389 |   1.2955 |     42.572 |     1.7
   22 |   1.2798 |     42.966 |   1.2831 |     41.854 |     1.8
   23 |   1.2766 |     42.768 |   1.2788 |     41.916 |     1.9
   24 |   1.2655 |     42.668 |   1.2724 |     42.010 |     2.0
   25 |   1.2617 |     42.443 |   1.2815 |     41.417 |     2.1
   26 |   1.2538 |     42.300 |   1.2596 |     41.823 |     2.2
   27 |   1.2386 |     41.931 |   1.2549 |     41.604 |     2.2
   28 |   1.2342 |     41.656 |   1.2517 |     41.479 |     2.3
   29 |   1.2320 |     41.309 |   1.2615 |     41.479 |     2.4
   30 |   1.2266 |     41.270 |   1.2560 |     41.230 |     2.5
   31 |   1.2220 |     41.133 |   1.2532 |     40.793 |     2.6
   32 |   1.2161 |     41.100 |   1.2325 |     40.262 |     2.7
   33 |   1.2027 |     40.280 |   1.2296 |     40.137 |     2.7
   34 |   1.1962 |     40.048 |   1.2140 |     40.012 |     2.8
   35 |   1.1895 |     39.740 |   1.2291 |     40.387 |     2.9
   36 |   1.1867 |     39.636 |   1.2053 |     39.763 |     3.0
   37 |   1.1816 |     39.415 |   1.2132 |     39.950 |     3.1
   38 |   1.1804 |     39.597 |   1.2132 |     40.543 |     3.2
   39 |   1.1772 |     39.779 |   1.2103 |     39.388 |     3.2
   40 |   1.1615 |     39.074 |   1.1989 |     39.513 |     3.3
   41 |   1.1557 |     39.003 |   1.1986 |     39.139 |     3.4
   42 |   1.1463 |     38.557 |   1.1943 |     38.951 |     3.5
   43 |   1.1407 |     38.408 |   1.1836 |     38.795 |     3.6
   44 |   1.1413 |     38.260 |   1.1963 |     39.107 |     3.6
   45 |   1.1403 |     38.562 |   1.1855 |     39.232 |     3.7
   46 |   1.1268 |     37.781 |   1.1723 |     38.764 |     3.8
   47 |   1.1240 |     37.973 |   1.1697 |     39.201 |     3.9
   48 |   1.1093 |     37.318 |   1.1765 |     38.452 |     4.0
   49 |   1.1057 |     37.170 |   1.1717 |     37.672 |     4.0
   50 |   1.0964 |     36.625 |   1.1595 |     38.421 |     4.1
   51 |   1.1008 |     37.060 |   1.1527 |     37.547 |     4.2
   52 |   1.0849 |     36.157 |   1.1693 |     38.733 |     4.3
   53 |   1.0910 |     36.691 |   1.1483 |     37.703 |     4.4
   54 |   1.0834 |     36.179 |   1.1565 |     37.828 |     4.4
   55 |   1.0871 |     36.526 |   1.1521 |     37.859 |     4.5
   56 |   1.0734 |     35.799 |   1.1478 |     37.734 |     4.6
   57 |   1.0753 |     36.047 |   1.1773 |     38.202 |     4.7
   58 |   1.0750 |     36.091 |   1.1470 |     37.391 |     4.8
   59 |   1.0574 |     35.161 |   1.1461 |     37.422 |     4.8
   60 |   1.0490 |     35.100 |   1.1360 |     36.548 |     4.9
   61 |   1.0474 |     34.742 |   1.1514 |     37.672 |     5.0
   62 |   1.0605 |     35.414 |   1.1355 |     36.954 |     5.1
   63 |   1.0491 |     35.155 |   1.1326 |     37.172 |     5.2
   64 |   1.0298 |     34.286 |   1.1149 |     36.486 |     5.2
   65 |   1.0387 |     34.731 |   1.1518 |     37.765 |     5.3
   66 |   1.0400 |     35.062 |   1.1283 |     36.798 |     5.4
   67 |   1.0222 |     34.236 |   1.1323 |     37.328 |     5.5
   68 |   1.0087 |     33.691 |   1.1129 |     36.205 |     5.6
   69 |   0.9989 |     33.339 |   1.1093 |     35.081 |     5.7
   70 |   1.0083 |     33.889 |   1.1331 |     36.610 |     5.7
   71 |   0.9924 |     33.080 |   1.1094 |     36.392 |     5.8
   72 |   0.9871 |     33.300 |   1.1542 |     37.141 |     5.9
   73 |   1.0189 |     34.231 |   1.1185 |     36.205 |     6.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 406,690

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4094 |     59.792 |   1.7531 |     48.002 |     0.0
    2 |   1.5717 |     47.512 |   1.4378 |     44.881 |     0.0
    3 |   1.4084 |     45.663 |   1.3669 |     44.913 |     0.1
    4 |   1.3512 |     44.931 |   1.3178 |     43.539 |     0.1
    5 |   1.3004 |     43.533 |   1.2788 |     40.949 |     0.1
    6 |   1.2517 |     41.259 |   1.2222 |     39.513 |     0.1
    7 |   1.2046 |     39.839 |   1.1851 |     38.733 |     0.2
    8 |   1.1646 |     38.689 |   1.1664 |     37.984 |     0.2
    9 |   1.1305 |     38.006 |   1.1463 |     36.548 |     0.2
   10 |   1.1032 |     36.845 |   1.1193 |     36.330 |     0.2
   11 |   1.0628 |     35.199 |   1.0949 |     34.988 |     0.2
   12 |   1.0271 |     34.038 |   1.0738 |     34.207 |     0.3
   13 |   0.9954 |     32.541 |   1.0428 |     33.333 |     0.3
   14 |   0.9620 |     31.242 |   1.0305 |     32.022 |     0.3
   15 |   0.9278 |     30.003 |   0.9985 |     32.647 |     0.3
   16 |   0.8987 |     29.051 |   0.9839 |     31.648 |     0.4
   17 |   0.8701 |     28.187 |   0.9787 |     31.305 |     0.4
   18 |   0.8334 |     26.915 |   0.9541 |     31.117 |     0.4
   19 |   0.8110 |     25.809 |   0.9255 |     29.931 |     0.4
   20 |   0.7784 |     24.769 |   0.9188 |     30.181 |     0.4
   21 |   0.7544 |     24.202 |   0.9273 |     29.619 |     0.5
   22 |   0.7319 |     23.640 |   0.9026 |     28.464 |     0.5
   23 |   0.7061 |     22.297 |   0.9004 |     28.558 |     0.5
   24 |   0.6831 |     21.808 |   0.8949 |     28.308 |     0.5
   25 |   0.6611 |     20.806 |   0.8991 |     27.747 |     0.6
   26 |   0.6508 |     20.586 |   0.9001 |     28.027 |     0.6
   27 |   0.6302 |     19.997 |   0.8907 |     27.434 |     0.6
   28 |   0.6194 |     19.468 |   0.8823 |     27.247 |     0.6
   29 |   0.5985 |     18.912 |   0.8744 |     26.498 |     0.6
   30 |   0.5745 |     18.142 |   0.8707 |     26.904 |     0.7
   31 |   0.5568 |     17.498 |   0.8761 |     25.968 |     0.7
   32 |   0.5345 |     16.804 |   0.8813 |     26.935 |     0.7
   33 |   0.5322 |     16.689 |   0.8720 |     25.999 |     0.7
   34 |   0.5183 |     16.100 |   0.8753 |     25.468 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 568,674

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1774 |     58.620 |   1.5305 |     45.287 |     0.0
    2 |   1.4202 |     45.443 |   1.3333 |     41.823 |     0.0
    3 |   1.2989 |     42.338 |   1.2562 |     40.293 |     0.1
    4 |   1.2213 |     40.269 |   1.1904 |     38.702 |     0.1
    5 |   1.1547 |     38.320 |   1.1423 |     36.923 |     0.1
    6 |   1.0941 |     36.124 |   1.0953 |     35.456 |     0.1
    7 |   1.0372 |     33.774 |   1.0628 |     34.551 |     0.2
    8 |   0.9792 |     31.957 |   1.0199 |     33.271 |     0.2
    9 |   0.9247 |     29.992 |   0.9893 |     31.960 |     0.2
   10 |   0.8728 |     27.989 |   0.9709 |     31.367 |     0.2
   11 |   0.8290 |     26.794 |   0.9396 |     30.649 |     0.2
   12 |   0.7829 |     25.253 |   0.9206 |     29.401 |     0.3
   13 |   0.7347 |     23.558 |   0.8972 |     28.808 |     0.3
   14 |   0.7011 |     22.628 |   0.8946 |     28.402 |     0.3
   15 |   0.6595 |     21.009 |   0.8789 |     26.873 |     0.3
   16 |   0.6260 |     20.178 |   0.8799 |     27.122 |     0.4
   17 |   0.5844 |     18.472 |   0.8729 |     26.904 |     0.4
   18 |   0.5606 |     17.652 |   0.8794 |     26.654 |     0.4
   19 |   0.5383 |     17.223 |   0.8847 |     26.592 |     0.4
   20 |   0.5069 |     16.072 |   0.8623 |     26.186 |     0.4
   21 |   0.4846 |     15.637 |   0.8646 |     25.999 |     0.5
   22 |   0.4658 |     15.076 |   0.8697 |     25.874 |     0.5
   23 |   0.4345 |     13.672 |   0.8650 |     25.687 |     0.5
   24 |   0.4184 |     13.436 |   0.8538 |     24.875 |     0.5
   25 |   0.3959 |     12.511 |   0.8744 |     25.094 |     0.6
   26 |   0.3789 |     12.164 |   0.8887 |     25.468 |     0.6
   27 |   0.3691 |     11.839 |   0.8821 |     25.218 |     0.6
   28 |   0.3499 |     11.025 |   0.9006 |     24.906 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 2,433,634

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5373 |     66.810 |   2.0583 |     58.739 |     0.1
    2 |   1.8320 |     51.249 |   1.6112 |     45.350 |     0.2
    3 |   1.5253 |     46.169 |   1.4554 |     45.350 |     0.2
    4 |   1.4382 |     46.285 |   1.4151 |     45.350 |     0.3
    5 |   1.4145 |     46.114 |   1.4017 |     45.318 |     0.4
    6 |   1.4032 |     46.230 |   1.3933 |     45.350 |     0.5
    7 |   1.3965 |     46.136 |   1.3861 |     45.318 |     0.6
    8 |   1.3866 |     45.905 |   1.3710 |     44.757 |     0.7
    9 |   1.3710 |     45.162 |   1.3612 |     43.414 |     0.7
   10 |   1.3548 |     44.710 |   1.3456 |     43.352 |     0.8
   11 |   1.3437 |     44.413 |   1.3333 |     43.040 |     0.9
   12 |   1.3293 |     44.044 |   1.3257 |     43.227 |     1.0
   13 |   1.3180 |     43.709 |   1.3133 |     42.447 |     1.1
   14 |   1.3106 |     43.626 |   1.3035 |     41.667 |     1.2
   15 |   1.3030 |     43.296 |   1.3105 |     42.665 |     1.2
   16 |   1.2996 |     43.483 |   1.2932 |     41.979 |     1.3
   17 |   1.2864 |     43.010 |   1.2868 |     41.916 |     1.4
   18 |   1.2781 |     42.872 |   1.2821 |     41.823 |     1.5
   19 |   1.2666 |     42.256 |   1.2811 |     40.918 |     1.6
   20 |   1.2583 |     41.892 |   1.2664 |     40.699 |     1.7
   21 |   1.2505 |     41.788 |   1.2579 |     40.918 |     1.7
   22 |   1.2459 |     41.458 |   1.2665 |     40.886 |     1.8
   23 |   1.2371 |     41.430 |   1.2539 |     40.574 |     1.9
   24 |   1.2295 |     41.012 |   1.2445 |     40.605 |     2.0
   25 |   1.2249 |     40.808 |   1.2383 |     40.044 |     2.1
   26 |   1.2167 |     40.324 |   1.2313 |     40.137 |     2.2
   27 |   1.2088 |     40.467 |   1.2269 |     39.950 |     2.2
   28 |   1.1995 |     40.170 |   1.2259 |     39.825 |     2.3
   29 |   1.1883 |     39.856 |   1.2159 |     39.544 |     2.4
   30 |   1.1830 |     39.586 |   1.2247 |     40.075 |     2.5
   31 |   1.1758 |     39.223 |   1.2105 |     39.045 |     2.6
   32 |   1.1730 |     39.267 |   1.2176 |     39.295 |     2.6
   33 |   1.1690 |     39.025 |   1.2154 |     39.669 |     2.7
   34 |   1.1747 |     39.157 |   1.1995 |     38.639 |     2.8
   35 |   1.1583 |     38.683 |   1.2009 |     38.795 |     2.9
   36 |   1.1509 |     38.540 |   1.2057 |     39.139 |     3.0
   37 |   1.1443 |     38.392 |   1.1962 |     39.170 |     3.0
   38 |   1.1396 |     37.858 |   1.1785 |     38.546 |     3.1
   39 |   1.1278 |     37.500 |   1.1840 |     37.984 |     3.2
   40 |   1.1350 |     38.094 |   1.1830 |     38.421 |     3.3
   41 |   1.1269 |     38.017 |   1.1938 |     38.733 |     3.4
   42 |   1.1175 |     37.384 |   1.1819 |     38.670 |     3.5
   43 |   1.1081 |     36.900 |   1.1744 |     37.516 |     3.6
   44 |   1.1120 |     37.104 |   1.1790 |     38.077 |     3.6
   45 |   1.1054 |     37.076 |   1.1854 |     39.076 |     3.7
   46 |   1.0923 |     36.636 |   1.1712 |     37.953 |     3.8
   47 |   1.0820 |     36.674 |   1.1673 |     38.546 |     3.9
   48 |   1.0778 |     36.361 |   1.1496 |     36.423 |     4.0
   49 |   1.0674 |     35.744 |   1.1550 |     36.954 |     4.1
   50 |   1.0627 |     35.640 |   1.1557 |     37.422 |     4.2
   51 |   1.0649 |     35.860 |   1.1476 |     37.297 |     4.2
   52 |   1.0561 |     35.772 |   1.1448 |     37.079 |     4.3
   53 |   1.0408 |     35.370 |   1.1574 |     37.453 |     4.4
   54 |   1.0546 |     35.397 |   1.1360 |     36.673 |     4.5
   55 |   1.0432 |     35.238 |   1.1436 |     37.516 |     4.6
   56 |   1.0381 |     35.260 |   1.1431 |     37.016 |     4.6
   57 |   1.0347 |     35.128 |   1.1344 |     36.579 |     4.7
   58 |   1.0258 |     34.610 |   1.1328 |     36.236 |     4.8
   59 |   1.0166 |     34.506 |   1.1251 |     35.581 |     4.9
   60 |   1.0134 |     34.242 |   1.1184 |     35.924 |     5.0
   61 |   1.0181 |     34.588 |   1.1375 |     36.236 |     5.1
   62 |   1.0124 |     34.280 |   1.1242 |     36.361 |     5.1
   63 |   1.0032 |     34.247 |   1.1121 |     35.581 |     5.2
   64 |   1.0040 |     33.972 |   1.1168 |     36.548 |     5.3
   65 |   0.9844 |     33.548 |   1.1223 |     36.798 |     5.4
   66 |   0.9987 |     33.807 |   1.1306 |     36.798 |     5.5
   67 |   0.9949 |     33.911 |   1.1152 |     36.392 |     5.5
   68 |   0.9789 |     33.438 |   1.1074 |     35.830 |     5.6
   69 |   0.9788 |     32.998 |   1.1059 |     34.675 |     5.7
   70 |   0.9758 |     33.350 |   1.1211 |     36.423 |     5.8
   71 |   0.9681 |     32.970 |   1.1204 |     35.955 |     5.9
   72 |   0.9791 |     33.295 |   1.1171 |     35.581 |     5.9
   73 |   0.9610 |     32.502 |   1.1072 |     35.581 |     6.0
   74 |   0.9585 |     32.629 |   1.1018 |     36.486 |     6.1
   75 |   0.9538 |     32.425 |   1.0847 |     35.331 |     6.2
   76 |   0.9389 |     31.677 |   1.0945 |     35.456 |     6.3
   77 |   0.9388 |     31.781 |   1.1006 |     35.393 |     6.4
   78 |   0.9322 |     31.787 |   1.0899 |     34.707 |     6.4
   79 |   0.9242 |     31.644 |   1.0877 |     34.894 |     6.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,210,146

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4776 |     66.876 |   1.9267 |     54.775 |     0.0
    2 |   1.7205 |     49.268 |   1.5428 |     45.350 |     0.1
    3 |   1.4856 |     46.120 |   1.4399 |     45.350 |     0.1
    4 |   1.4280 |     46.120 |   1.4062 |     45.350 |     0.2
    5 |   1.4077 |     46.224 |   1.3960 |     45.350 |     0.2
    6 |   1.3877 |     46.120 |   1.3789 |     45.350 |     0.3
    7 |   1.3739 |     46.054 |   1.3691 |     45.350 |     0.3
    8 |   1.3565 |     45.734 |   1.3472 |     44.881 |     0.3
    9 |   1.3353 |     45.057 |   1.3239 |     44.600 |     0.4
   10 |   1.3138 |     44.347 |   1.2974 |     43.134 |     0.4
   11 |   1.2967 |     43.769 |   1.2745 |     42.634 |     0.5
   12 |   1.2621 |     42.723 |   1.2436 |     41.355 |     0.5
   13 |   1.2374 |     41.601 |   1.2308 |     40.918 |     0.6
   14 |   1.2216 |     41.281 |   1.2198 |     40.231 |     0.6
   15 |   1.1986 |     40.577 |   1.2039 |     38.577 |     0.6
   16 |   1.1819 |     40.032 |   1.1949 |     39.014 |     0.7
   17 |   1.1664 |     39.570 |   1.1872 |     39.107 |     0.7
   18 |   1.1431 |     38.738 |   1.1660 |     37.609 |     0.8
   19 |   1.1335 |     38.271 |   1.1600 |     37.235 |     0.8
   20 |   1.1247 |     37.973 |   1.1603 |     37.016 |     0.8
   21 |   1.1053 |     37.082 |   1.1421 |     36.423 |     0.9
   22 |   1.0805 |     36.366 |   1.1342 |     36.985 |     0.9
   23 |   1.0664 |     35.684 |   1.1137 |     35.893 |     1.0
   24 |   1.0429 |     34.770 |   1.0969 |     35.612 |     1.0
   25 |   1.0232 |     34.286 |   1.1048 |     35.955 |     1.0
   26 |   1.0013 |     33.179 |   1.0667 |     34.644 |     1.1
   27 |   0.9885 |     32.590 |   1.0854 |     35.050 |     1.1
   28 |   0.9847 |     32.766 |   1.0642 |     34.270 |     1.2
   29 |   0.9658 |     32.062 |   1.0554 |     33.833 |     1.2
   30 |   0.9499 |     31.957 |   1.0551 |     33.958 |     1.2
   31 |   0.9325 |     31.242 |   1.0600 |     34.863 |     1.3
   32 |   0.9185 |     30.697 |   1.0540 |     34.675 |     1.3
   33 |   0.8991 |     29.948 |   1.0374 |     33.770 |     1.4
   34 |   0.8815 |     29.095 |   1.0200 |     32.990 |     1.4
   35 |   0.8646 |     28.743 |   1.0247 |     32.272 |     1.5
   36 |   0.8618 |     28.330 |   1.0258 |     32.459 |     1.5
   37 |   0.8428 |     28.027 |   1.0055 |     32.397 |     1.5
   38 |   0.8247 |     27.031 |   1.0091 |     31.617 |     1.6
   39 |   0.8208 |     27.042 |   0.9906 |     30.930 |     1.6
   40 |   0.8107 |     26.750 |   0.9945 |     31.305 |     1.7
   41 |   0.7935 |     25.820 |   1.0101 |     30.899 |     1.7
   42 |   0.7835 |     25.561 |   0.9995 |     31.055 |     1.8
   43 |   0.7717 |     25.209 |   1.0085 |     31.554 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 359,586

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5399 |     67.861 |   2.0280 |     57.772 |     0.0
    2 |   1.8186 |     51.481 |   1.6023 |     45.381 |     0.0
    3 |   1.5091 |     45.580 |   1.4358 |     43.571 |     0.1
    4 |   1.4003 |     44.611 |   1.3705 |     43.196 |     0.1
    5 |   1.3478 |     43.879 |   1.3279 |     42.447 |     0.1
    6 |   1.3034 |     42.729 |   1.2928 |     41.199 |     0.1
    7 |   1.2655 |     41.738 |   1.2549 |     39.669 |     0.2
    8 |   1.2329 |     40.758 |   1.2375 |     40.481 |     0.2
    9 |   1.2030 |     40.059 |   1.2177 |     40.418 |     0.2
   10 |   1.1730 |     39.146 |   1.1925 |     39.076 |     0.2
   11 |   1.1331 |     37.307 |   1.1717 |     37.984 |     0.2
   12 |   1.1006 |     36.003 |   1.1420 |     36.267 |     0.3
   13 |   1.0662 |     34.577 |   1.1247 |     36.673 |     0.3
   14 |   1.0269 |     33.482 |   1.0897 |     34.707 |     0.3
   15 |   0.9975 |     32.210 |   1.0755 |     34.082 |     0.3
   16 |   0.9663 |     31.269 |   1.0648 |     33.552 |     0.4
   17 |   0.9329 |     30.174 |   1.0486 |     33.271 |     0.4
   18 |   0.9044 |     28.809 |   1.0311 |     32.147 |     0.4
   19 |   0.8730 |     27.989 |   1.0161 |     32.241 |     0.4
   20 |   0.8447 |     27.196 |   1.0196 |     33.021 |     0.4
   21 |   0.8235 |     26.398 |   1.0049 |     31.242 |     0.5
   22 |   0.7993 |     25.683 |   0.9958 |     31.211 |     0.5
   23 |   0.7715 |     24.631 |   0.9910 |     31.461 |     0.5
   24 |   0.7481 |     24.152 |   0.9816 |     30.243 |     0.5
   25 |   0.7243 |     23.206 |   0.9870 |     31.055 |     0.6
   26 |   0.7160 |     22.908 |   0.9936 |     31.055 |     0.6
   27 |   0.6880 |     22.215 |   0.9767 |     30.400 |     0.6
   28 |   0.6630 |     21.285 |   0.9741 |     29.619 |     0.6
   29 |   0.6421 |     20.360 |   0.9783 |     29.494 |     0.7
   30 |   0.6365 |     20.239 |   0.9618 |     28.964 |     0.7
   31 |   0.6117 |     19.314 |   0.9793 |     29.994 |     0.7
   32 |   0.5990 |     19.177 |   0.9903 |     29.775 |     0.7
   33 |   0.5923 |     18.962 |   0.9676 |     28.870 |     0.8
   34 |   0.5845 |     18.626 |   0.9770 |     28.995 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 412,130

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5651 |     68.769 |   2.0117 |     53.402 |     0.0
    2 |   1.7809 |     49.516 |   1.5906 |     45.350 |     0.0
    3 |   1.5140 |     46.125 |   1.4573 |     45.350 |     0.1
    4 |   1.4408 |     46.120 |   1.4210 |     45.350 |     0.1
    5 |   1.4162 |     46.202 |   1.4041 |     45.318 |     0.1
    6 |   1.4023 |     46.213 |   1.3943 |     45.381 |     0.1
    7 |   1.3937 |     45.905 |   1.3897 |     45.256 |     0.1
    8 |   1.3854 |     45.426 |   1.3783 |     44.039 |     0.2
    9 |   1.3743 |     45.145 |   1.3603 |     43.664 |     0.2
   10 |   1.3538 |     44.204 |   1.3479 |     42.759 |     0.2
   11 |   1.3343 |     43.610 |   1.3265 |     42.728 |     0.2
   12 |   1.3083 |     42.960 |   1.3116 |     42.166 |     0.3
   13 |   1.2840 |     42.393 |   1.2865 |     41.916 |     0.3
   14 |   1.2601 |     41.997 |   1.2723 |     41.042 |     0.3
   15 |   1.2394 |     41.210 |   1.2588 |     40.512 |     0.3
   16 |   1.2177 |     40.494 |   1.2487 |     40.668 |     0.3
   17 |   1.1959 |     39.823 |   1.2214 |     39.950 |     0.4
   18 |   1.1642 |     38.959 |   1.2074 |     38.951 |     0.4
   19 |   1.1448 |     38.436 |   1.2002 |     39.856 |     0.4
   20 |   1.1227 |     37.693 |   1.1938 |     38.733 |     0.4
   21 |   1.0968 |     36.729 |   1.1769 |     38.390 |     0.4
   22 |   1.0723 |     35.706 |   1.1562 |     37.141 |     0.5
   23 |   1.0565 |     35.249 |   1.1324 |     36.298 |     0.5
   24 |   1.0355 |     34.126 |   1.1426 |     36.236 |     0.5
   25 |   1.0170 |     33.873 |   1.1272 |     35.799 |     0.5
   26 |   1.0000 |     32.772 |   1.1163 |     35.175 |     0.5
   27 |   0.9742 |     32.177 |   1.1091 |     35.144 |     0.6
   28 |   0.9570 |     31.666 |   1.1076 |     34.644 |     0.6
   29 |   0.9415 |     31.137 |   1.1008 |     34.988 |     0.6
   30 |   0.9279 |     30.466 |   1.1063 |     35.050 |     0.6
   31 |   0.9013 |     29.436 |   1.1019 |     33.864 |     0.7
   32 |   0.8828 |     28.792 |   1.0993 |     34.051 |     0.7
   33 |   0.8633 |     28.380 |   1.0874 |     33.989 |     0.7
   34 |   0.8420 |     27.736 |   1.0814 |     32.803 |     0.7
   35 |   0.8289 |     27.345 |   1.0837 |     34.020 |     0.7
   36 |   0.8120 |     26.497 |   1.0958 |     34.332 |     0.8
   37 |   0.7913 |     25.776 |   1.1041 |     34.301 |     0.8
   38 |   0.7740 |     25.072 |   1.0768 |     33.021 |     0.8
   39 |   0.7598 |     24.917 |   1.0776 |     32.896 |     0.8
   40 |   0.7456 |     24.411 |   1.0706 |     32.615 |     0.8
   41 |   0.7307 |     23.795 |   1.0709 |     32.959 |     0.9
   42 |   0.7134 |     23.134 |   1.0660 |     32.366 |     0.9
   43 |   0.7013 |     22.914 |   1.0719 |     32.647 |     0.9
   44 |   0.6726 |     21.703 |   1.0554 |     31.461 |     0.9
   45 |   0.6607 |     21.241 |   1.0622 |     31.773 |     1.0
   46 |   0.6457 |     20.833 |   1.0757 |     31.554 |     1.0
   47 |   0.6261 |     19.788 |   1.0652 |     31.086 |     1.0
   48 |   0.6365 |     20.542 |   1.0821 |     30.868 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 894,530

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5893 |     69.094 |   2.0523 |     58.739 |     0.0
    2 |   1.8176 |     51.860 |   1.6159 |     45.350 |     0.1
    3 |   1.5339 |     46.164 |   1.4700 |     45.662 |     0.1
    4 |   1.4509 |     46.142 |   1.4273 |     45.350 |     0.1
    5 |   1.4227 |     46.114 |   1.4109 |     45.350 |     0.2
    6 |   1.4105 |     46.125 |   1.4011 |     45.350 |     0.2
    7 |   1.4044 |     46.191 |   1.3969 |     45.350 |     0.2
    8 |   1.3976 |     46.147 |   1.3914 |     45.318 |     0.3
    9 |   1.3946 |     46.125 |   1.3891 |     45.350 |     0.3
   10 |   1.3894 |     45.800 |   1.3810 |     45.350 |     0.3
   11 |   1.3778 |     45.443 |   1.3654 |     44.288 |     0.4
   12 |   1.3600 |     44.876 |   1.3558 |     44.132 |     0.4
   13 |   1.3432 |     44.270 |   1.3338 |     43.071 |     0.4
   14 |   1.3272 |     43.901 |   1.3200 |     42.790 |     0.5
   15 |   1.3098 |     43.411 |   1.3089 |     42.821 |     0.5
   16 |   1.2980 |     43.010 |   1.3049 |     42.541 |     0.5
   17 |   1.2909 |     42.977 |   1.2859 |     41.448 |     0.6
   18 |   1.2774 |     42.586 |   1.2843 |     41.698 |     0.6
   19 |   1.2643 |     42.118 |   1.2715 |     41.105 |     0.6
   20 |   1.2579 |     42.278 |   1.2753 |     41.105 |     0.7
   21 |   1.2468 |     41.535 |   1.2593 |     40.949 |     0.7
   22 |   1.2284 |     40.808 |   1.2522 |     40.512 |     0.7
   23 |   1.2242 |     40.764 |   1.2369 |     40.762 |     0.8
   24 |   1.2050 |     40.252 |   1.2272 |     39.856 |     0.8
   25 |   1.1863 |     39.520 |   1.2175 |     39.638 |     0.8
   26 |   1.1774 |     39.669 |   1.2165 |     39.139 |     0.9
   27 |   1.1633 |     38.777 |   1.1961 |     38.795 |     0.9
   28 |   1.1451 |     38.039 |   1.1872 |     38.764 |     0.9
   29 |   1.1313 |     37.605 |   1.1744 |     38.265 |     1.0
   30 |   1.1153 |     37.159 |   1.1662 |     38.109 |     1.0
   31 |   1.0978 |     36.410 |   1.1654 |     38.140 |     1.0
   32 |   1.0891 |     36.416 |   1.1561 |     37.547 |     1.1
   33 |   1.0716 |     35.717 |   1.1483 |     36.954 |     1.1
   34 |   1.0656 |     35.563 |   1.1434 |     37.422 |     1.1
   35 |   1.0472 |     34.742 |   1.1262 |     37.297 |     1.2
   36 |   1.0279 |     34.032 |   1.1183 |     36.548 |     1.2
   37 |   1.0127 |     33.801 |   1.1135 |     36.704 |     1.2
   38 |   1.0012 |     33.476 |   1.1007 |     35.612 |     1.3
   39 |   0.9860 |     32.959 |   1.1065 |     36.642 |     1.3
   40 |   0.9809 |     32.502 |   1.0947 |     36.205 |     1.4
   41 |   0.9759 |     32.673 |   1.0978 |     36.361 |     1.4
   42 |   0.9575 |     32.078 |   1.0816 |     34.988 |     1.4
   43 |   0.9362 |     31.671 |   1.0850 |     36.267 |     1.5
   44 |   0.9366 |     31.385 |   1.0653 |     34.956 |     1.5
   45 |   0.9197 |     30.856 |   1.0599 |     34.582 |     1.5
   46 |   0.9065 |     30.306 |   1.0615 |     33.958 |     1.6
   47 |   0.8877 |     29.690 |   1.0720 |     34.863 |     1.6
   48 |   0.8833 |     29.574 |   1.0597 |     34.363 |     1.7
   49 |   0.8728 |     28.985 |   1.0496 |     33.926 |     1.7
   50 |   0.8648 |     28.991 |   1.0466 |     33.645 |     1.7
   51 |   0.8437 |     28.236 |   1.0321 |     33.084 |     1.8
   52 |   0.8295 |     27.681 |   1.0340 |     32.959 |     1.8
   53 |   0.8235 |     27.378 |   1.0384 |     32.928 |     1.8
   54 |   0.8177 |     27.339 |   1.0265 |     33.645 |     1.9
   55 |   0.8103 |     26.998 |   1.0166 |     32.740 |     1.9
   56 |   0.7963 |     26.371 |   1.0180 |     31.960 |     1.9
   57 |   0.7856 |     26.255 |   1.0176 |     32.459 |     2.0
   58 |   0.7727 |     25.589 |   1.0266 |     31.305 |     2.0
   59 |   0.7639 |     25.523 |   1.0362 |     33.489 |     2.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,128,034

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0822 |     56.308 |   1.5172 |     45.537 |     0.0
    2 |   1.4096 |     45.107 |   1.3330 |     42.853 |     0.1
    3 |   1.2963 |     42.850 |   1.2569 |     40.200 |     0.1
    4 |   1.2238 |     40.577 |   1.1969 |     38.390 |     0.1
    5 |   1.1644 |     39.311 |   1.1631 |     37.609 |     0.2
    6 |   1.1041 |     36.328 |   1.1090 |     35.362 |     0.2
    7 |   1.0439 |     34.208 |   1.0795 |     34.457 |     0.2
    8 |   0.9794 |     31.886 |   1.0281 |     34.020 |     0.3
    9 |   0.9246 |     29.778 |   0.9800 |     32.147 |     0.3
   10 |   0.8616 |     27.730 |   0.9613 |     31.554 |     0.3
   11 |   0.8167 |     26.183 |   0.9357 |     29.588 |     0.4
   12 |   0.7642 |     24.488 |   0.9310 |     28.558 |     0.4
   13 |   0.7180 |     22.919 |   0.9117 |     28.340 |     0.5
   14 |   0.6689 |     21.257 |   0.8934 |     28.527 |     0.5
   15 |   0.6328 |     20.002 |   0.8767 |     28.121 |     0.5
   16 |   0.5928 |     18.929 |   0.8857 |     27.622 |     0.6
   17 |   0.5677 |     18.345 |   0.8567 |     26.030 |     0.6
   18 |   0.5296 |     16.887 |   0.8734 |     26.810 |     0.6
   19 |   0.5021 |     15.929 |   0.8713 |     25.749 |     0.7
   20 |   0.4726 |     14.999 |   0.8798 |     26.592 |     0.7
   21 |   0.4557 |     14.641 |   0.8606 |     26.030 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 634,210

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2249 |     60.860 |   1.6134 |     48.596 |     0.0
    2 |   1.4522 |     45.624 |   1.3603 |     42.072 |     0.0
    3 |   1.3102 |     42.889 |   1.2727 |     41.604 |     0.1
    4 |   1.2199 |     39.966 |   1.2053 |     39.326 |     0.1
    5 |   1.1512 |     38.094 |   1.1597 |     37.297 |     0.1
    6 |   1.0796 |     35.783 |   1.1006 |     35.050 |     0.1
    7 |   1.0107 |     32.777 |   1.0420 |     33.489 |     0.1
    8 |   0.9447 |     29.882 |   1.0063 |     31.898 |     0.1
    9 |   0.8685 |     27.928 |   0.9586 |     30.680 |     0.2
   10 |   0.8113 |     25.793 |   0.9382 |     29.806 |     0.2
   11 |   0.7489 |     23.740 |   0.9316 |     29.151 |     0.2
   12 |   0.6961 |     21.923 |   0.9084 |     28.433 |     0.2
   13 |   0.6430 |     20.178 |   0.8858 |     27.871 |     0.2
   14 |   0.5906 |     18.356 |   0.8725 |     27.060 |     0.2
   15 |   0.5483 |     16.755 |   0.8802 |     26.436 |     0.3
   16 |   0.5078 |     15.566 |   0.8617 |     26.467 |     0.3
   17 |   0.4650 |     14.239 |   0.8718 |     26.280 |     0.3
   18 |   0.4239 |     13.012 |   0.8796 |     25.936 |     0.3
   19 |   0.3929 |     11.856 |   0.8701 |     25.406 |     0.3
   20 |   0.3585 |     10.711 |   0.8930 |     25.655 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 532,770

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2324 |     61.047 |   1.6098 |     45.381 |     0.0
    2 |   1.4815 |     46.197 |   1.4120 |     45.350 |     0.0
    3 |   1.3953 |     46.020 |   1.3557 |     44.788 |     0.0
    4 |   1.3450 |     44.837 |   1.3110 |     42.821 |     0.1
    5 |   1.2911 |     43.362 |   1.2615 |     42.603 |     0.1
    6 |   1.2468 |     42.157 |   1.2175 |     39.950 |     0.1
    7 |   1.1979 |     40.423 |   1.1981 |     38.702 |     0.1
    8 |   1.1551 |     38.634 |   1.1591 |     37.484 |     0.1
    9 |   1.1095 |     37.346 |   1.1311 |     36.954 |     0.1
   10 |   1.0637 |     36.201 |   1.0994 |     35.986 |     0.1
   11 |   1.0130 |     34.396 |   1.0730 |     34.426 |     0.2
   12 |   0.9637 |     32.293 |   1.0403 |     33.677 |     0.2
   13 |   0.9076 |     30.031 |   1.0186 |     33.645 |     0.2
   14 |   0.8600 |     27.978 |   1.0015 |     31.461 |     0.2
   15 |   0.8023 |     25.996 |   0.9849 |     31.617 |     0.2
   16 |   0.7498 |     23.833 |   0.9761 |     30.337 |     0.2
   17 |   0.6994 |     22.061 |   0.9851 |     30.368 |     0.2
   18 |   0.6474 |     20.338 |   0.9544 |     28.496 |     0.3
   19 |   0.6075 |     19.039 |   0.9628 |     28.371 |     0.3
   20 |   0.5587 |     17.256 |   0.9725 |     28.340 |     0.3
   21 |   0.5169 |     15.659 |   0.9611 |     27.591 |     0.3
   22 |   0.4766 |     14.393 |   0.9520 |     27.122 |     0.3
   23 |   0.4341 |     13.122 |   0.9823 |     27.310 |     0.3
   24 |   0.4038 |     12.126 |   0.9710 |     26.748 |     0.4
   25 |   0.3727 |     11.234 |   0.9936 |     26.654 |     0.4
   26 |   0.3489 |     10.513 |   0.9964 |     26.717 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,322,466

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1774 |     59.649 |   1.6151 |     45.630 |     0.0
    2 |   1.4823 |     45.976 |   1.3993 |     44.070 |     0.1
    3 |   1.3628 |     44.325 |   1.3365 |     42.790 |     0.1
    4 |   1.2905 |     42.327 |   1.2683 |     40.762 |     0.2
    5 |   1.2325 |     40.654 |   1.2369 |     40.262 |     0.2
    6 |   1.1794 |     38.964 |   1.1884 |     38.327 |     0.2
    7 |   1.1250 |     36.768 |   1.1414 |     36.330 |     0.3
    8 |   1.0822 |     35.045 |   1.1033 |     35.050 |     0.3
    9 |   1.0234 |     33.201 |   1.0564 |     34.395 |     0.4
   10 |   0.9716 |     31.462 |   1.0323 |     33.833 |     0.4
   11 |   0.9262 |     30.312 |   1.0212 |     33.645 |     0.4
   12 |   0.8922 |     29.244 |   0.9919 |     31.742 |     0.5
   13 |   0.8455 |     27.565 |   0.9880 |     32.241 |     0.5
   14 |   0.8068 |     26.134 |   0.9649 |     31.149 |     0.5
   15 |   0.7722 |     24.862 |   0.9357 |     30.243 |     0.6
   16 |   0.7386 |     24.026 |   0.9821 |     31.055 |     0.6
   17 |   0.7100 |     23.007 |   0.9286 |     28.964 |     0.7
   18 |   0.6840 |     22.303 |   0.9350 |     28.340 |     0.7
   19 |   0.6368 |     20.657 |   0.9339 |     28.995 |     0.7
   20 |   0.5983 |     19.193 |   0.9267 |     28.059 |     0.8
   21 |   0.5800 |     18.676 |   0.9311 |     29.276 |     0.8
   22 |   0.5648 |     18.186 |   0.9175 |     28.464 |     0.9
   23 |   0.5448 |     17.817 |   0.9251 |     27.216 |     0.9
   24 |   0.5255 |     17.151 |   0.9236 |     28.808 |     0.9
   25 |   0.4894 |     15.670 |   0.9390 |     28.652 |     1.0
   26 |   0.4699 |     15.368 |   0.9121 |     27.122 |     1.0
   27 |   0.4430 |     14.113 |   0.9273 |     26.467 |     1.1
   28 |   0.4279 |     13.667 |   0.9433 |     26.685 |     1.1
   29 |   0.4174 |     13.320 |   0.9423 |     28.152 |     1.1
   30 |   0.4204 |     13.727 |   0.9318 |     26.467 |     1.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 302,370

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6319 |     70.564 |   2.0528 |     58.708 |     0.0
    2 |   1.8115 |     51.073 |   1.5965 |     45.443 |     0.0
    3 |   1.5161 |     46.147 |   1.4568 |     45.350 |     0.0
    4 |   1.4387 |     46.131 |   1.4166 |     45.350 |     0.1
    5 |   1.3986 |     46.031 |   1.3738 |     45.443 |     0.1
    6 |   1.3692 |     45.459 |   1.3558 |     44.788 |     0.1
    7 |   1.3463 |     45.167 |   1.3265 |     43.727 |     0.1
    8 |   1.3246 |     44.821 |   1.3077 |     44.288 |     0.1
    9 |   1.3016 |     44.556 |   1.2918 |     44.070 |     0.1
   10 |   1.2805 |     44.050 |   1.2690 |     43.071 |     0.2
   11 |   1.2609 |     43.621 |   1.2576 |     42.821 |     0.2
   12 |   1.2407 |     42.459 |   1.2430 |     41.604 |     0.2
   13 |   1.2183 |     42.002 |   1.2313 |     41.042 |     0.2
   14 |   1.2028 |     41.325 |   1.2221 |     40.824 |     0.2
   15 |   1.1813 |     40.703 |   1.2093 |     40.449 |     0.2
   16 |   1.1664 |     40.004 |   1.1935 |     40.106 |     0.2
   17 |   1.1460 |     39.305 |   1.1833 |     38.795 |     0.3
   18 |   1.1310 |     38.804 |   1.1816 |     39.045 |     0.3
   19 |   1.1135 |     38.326 |   1.1626 |     38.764 |     0.3
   20 |   1.0956 |     37.439 |   1.1500 |     37.984 |     0.3
   21 |   1.0743 |     36.443 |   1.1316 |     36.891 |     0.3
   22 |   1.0599 |     36.008 |   1.1221 |     36.579 |     0.3
   23 |   1.0409 |     35.238 |   1.1027 |     35.581 |     0.3
   24 |   1.0184 |     34.550 |   1.0903 |     35.643 |     0.4
   25 |   1.0024 |     34.164 |   1.0801 |     35.206 |     0.4
   26 |   0.9888 |     33.625 |   1.0845 |     35.331 |     0.4
   27 |   0.9743 |     33.465 |   1.0752 |     34.551 |     0.4
   28 |   0.9649 |     32.772 |   1.0624 |     34.238 |     0.4
   29 |   0.9454 |     32.199 |   1.0580 |     33.864 |     0.4
   30 |   0.9346 |     31.985 |   1.0655 |     33.115 |     0.4
   31 |   0.9242 |     31.220 |   1.0609 |     33.645 |     0.5
   32 |   0.9091 |     30.757 |   1.0593 |     33.177 |     0.5
   33 |   0.9091 |     30.658 |   1.0417 |     33.240 |     0.5
   34 |   0.8916 |     30.295 |   1.0390 |     32.491 |     0.5
   35 |   0.8800 |     29.992 |   1.0345 |     33.240 |     0.5
   36 |   0.8669 |     29.299 |   1.0428 |     31.929 |     0.5
   37 |   0.8581 |     29.024 |   1.0126 |     32.241 |     0.5
   38 |   0.8476 |     28.677 |   1.0248 |     32.179 |     0.6
   39 |   0.8355 |     27.989 |   1.0178 |     31.242 |     0.6
   40 |   0.8207 |     27.659 |   1.0179 |     31.336 |     0.6
   41 |   0.8199 |     27.741 |   1.0217 |     31.492 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 962,722

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5987 |     71.037 |   2.0334 |     58.708 |     0.0
    2 |   1.7713 |     49.620 |   1.5698 |     45.350 |     0.1
    3 |   1.4972 |     46.120 |   1.4463 |     45.350 |     0.1
    4 |   1.4315 |     46.142 |   1.4166 |     45.350 |     0.1
    5 |   1.4118 |     46.125 |   1.4043 |     45.350 |     0.2
    6 |   1.4063 |     46.142 |   1.3935 |     45.350 |     0.2
    7 |   1.3963 |     46.120 |   1.3950 |     44.788 |     0.2
    8 |   1.3935 |     46.202 |   1.3861 |     45.350 |     0.3
    9 |   1.3880 |     46.136 |   1.3778 |     45.350 |     0.3
   10 |   1.3774 |     46.109 |   1.3642 |     45.350 |     0.3
   11 |   1.3629 |     46.114 |   1.3492 |     45.381 |     0.4
   12 |   1.3408 |     45.663 |   1.3226 |     44.195 |     0.4
   13 |   1.3305 |     45.624 |   1.3142 |     44.850 |     0.4
   14 |   1.3148 |     45.101 |   1.3117 |     43.976 |     0.5
   15 |   1.3062 |     44.870 |   1.2917 |     43.851 |     0.5
   16 |   1.2899 |     44.628 |   1.2754 |     42.853 |     0.5
   17 |   1.2794 |     44.507 |   1.2705 |     43.851 |     0.6
   18 |   1.2750 |     44.479 |   1.2679 |     43.539 |     0.6
   19 |   1.2593 |     44.182 |   1.2658 |     43.446 |     0.6
   20 |   1.2557 |     44.000 |   1.2471 |     44.070 |     0.7
   21 |   1.2436 |     43.395 |   1.2407 |     42.634 |     0.7
   22 |   1.2275 |     42.878 |   1.2499 |     42.946 |     0.7
   23 |   1.2208 |     42.250 |   1.2265 |     41.698 |     0.8
   24 |   1.2131 |     42.300 |   1.2270 |     40.886 |     0.8
   25 |   1.1961 |     41.601 |   1.2147 |     41.011 |     0.8
   26 |   1.1824 |     40.880 |   1.2147 |     41.199 |     0.9
   27 |   1.1639 |     40.351 |   1.2110 |     40.918 |     0.9
   28 |   1.1499 |     39.751 |   1.2092 |     40.512 |     0.9
   29 |   1.1368 |     38.694 |   1.1750 |     38.639 |     1.0
   30 |   1.1280 |     38.149 |   1.1697 |     38.296 |     1.0
   31 |   1.1079 |     37.649 |   1.1560 |     37.921 |     1.0
   32 |   1.0957 |     36.933 |   1.1629 |     38.202 |     1.1
   33 |   1.0840 |     36.559 |   1.1544 |     37.484 |     1.1
   34 |   1.0755 |     36.388 |   1.1314 |     36.985 |     1.1
   35 |   1.0564 |     35.871 |   1.1283 |     35.893 |     1.2
   36 |   1.0371 |     35.243 |   1.1113 |     35.830 |     1.2
   37 |   1.0161 |     34.737 |   1.1162 |     35.456 |     1.2
   38 |   1.0054 |     34.131 |   1.0883 |     35.050 |     1.3
   39 |   1.0025 |     33.939 |   1.0894 |     35.050 |     1.3
   40 |   0.9908 |     33.625 |   1.0783 |     34.145 |     1.3
   41 |   0.9708 |     32.954 |   1.0592 |     33.801 |     1.3
   42 |   0.9600 |     32.607 |   1.0924 |     34.488 |     1.4
   43 |   0.9484 |     32.034 |   1.0734 |     34.800 |     1.4
   44 |   0.9434 |     32.084 |   1.1033 |     35.924 |     1.4
   45 |   0.9505 |     32.458 |   1.0643 |     34.082 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 515,298

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3143 |     63.524 |   1.6561 |     48.283 |     0.0
    2 |   1.4995 |     46.450 |   1.4109 |     45.350 |     0.0
    3 |   1.3948 |     45.795 |   1.3499 |     43.851 |     0.0
    4 |   1.3311 |     44.133 |   1.3045 |     42.228 |     0.1
    5 |   1.2844 |     42.971 |   1.2582 |     41.261 |     0.1
    6 |   1.2440 |     41.953 |   1.2350 |     41.136 |     0.1
    7 |   1.2133 |     40.428 |   1.1980 |     39.014 |     0.1
    8 |   1.1855 |     39.839 |   1.1928 |     38.639 |     0.1
    9 |   1.1555 |     38.815 |   1.1680 |     38.140 |     0.1
   10 |   1.1299 |     37.946 |   1.1448 |     37.734 |     0.1
   11 |   1.1006 |     37.071 |   1.1277 |     37.422 |     0.2
   12 |   1.0757 |     36.295 |   1.1110 |     36.049 |     0.2
   13 |   1.0456 |     35.117 |   1.1081 |     35.674 |     0.2
   14 |   1.0123 |     33.807 |   1.0679 |     34.956 |     0.2
   15 |   0.9833 |     32.596 |   1.0638 |     34.457 |     0.2
   16 |   0.9476 |     31.622 |   1.0385 |     33.396 |     0.2
   17 |   0.9109 |     30.009 |   1.0303 |     32.335 |     0.2
   18 |   0.8811 |     28.924 |   1.0080 |     31.461 |     0.3
   19 |   0.8510 |     27.939 |   0.9986 |     31.523 |     0.3
   20 |   0.8196 |     27.081 |   0.9886 |     30.899 |     0.3
   21 |   0.7900 |     26.117 |   0.9774 |     30.431 |     0.3
   22 |   0.7625 |     24.879 |   0.9736 |     30.556 |     0.3
   23 |   0.7235 |     23.596 |   0.9645 |     29.557 |     0.3
   24 |   0.7062 |     23.173 |   0.9421 |     28.964 |     0.3
   25 |   0.6736 |     22.154 |   0.9466 |     28.433 |     0.4
   26 |   0.6442 |     20.701 |   0.9384 |     28.090 |     0.4
   27 |   0.6172 |     19.903 |   0.9373 |     28.558 |     0.4
   28 |   0.6008 |     19.215 |   0.9313 |     27.684 |     0.4
   29 |   0.5680 |     18.411 |   0.9626 |     28.652 |     0.4
   30 |   0.5533 |     17.790 |   0.9476 |     27.497 |     0.4
   31 |   0.5404 |     17.652 |   0.9415 |     26.873 |     0.4
   32 |   0.5177 |     16.859 |   0.9470 |     27.185 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 303,074

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6212 |     68.830 |   2.0455 |     58.708 |     0.0
    2 |   1.8043 |     50.809 |   1.6022 |     45.350 |     0.0
    3 |   1.5191 |     46.125 |   1.4537 |     45.350 |     0.0
    4 |   1.4398 |     46.213 |   1.4195 |     45.350 |     0.1
    5 |   1.4117 |     46.120 |   1.3949 |     45.350 |     0.1
    6 |   1.3915 |     46.197 |   1.3725 |     45.350 |     0.1
    7 |   1.3670 |     45.718 |   1.3491 |     44.413 |     0.1
    8 |   1.3480 |     45.090 |   1.3286 |     43.321 |     0.1
    9 |   1.3208 |     44.006 |   1.3057 |     42.416 |     0.1
   10 |   1.2974 |     43.582 |   1.2781 |     42.260 |     0.1
   11 |   1.2775 |     42.944 |   1.2644 |     42.010 |     0.2
   12 |   1.2591 |     42.514 |   1.2432 |     40.793 |     0.2
   13 |   1.2352 |     41.309 |   1.2298 |     40.293 |     0.2
   14 |   1.2145 |     40.417 |   1.2218 |     39.607 |     0.2
   15 |   1.1900 |     39.630 |   1.2028 |     38.858 |     0.2
   16 |   1.1743 |     39.206 |   1.1951 |     38.670 |     0.2
   17 |   1.1556 |     38.827 |   1.1789 |     37.890 |     0.2
   18 |   1.1339 |     38.441 |   1.1682 |     37.984 |     0.3
   19 |   1.1138 |     38.056 |   1.1606 |     37.609 |     0.3
   20 |   1.0988 |     37.390 |   1.1469 |     37.547 |     0.3
   21 |   1.0791 |     37.038 |   1.1437 |     37.547 |     0.3
   22 |   1.0597 |     36.168 |   1.1449 |     36.985 |     0.3
   23 |   1.0456 |     35.700 |   1.1234 |     36.673 |     0.3
   24 |   1.0313 |     35.106 |   1.1240 |     36.174 |     0.4
   25 |   1.0137 |     34.841 |   1.1172 |     36.330 |     0.4
   26 |   0.9955 |     34.175 |   1.1075 |     36.017 |     0.4
   27 |   0.9803 |     33.262 |   1.0966 |     35.581 |     0.4
   28 |   0.9633 |     32.992 |   1.1111 |     36.017 |     0.4
   29 |   0.9445 |     32.089 |   1.1024 |     35.175 |     0.4
   30 |   0.9200 |     31.352 |   1.1023 |     35.081 |     0.4
   31 |   0.9158 |     31.093 |   1.1039 |     34.644 |     0.5
   32 |   0.9053 |     30.664 |   1.0845 |     34.988 |     0.5
   33 |   0.8904 |     30.113 |   1.0902 |     34.332 |     0.5
   34 |   0.8683 |     29.249 |   1.0738 |     33.333 |     0.5
   35 |   0.8479 |     28.413 |   1.0975 |     33.958 |     0.5
   36 |   0.8297 |     27.813 |   1.0673 |     33.084 |     0.5
   37 |   0.8186 |     27.416 |   1.0743 |     34.176 |     0.5
   38 |   0.8038 |     26.640 |   1.0519 |     33.208 |     0.6
   39 |   0.7969 |     26.585 |   1.0595 |     32.553 |     0.6
   40 |   0.7823 |     26.046 |   1.0583 |     32.615 |     0.6
   41 |   0.7708 |     25.556 |   1.0603 |     32.303 |     0.6
   42 |   0.7583 |     25.050 |   1.0522 |     31.898 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,829,634

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2545 |     61.773 |   1.6761 |     48.283 |     0.1
    2 |   1.5169 |     46.428 |   1.4284 |     45.350 |     0.1
    3 |   1.4195 |     46.120 |   1.4018 |     45.350 |     0.2
    4 |   1.4024 |     46.208 |   1.3964 |     45.350 |     0.3
    5 |   1.3950 |     46.103 |   1.3856 |     45.350 |     0.4
    6 |   1.3845 |     45.833 |   1.3751 |     43.851 |     0.4
    7 |   1.3603 |     44.870 |   1.3472 |     43.695 |     0.5
    8 |   1.3411 |     44.567 |   1.3364 |     43.383 |     0.6
    9 |   1.3264 |     44.100 |   1.3157 |     42.541 |     0.7
   10 |   1.3090 |     43.819 |   1.3106 |     42.821 |     0.8
   11 |   1.2935 |     43.224 |   1.2969 |     43.040 |     0.8
   12 |   1.2806 |     43.048 |   1.2900 |     42.572 |     0.9
   13 |   1.2701 |     42.696 |   1.2816 |     42.228 |     1.0
   14 |   1.2588 |     42.366 |   1.2585 |     41.479 |     1.1
   15 |   1.2467 |     42.250 |   1.2767 |     41.542 |     1.1
   16 |   1.2405 |     42.013 |   1.2608 |     41.074 |     1.2
   17 |   1.2313 |     41.540 |   1.2513 |     40.762 |     1.3
   18 |   1.2198 |     41.353 |   1.2480 |     41.105 |     1.4
   19 |   1.2096 |     41.100 |   1.2401 |     40.980 |     1.4
   20 |   1.2005 |     41.089 |   1.2390 |     40.262 |     1.5
   21 |   1.1912 |     40.445 |   1.2402 |     40.137 |     1.6
   22 |   1.1807 |     40.269 |   1.2310 |     40.231 |     1.7
   23 |   1.1699 |     39.652 |   1.2251 |     40.169 |     1.7
   24 |   1.1696 |     39.515 |   1.2063 |     39.357 |     1.8
   25 |   1.1472 |     39.041 |   1.2007 |     40.044 |     1.9
   26 |   1.1351 |     38.540 |   1.1977 |     39.107 |     2.0
   27 |   1.1266 |     38.177 |   1.1975 |     39.076 |     2.0
   28 |   1.1135 |     37.775 |   1.1927 |     39.107 |     2.1
   29 |   1.1053 |     37.522 |   1.1885 |     39.045 |     2.2
   30 |   1.0998 |     37.522 |   1.1765 |     38.452 |     2.3
   31 |   1.0891 |     37.566 |   1.1713 |     38.140 |     2.3
   32 |   1.0719 |     36.674 |   1.1699 |     38.015 |     2.4
   33 |   1.0598 |     36.388 |   1.1828 |     38.327 |     2.5
   34 |   1.0491 |     35.986 |   1.1786 |     39.014 |     2.6
   35 |   1.0394 |     35.755 |   1.1584 |     38.702 |     2.7
   36 |   1.0209 |     35.100 |   1.1683 |     37.578 |     2.7
   37 |   1.0240 |     35.018 |   1.1439 |     38.514 |     2.8
   38 |   1.0268 |     35.386 |   1.1661 |     38.514 |     2.9
   39 |   0.9966 |     34.264 |   1.1498 |     37.609 |     3.0
   40 |   0.9912 |     34.115 |   1.1502 |     37.484 |     3.0
   41 |   0.9838 |     33.807 |   1.1377 |     38.265 |     3.1
   42 |   0.9700 |     33.284 |   1.1417 |     37.235 |     3.2
   43 |   0.9634 |     32.926 |   1.1464 |     37.516 |     3.3
   44 |   0.9537 |     32.981 |   1.1306 |     37.016 |     3.3
   45 |   0.9368 |     32.133 |   1.1235 |     36.767 |     3.4
   46 |   0.9383 |     31.996 |   1.1294 |     37.079 |     3.5
   47 |   0.9214 |     31.627 |   1.1289 |     35.799 |     3.6
   48 |   0.9276 |     31.776 |   1.1295 |     36.642 |     3.7
   49 |   0.9048 |     30.867 |   1.1248 |     37.047 |     3.7
   50 |   0.8833 |     30.053 |   1.1128 |     35.705 |     3.8
   51 |   0.8777 |     30.240 |   1.1172 |     36.423 |     3.9
   52 |   0.8699 |     30.080 |   1.1263 |     36.954 |     4.0
   53 |   0.8460 |     29.057 |   1.1081 |     35.924 |     4.0
   54 |   0.8381 |     28.523 |   1.1090 |     35.487 |     4.1
   55 |   0.8314 |     28.660 |   1.1038 |     35.237 |     4.2
   56 |   0.8137 |     27.967 |   1.1046 |     35.019 |     4.3
   57 |   0.8099 |     27.956 |   1.0968 |     35.581 |     4.3
   58 |   0.7909 |     26.838 |   1.1133 |     34.519 |     4.4
   59 |   0.7815 |     26.805 |   1.1030 |     33.958 |     4.5
   60 |   0.7712 |     26.437 |   1.0966 |     34.863 |     4.6
   61 |   0.7723 |     26.327 |   1.1158 |     35.830 |     4.6
   62 |   0.7519 |     25.694 |   1.1178 |     34.395 |     4.7
   63 |   0.7373 |     25.325 |   1.1183 |     34.675 |     4.8
   64 |   0.7279 |     25.099 |   1.1004 |     33.989 |     4.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,425,826

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1081 |     58.119 |   1.5286 |     45.474 |     0.0
    2 |   1.4255 |     45.652 |   1.3599 |     43.914 |     0.1
    3 |   1.3164 |     43.450 |   1.2684 |     40.574 |     0.1
    4 |   1.2420 |     40.968 |   1.2149 |     38.764 |     0.2
    5 |   1.1748 |     38.948 |   1.1633 |     37.328 |     0.2
    6 |   1.1215 |     36.983 |   1.1361 |     36.891 |     0.2
    7 |   1.0704 |     35.117 |   1.0892 |     34.738 |     0.3
    8 |   1.0179 |     33.465 |   1.0489 |     33.427 |     0.3
    9 |   0.9693 |     31.765 |   1.0252 |     33.365 |     0.4
   10 |   0.9190 |     30.179 |   0.9815 |     31.679 |     0.4
   11 |   0.8768 |     28.666 |   0.9689 |     30.899 |     0.4
   12 |   0.8344 |     27.273 |   0.9612 |     30.868 |     0.5
   13 |   0.7954 |     26.007 |   0.9586 |     30.462 |     0.5
   14 |   0.7711 |     24.774 |   0.9246 |     29.557 |     0.6
   15 |   0.7334 |     23.773 |   0.9003 |     29.182 |     0.6
   16 |   0.6839 |     22.072 |   0.9039 |     28.308 |     0.6
   17 |   0.6669 |     21.532 |   0.8942 |     28.964 |     0.7
   18 |   0.6500 |     20.580 |   0.9096 |     28.620 |     0.7
   19 |   0.6117 |     19.771 |   0.8913 |     28.152 |     0.8
   20 |   0.6182 |     20.129 |   0.9271 |     28.995 |     0.8
   21 |   0.6174 |     20.024 |   0.8939 |     28.371 |     0.9
   22 |   0.5509 |     17.668 |   0.8714 |     26.186 |     0.9
   23 |   0.5229 |     16.870 |   0.8801 |     27.216 |     0.9
   24 |   0.4976 |     15.957 |   0.8982 |     26.685 |     1.0
   25 |   0.4716 |     15.164 |   0.8958 |     26.529 |     1.0
   26 |   0.4515 |     14.757 |   0.8751 |     25.874 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 2,484,546

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6057 |     69.089 |   2.0191 |     58.708 |     0.1
    2 |   1.8010 |     51.393 |   1.5963 |     45.350 |     0.2
    3 |   1.5125 |     46.164 |   1.4533 |     45.350 |     0.2
    4 |   1.4384 |     46.345 |   1.4189 |     45.350 |     0.3
    5 |   1.4168 |     46.142 |   1.4033 |     45.350 |     0.4
    6 |   1.4053 |     46.136 |   1.3957 |     45.350 |     0.5
    7 |   1.3988 |     46.158 |   1.3923 |     45.350 |     0.6
    8 |   1.3948 |     46.120 |   1.3913 |     45.318 |     0.7
    9 |   1.3912 |     46.197 |   1.3818 |     45.350 |     0.7
   10 |   1.3816 |     45.888 |   1.3670 |     44.788 |     0.8
   11 |   1.3667 |     44.997 |   1.3492 |     43.789 |     0.9
   12 |   1.3538 |     44.832 |   1.3407 |     43.820 |     1.0
   13 |   1.3425 |     44.688 |   1.3339 |     43.602 |     1.1
   14 |   1.3367 |     44.589 |   1.3334 |     43.664 |     1.2
   15 |   1.3319 |     44.600 |   1.3230 |     43.851 |     1.2
   16 |   1.3239 |     44.292 |   1.3195 |     43.758 |     1.3
   17 |   1.3289 |     44.727 |   1.3264 |     43.633 |     1.4
   18 |   1.3230 |     44.309 |   1.3237 |     43.851 |     1.5
   19 |   1.3130 |     44.055 |   1.3079 |     42.509 |     1.6
   20 |   1.3069 |     43.841 |   1.3160 |     42.416 |     1.7
   21 |   1.3060 |     43.753 |   1.3016 |     42.135 |     1.8
   22 |   1.2979 |     43.445 |   1.2999 |     42.416 |     1.9
   23 |   1.2919 |     43.274 |   1.2959 |     42.166 |     1.9
   24 |   1.2879 |     43.070 |   1.2899 |     42.104 |     2.0
   25 |   1.2810 |     42.867 |   1.2816 |     42.041 |     2.1
   26 |   1.2723 |     42.723 |   1.2772 |     41.760 |     2.2
   27 |   1.2701 |     42.327 |   1.2693 |     41.386 |     2.3
   28 |   1.2644 |     42.278 |   1.2701 |     41.199 |     2.4
   29 |   1.2605 |     42.311 |   1.2661 |     41.292 |     2.5
   30 |   1.2549 |     42.245 |   1.2670 |     41.573 |     2.5
   31 |   1.2552 |     42.201 |   1.2664 |     41.074 |     2.6
   32 |   1.2528 |     42.030 |   1.2548 |     41.261 |     2.7
   33 |   1.2429 |     41.909 |   1.2630 |     41.105 |     2.8
   34 |   1.2453 |     41.969 |   1.2560 |     41.011 |     2.9
   35 |   1.2357 |     41.590 |   1.2527 |     40.668 |     3.0
   36 |   1.2297 |     41.259 |   1.2505 |     40.699 |     3.1
   37 |   1.2290 |     41.480 |   1.2339 |     40.730 |     3.1
   38 |   1.2207 |     41.342 |   1.2347 |     40.481 |     3.2
   39 |   1.2152 |     41.160 |   1.2365 |     40.668 |     3.3
   40 |   1.2159 |     40.957 |   1.2395 |     40.824 |     3.4
   41 |   1.2129 |     40.836 |   1.2212 |     40.137 |     3.5
   42 |   1.2021 |     40.593 |   1.2199 |     39.919 |     3.6
   43 |   1.1920 |     40.043 |   1.2209 |     40.106 |     3.6
   44 |   1.1912 |     39.993 |   1.2093 |     40.231 |     3.7
   45 |   1.1866 |     39.718 |   1.2167 |     40.418 |     3.8
   46 |   1.1789 |     40.032 |   1.2119 |     39.607 |     3.9
   47 |   1.1759 |     39.608 |   1.2081 |     40.012 |     4.0
   48 |   1.1783 |     39.724 |   1.2085 |     39.638 |     4.1
   49 |   1.1720 |     39.245 |   1.2044 |     40.044 |     4.1
   50 |   1.1631 |     39.311 |   1.2120 |     39.388 |     4.2
   51 |   1.1575 |     39.014 |   1.2114 |     39.669 |     4.3
   52 |   1.1576 |     39.107 |   1.2118 |     40.044 |     4.4
   53 |   1.1583 |     39.195 |   1.2094 |     39.419 |     4.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 2,223,234

Training started
X_train.shape: torch.Size([3028, 649])
Y_train.shape: torch.Size([3028, 7])
X_dev.shape: torch.Size([534, 702])
Y_dev.shape: torch.Size([534, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2838 |     61.834 |   1.6868 |     48.283 |     0.1
    2 |   1.5187 |     46.433 |   1.4285 |     45.350 |     0.1
    3 |   1.4194 |     46.202 |   1.4023 |     45.350 |     0.2
    4 |   1.4003 |     46.164 |   1.4056 |     45.350 |     0.2
    5 |   1.3954 |     46.241 |   1.3934 |     45.381 |     0.3
    6 |   1.3945 |     46.439 |   1.3914 |     45.381 |     0.4
    7 |   1.3915 |     46.142 |   1.3898 |     45.350 |     0.4
    8 |   1.3887 |     46.279 |   1.3848 |     45.350 |     0.5
    9 |   1.3834 |     46.136 |   1.3774 |     45.350 |     0.5
   10 |   1.3753 |     46.219 |   1.3667 |     45.630 |     0.6
   11 |   1.3643 |     46.252 |   1.3589 |     45.131 |     0.6
   12 |   1.3448 |     45.184 |   1.3489 |     44.101 |     0.7
   13 |   1.3300 |     44.622 |   1.3362 |     44.007 |     0.8
   14 |   1.3133 |     44.144 |   1.3135 |     43.196 |     0.8
   15 |   1.2934 |     43.450 |   1.3042 |     42.946 |     0.9
   16 |   1.2838 |     43.224 |   1.2928 |     42.790 |     0.9
   17 |   1.2775 |     43.279 |   1.2849 |     42.353 |     1.0
   18 |   1.2664 |     42.790 |   1.2809 |     42.135 |     1.1
   19 |   1.2556 |     42.448 |   1.2739 |     41.823 |     1.1
   20 |   1.2479 |     42.608 |   1.2668 |     41.511 |     1.2
   21 |   1.2396 |     42.135 |   1.2763 |     41.604 |     1.2
   22 |   1.2308 |     41.810 |   1.2569 |     41.261 |     1.3
   23 |   1.2266 |     41.623 |   1.2719 |     41.136 |     1.4
   24 |   1.2172 |     41.678 |   1.2445 |     40.730 |     1.4
   25 |   1.2030 |     40.819 |   1.2463 |     40.855 |     1.5
   26 |   1.1991 |     40.626 |   1.2394 |     40.106 |     1.5
   27 |   1.1828 |     40.092 |   1.2296 |     40.512 |     1.6
   28 |   1.1818 |     39.966 |   1.2209 |     39.950 |     1.6
   29 |   1.1628 |     39.377 |   1.2268 |     40.231 |     1.7
   30 |   1.1538 |     38.997 |   1.2124 |     39.856 |     1.8
   31 |   1.1459 |     38.628 |   1.1934 |     39.576 |     1.8
   32 |   1.1323 |     37.946 |   1.2152 |     39.513 |     1.9
   33 |   1.1138 |     37.428 |   1.1870 |     39.576 |     1.9
   34 |   1.1167 |     37.594 |   1.1839 |     38.889 |     2.0
   35 |   1.1061 |     37.258 |   1.1959 |     39.607 |     2.1
   36 |   1.0990 |     36.961 |   1.1902 |     38.764 |     2.1
   37 |   1.0926 |     37.016 |   1.1809 |     38.514 |     2.2
   38 |   1.0860 |     36.702 |   1.1823 |     38.577 |     2.2
   39 |   1.0646 |     35.502 |   1.1720 |     37.953 |     2.3
   40 |   1.0531 |     35.513 |   1.1610 |     37.640 |     2.4
   41 |   1.0529 |     35.634 |   1.1600 |     37.297 |     2.4
   42 |   1.0496 |     35.282 |   1.1708 |     38.546 |     2.5
   43 |   1.0344 |     34.946 |   1.1441 |     36.735 |     2.5
   44 |   1.0282 |     34.770 |   1.1256 |     36.142 |     2.6
   45 |   1.0078 |     33.702 |   1.1498 |     37.609 |     2.6
   46 |   1.0108 |     33.933 |   1.1351 |     37.016 |     2.7
   47 |   0.9959 |     33.295 |   1.1469 |     37.797 |     2.8
   48 |   0.9807 |     32.838 |   1.1204 |     36.704 |     2.8
   49 |   0.9812 |     32.728 |   1.1521 |     37.328 |     2.9
   50 |   0.9966 |     33.201 |   1.1527 |     37.141 |     2.9
   51 |   0.9869 |     33.207 |   1.1204 |     35.487 |     3.0
   52 |   0.9501 |     31.930 |   1.1050 |     35.050 |     3.1
   53 |   0.9361 |     31.440 |   1.1207 |     35.830 |     3.1
   54 |   0.9367 |     31.297 |   1.1160 |     35.112 |     3.2
   55 |   0.9111 |     30.383 |   1.1066 |     34.956 |     3.2
   56 |   0.8940 |     30.047 |   1.1066 |     35.050 |     3.3
Early stopping

