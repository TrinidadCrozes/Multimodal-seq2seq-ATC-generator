Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 491,585

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5874 |     68.793 |   2.0307 |     58.727 |     0.0
    2 |   1.7919 |     50.736 |   1.5837 |     45.432 |     0.0
    3 |   1.5055 |     46.318 |   1.4508 |     45.432 |     0.1
    4 |   1.4365 |     46.302 |   1.4205 |     45.432 |     0.1
    5 |   1.4148 |     46.291 |   1.4042 |     45.432 |     0.1
    6 |   1.4051 |     46.445 |   1.4027 |     45.432 |     0.1
    7 |   1.3926 |     46.291 |   1.3843 |     45.432 |     0.1
    8 |   1.3831 |     46.351 |   1.3791 |     45.432 |     0.1
    9 |   1.3729 |     46.263 |   1.3653 |     45.274 |     0.2
   10 |   1.3546 |     45.939 |   1.3436 |     45.589 |     0.2
   11 |   1.3343 |     45.175 |   1.3223 |     43.226 |     0.2
   12 |   1.3101 |     44.087 |   1.3014 |     43.510 |     0.2
   13 |   1.2883 |     44.021 |   1.2820 |     43.258 |     0.2
   14 |   1.2684 |     43.626 |   1.2592 |     42.060 |     0.2
   15 |   1.2485 |     43.027 |   1.2463 |     42.250 |     0.3
   16 |   1.2359 |     42.686 |   1.2340 |     41.934 |     0.3
   17 |   1.2185 |     42.285 |   1.2168 |     40.580 |     0.3
   18 |   1.2026 |     41.702 |   1.2042 |     40.233 |     0.3
   19 |   1.1892 |     40.994 |   1.2066 |     41.115 |     0.3
   20 |   1.1764 |     40.384 |   1.1933 |     40.044 |     0.3
   21 |   1.1609 |     39.625 |   1.1970 |     39.729 |     0.4
   22 |   1.1534 |     39.493 |   1.1849 |     38.563 |     0.4
   23 |   1.1392 |     39.065 |   1.1815 |     39.004 |     0.4
   24 |   1.1212 |     38.224 |   1.1624 |     38.343 |     0.4
   25 |   1.1078 |     37.702 |   1.1575 |     38.469 |     0.4
   26 |   1.0961 |     37.438 |   1.1500 |     37.902 |     0.4
   27 |   1.0827 |     36.894 |   1.1420 |     37.776 |     0.5
   28 |   1.0647 |     36.125 |   1.1291 |     37.555 |     0.5
   29 |   1.0524 |     35.636 |   1.1456 |     37.681 |     0.5
   30 |   1.0447 |     35.581 |   1.1332 |     37.461 |     0.5
   31 |   1.0297 |     34.866 |   1.1457 |     37.681 |     0.5
   32 |   1.0176 |     34.493 |   1.1306 |     38.154 |     0.5
   33 |   1.0080 |     34.311 |   1.1244 |     36.988 |     0.6
   34 |   0.9951 |     33.388 |   1.1126 |     36.295 |     0.6
   35 |   0.9745 |     32.575 |   1.1099 |     36.484 |     0.6
   36 |   0.9609 |     32.591 |   1.1128 |     36.263 |     0.6
   37 |   0.9540 |     32.399 |   1.1107 |     36.358 |     0.6
   38 |   0.9357 |     32.009 |   1.0969 |     36.169 |     0.7
   39 |   0.9342 |     31.652 |   1.0960 |     35.539 |     0.7
   40 |   0.9147 |     30.833 |   1.1030 |     36.484 |     0.7
   41 |   0.9080 |     30.558 |   1.0939 |     34.940 |     0.7
   42 |   0.8976 |     30.229 |   1.0989 |     35.570 |     0.7
   43 |   0.8821 |     29.740 |   1.0882 |     35.759 |     0.7
   44 |   0.8669 |     29.267 |   1.1004 |     34.657 |     0.8
   45 |   0.8574 |     28.943 |   1.1023 |     35.066 |     0.8
   46 |   0.8446 |     28.465 |   1.1017 |     34.625 |     0.8
   47 |   0.8381 |     28.124 |   1.0916 |     34.499 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 661,729

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4283 |     62.979 |   1.8889 |     48.488 |     0.0
    2 |   1.6725 |     48.055 |   1.5117 |     45.495 |     0.0
    3 |   1.4502 |     46.049 |   1.4030 |     45.117 |     0.1
    4 |   1.3738 |     44.626 |   1.3419 |     42.628 |     0.1
    5 |   1.3160 |     43.230 |   1.2920 |     41.336 |     0.1
    6 |   1.2620 |     41.466 |   1.2393 |     39.225 |     0.1
    7 |   1.2129 |     39.719 |   1.2093 |     39.288 |     0.2
    8 |   1.1670 |     38.383 |   1.1772 |     37.870 |     0.2
    9 |   1.1267 |     37.043 |   1.1508 |     37.177 |     0.2
   10 |   1.0838 |     35.465 |   1.1286 |     37.209 |     0.2
   11 |   1.0488 |     34.202 |   1.0951 |     35.539 |     0.3
   12 |   0.9944 |     31.949 |   1.0585 |     34.373 |     0.3
   13 |   0.9511 |     30.322 |   1.0522 |     33.050 |     0.3
   14 |   0.9133 |     29.036 |   1.0362 |     33.081 |     0.3
   15 |   0.8759 |     27.470 |   1.0107 |     32.073 |     0.3
   16 |   0.8430 |     26.525 |   0.9978 |     31.537 |     0.4
   17 |   0.8043 |     25.261 |   0.9904 |     31.285 |     0.4
   18 |   0.7731 |     24.354 |   0.9895 |     30.907 |     0.4
   19 |   0.7510 |     23.481 |   0.9645 |     30.277 |     0.4
   20 |   0.7080 |     22.178 |   0.9622 |     30.466 |     0.5
   21 |   0.6843 |     21.228 |   0.9442 |     28.859 |     0.5
   22 |   0.6552 |     20.211 |   0.9540 |     29.490 |     0.5
   23 |   0.6328 |     19.425 |   0.9510 |     28.922 |     0.5
   24 |   0.6054 |     18.799 |   0.9345 |     28.733 |     0.6
   25 |   0.5862 |     18.079 |   0.9429 |     29.269 |     0.6
   26 |   0.5580 |     17.227 |   0.9362 |     28.261 |     0.6
   27 |   0.5375 |     16.337 |   0.9434 |     28.670 |     0.6
   28 |   0.5165 |     15.985 |   0.9332 |     28.513 |     0.7
   29 |   0.4983 |     15.392 |   0.9439 |     28.166 |     0.7
   30 |   0.4853 |     14.787 |   0.9466 |     28.040 |     0.7
   31 |   0.4732 |     14.491 |   0.9448 |     28.450 |     0.7
   32 |   0.4475 |     13.650 |   0.9560 |     27.694 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,455,041

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2431 |     61.287 |   1.6354 |     48.362 |     0.0
    2 |   1.4907 |     46.741 |   1.4118 |     45.432 |     0.1
    3 |   1.3986 |     46.351 |   1.3749 |     45.432 |     0.1
    4 |   1.3542 |     44.934 |   1.3277 |     42.974 |     0.2
    5 |   1.3099 |     43.928 |   1.2803 |     42.407 |     0.2
    6 |   1.2760 |     43.181 |   1.2607 |     41.525 |     0.2
    7 |   1.2723 |     42.922 |   1.2356 |     40.328 |     0.3
    8 |   1.2317 |     41.384 |   1.2212 |     39.792 |     0.3
    9 |   1.2038 |     40.466 |   1.2001 |     39.698 |     0.4
   10 |   1.1811 |     39.851 |   1.1819 |     38.847 |     0.4
   11 |   1.1580 |     39.164 |   1.1590 |     37.776 |     0.4
   12 |   1.1308 |     37.966 |   1.1403 |     37.839 |     0.5
   13 |   1.1068 |     37.235 |   1.1657 |     38.626 |     0.5
   14 |   1.0777 |     36.180 |   1.1066 |     37.020 |     0.6
   15 |   1.0559 |     35.306 |   1.1025 |     35.791 |     0.6
   16 |   1.0356 |     34.399 |   1.0720 |     34.877 |     0.6
   17 |   1.0046 |     33.641 |   1.0638 |     34.531 |     0.7
   18 |   0.9761 |     32.421 |   1.0907 |     34.972 |     0.7
   19 |   0.9586 |     31.888 |   1.0482 |     34.342 |     0.8
   20 |   0.9382 |     31.091 |   1.0191 |     33.176 |     0.8
   21 |   0.9033 |     29.849 |   1.0244 |     32.861 |     0.9
   22 |   0.8804 |     29.300 |   1.0123 |     32.136 |     0.9
   23 |   0.8599 |     28.646 |   1.0193 |     32.829 |     0.9
   24 |   0.8419 |     28.025 |   1.0114 |     32.892 |     1.0
   25 |   0.8203 |     27.289 |   0.9955 |     31.474 |     1.0
   26 |   0.7977 |     26.635 |   0.9815 |     30.498 |     1.1
   27 |   0.7689 |     25.712 |   0.9736 |     30.624 |     1.1
   28 |   0.7473 |     24.766 |   0.9760 |     30.372 |     1.1
   29 |   0.7284 |     23.953 |   0.9678 |     30.088 |     1.2
   30 |   0.7067 |     23.250 |   0.9681 |     30.844 |     1.2
   31 |   0.6793 |     22.085 |   0.9597 |     29.616 |     1.3
   32 |   0.6692 |     22.041 |   0.9667 |     29.962 |     1.3
   33 |   0.6533 |     21.920 |   0.9714 |     29.017 |     1.3
   34 |   0.6281 |     20.903 |   0.9427 |     28.355 |     1.4
   35 |   0.6391 |     21.129 |   0.9636 |     29.112 |     1.4
   36 |   0.6163 |     20.354 |   0.9513 |     29.143 |     1.5
   37 |   0.5888 |     19.343 |   0.9734 |     28.513 |     1.5
   38 |   0.5696 |     18.683 |   0.9671 |     28.796 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 658,689

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6255 |     70.321 |   2.0815 |     58.727 |     0.0
    2 |   1.8298 |     52.226 |   1.6155 |     45.432 |     0.1
    3 |   1.5303 |     46.307 |   1.4719 |     45.432 |     0.1
    4 |   1.4474 |     46.478 |   1.4284 |     45.432 |     0.1
    5 |   1.4149 |     46.291 |   1.4009 |     45.432 |     0.1
    6 |   1.3924 |     46.033 |   1.3804 |     44.707 |     0.2
    7 |   1.3711 |     45.456 |   1.3650 |     44.739 |     0.2
    8 |   1.3555 |     45.258 |   1.3434 |     44.675 |     0.2
    9 |   1.3380 |     45.126 |   1.3282 |     44.108 |     0.2
   10 |   1.3177 |     44.703 |   1.3120 |     42.880 |     0.3
   11 |   1.2977 |     43.279 |   1.2886 |     41.619 |     0.3
   12 |   1.2708 |     42.543 |   1.2670 |     41.399 |     0.3
   13 |   1.2536 |     42.241 |   1.2478 |     40.800 |     0.3
   14 |   1.2344 |     41.719 |   1.2300 |     40.391 |     0.4
   15 |   1.2111 |     40.878 |   1.2272 |     40.422 |     0.4
   16 |   1.1930 |     40.279 |   1.2074 |     38.689 |     0.4
   17 |   1.1686 |     39.328 |   1.1779 |     38.941 |     0.4
   18 |   1.1436 |     38.532 |   1.1610 |     38.343 |     0.5
   19 |   1.1242 |     37.966 |   1.1546 |     37.713 |     0.5
   20 |   1.1180 |     37.641 |   1.1551 |     37.272 |     0.5
   21 |   1.0978 |     36.713 |   1.1363 |     37.366 |     0.5
   22 |   1.0787 |     36.020 |   1.1229 |     36.547 |     0.6
   23 |   1.0529 |     35.015 |   1.1306 |     36.389 |     0.6
   24 |   1.0389 |     34.762 |   1.1132 |     35.759 |     0.6
   25 |   1.0247 |     34.240 |   1.0929 |     35.224 |     0.6
   26 |   1.0030 |     33.168 |   1.0977 |     35.381 |     0.7
   27 |   0.9887 |     33.042 |   1.1009 |     35.255 |     0.7
   28 |   0.9833 |     32.487 |   1.1011 |     35.192 |     0.7
   29 |   0.9631 |     31.773 |   1.0795 |     34.783 |     0.7
   30 |   0.9418 |     31.141 |   1.0770 |     34.279 |     0.8
   31 |   0.9206 |     30.377 |   1.0530 |     33.963 |     0.8
   32 |   0.9106 |     30.262 |   1.0607 |     33.585 |     0.8
   33 |   0.8949 |     29.630 |   1.0550 |     33.774 |     0.8
   34 |   0.8788 |     29.031 |   1.0438 |     32.892 |     0.9
   35 |   0.8670 |     28.327 |   1.0425 |     33.648 |     0.9
   36 |   0.8388 |     27.728 |   1.0335 |     33.207 |     0.9
   37 |   0.8343 |     27.344 |   1.0522 |     33.365 |     0.9
   38 |   0.8187 |     27.047 |   1.0432 |     32.766 |     1.0
   39 |   0.7985 |     26.080 |   1.0501 |     33.365 |     1.0
   40 |   0.7803 |     25.745 |   1.0348 |     32.105 |     1.0
   41 |   0.7799 |     25.574 |   1.0309 |     32.199 |     1.0
   42 |   0.7579 |     24.673 |   1.0237 |     32.231 |     1.1
   43 |   0.7438 |     24.085 |   1.0270 |     31.853 |     1.1
   44 |   0.7293 |     23.816 |   1.0178 |     31.979 |     1.1
   45 |   0.7274 |     23.634 |   1.0204 |     31.348 |     1.1
   46 |   0.7019 |     22.563 |   1.0013 |     30.970 |     1.2
   47 |   0.6969 |     22.574 |   1.0260 |     31.191 |     1.2
   48 |   0.6927 |     22.338 |   1.0255 |     31.128 |     1.2
   49 |   0.6777 |     21.898 |   1.0259 |     30.907 |     1.2
   50 |   0.6752 |     21.783 |   1.0147 |     30.372 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 851,137

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5198 |     66.568 |   2.0001 |     55.072 |     0.0
    2 |   1.7849 |     50.863 |   1.5803 |     45.463 |     0.1
    3 |   1.5098 |     46.362 |   1.4516 |     45.558 |     0.1
    4 |   1.4338 |     46.318 |   1.4127 |     45.432 |     0.1
    5 |   1.4056 |     46.181 |   1.3922 |     45.274 |     0.2
    6 |   1.3901 |     46.175 |   1.3762 |     45.211 |     0.2
    7 |   1.3648 |     44.884 |   1.3530 |     43.384 |     0.2
    8 |   1.3408 |     44.560 |   1.3370 |     43.573 |     0.3
    9 |   1.3216 |     43.774 |   1.3160 |     42.722 |     0.3
   10 |   1.3019 |     43.345 |   1.3036 |     42.628 |     0.4
   11 |   1.2839 |     42.692 |   1.2825 |     41.084 |     0.4
   12 |   1.2644 |     41.851 |   1.2706 |     41.210 |     0.4
   13 |   1.2497 |     41.312 |   1.2541 |     40.107 |     0.5
   14 |   1.2343 |     40.807 |   1.2413 |     39.792 |     0.5
   15 |   1.2169 |     40.318 |   1.2300 |     39.572 |     0.5
   16 |   1.1943 |     39.581 |   1.2243 |     39.225 |     0.6
   17 |   1.1803 |     39.103 |   1.2014 |     38.626 |     0.6
   18 |   1.1646 |     38.598 |   1.2042 |     38.626 |     0.6
   19 |   1.1480 |     38.147 |   1.1869 |     38.185 |     0.7
   20 |   1.1392 |     37.916 |   1.1783 |     37.776 |     0.7
   21 |   1.1181 |     37.070 |   1.1719 |     37.776 |     0.7
   22 |   1.1019 |     36.224 |   1.1639 |     37.618 |     0.8
   23 |   1.0836 |     35.790 |   1.1532 |     37.335 |     0.8
   24 |   1.0716 |     35.317 |   1.1446 |     36.894 |     0.8
   25 |   1.0591 |     34.828 |   1.1369 |     36.263 |     0.9
   26 |   1.0424 |     34.526 |   1.1158 |     36.200 |     0.9
   27 |   1.0296 |     33.932 |   1.1171 |     36.673 |     0.9
   28 |   1.0100 |     33.339 |   1.1041 |     35.917 |     1.0
   29 |   0.9896 |     32.888 |   1.0902 |     34.940 |     1.0
   30 |   0.9804 |     32.207 |   1.0892 |     35.255 |     1.0
   31 |   0.9676 |     32.097 |   1.0844 |     35.287 |     1.1
   32 |   0.9532 |     31.503 |   1.0805 |     34.783 |     1.1
   33 |   0.9439 |     31.427 |   1.0797 |     34.751 |     1.1
   34 |   0.9306 |     30.773 |   1.0707 |     34.877 |     1.2
   35 |   0.9233 |     30.674 |   1.0642 |     34.846 |     1.2
   36 |   0.9018 |     29.800 |   1.0500 |     33.554 |     1.2
   37 |   0.8928 |     29.926 |   1.0649 |     34.026 |     1.3
   38 |   0.8774 |     28.921 |   1.0429 |     33.743 |     1.3
   39 |   0.8673 |     28.833 |   1.0639 |     33.617 |     1.4
   40 |   0.8560 |     28.069 |   1.0498 |     33.459 |     1.4
   41 |   0.8444 |     28.036 |   1.0515 |     33.995 |     1.4
   42 |   0.8378 |     27.811 |   1.0440 |     32.798 |     1.5
   43 |   0.8189 |     26.997 |   1.0375 |     32.609 |     1.5
   44 |   0.8199 |     27.382 |   1.0572 |     33.680 |     1.5
   45 |   0.8055 |     26.684 |   1.0632 |     33.806 |     1.6
   46 |   0.7934 |     26.530 |   1.0448 |     32.955 |     1.6
   47 |   0.7785 |     25.800 |   1.0376 |     32.892 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 453,793

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6199 |     70.436 |   2.0920 |     58.727 |     0.0
    2 |   1.8602 |     52.506 |   1.6395 |     45.463 |     0.0
    3 |   1.5471 |     46.544 |   1.4774 |     45.432 |     0.1
    4 |   1.4574 |     46.450 |   1.4428 |     45.432 |     0.1
    5 |   1.4303 |     46.318 |   1.4167 |     45.432 |     0.1
    6 |   1.4158 |     46.285 |   1.4083 |     45.432 |     0.1
    7 |   1.4082 |     46.340 |   1.4016 |     45.432 |     0.2
    8 |   1.4024 |     46.346 |   1.4002 |     45.495 |     0.2
    9 |   1.3988 |     46.291 |   1.3956 |     45.463 |     0.2
   10 |   1.3959 |     46.280 |   1.3934 |     45.369 |     0.2
   11 |   1.3883 |     46.379 |   1.3814 |     45.274 |     0.3
   12 |   1.3748 |     46.022 |   1.3655 |     44.297 |     0.3
   13 |   1.3546 |     44.675 |   1.3448 |     43.478 |     0.3
   14 |   1.3309 |     44.538 |   1.3171 |     43.541 |     0.3
   15 |   1.3070 |     43.747 |   1.2956 |     42.628 |     0.4
   16 |   1.2930 |     43.565 |   1.3039 |     43.037 |     0.4
   17 |   1.2822 |     43.329 |   1.2708 |     43.258 |     0.4
   18 |   1.2620 |     42.889 |   1.2598 |     41.399 |     0.4
   19 |   1.2492 |     42.527 |   1.2469 |     41.462 |     0.4
   20 |   1.2332 |     41.955 |   1.2292 |     40.863 |     0.5
   21 |   1.2177 |     41.565 |   1.2324 |     40.832 |     0.5
   22 |   1.2084 |     41.015 |   1.2076 |     39.792 |     0.5
   23 |   1.1934 |     40.647 |   1.2027 |     39.540 |     0.5
   24 |   1.1810 |     40.334 |   1.2078 |     40.517 |     0.6
   25 |   1.1734 |     39.735 |   1.1873 |     40.139 |     0.6
   26 |   1.1532 |     39.037 |   1.1815 |     39.761 |     0.6
   27 |   1.1391 |     38.642 |   1.1756 |     39.445 |     0.6
   28 |   1.1274 |     38.361 |   1.1542 |     38.626 |     0.7
   29 |   1.1196 |     38.202 |   1.1459 |     38.721 |     0.7
   30 |   1.0996 |     37.680 |   1.1482 |     38.658 |     0.7
   31 |   1.0924 |     37.147 |   1.1517 |     38.311 |     0.7
   32 |   1.0811 |     36.856 |   1.1342 |     38.343 |     0.7
   33 |   1.0631 |     36.191 |   1.1233 |     37.303 |     0.8
   34 |   1.0569 |     36.097 |   1.1115 |     37.083 |     0.8
   35 |   1.0435 |     35.334 |   1.1097 |     36.578 |     0.8
   36 |   1.0278 |     34.883 |   1.1070 |     36.799 |     0.8
   37 |   1.0170 |     34.548 |   1.0948 |     36.799 |     0.9
   38 |   1.0023 |     34.147 |   1.1018 |     36.106 |     0.9
   39 |   0.9880 |     33.471 |   1.0896 |     35.602 |     0.9
   40 |   0.9722 |     32.526 |   1.0895 |     35.381 |     0.9
   41 |   0.9617 |     32.300 |   1.0816 |     35.948 |     0.9
   42 |   0.9563 |     32.471 |   1.0687 |     35.381 |     1.0
   43 |   0.9421 |     31.905 |   1.0839 |     35.665 |     1.0
   44 |   0.9445 |     32.025 |   1.0737 |     35.570 |     1.0
   45 |   0.9292 |     31.278 |   1.0740 |     35.161 |     1.0
   46 |   0.9101 |     30.965 |   1.0769 |     35.129 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 833,313

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4987 |     66.079 |   2.0196 |     57.152 |     0.0
    2 |   1.7943 |     50.522 |   1.6059 |     45.432 |     0.1
    3 |   1.5212 |     46.285 |   1.4628 |     45.526 |     0.1
    4 |   1.4311 |     46.137 |   1.4123 |     44.423 |     0.1
    5 |   1.3878 |     44.879 |   1.3830 |     44.297 |     0.2
    6 |   1.3626 |     44.411 |   1.3497 |     43.195 |     0.2
    7 |   1.3384 |     43.878 |   1.3344 |     43.069 |     0.2
    8 |   1.3135 |     43.494 |   1.3117 |     42.722 |     0.3
    9 |   1.2979 |     43.071 |   1.3024 |     42.187 |     0.3
   10 |   1.2805 |     42.450 |   1.2859 |     41.619 |     0.3
   11 |   1.2610 |     41.675 |   1.2796 |     40.989 |     0.4
   12 |   1.2442 |     41.087 |   1.2652 |     40.611 |     0.4
   13 |   1.2280 |     40.642 |   1.2573 |     40.139 |     0.4
   14 |   1.2100 |     39.675 |   1.2460 |     39.572 |     0.4
   15 |   1.1963 |     39.680 |   1.2327 |     38.784 |     0.5
   16 |   1.1781 |     38.905 |   1.2180 |     38.091 |     0.5
   17 |   1.1599 |     38.059 |   1.2024 |     37.555 |     0.5
   18 |   1.1346 |     37.048 |   1.1980 |     37.839 |     0.6
   19 |   1.1165 |     36.493 |   1.1843 |     37.650 |     0.6
   20 |   1.1019 |     36.042 |   1.1677 |     36.578 |     0.6
   21 |   1.0743 |     34.965 |   1.1608 |     37.051 |     0.7
   22 |   1.0585 |     34.487 |   1.1601 |     36.925 |     0.7
   23 |   1.0514 |     34.361 |   1.1484 |     36.862 |     0.7
   24 |   1.0279 |     33.652 |   1.1489 |     36.547 |     0.8
   25 |   1.0059 |     32.993 |   1.1388 |     36.263 |     0.8
   26 |   0.9831 |     32.212 |   1.1284 |     35.917 |     0.8
   27 |   0.9718 |     31.850 |   1.1289 |     36.169 |     0.9
   28 |   0.9553 |     31.503 |   1.1081 |     34.940 |     0.9
   29 |   0.9379 |     30.800 |   1.1301 |     36.137 |     0.9
   30 |   0.9172 |     30.322 |   1.1182 |     35.098 |     1.0
   31 |   0.9138 |     30.256 |   1.1149 |     34.940 |     1.0
   32 |   0.8884 |     29.157 |   1.1085 |     35.003 |     1.0
   33 |   0.8746 |     28.739 |   1.1052 |     35.539 |     1.0
   34 |   0.8628 |     28.228 |   1.1046 |     35.192 |     1.1
   35 |   0.8434 |     27.673 |   1.1182 |     35.255 |     1.1
   36 |   0.8346 |     27.503 |   1.1020 |     34.310 |     1.1
   37 |   0.8089 |     26.371 |   1.0991 |     34.216 |     1.2
   38 |   0.8004 |     26.355 |   1.0972 |     33.302 |     1.2
   39 |   0.7839 |     25.514 |   1.0790 |     33.396 |     1.2
   40 |   0.7727 |     25.360 |   1.0868 |     33.270 |     1.3
   41 |   0.7505 |     24.244 |   1.0819 |     33.081 |     1.3
   42 |   0.7344 |     23.838 |   1.0871 |     32.577 |     1.3
   43 |   0.7186 |     23.261 |   1.0949 |     33.176 |     1.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,142,625

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2515 |     61.573 |   1.6661 |     48.299 |     0.1
    2 |   1.5108 |     46.516 |   1.4303 |     45.432 |     0.1
    3 |   1.4183 |     46.291 |   1.4086 |     45.432 |     0.2
    4 |   1.4043 |     46.351 |   1.4002 |     45.432 |     0.2
    5 |   1.3971 |     46.329 |   1.3953 |     45.810 |     0.3
    6 |   1.3867 |     46.000 |   1.3776 |     44.108 |     0.4
    7 |   1.3588 |     44.928 |   1.3515 |     43.982 |     0.4
    8 |   1.3380 |     44.483 |   1.3387 |     43.667 |     0.5
    9 |   1.3188 |     44.060 |   1.3231 |     43.132 |     0.5
   10 |   1.3006 |     43.378 |   1.3041 |     42.880 |     0.6
   11 |   1.2866 |     42.999 |   1.2979 |     42.722 |     0.7
   12 |   1.2705 |     42.499 |   1.2761 |     41.651 |     0.7
   13 |   1.2508 |     41.829 |   1.2653 |     41.588 |     0.8
   14 |   1.2327 |     41.406 |   1.2552 |     41.115 |     0.8
   15 |   1.2181 |     40.906 |   1.2452 |     40.769 |     0.9
   16 |   1.1895 |     40.021 |   1.2343 |     40.611 |     0.9
   17 |   1.1817 |     39.543 |   1.2221 |     39.950 |     1.0
   18 |   1.1569 |     38.697 |   1.2187 |     38.910 |     1.1
   19 |   1.1395 |     37.790 |   1.1983 |     38.217 |     1.1
   20 |   1.1151 |     36.999 |   1.2012 |     38.343 |     1.2
   21 |   1.1076 |     37.290 |   1.1932 |     38.626 |     1.2
   22 |   1.0841 |     36.466 |   1.1889 |     37.996 |     1.3
   23 |   1.0650 |     35.773 |   1.1780 |     37.776 |     1.4
   24 |   1.0484 |     35.158 |   1.1682 |     37.366 |     1.4
   25 |   1.0326 |     34.954 |   1.1534 |     37.303 |     1.5
   26 |   1.0118 |     33.745 |   1.1579 |     38.028 |     1.5
   27 |   0.9889 |     33.388 |   1.1409 |     36.830 |     1.6
   28 |   0.9685 |     32.548 |   1.1420 |     36.326 |     1.7
   29 |   0.9419 |     31.322 |   1.1712 |     37.366 |     1.7
   30 |   0.9410 |     31.734 |   1.1572 |     36.043 |     1.8
   31 |   0.9149 |     30.641 |   1.1394 |     35.633 |     1.8
   32 |   0.8937 |     29.877 |   1.1539 |     36.232 |     1.9
   33 |   0.8749 |     29.179 |   1.1371 |     35.728 |     1.9
   34 |   0.8555 |     28.421 |   1.1420 |     35.948 |     2.0
   35 |   0.8390 |     28.091 |   1.1428 |     35.696 |     2.1
   36 |   0.8192 |     27.278 |   1.1576 |     35.098 |     2.1
   37 |   0.8103 |     27.118 |   1.1727 |     35.980 |     2.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,194,081

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2991 |     63.628 |   1.6572 |     48.330 |     0.0
    2 |   1.5033 |     46.604 |   1.4316 |     45.432 |     0.1
    3 |   1.4168 |     46.373 |   1.4123 |     45.432 |     0.1
    4 |   1.4018 |     46.434 |   1.3872 |     45.432 |     0.1
    5 |   1.3906 |     46.478 |   1.3757 |     45.369 |     0.1
    6 |   1.3725 |     45.576 |   1.3543 |     44.423 |     0.2
    7 |   1.3373 |     44.576 |   1.3316 |     44.045 |     0.2
    8 |   1.3053 |     43.527 |   1.2943 |     41.651 |     0.2
    9 |   1.2749 |     42.642 |   1.2550 |     40.863 |     0.3
   10 |   1.2431 |     41.823 |   1.2246 |     40.076 |     0.3
   11 |   1.2203 |     41.202 |   1.2170 |     40.517 |     0.3
   12 |   1.1942 |     40.653 |   1.1936 |     39.036 |     0.4
   13 |   1.1814 |     40.065 |   1.1870 |     39.319 |     0.4
   14 |   1.1668 |     39.840 |   1.1739 |     39.351 |     0.4
   15 |   1.1401 |     38.944 |   1.1645 |     38.847 |     0.4
   16 |   1.1281 |     38.730 |   1.1256 |     38.280 |     0.5
   17 |   1.0981 |     37.609 |   1.1251 |     36.988 |     0.5
   18 |   1.0759 |     36.575 |   1.1123 |     37.429 |     0.5
   19 |   1.0532 |     35.960 |   1.1192 |     36.169 |     0.6
   20 |   1.0303 |     34.910 |   1.0970 |     36.295 |     0.6
   21 |   1.0100 |     34.432 |   1.0709 |     34.499 |     0.6
   22 |   0.9896 |     33.712 |   1.0762 |     36.263 |     0.6
   23 |   0.9688 |     32.916 |   1.0642 |     35.192 |     0.7
   24 |   0.9399 |     32.168 |   1.0379 |     34.594 |     0.7
   25 |   0.9270 |     31.712 |   1.0558 |     35.381 |     0.7
   26 |   0.9021 |     30.674 |   1.0508 |     34.405 |     0.8
   27 |   0.8754 |     29.882 |   1.0120 |     33.396 |     0.8
   28 |   0.8612 |     29.294 |   1.0530 |     34.405 |     0.8
   29 |   0.8304 |     27.992 |   1.0230 |     32.735 |     0.9
   30 |   0.8216 |     27.943 |   1.0302 |     32.987 |     0.9
   31 |   0.8045 |     27.261 |   1.0131 |     32.672 |     0.9
   32 |   0.7843 |     26.541 |   1.0022 |     32.420 |     0.9
   33 |   0.7691 |     25.789 |   1.0082 |     31.916 |     1.0
   34 |   0.7563 |     25.453 |   1.0058 |     31.727 |     1.0
   35 |   0.7339 |     24.805 |   0.9930 |     31.695 |     1.0
   36 |   0.7193 |     24.124 |   0.9802 |     30.655 |     1.1
   37 |   0.6922 |     23.123 |   1.0101 |     31.821 |     1.1
   38 |   0.6887 |     22.975 |   0.9898 |     31.348 |     1.1
   39 |   0.6766 |     22.596 |   1.0049 |     30.970 |     1.2
   40 |   0.6590 |     21.854 |   0.9860 |     30.120 |     1.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,074,049

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3935 |     62.924 |   1.8363 |     50.126 |     0.0
    2 |   1.6455 |     47.698 |   1.5058 |     45.495 |     0.1
    3 |   1.4461 |     45.736 |   1.4037 |     43.667 |     0.1
    4 |   1.3718 |     44.549 |   1.3431 |     42.407 |     0.2
    5 |   1.3198 |     43.274 |   1.2947 |     41.462 |     0.2
    6 |   1.2697 |     41.653 |   1.2492 |     39.887 |     0.2
    7 |   1.2218 |     40.235 |   1.2220 |     39.698 |     0.3
    8 |   1.1830 |     39.350 |   1.1909 |     39.193 |     0.3
    9 |   1.1449 |     38.197 |   1.1563 |     37.303 |     0.4
   10 |   1.1013 |     36.724 |   1.1282 |     36.988 |     0.4
   11 |   1.0677 |     35.421 |   1.1085 |     36.043 |     0.4
   12 |   1.0425 |     34.311 |   1.0909 |     34.877 |     0.5
   13 |   1.0012 |     32.850 |   1.0745 |     34.216 |     0.5
   14 |   0.9588 |     30.970 |   1.0480 |     33.900 |     0.6
   15 |   0.9215 |     29.723 |   1.0374 |     33.837 |     0.6
   16 |   0.8934 |     28.602 |   1.0231 |     33.239 |     0.6
   17 |   0.8624 |     27.382 |   1.0220 |     33.113 |     0.7
   18 |   0.8265 |     26.195 |   1.0149 |     32.168 |     0.7
   19 |   0.7997 |     25.475 |   1.0087 |     31.033 |     0.8
   20 |   0.7675 |     24.420 |   1.0050 |     31.664 |     0.8
   21 |   0.7501 |     23.777 |   0.9919 |     31.411 |     0.8
   22 |   0.7254 |     22.970 |   0.9845 |     31.191 |     0.9
   23 |   0.6909 |     21.728 |   0.9852 |     30.372 |     0.9
   24 |   0.6886 |     21.728 |   0.9929 |     30.718 |     1.0
   25 |   0.6710 |     21.338 |   0.9974 |     30.403 |     1.0
   26 |   0.6362 |     19.898 |   0.9751 |     29.994 |     1.0
   27 |   0.6041 |     19.085 |   0.9830 |     30.466 |     1.1
   28 |   0.5779 |     18.321 |   0.9703 |     29.490 |     1.1
   29 |   0.5574 |     17.095 |   0.9910 |     30.088 |     1.1
   30 |   0.5434 |     16.804 |   0.9695 |     30.340 |     1.2
   31 |   0.5237 |     16.315 |   0.9853 |     29.616 |     1.2
   32 |   0.5083 |     15.667 |   1.0038 |     29.427 |     1.3
   33 |   0.4874 |     14.958 |   0.9928 |     28.891 |     1.3
   34 |   0.4734 |     14.496 |   0.9842 |     28.986 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 690,945

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2549 |     61.782 |   1.6332 |     48.425 |     0.0
    2 |   1.4851 |     46.445 |   1.4250 |     45.526 |     0.0
    3 |   1.3893 |     45.296 |   1.3628 |     43.667 |     0.1
    4 |   1.3290 |     43.719 |   1.3148 |     42.470 |     0.1
    5 |   1.2903 |     42.972 |   1.2706 |     41.430 |     0.1
    6 |   1.2473 |     41.994 |   1.2322 |     40.737 |     0.1
    7 |   1.2107 |     40.691 |   1.1978 |     39.036 |     0.1
    8 |   1.1734 |     39.411 |   1.1864 |     38.374 |     0.2
    9 |   1.1423 |     38.790 |   1.1615 |     37.744 |     0.2
   10 |   1.0982 |     37.262 |   1.1313 |     37.713 |     0.2
   11 |   1.0574 |     35.971 |   1.1201 |     37.051 |     0.2
   12 |   1.0199 |     34.592 |   1.0832 |     35.759 |     0.3
   13 |   0.9780 |     32.828 |   1.0641 |     35.696 |     0.3
   14 |   0.9331 |     31.234 |   1.0394 |     33.302 |     0.3
   15 |   0.9034 |     29.981 |   1.0486 |     34.089 |     0.3
   16 |   0.8546 |     28.234 |   1.0240 |     33.365 |     0.3
   17 |   0.8141 |     26.750 |   1.0070 |     32.325 |     0.4
   18 |   0.7575 |     24.679 |   1.0053 |     31.569 |     0.4
   19 |   0.7233 |     23.519 |   1.0027 |     30.813 |     0.4
   20 |   0.6797 |     21.711 |   0.9897 |     30.655 |     0.4
   21 |   0.6428 |     20.579 |   0.9729 |     30.277 |     0.4
   22 |   0.5985 |     18.782 |   0.9864 |     30.340 |     0.5
   23 |   0.5640 |     17.958 |   0.9909 |     29.427 |     0.5
   24 |   0.5274 |     16.331 |   0.9811 |     28.859 |     0.5
   25 |   0.4931 |     15.320 |   1.0062 |     29.269 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 719,841

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2837 |     62.617 |   1.6603 |     48.330 |     0.0
    2 |   1.4922 |     46.615 |   1.4094 |     45.463 |     0.0
    3 |   1.3803 |     45.236 |   1.3526 |     44.045 |     0.1
    4 |   1.3289 |     44.291 |   1.3112 |     42.092 |     0.1
    5 |   1.2815 |     43.027 |   1.2608 |     40.958 |     0.1
    6 |   1.2448 |     41.906 |   1.2200 |     39.761 |     0.1
    7 |   1.2095 |     40.719 |   1.2100 |     39.918 |     0.1
    8 |   1.1854 |     40.367 |   1.1793 |     38.689 |     0.2
    9 |   1.1548 |     39.493 |   1.1552 |     38.091 |     0.2
   10 |   1.1142 |     38.295 |   1.1416 |     38.059 |     0.2
   11 |   1.0790 |     37.032 |   1.1148 |     36.358 |     0.2
   12 |   1.0422 |     35.581 |   1.0976 |     36.200 |     0.3
   13 |   0.9996 |     34.031 |   1.0782 |     35.318 |     0.3
   14 |   0.9582 |     32.361 |   1.0540 |     33.963 |     0.3
   15 |   0.9106 |     30.751 |   1.0555 |     34.247 |     0.3
   16 |   0.8667 |     29.003 |   1.0473 |     33.522 |     0.3
   17 |   0.8352 |     27.596 |   1.0225 |     32.231 |     0.4
   18 |   0.7862 |     26.179 |   1.0089 |     31.285 |     0.4
   19 |   0.7431 |     24.552 |   1.0097 |     31.727 |     0.4
   20 |   0.7142 |     23.376 |   1.0343 |     32.735 |     0.4
   21 |   0.6746 |     22.266 |   1.0093 |     30.435 |     0.4
   22 |   0.6312 |     20.425 |   1.0106 |     29.553 |     0.5
   23 |   0.6018 |     19.222 |   0.9718 |     28.733 |     0.5
   24 |   0.5571 |     17.672 |   0.9985 |     29.395 |     0.5
   25 |   0.5305 |     16.694 |   0.9993 |     29.049 |     0.5
   26 |   0.5008 |     16.046 |   1.0265 |     29.206 |     0.5
   27 |   0.4730 |     15.216 |   1.0437 |     29.175 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 598,113

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2985 |     62.298 |   1.6422 |     48.362 |     0.0
    2 |   1.4983 |     46.500 |   1.4288 |     45.526 |     0.0
    3 |   1.4114 |     46.285 |   1.3933 |     45.810 |     0.1
    4 |   1.3827 |     46.093 |   1.3585 |     43.888 |     0.1
    5 |   1.3381 |     44.675 |   1.3179 |     43.100 |     0.1
    6 |   1.3015 |     43.697 |   1.2880 |     43.132 |     0.1
    7 |   1.2735 |     42.834 |   1.2654 |     42.407 |     0.1
    8 |   1.2443 |     41.527 |   1.2422 |     40.422 |     0.2
    9 |   1.2173 |     40.807 |   1.2142 |     40.013 |     0.2
   10 |   1.1839 |     39.570 |   1.1827 |     39.193 |     0.2
   11 |   1.1530 |     38.708 |   1.1792 |     38.374 |     0.2
   12 |   1.1204 |     37.587 |   1.1420 |     37.650 |     0.2
   13 |   1.0889 |     36.608 |   1.1206 |     37.177 |     0.2
   14 |   1.0597 |     35.900 |   1.1011 |     37.051 |     0.3
   15 |   1.0161 |     34.438 |   1.0890 |     35.476 |     0.3
   16 |   0.9923 |     33.289 |   1.0735 |     34.783 |     0.3
   17 |   0.9535 |     32.273 |   1.0737 |     35.161 |     0.3
   18 |   0.9232 |     31.069 |   1.0504 |     34.184 |     0.3
   19 |   0.8931 |     29.783 |   1.0292 |     32.861 |     0.4
   20 |   0.8548 |     28.443 |   1.0259 |     32.168 |     0.4
   21 |   0.8241 |     27.300 |   1.0170 |     32.451 |     0.4
   22 |   0.8013 |     26.503 |   1.0106 |     32.042 |     0.4
   23 |   0.7616 |     25.371 |   1.0146 |     31.947 |     0.4
   24 |   0.7397 |     24.514 |   1.0078 |     32.073 |     0.5
   25 |   0.7120 |     23.305 |   0.9965 |     30.876 |     0.5
   26 |   0.6849 |     22.684 |   0.9757 |     30.183 |     0.5
   27 |   0.6517 |     20.997 |   0.9836 |     30.498 |     0.5
   28 |   0.6343 |     20.442 |   1.0085 |     30.561 |     0.5
   29 |   0.6072 |     19.881 |   0.9966 |     30.466 |     0.5
   30 |   0.5804 |     18.804 |   1.0006 |     29.584 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 207,489

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4399 |     65.881 |   1.8187 |     49.874 |     0.0
    2 |   1.6132 |     47.428 |   1.4792 |     45.526 |     0.0
    3 |   1.4302 |     46.197 |   1.3868 |     45.432 |     0.0
    4 |   1.3536 |     44.406 |   1.3143 |     42.060 |     0.1
    5 |   1.2849 |     41.752 |   1.2575 |     40.296 |     0.1
    6 |   1.2295 |     40.340 |   1.2152 |     39.319 |     0.1
    7 |   1.1854 |     39.257 |   1.1959 |     38.878 |     0.1
    8 |   1.1399 |     38.142 |   1.1529 |     37.618 |     0.1
    9 |   1.1028 |     36.812 |   1.1250 |     36.894 |     0.1
   10 |   1.0649 |     34.993 |   1.0949 |     34.940 |     0.1
   11 |   1.0190 |     33.509 |   1.0801 |     34.972 |     0.1
   12 |   0.9784 |     32.058 |   1.0569 |     33.333 |     0.2
   13 |   0.9378 |     30.602 |   1.0342 |     33.837 |     0.2
   14 |   0.9033 |     29.223 |   1.0413 |     33.365 |     0.2
   15 |   0.8613 |     27.998 |   0.9996 |     31.506 |     0.2
   16 |   0.8227 |     26.580 |   0.9983 |     30.592 |     0.2
   17 |   0.7892 |     25.173 |   0.9764 |     29.805 |     0.2
   18 |   0.7574 |     24.124 |   0.9785 |     30.435 |     0.2
   19 |   0.7245 |     23.107 |   0.9678 |     30.435 |     0.2
   20 |   0.6933 |     22.035 |   0.9545 |     29.742 |     0.3
   21 |   0.6597 |     20.563 |   0.9518 |     29.269 |     0.3
   22 |   0.6254 |     19.458 |   0.9409 |     28.544 |     0.3
   23 |   0.5993 |     18.205 |   0.9553 |     29.049 |     0.3
   24 |   0.5765 |     17.755 |   0.9581 |     29.206 |     0.3
   25 |   0.5489 |     16.864 |   0.9535 |     28.450 |     0.3
   26 |   0.5229 |     15.936 |   0.9595 |     28.607 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 300,769

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3902 |     63.122 |   1.7964 |     48.456 |     0.0
    2 |   1.6076 |     47.906 |   1.4742 |     45.054 |     0.0
    3 |   1.4270 |     45.978 |   1.3854 |     44.612 |     0.1
    4 |   1.3501 |     44.450 |   1.3247 |     42.565 |     0.1
    5 |   1.2923 |     42.477 |   1.2737 |     40.422 |     0.1
    6 |   1.2406 |     40.515 |   1.2225 |     39.950 |     0.1
    7 |   1.1961 |     39.153 |   1.1998 |     39.130 |     0.1
    8 |   1.1584 |     38.120 |   1.1546 |     38.248 |     0.1
    9 |   1.1146 |     36.927 |   1.1253 |     37.209 |     0.2
   10 |   1.0787 |     35.878 |   1.1029 |     36.169 |     0.2
   11 |   1.0399 |     34.377 |   1.0739 |     34.058 |     0.2
   12 |   0.9976 |     32.537 |   1.0462 |     33.365 |     0.2
   13 |   0.9573 |     30.948 |   1.0417 |     32.766 |     0.2
   14 |   0.9179 |     29.267 |   1.0202 |     31.853 |     0.2
   15 |   0.8821 |     28.151 |   0.9925 |     30.750 |     0.3
   16 |   0.8466 |     26.684 |   0.9836 |     30.939 |     0.3
   17 |   0.8152 |     25.778 |   0.9619 |     29.616 |     0.3
   18 |   0.7829 |     24.365 |   0.9565 |     29.836 |     0.3
   19 |   0.7524 |     23.618 |   0.9311 |     27.946 |     0.3
   20 |   0.7158 |     22.376 |   0.9396 |     28.544 |     0.3
   21 |   0.6962 |     21.585 |   0.9201 |     28.009 |     0.4
   22 |   0.6684 |     21.063 |   0.9344 |     28.261 |     0.4
   23 |   0.6365 |     19.480 |   0.9193 |     27.946 |     0.4
   24 |   0.6161 |     19.189 |   0.9105 |     26.875 |     0.4
   25 |   0.5959 |     18.425 |   0.9106 |     27.284 |     0.4
   26 |   0.5813 |     18.205 |   0.9195 |     27.442 |     0.5
   27 |   0.5581 |     17.419 |   0.9088 |     26.560 |     0.5
   28 |   0.5346 |     16.540 |   0.9148 |     26.528 |     0.5
   29 |   0.5206 |     16.172 |   0.9145 |     26.371 |     0.5
   30 |   0.5105 |     15.853 |   0.9251 |     27.253 |     0.5
   31 |   0.4932 |     15.260 |   0.9157 |     25.425 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 2,245,921

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2028 |     60.765 |   1.6129 |     45.432 |     0.1
    2 |   1.4885 |     46.445 |   1.4357 |     45.432 |     0.1
    3 |   1.4157 |     46.296 |   1.4011 |     45.432 |     0.2
    4 |   1.4023 |     46.357 |   1.3954 |     45.463 |     0.2
    5 |   1.3959 |     46.313 |   1.3904 |     45.432 |     0.3
    6 |   1.3936 |     46.340 |   1.3921 |     45.432 |     0.4
    7 |   1.3869 |     46.049 |   1.3769 |     44.707 |     0.4
    8 |   1.3632 |     45.071 |   1.3481 |     43.919 |     0.5
    9 |   1.3438 |     44.681 |   1.3441 |     44.045 |     0.6
   10 |   1.3282 |     44.417 |   1.3242 |     43.573 |     0.6
   11 |   1.3106 |     43.774 |   1.3324 |     43.636 |     0.7
   12 |   1.3032 |     43.659 |   1.3165 |     43.132 |     0.8
   13 |   1.2952 |     43.483 |   1.2989 |     43.006 |     0.8
   14 |   1.2805 |     42.779 |   1.3029 |     42.754 |     0.9
   15 |   1.2721 |     42.735 |   1.2867 |     42.124 |     0.9
   16 |   1.2644 |     42.411 |   1.2806 |     42.281 |     1.0
   17 |   1.2514 |     42.219 |   1.2701 |     41.430 |     1.1
   18 |   1.2400 |     41.592 |   1.2676 |     41.714 |     1.1
   19 |   1.2335 |     41.411 |   1.2591 |     41.367 |     1.2
   20 |   1.2188 |     40.609 |   1.2557 |     40.832 |     1.3
   21 |   1.2141 |     40.559 |   1.2481 |     40.832 |     1.3
   22 |   1.2016 |     40.373 |   1.2511 |     41.084 |     1.4
   23 |   1.1914 |     40.103 |   1.2318 |     40.170 |     1.4
   24 |   1.1775 |     39.197 |   1.2309 |     41.273 |     1.5
   25 |   1.1647 |     38.938 |   1.2248 |     39.666 |     1.6
   26 |   1.1539 |     38.433 |   1.2119 |     39.288 |     1.6
   27 |   1.1457 |     38.037 |   1.2041 |     38.280 |     1.7
   28 |   1.1304 |     37.883 |   1.2015 |     38.941 |     1.8
   29 |   1.1216 |     37.471 |   1.2047 |     38.752 |     1.8
   30 |   1.1055 |     36.938 |   1.1876 |     37.807 |     1.9
   31 |   1.0963 |     36.757 |   1.2139 |     38.626 |     1.9
   32 |   1.0753 |     36.092 |   1.1785 |     37.555 |     2.0
   33 |   1.0576 |     35.465 |   1.1634 |     37.839 |     2.1
   34 |   1.0471 |     35.284 |   1.1569 |     36.830 |     2.1
   35 |   1.0358 |     34.927 |   1.1601 |     37.744 |     2.2
   36 |   1.0263 |     34.268 |   1.1683 |     37.492 |     2.3
   37 |   1.0123 |     33.888 |   1.1519 |     36.704 |     2.3
   38 |   0.9911 |     33.075 |   1.1376 |     36.295 |     2.4
   39 |   0.9779 |     32.630 |   1.1336 |     35.885 |     2.5
   40 |   0.9610 |     31.894 |   1.1371 |     36.862 |     2.5
   41 |   0.9469 |     31.438 |   1.1257 |     35.318 |     2.6
   42 |   0.9403 |     31.498 |   1.1367 |     35.570 |     2.6
   43 |   0.9265 |     30.987 |   1.1472 |     36.358 |     2.7
   44 |   0.9106 |     30.349 |   1.1328 |     35.507 |     2.8
   45 |   0.8923 |     29.690 |   1.1285 |     36.137 |     2.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 709,793

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5953 |     69.079 |   2.0548 |     56.648 |     0.0
    2 |   1.8416 |     52.247 |   1.6456 |     48.299 |     0.1
    3 |   1.5572 |     46.604 |   1.4835 |     45.432 |     0.1
    4 |   1.4617 |     46.291 |   1.4394 |     45.432 |     0.1
    5 |   1.4291 |     46.384 |   1.4139 |     45.432 |     0.1
    6 |   1.4123 |     46.291 |   1.4075 |     45.432 |     0.2
    7 |   1.4047 |     46.401 |   1.4010 |     45.432 |     0.2
    8 |   1.3996 |     46.291 |   1.3942 |     45.432 |     0.2
    9 |   1.3942 |     46.318 |   1.3845 |     45.432 |     0.2
   10 |   1.3776 |     46.142 |   1.3744 |     44.896 |     0.3
   11 |   1.3590 |     45.807 |   1.3419 |     44.675 |     0.3
   12 |   1.3410 |     45.758 |   1.3282 |     44.581 |     0.3
   13 |   1.3265 |     45.582 |   1.3253 |     44.802 |     0.3
   14 |   1.3133 |     45.357 |   1.2991 |     44.360 |     0.4
   15 |   1.3004 |     45.153 |   1.2953 |     44.707 |     0.4
   16 |   1.2930 |     44.736 |   1.2904 |     43.667 |     0.4
   17 |   1.2758 |     44.175 |   1.2764 |     43.195 |     0.4
   18 |   1.2652 |     43.703 |   1.2637 |     43.100 |     0.5
   19 |   1.2536 |     43.400 |   1.2583 |     42.817 |     0.5
   20 |   1.2393 |     42.994 |   1.2392 |     42.092 |     0.5
   21 |   1.2263 |     42.263 |   1.2248 |     41.115 |     0.5
   22 |   1.2051 |     41.175 |   1.2109 |     40.548 |     0.6
   23 |   1.1889 |     40.691 |   1.1998 |     40.674 |     0.6
   24 |   1.1736 |     40.417 |   1.1850 |     40.233 |     0.6
   25 |   1.1602 |     39.801 |   1.1717 |     39.698 |     0.6
   26 |   1.1413 |     39.350 |   1.1656 |     38.878 |     0.7
   27 |   1.1341 |     38.982 |   1.1450 |     38.469 |     0.7
   28 |   1.1153 |     38.246 |   1.1459 |     38.280 |     0.7
   29 |   1.1079 |     37.938 |   1.1345 |     37.870 |     0.7
   30 |   1.0888 |     37.191 |   1.1379 |     37.965 |     0.8
   31 |   1.0869 |     37.103 |   1.1316 |     37.618 |     0.8
   32 |   1.0784 |     36.790 |   1.1199 |     36.894 |     0.8
   33 |   1.0581 |     35.823 |   1.1230 |     37.492 |     0.8
   34 |   1.0410 |     35.273 |   1.1187 |     37.492 |     0.9
   35 |   1.0294 |     35.064 |   1.1223 |     36.736 |     0.9
   36 |   1.0242 |     34.746 |   1.1011 |     36.799 |     0.9
   37 |   1.0101 |     34.476 |   1.1080 |     35.917 |     0.9
   38 |   1.0031 |     34.004 |   1.0885 |     35.444 |     1.0
   39 |   0.9987 |     33.822 |   1.0909 |     35.791 |     1.0
   40 |   0.9841 |     33.592 |   1.0882 |     35.759 |     1.0
   41 |   0.9832 |     33.515 |   1.0884 |     35.885 |     1.0
   42 |   0.9646 |     33.108 |   1.0901 |     35.854 |     1.1
   43 |   0.9600 |     33.086 |   1.0855 |     35.602 |     1.1
   44 |   0.9525 |     32.498 |   1.0710 |     34.688 |     1.1
   45 |   0.9505 |     32.361 |   1.0651 |     34.468 |     1.1
   46 |   0.9361 |     31.652 |   1.0929 |     35.822 |     1.2
   47 |   0.9325 |     31.905 |   1.0823 |     35.287 |     1.2
   48 |   0.9183 |     31.580 |   1.0790 |     35.665 |     1.2
   49 |   0.9094 |     31.009 |   1.0893 |     35.098 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 568,481

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1573 |     58.798 |   1.5461 |     45.463 |     0.0
    2 |   1.4176 |     45.208 |   1.3366 |     42.848 |     0.1
    3 |   1.2958 |     42.499 |   1.2656 |     39.887 |     0.1
    4 |   1.2125 |     39.933 |   1.1958 |     38.028 |     0.1
    5 |   1.1444 |     37.740 |   1.1464 |     37.083 |     0.1
    6 |   1.0802 |     35.493 |   1.1034 |     35.728 |     0.2
    7 |   1.0085 |     32.982 |   1.0606 |     33.396 |     0.2
    8 |   0.9474 |     30.196 |   1.0219 |     31.979 |     0.2
    9 |   0.8776 |     28.107 |   1.0006 |     31.380 |     0.2
   10 |   0.8132 |     26.041 |   0.9824 |     30.025 |     0.3
   11 |   0.7548 |     23.876 |   0.9632 |     29.773 |     0.3
   12 |   0.7004 |     22.178 |   0.9311 |     28.891 |     0.3
   13 |   0.6415 |     20.431 |   0.9152 |     27.631 |     0.3
   14 |   0.5932 |     18.551 |   0.8971 |     27.284 |     0.4
   15 |   0.5441 |     16.606 |   0.9065 |     26.623 |     0.4
   16 |   0.4986 |     15.419 |   0.9177 |     27.316 |     0.4
   17 |   0.4626 |     14.040 |   0.8796 |     25.835 |     0.5
   18 |   0.4182 |     12.501 |   0.9048 |     26.307 |     0.5
   19 |   0.3941 |     11.787 |   0.8997 |     26.402 |     0.5
   20 |   0.3602 |     10.545 |   0.9061 |     25.677 |     0.5
   21 |   0.3358 |     10.122 |   0.9421 |     25.488 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 2,520,417

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4537 |     65.787 |   1.9602 |     54.348 |     0.9
    2 |   1.7564 |     49.852 |   1.5631 |     45.463 |     1.9
    3 |   1.4943 |     46.362 |   1.4430 |     45.463 |     2.8
    4 |   1.4265 |     46.351 |   1.4046 |     45.463 |     3.8
    5 |   1.3925 |     45.703 |   1.3837 |     44.140 |     4.8
    6 |   1.3635 |     44.840 |   1.3598 |     43.856 |     5.8
    7 |   1.3432 |     44.373 |   1.3371 |     43.132 |     6.7
    8 |   1.3232 |     43.697 |   1.3152 |     42.218 |     7.7
    9 |   1.3052 |     43.027 |   1.2987 |     41.682 |     8.6
   10 |   1.2854 |     42.675 |   1.2828 |     41.241 |     9.6
   11 |   1.2673 |     41.823 |   1.2800 |     41.840 |    10.5
   12 |   1.2567 |     41.917 |   1.2718 |     40.548 |    11.5
   13 |   1.2451 |     41.219 |   1.2552 |     40.517 |    12.4
   14 |   1.2241 |     40.609 |   1.2365 |     40.517 |    13.4
   15 |   1.2081 |     40.400 |   1.2197 |     39.540 |    14.4
   16 |   1.1911 |     39.862 |   1.2116 |     39.950 |    15.3
   17 |   1.1753 |     39.290 |   1.1990 |     38.500 |    16.3
   18 |   1.1611 |     38.763 |   1.1905 |     38.910 |    17.3
   19 |   1.1466 |     38.207 |   1.1709 |     37.492 |    18.2
   20 |   1.1288 |     37.433 |   1.1540 |     37.240 |    19.2
   21 |   1.1252 |     37.504 |   1.1826 |     38.469 |    20.2
   22 |   1.1165 |     37.301 |   1.1421 |     36.515 |    21.1
   23 |   1.0908 |     36.174 |   1.1378 |     36.830 |    22.1
   24 |   1.0722 |     35.504 |   1.1214 |     36.326 |    23.1
   25 |   1.0524 |     34.877 |   1.0988 |     35.791 |    24.0
   26 |   1.0378 |     34.647 |   1.1092 |     35.539 |    25.0
   27 |   1.0319 |     34.487 |   1.0856 |     34.814 |    26.0
   28 |   1.0164 |     33.559 |   1.0979 |     35.885 |    26.9
   29 |   0.9983 |     33.059 |   1.1037 |     35.791 |    27.9
   30 |   0.9949 |     32.844 |   1.0864 |     35.444 |    28.8
   31 |   0.9832 |     32.597 |   1.0606 |     34.594 |    29.8
   32 |   0.9809 |     32.855 |   1.0783 |     34.783 |    30.8
   33 |   0.9638 |     32.267 |   1.0715 |     35.066 |    31.7
   34 |   0.9471 |     31.641 |   1.0622 |     33.900 |    32.7
   35 |   0.9354 |     31.097 |   1.0600 |     34.247 |    33.7
   36 |   0.9318 |     31.207 |   1.0770 |     34.783 |    34.6
   37 |   0.9320 |     30.970 |   1.0562 |     33.806 |    35.6
   38 |   0.9100 |     30.569 |   1.0598 |     33.869 |    36.6
   39 |   0.9230 |     30.591 |   1.0551 |     33.459 |    37.6
   40 |   0.9080 |     30.267 |   1.0521 |     34.468 |    38.5
   41 |   0.8866 |     29.619 |   1.0557 |     33.932 |    39.5
   42 |   0.8755 |     29.465 |   1.0370 |     33.869 |    40.5
   43 |   0.8495 |     28.201 |   1.0355 |     32.987 |    41.4
   44 |   0.8452 |     28.212 |   1.0344 |     32.766 |    42.4
   45 |   0.8373 |     27.844 |   1.0420 |     32.514 |    43.3
   46 |   0.8319 |     27.756 |   1.0250 |     32.672 |    44.3
   47 |   0.8240 |     27.618 |   1.0266 |     32.420 |    45.3
   48 |   0.8156 |     27.371 |   1.0346 |     32.829 |    46.2
   49 |   0.8094 |     26.767 |   1.0066 |     31.821 |    47.2
   50 |   0.8165 |     27.162 |   1.0361 |     32.294 |    48.2
   51 |   0.8323 |     28.009 |   1.0181 |     32.609 |    49.1
   52 |   0.8019 |     26.855 |   1.0392 |     33.365 |    50.1
   53 |   0.7882 |     26.305 |   1.0081 |     31.884 |    51.1
   54 |   0.7759 |     26.003 |   1.0053 |     32.136 |    52.1
   55 |   0.7621 |     25.437 |   1.0237 |     32.168 |    53.0
   56 |   0.7623 |     25.431 |   1.0186 |     31.758 |    54.0
   57 |   0.7494 |     24.876 |   1.0119 |     31.979 |    55.0
   58 |   0.7540 |     25.223 |   1.0242 |     32.105 |    55.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 617,377

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2667 |     60.858 |   1.6685 |     48.551 |     0.0
    2 |   1.5070 |     46.549 |   1.4219 |     45.432 |     0.1
    3 |   1.3998 |     45.626 |   1.3660 |     43.919 |     0.1
    4 |   1.3432 |     44.357 |   1.3183 |     43.100 |     0.1
    5 |   1.3043 |     43.417 |   1.2941 |     41.966 |     0.1
    6 |   1.2658 |     42.450 |   1.2527 |     40.958 |     0.2
    7 |   1.2326 |     41.560 |   1.2380 |     40.989 |     0.2
    8 |   1.2061 |     40.922 |   1.2059 |     39.540 |     0.2
    9 |   1.1786 |     40.048 |   1.1777 |     39.004 |     0.2
   10 |   1.1498 |     39.252 |   1.1642 |     38.122 |     0.3
   11 |   1.1200 |     38.147 |   1.1429 |     37.650 |     0.3
   12 |   1.0873 |     37.037 |   1.1199 |     36.704 |     0.3
   13 |   1.0519 |     36.081 |   1.1020 |     36.704 |     0.3
   14 |   1.0201 |     34.757 |   1.0772 |     35.476 |     0.4
   15 |   0.9803 |     33.542 |   1.0613 |     35.003 |     0.4
   16 |   0.9428 |     31.921 |   1.0613 |     34.657 |     0.4
   17 |   0.9279 |     31.262 |   1.0420 |     34.310 |     0.4
   18 |   0.8833 |     29.855 |   1.0157 |     32.955 |     0.5
   19 |   0.8478 |     28.767 |   1.0082 |     32.703 |     0.5
   20 |   0.8122 |     27.316 |   0.9971 |     32.514 |     0.5
   21 |   0.7812 |     25.904 |   0.9876 |     32.231 |     0.6
   22 |   0.7543 |     24.898 |   0.9951 |     32.483 |     0.6
   23 |   0.7202 |     23.953 |   0.9971 |     32.010 |     0.6
   24 |   0.6967 |     23.283 |   0.9768 |     30.655 |     0.6
   25 |   0.6718 |     22.090 |   0.9785 |     29.994 |     0.7
   26 |   0.6461 |     21.250 |   0.9960 |     30.183 |     0.7
   27 |   0.6159 |     20.046 |   0.9795 |     29.521 |     0.7
   28 |   0.6042 |     20.107 |   0.9847 |     29.395 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 503,201

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6143 |     69.216 |   2.0457 |     58.759 |     0.0
    2 |   1.7957 |     50.764 |   1.5989 |     45.432 |     0.0
    3 |   1.5249 |     46.351 |   1.4645 |     45.432 |     0.1
    4 |   1.4449 |     46.318 |   1.4210 |     45.432 |     0.1
    5 |   1.4164 |     46.302 |   1.4036 |     45.432 |     0.1
    6 |   1.3965 |     46.340 |   1.3912 |     44.991 |     0.1
    7 |   1.3801 |     46.087 |   1.3671 |     45.180 |     0.1
    8 |   1.3603 |     45.307 |   1.3423 |     43.730 |     0.1
    9 |   1.3313 |     44.307 |   1.3308 |     43.447 |     0.2
   10 |   1.3074 |     43.845 |   1.2965 |     41.871 |     0.2
   11 |   1.2856 |     43.433 |   1.2746 |     41.966 |     0.2
   12 |   1.2602 |     42.279 |   1.2533 |     41.399 |     0.2
   13 |   1.2368 |     41.862 |   1.2324 |     40.611 |     0.2
   14 |   1.2217 |     41.625 |   1.2146 |     40.296 |     0.3
   15 |   1.1973 |     40.669 |   1.1987 |     39.414 |     0.3
   16 |   1.1810 |     40.373 |   1.1980 |     39.193 |     0.3
   17 |   1.1626 |     39.801 |   1.1757 |     38.595 |     0.3
   18 |   1.1412 |     38.653 |   1.1433 |     37.335 |     0.3
   19 |   1.1231 |     38.048 |   1.1536 |     38.752 |     0.4
   20 |   1.0957 |     37.092 |   1.1355 |     36.925 |     0.4
   21 |   1.0805 |     36.328 |   1.1268 |     36.389 |     0.4
   22 |   1.0639 |     35.531 |   1.1146 |     36.389 |     0.4
   23 |   1.0534 |     35.119 |   1.1071 |     36.389 |     0.4
   24 |   1.0324 |     34.548 |   1.0979 |     36.074 |     0.5
   25 |   1.0134 |     33.927 |   1.0824 |     35.633 |     0.5
   26 |   0.9876 |     32.943 |   1.0831 |     35.696 |     0.5
   27 |   0.9700 |     32.130 |   1.0784 |     34.940 |     0.5
   28 |   0.9525 |     31.157 |   1.0730 |     34.279 |     0.5
   29 |   0.9303 |     30.668 |   1.0639 |     33.869 |     0.5
   30 |   0.9246 |     30.454 |   1.0946 |     35.476 |     0.6
   31 |   0.9192 |     30.360 |   1.0698 |     34.625 |     0.6
   32 |   0.8931 |     29.228 |   1.0478 |     32.703 |     0.6
   33 |   0.8772 |     28.437 |   1.0392 |     33.176 |     0.6
   34 |   0.8546 |     27.541 |   1.0453 |     33.270 |     0.6
   35 |   0.8401 |     27.481 |   1.0466 |     33.018 |     0.7
   36 |   0.8318 |     26.986 |   1.0288 |     32.325 |     0.7
   37 |   0.8069 |     26.096 |   1.0272 |     32.357 |     0.7
   38 |   0.7966 |     25.706 |   1.0449 |     32.798 |     0.7
   39 |   0.7826 |     25.179 |   1.0383 |     32.672 |     0.7
   40 |   0.7722 |     24.591 |   1.0523 |     32.388 |     0.8
   41 |   0.7600 |     24.431 |   1.0455 |     31.695 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,092,897

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1372 |     57.803 |   1.5597 |     45.558 |     0.0
    2 |   1.4268 |     45.269 |   1.3697 |     42.785 |     0.1
    3 |   1.3085 |     42.763 |   1.2798 |     41.430 |     0.1
    4 |   1.2301 |     40.417 |   1.2023 |     38.878 |     0.1
    5 |   1.1618 |     38.026 |   1.1575 |     37.051 |     0.2
    6 |   1.0997 |     35.889 |   1.1207 |     35.633 |     0.2
    7 |   1.0451 |     34.042 |   1.0883 |     34.877 |     0.2
    8 |   0.9846 |     31.938 |   1.0555 |     34.405 |     0.3
    9 |   0.9305 |     30.146 |   1.0186 |     32.199 |     0.3
   10 |   0.8735 |     28.613 |   0.9854 |     31.065 |     0.4
   11 |   0.8286 |     27.047 |   1.0049 |     31.947 |     0.4
   12 |   0.7888 |     25.179 |   0.9885 |     31.727 |     0.4
   13 |   0.7472 |     24.058 |   0.9942 |     31.128 |     0.5
   14 |   0.7009 |     22.343 |   0.9665 |     29.962 |     0.5
   15 |   0.6582 |     21.090 |   0.9587 |     29.364 |     0.5
   16 |   0.6218 |     19.755 |   0.9793 |     29.458 |     0.6
   17 |   0.5899 |     18.909 |   0.9586 |     29.427 |     0.6
   18 |   0.5616 |     18.024 |   0.9723 |     28.954 |     0.6
   19 |   0.5293 |     16.793 |   0.9761 |     28.481 |     0.7
   20 |   0.4907 |     15.331 |   0.9626 |     28.324 |     0.7
   21 |   0.4572 |     14.546 |   0.9598 |     27.725 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 373,409

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2213 |     60.930 |   1.5903 |     46.030 |     0.0
    2 |   1.4363 |     45.236 |   1.3540 |     43.258 |     0.0
    3 |   1.3140 |     43.032 |   1.2851 |     41.714 |     0.1
    4 |   1.2423 |     40.785 |   1.2179 |     38.658 |     0.1
    5 |   1.1848 |     39.070 |   1.1845 |     38.343 |     0.1
    6 |   1.1313 |     37.422 |   1.1457 |     36.988 |     0.1
    7 |   1.0765 |     35.279 |   1.1141 |     35.444 |     0.1
    8 |   1.0245 |     33.449 |   1.0668 |     34.436 |     0.1
    9 |   0.9765 |     31.679 |   1.0386 |     33.081 |     0.2
   10 |   0.9266 |     29.921 |   1.0121 |     33.018 |     0.2
   11 |   0.8821 |     28.426 |   1.0021 |     32.010 |     0.2
   12 |   0.8387 |     27.201 |   0.9797 |     31.411 |     0.2
   13 |   0.7948 |     25.349 |   0.9587 |     30.687 |     0.2
   14 |   0.7612 |     24.613 |   0.9422 |     29.049 |     0.3
   15 |   0.7222 |     23.134 |   0.9327 |     29.175 |     0.3
   16 |   0.6861 |     21.810 |   0.9403 |     28.513 |     0.3
   17 |   0.6558 |     21.085 |   0.9521 |     28.986 |     0.3
   18 |   0.6218 |     19.859 |   0.9310 |     28.387 |     0.3
   19 |   0.5896 |     18.898 |   0.9182 |     27.694 |     0.4
   20 |   0.5633 |     17.903 |   0.9134 |     27.631 |     0.4
   21 |   0.5436 |     17.161 |   0.9037 |     26.686 |     0.4
   22 |   0.5194 |     16.447 |   0.9058 |     26.307 |     0.4
   23 |   0.4898 |     15.463 |   0.9110 |     26.497 |     0.4
   24 |   0.4682 |     14.963 |   0.9189 |     26.591 |     0.4
   25 |   0.4499 |     14.139 |   0.9177 |     26.560 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 709,793

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5995 |     69.727 |   2.0273 |     58.727 |     0.0
    2 |   1.7827 |     49.973 |   1.5884 |     45.432 |     0.1
    3 |   1.5190 |     46.324 |   1.4674 |     45.432 |     0.1
    4 |   1.4480 |     46.296 |   1.4258 |     45.432 |     0.1
    5 |   1.4224 |     46.291 |   1.4142 |     45.432 |     0.1
    6 |   1.4091 |     46.296 |   1.4028 |     45.463 |     0.2
    7 |   1.4023 |     46.269 |   1.3999 |     45.432 |     0.2
    8 |   1.3971 |     46.203 |   1.3945 |     45.243 |     0.2
    9 |   1.3920 |     46.170 |   1.3834 |     45.400 |     0.2
   10 |   1.3821 |     45.994 |   1.3761 |     44.297 |     0.3
   11 |   1.3644 |     45.038 |   1.3526 |     44.171 |     0.3
   12 |   1.3488 |     44.840 |   1.3468 |     43.856 |     0.3
   13 |   1.3355 |     44.824 |   1.3410 |     44.140 |     0.3
   14 |   1.3259 |     44.582 |   1.3231 |     43.951 |     0.4
   15 |   1.3174 |     44.296 |   1.3238 |     43.321 |     0.4
   16 |   1.3108 |     43.977 |   1.3184 |     43.573 |     0.4
   17 |   1.2986 |     43.444 |   1.3093 |     42.848 |     0.4
   18 |   1.2911 |     43.241 |   1.3016 |     43.163 |     0.5
   19 |   1.2822 |     43.093 |   1.3010 |     43.258 |     0.5
   20 |   1.2775 |     42.768 |   1.2910 |     42.155 |     0.5
   21 |   1.2736 |     42.615 |   1.3013 |     42.376 |     0.5
   22 |   1.2630 |     42.389 |   1.2843 |     42.596 |     0.6
   23 |   1.2565 |     42.224 |   1.2828 |     41.997 |     0.6
   24 |   1.2517 |     42.235 |   1.2641 |     41.840 |     0.6
   25 |   1.2446 |     41.675 |   1.2761 |     41.556 |     0.6
   26 |   1.2421 |     41.571 |   1.2579 |     41.147 |     0.7
   27 |   1.2278 |     41.279 |   1.2561 |     40.832 |     0.7
   28 |   1.2225 |     40.873 |   1.2467 |     40.454 |     0.7
   29 |   1.2106 |     40.878 |   1.2437 |     40.958 |     0.8
   30 |   1.2039 |     40.439 |   1.2362 |     40.611 |     0.8
   31 |   1.1956 |     40.422 |   1.2315 |     40.359 |     0.8
   32 |   1.1861 |     40.208 |   1.2341 |     40.517 |     0.8
   33 |   1.1743 |     40.081 |   1.2127 |     39.162 |     0.9
   34 |   1.1688 |     39.686 |   1.2232 |     38.752 |     0.9
   35 |   1.1612 |     39.680 |   1.2089 |     39.666 |     0.9
   36 |   1.1487 |     39.208 |   1.1952 |     38.878 |     0.9
   37 |   1.1389 |     38.911 |   1.1935 |     38.248 |     1.0
   38 |   1.1337 |     38.675 |   1.1672 |     37.902 |     1.0
   39 |   1.1205 |     38.268 |   1.1714 |     38.374 |     1.0
   40 |   1.1092 |     37.790 |   1.1529 |     37.650 |     1.0
   41 |   1.0849 |     36.713 |   1.1558 |     37.020 |     1.1
   42 |   1.0797 |     36.823 |   1.1550 |     37.114 |     1.1
   43 |   1.0703 |     36.691 |   1.1363 |     36.547 |     1.1
   44 |   1.0529 |     35.828 |   1.1476 |     37.020 |     1.1
   45 |   1.0463 |     35.515 |   1.1214 |     35.287 |     1.2
   46 |   1.0334 |     35.207 |   1.1363 |     36.704 |     1.2
   47 |   1.0190 |     34.504 |   1.1069 |     35.129 |     1.2
   48 |   1.0102 |     34.125 |   1.1081 |     35.948 |     1.3
   49 |   1.0016 |     33.943 |   1.1016 |     35.633 |     1.3
   50 |   0.9924 |     33.438 |   1.1013 |     35.035 |     1.3
   51 |   1.0001 |     33.597 |   1.1149 |     35.759 |     1.3
   52 |   0.9889 |     33.625 |   1.1129 |     35.980 |     1.4
   53 |   0.9623 |     32.311 |   1.0949 |     35.224 |     1.4
   54 |   0.9497 |     32.267 |   1.0857 |     35.066 |     1.4
   55 |   0.9382 |     31.608 |   1.0957 |     35.098 |     1.4
   56 |   0.9299 |     31.141 |   1.0783 |     34.751 |     1.5
   57 |   0.9261 |     31.262 |   1.0731 |     33.963 |     1.5
   58 |   0.9073 |     30.338 |   1.0772 |     33.963 |     1.5
   59 |   0.8990 |     30.179 |   1.0685 |     34.405 |     1.5
   60 |   0.8875 |     29.811 |   1.0748 |     34.342 |     1.6
   61 |   0.8792 |     29.179 |   1.0683 |     34.373 |     1.6
   62 |   0.8674 |     29.102 |   1.0681 |     33.554 |     1.6
   63 |   0.8621 |     28.789 |   1.0751 |     34.468 |     1.6
   64 |   0.8490 |     28.531 |   1.0532 |     32.924 |     1.7
   65 |   0.8389 |     27.915 |   1.0655 |     32.924 |     1.7
   66 |   0.8299 |     27.756 |   1.0593 |     33.617 |     1.7
   67 |   0.8313 |     27.558 |   1.0635 |     33.270 |     1.8
   68 |   0.8149 |     26.965 |   1.0477 |     33.050 |     1.8
   69 |   0.8026 |     27.019 |   1.0521 |     33.270 |     1.8
   70 |   0.7857 |     26.223 |   1.0594 |     33.113 |     1.8
   71 |   0.7798 |     26.036 |   1.0552 |     33.050 |     1.9
   72 |   0.7752 |     25.789 |   1.0468 |     33.144 |     1.9
   73 |   0.7644 |     25.294 |   1.0526 |     32.609 |     1.9
   74 |   0.7644 |     25.536 |   1.0537 |     32.955 |     1.9
   75 |   0.7567 |     24.975 |   1.0554 |     32.483 |     2.0
   76 |   0.7544 |     25.168 |   1.0656 |     32.735 |     2.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,140,609

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3124 |     63.320 |   1.6641 |     48.299 |     0.0
    2 |   1.4996 |     46.516 |   1.4235 |     45.810 |     0.1
    3 |   1.4086 |     46.247 |   1.3935 |     45.463 |     0.1
    4 |   1.3741 |     45.917 |   1.3463 |     44.865 |     0.1
    5 |   1.3455 |     45.675 |   1.3260 |     44.486 |     0.2
    6 |   1.3135 |     45.313 |   1.2999 |     44.203 |     0.2
    7 |   1.2869 |     44.659 |   1.2854 |     43.478 |     0.3
    8 |   1.2601 |     43.477 |   1.2329 |     41.745 |     0.3
    9 |   1.2269 |     42.087 |   1.2315 |     42.155 |     0.3
   10 |   1.2090 |     41.675 |   1.2069 |     40.863 |     0.4
   11 |   1.1828 |     41.208 |   1.1836 |     40.139 |     0.4
   12 |   1.1595 |     39.949 |   1.1754 |     39.099 |     0.4
   13 |   1.1424 |     39.076 |   1.1608 |     38.658 |     0.5
   14 |   1.1249 |     38.301 |   1.1467 |     38.910 |     0.5
   15 |   1.1005 |     37.372 |   1.1556 |     38.217 |     0.5
   16 |   1.0833 |     37.174 |   1.1240 |     37.524 |     0.6
   17 |   1.0678 |     36.257 |   1.1075 |     37.681 |     0.6
   18 |   1.0462 |     35.883 |   1.0990 |     36.641 |     0.7
   19 |   1.0222 |     34.740 |   1.0977 |     36.326 |     0.7
   20 |   1.0054 |     34.570 |   1.0773 |     36.137 |     0.7
   21 |   0.9851 |     33.647 |   1.0752 |     35.602 |     0.8
   22 |   0.9643 |     32.548 |   1.0670 |     34.877 |     0.8
   23 |   0.9457 |     31.839 |   1.0830 |     35.413 |     0.8
   24 |   0.9186 |     31.366 |   1.0434 |     33.932 |     0.9
   25 |   0.8996 |     30.509 |   1.0600 |     35.066 |     0.9
   26 |   0.8863 |     30.141 |   1.0366 |     33.270 |     0.9
   27 |   0.8712 |     29.316 |   1.0482 |     33.932 |     1.0
   28 |   0.8510 |     28.355 |   1.0385 |     33.050 |     1.0
   29 |   0.8360 |     27.937 |   1.0297 |     32.546 |     1.0
   30 |   0.8180 |     27.481 |   1.0305 |     32.231 |     1.1
   31 |   0.7923 |     26.536 |   1.0332 |     32.798 |     1.1
   32 |   0.7873 |     26.591 |   1.0291 |     32.105 |     1.2
   33 |   0.7639 |     25.305 |   1.0461 |     32.199 |     1.2
   34 |   0.7531 |     24.986 |   1.0300 |     31.884 |     1.2
   35 |   0.7465 |     24.701 |   1.0019 |     31.096 |     1.3
   36 |   0.7164 |     23.574 |   0.9934 |     29.742 |     1.3
   37 |   0.6986 |     22.832 |   1.0117 |     30.435 |     1.3
   38 |   0.6959 |     22.975 |   1.0245 |     30.088 |     1.4
   39 |   0.6731 |     22.107 |   0.9900 |     29.710 |     1.4
   40 |   0.6605 |     21.640 |   1.0050 |     30.057 |     1.4
   41 |   0.6508 |     21.294 |   1.0148 |     30.655 |     1.5
   42 |   0.6296 |     20.403 |   1.0191 |     30.151 |     1.5
   43 |   0.6144 |     20.332 |   1.0416 |     30.718 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,194,081

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2609 |     61.606 |   1.6355 |     45.432 |     0.0
    2 |   1.4983 |     46.445 |   1.4267 |     45.432 |     0.1
    3 |   1.4152 |     46.379 |   1.4058 |     45.432 |     0.1
    4 |   1.3962 |     46.417 |   1.3857 |     45.432 |     0.2
    5 |   1.3745 |     46.082 |   1.3648 |     44.171 |     0.2
    6 |   1.3373 |     44.604 |   1.3181 |     43.321 |     0.2
    7 |   1.3187 |     44.620 |   1.2956 |     43.069 |     0.3
    8 |   1.2891 |     43.593 |   1.2842 |     42.313 |     0.3
    9 |   1.2666 |     42.889 |   1.2588 |     41.903 |     0.4
   10 |   1.2402 |     42.241 |   1.2226 |     40.233 |     0.4
   11 |   1.2108 |     41.158 |   1.2010 |     39.036 |     0.4
   12 |   1.1916 |     40.307 |   1.1968 |     39.635 |     0.5
   13 |   1.1715 |     39.576 |   1.1832 |     39.256 |     0.5
   14 |   1.1494 |     39.004 |   1.1502 |     38.028 |     0.5
   15 |   1.1270 |     38.081 |   1.1555 |     37.744 |     0.6
   16 |   1.1114 |     37.674 |   1.1492 |     38.374 |     0.6
   17 |   1.0991 |     37.185 |   1.1428 |     38.028 |     0.7
   18 |   1.0832 |     36.845 |   1.1248 |     37.272 |     0.7
   19 |   1.0513 |     36.042 |   1.1356 |     37.492 |     0.7
   20 |   1.0301 |     35.213 |   1.1000 |     36.484 |     0.8
   21 |   1.0024 |     34.344 |   1.1054 |     36.011 |     0.8
   22 |   0.9839 |     33.795 |   1.0955 |     36.358 |     0.9
   23 |   0.9732 |     32.949 |   1.0826 |     35.287 |     0.9
   24 |   0.9384 |     31.883 |   1.0742 |     35.161 |     0.9
   25 |   0.9209 |     31.196 |   1.0859 |     35.287 |     1.0
   26 |   0.9109 |     30.806 |   1.0633 |     34.657 |     1.0
   27 |   0.8851 |     30.042 |   1.0717 |     33.900 |     1.1
   28 |   0.8663 |     29.075 |   1.0534 |     33.869 |     1.1
   29 |   0.8344 |     28.294 |   1.0535 |     33.491 |     1.1
   30 |   0.8084 |     27.157 |   1.0378 |     32.924 |     1.2
   31 |   0.7902 |     26.541 |   1.0517 |     33.270 |     1.2
   32 |   0.7702 |     25.772 |   1.0336 |     32.451 |     1.2
   33 |   0.7513 |     24.975 |   1.0315 |     33.081 |     1.3
   34 |   0.7205 |     23.942 |   1.0284 |     32.609 |     1.3
   35 |   0.7040 |     23.228 |   1.0353 |     32.514 |     1.4
   36 |   0.6839 |     22.546 |   1.0395 |     31.664 |     1.4
   37 |   0.6704 |     22.074 |   1.0412 |     31.632 |     1.4
   38 |   0.6500 |     21.722 |   1.0086 |     29.647 |     1.5
   39 |   0.6269 |     20.354 |   1.0144 |     30.624 |     1.5
   40 |   0.6012 |     19.760 |   1.0222 |     29.143 |     1.6
   41 |   0.5812 |     19.112 |   1.0393 |     29.868 |     1.6
   42 |   0.5693 |     18.711 |   1.0294 |     29.710 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 598,753

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2146 |     60.545 |   1.5720 |     45.684 |     0.0
    2 |   1.4463 |     45.642 |   1.3732 |     43.762 |     0.0
    3 |   1.3278 |     43.197 |   1.3004 |     41.588 |     0.1
    4 |   1.2608 |     41.757 |   1.2441 |     39.761 |     0.1
    5 |   1.2054 |     40.296 |   1.1945 |     38.532 |     0.1
    6 |   1.1534 |     38.339 |   1.1453 |     37.083 |     0.1
    7 |   1.0961 |     36.383 |   1.1082 |     35.413 |     0.2
    8 |   1.0458 |     34.410 |   1.0709 |     33.837 |     0.2
    9 |   1.0078 |     33.031 |   1.0497 |     32.672 |     0.2
   10 |   0.9457 |     30.970 |   1.0270 |     33.207 |     0.2
   11 |   0.8948 |     29.250 |   1.0097 |     32.325 |     0.3
   12 |   0.8431 |     27.580 |   0.9894 |     31.285 |     0.3
   13 |   0.8025 |     25.953 |   0.9662 |     30.876 |     0.3
   14 |   0.7648 |     24.783 |   0.9627 |     30.088 |     0.3
   15 |   0.7130 |     23.420 |   0.9641 |     30.025 |     0.3
   16 |   0.6817 |     22.052 |   0.9414 |     28.765 |     0.4
   17 |   0.6457 |     20.744 |   0.9252 |     28.702 |     0.4
   18 |   0.6062 |     19.381 |   0.9344 |     28.387 |     0.4
   19 |   0.5802 |     18.914 |   0.9175 |     27.631 |     0.4
   20 |   0.5508 |     17.804 |   0.9170 |     27.788 |     0.5
   21 |   0.5284 |     17.007 |   0.9146 |     27.379 |     0.5
   22 |   0.4918 |     15.886 |   0.9275 |     27.253 |     0.5
   23 |   0.4634 |     14.760 |   0.9184 |     26.654 |     0.5
   24 |   0.4481 |     14.243 |   0.9310 |     26.623 |     0.6
   25 |   0.4287 |     13.710 |   0.9529 |     27.064 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,654,881

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2816 |     62.870 |   1.6490 |     45.432 |     0.5
    2 |   1.5065 |     46.406 |   1.4371 |     45.432 |     1.0
    3 |   1.4175 |     46.318 |   1.4010 |     45.432 |     1.5
    4 |   1.4019 |     46.357 |   1.3959 |     45.432 |     2.0
    5 |   1.3975 |     46.401 |   1.4010 |     45.558 |     2.5
    6 |   1.3920 |     46.456 |   1.3873 |     44.739 |     2.9
    7 |   1.3808 |     45.758 |   1.3625 |     43.888 |     3.4
    8 |   1.3548 |     45.005 |   1.3431 |     43.636 |     3.9
    9 |   1.3402 |     44.752 |   1.3342 |     44.108 |     4.4
   10 |   1.3213 |     44.527 |   1.3183 |     43.856 |     4.9
   11 |   1.3066 |     44.054 |   1.3105 |     43.636 |     5.4
   12 |   1.2954 |     43.406 |   1.2970 |     42.470 |     5.9
   13 |   1.2801 |     43.087 |   1.2824 |     41.808 |     6.4
   14 |   1.2651 |     42.571 |   1.2853 |     41.777 |     6.9
   15 |   1.2533 |     42.202 |   1.2716 |     41.714 |     7.4
   16 |   1.2389 |     41.713 |   1.2587 |     41.241 |     7.9
   17 |   1.2258 |     41.219 |   1.2487 |     41.430 |     8.4
   18 |   1.2150 |     40.994 |   1.2399 |     40.580 |     8.9
   19 |   1.1983 |     40.191 |   1.2348 |     40.548 |     9.4
   20 |   1.1845 |     39.851 |   1.2345 |     40.895 |     9.8
   21 |   1.1684 |     39.323 |   1.2088 |     39.099 |    10.3
   22 |   1.1563 |     39.076 |   1.2022 |     39.036 |    10.8
   23 |   1.1410 |     38.164 |   1.2061 |     38.248 |    11.3
   24 |   1.1297 |     38.153 |   1.1826 |     37.965 |    11.8
   25 |   1.1101 |     37.054 |   1.1894 |     37.996 |    12.3
   26 |   1.0978 |     36.922 |   1.1679 |     37.177 |    12.8
   27 |   1.0855 |     36.114 |   1.1683 |     37.051 |    13.3
   28 |   1.0645 |     35.460 |   1.1663 |     37.083 |    13.8
   29 |   1.0611 |     35.345 |   1.1605 |     37.303 |    14.3
   30 |   1.0510 |     34.757 |   1.1598 |     37.146 |    14.8
   31 |   1.0324 |     34.377 |   1.1584 |     36.358 |    15.3
   32 |   1.0167 |     33.691 |   1.1419 |     35.917 |    15.8
   33 |   0.9985 |     33.284 |   1.1515 |     36.704 |    16.3
   34 |   0.9950 |     33.119 |   1.1554 |     37.114 |    16.8
   35 |   0.9756 |     32.553 |   1.1366 |     36.106 |    17.3
   36 |   0.9565 |     31.932 |   1.1402 |     36.484 |    17.8
   37 |   0.9456 |     31.350 |   1.1321 |     35.318 |    18.3
   38 |   0.9252 |     30.542 |   1.1289 |     35.885 |    18.8
   39 |   0.9239 |     30.800 |   1.1376 |     35.570 |    19.3
   40 |   0.9177 |     30.872 |   1.1309 |     35.413 |    19.8
   41 |   0.9022 |     30.306 |   1.1329 |     35.192 |    20.2
   42 |   0.8836 |     29.366 |   1.1245 |     35.539 |    20.7
   43 |   0.8730 |     29.228 |   1.1129 |     34.468 |    21.2
   44 |   0.8574 |     29.075 |   1.1376 |     33.963 |    21.7
   45 |   0.8397 |     27.772 |   1.1319 |     34.310 |    22.2
   46 |   0.8318 |     28.053 |   1.1184 |     33.554 |    22.7
   47 |   0.8179 |     27.563 |   1.1152 |     33.207 |    23.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 505,505

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2946 |     61.858 |   1.6727 |     48.393 |     0.0
    2 |   1.5103 |     46.533 |   1.4262 |     45.306 |     0.0
    3 |   1.4036 |     45.890 |   1.3752 |     43.919 |     0.1
    4 |   1.3538 |     44.664 |   1.3352 |     44.140 |     0.1
    5 |   1.3086 |     43.736 |   1.2982 |     41.934 |     0.1
    6 |   1.2662 |     42.005 |   1.2519 |     40.296 |     0.1
    7 |   1.2244 |     40.812 |   1.2202 |     39.729 |     0.1
    8 |   1.1945 |     40.230 |   1.2025 |     39.067 |     0.2
    9 |   1.1682 |     39.526 |   1.1705 |     38.658 |     0.2
   10 |   1.1375 |     38.795 |   1.1481 |     37.902 |     0.2
   11 |   1.1015 |     37.350 |   1.1315 |     37.020 |     0.2
   12 |   1.0684 |     36.229 |   1.1103 |     35.980 |     0.2
   13 |   1.0335 |     35.130 |   1.0867 |     35.539 |     0.3
   14 |   0.9967 |     33.388 |   1.0651 |     34.657 |     0.3
   15 |   0.9574 |     32.157 |   1.0510 |     33.365 |     0.3
   16 |   0.9224 |     30.707 |   1.0416 |     34.121 |     0.3
   17 |   0.8906 |     29.454 |   1.0211 |     32.546 |     0.4
   18 |   0.8532 |     28.058 |   1.0339 |     33.113 |     0.4
   19 |   0.8223 |     26.965 |   1.0173 |     32.577 |     0.4
   20 |   0.7872 |     25.970 |   1.0068 |     32.420 |     0.4
   21 |   0.7607 |     25.140 |   0.9842 |     30.372 |     0.4
   22 |   0.7240 |     23.772 |   0.9897 |     30.970 |     0.5
   23 |   0.6935 |     22.623 |   0.9894 |     30.246 |     0.5
   24 |   0.6656 |     21.816 |   0.9873 |     30.088 |     0.5
   25 |   0.6432 |     20.645 |   0.9772 |     29.616 |     0.5
   26 |   0.6113 |     19.716 |   0.9861 |     29.238 |     0.5
   27 |   0.5978 |     19.150 |   0.9995 |     30.088 |     0.6
   28 |   0.5732 |     18.464 |   1.0305 |     29.616 |     0.6
   29 |   0.5547 |     17.672 |   0.9863 |     28.166 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,701,793

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4908 |     66.804 |   2.0099 |     55.955 |     0.7
    2 |   1.8188 |     51.159 |   1.6127 |     45.432 |     1.4
    3 |   1.5228 |     46.302 |   1.4526 |     45.432 |     2.2
    4 |   1.4332 |     46.340 |   1.4165 |     45.432 |     2.9
    5 |   1.4104 |     46.324 |   1.4048 |     45.432 |     3.6
    6 |   1.4015 |     46.274 |   1.3974 |     45.432 |     4.3
    7 |   1.3938 |     46.055 |   1.3825 |     44.928 |     5.1
    8 |   1.3739 |     45.120 |   1.3675 |     43.982 |     5.8
    9 |   1.3532 |     44.686 |   1.3494 |     43.793 |     6.5
   10 |   1.3328 |     44.384 |   1.3340 |     43.478 |     7.2
   11 |   1.3205 |     43.939 |   1.3191 |     43.069 |     7.9
   12 |   1.3081 |     43.703 |   1.3172 |     42.596 |     8.7
   13 |   1.2944 |     43.296 |   1.3051 |     42.659 |     9.4
   14 |   1.2834 |     42.757 |   1.2919 |     42.060 |    10.1
   15 |   1.2726 |     42.411 |   1.2830 |     41.934 |    10.8
   16 |   1.2620 |     41.878 |   1.2770 |     42.060 |    11.5
   17 |   1.2589 |     41.961 |   1.2596 |     40.895 |    12.2
   18 |   1.2533 |     41.691 |   1.2671 |     41.336 |    13.0
   19 |   1.2422 |     41.235 |   1.2580 |     40.359 |    13.7
   20 |   1.2300 |     40.675 |   1.2477 |     40.170 |    14.4
   21 |   1.2214 |     40.263 |   1.2466 |     40.454 |    15.2
   22 |   1.2121 |     39.840 |   1.2269 |     39.225 |    15.9
   23 |   1.2010 |     39.636 |   1.2297 |     39.635 |    16.6
   24 |   1.1920 |     39.455 |   1.2354 |     39.193 |    17.3
   25 |   1.1812 |     38.999 |   1.2279 |     39.319 |    18.1
   26 |   1.1712 |     39.010 |   1.2151 |     38.973 |    18.8
   27 |   1.1642 |     38.647 |   1.2214 |     39.477 |    19.5
   28 |   1.1510 |     38.323 |   1.2023 |     38.437 |    20.2
   29 |   1.1407 |     37.883 |   1.2067 |     38.595 |    20.9
   30 |   1.1318 |     37.773 |   1.1921 |     37.965 |    21.7
   31 |   1.1245 |     37.367 |   1.1901 |     38.185 |    22.4
   32 |   1.1181 |     37.048 |   1.1869 |     38.122 |    23.1
   33 |   1.1077 |     36.795 |   1.1870 |     37.902 |    23.8
   34 |   1.0990 |     36.647 |   1.1819 |     37.681 |    24.5
   35 |   1.0847 |     36.075 |   1.1704 |     37.681 |    25.3
   36 |   1.0805 |     36.169 |   1.1822 |     37.902 |    26.0
   37 |   1.0728 |     35.850 |   1.1651 |     37.335 |    26.7
   38 |   1.0558 |     35.482 |   1.1699 |     37.587 |    27.5
   39 |   1.0491 |     35.009 |   1.1707 |     37.587 |    28.2
   40 |   1.0354 |     34.559 |   1.1523 |     36.925 |    28.9
   41 |   1.0348 |     34.427 |   1.1618 |     36.988 |    29.6
   42 |   1.0269 |     34.322 |   1.1500 |     37.398 |    30.4
   43 |   1.0139 |     33.839 |   1.1580 |     37.776 |    31.1
   44 |   1.0005 |     33.311 |   1.1495 |     37.240 |    31.8
   45 |   1.0043 |     33.509 |   1.1499 |     37.461 |    32.5
   46 |   1.0051 |     33.817 |   1.1455 |     36.862 |    33.3
   47 |   0.9942 |     33.361 |   1.1354 |     36.862 |    34.0
   48 |   0.9856 |     32.938 |   1.1202 |     36.799 |    34.7
   49 |   0.9754 |     32.866 |   1.1188 |     36.830 |    35.4
   50 |   0.9593 |     32.091 |   1.1191 |     35.917 |    36.1
   51 |   0.9592 |     31.811 |   1.1277 |     36.484 |    36.9
   52 |   0.9544 |     32.036 |   1.1156 |     35.885 |    37.6
   53 |   0.9430 |     31.734 |   1.1196 |     36.043 |    38.3
   54 |   0.9332 |     31.619 |   1.1067 |     35.696 |    39.0
   55 |   0.9311 |     31.157 |   1.1255 |     36.263 |    39.7
   56 |   0.9320 |     31.460 |   1.1195 |     35.980 |    40.5
   57 |   0.9299 |     31.317 |   1.1248 |     36.263 |    41.2
   58 |   0.9108 |     30.525 |   1.1141 |     35.791 |    41.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,745,249

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5197 |     66.974 |   2.0391 |     54.253 |     0.7
    2 |   1.8178 |     51.797 |   1.6251 |     45.495 |     1.4
    3 |   1.5254 |     46.296 |   1.4585 |     45.432 |     2.1
    4 |   1.4380 |     46.274 |   1.4233 |     45.432 |     2.8
    5 |   1.4110 |     46.098 |   1.4008 |     45.558 |     3.6
    6 |   1.3959 |     46.148 |   1.3851 |     45.306 |     4.3
    7 |   1.3766 |     45.274 |   1.3667 |     43.541 |     5.0
    8 |   1.3517 |     44.444 |   1.3498 |     43.321 |     5.8
    9 |   1.3282 |     43.851 |   1.3298 |     42.659 |     6.5
   10 |   1.3134 |     43.560 |   1.3147 |     42.722 |     7.2
   11 |   1.2947 |     43.175 |   1.3011 |     41.871 |     7.9
   12 |   1.2796 |     42.411 |   1.2866 |     41.430 |     8.6
   13 |   1.2686 |     42.005 |   1.2860 |     41.115 |     9.4
   14 |   1.2544 |     41.664 |   1.2703 |     40.548 |    10.1
   15 |   1.2439 |     41.499 |   1.2533 |     40.359 |    10.8
   16 |   1.2291 |     40.752 |   1.2491 |     39.887 |    11.6
   17 |   1.2150 |     40.169 |   1.2520 |     40.800 |    12.3
   18 |   1.2071 |     40.197 |   1.2326 |     38.973 |    13.0
   19 |   1.1855 |     39.493 |   1.2216 |     38.752 |    13.7
   20 |   1.1737 |     38.971 |   1.2070 |     38.878 |    14.4
   21 |   1.1589 |     38.680 |   1.2034 |     38.815 |    15.2
   22 |   1.1454 |     38.136 |   1.1993 |     38.532 |    15.9
   23 |   1.1212 |     37.345 |   1.1963 |     38.185 |    16.6
   24 |   1.1141 |     37.196 |   1.1804 |     37.618 |    17.3
   25 |   1.0988 |     36.372 |   1.1618 |     36.799 |    18.0
   26 |   1.0833 |     35.828 |   1.1606 |     36.736 |    18.7
   27 |   1.0652 |     34.998 |   1.1509 |     36.767 |    19.4
   28 |   1.0501 |     34.746 |   1.1354 |     35.507 |    20.1
   29 |   1.0309 |     33.910 |   1.1281 |     35.854 |    20.9
   30 |   1.0113 |     33.471 |   1.1420 |     36.515 |    21.6
   31 |   1.0010 |     32.921 |   1.1087 |     35.192 |    22.3
   32 |   0.9842 |     32.421 |   1.0997 |     34.972 |    23.0
   33 |   0.9692 |     31.949 |   1.1043 |     36.169 |    23.8
   34 |   0.9544 |     31.328 |   1.0820 |     34.625 |    24.5
   35 |   0.9412 |     30.948 |   1.0922 |     35.003 |    25.2
   36 |   0.9370 |     31.069 |   1.0858 |     34.499 |    25.9
   37 |   0.9139 |     30.009 |   1.0738 |     33.963 |    26.6
   38 |   0.8917 |     29.207 |   1.0775 |     34.405 |    27.4
   39 |   0.8789 |     28.882 |   1.0675 |     34.216 |    28.1
   40 |   0.8656 |     28.432 |   1.0679 |     34.216 |    28.8
   41 |   0.8610 |     28.151 |   1.0612 |     34.121 |    29.5
   42 |   0.8494 |     27.871 |   1.0597 |     33.396 |    30.2
   43 |   0.8303 |     27.278 |   1.0677 |     34.688 |    30.9
   44 |   0.8254 |     26.981 |   1.0609 |     33.491 |    31.7
   45 |   0.8094 |     26.371 |   1.0742 |     33.396 |    32.4
   46 |   0.8067 |     26.393 |   1.0712 |     34.310 |    33.1
   47 |   0.7936 |     26.008 |   1.0500 |     33.270 |    33.8
   48 |   0.7790 |     25.536 |   1.0510 |     33.270 |    34.6
   49 |   0.7701 |     25.212 |   1.0403 |     32.231 |    35.3
   50 |   0.7610 |     24.893 |   1.0431 |     32.861 |    36.0
   51 |   0.7543 |     24.552 |   1.0435 |     32.766 |    36.7
   52 |   0.7372 |     24.255 |   1.0483 |     32.546 |    37.4
   53 |   0.7153 |     23.167 |   1.0379 |     32.640 |    38.2
   54 |   0.7177 |     23.750 |   1.0540 |     33.617 |    38.9
   55 |   0.7181 |     23.832 |   1.0521 |     32.672 |    39.6
   56 |   0.6980 |     22.711 |   1.0520 |     33.270 |    40.3
   57 |   0.6853 |     22.354 |   1.0556 |     32.798 |    41.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 282,273

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4686 |     65.738 |   1.9256 |     50.788 |     0.0
    2 |   1.6986 |     48.368 |   1.5193 |     45.306 |     0.0
    3 |   1.4486 |     45.692 |   1.3943 |     44.644 |     0.0
    4 |   1.3547 |     43.620 |   1.3293 |     42.407 |     0.1
    5 |   1.2955 |     41.917 |   1.2830 |     40.454 |     0.1
    6 |   1.2520 |     40.603 |   1.2492 |     39.950 |     0.1
    7 |   1.2071 |     39.504 |   1.2068 |     39.351 |     0.1
    8 |   1.1634 |     38.076 |   1.1769 |     37.807 |     0.1
    9 |   1.1212 |     36.575 |   1.1537 |     37.461 |     0.1
   10 |   1.0824 |     35.191 |   1.1181 |     35.948 |     0.2
   11 |   1.0339 |     33.355 |   1.0969 |     34.657 |     0.2
   12 |   0.9897 |     31.509 |   1.0785 |     34.468 |     0.2
   13 |   0.9508 |     30.459 |   1.0635 |     33.869 |     0.2
   14 |   0.9101 |     29.014 |   1.0474 |     33.617 |     0.2
   15 |   0.8651 |     27.530 |   1.0266 |     31.916 |     0.2
   16 |   0.8284 |     26.344 |   1.0146 |     31.979 |     0.3
   17 |   0.7910 |     25.008 |   1.0119 |     32.073 |     0.3
   18 |   0.7483 |     23.459 |   0.9976 |     31.002 |     0.3
   19 |   0.7185 |     22.486 |   0.9807 |     30.466 |     0.3
   20 |   0.6763 |     20.920 |   0.9964 |     30.214 |     0.3
   21 |   0.6473 |     19.909 |   0.9905 |     30.088 |     0.3
   22 |   0.6197 |     19.189 |   0.9744 |     29.143 |     0.4
   23 |   0.5850 |     18.002 |   0.9727 |     29.206 |     0.4
   24 |   0.5578 |     16.919 |   0.9857 |     28.576 |     0.4
   25 |   0.5410 |     16.502 |   0.9830 |     28.796 |     0.4
   26 |   0.5092 |     15.265 |   0.9803 |     28.072 |     0.4
   27 |   0.4818 |     14.562 |   0.9917 |     28.324 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 416,449

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4620 |     64.562 |   1.8895 |     49.370 |     0.0
    2 |   1.6561 |     47.857 |   1.4869 |     45.495 |     0.0
    3 |   1.4333 |     46.109 |   1.3951 |     45.054 |     0.0
    4 |   1.3646 |     44.642 |   1.3362 |     42.659 |     0.1
    5 |   1.3106 |     42.730 |   1.2923 |     41.840 |     0.1
    6 |   1.2674 |     41.367 |   1.2499 |     40.359 |     0.1
    7 |   1.2333 |     40.576 |   1.2268 |     39.067 |     0.1
    8 |   1.1959 |     39.164 |   1.1966 |     38.595 |     0.1
    9 |   1.1579 |     38.114 |   1.1692 |     37.681 |     0.1
   10 |   1.1207 |     37.070 |   1.1501 |     36.610 |     0.2
   11 |   1.0880 |     35.982 |   1.1325 |     36.673 |     0.2
   12 |   1.0466 |     34.592 |   1.1165 |     36.326 |     0.2
   13 |   1.0096 |     32.943 |   1.0705 |     35.066 |     0.2
   14 |   0.9728 |     31.284 |   1.0592 |     33.617 |     0.2
   15 |   0.9347 |     30.036 |   1.0665 |     34.184 |     0.2
   16 |   0.9044 |     28.998 |   1.0337 |     31.947 |     0.3
   17 |   0.8702 |     27.723 |   1.0118 |     32.073 |     0.3
   18 |   0.8360 |     26.267 |   1.0163 |     31.254 |     0.3
   19 |   0.8044 |     25.569 |   0.9931 |     30.655 |     0.3
   20 |   0.7740 |     24.728 |   0.9808 |     29.773 |     0.3
   21 |   0.7439 |     23.277 |   0.9851 |     30.498 |     0.4
   22 |   0.7200 |     22.464 |   0.9835 |     29.175 |     0.4
   23 |   0.7006 |     22.052 |   0.9607 |     29.710 |     0.4
   24 |   0.6779 |     21.277 |   0.9932 |     29.773 |     0.4
   25 |   0.6564 |     20.579 |   0.9696 |     29.206 |     0.4
   26 |   0.6251 |     19.793 |   0.9657 |     29.206 |     0.4
   27 |   0.6034 |     18.848 |   0.9734 |     29.427 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 335,201

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5710 |     68.931 |   2.0324 |     58.759 |     0.0
    2 |   1.8079 |     51.797 |   1.6159 |     48.299 |     0.0
    3 |   1.5347 |     46.719 |   1.4689 |     45.432 |     0.1
    4 |   1.4463 |     46.291 |   1.4240 |     45.432 |     0.1
    5 |   1.4167 |     46.285 |   1.4017 |     45.463 |     0.1
    6 |   1.3992 |     46.340 |   1.3909 |     45.432 |     0.1
    7 |   1.3842 |     46.527 |   1.3785 |     45.432 |     0.1
    8 |   1.3621 |     45.818 |   1.3444 |     43.825 |     0.1
    9 |   1.3308 |     44.307 |   1.3109 |     42.502 |     0.2
   10 |   1.3044 |     43.725 |   1.2977 |     42.187 |     0.2
   11 |   1.2843 |     43.054 |   1.2768 |     41.903 |     0.2
   12 |   1.2655 |     42.686 |   1.2596 |     42.281 |     0.2
   13 |   1.2504 |     42.257 |   1.2532 |     42.029 |     0.2
   14 |   1.2307 |     41.516 |   1.2261 |     40.958 |     0.3
   15 |   1.2133 |     40.994 |   1.2130 |     39.540 |     0.3
   16 |   1.1945 |     40.180 |   1.2071 |     39.382 |     0.3
   17 |   1.1735 |     39.125 |   1.1882 |     38.815 |     0.3
   18 |   1.1559 |     38.911 |   1.1830 |     39.351 |     0.3
   19 |   1.1387 |     38.620 |   1.1588 |     37.902 |     0.3
   20 |   1.1243 |     37.674 |   1.1645 |     38.059 |     0.4
   21 |   1.1103 |     37.603 |   1.1451 |     37.240 |     0.4
   22 |   1.0954 |     37.032 |   1.1452 |     37.461 |     0.4
   23 |   1.0782 |     36.119 |   1.1423 |     37.492 |     0.4
   24 |   1.0589 |     35.965 |   1.1212 |     36.830 |     0.4
   25 |   1.0415 |     35.053 |   1.1168 |     36.389 |     0.5
   26 |   1.0259 |     34.597 |   1.1037 |     36.106 |     0.5
   27 |   1.0087 |     34.048 |   1.1012 |     36.515 |     0.5
   28 |   0.9936 |     33.284 |   1.0931 |     35.665 |     0.5
   29 |   0.9803 |     33.146 |   1.1001 |     35.665 |     0.5
   30 |   0.9655 |     32.427 |   1.0858 |     35.224 |     0.5
   31 |   0.9431 |     31.674 |   1.0761 |     34.688 |     0.6
   32 |   0.9274 |     31.201 |   1.0698 |     34.184 |     0.6
   33 |   0.9137 |     30.509 |   1.0633 |     34.152 |     0.6
   34 |   0.8975 |     30.113 |   1.0567 |     33.617 |     0.6
   35 |   0.8699 |     29.421 |   1.0677 |     33.648 |     0.6
   36 |   0.8656 |     29.036 |   1.0692 |     33.522 |     0.6
   37 |   0.8495 |     28.553 |   1.0484 |     32.955 |     0.7
   38 |   0.8361 |     28.195 |   1.0550 |     32.514 |     0.7
   39 |   0.8184 |     27.322 |   1.0520 |     32.609 |     0.7
   40 |   0.8151 |     27.294 |   1.0416 |     31.884 |     0.7
   41 |   0.8038 |     26.701 |   1.0430 |     31.884 |     0.7
   42 |   0.7899 |     26.497 |   1.0702 |     32.672 |     0.8
   43 |   0.7733 |     25.948 |   1.0323 |     31.222 |     0.8
   44 |   0.7609 |     25.113 |   1.0421 |     31.947 |     0.8
   45 |   0.7448 |     24.777 |   1.0457 |     31.254 |     0.8
   46 |   0.7330 |     24.327 |   1.0333 |     30.970 |     0.8
   47 |   0.7166 |     23.959 |   1.0420 |     31.790 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 598,113

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2974 |     62.485 |   1.6923 |     48.299 |     0.0
    2 |   1.5152 |     46.615 |   1.4216 |     45.432 |     0.1
    3 |   1.3993 |     46.011 |   1.3862 |     44.266 |     0.1
    4 |   1.3516 |     44.895 |   1.3397 |     44.203 |     0.1
    5 |   1.3211 |     44.247 |   1.3036 |     42.785 |     0.1
    6 |   1.2872 |     43.230 |   1.2889 |     41.966 |     0.2
    7 |   1.2598 |     42.197 |   1.2460 |     40.485 |     0.2
    8 |   1.2236 |     41.307 |   1.2148 |     39.351 |     0.2
    9 |   1.1936 |     40.213 |   1.1965 |     39.509 |     0.2
   10 |   1.1641 |     39.576 |   1.1995 |     39.540 |     0.3
   11 |   1.1398 |     38.773 |   1.1643 |     38.532 |     0.3
   12 |   1.1113 |     37.960 |   1.1394 |     38.059 |     0.3
   13 |   1.0825 |     37.048 |   1.1235 |     37.618 |     0.3
   14 |   1.0565 |     35.751 |   1.1075 |     36.799 |     0.4
   15 |   1.0213 |     34.586 |   1.0902 |     35.791 |     0.4
   16 |   0.9862 |     32.905 |   1.0810 |     35.665 |     0.4
   17 |   0.9638 |     32.075 |   1.0660 |     34.877 |     0.4
   18 |   0.9230 |     30.426 |   1.0471 |     34.058 |     0.5
   19 |   0.8889 |     29.256 |   1.0285 |     32.609 |     0.5
   20 |   0.8525 |     27.948 |   1.0266 |     32.577 |     0.5
   21 |   0.8126 |     26.635 |   1.0166 |     31.979 |     0.5
   22 |   0.7820 |     25.069 |   0.9992 |     31.474 |     0.6
   23 |   0.7522 |     24.580 |   1.0063 |     32.010 |     0.6
   24 |   0.7127 |     22.970 |   0.9840 |     31.285 |     0.6
   25 |   0.6823 |     22.035 |   1.0071 |     30.088 |     0.7
   26 |   0.6567 |     21.327 |   0.9690 |     29.427 |     0.7
   27 |   0.6255 |     19.980 |   0.9792 |     29.490 |     0.7
   28 |   0.5982 |     19.068 |   0.9957 |     29.931 |     0.7
   29 |   0.5783 |     18.788 |   0.9847 |     30.214 |     0.8
   30 |   0.5576 |     17.832 |   0.9970 |     29.395 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 392,385

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5437 |     68.288 |   1.9730 |     58.223 |     0.0
    2 |   1.7444 |     49.407 |   1.5559 |     45.432 |     0.0
    3 |   1.4949 |     46.307 |   1.4489 |     45.432 |     0.1
    4 |   1.4342 |     46.373 |   1.4183 |     45.432 |     0.1
    5 |   1.4050 |     46.439 |   1.3911 |     45.432 |     0.1
    6 |   1.3778 |     46.115 |   1.3605 |     44.423 |     0.1
    7 |   1.3510 |     45.307 |   1.3480 |     44.865 |     0.2
    8 |   1.3307 |     45.060 |   1.3208 |     44.486 |     0.2
    9 |   1.3061 |     44.741 |   1.2940 |     43.321 |     0.2
   10 |   1.2818 |     43.296 |   1.2757 |     42.092 |     0.2
   11 |   1.2487 |     42.076 |   1.2330 |     41.115 |     0.2
   12 |   1.2183 |     41.224 |   1.2124 |     39.824 |     0.3
   13 |   1.1935 |     40.169 |   1.1912 |     39.036 |     0.3
   14 |   1.1634 |     38.922 |   1.1622 |     37.650 |     0.3
   15 |   1.1389 |     38.065 |   1.1601 |     38.311 |     0.3
   16 |   1.1189 |     37.515 |   1.1543 |     37.744 |     0.3
   17 |   1.0935 |     36.691 |   1.1422 |     37.429 |     0.4
   18 |   1.0679 |     35.575 |   1.1161 |     36.389 |     0.4
   19 |   1.0520 |     34.795 |   1.1091 |     36.137 |     0.4
   20 |   1.0287 |     34.048 |   1.0996 |     35.791 |     0.4
   21 |   1.0084 |     33.548 |   1.0861 |     34.909 |     0.5
   22 |   0.9886 |     32.366 |   1.0804 |     34.909 |     0.5
   23 |   0.9638 |     31.789 |   1.0612 |     34.184 |     0.5
   24 |   0.9467 |     31.157 |   1.0528 |     33.774 |     0.5
   25 |   0.9276 |     30.487 |   1.0448 |     33.396 |     0.5
   26 |   0.9129 |     29.904 |   1.0703 |     34.720 |     0.6
   27 |   0.8953 |     29.228 |   1.0557 |     33.806 |     0.6
   28 |   0.8700 |     28.838 |   1.0391 |     33.491 |     0.6
   29 |   0.8501 |     27.871 |   1.0370 |     32.766 |     0.6
   30 |   0.8375 |     27.256 |   1.0193 |     32.798 |     0.6
   31 |   0.8133 |     26.420 |   1.0228 |     32.451 |     0.7
   32 |   0.8037 |     26.157 |   1.0053 |     32.388 |     0.7
   33 |   0.7887 |     25.723 |   1.0098 |     32.294 |     0.7
   34 |   0.7681 |     25.030 |   1.0117 |     31.758 |     0.7
   35 |   0.7465 |     24.332 |   1.0044 |     31.380 |     0.8
   36 |   0.7343 |     23.827 |   1.0143 |     31.506 |     0.8
   37 |   0.7162 |     23.195 |   1.0031 |     30.876 |     0.8
   38 |   0.7071 |     22.997 |   0.9841 |     30.214 |     0.8
   39 |   0.7014 |     23.008 |   1.0107 |     30.529 |     0.8
   40 |   0.6767 |     21.854 |   0.9910 |     30.183 |     0.9
   41 |   0.6655 |     21.475 |   1.0038 |     29.994 |     0.9
   42 |   0.6508 |     21.228 |   0.9978 |     29.805 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 2,500,065

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5880 |     70.030 |   2.0290 |     58.727 |     0.9
    2 |   1.8182 |     51.753 |   1.6198 |     45.432 |     1.9
    3 |   1.5326 |     46.445 |   1.4655 |     45.810 |     2.9
    4 |   1.4480 |     46.307 |   1.4265 |     45.432 |     3.8
    5 |   1.4231 |     46.368 |   1.4113 |     45.432 |     4.8
    6 |   1.4098 |     46.296 |   1.4072 |     45.463 |     5.7
    7 |   1.4029 |     46.373 |   1.3995 |     45.432 |     6.7
    8 |   1.3981 |     46.280 |   1.3939 |     45.432 |     7.7
    9 |   1.3936 |     46.307 |   1.3889 |     45.432 |     8.6
   10 |   1.3890 |     46.263 |   1.3847 |     45.180 |     9.6
   11 |   1.3769 |     45.401 |   1.3648 |     43.856 |    10.6
   12 |   1.3614 |     44.807 |   1.3481 |     43.951 |    11.5
   13 |   1.3514 |     44.890 |   1.3501 |     44.014 |    12.5
   14 |   1.3434 |     44.791 |   1.3418 |     44.014 |    13.5
   15 |   1.3387 |     44.857 |   1.3375 |     44.171 |    14.4
   16 |   1.3319 |     44.681 |   1.3323 |     43.667 |    15.4
   17 |   1.3278 |     44.868 |   1.3254 |     43.730 |    16.4
   18 |   1.3229 |     44.653 |   1.3304 |     43.699 |    17.4
   19 |   1.3178 |     44.521 |   1.3220 |     43.415 |    18.3
   20 |   1.3151 |     44.527 |   1.3262 |     43.415 |    19.3
   21 |   1.3047 |     43.955 |   1.3158 |     43.226 |    20.2
   22 |   1.2983 |     43.878 |   1.3145 |     43.573 |    21.2
   23 |   1.2954 |     43.659 |   1.3000 |     42.817 |    22.2
   24 |   1.2897 |     43.466 |   1.3118 |     43.132 |    23.1
   25 |   1.2848 |     43.439 |   1.3058 |     43.069 |    24.1
   26 |   1.2815 |     43.263 |   1.3008 |     43.132 |    25.1
   27 |   1.2771 |     43.422 |   1.2937 |     41.997 |    26.1
   28 |   1.2754 |     43.263 |   1.2974 |     42.911 |    27.0
   29 |   1.2708 |     43.164 |   1.2913 |     42.376 |    28.0
   30 |   1.2646 |     42.928 |   1.2877 |     42.218 |    29.0
   31 |   1.2643 |     42.977 |   1.2834 |     42.092 |    29.9
   32 |   1.2599 |     42.768 |   1.2831 |     41.714 |    30.9
   33 |   1.2498 |     42.571 |   1.2894 |     42.250 |    31.9
   34 |   1.2507 |     42.549 |   1.2793 |     41.997 |    32.8
   35 |   1.2456 |     42.576 |   1.2701 |     41.714 |    33.8
   36 |   1.2398 |     42.197 |   1.2707 |     42.439 |    34.8
   37 |   1.2306 |     42.120 |   1.2667 |     41.871 |    35.7
   38 |   1.2320 |     42.043 |   1.2605 |     41.493 |    36.7
   39 |   1.2281 |     41.686 |   1.2670 |     41.525 |    37.7
   40 |   1.2228 |     41.757 |   1.2577 |     40.895 |    38.6
   41 |   1.2181 |     41.642 |   1.2492 |     41.399 |    39.6
   42 |   1.2099 |     41.318 |   1.2486 |     40.611 |    40.6
   43 |   1.2115 |     41.037 |   1.2521 |     41.178 |    41.6
   44 |   1.2028 |     41.059 |   1.2449 |     40.863 |    42.5
   45 |   1.2002 |     40.774 |   1.2359 |     40.517 |    43.5
   46 |   1.1968 |     40.911 |   1.2291 |     40.517 |    44.5
   47 |   1.1924 |     40.686 |   1.2390 |     40.800 |    45.4
   48 |   1.1854 |     40.301 |   1.2332 |     39.824 |    46.4
   49 |   1.1847 |     40.482 |   1.2408 |     40.517 |    47.4
   50 |   1.1850 |     40.395 |   1.2266 |     39.918 |    48.3
   51 |   1.1829 |     40.417 |   1.2310 |     39.761 |    49.3
   52 |   1.1781 |     40.356 |   1.2387 |     40.580 |    50.3
   53 |   1.1752 |     39.873 |   1.2386 |     40.611 |    51.3
   54 |   1.1789 |     40.048 |   1.2349 |     40.265 |    52.2
   55 |   1.1752 |     39.905 |   1.2240 |     39.319 |    53.2
   56 |   1.1714 |     39.840 |   1.2291 |     39.509 |    54.1
   57 |   1.1651 |     39.460 |   1.2239 |     40.328 |    55.1
   58 |   1.1637 |     39.422 |   1.2168 |     39.130 |    56.1
   59 |   1.1498 |     39.065 |   1.2275 |     39.698 |    57.1
   60 |   1.1493 |     39.202 |   1.2236 |     39.445 |    58.0
   61 |   1.1479 |     38.949 |   1.2218 |     40.044 |    59.0
   62 |   1.1410 |     38.741 |   1.2276 |     40.107 |    60.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,046,305

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5300 |     65.683 |   2.0458 |     58.601 |     0.5
    2 |   1.8351 |     51.632 |   1.6309 |     45.432 |     0.9
    3 |   1.5312 |     46.291 |   1.4667 |     45.432 |     1.4
    4 |   1.4268 |     45.406 |   1.3979 |     44.360 |     1.9
    5 |   1.3753 |     44.730 |   1.3594 |     43.447 |     2.4
    6 |   1.3436 |     43.933 |   1.3426 |     42.848 |     2.8
    7 |   1.3158 |     43.329 |   1.3106 |     42.092 |     3.3
    8 |   1.2901 |     42.483 |   1.2922 |     41.808 |     3.8
    9 |   1.2668 |     41.851 |   1.2824 |     40.674 |     4.3
   10 |   1.2459 |     41.015 |   1.2625 |     40.328 |     4.8
   11 |   1.2277 |     40.840 |   1.2594 |     40.328 |     5.3
   12 |   1.2092 |     39.840 |   1.2397 |     39.603 |     5.7
   13 |   1.1794 |     38.735 |   1.2133 |     38.595 |     6.2
   14 |   1.1590 |     38.054 |   1.2138 |     37.902 |     6.7
   15 |   1.1304 |     37.081 |   1.1959 |     38.595 |     7.2
   16 |   1.1117 |     36.581 |   1.1811 |     38.154 |     7.6
   17 |   1.0774 |     35.542 |   1.1604 |     36.641 |     8.1
   18 |   1.0583 |     34.729 |   1.1307 |     36.515 |     8.6
   19 |   1.0278 |     33.284 |   1.1346 |     36.358 |     9.1
   20 |   1.0058 |     32.789 |   1.1160 |     35.633 |     9.6
   21 |   0.9786 |     31.938 |   1.1063 |     35.161 |    10.0
   22 |   0.9608 |     31.086 |   1.0966 |     34.562 |    10.5
   23 |   0.9387 |     30.569 |   1.0877 |     34.625 |    11.0
   24 |   0.9139 |     29.580 |   1.0853 |     34.058 |    11.5
   25 |   0.8951 |     29.080 |   1.0964 |     35.129 |    12.0
   26 |   0.8739 |     28.102 |   1.0770 |     34.216 |    12.5
   27 |   0.8465 |     27.421 |   1.0550 |     33.050 |    12.9
   28 |   0.8274 |     26.706 |   1.0757 |     33.743 |    13.4
   29 |   0.8079 |     25.811 |   1.0460 |     31.601 |    13.9
   30 |   0.7840 |     25.069 |   1.0602 |     32.892 |    14.4
   31 |   0.7639 |     24.338 |   1.0553 |     33.239 |    14.9
   32 |   0.7545 |     24.299 |   1.0411 |     32.262 |    15.3
   33 |   0.7322 |     23.470 |   1.0274 |     31.348 |    15.8
   34 |   0.7110 |     22.777 |   1.0366 |     32.073 |    16.3
   35 |   0.6983 |     22.387 |   1.0504 |     32.451 |    16.8
   36 |   0.6903 |     21.871 |   1.0617 |     32.514 |    17.3
   37 |   0.6752 |     21.755 |   1.0242 |     31.821 |    17.7
   38 |   0.6474 |     20.892 |   1.0369 |     31.853 |    18.2
   39 |   0.6296 |     19.815 |   1.0395 |     30.813 |    18.7
   40 |   0.6302 |     20.118 |   1.0544 |     31.537 |    19.2
   41 |   0.6072 |     19.392 |   1.0490 |     31.254 |    19.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,420,161

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2614 |     61.831 |   1.6487 |     45.432 |     0.5
    2 |   1.5013 |     46.390 |   1.4290 |     45.810 |     0.9
    3 |   1.4172 |     46.379 |   1.4048 |     45.432 |     1.4
    4 |   1.3967 |     46.307 |   1.3860 |     45.432 |     1.9
    5 |   1.3679 |     45.357 |   1.3671 |     43.919 |     2.4
    6 |   1.3443 |     44.802 |   1.3369 |     43.258 |     2.9
    7 |   1.3278 |     44.296 |   1.3323 |     44.486 |     3.4
    8 |   1.3049 |     43.950 |   1.3211 |     42.754 |     3.9
    9 |   1.2869 |     43.115 |   1.2950 |     41.997 |     4.4
   10 |   1.2731 |     42.516 |   1.2794 |     41.808 |     4.8
   11 |   1.2556 |     41.944 |   1.2710 |     41.430 |     5.3
   12 |   1.2341 |     41.246 |   1.2408 |     40.580 |     5.8
   13 |   1.2096 |     40.395 |   1.2325 |     39.918 |     6.3
   14 |   1.1883 |     40.054 |   1.2153 |     39.666 |     6.8
   15 |   1.1584 |     38.806 |   1.1856 |     38.815 |     7.3
   16 |   1.1395 |     38.268 |   1.1770 |     38.847 |     7.8
   17 |   1.1035 |     37.021 |   1.1430 |     36.673 |     8.3
   18 |   1.0705 |     35.933 |   1.1230 |     36.547 |     8.7
   19 |   1.0388 |     34.537 |   1.1137 |     36.641 |     9.2
   20 |   1.0074 |     33.564 |   1.0864 |     35.129 |     9.7
   21 |   0.9760 |     32.773 |   1.0760 |     35.602 |    10.2
   22 |   0.9596 |     32.146 |   1.0681 |     35.098 |    10.7
   23 |   0.9218 |     30.608 |   1.0619 |     34.405 |    11.2
   24 |   0.9154 |     30.690 |   1.0455 |     33.585 |    11.6
   25 |   0.8755 |     29.344 |   1.0309 |     33.176 |    12.1
   26 |   0.8358 |     27.954 |   1.0345 |     33.302 |    12.6
   27 |   0.8145 |     27.085 |   1.0319 |     33.396 |    13.1
   28 |   0.7869 |     25.970 |   1.0152 |     32.892 |    13.6
   29 |   0.7665 |     25.431 |   0.9994 |     32.168 |    14.1
   30 |   0.7388 |     24.492 |   0.9939 |     31.537 |    14.6
   31 |   0.7092 |     23.200 |   0.9894 |     31.979 |    15.1
   32 |   0.6827 |     22.354 |   0.9707 |     31.254 |    15.6
   33 |   0.6465 |     21.068 |   0.9858 |     31.065 |    16.1
   34 |   0.6246 |     20.480 |   0.9903 |     30.309 |    16.5
   35 |   0.5948 |     19.365 |   0.9793 |     30.435 |    17.0
   36 |   0.5743 |     18.617 |   0.9964 |     31.065 |    17.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 866,593

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5219 |     67.711 |   1.9612 |     54.222 |     0.0
    2 |   1.7658 |     50.758 |   1.5884 |     45.432 |     0.1
    3 |   1.5211 |     46.368 |   1.4684 |     45.432 |     0.1
    4 |   1.4488 |     46.302 |   1.4294 |     45.684 |     0.1
    5 |   1.4203 |     46.384 |   1.4087 |     45.432 |     0.2
    6 |   1.4039 |     46.269 |   1.3971 |     45.432 |     0.2
    7 |   1.3920 |     46.219 |   1.3843 |     45.432 |     0.2
    8 |   1.3797 |     46.208 |   1.3742 |     44.865 |     0.3
    9 |   1.3676 |     45.692 |   1.3656 |     43.573 |     0.3
   10 |   1.3518 |     44.966 |   1.3398 |     44.077 |     0.3
   11 |   1.3343 |     44.741 |   1.3350 |     43.415 |     0.4
   12 |   1.3233 |     44.137 |   1.3294 |     42.659 |     0.4
   13 |   1.3129 |     44.087 |   1.3136 |     43.573 |     0.4
   14 |   1.2995 |     43.505 |   1.3048 |     42.250 |     0.5
   15 |   1.2879 |     43.208 |   1.2960 |     42.124 |     0.5
   16 |   1.2761 |     42.686 |   1.2770 |     41.903 |     0.5
   17 |   1.2671 |     42.510 |   1.2786 |     41.745 |     0.6
   18 |   1.2532 |     41.950 |   1.2740 |     42.092 |     0.6
   19 |   1.2481 |     42.158 |   1.2787 |     42.218 |     0.6
   20 |   1.2385 |     41.362 |   1.2560 |     41.115 |     0.6
   21 |   1.2265 |     41.109 |   1.2606 |     41.336 |     0.7
   22 |   1.2189 |     40.719 |   1.2547 |     41.556 |     0.7
   23 |   1.2093 |     40.554 |   1.2471 |     40.958 |     0.7
   24 |   1.1981 |     39.905 |   1.2367 |     40.422 |     0.8
   25 |   1.1889 |     39.653 |   1.2473 |     40.737 |     0.8
   26 |   1.1882 |     39.691 |   1.2296 |     40.769 |     0.8
   27 |   1.1673 |     38.988 |   1.2236 |     39.572 |     0.9
   28 |   1.1600 |     38.790 |   1.2232 |     39.887 |     0.9
   29 |   1.1549 |     38.521 |   1.2153 |     39.193 |     0.9
   30 |   1.1450 |     38.367 |   1.2177 |     39.509 |     1.0
   31 |   1.1357 |     37.729 |   1.2196 |     39.666 |     1.0
   32 |   1.1238 |     37.339 |   1.1915 |     38.280 |     1.0
   33 |   1.1277 |     37.696 |   1.2096 |     39.319 |     1.1
   34 |   1.1201 |     37.257 |   1.1916 |     38.374 |     1.1
   35 |   1.0996 |     36.531 |   1.1870 |     38.532 |     1.1
   36 |   1.0897 |     36.103 |   1.1836 |     38.311 |     1.2
   37 |   1.0802 |     35.779 |   1.1871 |     37.524 |     1.2
   38 |   1.0754 |     35.960 |   1.1754 |     38.028 |     1.2
   39 |   1.0686 |     35.564 |   1.1729 |     37.366 |     1.3
   40 |   1.0620 |     35.295 |   1.1755 |     36.862 |     1.3
   41 |   1.0492 |     35.213 |   1.1697 |     37.461 |     1.3
   42 |   1.0462 |     34.872 |   1.1541 |     36.326 |     1.4
   43 |   1.0350 |     34.438 |   1.1494 |     36.295 |     1.4
   44 |   1.0288 |     34.394 |   1.1639 |     37.083 |     1.4
   45 |   1.0163 |     33.086 |   1.1541 |     36.484 |     1.5
   46 |   1.0036 |     33.037 |   1.1476 |     36.389 |     1.5
   47 |   1.0117 |     33.707 |   1.1450 |     36.610 |     1.5
   48 |   1.0033 |     33.234 |   1.1505 |     35.791 |     1.6
   49 |   0.9943 |     33.157 |   1.1232 |     35.129 |     1.6
   50 |   0.9837 |     32.465 |   1.1372 |     36.074 |     1.6
   51 |   0.9699 |     32.069 |   1.1406 |     36.074 |     1.7
   52 |   0.9791 |     32.262 |   1.1518 |     36.232 |     1.7
   53 |   0.9675 |     32.004 |   1.1340 |     35.885 |     1.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 349,217

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6301 |     69.898 |   2.0553 |     58.727 |     0.0
    2 |   1.8162 |     51.462 |   1.6085 |     45.432 |     0.0
    3 |   1.5184 |     46.302 |   1.4556 |     45.432 |     0.1
    4 |   1.4387 |     46.401 |   1.4242 |     45.432 |     0.1
    5 |   1.4156 |     46.401 |   1.4246 |     45.715 |     0.1
    6 |   1.4053 |     46.291 |   1.3983 |     45.400 |     0.1
    7 |   1.3998 |     46.291 |   1.3956 |     45.432 |     0.1
    8 |   1.3965 |     46.291 |   1.3908 |     45.400 |     0.1
    9 |   1.3906 |     46.373 |   1.3826 |     45.432 |     0.2
   10 |   1.3759 |     46.131 |   1.3629 |     44.896 |     0.2
   11 |   1.3568 |     45.747 |   1.3446 |     44.612 |     0.2
   12 |   1.3346 |     45.631 |   1.3187 |     43.825 |     0.2
   13 |   1.3059 |     44.741 |   1.2932 |     42.691 |     0.2
   14 |   1.2742 |     43.411 |   1.2697 |     42.659 |     0.2
   15 |   1.2495 |     42.983 |   1.2443 |     41.430 |     0.2
   16 |   1.2239 |     42.510 |   1.2593 |     42.218 |     0.3
   17 |   1.2004 |     41.554 |   1.2177 |     40.989 |     0.3
   18 |   1.1847 |     40.966 |   1.2078 |     39.792 |     0.3
   19 |   1.1659 |     40.131 |   1.1856 |     40.296 |     0.3
   20 |   1.1423 |     39.301 |   1.1806 |     38.941 |     0.3
   21 |   1.1207 |     38.735 |   1.1621 |     38.154 |     0.3
   22 |   1.1025 |     37.669 |   1.1646 |     37.839 |     0.4
   23 |   1.0885 |     37.114 |   1.1519 |     37.240 |     0.4
   24 |   1.0644 |     35.564 |   1.1436 |     37.398 |     0.4
   25 |   1.0483 |     35.421 |   1.1192 |     35.633 |     0.4
   26 |   1.0214 |     34.300 |   1.1314 |     36.547 |     0.4
   27 |   1.0051 |     33.965 |   1.1222 |     36.043 |     0.4
   28 |   0.9864 |     33.295 |   1.1347 |     36.578 |     0.5
   29 |   0.9696 |     32.267 |   1.1242 |     35.444 |     0.5
   30 |   0.9466 |     31.553 |   1.1178 |     35.192 |     0.5
   31 |   0.9238 |     30.828 |   1.1412 |     36.736 |     0.5
   32 |   0.9128 |     30.767 |   1.1006 |     34.436 |     0.5
   33 |   0.8995 |     30.069 |   1.0971 |     34.877 |     0.5
   34 |   0.8803 |     29.652 |   1.1019 |     34.940 |     0.6
   35 |   0.8601 |     28.695 |   1.1045 |     34.405 |     0.6
   36 |   0.8364 |     27.970 |   1.1085 |     34.152 |     0.6
   37 |   0.8176 |     27.261 |   1.1082 |     34.877 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 486,049

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5249 |     67.507 |   1.9776 |     58.570 |     0.0
    2 |   1.7448 |     50.027 |   1.5597 |     45.432 |     0.0
    3 |   1.4909 |     46.291 |   1.4460 |     45.432 |     0.0
    4 |   1.4293 |     46.379 |   1.4152 |     45.463 |     0.1
    5 |   1.4059 |     46.346 |   1.3937 |     45.432 |     0.1
    6 |   1.3820 |     46.236 |   1.3699 |     45.306 |     0.1
    7 |   1.3544 |     45.230 |   1.3433 |     43.541 |     0.1
    8 |   1.3267 |     44.291 |   1.3151 |     43.195 |     0.1
    9 |   1.2958 |     42.796 |   1.2961 |     41.430 |     0.1
   10 |   1.2650 |     41.834 |   1.2560 |     40.895 |     0.2
   11 |   1.2232 |     40.983 |   1.2165 |     40.013 |     0.2
   12 |   1.1916 |     39.949 |   1.1864 |     38.878 |     0.2
   13 |   1.1625 |     39.197 |   1.1865 |     38.910 |     0.2
   14 |   1.1379 |     38.504 |   1.1541 |     37.839 |     0.2
   15 |   1.1069 |     37.691 |   1.1344 |     37.713 |     0.2
   16 |   1.0797 |     36.889 |   1.1216 |     37.051 |     0.3
   17 |   1.0550 |     35.625 |   1.1165 |     37.146 |     0.3
   18 |   1.0268 |     34.603 |   1.0875 |     35.035 |     0.3
   19 |   0.9944 |     32.784 |   1.0718 |     35.255 |     0.3
   20 |   0.9626 |     31.971 |   1.0620 |     34.846 |     0.3
   21 |   0.9347 |     30.668 |   1.0740 |     34.625 |     0.3
   22 |   0.9063 |     29.575 |   1.0603 |     34.562 |     0.4
   23 |   0.8827 |     28.844 |   1.0480 |     34.279 |     0.4
   24 |   0.8540 |     27.783 |   1.0601 |     34.216 |     0.4
   25 |   0.8328 |     27.168 |   1.0406 |     33.680 |     0.4
   26 |   0.8023 |     26.008 |   1.0538 |     33.081 |     0.4
   27 |   0.7814 |     25.014 |   1.0257 |     33.428 |     0.4
   28 |   0.7542 |     24.085 |   1.0311 |     32.357 |     0.5
   29 |   0.7324 |     23.481 |   1.0085 |     30.876 |     0.5
   30 |   0.7040 |     22.448 |   1.0044 |     31.222 |     0.5
   31 |   0.6908 |     21.969 |   1.0241 |     30.183 |     0.5
   32 |   0.6714 |     21.206 |   1.0245 |     30.939 |     0.5
   33 |   0.6518 |     20.744 |   1.0183 |     30.403 |     0.5
   34 |   0.6251 |     19.755 |   0.9875 |     29.647 |     0.6
   35 |   0.5972 |     18.469 |   1.0164 |     29.616 |     0.6
   36 |   0.5913 |     18.557 |   1.0297 |     29.899 |     0.6
   37 |   0.5762 |     17.832 |   1.0296 |     29.521 |     0.6
   38 |   0.5629 |     17.381 |   1.0310 |     29.805 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 349,857

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5031 |     66.244 |   1.9743 |     57.467 |     0.0
    2 |   1.7685 |     50.011 |   1.5771 |     45.463 |     0.0
    3 |   1.4986 |     46.126 |   1.4442 |     45.463 |     0.1
    4 |   1.4116 |     45.527 |   1.3857 |     43.951 |     0.1
    5 |   1.3577 |     43.999 |   1.3448 |     42.754 |     0.1
    6 |   1.3139 |     42.752 |   1.3023 |     42.155 |     0.1
    7 |   1.2787 |     42.087 |   1.2839 |     40.643 |     0.2
    8 |   1.2455 |     41.087 |   1.2497 |     39.981 |     0.2
    9 |   1.2174 |     40.125 |   1.2216 |     39.162 |     0.2
   10 |   1.1771 |     38.823 |   1.1946 |     38.878 |     0.2
   11 |   1.1460 |     38.158 |   1.1699 |     37.744 |     0.2
   12 |   1.1157 |     37.015 |   1.1468 |     37.429 |     0.3
   13 |   1.0815 |     35.757 |   1.1210 |     36.295 |     0.3
   14 |   1.0462 |     34.092 |   1.1151 |     35.476 |     0.3
   15 |   1.0267 |     33.322 |   1.1263 |     35.822 |     0.3
   16 |   1.0103 |     32.850 |   1.1029 |     35.003 |     0.4
   17 |   0.9616 |     31.284 |   1.0667 |     34.089 |     0.4
   18 |   0.9315 |     29.921 |   1.0557 |     33.050 |     0.4
   19 |   0.9073 |     29.311 |   1.0408 |     33.081 |     0.4
   20 |   0.8785 |     27.998 |   1.0291 |     32.924 |     0.4
   21 |   0.8514 |     27.261 |   1.0273 |     32.294 |     0.5
   22 |   0.8274 |     26.448 |   1.0190 |     31.979 |     0.5
   23 |   0.8055 |     25.739 |   1.0202 |     32.420 |     0.5
   24 |   0.7777 |     24.744 |   1.0067 |     31.727 |     0.5
   25 |   0.7587 |     24.030 |   1.0277 |     31.569 |     0.5
   26 |   0.7400 |     23.415 |   1.0090 |     31.096 |     0.6
   27 |   0.7189 |     22.981 |   1.0025 |     31.222 |     0.6
   28 |   0.7051 |     22.376 |   1.0199 |     30.876 |     0.6
   29 |   0.6806 |     21.403 |   1.0166 |     30.939 |     0.6
   30 |   0.6546 |     20.601 |   1.0058 |     30.309 |     0.7
   31 |   0.6374 |     20.041 |   1.0232 |     30.498 |     0.7
   32 |   0.6255 |     19.953 |   0.9952 |     29.931 |     0.7
   33 |   0.6045 |     19.008 |   1.0062 |     30.025 |     0.7
   34 |   0.5898 |     18.530 |   0.9914 |     29.238 |     0.7
   35 |   0.5825 |     18.584 |   1.0055 |     29.773 |     0.8
   36 |   0.5659 |     17.744 |   0.9978 |     29.962 |     0.8
   37 |   0.5509 |     17.518 |   1.0003 |     29.112 |     0.8
   38 |   0.5396 |     16.892 |   1.0133 |     29.112 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,454,369

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2088 |     60.419 |   1.6184 |     45.495 |     0.5
    2 |   1.4898 |     46.329 |   1.4306 |     45.495 |     1.0
    3 |   1.4130 |     46.417 |   1.4107 |     45.526 |     1.4
    4 |   1.3934 |     46.263 |   1.3844 |     45.463 |     1.9
    5 |   1.3653 |     45.307 |   1.3527 |     43.352 |     2.4
    6 |   1.3391 |     44.675 |   1.3262 |     43.037 |     2.9
    7 |   1.3134 |     44.065 |   1.3154 |     42.376 |     3.4
    8 |   1.2814 |     42.917 |   1.2657 |     42.187 |     3.9
    9 |   1.2450 |     41.603 |   1.2275 |     40.422 |     4.4
   10 |   1.2104 |     40.823 |   1.2123 |     40.485 |     4.9
   11 |   1.1875 |     40.285 |   1.1855 |     39.099 |     5.4
   12 |   1.1567 |     39.043 |   1.1629 |     38.941 |     5.8
   13 |   1.1319 |     38.592 |   1.1449 |     38.311 |     6.3
   14 |   1.0962 |     37.587 |   1.1244 |     37.398 |     6.8
   15 |   1.0665 |     36.240 |   1.1313 |     36.925 |     7.3
   16 |   1.0475 |     35.482 |   1.1047 |     36.799 |     7.8
   17 |   1.0066 |     34.081 |   1.0820 |     35.381 |     8.3
   18 |   0.9693 |     32.564 |   1.0856 |     35.444 |     8.8
   19 |   0.9438 |     31.328 |   1.0546 |     34.783 |     9.3
   20 |   0.9220 |     30.492 |   1.0484 |     34.058 |     9.8
   21 |   0.8930 |     29.762 |   1.0660 |     34.562 |    10.3
   22 |   0.8577 |     28.712 |   1.0448 |     33.144 |    10.7
   23 |   0.8361 |     27.580 |   1.0149 |     32.798 |    11.2
   24 |   0.7968 |     26.371 |   1.0242 |     32.577 |    11.7
   25 |   0.7657 |     25.267 |   1.0103 |     31.569 |    12.2
   26 |   0.7292 |     23.876 |   0.9941 |     30.781 |    12.7
   27 |   0.6996 |     22.684 |   1.0121 |     31.695 |    13.2
   28 |   0.6788 |     22.030 |   1.0432 |     31.443 |    13.7
   29 |   0.6548 |     21.189 |   1.0217 |     30.687 |    14.1
   30 |   0.6360 |     21.046 |   0.9941 |     30.057 |    14.6
   31 |   0.6110 |     19.826 |   1.0196 |     30.435 |    15.1
   32 |   0.5844 |     18.766 |   1.0406 |     29.899 |    15.6
   33 |   0.5599 |     18.007 |   1.0139 |     29.332 |    16.1
   34 |   0.5337 |     17.134 |   1.0419 |     29.584 |    16.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 586,721

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2104 |     60.051 |   1.5719 |     45.463 |     0.0
    2 |   1.4511 |     46.467 |   1.3780 |     44.644 |     0.0
    3 |   1.3495 |     45.362 |   1.3241 |     44.266 |     0.1
    4 |   1.3000 |     44.131 |   1.2855 |     43.415 |     0.1
    5 |   1.2621 |     42.988 |   1.2347 |     40.296 |     0.1
    6 |   1.2063 |     40.768 |   1.1846 |     39.288 |     0.1
    7 |   1.1588 |     39.054 |   1.1572 |     38.374 |     0.1
    8 |   1.1140 |     37.510 |   1.1221 |     37.083 |     0.2
    9 |   1.0622 |     35.878 |   1.0838 |     36.169 |     0.2
   10 |   1.0242 |     34.718 |   1.0611 |     35.161 |     0.2
   11 |   0.9812 |     33.141 |   1.0349 |     34.058 |     0.2
   12 |   0.9393 |     31.536 |   1.0085 |     32.829 |     0.3
   13 |   0.8997 |     29.981 |   0.9944 |     32.262 |     0.3
   14 |   0.8560 |     28.432 |   0.9822 |     31.254 |     0.3
   15 |   0.8244 |     27.432 |   0.9684 |     31.380 |     0.3
   16 |   0.7829 |     25.942 |   0.9498 |     30.403 |     0.3
   17 |   0.7533 |     24.722 |   0.9603 |     29.836 |     0.4
   18 |   0.7087 |     22.865 |   0.9375 |     29.616 |     0.4
   19 |   0.6720 |     21.733 |   0.9273 |     28.607 |     0.4
   20 |   0.6374 |     20.359 |   0.9490 |     28.922 |     0.4
   21 |   0.6093 |     19.535 |   0.9403 |     29.269 |     0.4
   22 |   0.5721 |     18.249 |   0.9172 |     28.418 |     0.5
   23 |   0.5498 |     17.321 |   0.9326 |     27.064 |     0.5
   24 |   0.5280 |     16.485 |   0.9243 |     27.158 |     0.5
   25 |   0.4996 |     15.760 |   0.9320 |     26.434 |     0.5
   26 |   0.4877 |     15.238 |   0.9218 |     25.835 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 880,385

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2970 |     61.858 |   1.7085 |     48.299 |     0.0
    2 |   1.5282 |     46.686 |   1.4445 |     45.432 |     0.1
    3 |   1.4187 |     46.291 |   1.4101 |     45.432 |     0.1
    4 |   1.4002 |     46.401 |   1.3998 |     45.243 |     0.1
    5 |   1.3869 |     46.313 |   1.3798 |     45.306 |     0.1
    6 |   1.3553 |     45.357 |   1.3255 |     43.132 |     0.2
    7 |   1.3053 |     43.845 |   1.3049 |     43.195 |     0.2
    8 |   1.2747 |     43.247 |   1.2797 |     42.029 |     0.2
    9 |   1.2454 |     42.818 |   1.2395 |     41.966 |     0.2
   10 |   1.2173 |     42.032 |   1.2173 |     40.548 |     0.3
   11 |   1.1886 |     40.878 |   1.1953 |     39.445 |     0.3
   12 |   1.1615 |     39.680 |   1.1741 |     38.280 |     0.3
   13 |   1.1369 |     38.949 |   1.1524 |     38.059 |     0.3
   14 |   1.1052 |     37.751 |   1.1245 |     37.461 |     0.4
   15 |   1.0784 |     36.636 |   1.1243 |     37.209 |     0.4
   16 |   1.0436 |     35.658 |   1.0967 |     35.885 |     0.4
   17 |   1.0184 |     34.471 |   1.1420 |     37.587 |     0.5
   18 |   0.9921 |     33.476 |   1.1014 |     36.074 |     0.5
   19 |   0.9654 |     32.355 |   1.0895 |     36.358 |     0.5
   20 |   0.9352 |     31.289 |   1.0869 |     35.066 |     0.5
   21 |   0.9119 |     30.696 |   1.0716 |     34.846 |     0.6
   22 |   0.8761 |     29.217 |   1.0766 |     34.121 |     0.6
   23 |   0.8517 |     28.492 |   1.0689 |     34.846 |     0.6
   24 |   0.8353 |     27.998 |   1.0625 |     34.657 |     0.6
   25 |   0.8079 |     27.096 |   1.0664 |     33.900 |     0.7
   26 |   0.7808 |     25.547 |   1.0641 |     33.585 |     0.7
   27 |   0.7582 |     25.074 |   1.0446 |     32.798 |     0.7
   28 |   0.7263 |     23.920 |   1.0555 |     33.144 |     0.7
   29 |   0.7083 |     23.398 |   1.0550 |     32.892 |     0.8
   30 |   0.6856 |     22.354 |   1.0535 |     31.916 |     0.8
   31 |   0.6527 |     21.030 |   1.0582 |     31.191 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 473,825

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2151 |     60.023 |   1.5633 |     45.495 |     0.0
    2 |   1.4141 |     44.934 |   1.3241 |     42.187 |     0.0
    3 |   1.2779 |     41.834 |   1.2386 |     40.485 |     0.1
    4 |   1.1964 |     39.543 |   1.1687 |     38.059 |     0.1
    5 |   1.1259 |     37.427 |   1.1276 |     36.736 |     0.1
    6 |   1.0597 |     34.548 |   1.0714 |     35.192 |     0.1
    7 |   0.9938 |     32.635 |   1.0374 |     33.113 |     0.2
    8 |   0.9212 |     29.783 |   1.0033 |     31.947 |     0.2
    9 |   0.8596 |     27.893 |   0.9730 |     31.632 |     0.2
   10 |   0.8125 |     26.349 |   0.9370 |     29.616 |     0.2
   11 |   0.7464 |     23.662 |   0.9220 |     29.301 |     0.3
   12 |   0.7020 |     22.233 |   0.9041 |     27.505 |     0.3
   13 |   0.6536 |     21.123 |   0.9006 |     27.883 |     0.3
   14 |   0.6063 |     19.013 |   0.8736 |     27.379 |     0.3
   15 |   0.5612 |     17.507 |   0.8571 |     25.992 |     0.3
   16 |   0.5128 |     16.106 |   0.8610 |     25.929 |     0.4
   17 |   0.4846 |     15.260 |   0.8661 |     25.961 |     0.4
   18 |   0.4483 |     14.287 |   0.8666 |     25.488 |     0.4
   19 |   0.4205 |     13.238 |   0.8690 |     24.228 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 893,665

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4747 |     65.947 |   1.9440 |     54.064 |     0.0
    2 |   1.7450 |     49.341 |   1.5734 |     45.432 |     0.1
    3 |   1.5016 |     46.291 |   1.4607 |     45.463 |     0.1
    4 |   1.4375 |     46.329 |   1.4224 |     45.463 |     0.1
    5 |   1.4164 |     46.307 |   1.4067 |     45.432 |     0.2
    6 |   1.4060 |     46.368 |   1.4004 |     45.432 |     0.2
    7 |   1.3981 |     46.280 |   1.3946 |     45.432 |     0.2
    8 |   1.3882 |     46.258 |   1.3812 |     44.770 |     0.2
    9 |   1.3721 |     45.631 |   1.3626 |     44.045 |     0.3
   10 |   1.3527 |     44.835 |   1.3438 |     43.573 |     0.3
   11 |   1.3358 |     44.532 |   1.3286 |     43.100 |     0.3
   12 |   1.3215 |     44.203 |   1.3195 |     42.596 |     0.4
   13 |   1.3072 |     43.428 |   1.3111 |     42.155 |     0.4
   14 |   1.2980 |     43.203 |   1.3111 |     43.100 |     0.4
   15 |   1.2879 |     42.911 |   1.2896 |     42.344 |     0.5
   16 |   1.2768 |     42.587 |   1.2848 |     41.525 |     0.5
   17 |   1.2691 |     42.285 |   1.2760 |     41.556 |     0.5
   18 |   1.2577 |     41.917 |   1.2685 |     40.706 |     0.6
   19 |   1.2440 |     41.680 |   1.2708 |     41.210 |     0.6
   20 |   1.2262 |     40.840 |   1.2504 |     40.139 |     0.6
   21 |   1.2118 |     40.449 |   1.2382 |     39.855 |     0.7
   22 |   1.1997 |     40.290 |   1.2231 |     39.666 |     0.7
   23 |   1.1863 |     39.730 |   1.2413 |     40.170 |     0.7
   24 |   1.1773 |     39.400 |   1.2164 |     39.761 |     0.7
   25 |   1.1628 |     39.048 |   1.2224 |     39.319 |     0.8
   26 |   1.1475 |     38.598 |   1.2077 |     39.036 |     0.8
   27 |   1.1301 |     37.625 |   1.2057 |     38.752 |     0.8
   28 |   1.1169 |     37.603 |   1.1882 |     38.154 |     0.9
   29 |   1.0999 |     36.823 |   1.1840 |     38.248 |     0.9
   30 |   1.0807 |     35.586 |   1.1922 |     37.839 |     0.9
   31 |   1.0656 |     35.031 |   1.1846 |     38.028 |     1.0
   32 |   1.0552 |     34.757 |   1.1717 |     37.020 |     1.0
   33 |   1.0386 |     34.476 |   1.1824 |     38.311 |     1.0
   34 |   1.0183 |     33.811 |   1.1536 |     37.146 |     1.1
   35 |   1.0031 |     33.515 |   1.1572 |     37.461 |     1.1
   36 |   0.9896 |     32.690 |   1.1657 |     36.452 |     1.1
   37 |   0.9705 |     32.377 |   1.1403 |     36.452 |     1.2
   38 |   0.9572 |     31.696 |   1.1477 |     36.957 |     1.2
   39 |   0.9479 |     31.454 |   1.1392 |     36.452 |     1.2
   40 |   0.9343 |     30.855 |   1.1326 |     35.602 |     1.2
   41 |   0.9216 |     30.454 |   1.1425 |     36.074 |     1.3
   42 |   0.9068 |     29.987 |   1.1275 |     36.137 |     1.3
   43 |   0.8999 |     29.844 |   1.1198 |     35.444 |     1.3
   44 |   0.8810 |     29.108 |   1.1224 |     35.381 |     1.4
   45 |   0.8642 |     28.421 |   1.1192 |     34.814 |     1.4
   46 |   0.8572 |     28.470 |   1.1331 |     35.003 |     1.4
   47 |   0.8404 |     27.690 |   1.1166 |     35.476 |     1.5
   48 |   0.8334 |     27.195 |   1.1046 |     34.783 |     1.5
   49 |   0.8071 |     26.547 |   1.1078 |     34.310 |     1.5
   50 |   0.8057 |     26.322 |   1.1110 |     34.436 |     1.6
   51 |   0.7895 |     25.640 |   1.1211 |     35.192 |     1.6
   52 |   0.7813 |     25.596 |   1.1246 |     34.436 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 454,561

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6038 |     69.865 |   2.0220 |     58.727 |     0.0
    2 |   1.8134 |     51.808 |   1.6135 |     48.299 |     0.0
    3 |   1.5263 |     46.560 |   1.4534 |     45.463 |     0.1
    4 |   1.4375 |     46.329 |   1.4149 |     45.432 |     0.1
    5 |   1.4141 |     46.362 |   1.4057 |     45.432 |     0.1
    6 |   1.4038 |     46.313 |   1.4009 |     45.432 |     0.1
    7 |   1.3981 |     46.296 |   1.3921 |     45.463 |     0.2
    8 |   1.3880 |     46.340 |   1.3767 |     45.589 |     0.2
    9 |   1.3624 |     45.862 |   1.3504 |     44.486 |     0.2
   10 |   1.3376 |     45.505 |   1.3203 |     44.360 |     0.2
   11 |   1.3156 |     45.307 |   1.2996 |     44.203 |     0.3
   12 |   1.3022 |     45.049 |   1.2833 |     43.982 |     0.3
   13 |   1.2862 |     44.675 |   1.2820 |     43.667 |     0.3
   14 |   1.2700 |     44.368 |   1.2730 |     42.974 |     0.3
   15 |   1.2586 |     43.747 |   1.2586 |     42.470 |     0.3
   16 |   1.2417 |     42.977 |   1.2441 |     41.651 |     0.4
   17 |   1.2273 |     42.384 |   1.2454 |     41.871 |     0.4
   18 |   1.2165 |     42.115 |   1.2223 |     42.218 |     0.4
   19 |   1.1943 |     41.081 |   1.2112 |     40.769 |     0.4
   20 |   1.1796 |     40.455 |   1.2001 |     40.107 |     0.5
   21 |   1.1647 |     39.889 |   1.1934 |     40.139 |     0.5
   22 |   1.1499 |     39.460 |   1.2092 |     40.233 |     0.5
   23 |   1.1384 |     38.801 |   1.1808 |     38.815 |     0.5
   24 |   1.1207 |     37.922 |   1.1590 |     38.563 |     0.5
   25 |   1.1018 |     37.268 |   1.1491 |     37.524 |     0.6
   26 |   1.0879 |     36.427 |   1.1398 |     37.618 |     0.6
   27 |   1.0754 |     36.652 |   1.1421 |     37.650 |     0.6
   28 |   1.0615 |     35.795 |   1.1376 |     37.965 |     0.6
   29 |   1.0487 |     35.383 |   1.1179 |     37.240 |     0.7
   30 |   1.0235 |     34.691 |   1.1144 |     36.515 |     0.7
   31 |   1.0113 |     34.053 |   1.1066 |     36.894 |     0.7
   32 |   1.0046 |     33.993 |   1.0980 |     36.862 |     0.7
   33 |   0.9889 |     33.438 |   1.0743 |     35.791 |     0.7
   34 |   0.9714 |     32.734 |   1.0978 |     36.137 |     0.8
   35 |   0.9661 |     32.784 |   1.0845 |     36.043 |     0.8
   36 |   0.9489 |     32.223 |   1.0765 |     35.255 |     0.8
   37 |   0.9465 |     32.284 |   1.0660 |     35.098 |     0.8
   38 |   0.9302 |     31.498 |   1.0820 |     34.720 |     0.9
   39 |   0.9169 |     31.091 |   1.0665 |     35.318 |     0.9
   40 |   0.9124 |     30.970 |   1.0536 |     35.035 |     0.9
   41 |   0.8999 |     30.701 |   1.0623 |     34.940 |     0.9
   42 |   0.8861 |     30.157 |   1.0569 |     33.932 |     0.9
   43 |   0.8832 |     30.218 |   1.0437 |     33.837 |     1.0
   44 |   0.8765 |     29.981 |   1.0647 |     34.152 |     1.0
   45 |   0.8531 |     29.212 |   1.0339 |     33.554 |     1.0
   46 |   0.8495 |     29.025 |   1.0266 |     32.861 |     1.0
   47 |   0.8331 |     28.294 |   1.0305 |     33.554 |     1.1
   48 |   0.8367 |     28.580 |   1.0400 |     32.987 |     1.1
   49 |   0.8179 |     27.954 |   1.0277 |     32.861 |     1.1
   50 |   0.8202 |     27.492 |   1.0463 |     33.963 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,553,697

Training started
X_train.shape: torch.Size([3033, 702])
Y_train.shape: torch.Size([3033, 7])
X_dev.shape: torch.Size([529, 267])
Y_dev.shape: torch.Size([529, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4713 |     66.628 |   1.9150 |     54.001 |     0.9
    2 |   1.7032 |     49.038 |   1.5467 |     45.495 |     1.9
    3 |   1.4844 |     46.291 |   1.4448 |     45.432 |     2.8
    4 |   1.4317 |     46.291 |   1.4227 |     45.432 |     3.8
    5 |   1.4141 |     46.291 |   1.4072 |     45.432 |     4.8
    6 |   1.4039 |     46.291 |   1.4008 |     45.432 |     5.7
    7 |   1.3950 |     46.214 |   1.3872 |     45.432 |     6.7
    8 |   1.3864 |     46.263 |   1.3867 |     45.432 |     7.7
    9 |   1.3757 |     45.978 |   1.3658 |     43.919 |     8.6
   10 |   1.3591 |     45.005 |   1.3580 |     44.234 |     9.6
   11 |   1.3472 |     44.714 |   1.3597 |     44.234 |    10.5
   12 |   1.3398 |     44.637 |   1.3342 |     43.478 |    11.5
   13 |   1.3265 |     44.461 |   1.3374 |     44.612 |    12.5
   14 |   1.3241 |     44.549 |   1.3226 |     43.195 |    13.4
   15 |   1.3098 |     44.038 |   1.3218 |     43.510 |    14.4
   16 |   1.3023 |     43.719 |   1.3116 |     42.817 |    15.4
   17 |   1.2929 |     43.494 |   1.3103 |     42.187 |    16.3
   18 |   1.2855 |     43.027 |   1.2996 |     41.871 |    17.3
   19 |   1.2763 |     42.977 |   1.2864 |     41.808 |    18.2
   20 |   1.2695 |     42.834 |   1.2827 |     41.997 |    19.2
   21 |   1.2667 |     42.488 |   1.2898 |     42.344 |    20.2
   22 |   1.2553 |     42.153 |   1.2814 |     42.124 |    21.1
   23 |   1.2535 |     42.246 |   1.2691 |     41.273 |    22.1
   24 |   1.2434 |     41.658 |   1.2705 |     41.588 |    23.0
   25 |   1.2411 |     41.977 |   1.2617 |     41.430 |    24.0
   26 |   1.2335 |     41.664 |   1.2624 |     40.958 |    25.0
   27 |   1.2278 |     41.323 |   1.2636 |     41.021 |    25.9
   28 |   1.2164 |     41.043 |   1.2436 |     40.233 |    26.9
   29 |   1.2024 |     40.417 |   1.2498 |     40.548 |    27.8
   30 |   1.1964 |     40.642 |   1.2485 |     40.233 |    28.8
   31 |   1.1872 |     39.988 |   1.2562 |     40.233 |    29.7
   32 |   1.1824 |     39.873 |   1.2228 |     39.288 |    30.7
   33 |   1.1645 |     39.268 |   1.2350 |     39.382 |    31.7
   34 |   1.1629 |     39.318 |   1.2428 |     39.698 |    32.6
   35 |   1.1513 |     38.938 |   1.2167 |     39.099 |    33.6
   36 |   1.1382 |     38.543 |   1.2207 |     39.067 |    34.5
   37 |   1.1324 |     38.493 |   1.2162 |     39.635 |    35.5
   38 |   1.1260 |     38.054 |   1.2181 |     39.162 |    36.4
   39 |   1.1164 |     37.828 |   1.2002 |     39.225 |    37.4
   40 |   1.1023 |     37.240 |   1.1993 |     39.130 |    38.3
   41 |   1.0996 |     37.010 |   1.1977 |     38.941 |    39.3
   42 |   1.0859 |     36.510 |   1.2095 |     38.689 |    40.3
   43 |   1.0804 |     36.422 |   1.1760 |     37.492 |    41.2
   44 |   1.0737 |     36.213 |   1.1936 |     38.091 |    42.2
   45 |   1.0632 |     36.262 |   1.1740 |     37.587 |    43.1
   46 |   1.0557 |     35.493 |   1.1708 |     37.461 |    44.1
   47 |   1.0602 |     36.059 |   1.2060 |     38.815 |    45.1
   48 |   1.0821 |     36.718 |   1.1921 |     38.374 |    46.0
   49 |   1.0639 |     36.268 |   1.1927 |     37.933 |    47.0
   50 |   1.0479 |     35.718 |   1.1654 |     37.303 |    47.9
   51 |   1.0259 |     34.685 |   1.1674 |     37.555 |    48.9
   52 |   1.0202 |     34.696 |   1.1623 |     37.618 |    49.9
   53 |   1.0061 |     34.048 |   1.1732 |     37.524 |    50.8
   54 |   1.0006 |     33.603 |   1.1544 |     37.272 |    51.8
   55 |   0.9959 |     33.795 |   1.1591 |     36.767 |    52.8
   56 |   1.0020 |     33.833 |   1.1510 |     37.209 |    53.7
   57 |   0.9760 |     32.718 |   1.1556 |     36.830 |    54.7
   58 |   0.9770 |     32.608 |   1.1520 |     36.894 |    55.7
   59 |   0.9634 |     32.613 |   1.1647 |     37.681 |    56.6
   60 |   0.9571 |     32.289 |   1.1465 |     36.137 |    57.6
   61 |   0.9510 |     32.031 |   1.1386 |     35.948 |    58.5
   62 |   0.9321 |     31.361 |   1.1420 |     36.704 |    59.5
   63 |   0.9256 |     31.322 |   1.1586 |     37.272 |    60.5
   64 |   0.9204 |     31.102 |   1.1591 |     36.767 |    61.4
   65 |   0.9063 |     30.503 |   1.1383 |     36.830 |    62.4
   66 |   0.9153 |     31.102 |   1.1532 |     36.736 |    63.4
   67 |   0.9061 |     30.564 |   1.1487 |     37.051 |    64.3
   68 |   0.8872 |     30.119 |   1.1329 |     35.791 |    65.3
   69 |   0.8852 |     30.091 |   1.1450 |     36.137 |    66.2
   70 |   0.8733 |     29.751 |   1.1252 |     35.696 |    67.2
   71 |   0.8601 |     29.228 |   1.1587 |     35.948 |    68.1
   72 |   0.8610 |     28.976 |   1.1379 |     35.539 |    69.1
   73 |   0.8552 |     28.943 |   1.1347 |     35.854 |    70.1
   74 |   0.8497 |     28.844 |   1.1204 |     35.507 |    71.0
   75 |   0.8242 |     27.613 |   1.1123 |     34.531 |    72.0
   76 |   0.8106 |     27.146 |   1.1211 |     35.192 |    73.0
   77 |   0.8149 |     27.151 |   1.1360 |     34.720 |    73.9
   78 |   0.7991 |     26.739 |   1.1339 |     35.318 |    74.9
   79 |   0.7875 |     26.580 |   1.1251 |     34.152 |    75.9
Early stopping

