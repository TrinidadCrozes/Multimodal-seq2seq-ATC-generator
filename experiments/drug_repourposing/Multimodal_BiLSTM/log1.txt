Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 259,490

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5555 |     67.410 |   2.0011 |     57.695 |     0.0
    2 |   1.7587 |     50.325 |   1.5700 |     45.763 |     0.0
    3 |   1.4874 |     46.036 |   1.4350 |     45.763 |     0.0
    4 |   1.4084 |     46.146 |   1.3902 |     45.763 |     0.1
    5 |   1.3650 |     45.518 |   1.3564 |     44.798 |     0.1
    6 |   1.3259 |     44.511 |   1.3157 |     44.548 |     0.1
    7 |   1.2861 |     43.288 |   1.2823 |     43.115 |     0.1
    8 |   1.2425 |     41.934 |   1.2502 |     42.150 |     0.1
    9 |   1.2121 |     41.135 |   1.2335 |     42.087 |     0.1
   10 |   1.1756 |     39.792 |   1.2192 |     40.717 |     0.1
   11 |   1.1419 |     38.437 |   1.2230 |     40.903 |     0.1
   12 |   1.1067 |     37.347 |   1.1682 |     39.626 |     0.2
   13 |   1.0651 |     35.811 |   1.1497 |     38.474 |     0.2
   14 |   1.0351 |     34.666 |   1.1311 |     37.539 |     0.2
   15 |   1.0030 |     33.460 |   1.1232 |     37.383 |     0.2
   16 |   0.9690 |     32.105 |   1.0918 |     35.888 |     0.2
   17 |   0.9380 |     30.900 |   1.0917 |     36.106 |     0.2
   18 |   0.9035 |     29.584 |   1.0737 |     34.735 |     0.2
   19 |   0.8695 |     28.290 |   1.0653 |     33.894 |     0.2
   20 |   0.8415 |     27.359 |   1.0596 |     34.548 |     0.3
   21 |   0.8151 |     26.352 |   1.0664 |     33.364 |     0.3
   22 |   0.7872 |     25.603 |   1.0520 |     32.555 |     0.3
   23 |   0.7578 |     24.452 |   1.0465 |     32.118 |     0.3
   24 |   0.7409 |     23.913 |   1.0743 |     32.679 |     0.3
   25 |   0.7089 |     22.866 |   1.0634 |     32.461 |     0.3
   26 |   0.6839 |     21.710 |   1.0623 |     31.651 |     0.3
   27 |   0.6622 |     20.912 |   1.0645 |     32.368 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,243,490

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2213 |     59.988 |   1.6174 |     45.763 |     0.0
    2 |   1.4801 |     46.190 |   1.4187 |     45.763 |     0.1
    3 |   1.4069 |     46.344 |   1.3914 |     45.763 |     0.1
    4 |   1.3790 |     46.135 |   1.3731 |     44.642 |     0.1
    5 |   1.3471 |     44.615 |   1.3450 |     44.486 |     0.2
    6 |   1.3203 |     43.850 |   1.3225 |     44.455 |     0.2
    7 |   1.2961 |     43.310 |   1.3097 |     43.271 |     0.2
    8 |   1.2761 |     42.627 |   1.3040 |     43.146 |     0.3
    9 |   1.2609 |     42.209 |   1.2848 |     42.773 |     0.3
   10 |   1.2413 |     41.245 |   1.2928 |     42.897 |     0.3
   11 |   1.2205 |     40.821 |   1.2554 |     41.464 |     0.4
   12 |   1.2025 |     40.442 |   1.2531 |     41.869 |     0.4
   13 |   1.1729 |     39.456 |   1.2187 |     41.059 |     0.4
   14 |   1.1389 |     38.448 |   1.2261 |     41.994 |     0.5
   15 |   1.1257 |     38.013 |   1.1864 |     39.720 |     0.5
   16 |   1.0927 |     36.813 |   1.1557 |     38.255 |     0.5
   17 |   1.0626 |     35.778 |   1.1564 |     38.100 |     0.6
   18 |   1.0248 |     34.539 |   1.1425 |     38.006 |     0.6
   19 |   0.9996 |     33.576 |   1.1405 |     36.791 |     0.6
   20 |   0.9825 |     33.031 |   1.1213 |     37.134 |     0.7
   21 |   0.9455 |     31.825 |   1.1010 |     36.511 |     0.7
   22 |   0.9271 |     30.999 |   1.0842 |     35.389 |     0.7
   23 |   0.8881 |     29.705 |   1.0857 |     35.109 |     0.8
   24 |   0.8593 |     28.609 |   1.0796 |     36.293 |     0.8
   25 |   0.8330 |     27.794 |   1.0538 |     34.704 |     0.8
   26 |   0.8053 |     27.123 |   1.0473 |     33.458 |     0.9
   27 |   0.7709 |     25.801 |   1.0498 |     33.178 |     0.9
   28 |   0.7445 |     24.893 |   1.0481 |     33.053 |     0.9
   29 |   0.7169 |     23.797 |   1.0510 |     33.084 |     1.0
   30 |   0.6967 |     23.164 |   1.0458 |     31.900 |     1.0
   31 |   0.6744 |     22.481 |   1.0487 |     32.492 |     1.0
   32 |   0.6499 |     21.556 |   1.0389 |     32.710 |     1.1
   33 |   0.6381 |     21.198 |   1.0199 |     31.807 |     1.1
   34 |   0.6090 |     20.058 |   1.0448 |     31.277 |     1.1
   35 |   0.5860 |     19.221 |   1.0425 |     32.243 |     1.2
   36 |   0.5596 |     18.230 |   1.0317 |     30.249 |     1.2
   37 |   0.5515 |     18.065 |   1.0179 |     30.810 |     1.2
   38 |   0.5261 |     17.234 |   1.0438 |     30.561 |     1.3
   39 |   0.5078 |     16.766 |   1.0514 |     29.969 |     1.3
   40 |   0.4877 |     15.989 |   1.0611 |     29.907 |     1.3
   41 |   0.4771 |     15.769 |   1.0813 |     30.498 |     1.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,008,802

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2627 |     61.673 |   1.6530 |     48.816 |     0.0
    2 |   1.4997 |     46.350 |   1.4236 |     45.763 |     0.1
    3 |   1.3982 |     46.041 |   1.3759 |     45.919 |     0.1
    4 |   1.3569 |     45.513 |   1.3366 |     44.798 |     0.1
    5 |   1.3232 |     45.023 |   1.3267 |     45.016 |     0.1
    6 |   1.2935 |     44.461 |   1.3027 |     43.551 |     0.2
    7 |   1.2558 |     42.837 |   1.2744 |     43.178 |     0.2
    8 |   1.2245 |     41.747 |   1.2302 |     41.495 |     0.2
    9 |   1.1885 |     40.320 |   1.2135 |     41.526 |     0.2
   10 |   1.1646 |     39.797 |   1.1978 |     40.374 |     0.3
   11 |   1.1336 |     38.570 |   1.1628 |     38.910 |     0.3
   12 |   1.1038 |     37.309 |   1.1417 |     38.505 |     0.3
   13 |   1.0710 |     35.855 |   1.1191 |     37.819 |     0.3
   14 |   1.0276 |     34.633 |   1.1121 |     36.417 |     0.4
   15 |   0.9918 |     33.311 |   1.0851 |     35.763 |     0.4
   16 |   0.9691 |     32.331 |   1.0667 |     35.047 |     0.4
   17 |   0.9326 |     31.142 |   1.0646 |     33.988 |     0.4
   18 |   0.9092 |     30.283 |   1.0464 |     33.707 |     0.5
   19 |   0.8886 |     29.386 |   1.0609 |     34.798 |     0.5
   20 |   0.8548 |     28.273 |   1.0345 |     34.081 |     0.5
   21 |   0.8284 |     27.453 |   0.9954 |     31.464 |     0.5
   22 |   0.8044 |     26.732 |   1.0079 |     31.526 |     0.6
   23 |   0.7689 |     25.074 |   0.9794 |     30.374 |     0.6
   24 |   0.7620 |     24.926 |   0.9841 |     31.153 |     0.6
   25 |   0.7251 |     23.461 |   0.9643 |     30.187 |     0.7
   26 |   0.7003 |     22.877 |   0.9633 |     30.000 |     0.7
   27 |   0.6822 |     22.448 |   0.9643 |     29.782 |     0.7
   28 |   0.6672 |     22.007 |   0.9540 |     30.031 |     0.7
   29 |   0.6380 |     20.747 |   0.9715 |     29.003 |     0.8
   30 |   0.6223 |     20.570 |   0.9815 |     29.252 |     0.8
   31 |   0.6013 |     19.585 |   0.9714 |     28.910 |     0.8
   32 |   0.5830 |     19.040 |   0.9842 |     29.470 |     0.8
   33 |   0.5696 |     18.583 |   0.9478 |     28.255 |     0.9
   34 |   0.5589 |     18.142 |   0.9634 |     28.318 |     0.9
   35 |   0.5325 |     17.426 |   0.9623 |     28.255 |     0.9
   36 |   0.5199 |     16.733 |   0.9713 |     27.477 |     0.9
   37 |   0.4981 |     16.160 |   0.9804 |     27.009 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 658,850

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6119 |     70.009 |   2.0784 |     59.159 |     0.0
    2 |   1.8209 |     51.949 |   1.5978 |     45.763 |     0.1
    3 |   1.5186 |     46.091 |   1.4581 |     45.763 |     0.1
    4 |   1.4412 |     46.102 |   1.4205 |     45.763 |     0.1
    5 |   1.4151 |     46.124 |   1.4037 |     45.763 |     0.1
    6 |   1.3959 |     46.030 |   1.3894 |     45.670 |     0.2
    7 |   1.3763 |     45.942 |   1.3711 |     45.327 |     0.2
    8 |   1.3570 |     44.780 |   1.3495 |     44.611 |     0.2
    9 |   1.3337 |     44.500 |   1.3399 |     44.330 |     0.2
   10 |   1.3202 |     44.131 |   1.3439 |     45.639 |     0.3
   11 |   1.3111 |     43.932 |   1.3201 |     44.174 |     0.3
   12 |   1.2958 |     43.519 |   1.3072 |     43.707 |     0.3
   13 |   1.2812 |     43.195 |   1.2966 |     43.707 |     0.3
   14 |   1.2709 |     42.897 |   1.2784 |     43.084 |     0.4
   15 |   1.2526 |     42.738 |   1.2647 |     42.523 |     0.4
   16 |   1.2241 |     41.636 |   1.2372 |     41.931 |     0.4
   17 |   1.2063 |     40.662 |   1.2348 |     41.526 |     0.4
   18 |   1.1941 |     40.210 |   1.2110 |     40.841 |     0.5
   19 |   1.1719 |     39.638 |   1.2192 |     40.810 |     0.5
   20 |   1.1559 |     39.401 |   1.2003 |     40.561 |     0.5
   21 |   1.1376 |     38.817 |   1.1677 |     39.065 |     0.5
   22 |   1.1246 |     38.179 |   1.1689 |     39.065 |     0.6
   23 |   1.1131 |     37.689 |   1.1601 |     38.754 |     0.6
   24 |   1.0906 |     37.116 |   1.1472 |     38.785 |     0.6
   25 |   1.0824 |     36.753 |   1.1477 |     38.754 |     0.6
   26 |   1.0636 |     36.268 |   1.1245 |     38.193 |     0.7
   27 |   1.0522 |     35.855 |   1.1379 |     38.100 |     0.7
   28 |   1.0425 |     35.404 |   1.1081 |     37.539 |     0.7
   29 |   1.0275 |     34.616 |   1.1188 |     37.570 |     0.7
   30 |   1.0200 |     34.143 |   1.1121 |     37.290 |     0.8
   31 |   1.0122 |     34.016 |   1.0999 |     37.290 |     0.8
   32 |   0.9959 |     33.333 |   1.1014 |     36.854 |     0.8
   33 |   0.9754 |     32.540 |   1.0875 |     35.950 |     0.8
   34 |   0.9784 |     32.634 |   1.0896 |     36.012 |     0.9
   35 |   0.9616 |     32.078 |   1.0846 |     36.231 |     0.9
   36 |   0.9455 |     31.291 |   1.0617 |     35.826 |     0.9
   37 |   0.9313 |     30.977 |   1.0552 |     35.545 |     0.9
   38 |   0.9135 |     30.283 |   1.0673 |     34.984 |     1.0
   39 |   0.9037 |     29.710 |   1.0570 |     35.202 |     1.0
   40 |   0.8956 |     29.666 |   1.0504 |     35.016 |     1.0
   41 |   0.8898 |     29.639 |   1.0482 |     34.361 |     1.0
   42 |   0.8748 |     29.165 |   1.0514 |     35.016 |     1.1
   43 |   0.8675 |     28.736 |   1.0300 |     34.393 |     1.1
   44 |   0.8509 |     28.147 |   1.0302 |     33.925 |     1.1
   45 |   0.8414 |     27.844 |   1.0186 |     33.302 |     1.1
   46 |   0.8221 |     27.211 |   1.0286 |     33.801 |     1.2
   47 |   0.8180 |     27.090 |   1.0247 |     33.022 |     1.2
   48 |   0.8044 |     26.825 |   1.0388 |     33.364 |     1.2
   49 |   0.7900 |     26.060 |   1.0277 |     33.427 |     1.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 805,794

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3471 |     63.330 |   1.7278 |     52.087 |     0.0
    2 |   1.5291 |     46.691 |   1.4309 |     45.763 |     0.0
    3 |   1.4162 |     46.030 |   1.3987 |     45.763 |     0.1
    4 |   1.3948 |     45.953 |   1.3945 |     45.576 |     0.1
    5 |   1.3710 |     45.458 |   1.3598 |     44.611 |     0.1
    6 |   1.3368 |     44.516 |   1.3367 |     44.455 |     0.1
    7 |   1.3148 |     43.756 |   1.3110 |     43.396 |     0.2
    8 |   1.2860 |     42.969 |   1.2871 |     43.240 |     0.2
    9 |   1.2606 |     42.231 |   1.2754 |     42.399 |     0.2
   10 |   1.2295 |     41.301 |   1.2531 |     41.745 |     0.2
   11 |   1.2036 |     40.585 |   1.2321 |     40.748 |     0.3
   12 |   1.1679 |     39.797 |   1.2107 |     39.938 |     0.3
   13 |   1.1439 |     38.955 |   1.2023 |     40.685 |     0.3
   14 |   1.1202 |     38.151 |   1.1847 |     40.343 |     0.3
   15 |   1.0976 |     37.705 |   1.1874 |     39.688 |     0.4
   16 |   1.0757 |     37.011 |   1.1632 |     38.910 |     0.4
   17 |   1.0449 |     35.629 |   1.1498 |     38.567 |     0.4
   18 |   1.0266 |     35.343 |   1.1342 |     38.131 |     0.4
   19 |   1.0003 |     34.374 |   1.1479 |     37.944 |     0.5
   20 |   0.9807 |     33.873 |   1.1268 |     37.383 |     0.5
   21 |   0.9534 |     32.607 |   1.1247 |     37.259 |     0.5
   22 |   0.9297 |     31.671 |   1.1238 |     36.698 |     0.5
   23 |   0.9106 |     31.114 |   1.0956 |     35.421 |     0.5
   24 |   0.8864 |     30.448 |   1.0906 |     35.950 |     0.6
   25 |   0.8490 |     28.642 |   1.0838 |     35.265 |     0.6
   26 |   0.8270 |     28.053 |   1.0738 |     34.112 |     0.6
   27 |   0.8123 |     27.464 |   1.0737 |     34.455 |     0.6
   28 |   0.7894 |     26.500 |   1.0874 |     35.140 |     0.7
   29 |   0.7693 |     26.131 |   1.0675 |     34.361 |     0.7
   30 |   0.7377 |     24.661 |   1.0475 |     32.461 |     0.7
   31 |   0.7157 |     23.913 |   1.0697 |     32.368 |     0.7
   32 |   0.6878 |     22.921 |   1.0588 |     32.928 |     0.8
   33 |   0.6771 |     22.487 |   1.0486 |     31.931 |     0.8
   34 |   0.6558 |     22.074 |   1.0569 |     31.433 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,745,442

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4850 |     65.268 |   1.9974 |     58.162 |     0.1
    2 |   1.7648 |     49.906 |   1.5682 |     45.763 |     0.1
    3 |   1.4915 |     46.080 |   1.4449 |     46.262 |     0.2
    4 |   1.4173 |     46.102 |   1.3964 |     45.794 |     0.2
    5 |   1.3752 |     44.841 |   1.3608 |     44.330 |     0.3
    6 |   1.3415 |     43.861 |   1.3398 |     44.112 |     0.4
    7 |   1.3137 |     43.167 |   1.3091 |     43.894 |     0.4
    8 |   1.2856 |     42.451 |   1.2958 |     42.897 |     0.5
    9 |   1.2623 |     41.609 |   1.2841 |     42.368 |     0.5
   10 |   1.2484 |     41.367 |   1.2712 |     42.118 |     0.6
   11 |   1.2258 |     40.810 |   1.2552 |     42.087 |     0.7
   12 |   1.2047 |     40.271 |   1.2389 |     41.308 |     0.7
   13 |   1.1731 |     39.346 |   1.2171 |     40.654 |     0.8
   14 |   1.1539 |     38.630 |   1.2024 |     40.031 |     0.8
   15 |   1.1281 |     38.052 |   1.1897 |     39.907 |     0.9
   16 |   1.0958 |     36.637 |   1.1578 |     39.097 |     1.0
   17 |   1.0753 |     36.070 |   1.1571 |     38.442 |     1.0
   18 |   1.0644 |     35.695 |   1.1482 |     38.349 |     1.1
   19 |   1.0499 |     34.969 |   1.1427 |     37.913 |     1.1
   20 |   1.0253 |     33.917 |   1.1324 |     36.854 |     1.2
   21 |   1.0231 |     33.746 |   1.1321 |     37.882 |     1.3
   22 |   1.0013 |     32.931 |   1.1082 |     36.293 |     1.3
   23 |   0.9782 |     32.238 |   1.1011 |     35.950 |     1.4
   24 |   0.9556 |     31.335 |   1.0958 |     36.449 |     1.4
   25 |   0.9428 |     30.955 |   1.0958 |     35.950 |     1.5
   26 |   0.9267 |     30.553 |   1.0926 |     35.576 |     1.6
   27 |   0.9077 |     30.090 |   1.1119 |     36.293 |     1.6
   28 |   0.9203 |     30.465 |   1.0770 |     35.047 |     1.7
   29 |   0.8972 |     29.727 |   1.0676 |     35.483 |     1.7
   30 |   0.8818 |     29.066 |   1.0744 |     35.576 |     1.8
   31 |   0.8666 |     28.730 |   1.0643 |     34.143 |     1.9
   32 |   0.8467 |     28.081 |   1.0595 |     34.019 |     1.9
   33 |   0.8296 |     27.310 |   1.0533 |     34.673 |     2.0
   34 |   0.8137 |     27.095 |   1.0403 |     33.520 |     2.0
   35 |   0.8082 |     26.363 |   1.0525 |     34.112 |     2.1
   36 |   0.8094 |     26.787 |   1.0382 |     33.302 |     2.2
   37 |   0.7927 |     26.374 |   1.0413 |     33.489 |     2.2
   38 |   0.7698 |     25.306 |   1.0338 |     32.679 |     2.3
   39 |   0.7542 |     24.838 |   1.0295 |     33.146 |     2.3
   40 |   0.7490 |     25.091 |   1.0352 |     32.399 |     2.4
   41 |   0.7475 |     24.937 |   1.0454 |     32.804 |     2.5
   42 |   0.7228 |     24.155 |   1.0281 |     31.838 |     2.5
   43 |   0.7196 |     23.665 |   1.0377 |     32.399 |     2.6
   44 |   0.7083 |     23.538 |   1.0549 |     33.022 |     2.6
   45 |   0.6969 |     22.624 |   1.0386 |     32.118 |     2.7
   46 |   0.6915 |     22.789 |   1.0320 |     33.178 |     2.8
   47 |   0.6839 |     22.789 |   1.0263 |     32.150 |     2.8
   48 |   0.6655 |     21.941 |   1.0213 |     31.558 |     2.9
   49 |   0.6603 |     21.600 |   1.0247 |     32.150 |     2.9
   50 |   0.6530 |     21.374 |   1.0484 |     32.897 |     3.0
   51 |   0.6514 |     21.523 |   1.0034 |     32.586 |     3.1
   52 |   0.6310 |     20.576 |   1.0238 |     31.121 |     3.1
   53 |   0.6369 |     20.736 |   1.0197 |     31.059 |     3.2
   54 |   0.6186 |     20.416 |   1.0369 |     31.184 |     3.2
   55 |   0.6089 |     20.273 |   1.0174 |     30.374 |     3.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,182,434

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5536 |     67.751 |   2.0086 |     59.159 |     0.0
    2 |   1.7905 |     50.562 |   1.5945 |     45.826 |     0.1
    3 |   1.5110 |     46.063 |   1.4533 |     45.763 |     0.1
    4 |   1.4377 |     46.058 |   1.4152 |     45.763 |     0.2
    5 |   1.4122 |     46.030 |   1.4012 |     45.763 |     0.2
    6 |   1.4004 |     46.069 |   1.3959 |     46.791 |     0.2
    7 |   1.3913 |     46.267 |   1.3848 |     46.791 |     0.3
    8 |   1.3787 |     46.190 |   1.3711 |     45.701 |     0.3
    9 |   1.3700 |     45.964 |   1.3695 |     45.826 |     0.4
   10 |   1.3580 |     45.325 |   1.3641 |     44.984 |     0.4
   11 |   1.3430 |     44.582 |   1.3417 |     44.299 |     0.4
   12 |   1.3263 |     44.219 |   1.3288 |     44.237 |     0.5
   13 |   1.3156 |     43.954 |   1.3273 |     44.860 |     0.5
   14 |   1.3081 |     43.905 |   1.3184 |     44.704 |     0.6
   15 |   1.3011 |     43.591 |   1.3106 |     44.143 |     0.6
   16 |   1.2929 |     43.767 |   1.2996 |     44.766 |     0.7
   17 |   1.2841 |     43.288 |   1.2969 |     43.988 |     0.7
   18 |   1.2720 |     43.068 |   1.2913 |     43.676 |     0.7
   19 |   1.2661 |     43.013 |   1.2874 |     43.240 |     0.8
   20 |   1.2563 |     42.705 |   1.2786 |     44.019 |     0.8
   21 |   1.2497 |     42.479 |   1.2706 |     42.804 |     0.9
   22 |   1.2436 |     41.983 |   1.2720 |     42.679 |     0.9
   23 |   1.2333 |     41.642 |   1.2663 |     42.960 |     0.9
   24 |   1.2248 |     41.378 |   1.2602 |     42.492 |     1.0
   25 |   1.2160 |     40.981 |   1.2587 |     41.526 |     1.0
   26 |   1.2066 |     40.634 |   1.2467 |     41.215 |     1.1
   27 |   1.1961 |     40.403 |   1.2412 |     41.246 |     1.1
   28 |   1.1938 |     40.458 |   1.2440 |     41.807 |     1.1
   29 |   1.1771 |     40.001 |   1.2447 |     41.028 |     1.2
   30 |   1.1793 |     39.990 |   1.2342 |     41.464 |     1.2
   31 |   1.1719 |     39.544 |   1.2380 |     41.589 |     1.3
   32 |   1.1538 |     39.104 |   1.2269 |     40.997 |     1.3
   33 |   1.1368 |     38.399 |   1.2163 |     40.343 |     1.4
   34 |   1.1334 |     38.173 |   1.2188 |     40.343 |     1.4
   35 |   1.1343 |     38.344 |   1.2232 |     41.059 |     1.4
   36 |   1.1162 |     37.826 |   1.2150 |     40.218 |     1.5
   37 |   1.1052 |     36.989 |   1.2010 |     39.844 |     1.5
   38 |   1.0965 |     37.072 |   1.2117 |     40.187 |     1.6
   39 |   1.0840 |     36.516 |   1.1971 |     39.751 |     1.6
   40 |   1.0728 |     36.263 |   1.2055 |     40.218 |     1.6
   41 |   1.0691 |     35.971 |   1.2045 |     39.377 |     1.7
   42 |   1.0587 |     35.354 |   1.1902 |     40.093 |     1.7
   43 |   1.0491 |     35.035 |   1.1871 |     39.221 |     1.8
   44 |   1.0407 |     34.385 |   1.1647 |     37.383 |     1.8
   45 |   1.0257 |     34.027 |   1.1700 |     38.598 |     1.8
   46 |   1.0288 |     34.473 |   1.1706 |     37.850 |     1.9
   47 |   1.0170 |     33.741 |   1.1689 |     38.723 |     1.9
   48 |   1.0124 |     33.543 |   1.1712 |     38.193 |     2.0
   49 |   1.0014 |     33.322 |   1.1640 |     38.442 |     2.0
   50 |   0.9997 |     33.355 |   1.1913 |     38.879 |     2.1
   51 |   0.9852 |     32.799 |   1.1661 |     37.788 |     2.1
   52 |   0.9784 |     32.645 |   1.1695 |     38.287 |     2.1
   53 |   0.9644 |     32.298 |   1.1485 |     38.100 |     2.2
   54 |   0.9536 |     31.505 |   1.1450 |     37.196 |     2.2
   55 |   0.9505 |     31.687 |   1.1602 |     37.445 |     2.3
   56 |   0.9669 |     32.133 |   1.1592 |     38.100 |     2.3
   57 |   0.9557 |     31.979 |   1.1301 |     36.729 |     2.3
   58 |   0.9442 |     31.236 |   1.1317 |     36.604 |     2.4
   59 |   0.9266 |     30.861 |   1.1419 |     36.947 |     2.4
   60 |   0.9220 |     30.652 |   1.1286 |     36.636 |     2.5
   61 |   0.9142 |     30.657 |   1.1299 |     36.604 |     2.5
   62 |   0.9061 |     29.986 |   1.1479 |     36.822 |     2.5
   63 |   0.8980 |     29.672 |   1.1476 |     37.259 |     2.6
   64 |   0.9027 |     29.793 |   1.1355 |     36.978 |     2.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 426,210

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5919 |     69.326 |   2.0233 |     58.660 |     0.0
    2 |   1.7753 |     50.275 |   1.5923 |     45.826 |     0.0
    3 |   1.5023 |     46.041 |   1.4464 |     45.763 |     0.1
    4 |   1.4323 |     46.052 |   1.4192 |     45.763 |     0.1
    5 |   1.4115 |     46.080 |   1.4039 |     45.763 |     0.1
    6 |   1.3990 |     45.997 |   1.3976 |     45.763 |     0.1
    7 |   1.3860 |     45.992 |   1.3846 |     45.639 |     0.1
    8 |   1.3727 |     45.953 |   1.3732 |     45.545 |     0.2
    9 |   1.3505 |     45.320 |   1.3467 |     44.050 |     0.2
   10 |   1.3238 |     43.679 |   1.3276 |     43.520 |     0.2
   11 |   1.2989 |     43.228 |   1.3178 |     43.178 |     0.2
   12 |   1.2782 |     42.815 |   1.2934 |     43.271 |     0.3
   13 |   1.2556 |     42.237 |   1.2740 |     42.710 |     0.3
   14 |   1.2389 |     41.625 |   1.2628 |     42.741 |     0.3
   15 |   1.2196 |     41.047 |   1.2601 |     41.371 |     0.3
   16 |   1.2092 |     40.882 |   1.2365 |     41.776 |     0.3
   17 |   1.1917 |     40.464 |   1.2349 |     41.745 |     0.4
   18 |   1.1747 |     39.819 |   1.2244 |     41.558 |     0.4
   19 |   1.1555 |     39.296 |   1.2328 |     42.025 |     0.4
   20 |   1.1405 |     38.680 |   1.2028 |     40.717 |     0.4
   21 |   1.1332 |     38.487 |   1.1974 |     40.717 |     0.4
   22 |   1.1155 |     37.931 |   1.1941 |     40.280 |     0.5
   23 |   1.0960 |     37.501 |   1.2004 |     40.467 |     0.5
   24 |   1.0742 |     36.488 |   1.1893 |     40.685 |     0.5
   25 |   1.0660 |     36.218 |   1.2035 |     40.187 |     0.5
   26 |   1.0514 |     36.158 |   1.1836 |     39.782 |     0.5
   27 |   1.0343 |     35.266 |   1.1711 |     39.283 |     0.6
   28 |   1.0205 |     34.963 |   1.1693 |     39.128 |     0.6
   29 |   1.0006 |     34.424 |   1.1556 |     38.193 |     0.6
   30 |   0.9921 |     34.099 |   1.1529 |     38.879 |     0.6
   31 |   0.9736 |     33.008 |   1.1452 |     38.162 |     0.6
   32 |   0.9722 |     32.948 |   1.1620 |     38.474 |     0.7
   33 |   0.9529 |     32.210 |   1.1626 |     38.318 |     0.7
   34 |   0.9294 |     31.390 |   1.1647 |     38.442 |     0.7
   35 |   0.9269 |     31.538 |   1.1694 |     38.255 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 736,418

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5957 |     69.260 |   2.0399 |     59.159 |     0.0
    2 |   1.7876 |     50.374 |   1.5952 |     45.763 |     0.1
    3 |   1.5153 |     46.041 |   1.4604 |     45.763 |     0.1
    4 |   1.4399 |     46.157 |   1.4211 |     45.763 |     0.1
    5 |   1.4149 |     46.036 |   1.4053 |     45.763 |     0.1
    6 |   1.4030 |     46.036 |   1.3991 |     45.763 |     0.2
    7 |   1.3959 |     46.036 |   1.3904 |     45.763 |     0.2
    8 |   1.3925 |     46.146 |   1.3856 |     45.763 |     0.2
    9 |   1.3843 |     46.036 |   1.3807 |     45.763 |     0.2
   10 |   1.3788 |     46.151 |   1.3787 |     45.763 |     0.3
   11 |   1.3713 |     46.047 |   1.3722 |     45.857 |     0.3
   12 |   1.3638 |     46.151 |   1.3629 |     45.763 |     0.3
   13 |   1.3520 |     45.166 |   1.3490 |     44.860 |     0.3
   14 |   1.3313 |     44.571 |   1.3373 |     44.673 |     0.4
   15 |   1.3205 |     44.323 |   1.3296 |     44.393 |     0.4
   16 |   1.3142 |     44.389 |   1.3353 |     44.829 |     0.4
   17 |   1.3053 |     43.927 |   1.3182 |     44.579 |     0.5
   18 |   1.2965 |     43.910 |   1.3122 |     43.925 |     0.5
   19 |   1.2940 |     43.597 |   1.3106 |     44.330 |     0.5
   20 |   1.2825 |     43.349 |   1.3087 |     44.050 |     0.5
   21 |   1.2705 |     42.793 |   1.3005 |     43.583 |     0.6
   22 |   1.2594 |     42.506 |   1.2889 |     42.555 |     0.6
   23 |   1.2528 |     42.413 |   1.2876 |     43.084 |     0.6
   24 |   1.2350 |     41.702 |   1.2776 |     43.209 |     0.6
   25 |   1.2232 |     41.372 |   1.2593 |     42.399 |     0.7
   26 |   1.2076 |     40.750 |   1.2470 |     41.713 |     0.7
   27 |   1.1957 |     40.337 |   1.2452 |     41.682 |     0.7
   28 |   1.1870 |     39.990 |   1.2397 |     41.402 |     0.7
   29 |   1.1758 |     39.561 |   1.2429 |     41.246 |     0.8
   30 |   1.1689 |     39.247 |   1.2332 |     41.433 |     0.8
   31 |   1.1550 |     39.120 |   1.2125 |     40.530 |     0.8
   32 |   1.1399 |     38.570 |   1.2170 |     40.717 |     0.9
   33 |   1.1353 |     38.658 |   1.2120 |     40.779 |     0.9
   34 |   1.1191 |     38.162 |   1.2176 |     40.592 |     0.9
   35 |   1.1043 |     37.782 |   1.2164 |     40.530 |     0.9
   36 |   1.0922 |     37.171 |   1.1894 |     40.156 |     1.0
   37 |   1.0854 |     37.077 |   1.1932 |     39.844 |     1.0
   38 |   1.0685 |     36.571 |   1.1935 |     39.595 |     1.0
   39 |   1.0575 |     36.554 |   1.1840 |     39.626 |     1.0
   40 |   1.0425 |     35.861 |   1.1826 |     39.408 |     1.1
   41 |   1.0303 |     35.194 |   1.1802 |     39.938 |     1.1
   42 |   1.0199 |     35.101 |   1.1615 |     39.533 |     1.1
   43 |   1.0001 |     34.187 |   1.1787 |     38.972 |     1.1
   44 |   0.9984 |     34.297 |   1.1567 |     39.003 |     1.2
   45 |   0.9753 |     33.322 |   1.1529 |     38.972 |     1.2
   46 |   0.9665 |     32.948 |   1.1486 |     38.162 |     1.2
   47 |   0.9479 |     32.183 |   1.1429 |     37.850 |     1.3
   48 |   0.9429 |     32.111 |   1.1368 |     38.193 |     1.3
   49 |   0.9266 |     31.081 |   1.1408 |     38.037 |     1.3
   50 |   0.9150 |     31.059 |   1.1305 |     36.137 |     1.3
   51 |   0.9119 |     30.779 |   1.1292 |     36.417 |     1.4
   52 |   0.8989 |     30.426 |   1.1389 |     36.854 |     1.4
   53 |   0.8886 |     29.953 |   1.1336 |     36.667 |     1.4
   54 |   0.8768 |     29.622 |   1.1095 |     35.794 |     1.4
   55 |   0.8680 |     29.319 |   1.1366 |     36.293 |     1.5
   56 |   0.8591 |     28.995 |   1.1146 |     35.857 |     1.5
   57 |   0.8327 |     27.739 |   1.1212 |     36.044 |     1.5
   58 |   0.8202 |     27.662 |   1.1506 |     37.414 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 669,986

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1227 |     57.510 |   1.5271 |     45.857 |     0.0
    2 |   1.4185 |     45.325 |   1.3566 |     44.112 |     0.0
    3 |   1.3116 |     42.732 |   1.2889 |     42.274 |     0.1
    4 |   1.2446 |     40.987 |   1.2366 |     40.467 |     0.1
    5 |   1.1822 |     39.142 |   1.1941 |     39.595 |     0.1
    6 |   1.1238 |     37.331 |   1.1450 |     38.006 |     0.1
    7 |   1.0660 |     35.266 |   1.1187 |     37.882 |     0.1
    8 |   1.0102 |     33.515 |   1.0714 |     35.857 |     0.2
    9 |   0.9649 |     31.803 |   1.0474 |     35.234 |     0.2
   10 |   0.9046 |     29.633 |   1.0135 |     33.022 |     0.2
   11 |   0.8591 |     28.136 |   1.0115 |     32.835 |     0.2
   12 |   0.8018 |     25.757 |   0.9721 |     31.620 |     0.2
   13 |   0.7649 |     25.036 |   0.9581 |     30.654 |     0.3
   14 |   0.7185 |     23.577 |   0.9477 |     30.000 |     0.3
   15 |   0.6823 |     21.760 |   0.9303 |     29.346 |     0.3
   16 |   0.6416 |     20.802 |   0.9117 |     28.474 |     0.3
   17 |   0.6073 |     19.172 |   0.9169 |     29.003 |     0.3
   18 |   0.5698 |     18.076 |   0.9087 |     27.975 |     0.4
   19 |   0.5352 |     17.333 |   0.9006 |     27.944 |     0.4
   20 |   0.5148 |     16.336 |   0.9054 |     27.383 |     0.4
   21 |   0.4856 |     15.296 |   0.8972 |     27.664 |     0.4
   22 |   0.4695 |     15.059 |   0.9026 |     27.072 |     0.4
   23 |   0.4346 |     13.903 |   0.8903 |     26.199 |     0.5
   24 |   0.4098 |     12.928 |   0.9093 |     25.265 |     0.5
   25 |   0.3882 |     12.355 |   0.9061 |     26.231 |     0.5
   26 |   0.3803 |     12.036 |   0.9277 |     26.667 |     0.5
   27 |   0.3707 |     12.069 |   0.9194 |     25.732 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 1,158,754

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2871 |     62.311 |   1.6525 |     45.763 |     0.0
    2 |   1.4938 |     46.041 |   1.4217 |     45.763 |     0.0
    3 |   1.4052 |     46.339 |   1.3985 |     45.763 |     0.1
    4 |   1.3720 |     45.865 |   1.3585 |     45.140 |     0.1
    5 |   1.3312 |     45.689 |   1.3228 |     44.517 |     0.1
    6 |   1.2960 |     44.698 |   1.3003 |     44.455 |     0.1
    7 |   1.2611 |     42.853 |   1.2716 |     42.368 |     0.2
    8 |   1.2244 |     42.000 |   1.2337 |     42.181 |     0.2
    9 |   1.1907 |     40.838 |   1.2159 |     41.402 |     0.2
   10 |   1.1620 |     39.682 |   1.2020 |     40.436 |     0.2
   11 |   1.1347 |     38.740 |   1.1884 |     39.097 |     0.3
   12 |   1.1058 |     37.347 |   1.1758 |     39.159 |     0.3
   13 |   1.0867 |     36.753 |   1.1638 |     38.723 |     0.3
   14 |   1.0561 |     35.916 |   1.1474 |     38.287 |     0.3
   15 |   1.0225 |     34.787 |   1.1536 |     38.380 |     0.4
   16 |   1.0082 |     34.231 |   1.1177 |     37.103 |     0.4
   17 |   0.9713 |     33.157 |   1.1190 |     37.072 |     0.4
   18 |   0.9485 |     32.717 |   1.1171 |     36.854 |     0.4
   19 |   0.9245 |     32.094 |   1.0926 |     36.044 |     0.5
   20 |   0.8915 |     30.415 |   1.0958 |     35.826 |     0.5
   21 |   0.8620 |     29.518 |   1.1124 |     36.231 |     0.5
   22 |   0.8538 |     29.303 |   1.1005 |     36.012 |     0.5
   23 |   0.8332 |     28.152 |   1.0887 |     34.829 |     0.6
   24 |   0.8134 |     27.519 |   1.0663 |     34.393 |     0.6
   25 |   0.7776 |     26.577 |   1.0764 |     34.330 |     0.6
   26 |   0.7442 |     25.223 |   1.0609 |     33.271 |     0.6
   27 |   0.7329 |     24.650 |   1.0840 |     33.489 |     0.7
   28 |   0.7130 |     23.835 |   1.0527 |     32.336 |     0.7
   29 |   0.6701 |     22.222 |   1.0558 |     32.368 |     0.7
   30 |   0.6468 |     21.435 |   1.0753 |     32.368 |     0.7
   31 |   0.6243 |     20.857 |   1.0685 |     31.620 |     0.8
   32 |   0.6110 |     20.009 |   1.0525 |     30.374 |     0.8
   33 |   0.5808 |     18.814 |   1.0456 |     31.620 |     0.8
   34 |   0.5627 |     18.296 |   1.0633 |     30.654 |     0.8
   35 |   0.5531 |     18.043 |   1.0856 |     31.246 |     0.9
   36 |   0.5382 |     17.498 |   1.0806 |     30.841 |     0.9
   37 |   0.5209 |     16.672 |   1.0861 |     30.530 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 2,079,266

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1868 |     59.971 |   1.6057 |     45.763 |     0.1
    2 |   1.4646 |     45.887 |   1.3981 |     45.047 |     0.1
    3 |   1.3680 |     44.450 |   1.3470 |     44.424 |     0.2
    4 |   1.3178 |     43.217 |   1.3241 |     43.396 |     0.2
    5 |   1.2886 |     42.556 |   1.2960 |     43.146 |     0.3
    6 |   1.2545 |     41.609 |   1.2674 |     42.336 |     0.4
    7 |   1.2168 |     40.381 |   1.2440 |     41.526 |     0.4
    8 |   1.1750 |     39.115 |   1.2147 |     40.343 |     0.5
    9 |   1.1350 |     37.485 |   1.1891 |     39.377 |     0.5
   10 |   1.0995 |     36.505 |   1.1797 |     38.131 |     0.6
   11 |   1.0637 |     35.558 |   1.1700 |     38.224 |     0.7
   12 |   1.0312 |     34.159 |   1.1438 |     37.383 |     0.7
   13 |   0.9935 |     32.964 |   1.1206 |     37.009 |     0.8
   14 |   0.9539 |     31.522 |   1.1007 |     36.231 |     0.8
   15 |   0.9172 |     30.382 |   1.0838 |     35.327 |     0.9
   16 |   0.8805 |     29.061 |   1.0715 |     35.078 |     1.0
   17 |   0.8514 |     27.943 |   1.0731 |     34.424 |     1.0
   18 |   0.8226 |     27.084 |   1.0644 |     33.988 |     1.1
   19 |   0.7965 |     25.922 |   1.0629 |     34.486 |     1.1
   20 |   0.7688 |     25.344 |   1.0499 |     32.773 |     1.2
   21 |   0.7364 |     24.254 |   1.0443 |     32.617 |     1.3
   22 |   0.7093 |     23.274 |   1.0351 |     32.430 |     1.3
   23 |   0.6843 |     22.244 |   1.0442 |     32.212 |     1.4
   24 |   0.6691 |     21.864 |   1.0250 |     32.056 |     1.4
   25 |   0.6354 |     20.752 |   1.0366 |     32.087 |     1.5
   26 |   0.6098 |     19.970 |   1.0173 |     30.405 |     1.5
   27 |   0.5856 |     19.018 |   1.0289 |     30.872 |     1.6
   28 |   0.5613 |     18.577 |   1.0514 |     31.340 |     1.7
   29 |   0.5463 |     17.614 |   1.0524 |     31.246 |     1.7
   30 |   0.5173 |     16.975 |   1.0546 |     31.090 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 349,986

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4835 |     66.325 |   1.9265 |     56.729 |     0.0
    2 |   1.7031 |     48.816 |   1.5404 |     45.389 |     0.0
    3 |   1.4545 |     44.533 |   1.4021 |     44.548 |     0.1
    4 |   1.3578 |     43.244 |   1.3445 |     43.271 |     0.1
    5 |   1.3045 |     41.796 |   1.3040 |     42.741 |     0.1
    6 |   1.2570 |     40.695 |   1.2825 |     41.651 |     0.1
    7 |   1.2165 |     39.379 |   1.2478 |     40.000 |     0.1
    8 |   1.1752 |     37.942 |   1.2290 |     39.252 |     0.2
    9 |   1.1329 |     36.400 |   1.2031 |     38.879 |     0.2
   10 |   1.0946 |     35.431 |   1.1934 |     38.660 |     0.2
   11 |   1.0559 |     34.110 |   1.1478 |     37.664 |     0.2
   12 |   1.0182 |     33.019 |   1.1411 |     38.006 |     0.3
   13 |   0.9857 |     31.869 |   1.1201 |     37.259 |     0.3
   14 |   0.9523 |     30.894 |   1.1081 |     36.449 |     0.3
   15 |   0.9206 |     29.600 |   1.0950 |     35.016 |     0.3
   16 |   0.8873 |     28.295 |   1.0818 |     35.140 |     0.3
   17 |   0.8558 |     27.376 |   1.0896 |     35.421 |     0.4
   18 |   0.8319 |     26.478 |   1.0613 |     33.676 |     0.4
   19 |   0.7992 |     25.399 |   1.0610 |     33.769 |     0.4
   20 |   0.7686 |     24.408 |   1.0708 |     33.614 |     0.4
   21 |   0.7507 |     23.797 |   1.0619 |     32.866 |     0.4
   22 |   0.7292 |     23.114 |   1.0397 |     31.963 |     0.5
   23 |   0.6942 |     21.919 |   1.0465 |     32.928 |     0.5
   24 |   0.6674 |     21.016 |   1.0568 |     32.710 |     0.5
   25 |   0.6436 |     20.075 |   1.0790 |     33.115 |     0.5
   26 |   0.6347 |     19.981 |   1.0621 |     31.869 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 2,142,882

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2475 |     61.309 |   1.6284 |     45.950 |     0.1
    2 |   1.4927 |     46.140 |   1.4240 |     45.763 |     0.1
    3 |   1.4130 |     46.091 |   1.3996 |     46.791 |     0.2
    4 |   1.3979 |     46.129 |   1.3951 |     45.763 |     0.2
    5 |   1.3873 |     45.964 |   1.3709 |     45.763 |     0.3
    6 |   1.3595 |     44.901 |   1.3498 |     44.829 |     0.4
    7 |   1.3348 |     44.725 |   1.3419 |     44.798 |     0.4
    8 |   1.3204 |     44.411 |   1.3266 |     44.704 |     0.5
    9 |   1.3071 |     43.888 |   1.3244 |     44.112 |     0.5
   10 |   1.2899 |     43.316 |   1.3004 |     43.676 |     0.6
   11 |   1.2673 |     42.479 |   1.2764 |     42.305 |     0.7
   12 |   1.2547 |     42.055 |   1.2802 |     42.586 |     0.7
   13 |   1.2378 |     41.609 |   1.2680 |     42.430 |     0.8
   14 |   1.2195 |     40.965 |   1.2603 |     42.243 |     0.8
   15 |   1.1990 |     40.453 |   1.2493 |     41.246 |     0.9
   16 |   1.1867 |     40.376 |   1.2372 |     41.090 |     1.0
   17 |   1.1670 |     39.500 |   1.2257 |     41.059 |     1.0
   18 |   1.1467 |     38.762 |   1.2159 |     40.280 |     1.1
   19 |   1.1354 |     37.953 |   1.2155 |     40.903 |     1.2
   20 |   1.1159 |     37.645 |   1.1843 |     39.720 |     1.2
   21 |   1.1020 |     37.127 |   1.1980 |     39.221 |     1.3
   22 |   1.0767 |     35.910 |   1.1847 |     39.502 |     1.3
   23 |   1.0603 |     35.453 |   1.1661 |     39.439 |     1.4
   24 |   1.0549 |     35.327 |   1.1713 |     38.505 |     1.5
   25 |   1.0359 |     34.892 |   1.1260 |     37.196 |     1.5
   26 |   1.0141 |     33.713 |   1.1505 |     36.916 |     1.6
   27 |   0.9993 |     33.053 |   1.1294 |     36.978 |     1.6
   28 |   0.9746 |     32.469 |   1.1111 |     36.168 |     1.7
   29 |   0.9515 |     32.144 |   1.0964 |     36.386 |     1.8
   30 |   0.9674 |     32.513 |   1.1215 |     37.290 |     1.8
   31 |   0.9393 |     31.962 |   1.1008 |     36.573 |     1.9
   32 |   0.9172 |     30.867 |   1.0738 |     36.293 |     1.9
   33 |   0.9024 |     30.432 |   1.0569 |     34.735 |     2.0
   34 |   0.8864 |     29.870 |   1.0585 |     34.735 |     2.1
   35 |   0.8634 |     29.253 |   1.0485 |     34.642 |     2.1
   36 |   0.8474 |     28.769 |   1.0604 |     34.486 |     2.2
   37 |   0.8363 |     28.290 |   1.0399 |     33.458 |     2.3
   38 |   0.8193 |     27.299 |   1.0284 |     33.676 |     2.3
   39 |   0.8096 |     26.886 |   1.0337 |     34.112 |     2.4
   40 |   0.8715 |     29.264 |   1.0417 |     34.611 |     2.4
   41 |   0.8097 |     27.156 |   1.0181 |     33.583 |     2.5
   42 |   0.7777 |     26.043 |   1.0183 |     33.707 |     2.6
   43 |   0.7713 |     25.933 |   1.0174 |     33.146 |     2.6
   44 |   0.7680 |     25.757 |   1.0344 |     33.583 |     2.7
   45 |   0.7486 |     25.262 |   1.0204 |     32.056 |     2.7
   46 |   0.7332 |     24.370 |   1.0235 |     32.368 |     2.8
   47 |   0.7226 |     24.315 |   1.0496 |     33.209 |     2.9
   48 |   0.7072 |     23.742 |   1.0164 |     32.399 |     2.9
   49 |   0.6838 |     22.949 |   1.0280 |     32.492 |     3.0
   50 |   0.6923 |     23.378 |   1.0178 |     32.835 |     3.0
   51 |   0.6923 |     23.401 |   1.0207 |     31.838 |     3.1
   52 |   0.6852 |     23.406 |   1.0145 |     31.558 |     3.2
   53 |   0.6659 |     22.575 |   1.0116 |     32.087 |     3.2
   54 |   0.6518 |     22.145 |   1.0401 |     33.520 |     3.3
   55 |   0.6488 |     21.958 |   1.0336 |     32.492 |     3.4
   56 |   0.6449 |     21.826 |   1.0377 |     32.336 |     3.4
   57 |   0.6624 |     22.349 |   1.0192 |     31.745 |     3.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 801,314

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2612 |     61.381 |   1.6173 |     48.785 |     0.0
    2 |   1.4751 |     46.239 |   1.4068 |     45.763 |     0.0
    3 |   1.3789 |     45.992 |   1.3724 |     45.483 |     0.1
    4 |   1.3438 |     45.265 |   1.3370 |     45.202 |     0.1
    5 |   1.3110 |     44.736 |   1.3033 |     44.237 |     0.1
    6 |   1.2756 |     43.503 |   1.2704 |     42.274 |     0.1
    7 |   1.2294 |     41.526 |   1.2364 |     41.776 |     0.1
    8 |   1.1931 |     40.216 |   1.2014 |     40.997 |     0.1
    9 |   1.1540 |     39.098 |   1.1913 |     39.688 |     0.2
   10 |   1.1191 |     37.810 |   1.1607 |     39.377 |     0.2
   11 |   1.0904 |     36.868 |   1.1287 |     38.474 |     0.2
   12 |   1.0470 |     35.475 |   1.1203 |     37.819 |     0.2
   13 |   1.0356 |     35.415 |   1.0960 |     37.196 |     0.2
   14 |   0.9888 |     34.093 |   1.0690 |     35.857 |     0.3
   15 |   0.9518 |     32.590 |   1.0638 |     35.202 |     0.3
   16 |   0.9167 |     31.252 |   1.0355 |     34.330 |     0.3
   17 |   0.8728 |     29.628 |   1.0117 |     33.115 |     0.3
   18 |   0.8455 |     28.505 |   0.9947 |     32.336 |     0.3
   19 |   0.8157 |     27.392 |   0.9942 |     32.087 |     0.4
   20 |   0.7776 |     25.977 |   0.9709 |     31.090 |     0.4
   21 |   0.7529 |     24.937 |   0.9742 |     30.343 |     0.4
   22 |   0.7257 |     24.155 |   0.9654 |     30.249 |     0.4
   23 |   0.6932 |     22.833 |   0.9734 |     30.343 |     0.4
   24 |   0.6745 |     22.162 |   0.9574 |     29.969 |     0.4
   25 |   0.6482 |     21.446 |   0.9430 |     29.065 |     0.5
   26 |   0.6187 |     20.069 |   0.9620 |     28.629 |     0.5
   27 |   0.6014 |     19.458 |   0.9637 |     28.629 |     0.5
   28 |   0.5776 |     18.820 |   0.9524 |     27.726 |     0.5
   29 |   0.5532 |     18.219 |   0.9627 |     27.975 |     0.5
   30 |   0.5348 |     17.239 |   0.9273 |     27.009 |     0.6
   31 |   0.5128 |     16.408 |   0.9447 |     26.573 |     0.6
   32 |   0.5027 |     16.408 |   0.9500 |     26.791 |     0.6
   33 |   0.4887 |     15.846 |   0.9544 |     27.165 |     0.6
   34 |   0.4697 |     15.191 |   0.9432 |     26.480 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 2,143,586

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2498 |     61.777 |   1.6337 |     48.785 |     0.1
    2 |   1.4934 |     46.272 |   1.4278 |     45.763 |     0.1
    3 |   1.4147 |     46.151 |   1.4005 |     45.763 |     0.2
    4 |   1.3979 |     46.157 |   1.3915 |     46.791 |     0.2
    5 |   1.3912 |     46.124 |   1.3838 |     45.545 |     0.3
    6 |   1.3659 |     44.995 |   1.3564 |     44.798 |     0.4
    7 |   1.3388 |     44.301 |   1.3390 |     44.019 |     0.4
    8 |   1.3246 |     44.020 |   1.3345 |     44.206 |     0.5
    9 |   1.3118 |     43.861 |   1.3174 |     43.489 |     0.6
   10 |   1.3016 |     43.310 |   1.3130 |     43.458 |     0.6
   11 |   1.2897 |     43.404 |   1.3100 |     44.112 |     0.7
   12 |   1.2748 |     42.517 |   1.2970 |     42.991 |     0.7
   13 |   1.2614 |     42.506 |   1.2780 |     42.866 |     0.8
   14 |   1.2499 |     42.181 |   1.2679 |     42.741 |     0.9
   15 |   1.2394 |     42.121 |   1.2636 |     42.648 |     0.9
   16 |   1.2275 |     41.411 |   1.2655 |     42.461 |     1.0
   17 |   1.2179 |     41.113 |   1.2652 |     42.368 |     1.1
   18 |   1.2011 |     40.342 |   1.2549 |     41.433 |     1.1
   19 |   1.1937 |     40.326 |   1.2468 |     40.810 |     1.2
   20 |   1.1797 |     39.528 |   1.2317 |     40.810 |     1.2
   21 |   1.1594 |     39.104 |   1.2201 |     40.654 |     1.3
   22 |   1.1427 |     38.548 |   1.2111 |     40.249 |     1.4
   23 |   1.1271 |     38.212 |   1.2060 |     39.844 |     1.4
   24 |   1.1068 |     37.430 |   1.1881 |     39.408 |     1.5
   25 |   1.0956 |     37.358 |   1.1862 |     39.221 |     1.6
   26 |   1.0782 |     36.538 |   1.1806 |     39.875 |     1.6
   27 |   1.0640 |     36.290 |   1.1918 |     39.813 |     1.7
   28 |   1.0502 |     35.646 |   1.1567 |     38.598 |     1.7
   29 |   1.0341 |     34.875 |   1.1590 |     38.442 |     1.8
   30 |   1.0224 |     34.633 |   1.1449 |     37.695 |     1.9
   31 |   1.0029 |     33.818 |   1.1439 |     38.255 |     1.9
   32 |   0.9801 |     33.234 |   1.1328 |     38.100 |     2.0
   33 |   0.9670 |     32.783 |   1.1179 |     36.480 |     2.1
   34 |   0.9527 |     32.524 |   1.1270 |     37.290 |     2.1
   35 |   0.9311 |     31.726 |   1.1104 |     36.262 |     2.2
   36 |   0.9115 |     30.856 |   1.1195 |     36.729 |     2.3
   37 |   0.9000 |     30.652 |   1.1029 |     36.137 |     2.3
   38 |   0.8803 |     29.776 |   1.0982 |     35.919 |     2.4
   39 |   0.8658 |     29.226 |   1.0955 |     35.701 |     2.4
   40 |   0.8486 |     28.962 |   1.0942 |     35.514 |     2.5
   41 |   0.8302 |     28.262 |   1.1025 |     35.576 |     2.6
   42 |   0.8233 |     27.833 |   1.0868 |     35.202 |     2.6
   43 |   0.8053 |     27.304 |   1.0810 |     34.642 |     2.7
   44 |   0.7800 |     26.225 |   1.0946 |     34.579 |     2.8
   45 |   0.7666 |     26.176 |   1.0666 |     34.174 |     2.8
   46 |   0.7610 |     25.840 |   1.0751 |     34.237 |     2.9
   47 |   0.7612 |     25.801 |   1.0954 |     35.140 |     3.0
   48 |   0.7590 |     25.652 |   1.0843 |     34.174 |     3.0
   49 |   0.7282 |     24.920 |   1.0675 |     33.645 |     3.1
   50 |   0.7044 |     24.028 |   1.0615 |     33.645 |     3.1
   51 |   0.6957 |     23.301 |   1.0843 |     34.081 |     3.2
   52 |   0.6828 |     23.489 |   1.0632 |     32.586 |     3.3
   53 |   0.6582 |     22.409 |   1.0679 |     33.115 |     3.3
   54 |   0.6468 |     21.875 |   1.0705 |     32.866 |     3.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 649,570

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5563 |     67.636 |   2.0280 |     59.159 |     0.0
    2 |   1.7932 |     51.195 |   1.5983 |     45.763 |     0.1
    3 |   1.5149 |     46.036 |   1.4577 |     45.763 |     0.1
    4 |   1.4407 |     46.058 |   1.4211 |     45.732 |     0.1
    5 |   1.4101 |     46.052 |   1.3963 |     45.763 |     0.1
    6 |   1.3903 |     46.041 |   1.3872 |     46.854 |     0.2
    7 |   1.3757 |     46.107 |   1.3696 |     45.421 |     0.2
    8 |   1.3539 |     44.626 |   1.3489 |     44.829 |     0.2
    9 |   1.3298 |     44.120 |   1.3359 |     43.988 |     0.2
   10 |   1.3112 |     43.932 |   1.3134 |     43.520 |     0.3
   11 |   1.2918 |     43.283 |   1.3054 |     43.084 |     0.3
   12 |   1.2749 |     42.980 |   1.2708 |     42.243 |     0.3
   13 |   1.2501 |     42.556 |   1.2538 |     41.963 |     0.3
   14 |   1.2280 |     41.653 |   1.2409 |     41.745 |     0.4
   15 |   1.2081 |     41.058 |   1.2235 |     40.748 |     0.4
   16 |   1.1852 |     39.990 |   1.2132 |     40.903 |     0.4
   17 |   1.1673 |     39.852 |   1.1927 |     39.533 |     0.4
   18 |   1.1406 |     38.581 |   1.1781 |     40.218 |     0.5
   19 |   1.1227 |     38.316 |   1.1723 |     39.813 |     0.5
   20 |   1.1034 |     37.606 |   1.1707 |     39.252 |     0.5
   21 |   1.0872 |     37.017 |   1.1664 |     39.626 |     0.5
   22 |   1.0731 |     36.664 |   1.1805 |     39.346 |     0.6
   23 |   1.0619 |     36.119 |   1.1559 |     38.816 |     0.6
   24 |   1.0363 |     35.360 |   1.1434 |     38.006 |     0.6
   25 |   1.0187 |     34.561 |   1.1255 |     38.318 |     0.6
   26 |   1.0062 |     34.082 |   1.1161 |     36.947 |     0.7
   27 |   0.9918 |     33.421 |   1.1104 |     37.072 |     0.7
   28 |   0.9759 |     32.860 |   1.0900 |     36.106 |     0.7
   29 |   0.9584 |     32.216 |   1.0871 |     36.417 |     0.7
   30 |   0.9348 |     31.494 |   1.0910 |     36.636 |     0.8
   31 |   0.9161 |     30.718 |   1.0890 |     36.542 |     0.8
   32 |   0.9043 |     30.377 |   1.0763 |     35.545 |     0.8
   33 |   0.8902 |     29.798 |   1.0551 |     34.891 |     0.8
   34 |   0.8742 |     29.231 |   1.0829 |     34.704 |     0.9
   35 |   0.8582 |     28.929 |   1.0479 |     34.237 |     0.9
   36 |   0.8419 |     27.937 |   1.0481 |     33.801 |     0.9
   37 |   0.8239 |     27.244 |   1.0331 |     33.271 |     0.9
   38 |   0.8118 |     27.056 |   1.0316 |     33.551 |     1.0
   39 |   0.7946 |     26.330 |   1.0236 |     33.832 |     1.0
   40 |   0.7792 |     25.663 |   1.0430 |     32.866 |     1.0
   41 |   0.7675 |     25.146 |   1.0318 |     32.773 |     1.0
   42 |   0.7579 |     25.047 |   1.0200 |     32.555 |     1.1
   43 |   0.7543 |     25.030 |   1.0369 |     33.146 |     1.1
   44 |   0.7414 |     24.315 |   1.0223 |     32.305 |     1.1
   45 |   0.7231 |     23.681 |   1.0084 |     31.651 |     1.2
   46 |   0.7046 |     23.439 |   0.9987 |     31.776 |     1.2
   47 |   0.6900 |     22.564 |   0.9956 |     31.776 |     1.2
   48 |   0.6792 |     22.470 |   1.0142 |     30.966 |     1.2
   49 |   0.6657 |     21.617 |   0.9933 |     31.433 |     1.3
   50 |   0.6679 |     21.820 |   1.0197 |     31.184 |     1.3
   51 |   0.6589 |     21.853 |   1.0075 |     31.215 |     1.3
   52 |   0.6394 |     21.171 |   1.0129 |     31.215 |     1.3
   53 |   0.6384 |     21.138 |   1.0058 |     30.685 |     1.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,797,282

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5474 |     68.049 |   2.0477 |     56.604 |     0.1
    2 |   1.7965 |     50.908 |   1.5972 |     45.763 |     0.1
    3 |   1.5130 |     46.135 |   1.4586 |     45.763 |     0.2
    4 |   1.4375 |     46.041 |   1.4189 |     45.763 |     0.2
    5 |   1.4084 |     46.151 |   1.4032 |     45.763 |     0.3
    6 |   1.3916 |     46.080 |   1.3881 |     45.763 |     0.3
    7 |   1.3691 |     45.524 |   1.3630 |     44.735 |     0.4
    8 |   1.3460 |     44.544 |   1.3437 |     44.361 |     0.5
    9 |   1.3208 |     43.954 |   1.3252 |     43.925 |     0.5
   10 |   1.2964 |     43.382 |   1.3193 |     43.707 |     0.6
   11 |   1.2704 |     42.462 |   1.2800 |     43.209 |     0.6
   12 |   1.2409 |     41.669 |   1.2732 |     42.399 |     0.7
   13 |   1.2288 |     40.992 |   1.2493 |     41.869 |     0.8
   14 |   1.2179 |     40.932 |   1.2499 |     41.838 |     0.8
   15 |   1.1957 |     40.122 |   1.2385 |     41.308 |     0.9
   16 |   1.1868 |     39.753 |   1.2378 |     41.931 |     0.9
   17 |   1.1780 |     39.753 |   1.2112 |     41.028 |     1.0
   18 |   1.1540 |     39.087 |   1.2090 |     40.374 |     1.0
   19 |   1.1407 |     38.625 |   1.2143 |     40.312 |     1.1
   20 |   1.1215 |     37.898 |   1.1809 |     39.346 |     1.2
   21 |   1.1039 |     37.441 |   1.1725 |     38.754 |     1.2
   22 |   1.0905 |     36.929 |   1.1838 |     40.062 |     1.3
   23 |   1.0829 |     36.576 |   1.1559 |     38.598 |     1.3
   24 |   1.0594 |     35.558 |   1.1557 |     37.726 |     1.4
   25 |   1.0412 |     34.980 |   1.1647 |     38.567 |     1.4
   26 |   1.0308 |     34.600 |   1.1423 |     38.162 |     1.5
   27 |   1.0208 |     34.330 |   1.1290 |     37.726 |     1.6
   28 |   1.0102 |     33.840 |   1.1177 |     37.103 |     1.6
   29 |   0.9917 |     33.410 |   1.1022 |     36.417 |     1.7
   30 |   0.9766 |     32.706 |   1.1070 |     36.604 |     1.7
   31 |   0.9584 |     32.105 |   1.0981 |     36.573 |     1.8
   32 |   0.9588 |     31.759 |   1.1247 |     37.321 |     1.8
   33 |   0.9646 |     32.276 |   1.0917 |     34.829 |     1.9
   34 |   0.9369 |     30.938 |   1.0920 |     35.607 |     2.0
   35 |   0.9222 |     30.476 |   1.0690 |     35.358 |     2.0
   36 |   0.9008 |     29.809 |   1.0787 |     35.389 |     2.1
   37 |   0.8928 |     29.375 |   1.0799 |     34.673 |     2.1
   38 |   0.8833 |     29.149 |   1.0653 |     34.579 |     2.2
   39 |   0.8729 |     29.220 |   1.0725 |     34.361 |     2.2
   40 |   0.8607 |     28.488 |   1.0653 |     34.361 |     2.3
   41 |   0.8441 |     27.629 |   1.0683 |     34.050 |     2.4
   42 |   0.8543 |     28.257 |   1.0861 |     34.579 |     2.4
   43 |   0.8340 |     27.772 |   1.0532 |     33.427 |     2.5
   44 |   0.8043 |     26.473 |   1.0517 |     33.489 |     2.5
   45 |   0.8003 |     26.258 |   1.0526 |     33.551 |     2.6
   46 |   0.7983 |     26.473 |   1.0422 |     33.084 |     2.6
   47 |   0.7644 |     24.810 |   1.0303 |     32.368 |     2.7
   48 |   0.7547 |     24.871 |   1.0385 |     32.617 |     2.8
   49 |   0.7534 |     24.937 |   1.0353 |     32.336 |     2.8
   50 |   0.7326 |     24.039 |   1.0049 |     31.090 |     2.9
   51 |   0.7221 |     23.659 |   1.0367 |     32.025 |     2.9
   52 |   0.7057 |     22.855 |   1.0273 |     32.648 |     3.0
   53 |   0.6909 |     22.442 |   1.0311 |     30.903 |     3.0
   54 |   0.6837 |     22.349 |   1.0332 |     31.838 |     3.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 914,850

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4514 |     66.441 |   1.9353 |     51.308 |     0.0
    2 |   1.7187 |     48.915 |   1.5527 |     45.763 |     0.1
    3 |   1.4800 |     46.014 |   1.4330 |     45.763 |     0.1
    4 |   1.4092 |     45.804 |   1.3885 |     44.953 |     0.1
    5 |   1.3641 |     44.549 |   1.3529 |     44.299 |     0.2
    6 |   1.3256 |     43.602 |   1.3199 |     43.801 |     0.2
    7 |   1.2935 |     42.881 |   1.2950 |     43.022 |     0.3
    8 |   1.2637 |     41.763 |   1.2717 |     42.243 |     0.3
    9 |   1.2352 |     40.717 |   1.2496 |     41.713 |     0.3
   10 |   1.2041 |     39.627 |   1.2331 |     41.402 |     0.4
   11 |   1.1791 |     38.757 |   1.2112 |     40.000 |     0.4
   12 |   1.1475 |     38.030 |   1.1882 |     40.031 |     0.4
   13 |   1.1183 |     37.116 |   1.1686 |     38.879 |     0.5
   14 |   1.0894 |     36.103 |   1.1605 |     38.816 |     0.5
   15 |   1.0650 |     35.222 |   1.1426 |     37.570 |     0.6
   16 |   1.0316 |     33.801 |   1.1170 |     37.383 |     0.6
   17 |   1.0001 |     32.821 |   1.1047 |     36.729 |     0.6
   18 |   0.9778 |     31.913 |   1.0843 |     35.888 |     0.7
   19 |   0.9460 |     30.982 |   1.0686 |     34.953 |     0.7
   20 |   0.9293 |     30.101 |   1.0778 |     35.826 |     0.7
   21 |   0.9130 |     29.958 |   1.0612 |     34.735 |     0.8
   22 |   0.8816 |     28.301 |   1.0464 |     34.019 |     0.8
   23 |   0.8517 |     27.629 |   1.0348 |     33.146 |     0.9
   24 |   0.8211 |     26.451 |   1.0342 |     33.302 |     0.9
   25 |   0.8063 |     26.038 |   1.0234 |     33.676 |     0.9
   26 |   0.7937 |     25.790 |   1.0004 |     31.776 |     1.0
   27 |   0.7639 |     24.843 |   1.0222 |     32.087 |     1.0
   28 |   0.7503 |     24.469 |   1.0071 |     32.243 |     1.0
   29 |   0.7318 |     23.813 |   0.9905 |     31.371 |     1.1
   30 |   0.7114 |     22.855 |   1.0063 |     32.118 |     1.1
   31 |   0.6923 |     22.442 |   1.0051 |     31.620 |     1.1
   32 |   0.6797 |     21.936 |   0.9853 |     31.402 |     1.2
   33 |   0.6579 |     21.396 |   0.9876 |     30.062 |     1.2
   34 |   0.6436 |     20.697 |   0.9978 |     31.464 |     1.3
   35 |   0.6277 |     20.372 |   0.9883 |     30.592 |     1.3
   36 |   0.6158 |     19.590 |   0.9895 |     29.938 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 917,858

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5802 |     69.133 |   2.0174 |     59.159 |     0.0
    2 |   1.7918 |     50.435 |   1.6008 |     45.763 |     0.1
    3 |   1.5217 |     46.003 |   1.4791 |     47.009 |     0.1
    4 |   1.4441 |     46.173 |   1.4234 |     45.763 |     0.1
    5 |   1.4190 |     46.069 |   1.4098 |     45.763 |     0.2
    6 |   1.4074 |     46.228 |   1.4003 |     45.763 |     0.2
    7 |   1.3994 |     46.267 |   1.3990 |     46.760 |     0.2
    8 |   1.3929 |     46.212 |   1.3976 |     45.857 |     0.3
    9 |   1.3873 |     46.173 |   1.3840 |     45.763 |     0.3
   10 |   1.3797 |     46.157 |   1.3764 |     45.763 |     0.3
   11 |   1.3708 |     46.146 |   1.3753 |     45.732 |     0.4
   12 |   1.3593 |     45.837 |   1.3559 |     44.704 |     0.4
   13 |   1.3430 |     44.797 |   1.3443 |     44.393 |     0.4
   14 |   1.3288 |     44.450 |   1.3377 |     44.953 |     0.5
   15 |   1.3225 |     44.461 |   1.3290 |     44.735 |     0.5
   16 |   1.3104 |     44.186 |   1.3199 |     44.424 |     0.6
   17 |   1.3058 |     44.290 |   1.3179 |     44.206 |     0.6
   18 |   1.2914 |     43.806 |   1.3068 |     44.579 |     0.6
   19 |   1.2849 |     43.701 |   1.3036 |     43.738 |     0.7
   20 |   1.2765 |     43.371 |   1.3060 |     43.364 |     0.7
   21 |   1.2725 |     43.040 |   1.2973 |     43.333 |     0.7
   22 |   1.2620 |     42.903 |   1.2885 |     43.209 |     0.8
   23 |   1.2549 |     42.534 |   1.3105 |     43.178 |     0.8
   24 |   1.2453 |     42.187 |   1.2828 |     43.146 |     0.8
   25 |   1.2370 |     41.983 |   1.2741 |     42.492 |     0.9
   26 |   1.2320 |     41.785 |   1.2786 |     43.115 |     0.9
   27 |   1.2271 |     41.752 |   1.2685 |     42.399 |     0.9
   28 |   1.2155 |     41.301 |   1.2614 |     42.773 |     1.0
   29 |   1.2137 |     41.488 |   1.2604 |     42.710 |     1.0
   30 |   1.2038 |     41.102 |   1.2591 |     42.305 |     1.0
   31 |   1.1976 |     41.130 |   1.2608 |     41.838 |     1.1
   32 |   1.2058 |     41.168 |   1.2570 |     41.807 |     1.1
   33 |   1.1870 |     40.860 |   1.2487 |     41.495 |     1.1
   34 |   1.1781 |     40.618 |   1.2603 |     42.523 |     1.2
   35 |   1.1793 |     40.392 |   1.2450 |     41.589 |     1.2
   36 |   1.1564 |     39.495 |   1.2343 |     41.495 |     1.2
   37 |   1.1556 |     39.395 |   1.2269 |     41.028 |     1.3
   38 |   1.1410 |     39.005 |   1.2323 |     41.402 |     1.3
   39 |   1.1323 |     38.355 |   1.2268 |     41.184 |     1.3
   40 |   1.1334 |     38.691 |   1.2309 |     40.997 |     1.4
   41 |   1.1282 |     38.245 |   1.2291 |     41.433 |     1.4
   42 |   1.1270 |     38.432 |   1.2261 |     40.717 |     1.4
   43 |   1.1136 |     38.013 |   1.2195 |     40.343 |     1.5
   44 |   1.1093 |     37.876 |   1.2049 |     40.436 |     1.5
   45 |   1.1015 |     37.507 |   1.1967 |     40.218 |     1.5
   46 |   1.0883 |     37.072 |   1.2104 |     40.187 |     1.6
   47 |   1.0840 |     37.028 |   1.2080 |     40.561 |     1.6
   48 |   1.0729 |     36.461 |   1.2116 |     40.685 |     1.6
   49 |   1.0656 |     36.521 |   1.1939 |     40.249 |     1.7
   50 |   1.0653 |     36.554 |   1.1843 |     39.720 |     1.7
   51 |   1.0559 |     35.993 |   1.1875 |     39.533 |     1.7
   52 |   1.0436 |     35.536 |   1.1897 |     39.751 |     1.8
   53 |   1.0289 |     35.101 |   1.1829 |     39.159 |     1.8
   54 |   1.0359 |     35.167 |   1.1880 |     38.785 |     1.8
   55 |   1.0205 |     34.418 |   1.1837 |     38.567 |     1.9
   56 |   1.0277 |     34.836 |   1.1882 |     39.252 |     1.9
   57 |   1.0258 |     34.836 |   1.1955 |     38.972 |     2.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,158,434

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4766 |     65.279 |   1.9846 |     54.798 |     0.0
    2 |   1.7484 |     50.072 |   1.5611 |     45.763 |     0.1
    3 |   1.4971 |     46.096 |   1.4479 |     45.763 |     0.1
    4 |   1.4254 |     45.826 |   1.4055 |     45.078 |     0.2
    5 |   1.3842 |     44.940 |   1.3711 |     44.548 |     0.2
    6 |   1.3518 |     44.175 |   1.3494 |     44.424 |     0.2
    7 |   1.3298 |     43.657 |   1.3327 |     43.520 |     0.3
    8 |   1.3077 |     43.173 |   1.3147 |     43.489 |     0.3
    9 |   1.2904 |     42.749 |   1.3083 |     43.427 |     0.4
   10 |   1.2748 |     42.391 |   1.2930 |     42.835 |     0.4
   11 |   1.2563 |     41.873 |   1.2780 |     42.586 |     0.5
   12 |   1.2320 |     40.849 |   1.2497 |     41.153 |     0.5
   13 |   1.2077 |     39.869 |   1.2413 |     40.467 |     0.5
   14 |   1.1806 |     38.955 |   1.2219 |     40.000 |     0.6
   15 |   1.1545 |     38.113 |   1.2064 |     39.969 |     0.6
   16 |   1.1353 |     37.490 |   1.1864 |     38.972 |     0.7
   17 |   1.1176 |     36.918 |   1.1780 |     38.660 |     0.7
   18 |   1.0872 |     35.883 |   1.1666 |     39.408 |     0.8
   19 |   1.0622 |     34.704 |   1.1494 |     37.165 |     0.8
   20 |   1.0454 |     34.346 |   1.1356 |     37.695 |     0.8
   21 |   1.0263 |     33.443 |   1.1336 |     37.477 |     0.9
   22 |   1.0000 |     32.662 |   1.1212 |     37.040 |     0.9
   23 |   0.9858 |     32.061 |   1.1200 |     36.542 |     1.0
   24 |   0.9598 |     31.285 |   1.1075 |     35.452 |     1.0
   25 |   0.9382 |     30.668 |   1.0879 |     35.109 |     1.0
   26 |   0.9531 |     31.169 |   1.1053 |     36.449 |     1.1
   27 |   0.9344 |     30.344 |   1.0859 |     34.642 |     1.1
   28 |   0.9082 |     29.540 |   1.0824 |     35.576 |     1.2
   29 |   0.9019 |     29.556 |   1.0611 |     33.988 |     1.2
   30 |   0.8633 |     28.152 |   1.0648 |     34.704 |     1.3
   31 |   0.8490 |     27.618 |   1.0642 |     34.237 |     1.3
   32 |   0.8268 |     27.095 |   1.0652 |     34.081 |     1.3
   33 |   0.8073 |     26.159 |   1.0463 |     34.393 |     1.4
   34 |   0.7971 |     25.845 |   1.0468 |     33.364 |     1.4
   35 |   0.7917 |     25.476 |   1.0503 |     33.240 |     1.5
   36 |   0.7758 |     25.129 |   1.0460 |     33.022 |     1.5
   37 |   0.7522 |     24.204 |   1.0179 |     31.900 |     1.5
   38 |   0.7352 |     23.698 |   1.0268 |     32.368 |     1.6
   39 |   0.7280 |     23.709 |   1.0351 |     32.492 |     1.6
   40 |   0.7120 |     22.751 |   1.0139 |     32.555 |     1.7
   41 |   0.7002 |     22.520 |   1.0216 |     31.838 |     1.7
   42 |   0.6921 |     22.487 |   1.0244 |     31.651 |     1.8
   43 |   0.6745 |     21.875 |   1.0260 |     30.966 |     1.8
   44 |   0.6656 |     21.418 |   1.0337 |     32.430 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 411,106

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6051 |     69.464 |   2.0476 |     57.259 |     0.0
    2 |   1.8189 |     51.074 |   1.6273 |     45.763 |     0.0
    3 |   1.5420 |     46.085 |   1.4719 |     45.763 |     0.1
    4 |   1.4461 |     45.997 |   1.4215 |     45.763 |     0.1
    5 |   1.4027 |     45.799 |   1.3877 |     45.545 |     0.1
    6 |   1.3606 |     45.050 |   1.3559 |     44.361 |     0.1
    7 |   1.3319 |     44.472 |   1.3202 |     44.361 |     0.2
    8 |   1.3011 |     43.778 |   1.2971 |     44.486 |     0.2
    9 |   1.2740 |     43.327 |   1.2830 |     43.396 |     0.2
   10 |   1.2466 |     42.831 |   1.2579 |     44.143 |     0.2
   11 |   1.2213 |     41.603 |   1.2338 |     41.931 |     0.2
   12 |   1.1866 |     40.238 |   1.2088 |     41.121 |     0.3
   13 |   1.1573 |     39.577 |   1.1885 |     39.751 |     0.3
   14 |   1.1327 |     38.525 |   1.1831 |     40.125 |     0.3
   15 |   1.1108 |     37.832 |   1.1656 |     39.252 |     0.3
   16 |   1.0873 |     37.011 |   1.1408 |     39.065 |     0.4
   17 |   1.0565 |     36.048 |   1.1397 |     38.505 |     0.4
   18 |   1.0334 |     35.189 |   1.1192 |     37.757 |     0.4
   19 |   1.0115 |     34.022 |   1.1123 |     38.037 |     0.4
   20 |   0.9826 |     33.058 |   1.1041 |     37.445 |     0.4
   21 |   0.9603 |     32.436 |   1.0810 |     35.950 |     0.5
   22 |   0.9346 |     31.346 |   1.0911 |     36.386 |     0.5
   23 |   0.9249 |     31.147 |   1.0854 |     35.545 |     0.5
   24 |   0.9028 |     30.222 |   1.0706 |     34.735 |     0.5
   25 |   0.8840 |     29.589 |   1.0675 |     34.891 |     0.6
   26 |   0.8644 |     28.703 |   1.0655 |     34.361 |     0.6
   27 |   0.8441 |     27.833 |   1.0732 |     34.268 |     0.6
   28 |   0.8254 |     27.112 |   1.0409 |     33.645 |     0.6
   29 |   0.8052 |     26.528 |   1.0459 |     33.115 |     0.6
   30 |   0.7890 |     25.851 |   1.0287 |     32.741 |     0.7
   31 |   0.7717 |     25.278 |   1.0466 |     32.368 |     0.7
   32 |   0.7588 |     24.948 |   1.0492 |     32.118 |     0.7
   33 |   0.7349 |     24.045 |   1.0460 |     31.994 |     0.7
   34 |   0.7215 |     23.604 |   1.0258 |     30.685 |     0.8
   35 |   0.7001 |     22.839 |   1.0169 |     30.841 |     0.8
   36 |   0.6871 |     22.277 |   1.0233 |     30.903 |     0.8
   37 |   0.6774 |     21.606 |   1.0389 |     30.872 |     0.8
   38 |   0.6605 |     21.424 |   1.0302 |     30.187 |     0.8
   39 |   0.6456 |     20.989 |   1.0251 |     30.249 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 2,125,410

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2448 |     61.970 |   1.6665 |     48.785 |     0.1
    2 |   1.5063 |     46.239 |   1.4289 |     45.763 |     0.1
    3 |   1.4134 |     46.184 |   1.4103 |     46.854 |     0.2
    4 |   1.3917 |     45.981 |   1.3850 |     45.109 |     0.2
    5 |   1.3594 |     44.863 |   1.3532 |     44.704 |     0.3
    6 |   1.3354 |     44.362 |   1.3376 |     44.081 |     0.4
    7 |   1.3183 |     44.054 |   1.3308 |     44.517 |     0.4
    8 |   1.3009 |     43.404 |   1.3074 |     43.738 |     0.5
    9 |   1.2873 |     42.903 |   1.3011 |     42.679 |     0.5
   10 |   1.2681 |     42.440 |   1.2897 |     43.364 |     0.6
   11 |   1.2539 |     42.126 |   1.2868 |     42.991 |     0.7
   12 |   1.2382 |     41.383 |   1.2789 |     42.274 |     0.7
   13 |   1.2235 |     41.075 |   1.2642 |     42.461 |     0.8
   14 |   1.2097 |     40.849 |   1.2842 |     41.838 |     0.9
   15 |   1.2028 |     40.519 |   1.2487 |     41.589 |     0.9
   16 |   1.1888 |     40.128 |   1.2404 |     41.776 |     1.0
   17 |   1.1784 |     40.073 |   1.2251 |     40.654 |     1.0
   18 |   1.1566 |     39.005 |   1.2078 |     40.312 |     1.1
   19 |   1.1409 |     38.669 |   1.2031 |     39.969 |     1.2
   20 |   1.1234 |     38.173 |   1.2017 |     39.813 |     1.2
   21 |   1.1127 |     37.898 |   1.1987 |     40.654 |     1.3
   22 |   1.0928 |     37.066 |   1.1799 |     39.065 |     1.3
   23 |   1.0744 |     36.389 |   1.1791 |     38.847 |     1.4
   24 |   1.0701 |     36.213 |   1.1622 |     38.162 |     1.5
   25 |   1.0512 |     35.420 |   1.1514 |     38.224 |     1.5
   26 |   1.0430 |     34.969 |   1.1487 |     37.882 |     1.6
   27 |   1.0273 |     34.446 |   1.1548 |     37.601 |     1.6
   28 |   1.0106 |     34.192 |   1.1445 |     37.321 |     1.7
   29 |   1.0005 |     33.432 |   1.1314 |     36.324 |     1.8
   30 |   0.9913 |     33.449 |   1.1261 |     36.480 |     1.8
   31 |   0.9747 |     32.585 |   1.1194 |     36.012 |     1.9
   32 |   0.9557 |     32.243 |   1.1250 |     36.760 |     1.9
   33 |   0.9550 |     32.221 |   1.1188 |     36.262 |     2.0
   34 |   0.9453 |     31.968 |   1.1094 |     36.106 |     2.1
   35 |   0.9242 |     31.302 |   1.1282 |     36.729 |     2.1
   36 |   0.9243 |     31.180 |   1.1343 |     36.449 |     2.2
   37 |   0.9118 |     30.718 |   1.1209 |     36.916 |     2.3
   38 |   0.8895 |     29.942 |   1.1242 |     36.760 |     2.3
   39 |   0.8885 |     30.184 |   1.0981 |     35.514 |     2.4
   40 |   0.8647 |     29.105 |   1.1112 |     36.106 |     2.4
   41 |   0.8641 |     29.297 |   1.1063 |     35.452 |     2.5
   42 |   0.8526 |     28.829 |   1.1231 |     35.047 |     2.6
   43 |   0.8395 |     28.367 |   1.0957 |     34.611 |     2.6
   44 |   0.8286 |     28.119 |   1.1129 |     35.234 |     2.7
   45 |   0.8244 |     28.037 |   1.1088 |     34.206 |     2.7
   46 |   0.8127 |     27.547 |   1.1059 |     34.891 |     2.8
   47 |   0.8026 |     27.266 |   1.1135 |     35.327 |     2.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 1,428,002

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2509 |     61.816 |   1.6164 |     48.785 |     0.0
    2 |   1.4759 |     46.162 |   1.4208 |     45.763 |     0.1
    3 |   1.4098 |     46.146 |   1.3963 |     45.763 |     0.1
    4 |   1.3963 |     46.085 |   1.3920 |     45.763 |     0.1
    5 |   1.3915 |     46.195 |   1.3938 |     47.819 |     0.2
    6 |   1.3884 |     46.195 |   1.3832 |     45.763 |     0.2
    7 |   1.3832 |     45.766 |   1.3766 |     45.389 |     0.2
    8 |   1.3633 |     44.654 |   1.3538 |     44.393 |     0.3
    9 |   1.3402 |     44.604 |   1.3462 |     44.766 |     0.3
   10 |   1.3258 |     44.296 |   1.3441 |     45.171 |     0.4
   11 |   1.3150 |     44.125 |   1.3310 |     44.548 |     0.4
   12 |   1.3028 |     43.943 |   1.3133 |     44.268 |     0.4
   13 |   1.2899 |     43.751 |   1.3057 |     43.801 |     0.5
   14 |   1.2731 |     43.029 |   1.2975 |     43.489 |     0.5
   15 |   1.2601 |     42.859 |   1.2771 |     43.115 |     0.5
   16 |   1.2499 |     42.490 |   1.2806 |     42.617 |     0.6
   17 |   1.2314 |     41.829 |   1.2796 |     42.586 |     0.6
   18 |   1.2220 |     41.576 |   1.2675 |     42.461 |     0.6
   19 |   1.2111 |     40.965 |   1.2499 |     41.184 |     0.7
   20 |   1.1879 |     40.475 |   1.2383 |     40.997 |     0.7
   21 |   1.1686 |     39.500 |   1.2308 |     40.530 |     0.7
   22 |   1.1569 |     38.955 |   1.2361 |     41.682 |     0.8
   23 |   1.1437 |     38.641 |   1.2027 |     39.782 |     0.8
   24 |   1.1174 |     37.903 |   1.1902 |     39.657 |     0.8
   25 |   1.1019 |     37.358 |   1.1824 |     39.128 |     0.9
   26 |   1.0833 |     36.808 |   1.1790 |     38.598 |     0.9
   27 |   1.0563 |     35.690 |   1.1747 |     39.034 |     0.9
   28 |   1.0390 |     35.167 |   1.1517 |     38.598 |     1.0
   29 |   1.0163 |     34.275 |   1.1445 |     37.290 |     1.0
   30 |   0.9920 |     33.064 |   1.1512 |     38.660 |     1.0
   31 |   0.9720 |     32.876 |   1.1375 |     37.103 |     1.1
   32 |   0.9449 |     31.582 |   1.1312 |     38.411 |     1.1
   33 |   0.9402 |     31.715 |   1.1282 |     37.757 |     1.2
   34 |   0.9054 |     30.432 |   1.1088 |     36.324 |     1.2
   35 |   0.8925 |     29.815 |   1.0972 |     35.950 |     1.2
   36 |   0.8656 |     29.171 |   1.1002 |     34.891 |     1.3
   37 |   0.8412 |     28.059 |   1.0827 |     35.047 |     1.3
   38 |   0.8160 |     27.260 |   1.0936 |     34.766 |     1.3
   39 |   0.8009 |     26.798 |   1.0729 |     35.202 |     1.4
   40 |   0.7771 |     25.851 |   1.0793 |     35.109 |     1.4
   41 |   0.7547 |     24.986 |   1.0749 |     33.988 |     1.4
   42 |   0.7313 |     24.309 |   1.0711 |     33.333 |     1.5
   43 |   0.7182 |     23.643 |   1.0617 |     33.271 |     1.5
   44 |   0.7028 |     23.428 |   1.0695 |     32.523 |     1.5
   45 |   0.6746 |     22.074 |   1.0710 |     32.648 |     1.6
   46 |   0.6433 |     21.127 |   1.0912 |     33.178 |     1.6
   47 |   0.6277 |     20.741 |   1.0718 |     32.555 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 927,138

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5749 |     69.194 |   2.0042 |     59.159 |     0.0
    2 |   1.7861 |     51.074 |   1.5986 |     45.763 |     0.1
    3 |   1.5147 |     46.052 |   1.4530 |     45.763 |     0.1
    4 |   1.4356 |     46.047 |   1.4163 |     45.763 |     0.1
    5 |   1.4122 |     46.135 |   1.4036 |     45.763 |     0.2
    6 |   1.3987 |     46.091 |   1.3877 |     45.763 |     0.2
    7 |   1.3811 |     46.113 |   1.3693 |     45.701 |     0.2
    8 |   1.3617 |     45.799 |   1.3502 |     44.798 |     0.3
    9 |   1.3447 |     45.342 |   1.3528 |     45.607 |     0.3
   10 |   1.3330 |     45.331 |   1.3285 |     46.044 |     0.3
   11 |   1.3186 |     45.171 |   1.3268 |     44.735 |     0.4
   12 |   1.3113 |     45.001 |   1.3172 |     44.704 |     0.4
   13 |   1.2974 |     44.758 |   1.3031 |     44.860 |     0.4
   14 |   1.2898 |     44.599 |   1.2967 |     44.673 |     0.5
   15 |   1.2830 |     44.615 |   1.3011 |     44.517 |     0.5
   16 |   1.2729 |     44.081 |   1.2820 |     43.115 |     0.5
   17 |   1.2648 |     44.009 |   1.2787 |     43.769 |     0.6
   18 |   1.2488 |     43.310 |   1.2687 |     43.115 |     0.6
   19 |   1.2388 |     42.985 |   1.2641 |     43.240 |     0.6
   20 |   1.2258 |     42.413 |   1.2584 |     42.461 |     0.7
   21 |   1.2132 |     41.526 |   1.2356 |     41.994 |     0.7
   22 |   1.1904 |     41.108 |   1.2177 |     41.589 |     0.8
   23 |   1.1749 |     40.491 |   1.2111 |     40.935 |     0.8
   24 |   1.1601 |     40.194 |   1.2104 |     41.371 |     0.8
   25 |   1.1536 |     39.638 |   1.2019 |     40.685 |     0.9
   26 |   1.1415 |     39.362 |   1.1911 |     40.280 |     0.9
   27 |   1.1243 |     38.718 |   1.1917 |     40.530 |     0.9
   28 |   1.1158 |     38.542 |   1.1917 |     39.439 |     1.0
   29 |   1.1043 |     37.848 |   1.1794 |     39.533 |     1.0
   30 |   1.0896 |     37.386 |   1.1786 |     39.128 |     1.0
   31 |   1.0802 |     37.248 |   1.1611 |     38.785 |     1.1
   32 |   1.0631 |     36.510 |   1.1522 |     37.788 |     1.1
   33 |   1.0573 |     35.982 |   1.1483 |     37.726 |     1.1
   34 |   1.0544 |     36.108 |   1.1483 |     38.287 |     1.2
   35 |   1.0441 |     35.360 |   1.1536 |     38.380 |     1.2
   36 |   1.0264 |     34.963 |   1.1387 |     37.477 |     1.2
   37 |   1.0218 |     34.814 |   1.1417 |     37.664 |     1.3
   38 |   1.0265 |     34.853 |   1.1369 |     38.224 |     1.3
   39 |   1.0035 |     34.055 |   1.1240 |     37.508 |     1.3
   40 |   0.9905 |     33.350 |   1.1288 |     37.944 |     1.4
   41 |   0.9741 |     32.948 |   1.1124 |     36.449 |     1.4
   42 |   0.9594 |     32.320 |   1.1160 |     36.791 |     1.4
   43 |   0.9571 |     31.781 |   1.1051 |     36.231 |     1.5
   44 |   0.9496 |     31.951 |   1.1039 |     37.290 |     1.5
   45 |   0.9277 |     31.329 |   1.1009 |     36.075 |     1.5
   46 |   0.9195 |     30.977 |   1.1148 |     36.262 |     1.6
   47 |   0.9125 |     30.663 |   1.0928 |     35.919 |     1.6
   48 |   0.9036 |     30.377 |   1.1068 |     35.514 |     1.6
   49 |   0.8995 |     30.068 |   1.0923 |     34.984 |     1.7
   50 |   0.8824 |     29.798 |   1.0976 |     35.421 |     1.7
   51 |   0.8822 |     29.991 |   1.0802 |     34.579 |     1.7
   52 |   0.8679 |     29.083 |   1.0893 |     34.922 |     1.8
   53 |   0.8570 |     28.670 |   1.0789 |     34.050 |     1.8
   54 |   0.8591 |     28.725 |   1.0852 |     35.452 |     1.8
   55 |   0.8537 |     28.708 |   1.0721 |     34.798 |     1.9
   56 |   0.8352 |     28.048 |   1.0997 |     34.922 |     1.9
   57 |   0.8261 |     27.778 |   1.0783 |     34.237 |     1.9
   58 |   0.8091 |     27.018 |   1.0621 |     33.707 |     2.0
   59 |   0.7969 |     26.368 |   1.0813 |     34.206 |     2.0
   60 |   0.7927 |     26.517 |   1.0825 |     33.988 |     2.0
   61 |   0.7896 |     26.242 |   1.0800 |     33.489 |     2.1
   62 |   0.7889 |     26.346 |   1.0709 |     32.991 |     2.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 859,618

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2023 |     60.225 |   1.6155 |     46.137 |     0.0
    2 |   1.4463 |     45.155 |   1.3664 |     44.174 |     0.0
    3 |   1.3097 |     42.589 |   1.2826 |     41.371 |     0.1
    4 |   1.2312 |     39.847 |   1.2334 |     41.090 |     0.1
    5 |   1.1699 |     38.465 |   1.1934 |     40.093 |     0.1
    6 |   1.1080 |     36.631 |   1.1434 |     38.100 |     0.1
    7 |   1.0457 |     34.479 |   1.1039 |     37.352 |     0.2
    8 |   0.9892 |     32.485 |   1.0839 |     36.012 |     0.2
    9 |   0.9382 |     30.905 |   1.0459 |     33.520 |     0.2
   10 |   0.8809 |     28.725 |   1.0235 |     33.801 |     0.2
   11 |   0.8284 |     26.908 |   1.0171 |     32.866 |     0.3
   12 |   0.7930 |     25.465 |   1.0102 |     32.523 |     0.3
   13 |   0.7424 |     24.001 |   0.9810 |     30.717 |     0.3
   14 |   0.6990 |     22.586 |   0.9894 |     31.028 |     0.3
   15 |   0.6564 |     21.138 |   0.9622 |     30.156 |     0.4
   16 |   0.6088 |     19.475 |   0.9670 |     29.938 |     0.4
   17 |   0.5761 |     18.396 |   0.9773 |     30.810 |     0.4
   18 |   0.5285 |     16.667 |   0.9906 |     30.280 |     0.4
   19 |   0.5020 |     16.033 |   0.9609 |     28.910 |     0.5
   20 |   0.4695 |     14.773 |   0.9631 |     28.131 |     0.5
   21 |   0.4418 |     13.682 |   0.9833 |     27.850 |     0.5
   22 |   0.4179 |     13.033 |   0.9973 |     28.536 |     0.5
   23 |   0.3877 |     12.278 |   1.0065 |     28.193 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,106,338

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3424 |     62.934 |   1.6914 |     48.785 |     0.0
    2 |   1.5102 |     46.410 |   1.4272 |     46.791 |     0.1
    3 |   1.4140 |     46.102 |   1.4005 |     45.826 |     0.1
    4 |   1.3981 |     46.074 |   1.3866 |     45.763 |     0.1
    5 |   1.3830 |     46.069 |   1.3865 |     46.916 |     0.1
    6 |   1.3666 |     45.760 |   1.3607 |     44.984 |     0.2
    7 |   1.3484 |     44.923 |   1.3490 |     44.611 |     0.2
    8 |   1.3229 |     44.296 |   1.3246 |     44.174 |     0.2
    9 |   1.3055 |     44.103 |   1.3027 |     43.707 |     0.2
   10 |   1.2804 |     43.464 |   1.2893 |     43.738 |     0.3
   11 |   1.2526 |     42.886 |   1.2647 |     42.866 |     0.3
   12 |   1.2311 |     42.215 |   1.2571 |     42.835 |     0.3
   13 |   1.2099 |     41.680 |   1.2294 |     42.025 |     0.3
   14 |   1.1872 |     40.877 |   1.2165 |     41.589 |     0.4
   15 |   1.1715 |     40.309 |   1.2055 |     40.935 |     0.4
   16 |   1.1493 |     39.572 |   1.2054 |     40.249 |     0.4
   17 |   1.1240 |     38.680 |   1.1908 |     40.592 |     0.5
   18 |   1.1071 |     38.091 |   1.1749 |     39.097 |     0.5
   19 |   1.0878 |     37.501 |   1.1624 |     38.847 |     0.5
   20 |   1.0600 |     36.356 |   1.1325 |     37.757 |     0.5
   21 |   1.0499 |     35.916 |   1.1434 |     37.788 |     0.6
   22 |   1.0278 |     35.172 |   1.1255 |     38.255 |     0.6
   23 |   1.0042 |     34.137 |   1.1236 |     37.259 |     0.6
   24 |   0.9867 |     33.554 |   1.1102 |     36.729 |     0.6
   25 |   0.9672 |     32.777 |   1.0962 |     36.199 |     0.7
   26 |   0.9488 |     32.227 |   1.0996 |     37.103 |     0.7
   27 |   0.9276 |     31.571 |   1.0944 |     35.794 |     0.7
   28 |   0.9031 |     30.779 |   1.0827 |     35.358 |     0.8
   29 |   0.8884 |     29.738 |   1.1152 |     35.888 |     0.8
   30 |   0.8958 |     30.266 |   1.0863 |     36.262 |     0.8
   31 |   0.8517 |     28.780 |   1.0582 |     34.330 |     0.8
   32 |   0.8282 |     27.734 |   1.0694 |     34.268 |     0.9
   33 |   0.8168 |     27.431 |   1.0629 |     34.393 |     0.9
   34 |   0.7955 |     26.627 |   1.0545 |     33.614 |     0.9
   35 |   0.7711 |     25.685 |   1.0679 |     33.333 |     0.9
   36 |   0.7549 |     25.124 |   1.0635 |     33.676 |     1.0
   37 |   0.7369 |     24.628 |   1.0488 |     33.115 |     1.0
   38 |   0.7219 |     23.962 |   1.0471 |     31.994 |     1.0
   39 |   0.7052 |     23.401 |   1.0471 |     32.928 |     1.0
   40 |   0.6947 |     22.910 |   1.0472 |     31.838 |     1.1
   41 |   0.6752 |     22.349 |   1.0452 |     31.776 |     1.1
   42 |   0.6516 |     21.402 |   1.0394 |     31.838 |     1.1
   43 |   0.6312 |     20.983 |   1.0717 |     32.212 |     1.2
   44 |   0.6263 |     20.697 |   1.0237 |     31.558 |     1.2
   45 |   0.6074 |     20.317 |   1.0278 |     30.623 |     1.2
   46 |   0.5995 |     19.904 |   1.0455 |     30.966 |     1.2
   47 |   0.5797 |     19.337 |   1.0475 |     30.592 |     1.3
   48 |   0.5679 |     18.897 |   1.0550 |     31.090 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 444,386

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6158 |     69.778 |   2.0614 |     59.159 |     0.0
    2 |   1.8089 |     51.173 |   1.5996 |     45.763 |     0.0
    3 |   1.5157 |     46.036 |   1.4596 |     45.763 |     0.1
    4 |   1.4414 |     46.030 |   1.4258 |     46.791 |     0.1
    5 |   1.4123 |     46.168 |   1.4006 |     45.763 |     0.1
    6 |   1.3839 |     46.030 |   1.3696 |     45.047 |     0.1
    7 |   1.3593 |     45.540 |   1.3548 |     45.950 |     0.1
    8 |   1.3335 |     45.138 |   1.3299 |     44.829 |     0.2
    9 |   1.3122 |     45.050 |   1.3131 |     44.766 |     0.2
   10 |   1.2911 |     44.599 |   1.3131 |     44.642 |     0.2
   11 |   1.2728 |     43.839 |   1.2862 |     44.081 |     0.2
   12 |   1.2557 |     43.404 |   1.2883 |     44.455 |     0.3
   13 |   1.2391 |     42.424 |   1.2541 |     42.710 |     0.3
   14 |   1.2135 |     41.124 |   1.2367 |     41.838 |     0.3
   15 |   1.1870 |     40.073 |   1.2211 |     40.717 |     0.3
   16 |   1.1656 |     39.583 |   1.2160 |     41.153 |     0.3
   17 |   1.1409 |     38.872 |   1.1988 |     40.748 |     0.4
   18 |   1.1173 |     38.432 |   1.1913 |     40.685 |     0.4
   19 |   1.0974 |     37.380 |   1.1654 |     39.688 |     0.4
   20 |   1.0691 |     36.301 |   1.1669 |     39.221 |     0.4
   21 |   1.0492 |     35.828 |   1.1606 |     38.723 |     0.4
   22 |   1.0336 |     35.095 |   1.1552 |     38.162 |     0.5
   23 |   1.0035 |     34.170 |   1.1347 |     37.664 |     0.5
   24 |   0.9841 |     33.521 |   1.1430 |     37.601 |     0.5
   25 |   0.9581 |     32.496 |   1.1296 |     37.570 |     0.5
   26 |   0.9304 |     31.263 |   1.1223 |     37.414 |     0.5
   27 |   0.9207 |     31.015 |   1.1170 |     36.044 |     0.6
   28 |   0.9060 |     30.707 |   1.1290 |     36.604 |     0.6
   29 |   0.8890 |     29.501 |   1.1163 |     36.231 |     0.6
   30 |   0.8707 |     29.039 |   1.1168 |     35.483 |     0.6
   31 |   0.8474 |     28.648 |   1.1056 |     35.389 |     0.6
   32 |   0.8205 |     27.101 |   1.1096 |     34.891 |     0.7
   33 |   0.8011 |     26.655 |   1.1106 |     34.891 |     0.7
   34 |   0.7854 |     26.115 |   1.0841 |     35.140 |     0.7
   35 |   0.7736 |     25.471 |   1.1183 |     34.922 |     0.7
   36 |   0.7571 |     25.471 |   1.1151 |     34.393 |     0.7
   37 |   0.7274 |     23.973 |   1.1070 |     34.019 |     0.8
   38 |   0.7118 |     23.401 |   1.1056 |     32.679 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 933,410

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2920 |     61.898 |   1.6502 |     48.785 |     0.0
    2 |   1.4907 |     46.432 |   1.4190 |     45.763 |     0.0
    3 |   1.4047 |     46.058 |   1.3924 |     45.763 |     0.1
    4 |   1.3820 |     45.970 |   1.3667 |     44.984 |     0.1
    5 |   1.3505 |     45.182 |   1.3471 |     46.355 |     0.1
    6 |   1.3204 |     44.175 |   1.3047 |     43.956 |     0.1
    7 |   1.2796 |     43.106 |   1.2807 |     42.212 |     0.1
    8 |   1.2491 |     41.680 |   1.2635 |     41.589 |     0.2
    9 |   1.2268 |     41.196 |   1.2437 |     41.121 |     0.2
   10 |   1.1939 |     40.199 |   1.2223 |     40.000 |     0.2
   11 |   1.1647 |     39.005 |   1.2237 |     40.530 |     0.2
   12 |   1.1425 |     38.470 |   1.1974 |     39.938 |     0.2
   13 |   1.1225 |     37.903 |   1.1846 |     39.034 |     0.2
   14 |   1.0939 |     37.154 |   1.1713 |     38.660 |     0.3
   15 |   1.0677 |     36.483 |   1.1431 |     37.882 |     0.3
   16 |   1.0391 |     35.332 |   1.1376 |     37.757 |     0.3
   17 |   1.0086 |     34.501 |   1.1187 |     37.508 |     0.3
   18 |   0.9768 |     33.416 |   1.1043 |     36.199 |     0.3
   19 |   0.9510 |     32.150 |   1.1194 |     36.604 |     0.4
   20 |   0.9262 |     30.977 |   1.1013 |     35.607 |     0.4
   21 |   0.9026 |     30.239 |   1.0837 |     36.480 |     0.4
   22 |   0.8670 |     29.149 |   1.0801 |     34.081 |     0.4
   23 |   0.8362 |     27.866 |   1.0669 |     34.393 |     0.4
   24 |   0.8097 |     26.633 |   1.0782 |     33.801 |     0.5
   25 |   0.7776 |     25.669 |   1.0626 |     32.586 |     0.5
   26 |   0.7554 |     25.014 |   1.0502 |     32.523 |     0.5
   27 |   0.7282 |     24.193 |   1.0312 |     31.651 |     0.5
   28 |   0.6996 |     22.773 |   1.0142 |     30.436 |     0.5
   29 |   0.6919 |     22.641 |   1.0309 |     31.246 |     0.5
   30 |   0.6515 |     21.187 |   1.0208 |     29.751 |     0.6
   31 |   0.6268 |     20.449 |   1.0377 |     30.561 |     0.6
   32 |   0.6108 |     19.519 |   1.0243 |     29.751 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,211,362

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2251 |     61.287 |   1.6515 |     48.785 |     0.1
    2 |   1.5014 |     46.410 |   1.4279 |     45.763 |     0.1
    3 |   1.4123 |     46.305 |   1.4044 |     45.763 |     0.2
    4 |   1.3877 |     45.722 |   1.3752 |     44.579 |     0.2
    5 |   1.3553 |     44.769 |   1.3542 |     45.514 |     0.3
    6 |   1.3361 |     44.632 |   1.3341 |     44.798 |     0.4
    7 |   1.3176 |     44.318 |   1.3294 |     44.268 |     0.4
    8 |   1.3004 |     43.569 |   1.3170 |     43.956 |     0.5
    9 |   1.2855 |     42.809 |   1.3069 |     43.489 |     0.5
   10 |   1.2740 |     42.446 |   1.2945 |     43.801 |     0.6
   11 |   1.2598 |     42.369 |   1.2852 |     42.586 |     0.6
   12 |   1.2432 |     41.774 |   1.2865 |     42.960 |     0.7
   13 |   1.2261 |     41.278 |   1.2599 |     41.713 |     0.8
   14 |   1.2074 |     40.552 |   1.2461 |     41.464 |     0.8
   15 |   1.1939 |     40.249 |   1.2347 |     40.903 |     0.9
   16 |   1.1750 |     39.654 |   1.2383 |     41.028 |     0.9
   17 |   1.1625 |     39.082 |   1.2115 |     39.408 |     1.0
   18 |   1.1501 |     38.762 |   1.2181 |     39.813 |     1.1
   19 |   1.1357 |     38.327 |   1.1970 |     39.439 |     1.1
   20 |   1.1233 |     37.826 |   1.1991 |     39.315 |     1.2
   21 |   1.0975 |     37.496 |   1.1818 |     38.287 |     1.2
   22 |   1.0753 |     36.417 |   1.1828 |     38.505 |     1.3
   23 |   1.0711 |     36.609 |   1.2019 |     39.626 |     1.3
   24 |   1.0505 |     35.574 |   1.1727 |     38.536 |     1.4
   25 |   1.0388 |     35.035 |   1.1674 |     38.224 |     1.5
   26 |   1.0238 |     34.781 |   1.1574 |     37.726 |     1.5
   27 |   0.9958 |     33.631 |   1.1656 |     37.944 |     1.6
   28 |   0.9883 |     33.344 |   1.1708 |     37.477 |     1.6
   29 |   0.9670 |     32.876 |   1.1507 |     37.508 |     1.7
   30 |   0.9549 |     32.205 |   1.1535 |     38.037 |     1.8
   31 |   0.9650 |     32.238 |   1.1400 |     37.321 |     1.8
   32 |   0.9177 |     30.696 |   1.1435 |     37.570 |     1.9
   33 |   0.9213 |     30.916 |   1.1430 |     37.009 |     1.9
   34 |   0.8966 |     30.046 |   1.1316 |     35.981 |     2.0
   35 |   0.8905 |     29.633 |   1.1468 |     36.604 |     2.0
   36 |   0.8614 |     28.945 |   1.1337 |     36.449 |     2.1
   37 |   0.8389 |     28.147 |   1.1166 |     35.296 |     2.2
   38 |   0.8299 |     27.794 |   1.1260 |     35.327 |     2.2
   39 |   0.8277 |     27.833 |   1.1262 |     36.137 |     2.3
   40 |   0.8121 |     27.530 |   1.1434 |     35.296 |     2.3
   41 |   0.7997 |     26.979 |   1.1268 |     35.514 |     2.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,804,642

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5280 |     67.883 |   2.0525 |     58.380 |     0.1
    2 |   1.7906 |     51.035 |   1.5821 |     45.763 |     0.1
    3 |   1.5066 |     46.212 |   1.4513 |     45.763 |     0.2
    4 |   1.4264 |     45.678 |   1.4046 |     44.922 |     0.2
    5 |   1.3832 |     44.797 |   1.3746 |     44.922 |     0.3
    6 |   1.3527 |     44.477 |   1.3464 |     44.579 |     0.4
    7 |   1.3299 |     44.004 |   1.3264 |     43.520 |     0.4
    8 |   1.3047 |     43.079 |   1.3097 |     43.178 |     0.5
    9 |   1.2828 |     42.137 |   1.2924 |     43.302 |     0.6
   10 |   1.2732 |     41.989 |   1.2817 |     42.492 |     0.6
   11 |   1.2449 |     41.080 |   1.2668 |     41.682 |     0.7
   12 |   1.2282 |     40.546 |   1.2618 |     41.215 |     0.7
   13 |   1.2059 |     39.808 |   1.2480 |     40.903 |     0.8
   14 |   1.1899 |     39.511 |   1.2343 |     40.062 |     0.9
   15 |   1.1712 |     38.938 |   1.2266 |     40.156 |     0.9
   16 |   1.1523 |     38.470 |   1.2149 |     40.062 |     1.0
   17 |   1.1267 |     37.523 |   1.1933 |     39.657 |     1.0
   18 |   1.1048 |     36.483 |   1.1879 |     38.411 |     1.1
   19 |   1.0856 |     36.114 |   1.1691 |     38.754 |     1.2
   20 |   1.0709 |     35.464 |   1.1475 |     38.224 |     1.2
   21 |   1.0508 |     34.726 |   1.1513 |     37.882 |     1.3
   22 |   1.0367 |     34.418 |   1.1525 |     38.193 |     1.4
   23 |   1.0304 |     34.258 |   1.1185 |     36.791 |     1.4
   24 |   1.0106 |     33.521 |   1.1109 |     36.916 |     1.5
   25 |   0.9870 |     32.480 |   1.1056 |     37.196 |     1.5
   26 |   0.9703 |     32.117 |   1.0976 |     36.324 |     1.6
   27 |   0.9567 |     31.566 |   1.0879 |     35.763 |     1.7
   28 |   0.9390 |     30.999 |   1.1002 |     36.012 |     1.7
   29 |   0.9299 |     30.867 |   1.0667 |     35.483 |     1.8
   30 |   0.9124 |     30.107 |   1.0812 |     35.234 |     1.8
   31 |   0.9049 |     29.958 |   1.0477 |     34.268 |     1.9
   32 |   0.9029 |     29.876 |   1.0756 |     35.639 |     2.0
   33 |   0.8931 |     29.468 |   1.0611 |     35.327 |     2.0
   34 |   0.8738 |     29.033 |   1.0481 |     34.735 |     2.1
   35 |   0.8594 |     28.637 |   1.0363 |     33.988 |     2.2
   36 |   0.8441 |     27.767 |   1.0354 |     33.925 |     2.2
   37 |   0.8389 |     27.855 |   1.0461 |     34.174 |     2.3
   38 |   0.8261 |     27.266 |   1.0416 |     34.361 |     2.3
   39 |   0.8113 |     27.040 |   1.0368 |     33.520 |     2.4
   40 |   0.7918 |     26.231 |   1.0387 |     33.551 |     2.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 641,090

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2123 |     59.591 |   1.6062 |     48.723 |     0.0
    2 |   1.4696 |     46.019 |   1.4019 |     45.857 |     0.0
    3 |   1.3635 |     45.568 |   1.3469 |     44.984 |     0.1
    4 |   1.3095 |     43.850 |   1.2865 |     42.866 |     0.1
    5 |   1.2543 |     42.099 |   1.2590 |     41.807 |     0.1
    6 |   1.2146 |     40.722 |   1.2225 |     41.215 |     0.1
    7 |   1.1697 |     39.120 |   1.1912 |     39.751 |     0.1
    8 |   1.1232 |     37.887 |   1.1553 |     39.626 |     0.1
    9 |   1.0740 |     36.218 |   1.1459 |     38.100 |     0.2
   10 |   1.0355 |     34.693 |   1.1066 |     37.414 |     0.2
   11 |   0.9777 |     32.662 |   1.0843 |     35.701 |     0.2
   12 |   0.9465 |     31.748 |   1.0555 |     35.202 |     0.2
   13 |   0.8938 |     29.683 |   1.0431 |     33.583 |     0.2
   14 |   0.8529 |     28.053 |   1.0177 |     33.146 |     0.3
   15 |   0.8034 |     26.511 |   1.0029 |     31.900 |     0.3
   16 |   0.7675 |     25.179 |   0.9901 |     31.620 |     0.3
   17 |   0.7267 |     23.615 |   0.9964 |     31.589 |     0.3
   18 |   0.6998 |     22.553 |   1.0076 |     30.031 |     0.3
   19 |   0.6631 |     21.220 |   0.9864 |     30.997 |     0.4
   20 |   0.6310 |     20.235 |   0.9867 |     29.720 |     0.4
   21 |   0.5972 |     18.786 |   0.9792 |     29.252 |     0.4
   22 |   0.5786 |     18.307 |   0.9898 |     28.380 |     0.4
   23 |   0.5418 |     17.107 |   0.9983 |     28.598 |     0.4
   24 |   0.5188 |     16.457 |   0.9767 |     27.726 |     0.4
   25 |   0.4958 |     15.808 |   0.9827 |     28.224 |     0.5
   26 |   0.4825 |     15.086 |   0.9863 |     28.411 |     0.5
   27 |   0.4476 |     14.189 |   1.0118 |     27.539 |     0.5
   28 |   0.4323 |     13.413 |   1.0134 |     26.916 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,147,234

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5816 |     70.570 |   2.0182 |     59.159 |     0.0
    2 |   1.7911 |     50.545 |   1.5970 |     45.763 |     0.1
    3 |   1.5157 |     46.052 |   1.4608 |     45.763 |     0.1
    4 |   1.4404 |     46.036 |   1.4237 |     45.763 |     0.2
    5 |   1.4148 |     46.074 |   1.4036 |     45.763 |     0.2
    6 |   1.4035 |     46.124 |   1.3970 |     45.763 |     0.2
    7 |   1.3968 |     46.074 |   1.3910 |     45.763 |     0.3
    8 |   1.3920 |     46.030 |   1.3870 |     45.763 |     0.3
    9 |   1.3835 |     46.102 |   1.3794 |     45.763 |     0.4
   10 |   1.3764 |     46.003 |   1.3763 |     45.732 |     0.4
   11 |   1.3678 |     45.882 |   1.3707 |     45.421 |     0.4
   12 |   1.3595 |     45.623 |   1.3602 |     45.514 |     0.5
   13 |   1.3444 |     44.940 |   1.3426 |     44.393 |     0.5
   14 |   1.3298 |     44.345 |   1.3402 |     44.548 |     0.6
   15 |   1.3205 |     44.009 |   1.3265 |     44.424 |     0.6
   16 |   1.3102 |     43.998 |   1.3194 |     44.019 |     0.6
   17 |   1.3061 |     43.773 |   1.3185 |     44.206 |     0.7
   18 |   1.2970 |     43.563 |   1.3071 |     43.614 |     0.7
   19 |   1.2931 |     43.426 |   1.3046 |     43.458 |     0.8
   20 |   1.2840 |     43.156 |   1.2937 |     43.364 |     0.8
   21 |   1.2738 |     42.655 |   1.2934 |     43.645 |     0.8
   22 |   1.2694 |     42.749 |   1.2864 |     43.458 |     0.9
   23 |   1.2597 |     42.424 |   1.2793 |     42.586 |     0.9
   24 |   1.2577 |     42.314 |   1.2738 |     42.773 |     1.0
   25 |   1.2462 |     42.022 |   1.2682 |     42.118 |     1.0
   26 |   1.2391 |     41.879 |   1.2653 |     41.869 |     1.1
   27 |   1.2279 |     41.570 |   1.2572 |     42.087 |     1.1
   28 |   1.2255 |     41.411 |   1.2497 |     41.402 |     1.1
   29 |   1.2145 |     41.306 |   1.2512 |     41.526 |     1.2
   30 |   1.1983 |     40.877 |   1.2321 |     40.903 |     1.2
   31 |   1.1936 |     40.739 |   1.2329 |     41.713 |     1.3
   32 |   1.1747 |     40.144 |   1.2282 |     41.371 |     1.3
   33 |   1.1666 |     39.841 |   1.2153 |     40.841 |     1.3
   34 |   1.1563 |     39.313 |   1.2056 |     41.277 |     1.4
   35 |   1.1410 |     38.773 |   1.1963 |     40.872 |     1.4
   36 |   1.1262 |     38.487 |   1.1965 |     40.249 |     1.5
   37 |   1.1192 |     38.184 |   1.1895 |     39.907 |     1.5
   38 |   1.1043 |     37.501 |   1.1781 |     39.034 |     1.5
   39 |   1.0909 |     37.259 |   1.1737 |     39.657 |     1.6
   40 |   1.0897 |     37.094 |   1.1669 |     39.065 |     1.6
   41 |   1.0748 |     36.422 |   1.1589 |     39.190 |     1.7
   42 |   1.0660 |     36.554 |   1.1685 |     39.315 |     1.7
   43 |   1.0564 |     36.125 |   1.1535 |     38.660 |     1.7
   44 |   1.0366 |     35.238 |   1.1595 |     38.723 |     1.8
   45 |   1.0336 |     35.260 |   1.1475 |     38.442 |     1.8
   46 |   1.0264 |     35.068 |   1.1391 |     37.570 |     1.9
   47 |   1.0191 |     34.842 |   1.1404 |     37.570 |     1.9
   48 |   1.0126 |     34.814 |   1.1328 |     37.352 |     2.0
   49 |   0.9970 |     34.044 |   1.1307 |     38.318 |     2.0
   50 |   0.9966 |     34.385 |   1.1278 |     37.757 |     2.0
   51 |   0.9886 |     33.537 |   1.1293 |     37.134 |     2.1
   52 |   0.9718 |     33.289 |   1.1159 |     37.009 |     2.1
   53 |   0.9672 |     33.019 |   1.1100 |     36.885 |     2.2
   54 |   0.9616 |     32.865 |   1.1145 |     36.791 |     2.2
   55 |   0.9472 |     32.452 |   1.1053 |     37.040 |     2.2
   56 |   0.9397 |     31.946 |   1.1001 |     36.542 |     2.3
   57 |   0.9264 |     31.709 |   1.1083 |     36.760 |     2.3
   58 |   0.9282 |     31.665 |   1.1087 |     36.542 |     2.4
   59 |   0.9259 |     31.346 |   1.1052 |     36.355 |     2.4
   60 |   0.9155 |     30.927 |   1.0861 |     35.514 |     2.4
   61 |   0.9033 |     30.470 |   1.0857 |     36.604 |     2.5
   62 |   0.8977 |     30.404 |   1.0975 |     37.072 |     2.5
   63 |   0.8928 |     30.437 |   1.0716 |     34.829 |     2.6
   64 |   0.8753 |     29.529 |   1.0964 |     36.542 |     2.6
   65 |   0.8745 |     29.617 |   1.0925 |     35.950 |     2.6
   66 |   0.8724 |     29.364 |   1.0754 |     35.545 |     2.7
   67 |   0.8505 |     28.829 |   1.0684 |     34.766 |     2.7
   68 |   0.8493 |     28.736 |   1.0825 |     35.389 |     2.8
   69 |   0.8365 |     28.582 |   1.0688 |     35.109 |     2.8
   70 |   0.8284 |     27.910 |   1.0765 |     34.984 |     2.9
   71 |   0.8199 |     27.750 |   1.0626 |     34.611 |     2.9
   72 |   0.8124 |     27.326 |   1.0613 |     35.327 |     2.9
   73 |   0.8154 |     27.447 |   1.0605 |     34.455 |     3.0
   74 |   0.8133 |     27.646 |   1.0500 |     33.396 |     3.0
   75 |   0.7950 |     26.858 |   1.0498 |     34.330 |     3.1
   76 |   0.7912 |     26.820 |   1.0516 |     33.520 |     3.1
   77 |   0.7848 |     26.511 |   1.0652 |     33.863 |     3.1
   78 |   0.7746 |     25.961 |   1.0751 |     34.081 |     3.2
   79 |   0.7666 |     25.641 |   1.0533 |     33.022 |     3.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 691,170

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2921 |     62.086 |   1.6505 |     45.794 |     0.0
    2 |   1.4905 |     46.179 |   1.4174 |     45.701 |     0.0
    3 |   1.3788 |     44.593 |   1.3575 |     44.642 |     0.1
    4 |   1.3210 |     43.674 |   1.3168 |     43.645 |     0.1
    5 |   1.2814 |     42.550 |   1.2784 |     42.336 |     0.1
    6 |   1.2302 |     41.290 |   1.2356 |     41.433 |     0.1
    7 |   1.1878 |     39.841 |   1.2111 |     40.748 |     0.2
    8 |   1.1541 |     38.861 |   1.1888 |     40.093 |     0.2
    9 |   1.1110 |     37.815 |   1.1577 |     38.941 |     0.2
   10 |   1.0832 |     36.945 |   1.1623 |     38.536 |     0.2
   11 |   1.0454 |     35.371 |   1.1129 |     37.227 |     0.3
   12 |   1.0071 |     34.242 |   1.1132 |     37.757 |     0.3
   13 |   0.9714 |     33.019 |   1.0829 |     36.417 |     0.3
   14 |   0.9324 |     31.423 |   1.0740 |     35.545 |     0.3
   15 |   0.9020 |     30.046 |   1.0548 |     34.891 |     0.3
   16 |   0.8564 |     28.725 |   1.0211 |     33.676 |     0.4
   17 |   0.8190 |     27.012 |   1.0097 |     32.773 |     0.4
   18 |   0.7864 |     26.275 |   1.0123 |     31.900 |     0.4
   19 |   0.7473 |     24.436 |   0.9887 |     32.025 |     0.4
   20 |   0.7167 |     23.378 |   0.9971 |     31.277 |     0.5
   21 |   0.6862 |     22.310 |   0.9696 |     30.935 |     0.5
   22 |   0.6517 |     20.785 |   0.9744 |     30.000 |     0.5
   23 |   0.6195 |     20.213 |   0.9872 |     30.717 |     0.5
   24 |   0.5919 |     19.117 |   0.9883 |     30.000 |     0.5
   25 |   0.5675 |     18.401 |   0.9832 |     28.785 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 916,706

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3361 |     64.255 |   1.6640 |     45.763 |     0.0
    2 |   1.4977 |     46.333 |   1.4222 |     45.763 |     0.0
    3 |   1.4109 |     46.008 |   1.4051 |     46.791 |     0.1
    4 |   1.3964 |     46.223 |   1.3917 |     46.791 |     0.1
    5 |   1.3876 |     46.096 |   1.3791 |     46.573 |     0.1
    6 |   1.3638 |     45.232 |   1.3546 |     44.611 |     0.1
    7 |   1.3386 |     44.378 |   1.3342 |     44.174 |     0.1
    8 |   1.3178 |     43.855 |   1.3186 |     43.832 |     0.2
    9 |   1.2908 |     42.743 |   1.3142 |     43.427 |     0.2
   10 |   1.2696 |     42.292 |   1.2754 |     43.084 |     0.2
   11 |   1.2487 |     41.824 |   1.2613 |     42.399 |     0.2
   12 |   1.2239 |     41.179 |   1.2522 |     41.931 |     0.2
   13 |   1.2004 |     40.744 |   1.2280 |     42.274 |     0.3
   14 |   1.1730 |     39.946 |   1.2054 |     41.340 |     0.3
   15 |   1.1580 |     39.445 |   1.2064 |     40.654 |     0.3
   16 |   1.1342 |     38.636 |   1.1854 |     40.374 |     0.3
   17 |   1.1169 |     38.052 |   1.1796 |     40.218 |     0.4
   18 |   1.1084 |     37.804 |   1.1507 |     38.785 |     0.4
   19 |   1.0846 |     36.846 |   1.1487 |     38.723 |     0.4
   20 |   1.0610 |     36.158 |   1.1554 |     38.785 |     0.4
   21 |   1.0387 |     35.409 |   1.1517 |     38.660 |     0.4
   22 |   1.0194 |     34.704 |   1.1291 |     38.287 |     0.5
   23 |   1.0001 |     34.038 |   1.1430 |     37.882 |     0.5
   24 |   0.9849 |     33.900 |   1.1276 |     37.072 |     0.5
   25 |   0.9654 |     32.766 |   1.1263 |     37.882 |     0.5
   26 |   0.9473 |     31.995 |   1.1088 |     36.791 |     0.5
   27 |   0.9282 |     31.450 |   1.0874 |     36.760 |     0.6
   28 |   0.9217 |     31.335 |   1.0967 |     35.826 |     0.6
   29 |   0.8884 |     29.743 |   1.0800 |     35.265 |     0.6
   30 |   0.8714 |     29.529 |   1.0929 |     34.393 |     0.6
   31 |   0.8393 |     27.976 |   1.0664 |     33.427 |     0.6
   32 |   0.8312 |     28.031 |   1.0793 |     33.676 |     0.7
   33 |   0.8188 |     27.359 |   1.0763 |     34.798 |     0.7
   34 |   0.7939 |     26.352 |   1.0542 |     33.178 |     0.7
   35 |   0.7657 |     25.256 |   1.0616 |     33.053 |     0.7
   36 |   0.7414 |     24.606 |   1.0603 |     32.835 |     0.7
   37 |   0.7311 |     24.083 |   1.0801 |     33.801 |     0.8
   38 |   0.7230 |     23.775 |   1.0526 |     31.994 |     0.8
   39 |   0.6852 |     22.442 |   1.0499 |     31.371 |     0.8
   40 |   0.6754 |     22.200 |   1.0604 |     31.464 |     0.8
   41 |   0.6534 |     21.600 |   1.0390 |     31.340 |     0.9
   42 |   0.6245 |     20.510 |   1.0539 |     31.371 |     0.9
   43 |   0.6069 |     20.119 |   1.0412 |     30.280 |     0.9
   44 |   0.5960 |     19.249 |   1.0678 |     30.530 |     0.9
   45 |   0.5838 |     19.205 |   1.0483 |     30.530 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 684,258

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3422 |     62.801 |   1.6839 |     48.785 |     0.0
    2 |   1.5030 |     46.361 |   1.4241 |     45.763 |     0.0
    3 |   1.4046 |     46.008 |   1.3863 |     45.763 |     0.0
    4 |   1.3724 |     45.700 |   1.3481 |     44.642 |     0.1
    5 |   1.3229 |     43.696 |   1.3154 |     43.240 |     0.1
    6 |   1.2869 |     42.897 |   1.2824 |     43.084 |     0.1
    7 |   1.2533 |     41.917 |   1.2659 |     42.212 |     0.1
    8 |   1.2292 |     41.212 |   1.2521 |     42.523 |     0.1
    9 |   1.2013 |     40.271 |   1.2417 |     41.807 |     0.1
   10 |   1.1703 |     39.021 |   1.2099 |     40.312 |     0.2
   11 |   1.1453 |     38.267 |   1.1928 |     39.844 |     0.2
   12 |   1.1202 |     37.854 |   1.1784 |     39.315 |     0.2
   13 |   1.1016 |     36.890 |   1.1705 |     39.221 |     0.2
   14 |   1.0697 |     36.092 |   1.1548 |     38.567 |     0.2
   15 |   1.0517 |     35.514 |   1.1595 |     38.287 |     0.2
   16 |   1.0215 |     34.545 |   1.1480 |     37.632 |     0.2
   17 |   1.0001 |     33.840 |   1.1535 |     38.692 |     0.3
   18 |   0.9767 |     33.201 |   1.1385 |     37.726 |     0.3
   19 |   0.9565 |     32.221 |   1.1364 |     37.321 |     0.3
   20 |   0.9322 |     31.048 |   1.1079 |     36.604 |     0.3
   21 |   0.9026 |     30.388 |   1.1031 |     36.012 |     0.3
   22 |   0.8857 |     29.655 |   1.1148 |     36.199 |     0.3
   23 |   0.8629 |     28.868 |   1.1104 |     35.389 |     0.4
   24 |   0.8279 |     27.756 |   1.0904 |     34.798 |     0.4
   25 |   0.8119 |     27.326 |   1.0730 |     33.707 |     0.4
   26 |   0.7906 |     26.231 |   1.1050 |     35.140 |     0.4
   27 |   0.7685 |     25.570 |   1.0683 |     32.866 |     0.4
   28 |   0.7415 |     24.452 |   1.0732 |     33.364 |     0.4
   29 |   0.7255 |     23.995 |   1.0654 |     32.368 |     0.4
   30 |   0.7072 |     23.268 |   1.0748 |     32.025 |     0.5
   31 |   0.6895 |     22.888 |   1.0653 |     32.243 |     0.5
   32 |   0.6669 |     22.052 |   1.0466 |     31.153 |     0.5
   33 |   0.6423 |     21.193 |   1.0654 |     31.807 |     0.5
   34 |   0.6260 |     20.780 |   1.0637 |     31.433 |     0.5
   35 |   0.6101 |     20.268 |   1.0646 |     31.495 |     0.5
   36 |   0.5901 |     19.365 |   1.0531 |     29.969 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 669,218

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0574 |     56.167 |   1.4815 |     45.950 |     0.0
    2 |   1.3700 |     44.439 |   1.3089 |     43.084 |     0.0
    3 |   1.2426 |     40.970 |   1.2300 |     40.966 |     0.1
    4 |   1.1591 |     38.068 |   1.1671 |     38.411 |     0.1
    5 |   1.0885 |     35.602 |   1.1101 |     36.978 |     0.1
    6 |   1.0112 |     33.333 |   1.0587 |     35.265 |     0.1
    7 |   0.9447 |     30.933 |   1.0097 |     33.146 |     0.1
    8 |   0.8683 |     28.125 |   0.9910 |     31.900 |     0.1
    9 |   0.8107 |     25.977 |   0.9565 |     30.436 |     0.2
   10 |   0.7461 |     23.478 |   0.9260 |     29.813 |     0.2
   11 |   0.6880 |     21.539 |   0.9116 |     28.660 |     0.2
   12 |   0.6344 |     20.108 |   0.8715 |     26.667 |     0.2
   13 |   0.5981 |     18.809 |   0.8661 |     26.386 |     0.2
   14 |   0.5538 |     17.289 |   0.8582 |     25.421 |     0.3
   15 |   0.5066 |     15.422 |   0.8463 |     25.701 |     0.3
   16 |   0.4770 |     14.740 |   0.8502 |     24.984 |     0.3
   17 |   0.4440 |     13.815 |   0.8351 |     24.143 |     0.3
   18 |   0.4132 |     12.598 |   0.8272 |     24.486 |     0.3
   19 |   0.3959 |     12.020 |   0.8621 |     24.735 |     0.3
   20 |   0.3727 |     11.535 |   0.8532 |     24.050 |     0.4
   21 |   0.3434 |     10.698 |   0.8549 |     23.271 |     0.4
   22 |   0.3231 |     10.032 |   0.8451 |     23.707 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,736,162

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5087 |     66.981 |   2.0334 |     59.159 |     0.1
    2 |   1.8091 |     51.437 |   1.6102 |     45.763 |     0.1
    3 |   1.5192 |     46.080 |   1.4588 |     45.763 |     0.2
    4 |   1.4380 |     46.080 |   1.4206 |     45.576 |     0.2
    5 |   1.4091 |     46.036 |   1.4009 |     45.763 |     0.3
    6 |   1.3925 |     45.733 |   1.3833 |     45.327 |     0.4
    7 |   1.3714 |     44.786 |   1.3702 |     44.953 |     0.4
    8 |   1.3538 |     44.527 |   1.3528 |     44.455 |     0.5
    9 |   1.3360 |     44.092 |   1.3340 |     43.863 |     0.6
   10 |   1.3281 |     43.833 |   1.3281 |     43.863 |     0.6
   11 |   1.3119 |     43.492 |   1.3157 |     43.614 |     0.7
   12 |   1.2953 |     42.831 |   1.3006 |     43.022 |     0.7
   13 |   1.2804 |     42.352 |   1.2882 |     42.523 |     0.8
   14 |   1.2664 |     41.780 |   1.2788 |     42.523 |     0.9
   15 |   1.2546 |     41.295 |   1.2706 |     41.713 |     0.9
   16 |   1.2418 |     40.921 |   1.2650 |     41.869 |     1.0
   17 |   1.2363 |     40.948 |   1.2577 |     41.402 |     1.0
   18 |   1.2225 |     40.629 |   1.2531 |     41.433 |     1.1
   19 |   1.2112 |     40.403 |   1.2449 |     41.215 |     1.2
   20 |   1.2001 |     40.100 |   1.2442 |     41.184 |     1.2
   21 |   1.1932 |     39.907 |   1.2277 |     40.280 |     1.3
   22 |   1.1831 |     39.930 |   1.2241 |     40.779 |     1.3
   23 |   1.1710 |     39.225 |   1.2140 |     40.125 |     1.4
   24 |   1.1561 |     38.735 |   1.2089 |     40.280 |     1.5
   25 |   1.1454 |     38.278 |   1.2110 |     40.280 |     1.5
   26 |   1.1336 |     37.931 |   1.1997 |     40.031 |     1.6
   27 |   1.1223 |     37.595 |   1.2030 |     40.000 |     1.6
   28 |   1.1143 |     37.254 |   1.2026 |     39.564 |     1.7
   29 |   1.1090 |     36.868 |   1.2028 |     39.938 |     1.8
   30 |   1.1011 |     36.686 |   1.1893 |     38.536 |     1.8
   31 |   1.0910 |     36.527 |   1.1854 |     38.879 |     1.9
   32 |   1.0729 |     35.668 |   1.1881 |     38.598 |     1.9
   33 |   1.0724 |     35.844 |   1.1927 |     38.598 |     2.0
   34 |   1.0611 |     35.409 |   1.1864 |     38.069 |     2.1
   35 |   1.0482 |     35.117 |   1.1838 |     38.505 |     2.1
   36 |   1.0461 |     34.770 |   1.1708 |     38.193 |     2.2
   37 |   1.0361 |     34.517 |   1.1726 |     38.567 |     2.3
   38 |   1.0326 |     34.556 |   1.1620 |     37.819 |     2.3
   39 |   1.0233 |     34.313 |   1.1646 |     38.006 |     2.4
   40 |   1.0152 |     34.126 |   1.1633 |     37.664 |     2.4
   41 |   1.0057 |     33.735 |   1.1705 |     38.224 |     2.5
   42 |   0.9999 |     33.499 |   1.1428 |     37.383 |     2.6
   43 |   0.9854 |     33.366 |   1.1422 |     37.321 |     2.6
   44 |   0.9810 |     32.926 |   1.1600 |     38.100 |     2.7
   45 |   0.9760 |     32.518 |   1.1433 |     37.259 |     2.7
   46 |   0.9634 |     32.662 |   1.1348 |     37.477 |     2.8
   47 |   0.9514 |     31.940 |   1.1286 |     36.760 |     2.9
   48 |   0.9463 |     31.417 |   1.1379 |     37.321 |     2.9
   49 |   0.9349 |     31.445 |   1.1152 |     36.417 |     3.0
   50 |   0.9251 |     30.977 |   1.1199 |     36.293 |     3.0
   51 |   0.9354 |     31.819 |   1.1409 |     36.791 |     3.1
   52 |   0.9270 |     30.845 |   1.1279 |     36.417 |     3.2
   53 |   0.9105 |     30.470 |   1.1313 |     36.480 |     3.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 250,594

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5473 |     66.039 |   1.9315 |     56.137 |     0.0
    2 |   1.7047 |     48.882 |   1.5338 |     45.763 |     0.0
    3 |   1.4764 |     46.052 |   1.4351 |     45.763 |     0.0
    4 |   1.4125 |     45.837 |   1.4000 |     45.732 |     0.1
    5 |   1.3864 |     45.876 |   1.3803 |     45.670 |     0.1
    6 |   1.3653 |     45.193 |   1.3612 |     45.234 |     0.1
    7 |   1.3482 |     45.199 |   1.3453 |     45.296 |     0.1
    8 |   1.3303 |     44.725 |   1.3273 |     44.050 |     0.1
    9 |   1.3107 |     44.351 |   1.3167 |     44.579 |     0.1
   10 |   1.2913 |     43.734 |   1.3052 |     44.174 |     0.1
   11 |   1.2743 |     43.277 |   1.2817 |     43.022 |     0.2
   12 |   1.2593 |     42.760 |   1.2741 |     43.458 |     0.2
   13 |   1.2359 |     41.724 |   1.2475 |     42.586 |     0.2
   14 |   1.2095 |     40.948 |   1.2363 |     41.869 |     0.2
   15 |   1.1868 |     40.023 |   1.2112 |     41.184 |     0.2
   16 |   1.1635 |     39.511 |   1.2023 |     40.561 |     0.2
   17 |   1.1415 |     39.137 |   1.1888 |     40.093 |     0.2
   18 |   1.1180 |     37.837 |   1.1828 |     39.688 |     0.3
   19 |   1.0933 |     36.989 |   1.1731 |     39.097 |     0.3
   20 |   1.0726 |     36.400 |   1.1558 |     39.159 |     0.3
   21 |   1.0479 |     35.338 |   1.1403 |     38.006 |     0.3
   22 |   1.0287 |     34.864 |   1.1362 |     38.692 |     0.3
   23 |   1.0069 |     33.928 |   1.1205 |     37.508 |     0.3
   24 |   0.9828 |     33.019 |   1.1045 |     36.885 |     0.3
   25 |   0.9551 |     32.144 |   1.1057 |     37.290 |     0.4
   26 |   0.9454 |     31.687 |   1.0850 |     35.639 |     0.4
   27 |   0.9268 |     31.296 |   1.0924 |     35.202 |     0.4
   28 |   0.9001 |     30.233 |   1.0733 |     34.361 |     0.4
   29 |   0.8856 |     29.534 |   1.0794 |     34.798 |     0.4
   30 |   0.8736 |     29.187 |   1.0691 |     34.798 |     0.4
   31 |   0.8508 |     28.367 |   1.0548 |     33.614 |     0.4
   32 |   0.8391 |     27.915 |   1.0403 |     33.396 |     0.5
   33 |   0.8174 |     27.045 |   1.0385 |     33.333 |     0.5
   34 |   0.8028 |     26.550 |   1.0378 |     32.648 |     0.5
   35 |   0.7847 |     25.845 |   1.0297 |     32.274 |     0.5
   36 |   0.7804 |     25.752 |   1.0260 |     33.115 |     0.5
   37 |   0.7616 |     24.953 |   1.0238 |     31.994 |     0.5
   38 |   0.7463 |     24.243 |   1.0096 |     31.308 |     0.5
   39 |   0.7368 |     23.951 |   1.0304 |     31.340 |     0.6
   40 |   0.7288 |     23.962 |   1.0355 |     31.308 |     0.6
   41 |   0.7069 |     23.202 |   1.0160 |     30.467 |     0.6
   42 |   0.7052 |     23.252 |   1.0258 |     31.246 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 1,106,338

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3323 |     62.862 |   1.7054 |     48.847 |     0.0
    2 |   1.5216 |     46.377 |   1.4240 |     45.763 |     0.0
    3 |   1.4139 |     46.030 |   1.4010 |     46.791 |     0.1
    4 |   1.3987 |     46.289 |   1.3890 |     45.763 |     0.1
    5 |   1.3888 |     46.091 |   1.3764 |     45.607 |     0.1
    6 |   1.3734 |     45.573 |   1.3679 |     45.763 |     0.1
    7 |   1.3416 |     44.450 |   1.3361 |     44.081 |     0.2
    8 |   1.3200 |     44.180 |   1.3280 |     44.922 |     0.2
    9 |   1.3020 |     43.475 |   1.3229 |     44.081 |     0.2
   10 |   1.2883 |     43.151 |   1.3095 |     43.489 |     0.2
   11 |   1.2708 |     42.622 |   1.2965 |     43.583 |     0.3
   12 |   1.2538 |     42.336 |   1.2839 |     43.084 |     0.3
   13 |   1.2420 |     41.697 |   1.2864 |     43.240 |     0.3
   14 |   1.2296 |     41.471 |   1.2682 |     42.741 |     0.3
   15 |   1.2193 |     41.460 |   1.2716 |     42.866 |     0.4
   16 |   1.2023 |     40.684 |   1.2770 |     42.897 |     0.4
   17 |   1.1953 |     40.585 |   1.2586 |     42.368 |     0.4
   18 |   1.1766 |     40.007 |   1.2501 |     42.025 |     0.4
   19 |   1.1582 |     39.676 |   1.2477 |     42.087 |     0.5
   20 |   1.1475 |     39.230 |   1.2429 |     41.402 |     0.5
   21 |   1.1476 |     39.258 |   1.2235 |     41.121 |     0.5
   22 |   1.1175 |     38.179 |   1.2428 |     41.371 |     0.5
   23 |   1.1116 |     37.788 |   1.2139 |     39.502 |     0.6
   24 |   1.0859 |     37.110 |   1.2149 |     41.589 |     0.6
   25 |   1.0755 |     36.709 |   1.2274 |     40.498 |     0.6
   26 |   1.0438 |     35.321 |   1.2320 |     40.093 |     0.6
   27 |   1.0325 |     35.128 |   1.1971 |     38.785 |     0.7
   28 |   1.0064 |     34.115 |   1.2007 |     38.660 |     0.7
   29 |   0.9902 |     33.768 |   1.2012 |     39.003 |     0.7
   30 |   0.9779 |     33.212 |   1.1983 |     39.346 |     0.7
   31 |   0.9487 |     32.397 |   1.1824 |     38.162 |     0.8
   32 |   0.9325 |     31.643 |   1.1921 |     38.069 |     0.8
   33 |   0.9133 |     30.448 |   1.1764 |     37.570 |     0.8
   34 |   0.8971 |     30.217 |   1.1955 |     38.100 |     0.8
   35 |   0.8746 |     29.523 |   1.1653 |     36.386 |     0.9
   36 |   0.8578 |     28.857 |   1.1694 |     35.981 |     0.9
   37 |   0.8328 |     28.257 |   1.1699 |     36.667 |     0.9
   38 |   0.8182 |     27.403 |   1.1695 |     35.483 |     0.9
   39 |   0.7933 |     26.605 |   1.1799 |     35.514 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 587,106

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2097 |     58.766 |   1.5710 |     45.763 |     0.0
    2 |   1.4499 |     46.074 |   1.3861 |     45.763 |     0.0
    3 |   1.3578 |     45.535 |   1.3380 |     43.676 |     0.0
    4 |   1.2937 |     43.140 |   1.2838 |     42.804 |     0.1
    5 |   1.2406 |     41.978 |   1.2478 |     41.402 |     0.1
    6 |   1.1989 |     40.502 |   1.2148 |     41.589 |     0.1
    7 |   1.1633 |     39.390 |   1.1898 |     40.280 |     0.1
    8 |   1.1195 |     38.008 |   1.1624 |     39.657 |     0.1
    9 |   1.0784 |     36.731 |   1.1472 |     38.131 |     0.1
   10 |   1.0439 |     35.602 |   1.1125 |     38.224 |     0.1
   11 |   1.0049 |     34.165 |   1.0883 |     36.293 |     0.2
   12 |   0.9672 |     32.496 |   1.0602 |     36.262 |     0.2
   13 |   0.9220 |     31.208 |   1.0529 |     35.016 |     0.2
   14 |   0.8859 |     29.798 |   1.0230 |     33.178 |     0.2
   15 |   0.8591 |     28.708 |   1.0069 |     32.586 |     0.2
   16 |   0.8238 |     27.536 |   0.9818 |     31.558 |     0.2
   17 |   0.7977 |     26.341 |   0.9739 |     30.966 |     0.2
   18 |   0.7681 |     25.151 |   1.0172 |     31.184 |     0.3
   19 |   0.7342 |     23.962 |   0.9644 |     29.533 |     0.3
   20 |   0.7077 |     23.329 |   0.9625 |     29.097 |     0.3
   21 |   0.6855 |     22.145 |   0.9612 |     28.879 |     0.3
   22 |   0.6627 |     21.556 |   0.9507 |     29.377 |     0.3
   23 |   0.6323 |     20.565 |   0.9637 |     29.097 |     0.3
   24 |   0.5995 |     19.348 |   0.9446 |     28.349 |     0.3
   25 |   0.5808 |     18.539 |   0.9630 |     28.879 |     0.4
   26 |   0.5694 |     18.352 |   0.9589 |     27.757 |     0.4
   27 |   0.5392 |     17.124 |   0.9646 |     27.882 |     0.4
   28 |   0.5262 |     16.760 |   0.9436 |     27.850 |     0.4
   29 |   0.5074 |     15.984 |   0.9476 |     27.196 |     0.4
   30 |   0.4861 |     15.329 |   0.9427 |     26.822 |     0.4
   31 |   0.4760 |     15.064 |   0.9559 |     27.290 |     0.4
   32 |   0.4641 |     14.651 |   0.9530 |     26.573 |     0.5
   33 |   0.4365 |     13.699 |   0.9810 |     26.760 |     0.5
   34 |   0.4336 |     13.748 |   0.9411 |     26.293 |     0.5
   35 |   0.4162 |     13.275 |   0.9422 |     26.355 |     0.5
   36 |   0.4169 |     13.396 |   0.9624 |     26.324 |     0.5
   37 |   0.4000 |     12.923 |   0.9672 |     26.355 |     0.5
   38 |   0.3808 |     11.970 |   0.9859 |     26.355 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 623,010

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1389 |     58.710 |   1.5150 |     45.763 |     0.0
    2 |   1.4001 |     44.736 |   1.3219 |     42.648 |     0.0
    3 |   1.2661 |     41.510 |   1.2303 |     40.405 |     0.1
    4 |   1.1819 |     39.021 |   1.1660 |     38.879 |     0.1
    5 |   1.1032 |     36.615 |   1.1359 |     38.006 |     0.1
    6 |   1.0375 |     34.104 |   1.0788 |     36.386 |     0.1
    7 |   0.9814 |     32.045 |   1.0439 |     34.112 |     0.2
    8 |   0.9176 |     29.749 |   1.0108 |     33.022 |     0.2
    9 |   0.8627 |     27.871 |   0.9755 |     31.371 |     0.2
   10 |   0.8024 |     25.377 |   0.9624 |     30.903 |     0.2
   11 |   0.7564 |     23.775 |   0.9422 |     29.782 |     0.2
   12 |   0.7169 |     22.966 |   0.9141 |     28.505 |     0.3
   13 |   0.6682 |     21.116 |   0.8892 |     27.695 |     0.3
   14 |   0.6371 |     20.218 |   0.9259 |     28.692 |     0.3
   15 |   0.6038 |     19.045 |   0.8863 |     26.978 |     0.3
   16 |   0.5587 |     17.426 |   0.8763 |     26.449 |     0.4
   17 |   0.5286 |     16.479 |   0.8813 |     26.293 |     0.4
   18 |   0.5023 |     15.692 |   0.8852 |     26.199 |     0.4
   19 |   0.4761 |     15.130 |   0.8827 |     26.262 |     0.4
   20 |   0.4541 |     14.046 |   0.8782 |     25.888 |     0.4
   21 |   0.4431 |     14.046 |   0.8754 |     24.984 |     0.5
   22 |   0.4124 |     12.851 |   0.8888 |     24.922 |     0.5
   23 |   0.3944 |     12.267 |   0.9027 |     25.358 |     0.5
   24 |   0.3884 |     12.284 |   0.8764 |     24.735 |     0.5
   25 |   0.3722 |     11.860 |   0.9179 |     25.545 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 2,490,978

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6153 |     69.607 |   2.0495 |     59.159 |     0.1
    2 |   1.8055 |     51.107 |   1.5925 |     45.763 |     0.2
    3 |   1.5114 |     46.052 |   1.4515 |     45.763 |     0.2
    4 |   1.4370 |     46.063 |   1.4159 |     45.763 |     0.3
    5 |   1.4120 |     46.063 |   1.4040 |     45.763 |     0.4
    6 |   1.4007 |     46.096 |   1.3981 |     45.763 |     0.5
    7 |   1.3979 |     46.041 |   1.3928 |     45.763 |     0.6
    8 |   1.3925 |     46.047 |   1.3892 |     45.763 |     0.6
    9 |   1.3894 |     46.063 |   1.3853 |     45.763 |     0.7
   10 |   1.3782 |     45.683 |   1.3754 |     45.140 |     0.8
   11 |   1.3600 |     44.698 |   1.3596 |     44.891 |     0.9
   12 |   1.3471 |     44.681 |   1.3512 |     44.642 |     1.0
   13 |   1.3408 |     44.643 |   1.3425 |     44.673 |     1.0
   14 |   1.3328 |     44.566 |   1.3366 |     44.486 |     1.1
   15 |   1.3255 |     44.395 |   1.3381 |     44.299 |     1.2
   16 |   1.3242 |     44.400 |   1.3284 |     44.579 |     1.3
   17 |   1.3148 |     44.433 |   1.3203 |     44.517 |     1.4
   18 |   1.3118 |     44.109 |   1.3327 |     44.143 |     1.4
   19 |   1.3092 |     44.081 |   1.3274 |     44.735 |     1.5
   20 |   1.3005 |     44.054 |   1.3316 |     44.891 |     1.6
   21 |   1.3048 |     43.932 |   1.3155 |     43.988 |     1.7
   22 |   1.2964 |     43.800 |   1.3170 |     43.707 |     1.8
   23 |   1.2899 |     43.420 |   1.3124 |     44.050 |     1.9
   24 |   1.2795 |     43.167 |   1.3149 |     44.019 |     1.9
   25 |   1.2776 |     42.969 |   1.3066 |     42.773 |     2.0
   26 |   1.2681 |     42.963 |   1.3064 |     43.832 |     2.1
   27 |   1.2686 |     42.699 |   1.2968 |     42.991 |     2.2
   28 |   1.2721 |     42.831 |   1.3092 |     43.458 |     2.3
   29 |   1.2608 |     42.545 |   1.3054 |     43.769 |     2.3
   30 |   1.2584 |     42.727 |   1.2997 |     43.894 |     2.4
   31 |   1.2566 |     42.490 |   1.2849 |     42.928 |     2.5
   32 |   1.2572 |     42.418 |   1.3031 |     43.302 |     2.6
   33 |   1.2528 |     42.319 |   1.2741 |     42.991 |     2.7
   34 |   1.2502 |     42.132 |   1.2789 |     42.523 |     2.7
   35 |   1.2436 |     42.336 |   1.2850 |     42.928 |     2.8
   36 |   1.2392 |     41.983 |   1.2754 |     42.399 |     2.9
   37 |   1.2324 |     41.686 |   1.2822 |     42.741 |     3.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 880,610

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2656 |     61.744 |   1.6400 |     48.785 |     0.0
    2 |   1.4907 |     46.184 |   1.4202 |     45.763 |     0.0
    3 |   1.4063 |     46.063 |   1.3932 |     45.763 |     0.1
    4 |   1.3770 |     45.402 |   1.3659 |     45.763 |     0.1
    5 |   1.3393 |     44.731 |   1.3376 |     43.988 |     0.1
    6 |   1.3164 |     43.872 |   1.3175 |     43.863 |     0.1
    7 |   1.2884 |     42.875 |   1.2987 |     43.364 |     0.1
    8 |   1.2620 |     42.429 |   1.2788 |     43.302 |     0.1
    9 |   1.2329 |     41.400 |   1.2553 |     41.900 |     0.2
   10 |   1.2104 |     40.810 |   1.2408 |     41.713 |     0.2
   11 |   1.1748 |     39.985 |   1.2067 |     41.246 |     0.2
   12 |   1.1405 |     38.960 |   1.2085 |     40.779 |     0.2
   13 |   1.1197 |     38.360 |   1.1919 |     39.875 |     0.2
   14 |   1.0937 |     37.259 |   1.1678 |     39.283 |     0.2
   15 |   1.0713 |     36.400 |   1.1661 |     38.941 |     0.3
   16 |   1.0461 |     35.943 |   1.1485 |     38.723 |     0.3
   17 |   1.0108 |     34.611 |   1.1498 |     38.069 |     0.3
   18 |   0.9874 |     33.653 |   1.1467 |     37.788 |     0.3
   19 |   0.9572 |     32.673 |   1.1527 |     38.505 |     0.3
   20 |   0.9277 |     31.891 |   1.1421 |     38.069 |     0.4
   21 |   0.8989 |     30.476 |   1.1075 |     36.012 |     0.4
   22 |   0.8721 |     29.474 |   1.1151 |     36.511 |     0.4
   23 |   0.8397 |     28.372 |   1.1140 |     35.857 |     0.4
   24 |   0.8142 |     26.990 |   1.0900 |     34.891 |     0.4
   25 |   0.7782 |     26.005 |   1.0790 |     34.673 |     0.4
   26 |   0.7463 |     24.832 |   1.0904 |     34.486 |     0.5
   27 |   0.7188 |     23.995 |   1.0891 |     34.112 |     0.5
   28 |   0.6888 |     22.855 |   1.0868 |     34.361 |     0.5
   29 |   0.6578 |     21.595 |   1.0812 |     32.866 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 684,258

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3194 |     63.616 |   1.6922 |     48.785 |     0.0
    2 |   1.5130 |     46.515 |   1.4262 |     45.763 |     0.0
    3 |   1.4105 |     46.041 |   1.3978 |     45.763 |     0.0
    4 |   1.3837 |     46.047 |   1.3720 |     45.763 |     0.1
    5 |   1.3476 |     45.546 |   1.3317 |     44.642 |     0.1
    6 |   1.3156 |     45.023 |   1.3061 |     44.704 |     0.1
    7 |   1.2843 |     44.703 |   1.2784 |     44.081 |     0.1
    8 |   1.2575 |     43.239 |   1.2589 |     42.835 |     0.1
    9 |   1.2151 |     41.747 |   1.2268 |     42.617 |     0.1
   10 |   1.1875 |     40.932 |   1.2088 |     41.994 |     0.2
   11 |   1.1687 |     40.359 |   1.1801 |     39.813 |     0.2
   12 |   1.1352 |     38.801 |   1.1721 |     39.159 |     0.2
   13 |   1.1112 |     38.041 |   1.1657 |     39.065 |     0.2
   14 |   1.0804 |     36.929 |   1.1461 |     38.505 |     0.2
   15 |   1.0618 |     36.444 |   1.1421 |     38.754 |     0.2
   16 |   1.0330 |     35.552 |   1.1390 |     38.380 |     0.2
   17 |   1.0113 |     34.501 |   1.1062 |     37.944 |     0.3
   18 |   0.9829 |     33.416 |   1.0903 |     35.857 |     0.3
   19 |   0.9550 |     32.309 |   1.0903 |     36.262 |     0.3
   20 |   0.9381 |     32.183 |   1.0667 |     35.826 |     0.3
   21 |   0.9087 |     30.591 |   1.0641 |     34.829 |     0.3
   22 |   0.8859 |     29.848 |   1.0696 |     34.891 |     0.3
   23 |   0.8688 |     29.352 |   1.0598 |     33.676 |     0.3
   24 |   0.8378 |     28.389 |   1.0419 |     32.928 |     0.4
   25 |   0.8134 |     27.491 |   1.0323 |     32.773 |     0.4
   26 |   0.7953 |     26.831 |   1.0360 |     32.150 |     0.4
   27 |   0.7743 |     25.691 |   1.0435 |     32.461 |     0.4
   28 |   0.7535 |     25.206 |   1.0446 |     31.807 |     0.4
   29 |   0.7293 |     24.111 |   1.0289 |     31.931 |     0.4
   30 |   0.7103 |     23.571 |   1.0291 |     31.246 |     0.4
   31 |   0.6947 |     22.971 |   1.0245 |     30.779 |     0.5
   32 |   0.6792 |     22.431 |   1.0272 |     30.903 |     0.5
   33 |   0.6535 |     21.738 |   1.0284 |     30.093 |     0.5
   34 |   0.6402 |     20.835 |   1.0223 |     30.218 |     0.5
   35 |   0.6185 |     20.229 |   1.0177 |     29.875 |     0.5
   36 |   0.6086 |     20.130 |   1.0064 |     28.972 |     0.5
   37 |   0.5983 |     19.579 |   1.0345 |     29.595 |     0.6
   38 |   0.5774 |     18.709 |   1.0299 |     29.377 |     0.6
   39 |   0.5675 |     18.649 |   1.0231 |     29.408 |     0.6
   40 |   0.5522 |     18.219 |   1.0256 |     29.439 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,260,194

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2389 |     61.513 |   1.6555 |     45.763 |     0.0
    2 |   1.5021 |     46.074 |   1.4239 |     45.763 |     0.1
    3 |   1.3980 |     45.815 |   1.3738 |     45.047 |     0.1
    4 |   1.3394 |     44.136 |   1.3192 |     43.053 |     0.1
    5 |   1.2918 |     43.255 |   1.2936 |     43.209 |     0.2
    6 |   1.2422 |     41.945 |   1.2637 |     42.741 |     0.2
    7 |   1.2142 |     40.844 |   1.2181 |     41.028 |     0.2
    8 |   1.1688 |     39.368 |   1.1918 |     40.218 |     0.3
    9 |   1.1266 |     38.168 |   1.1909 |     40.000 |     0.3
   10 |   1.0950 |     37.017 |   1.1540 |     39.502 |     0.3
   11 |   1.0593 |     35.844 |   1.1221 |     37.508 |     0.3
   12 |   1.0190 |     34.506 |   1.1068 |     36.791 |     0.4
   13 |   0.9815 |     33.097 |   1.1122 |     36.978 |     0.4
   14 |   0.9445 |     31.693 |   1.0645 |     35.421 |     0.4
   15 |   0.9125 |     30.266 |   1.0364 |     33.520 |     0.5
   16 |   0.8742 |     29.209 |   1.0440 |     33.551 |     0.5
   17 |   0.8411 |     27.904 |   1.0150 |     32.928 |     0.5
   18 |   0.8114 |     26.677 |   1.0064 |     32.150 |     0.6
   19 |   0.7787 |     25.504 |   0.9952 |     32.150 |     0.6
   20 |   0.7418 |     24.298 |   1.0034 |     31.464 |     0.6
   21 |   0.7061 |     23.202 |   0.9863 |     30.717 |     0.7
   22 |   0.6772 |     22.007 |   0.9825 |     30.623 |     0.7
   23 |   0.6510 |     21.253 |   0.9781 |     30.187 |     0.7
   24 |   0.6180 |     20.113 |   0.9602 |     29.875 |     0.8
   25 |   0.5901 |     19.238 |   0.9733 |     29.408 |     0.8
   26 |   0.5754 |     18.869 |   0.9648 |     29.221 |     0.8
   27 |   0.5442 |     17.542 |   0.9782 |     29.190 |     0.8
   28 |   0.5069 |     16.430 |   0.9827 |     29.377 |     0.9
   29 |   0.4843 |     15.681 |   0.9480 |     28.567 |     0.9
   30 |   0.4522 |     14.382 |   0.9789 |     28.629 |     0.9
   31 |   0.4335 |     14.112 |   1.0102 |     28.224 |     1.0
   32 |   0.4229 |     13.677 |   0.9976 |     28.380 |     1.0
   33 |   0.3980 |     12.653 |   1.0188 |     29.065 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,080,674

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4866 |     65.780 |   2.0041 |     56.573 |     0.0
    2 |   1.7802 |     50.358 |   1.5819 |     45.763 |     0.1
    3 |   1.5020 |     46.063 |   1.4435 |     45.327 |     0.1
    4 |   1.4151 |     45.336 |   1.3885 |     44.829 |     0.2
    5 |   1.3698 |     44.202 |   1.3574 |     43.769 |     0.2
    6 |   1.3374 |     43.817 |   1.3338 |     44.174 |     0.2
    7 |   1.3107 |     43.321 |   1.3195 |     43.489 |     0.3
    8 |   1.2912 |     42.688 |   1.2968 |     42.866 |     0.3
    9 |   1.2661 |     41.989 |   1.2799 |     42.804 |     0.4
   10 |   1.2380 |     40.937 |   1.2529 |     41.433 |     0.4
   11 |   1.2094 |     40.359 |   1.2399 |     40.966 |     0.4
   12 |   1.1843 |     39.566 |   1.2271 |     41.215 |     0.5
   13 |   1.1561 |     38.960 |   1.2036 |     40.218 |     0.5
   14 |   1.1297 |     37.969 |   1.1884 |     39.595 |     0.6
   15 |   1.1011 |     36.714 |   1.1762 |     38.411 |     0.6
   16 |   1.0963 |     36.830 |   1.1978 |     39.377 |     0.6
   17 |   1.0798 |     35.850 |   1.1593 |     38.847 |     0.7
   18 |   1.0488 |     34.627 |   1.1419 |     37.850 |     0.7
   19 |   1.0325 |     34.209 |   1.1362 |     37.227 |     0.8
   20 |   1.0056 |     32.887 |   1.1228 |     36.916 |     0.8
   21 |   0.9913 |     32.579 |   1.1099 |     37.632 |     0.8
   22 |   0.9690 |     31.830 |   1.1116 |     37.414 |     0.9
   23 |   0.9468 |     31.120 |   1.0968 |     36.636 |     0.9
   24 |   0.9308 |     30.509 |   1.0912 |     35.389 |     1.0
   25 |   0.9108 |     29.980 |   1.0781 |     35.109 |     1.0
   26 |   0.8922 |     29.204 |   1.0709 |     34.673 |     1.0
   27 |   0.8766 |     28.675 |   1.0713 |     34.611 |     1.1
   28 |   0.8646 |     28.427 |   1.0596 |     33.769 |     1.1
   29 |   0.8471 |     27.596 |   1.0452 |     33.520 |     1.2
   30 |   0.8349 |     27.090 |   1.0484 |     34.673 |     1.2
   31 |   0.8216 |     26.704 |   1.0478 |     33.302 |     1.2
   32 |   0.8008 |     26.131 |   1.0514 |     33.801 |     1.3
   33 |   0.7888 |     25.796 |   1.0400 |     33.676 |     1.3
   34 |   0.7706 |     25.019 |   1.0600 |     33.645 |     1.4
   35 |   0.7612 |     24.827 |   1.0321 |     32.430 |     1.4
   36 |   0.7505 |     24.557 |   1.0410 |     33.240 |     1.4
   37 |   0.7410 |     24.155 |   1.0371 |     32.399 |     1.5
   38 |   0.7225 |     23.725 |   1.0323 |     32.679 |     1.5
   39 |   0.7129 |     23.048 |   1.0328 |     32.710 |     1.6
   40 |   0.7052 |     22.993 |   1.0282 |     32.741 |     1.6
   41 |   0.6858 |     22.134 |   1.0470 |     31.277 |     1.6
   42 |   0.6783 |     22.085 |   1.0329 |     32.710 |     1.7
   43 |   0.6621 |     21.292 |   1.0347 |     31.838 |     1.7
   44 |   0.6572 |     21.077 |   1.0299 |     31.651 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 767,234

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3182 |     61.717 |   1.6978 |     48.847 |     0.0
    2 |   1.5101 |     46.625 |   1.4340 |     45.763 |     0.0
    3 |   1.4039 |     45.937 |   1.3928 |     46.698 |     0.1
    4 |   1.3696 |     45.628 |   1.3485 |     44.984 |     0.1
    5 |   1.3119 |     43.701 |   1.3058 |     43.769 |     0.1
    6 |   1.2731 |     43.332 |   1.2722 |     43.769 |     0.1
    7 |   1.2317 |     41.851 |   1.2424 |     41.869 |     0.1
    8 |   1.1940 |     40.425 |   1.2104 |     40.467 |     0.2
    9 |   1.1629 |     39.208 |   1.1956 |     40.685 |     0.2
   10 |   1.1348 |     38.399 |   1.1856 |     39.097 |     0.2
   11 |   1.1028 |     37.055 |   1.1650 |     38.723 |     0.2
   12 |   1.0714 |     35.784 |   1.1613 |     38.660 |     0.2
   13 |   1.0480 |     35.315 |   1.1381 |     38.349 |     0.3
   14 |   1.0181 |     34.413 |   1.1346 |     37.414 |     0.3
   15 |   0.9888 |     33.113 |   1.1533 |     37.539 |     0.3
   16 |   0.9681 |     32.574 |   1.1028 |     36.168 |     0.3
   17 |   0.9471 |     32.001 |   1.1013 |     36.262 |     0.3
   18 |   0.9183 |     30.635 |   1.0852 |     34.735 |     0.3
   19 |   0.8905 |     29.732 |   1.0912 |     35.389 |     0.4
   20 |   0.8709 |     28.818 |   1.0840 |     34.424 |     0.4
   21 |   0.8509 |     28.152 |   1.0723 |     33.801 |     0.4
   22 |   0.8178 |     27.056 |   1.0744 |     34.112 |     0.4
   23 |   0.8009 |     26.555 |   1.0796 |     34.268 |     0.4
   24 |   0.7775 |     25.735 |   1.0666 |     33.271 |     0.5
   25 |   0.7585 |     25.096 |   1.0728 |     34.174 |     0.5
   26 |   0.7283 |     24.221 |   1.0604 |     32.960 |     0.5
   27 |   0.7109 |     23.527 |   1.0509 |     31.963 |     0.5
   28 |   0.6982 |     22.921 |   1.0667 |     32.087 |     0.5
   29 |   0.6614 |     21.732 |   1.0685 |     31.838 |     0.6
   30 |   0.6393 |     20.983 |   1.0535 |     31.090 |     0.6
   31 |   0.6222 |     20.317 |   1.0710 |     31.526 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 425,826

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5999 |     70.537 |   2.0154 |     59.159 |     0.0
    2 |   1.7734 |     50.485 |   1.5882 |     46.791 |     0.0
    3 |   1.5070 |     46.036 |   1.4564 |     45.763 |     0.1
    4 |   1.4376 |     46.036 |   1.4214 |     45.763 |     0.1
    5 |   1.4138 |     46.019 |   1.4070 |     45.763 |     0.1
    6 |   1.4003 |     45.964 |   1.3961 |     45.576 |     0.1
    7 |   1.3884 |     45.843 |   1.3852 |     45.794 |     0.1
    8 |   1.3763 |     45.876 |   1.3765 |     45.452 |     0.2
    9 |   1.3572 |     45.414 |   1.3585 |     44.891 |     0.2
   10 |   1.3366 |     44.654 |   1.3359 |     44.143 |     0.2
   11 |   1.3175 |     44.301 |   1.3172 |     43.956 |     0.2
   12 |   1.2932 |     43.261 |   1.3041 |     42.773 |     0.2
   13 |   1.2696 |     42.231 |   1.2810 |     42.056 |     0.3
   14 |   1.2421 |     41.190 |   1.2691 |     42.181 |     0.3
   15 |   1.2293 |     41.240 |   1.2609 |     42.336 |     0.3
   16 |   1.2038 |     40.508 |   1.2353 |     41.495 |     0.3
   17 |   1.1864 |     40.315 |   1.2316 |     41.090 |     0.4
   18 |   1.1643 |     39.610 |   1.2204 |     41.121 |     0.4
   19 |   1.1479 |     39.236 |   1.2095 |     40.841 |     0.4
   20 |   1.1302 |     39.065 |   1.2059 |     41.558 |     0.4
   21 |   1.1144 |     38.311 |   1.1932 |     40.156 |     0.4
   22 |   1.0978 |     37.854 |   1.1923 |     39.688 |     0.5
   23 |   1.0724 |     36.907 |   1.1810 |     39.564 |     0.5
   24 |   1.0545 |     35.828 |   1.1790 |     39.470 |     0.5
   25 |   1.0388 |     35.580 |   1.1638 |     39.034 |     0.5
   26 |   1.0296 |     34.980 |   1.1901 |     40.187 |     0.5
   27 |   1.0212 |     34.649 |   1.1677 |     38.972 |     0.6
   28 |   0.9876 |     33.658 |   1.1645 |     38.629 |     0.6
   29 |   0.9777 |     33.383 |   1.1567 |     38.193 |     0.6
   30 |   0.9540 |     32.216 |   1.1566 |     37.882 |     0.6
   31 |   0.9535 |     32.397 |   1.1496 |     37.383 |     0.6
   32 |   0.9348 |     31.676 |   1.1565 |     38.785 |     0.7
   33 |   0.9097 |     30.503 |   1.1565 |     36.978 |     0.7
   34 |   0.8962 |     29.947 |   1.1250 |     36.075 |     0.7
   35 |   0.8767 |     29.380 |   1.1450 |     36.137 |     0.7
   36 |   0.8557 |     28.741 |   1.1471 |     36.293 |     0.7
   37 |   0.8432 |     28.070 |   1.1471 |     35.950 |     0.8
   38 |   0.8200 |     26.990 |   1.1537 |     36.324 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 231,650

Training started
X_train.shape: torch.Size([3027, 702])
Y_train.shape: torch.Size([3027, 7])
X_dev.shape: torch.Size([535, 258])
Y_dev.shape: torch.Size([535, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5831 |     68.357 |   2.0083 |     59.065 |     0.0
    2 |   1.7790 |     50.121 |   1.5878 |     45.763 |     0.0
    3 |   1.5134 |     46.036 |   1.4634 |     45.763 |     0.0
    4 |   1.4423 |     46.080 |   1.4217 |     45.763 |     0.1
    5 |   1.4159 |     46.063 |   1.4030 |     45.763 |     0.1
    6 |   1.3948 |     45.854 |   1.3849 |     44.953 |     0.1
    7 |   1.3716 |     45.430 |   1.3560 |     44.766 |     0.1
    8 |   1.3436 |     44.059 |   1.3304 |     43.925 |     0.1
    9 |   1.3189 |     43.652 |   1.3153 |     43.769 |     0.1
   10 |   1.2929 |     42.716 |   1.2883 |     42.243 |     0.1
   11 |   1.2633 |     41.521 |   1.2701 |     42.461 |     0.2
   12 |   1.2401 |     40.833 |   1.2546 |     41.402 |     0.2
   13 |   1.2176 |     40.453 |   1.2438 |     41.028 |     0.2
   14 |   1.1932 |     39.676 |   1.2214 |     40.498 |     0.2
   15 |   1.1721 |     39.043 |   1.2090 |     39.439 |     0.2
   16 |   1.1540 |     38.663 |   1.1963 |     39.813 |     0.2
   17 |   1.1307 |     37.881 |   1.1963 |     39.346 |     0.2
   18 |   1.1140 |     37.540 |   1.1844 |     39.751 |     0.2
   19 |   1.0923 |     36.769 |   1.1856 |     39.688 |     0.3
   20 |   1.0750 |     36.307 |   1.1752 |     39.252 |     0.3
   21 |   1.0486 |     35.321 |   1.1544 |     39.034 |     0.3
   22 |   1.0312 |     34.858 |   1.1597 |     38.692 |     0.3
   23 |   1.0100 |     34.352 |   1.1502 |     37.882 |     0.3
   24 |   1.0020 |     33.565 |   1.1382 |     37.757 |     0.3
   25 |   0.9747 |     32.562 |   1.1255 |     36.231 |     0.3
   26 |   0.9516 |     31.918 |   1.1311 |     36.604 |     0.4
   27 |   0.9355 |     31.087 |   1.1142 |     36.012 |     0.4
   28 |   0.9090 |     30.134 |   1.1193 |     36.137 |     0.4
   29 |   0.8889 |     29.589 |   1.1155 |     35.576 |     0.4
   30 |   0.8722 |     28.951 |   1.1022 |     34.860 |     0.4
   31 |   0.8502 |     28.042 |   1.1094 |     34.766 |     0.4
   32 |   0.8296 |     27.222 |   1.1038 |     34.455 |     0.4
   33 |   0.8139 |     26.622 |   1.0969 |     33.769 |     0.5
   34 |   0.7978 |     26.131 |   1.0904 |     33.458 |     0.5
   35 |   0.7751 |     25.438 |   1.1026 |     33.925 |     0.5
   36 |   0.7683 |     25.146 |   1.1034 |     33.583 |     0.5
   37 |   0.7435 |     24.232 |   1.0849 |     31.931 |     0.5
   38 |   0.7234 |     23.450 |   1.0612 |     31.558 |     0.5
   39 |   0.7109 |     23.263 |   1.0716 |     31.994 |     0.5
   40 |   0.7061 |     22.927 |   1.0676 |     31.713 |     0.6
   41 |   0.6859 |     21.826 |   1.0626 |     32.181 |     0.6
   42 |   0.6776 |     21.870 |   1.0769 |     31.371 |     0.6
Early stopping

