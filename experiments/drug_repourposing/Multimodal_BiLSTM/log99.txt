Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,522,978

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2186 |     59.875 |   1.6244 |     45.897 |     0.0
    2 |   1.4924 |     46.193 |   1.4179 |     46.533 |     0.1
    3 |   1.4115 |     46.248 |   1.3872 |     45.802 |     0.1
    4 |   1.3948 |     46.171 |   1.3797 |     45.802 |     0.2
    5 |   1.3816 |     46.215 |   1.3720 |     45.802 |     0.2
    6 |   1.3633 |     45.622 |   1.3425 |     44.052 |     0.2
    7 |   1.3373 |     44.607 |   1.3192 |     44.211 |     0.3
    8 |   1.3188 |     44.141 |   1.3049 |     43.098 |     0.3
    9 |   1.2981 |     43.175 |   1.2860 |     41.921 |     0.3
   10 |   1.2776 |     42.533 |   1.2640 |     41.858 |     0.4
   11 |   1.2563 |     41.793 |   1.2444 |     41.126 |     0.4
   12 |   1.2356 |     40.882 |   1.2400 |     40.712 |     0.5
   13 |   1.2157 |     40.608 |   1.2165 |     40.426 |     0.5
   14 |   1.1854 |     39.439 |   1.2087 |     40.140 |     0.5
   15 |   1.1628 |     39.181 |   1.1831 |     39.122 |     0.6
   16 |   1.1295 |     37.859 |   1.1629 |     38.200 |     0.6
   17 |   1.1006 |     37.311 |   1.1348 |     38.391 |     0.7
   18 |   1.0706 |     36.054 |   1.1198 |     36.546 |     0.7
   19 |   1.0406 |     34.623 |   1.0998 |     36.609 |     0.7
   20 |   1.0215 |     34.195 |   1.0856 |     35.623 |     0.8
   21 |   0.9949 |     33.465 |   1.0854 |     35.051 |     0.8
   22 |   0.9581 |     32.061 |   1.0780 |     34.733 |     0.9
   23 |   0.9259 |     30.843 |   1.0546 |     34.319 |     0.9
   24 |   0.8969 |     29.691 |   1.0414 |     33.620 |     0.9
   25 |   0.8735 |     29.005 |   1.0603 |     34.192 |     1.0
   26 |   0.8502 |     28.154 |   1.0608 |     34.160 |     1.0
   27 |   0.8303 |     27.518 |   1.0368 |     32.634 |     1.1
   28 |   0.7955 |     26.328 |   1.0293 |     32.888 |     1.1
   29 |   0.7541 |     24.687 |   1.0233 |     30.821 |     1.1
   30 |   0.7260 |     23.645 |   1.0468 |     31.997 |     1.2
   31 |   0.6990 |     22.767 |   1.0046 |     30.630 |     1.2
   32 |   0.6643 |     21.363 |   1.0318 |     30.630 |     1.3
   33 |   0.6497 |     21.105 |   1.0244 |     30.184 |     1.3
   34 |   0.6288 |     20.447 |   1.0404 |     31.266 |     1.3
   35 |   0.5974 |     19.174 |   1.0312 |     29.866 |     1.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 782,786

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2928 |     62.344 |   1.6751 |     48.919 |     0.0
    2 |   1.5040 |     46.330 |   1.4164 |     46.533 |     0.0
    3 |   1.4028 |     46.215 |   1.3772 |     45.706 |     0.1
    4 |   1.3582 |     45.200 |   1.3336 |     45.165 |     0.1
    5 |   1.3118 |     44.053 |   1.2700 |     42.780 |     0.1
    6 |   1.2549 |     42.852 |   1.2303 |     42.971 |     0.1
    7 |   1.2124 |     41.453 |   1.2033 |     40.331 |     0.1
    8 |   1.1730 |     40.218 |   1.1614 |     39.440 |     0.1
    9 |   1.1357 |     38.386 |   1.1423 |     38.677 |     0.2
   10 |   1.0919 |     36.801 |   1.1219 |     37.977 |     0.2
   11 |   1.0509 |     35.473 |   1.1124 |     36.864 |     0.2
   12 |   1.0129 |     34.079 |   1.1022 |     36.896 |     0.2
   13 |   0.9776 |     33.015 |   1.0699 |     34.860 |     0.2
   14 |   0.9338 |     31.474 |   1.0757 |     34.637 |     0.2
   15 |   0.8960 |     29.784 |   1.0839 |     34.669 |     0.3
   16 |   0.8696 |     29.433 |   1.0907 |     33.810 |     0.3
   17 |   0.8335 |     27.754 |   1.0622 |     33.302 |     0.3
   18 |   0.8073 |     26.942 |   1.0541 |     32.665 |     0.3
   19 |   0.7728 |     25.510 |   1.0503 |     32.284 |     0.3
   20 |   0.7372 |     24.029 |   1.0290 |     30.948 |     0.3
   21 |   0.7028 |     23.041 |   1.0281 |     31.011 |     0.4
   22 |   0.6767 |     21.697 |   1.0442 |     30.280 |     0.4
   23 |   0.6483 |     21.006 |   1.0764 |     31.489 |     0.4
   24 |   0.6330 |     20.200 |   1.0718 |     30.948 |     0.4
   25 |   0.6033 |     18.993 |   1.0385 |     29.676 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 1,569,186

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2834 |     62.086 |   1.6617 |     48.919 |     0.0
    2 |   1.5051 |     46.346 |   1.4230 |     45.802 |     0.1
    3 |   1.4110 |     46.275 |   1.3900 |     45.802 |     0.1
    4 |   1.3965 |     46.154 |   1.3858 |     45.802 |     0.2
    5 |   1.3909 |     46.193 |   1.3805 |     45.802 |     0.2
    6 |   1.3858 |     46.176 |   1.3761 |     45.802 |     0.2
    7 |   1.3809 |     45.946 |   1.3664 |     45.547 |     0.3
    8 |   1.3576 |     44.876 |   1.3438 |     44.370 |     0.3
    9 |   1.3391 |     44.728 |   1.3286 |     44.084 |     0.4
   10 |   1.3242 |     44.294 |   1.3106 |     43.511 |     0.4
   11 |   1.3102 |     44.048 |   1.3064 |     43.543 |     0.4
   12 |   1.2944 |     43.466 |   1.2788 |     43.034 |     0.5
   13 |   1.2799 |     43.027 |   1.2695 |     42.207 |     0.5
   14 |   1.2679 |     42.539 |   1.2711 |     42.462 |     0.5
   15 |   1.2595 |     42.363 |   1.2554 |     41.158 |     0.6
   16 |   1.2501 |     42.051 |   1.2556 |     42.239 |     0.6
   17 |   1.2390 |     41.908 |   1.2415 |     41.698 |     0.7
   18 |   1.2260 |     41.398 |   1.2414 |     40.903 |     0.7
   19 |   1.2105 |     40.783 |   1.2264 |     40.267 |     0.7
   20 |   1.2003 |     40.471 |   1.2126 |     40.553 |     0.8
   21 |   1.1827 |     39.928 |   1.2108 |     39.695 |     0.8
   22 |   1.1650 |     39.653 |   1.2091 |     40.045 |     0.9
   23 |   1.1615 |     38.968 |   1.1942 |     39.854 |     0.9
   24 |   1.1475 |     39.066 |   1.1788 |     38.740 |     0.9
   25 |   1.1355 |     38.282 |   1.1819 |     39.313 |     1.0
   26 |   1.1155 |     37.854 |   1.1653 |     38.263 |     1.0
   27 |   1.1146 |     37.662 |   1.1669 |     37.691 |     1.1
   28 |   1.0896 |     36.658 |   1.1414 |     37.150 |     1.1
   29 |   1.0797 |     36.257 |   1.1768 |     39.758 |     1.1
   30 |   1.0662 |     35.945 |   1.1496 |     37.277 |     1.2
   31 |   1.0421 |     34.919 |   1.1683 |     38.168 |     1.2
   32 |   1.0420 |     34.913 |   1.1483 |     37.182 |     1.3
   33 |   1.0186 |     33.833 |   1.1341 |     37.055 |     1.3
   34 |   1.0076 |     33.860 |   1.1211 |     36.768 |     1.3
   35 |   0.9834 |     33.136 |   1.1202 |     36.832 |     1.4
   36 |   0.9730 |     32.757 |   1.1223 |     36.387 |     1.4
   37 |   0.9539 |     32.022 |   1.1356 |     36.514 |     1.5
   38 |   0.9389 |     31.496 |   1.1265 |     36.101 |     1.5
   39 |   0.9216 |     31.007 |   1.1334 |     35.846 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,141,730

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5334 |     68.576 |   1.9985 |     58.810 |     0.0
    2 |   1.7613 |     50.170 |   1.5724 |     45.802 |     0.1
    3 |   1.4968 |     46.105 |   1.4419 |     45.802 |     0.1
    4 |   1.4283 |     46.154 |   1.4060 |     45.802 |     0.2
    5 |   1.4037 |     46.193 |   1.3921 |     45.674 |     0.2
    6 |   1.3835 |     45.990 |   1.3603 |     45.515 |     0.2
    7 |   1.3612 |     45.386 |   1.3529 |     44.561 |     0.3
    8 |   1.3282 |     43.801 |   1.3038 |     43.321 |     0.3
    9 |   1.2971 |     43.142 |   1.2788 |     43.384 |     0.3
   10 |   1.2698 |     42.802 |   1.2450 |     42.557 |     0.4
   11 |   1.2377 |     41.826 |   1.2399 |     42.430 |     0.4
   12 |   1.2234 |     41.162 |   1.2076 |     40.458 |     0.5
   13 |   1.1871 |     40.059 |   1.1974 |     40.999 |     0.5
   14 |   1.1685 |     39.445 |   1.1854 |     39.249 |     0.5
   15 |   1.1467 |     38.803 |   1.1561 |     39.440 |     0.6
   16 |   1.1211 |     37.629 |   1.1355 |     37.691 |     0.6
   17 |   1.1034 |     37.020 |   1.1378 |     38.136 |     0.7
   18 |   1.0755 |     36.537 |   1.1261 |     37.850 |     0.7
   19 |   1.0559 |     35.906 |   1.1013 |     36.768 |     0.7
   20 |   1.0358 |     34.853 |   1.1156 |     36.896 |     0.8
   21 |   1.0278 |     34.655 |   1.1060 |     36.387 |     0.8
   22 |   1.0105 |     33.909 |   1.0761 |     35.337 |     0.8
   23 |   0.9764 |     32.807 |   1.0847 |     35.433 |     0.9
   24 |   0.9573 |     31.567 |   1.0736 |     35.146 |     0.9
   25 |   0.9366 |     30.908 |   1.0649 |     34.892 |     1.0
   26 |   0.9124 |     30.195 |   1.0725 |     34.065 |     1.0
   27 |   0.8940 |     29.202 |   1.0606 |     34.637 |     1.0
   28 |   0.8829 |     29.213 |   1.0574 |     33.365 |     1.1
   29 |   0.8626 |     28.248 |   1.0400 |     32.983 |     1.1
   30 |   0.8452 |     27.578 |   1.0343 |     32.347 |     1.2
   31 |   0.8337 |     27.315 |   1.0356 |     33.524 |     1.2
   32 |   0.8088 |     26.426 |   1.0264 |     32.061 |     1.2
   33 |   0.8059 |     26.059 |   1.0580 |     32.411 |     1.3
   34 |   0.7927 |     25.850 |   1.0218 |     31.838 |     1.3
   35 |   0.7599 |     24.462 |   1.0264 |     31.361 |     1.3
   36 |   0.7359 |     23.837 |   1.0088 |     31.266 |     1.4
   37 |   0.7069 |     22.537 |   1.0260 |     31.139 |     1.4
   38 |   0.6893 |     22.136 |   1.0028 |     30.375 |     1.5
   39 |   0.6827 |     22.147 |   1.0082 |     30.375 |     1.5
   40 |   0.6682 |     21.599 |   1.0170 |     30.662 |     1.5
   41 |   0.6634 |     21.604 |   1.0095 |     30.852 |     1.6
   42 |   0.6264 |     20.013 |   1.0080 |     29.485 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 834,658

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3033 |     62.667 |   1.6738 |     48.919 |     0.0
    2 |   1.5112 |     46.335 |   1.4233 |     45.802 |     0.0
    3 |   1.4113 |     46.061 |   1.3921 |     46.565 |     0.1
    4 |   1.3922 |     46.182 |   1.3681 |     45.802 |     0.1
    5 |   1.3682 |     45.474 |   1.3444 |     45.388 |     0.1
    6 |   1.3409 |     44.755 |   1.3223 |     44.434 |     0.1
    7 |   1.3211 |     44.624 |   1.3041 |     43.639 |     0.2
    8 |   1.2977 |     43.598 |   1.2843 |     43.352 |     0.2
    9 |   1.2778 |     42.912 |   1.2638 |     42.017 |     0.2
   10 |   1.2517 |     42.056 |   1.2517 |     41.476 |     0.2
   11 |   1.2339 |     41.530 |   1.2312 |     40.363 |     0.2
   12 |   1.2064 |     40.542 |   1.2118 |     40.712 |     0.3
   13 |   1.1825 |     39.939 |   1.2028 |     40.204 |     0.3
   14 |   1.1570 |     39.428 |   1.1885 |     40.553 |     0.3
   15 |   1.1346 |     38.540 |   1.1853 |     40.235 |     0.3
   16 |   1.1083 |     37.596 |   1.1707 |     39.631 |     0.4
   17 |   1.0763 |     36.548 |   1.1510 |     38.200 |     0.4
   18 |   1.0479 |     35.374 |   1.1316 |     37.723 |     0.4
   19 |   1.0122 |     33.997 |   1.1192 |     37.118 |     0.4
   20 |   0.9836 |     33.240 |   1.1031 |     36.737 |     0.4
   21 |   0.9472 |     31.989 |   1.1100 |     37.150 |     0.5
   22 |   0.9100 |     29.954 |   1.0873 |     35.687 |     0.5
   23 |   0.8769 |     29.263 |   1.0827 |     35.655 |     0.5
   24 |   0.8533 |     28.215 |   1.0819 |     34.606 |     0.5
   25 |   0.8187 |     26.750 |   1.0954 |     35.369 |     0.6
   26 |   0.7929 |     26.174 |   1.0867 |     34.542 |     0.6
   27 |   0.7622 |     25.055 |   1.0914 |     34.065 |     0.6
   28 |   0.7321 |     24.045 |   1.0793 |     33.715 |     0.6
   29 |   0.6940 |     22.685 |   1.0883 |     33.142 |     0.6
   30 |   0.6728 |     22.131 |   1.0843 |     32.729 |     0.7
   31 |   0.6509 |     21.072 |   1.0982 |     31.870 |     0.7
   32 |   0.6118 |     19.882 |   1.0848 |     31.807 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,243,362

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2535 |     61.806 |   1.6374 |     45.802 |     0.0
    2 |   1.4993 |     46.171 |   1.4217 |     46.533 |     0.1
    3 |   1.4143 |     46.248 |   1.3957 |     46.533 |     0.1
    4 |   1.3946 |     46.187 |   1.3749 |     45.802 |     0.2
    5 |   1.3776 |     45.831 |   1.3548 |     44.179 |     0.2
    6 |   1.3538 |     44.947 |   1.3360 |     45.324 |     0.2
    7 |   1.3375 |     44.646 |   1.3376 |     44.688 |     0.3
    8 |   1.3301 |     44.470 |   1.3107 |     43.830 |     0.3
    9 |   1.3138 |     44.031 |   1.2955 |     43.543 |     0.3
   10 |   1.3041 |     43.916 |   1.2896 |     41.921 |     0.4
   11 |   1.2878 |     43.384 |   1.2709 |     42.239 |     0.4
   12 |   1.2797 |     43.099 |   1.2701 |     42.366 |     0.5
   13 |   1.2669 |     42.715 |   1.2638 |     41.985 |     0.5
   14 |   1.2573 |     42.424 |   1.2618 |     41.826 |     0.5
   15 |   1.2467 |     42.040 |   1.2470 |     41.253 |     0.6
   16 |   1.2356 |     41.711 |   1.2404 |     41.349 |     0.6
   17 |   1.2209 |     41.277 |   1.2271 |     40.808 |     0.6
   18 |   1.2122 |     40.855 |   1.2209 |     40.872 |     0.7
   19 |   1.1954 |     40.262 |   1.2199 |     40.808 |     0.7
   20 |   1.1796 |     40.476 |   1.2093 |     40.331 |     0.8
   21 |   1.1700 |     39.928 |   1.1957 |     39.822 |     0.8
   22 |   1.1529 |     39.264 |   1.1941 |     38.836 |     0.8
   23 |   1.1415 |     38.402 |   1.1781 |     38.709 |     0.9
   24 |   1.1245 |     37.991 |   1.1750 |     38.486 |     0.9
   25 |   1.1127 |     37.580 |   1.1581 |     37.913 |     0.9
   26 |   1.0818 |     36.488 |   1.1388 |     36.864 |     1.0
   27 |   1.0696 |     36.071 |   1.1224 |     36.196 |     1.0
   28 |   1.0502 |     35.144 |   1.1139 |     36.005 |     1.1
   29 |   1.0311 |     34.420 |   1.1102 |     36.005 |     1.1
   30 |   1.0185 |     34.085 |   1.0791 |     34.987 |     1.1
   31 |   0.9915 |     33.251 |   1.0809 |     35.464 |     1.2
   32 |   0.9827 |     33.086 |   1.0794 |     34.955 |     1.2
   33 |   0.9600 |     32.181 |   1.0648 |     34.097 |     1.2
   34 |   0.9473 |     31.945 |   1.0743 |     33.747 |     1.3
   35 |   0.9238 |     31.249 |   1.0616 |     33.651 |     1.3
   36 |   0.9060 |     30.431 |   1.0592 |     33.524 |     1.4
   37 |   0.8890 |     29.773 |   1.0486 |     32.952 |     1.4
   38 |   0.8735 |     29.444 |   1.0444 |     33.365 |     1.4
   39 |   0.8469 |     28.571 |   1.0225 |     32.252 |     1.5
   40 |   0.8289 |     28.083 |   1.0464 |     32.443 |     1.5
   41 |   0.8235 |     27.584 |   1.0269 |     32.093 |     1.5
   42 |   0.8070 |     27.002 |   1.0322 |     32.125 |     1.6
   43 |   0.7919 |     26.690 |   1.0355 |     32.411 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 2,995,938

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2845 |     61.115 |   1.6593 |     48.919 |     0.1
    2 |   1.5005 |     46.489 |   1.4180 |     46.533 |     0.2
    3 |   1.4101 |     46.297 |   1.3931 |     45.802 |     0.2
    4 |   1.3974 |     46.248 |   1.3829 |     45.802 |     0.3
    5 |   1.3914 |     46.302 |   1.3806 |     45.802 |     0.4
    6 |   1.3847 |     46.061 |   1.3761 |     46.533 |     0.5
    7 |   1.3770 |     45.617 |   1.3673 |     45.674 |     0.6
    8 |   1.3582 |     44.942 |   1.3404 |     44.148 |     0.7
    9 |   1.3469 |     44.964 |   1.3256 |     44.243 |     0.7
   10 |   1.3331 |     44.613 |   1.3196 |     44.211 |     0.8
   11 |   1.3312 |     44.794 |   1.3189 |     43.925 |     0.9
   12 |   1.3192 |     44.218 |   1.2962 |     43.003 |     1.0
   13 |   1.3085 |     43.812 |   1.2954 |     43.066 |     1.1
   14 |   1.2973 |     43.532 |   1.2819 |     42.812 |     1.2
   15 |   1.2899 |     43.230 |   1.2764 |     42.780 |     1.3
   16 |   1.2782 |     42.923 |   1.2609 |     41.889 |     1.3
   17 |   1.2782 |     42.967 |   1.2607 |     42.271 |     1.4
   18 |   1.2638 |     42.555 |   1.2467 |     41.603 |     1.5
   19 |   1.2561 |     42.336 |   1.2555 |     41.539 |     1.6
   20 |   1.2499 |     42.051 |   1.2655 |     41.985 |     1.7
   21 |   1.2486 |     42.182 |   1.2465 |     41.571 |     1.8
   22 |   1.2393 |     41.914 |   1.2368 |     40.872 |     1.8
   23 |   1.2329 |     41.656 |   1.2242 |     40.394 |     1.9
   24 |   1.2229 |     41.540 |   1.2366 |     40.808 |     2.0
   25 |   1.2193 |     41.239 |   1.2248 |     40.553 |     2.1
   26 |   1.2122 |     40.970 |   1.2197 |     40.299 |     2.2
   27 |   1.2101 |     40.690 |   1.2067 |     39.790 |     2.3
   28 |   1.1965 |     40.388 |   1.2058 |     40.140 |     2.3
   29 |   1.1907 |     40.207 |   1.1965 |     39.218 |     2.4
   30 |   1.1751 |     39.555 |   1.2106 |     39.790 |     2.5
   31 |   1.1786 |     39.845 |   1.2044 |     39.885 |     2.6
   32 |   1.1679 |     39.116 |   1.1879 |     39.122 |     2.7
   33 |   1.1602 |     39.099 |   1.1942 |     39.663 |     2.8
   34 |   1.1567 |     38.978 |   1.1913 |     39.281 |     2.8
   35 |   1.1568 |     38.891 |   1.1825 |     38.868 |     2.9
   36 |   1.1369 |     38.150 |   1.1893 |     39.440 |     3.0
   37 |   1.1351 |     38.095 |   1.1735 |     39.186 |     3.1
   38 |   1.1303 |     37.996 |   1.1799 |     38.836 |     3.2
   39 |   1.1199 |     37.815 |   1.1652 |     37.945 |     3.3
   40 |   1.1093 |     37.135 |   1.1596 |     38.804 |     3.3
   41 |   1.1037 |     37.004 |   1.1520 |     37.691 |     3.4
   42 |   1.1010 |     37.174 |   1.1615 |     38.327 |     3.5
   43 |   1.0900 |     36.510 |   1.1484 |     37.913 |     3.6
   44 |   1.0803 |     36.477 |   1.1463 |     38.073 |     3.7
   45 |   1.0792 |     36.427 |   1.1502 |     38.041 |     3.8
   46 |   1.0776 |     36.214 |   1.1570 |     38.263 |     3.8
   47 |   1.0707 |     36.115 |   1.1488 |     38.327 |     3.9
   48 |   1.0698 |     36.301 |   1.1456 |     37.500 |     4.0
   49 |   1.0557 |     35.473 |   1.1223 |     37.468 |     4.1
   50 |   1.0490 |     35.561 |   1.1348 |     36.673 |     4.2
   51 |   1.0422 |     35.160 |   1.1198 |     36.768 |     4.3
   52 |   1.0446 |     35.286 |   1.1211 |     35.973 |     4.3
   53 |   1.0343 |     34.623 |   1.1196 |     36.291 |     4.4
   54 |   1.0238 |     34.804 |   1.1316 |     38.009 |     4.5
   55 |   1.0214 |     34.370 |   1.1029 |     36.260 |     4.6
   56 |   1.0040 |     33.580 |   1.1089 |     36.546 |     4.7
   57 |   0.9927 |     33.454 |   1.1183 |     36.991 |     4.8
   58 |   0.9974 |     33.871 |   1.1139 |     36.101 |     4.8
   59 |   0.9919 |     33.668 |   1.1121 |     37.150 |     4.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 836,898

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2259 |     60.297 |   1.5862 |     45.802 |     0.0
    2 |   1.4669 |     46.215 |   1.3998 |     46.533 |     0.0
    3 |   1.3851 |     46.083 |   1.3474 |     45.483 |     0.1
    4 |   1.3418 |     45.200 |   1.3207 |     45.197 |     0.1
    5 |   1.2971 |     43.878 |   1.2697 |     42.494 |     0.1
    6 |   1.2539 |     42.451 |   1.2442 |     42.080 |     0.1
    7 |   1.2234 |     41.244 |   1.2014 |     39.536 |     0.1
    8 |   1.1813 |     39.428 |   1.1686 |     38.613 |     0.2
    9 |   1.1477 |     38.825 |   1.1548 |     38.422 |     0.2
   10 |   1.1103 |     37.612 |   1.1350 |     38.263 |     0.2
   11 |   1.0714 |     36.625 |   1.1117 |     37.182 |     0.2
   12 |   1.0362 |     35.034 |   1.0808 |     36.196 |     0.2
   13 |   0.9939 |     33.383 |   1.0770 |     35.146 |     0.3
   14 |   0.9497 |     31.896 |   1.0406 |     33.015 |     0.3
   15 |   0.9135 |     30.530 |   1.0155 |     32.570 |     0.3
   16 |   0.8728 |     29.104 |   1.0032 |     32.697 |     0.3
   17 |   0.8244 |     27.452 |   1.0020 |     32.379 |     0.3
   18 |   0.7915 |     25.790 |   0.9856 |     30.884 |     0.4
   19 |   0.7557 |     24.759 |   0.9828 |     30.980 |     0.4
   20 |   0.7164 |     23.283 |   0.9649 |     29.771 |     0.4
   21 |   0.6773 |     22.142 |   0.9716 |     29.453 |     0.4
   22 |   0.6489 |     21.034 |   0.9552 |     28.403 |     0.4
   23 |   0.6140 |     19.766 |   0.9757 |     29.071 |     0.5
   24 |   0.5779 |     18.570 |   0.9777 |     28.181 |     0.5
   25 |   0.5555 |     17.956 |   0.9533 |     28.244 |     0.5
   26 |   0.5299 |     16.925 |   0.9725 |     28.403 |     0.5
   27 |   0.5051 |     16.041 |   0.9618 |     27.926 |     0.6
   28 |   0.4702 |     15.114 |   0.9724 |     26.972 |     0.6
   29 |   0.4553 |     14.582 |   0.9789 |     27.354 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 710,658

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5576 |     68.899 |   1.9923 |     58.810 |     0.0
    2 |   1.7876 |     50.280 |   1.5916 |     45.802 |     0.1
    3 |   1.5122 |     46.198 |   1.4555 |     45.802 |     0.1
    4 |   1.4365 |     46.176 |   1.4131 |     45.802 |     0.1
    5 |   1.4125 |     46.231 |   1.4000 |     45.833 |     0.1
    6 |   1.4011 |     46.182 |   1.3871 |     45.802 |     0.2
    7 |   1.3926 |     46.077 |   1.3843 |     45.802 |     0.2
    8 |   1.3860 |     46.116 |   1.3722 |     45.802 |     0.2
    9 |   1.3751 |     46.001 |   1.3609 |     45.229 |     0.2
   10 |   1.3604 |     45.414 |   1.3430 |     44.847 |     0.3
   11 |   1.3490 |     45.260 |   1.3266 |     45.324 |     0.3
   12 |   1.3349 |     44.975 |   1.3151 |     44.275 |     0.3
   13 |   1.3245 |     44.898 |   1.3041 |     44.148 |     0.3
   14 |   1.3089 |     44.338 |   1.2914 |     42.525 |     0.4
   15 |   1.2924 |     43.044 |   1.2743 |     41.826 |     0.4
   16 |   1.2696 |     42.248 |   1.2509 |     41.412 |     0.4
   17 |   1.2508 |     41.881 |   1.2356 |     40.967 |     0.5
   18 |   1.2373 |     41.403 |   1.2328 |     41.221 |     0.5
   19 |   1.2226 |     41.244 |   1.2186 |     40.808 |     0.5
   20 |   1.2071 |     40.948 |   1.2038 |     40.426 |     0.5
   21 |   1.1949 |     40.526 |   1.1947 |     40.808 |     0.6
   22 |   1.1820 |     40.125 |   1.1886 |     40.299 |     0.6
   23 |   1.1652 |     39.604 |   1.1948 |     40.331 |     0.6
   24 |   1.1629 |     39.094 |   1.1690 |     39.408 |     0.6
   25 |   1.1441 |     38.616 |   1.1735 |     39.949 |     0.7
   26 |   1.1399 |     38.578 |   1.1707 |     39.631 |     0.7
   27 |   1.1320 |     38.616 |   1.1574 |     38.868 |     0.7
   28 |   1.1135 |     37.832 |   1.1502 |     37.882 |     0.7
   29 |   1.0996 |     37.503 |   1.1416 |     38.454 |     0.8
   30 |   1.0923 |     37.300 |   1.1578 |     37.977 |     0.8
   31 |   1.0840 |     36.691 |   1.1333 |     38.041 |     0.8
   32 |   1.0691 |     36.493 |   1.1255 |     37.246 |     0.8
   33 |   1.0554 |     36.043 |   1.1263 |     37.246 |     0.9
   34 |   1.0462 |     35.890 |   1.1272 |     37.150 |     0.9
   35 |   1.0434 |     35.424 |   1.1256 |     37.405 |     0.9
   36 |   1.0270 |     34.721 |   1.1243 |     37.373 |     1.0
   37 |   1.0204 |     34.442 |   1.1141 |     37.023 |     1.0
   38 |   1.0079 |     34.250 |   1.1122 |     36.896 |     1.0
   39 |   0.9926 |     33.624 |   1.1063 |     36.101 |     1.0
   40 |   0.9840 |     33.054 |   1.1018 |     36.005 |     1.1
   41 |   0.9709 |     32.894 |   1.0824 |     35.337 |     1.1
   42 |   0.9608 |     32.329 |   1.0970 |     36.228 |     1.1
   43 |   0.9434 |     31.858 |   1.0888 |     35.623 |     1.1
   44 |   0.9268 |     31.024 |   1.0849 |     34.383 |     1.2
   45 |   0.9208 |     30.557 |   1.0703 |     34.001 |     1.2
   46 |   0.9156 |     30.513 |   1.0655 |     33.620 |     1.2
   47 |   0.9091 |     30.563 |   1.0600 |     33.365 |     1.2
   48 |   0.8923 |     29.724 |   1.0623 |     33.938 |     1.3
   49 |   0.8849 |     29.367 |   1.0448 |     33.651 |     1.3
   50 |   0.8708 |     28.977 |   1.0557 |     33.588 |     1.3
   51 |   0.8556 |     28.687 |   1.0395 |     32.665 |     1.3
   52 |   0.8532 |     28.434 |   1.0371 |     33.142 |     1.4
   53 |   0.8403 |     27.979 |   1.0447 |     32.920 |     1.4
   54 |   0.8288 |     27.617 |   1.0428 |     32.665 |     1.4
   55 |   0.8264 |     27.315 |   1.0318 |     32.665 |     1.5
   56 |   0.8050 |     26.701 |   1.0349 |     32.888 |     1.5
   57 |   0.7944 |     26.218 |   1.0408 |     32.188 |     1.5
   58 |   0.7895 |     26.278 |   1.0317 |     32.602 |     1.5
   59 |   0.7840 |     26.015 |   1.0436 |     32.506 |     1.6
   60 |   0.7838 |     25.812 |   1.0303 |     31.489 |     1.6
   61 |   0.7709 |     25.653 |   1.0381 |     31.616 |     1.6
   62 |   0.7639 |     25.187 |   1.0375 |     31.170 |     1.6
   63 |   0.7415 |     24.506 |   1.0382 |     31.425 |     1.7
   64 |   0.7439 |     24.353 |   1.0532 |     31.838 |     1.7
   65 |   0.7427 |     24.671 |   1.0292 |     31.075 |     1.7
   66 |   0.7253 |     23.777 |   1.0251 |     30.598 |     1.7
   67 |   0.7139 |     23.436 |   1.0445 |     31.679 |     1.8
   68 |   0.7115 |     23.596 |   1.0188 |     30.789 |     1.8
   69 |   0.6999 |     22.844 |   1.0253 |     31.107 |     1.8
   70 |   0.6990 |     22.696 |   1.0146 |     30.344 |     1.8
   71 |   0.6854 |     22.328 |   1.0435 |     30.630 |     1.9
   72 |   0.6778 |     22.114 |   1.0249 |     31.011 |     1.9
   73 |   0.6717 |     21.835 |   1.0356 |     30.503 |     1.9
   74 |   0.6740 |     21.944 |   0.9985 |     29.485 |     2.0
   75 |   0.6609 |     21.461 |   1.0069 |     29.485 |     2.0
   76 |   0.6503 |     21.226 |   1.0239 |     30.630 |     2.0
   77 |   0.6420 |     21.083 |   1.0246 |     29.008 |     2.0
   78 |   0.6429 |     20.858 |   1.0513 |     30.121 |     2.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,454,562

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2722 |     62.064 |   1.6432 |     45.802 |     0.0
    2 |   1.5001 |     46.242 |   1.4240 |     45.929 |     0.1
    3 |   1.4128 |     46.269 |   1.3922 |     45.802 |     0.1
    4 |   1.3916 |     46.012 |   1.3719 |     45.165 |     0.2
    5 |   1.3643 |     45.150 |   1.3406 |     44.275 |     0.2
    6 |   1.3328 |     44.432 |   1.3257 |     43.957 |     0.2
    7 |   1.3140 |     43.740 |   1.2936 |     42.557 |     0.3
    8 |   1.2831 |     42.676 |   1.2624 |     42.048 |     0.3
    9 |   1.2570 |     41.996 |   1.2471 |     41.062 |     0.4
   10 |   1.2432 |     41.612 |   1.2329 |     40.872 |     0.4
   11 |   1.2176 |     40.646 |   1.2162 |     40.299 |     0.5
   12 |   1.2037 |     40.405 |   1.2059 |     40.522 |     0.5
   13 |   1.1854 |     39.675 |   1.1763 |     38.931 |     0.5
   14 |   1.1637 |     39.094 |   1.1740 |     39.027 |     0.6
   15 |   1.1441 |     38.594 |   1.1642 |     39.281 |     0.6
   16 |   1.1332 |     37.942 |   1.1422 |     38.645 |     0.7
   17 |   1.1042 |     36.949 |   1.1386 |     37.087 |     0.7
   18 |   1.0838 |     36.115 |   1.1105 |     36.419 |     0.8
   19 |   1.0582 |     35.358 |   1.1134 |     35.528 |     0.8
   20 |   1.0479 |     34.913 |   1.1001 |     36.482 |     0.8
   21 |   1.0240 |     34.178 |   1.0849 |     34.955 |     0.9
   22 |   0.9964 |     33.268 |   1.0761 |     35.337 |     0.9
   23 |   0.9730 |     32.126 |   1.0614 |     35.115 |     1.0
   24 |   0.9689 |     32.225 |   1.0567 |     34.224 |     1.0
   25 |   0.9440 |     30.963 |   1.0545 |     33.302 |     1.0
   26 |   0.9077 |     29.822 |   1.0608 |     34.160 |     1.1
   27 |   0.8955 |     29.883 |   1.0766 |     34.701 |     1.1
   28 |   0.8742 |     28.988 |   1.0521 |     33.397 |     1.2
   29 |   0.8526 |     28.116 |   1.0577 |     34.065 |     1.2
   30 |   0.8279 |     27.359 |   1.0168 |     32.316 |     1.3
   31 |   0.8125 |     26.893 |   1.0259 |     32.538 |     1.3
   32 |   0.7967 |     26.311 |   1.0204 |     31.997 |     1.3
   33 |   0.7723 |     25.691 |   1.0113 |     32.506 |     1.4
   34 |   0.7521 |     24.781 |   1.0004 |     32.125 |     1.4
   35 |   0.7332 |     23.985 |   1.0218 |     31.902 |     1.5
   36 |   0.7213 |     23.996 |   1.0341 |     31.298 |     1.5
   37 |   0.7153 |     23.859 |   1.0401 |     31.520 |     1.5
   38 |   0.6951 |     22.915 |   1.0304 |     31.489 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,455,298

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2334 |     60.539 |   1.6260 |     45.961 |     0.0
    2 |   1.4912 |     46.248 |   1.4144 |     45.802 |     0.1
    3 |   1.3998 |     46.028 |   1.3621 |     45.102 |     0.1
    4 |   1.3488 |     44.607 |   1.3073 |     43.257 |     0.2
    5 |   1.3009 |     43.214 |   1.2718 |     42.939 |     0.2
    6 |   1.2654 |     42.484 |   1.2460 |     41.380 |     0.2
    7 |   1.2367 |     41.617 |   1.2291 |     41.158 |     0.3
    8 |   1.1978 |     40.202 |   1.1922 |     40.712 |     0.3
    9 |   1.1647 |     39.428 |   1.1604 |     39.313 |     0.4
   10 |   1.1277 |     38.249 |   1.1481 |     38.009 |     0.4
   11 |   1.0998 |     37.102 |   1.1360 |     37.468 |     0.4
   12 |   1.0704 |     36.395 |   1.1199 |     37.309 |     0.5
   13 |   1.0491 |     35.385 |   1.0974 |     37.214 |     0.5
   14 |   1.0104 |     34.025 |   1.1008 |     35.846 |     0.5
   15 |   0.9769 |     33.054 |   1.0887 |     35.083 |     0.6
   16 |   0.9475 |     31.836 |   1.0444 |     33.365 |     0.6
   17 |   0.9087 |     30.371 |   1.0323 |     33.079 |     0.7
   18 |   0.8803 |     29.400 |   1.0269 |     33.556 |     0.7
   19 |   0.8473 |     28.176 |   0.9857 |     31.457 |     0.7
   20 |   0.8143 |     26.794 |   1.0039 |     31.043 |     0.8
   21 |   0.7744 |     25.532 |   1.0206 |     32.093 |     0.8
   22 |   0.7576 |     24.561 |   1.0360 |     31.520 |     0.9
   23 |   0.7185 |     23.316 |   1.0072 |     31.361 |     0.9
   24 |   0.6839 |     22.131 |   0.9835 |     29.453 |     0.9
   25 |   0.6471 |     20.924 |   0.9815 |     30.852 |     1.0
   26 |   0.6243 |     20.145 |   0.9872 |     29.389 |     1.0
   27 |   0.5965 |     19.371 |   0.9860 |     30.121 |     1.1
   28 |   0.5647 |     18.241 |   0.9997 |     30.280 |     1.1
   29 |   0.5413 |     17.479 |   0.9882 |     29.039 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 349,954

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5862 |     68.400 |   2.0400 |     58.492 |     0.0
    2 |   1.8202 |     51.712 |   1.5834 |     45.802 |     0.0
    3 |   1.4927 |     45.803 |   1.4145 |     44.307 |     0.1
    4 |   1.3882 |     44.421 |   1.3509 |     43.575 |     0.1
    5 |   1.3369 |     43.499 |   1.3152 |     42.748 |     0.1
    6 |   1.2954 |     42.555 |   1.2850 |     42.589 |     0.1
    7 |   1.2649 |     41.579 |   1.2495 |     41.508 |     0.2
    8 |   1.2328 |     40.493 |   1.2344 |     40.331 |     0.2
    9 |   1.1994 |     39.527 |   1.2048 |     39.949 |     0.2
   10 |   1.1704 |     38.616 |   1.1796 |     38.391 |     0.2
   11 |   1.1412 |     37.366 |   1.1602 |     38.740 |     0.2
   12 |   1.1184 |     36.938 |   1.1553 |     37.913 |     0.3
   13 |   1.0938 |     36.362 |   1.1264 |     36.260 |     0.3
   14 |   1.0660 |     35.182 |   1.1197 |     36.546 |     0.3
   15 |   1.0410 |     34.299 |   1.0999 |     35.433 |     0.3
   16 |   1.0119 |     33.059 |   1.0756 |     34.065 |     0.4
   17 |   0.9942 |     32.428 |   1.0686 |     34.478 |     0.4
   18 |   0.9676 |     31.397 |   1.0462 |     33.492 |     0.4
   19 |   0.9429 |     30.695 |   1.0532 |     33.524 |     0.4
   20 |   0.9223 |     29.806 |   1.0391 |     33.111 |     0.4
   21 |   0.9011 |     29.263 |   1.0234 |     32.506 |     0.5
   22 |   0.8812 |     28.731 |   1.0313 |     32.379 |     0.5
   23 |   0.8552 |     27.600 |   1.0074 |     31.330 |     0.5
   24 |   0.8356 |     27.271 |   1.0085 |     32.538 |     0.5
   25 |   0.8174 |     26.481 |   1.0142 |     31.679 |     0.6
   26 |   0.7978 |     25.763 |   0.9976 |     31.552 |     0.6
   27 |   0.7924 |     25.658 |   1.0105 |     31.552 |     0.6
   28 |   0.7737 |     25.033 |   1.0122 |     31.075 |     0.6
   29 |   0.7574 |     24.495 |   1.0139 |     31.457 |     0.6
   30 |   0.7384 |     23.881 |   1.0082 |     31.075 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 444,354

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6184 |     70.436 |   2.0226 |     58.810 |     0.0
    2 |   1.7959 |     50.982 |   1.5923 |     45.802 |     0.0
    3 |   1.5188 |     46.132 |   1.4569 |     45.802 |     0.1
    4 |   1.4441 |     46.171 |   1.4220 |     45.802 |     0.1
    5 |   1.4178 |     46.226 |   1.4068 |     45.802 |     0.1
    6 |   1.4050 |     46.099 |   1.3916 |     45.738 |     0.1
    7 |   1.3965 |     46.050 |   1.3867 |     45.802 |     0.2
    8 |   1.3865 |     45.984 |   1.3773 |     45.674 |     0.2
    9 |   1.3755 |     45.781 |   1.3630 |     45.770 |     0.2
   10 |   1.3522 |     44.871 |   1.3366 |     44.307 |     0.2
   11 |   1.3296 |     44.240 |   1.3183 |     44.211 |     0.3
   12 |   1.3088 |     43.779 |   1.2985 |     43.543 |     0.3
   13 |   1.2873 |     43.104 |   1.2904 |     42.939 |     0.3
   14 |   1.2708 |     42.665 |   1.2749 |     41.826 |     0.3
   15 |   1.2535 |     42.034 |   1.2562 |     41.539 |     0.3
   16 |   1.2369 |     41.151 |   1.2490 |     41.508 |     0.4
   17 |   1.2207 |     40.668 |   1.2363 |     41.062 |     0.4
   18 |   1.2077 |     40.394 |   1.2281 |     40.522 |     0.4
   19 |   1.1924 |     39.939 |   1.2248 |     40.267 |     0.4
   20 |   1.1759 |     39.401 |   1.2064 |     40.394 |     0.5
   21 |   1.1649 |     39.346 |   1.2147 |     39.758 |     0.5
   22 |   1.1470 |     38.298 |   1.1832 |     39.345 |     0.5
   23 |   1.1352 |     38.413 |   1.1743 |     38.677 |     0.5
   24 |   1.1273 |     37.903 |   1.1776 |     39.726 |     0.6
   25 |   1.1126 |     37.711 |   1.1617 |     38.804 |     0.6
   26 |   1.0987 |     36.993 |   1.1675 |     38.581 |     0.6
   27 |   1.0797 |     36.427 |   1.1449 |     38.073 |     0.6
   28 |   1.0678 |     36.038 |   1.1431 |     37.627 |     0.6
   29 |   1.0577 |     35.775 |   1.1458 |     37.564 |     0.7
   30 |   1.0341 |     34.935 |   1.1367 |     37.246 |     0.7
   31 |   1.0281 |     34.672 |   1.1600 |     37.373 |     0.7
   32 |   1.0138 |     34.337 |   1.1370 |     35.910 |     0.7
   33 |   1.0005 |     33.937 |   1.1347 |     36.578 |     0.8
   34 |   0.9810 |     33.086 |   1.1213 |     36.291 |     0.8
   35 |   0.9831 |     32.977 |   1.1203 |     34.669 |     0.8
   36 |   0.9659 |     32.428 |   1.1109 |     35.560 |     0.8
   37 |   0.9416 |     31.380 |   1.1195 |     35.592 |     0.8
   38 |   0.9260 |     30.985 |   1.1136 |     35.528 |     0.9
   39 |   0.9063 |     30.574 |   1.1073 |     34.701 |     0.9
   40 |   0.8935 |     29.680 |   1.0935 |     34.796 |     0.9
   41 |   0.8719 |     29.241 |   1.0920 |     34.606 |     0.9
   42 |   0.8677 |     28.977 |   1.0856 |     34.192 |     1.0
   43 |   0.8520 |     28.528 |   1.0928 |     33.969 |     1.0
   44 |   0.8406 |     28.133 |   1.1039 |     33.779 |     1.0
   45 |   0.8317 |     27.595 |   1.0867 |     33.429 |     1.0
   46 |   0.8095 |     26.695 |   1.0726 |     32.761 |     1.1
   47 |   0.8006 |     26.569 |   1.1049 |     33.683 |     1.1
   48 |   0.7755 |     25.549 |   1.0798 |     33.047 |     1.1
   49 |   0.7714 |     25.406 |   1.0868 |     33.588 |     1.1
   50 |   0.7531 |     25.044 |   1.0972 |     33.238 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 832,866

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3138 |     63.424 |   1.6628 |     48.919 |     0.0
    2 |   1.4995 |     46.451 |   1.4209 |     45.802 |     0.0
    3 |   1.4128 |     46.198 |   1.3936 |     46.533 |     0.1
    4 |   1.3920 |     46.116 |   1.3725 |     45.452 |     0.1
    5 |   1.3660 |     45.518 |   1.3349 |     45.261 |     0.1
    6 |   1.3380 |     44.613 |   1.3068 |     43.130 |     0.1
    7 |   1.3028 |     43.697 |   1.2812 |     43.098 |     0.2
    8 |   1.2816 |     43.186 |   1.2568 |     42.398 |     0.2
    9 |   1.2625 |     42.725 |   1.2337 |     41.285 |     0.2
   10 |   1.2366 |     41.590 |   1.2122 |     41.698 |     0.2
   11 |   1.2285 |     41.145 |   1.2214 |     40.712 |     0.3
   12 |   1.2103 |     40.827 |   1.1945 |     40.522 |     0.3
   13 |   1.1899 |     40.284 |   1.1896 |     40.045 |     0.3
   14 |   1.1664 |     39.439 |   1.1755 |     39.249 |     0.3
   15 |   1.1534 |     39.083 |   1.1766 |     39.313 |     0.4
   16 |   1.1330 |     38.221 |   1.1515 |     39.122 |     0.4
   17 |   1.1185 |     37.695 |   1.1559 |     39.218 |     0.4
   18 |   1.0927 |     37.124 |   1.1272 |     37.786 |     0.4
   19 |   1.0763 |     36.762 |   1.1082 |     37.150 |     0.5
   20 |   1.0516 |     35.473 |   1.1266 |     36.450 |     0.5
   21 |   1.0292 |     34.996 |   1.0816 |     35.242 |     0.5
   22 |   1.0007 |     33.800 |   1.0781 |     35.751 |     0.5
   23 |   0.9870 |     33.207 |   1.0748 |     34.860 |     0.5
   24 |   0.9589 |     32.340 |   1.0661 |     34.478 |     0.6
   25 |   0.9410 |     31.830 |   1.0382 |     33.461 |     0.6
   26 |   0.9118 |     30.415 |   1.0387 |     32.284 |     0.6
   27 |   0.8884 |     29.817 |   1.0344 |     32.634 |     0.6
   28 |   0.8712 |     29.521 |   1.0314 |     32.570 |     0.7
   29 |   0.8575 |     28.703 |   1.0219 |     32.793 |     0.7
   30 |   0.8291 |     27.798 |   0.9985 |     30.884 |     0.7
   31 |   0.8041 |     26.613 |   1.0123 |     31.838 |     0.7
   32 |   0.7899 |     26.004 |   1.0027 |     31.616 |     0.8
   33 |   0.7656 |     25.554 |   0.9943 |     30.789 |     0.8
   34 |   0.7434 |     24.808 |   1.0000 |     31.075 |     0.8
   35 |   0.7282 |     24.128 |   0.9830 |     30.693 |     0.8
   36 |   0.7168 |     23.875 |   0.9972 |     30.821 |     0.9
   37 |   0.6886 |     22.806 |   0.9872 |     30.439 |     0.9
   38 |   0.6684 |     22.054 |   1.0096 |     29.994 |     0.9
   39 |   0.6611 |     21.769 |   0.9997 |     29.930 |     0.9
   40 |   0.6479 |     21.407 |   0.9696 |     29.326 |     0.9
   41 |   0.6267 |     20.704 |   0.9929 |     29.421 |     1.0
   42 |   0.6121 |     20.057 |   1.0040 |     29.008 |     1.0
   43 |   0.5933 |     19.755 |   0.9913 |     28.976 |     1.0
   44 |   0.5886 |     19.377 |   1.0102 |     28.753 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 2,466,914

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5281 |     67.479 |   1.9847 |     55.057 |     0.1
    2 |   1.7793 |     50.697 |   1.5901 |     45.802 |     0.2
    3 |   1.5207 |     46.121 |   1.4616 |     45.802 |     0.2
    4 |   1.4465 |     46.105 |   1.4187 |     45.802 |     0.3
    5 |   1.4186 |     46.171 |   1.4018 |     45.802 |     0.4
    6 |   1.4062 |     46.110 |   1.3944 |     45.802 |     0.5
    7 |   1.3976 |     46.171 |   1.3864 |     45.802 |     0.6
    8 |   1.3921 |     46.182 |   1.3814 |     46.819 |     0.7
    9 |   1.3805 |     46.182 |   1.3638 |     45.642 |     0.7
   10 |   1.3615 |     45.150 |   1.3422 |     44.243 |     0.8
   11 |   1.3492 |     45.008 |   1.3396 |     44.052 |     0.9
   12 |   1.3393 |     44.827 |   1.3256 |     44.148 |     1.0
   13 |   1.3332 |     44.679 |   1.3195 |     44.434 |     1.1
   14 |   1.3299 |     44.569 |   1.3142 |     43.670 |     1.1
   15 |   1.3190 |     44.075 |   1.3058 |     43.321 |     1.2
   16 |   1.3104 |     43.817 |   1.3057 |     43.543 |     1.3
   17 |   1.3053 |     43.965 |   1.2865 |     42.939 |     1.4
   18 |   1.2983 |     43.587 |   1.2893 |     42.812 |     1.5
   19 |   1.2956 |     43.455 |   1.2918 |     42.844 |     1.5
   20 |   1.2890 |     43.055 |   1.2746 |     41.985 |     1.6
   21 |   1.2775 |     42.874 |   1.2672 |     41.858 |     1.7
   22 |   1.2687 |     42.358 |   1.2640 |     42.112 |     1.8
   23 |   1.2656 |     42.232 |   1.2675 |     42.303 |     1.9
   24 |   1.2544 |     41.941 |   1.2602 |     41.349 |     2.0
   25 |   1.2472 |     41.595 |   1.2438 |     40.999 |     2.0
   26 |   1.2402 |     41.376 |   1.2472 |     40.935 |     2.1
   27 |   1.2352 |     41.255 |   1.2530 |     42.176 |     2.2
   28 |   1.2252 |     40.849 |   1.2451 |     40.522 |     2.3
   29 |   1.2221 |     40.701 |   1.2375 |     40.935 |     2.4
   30 |   1.2107 |     40.493 |   1.2289 |     40.776 |     2.5
   31 |   1.2044 |     40.279 |   1.2289 |     40.553 |     2.5
   32 |   1.1978 |     39.982 |   1.2172 |     39.758 |     2.6
   33 |   1.1904 |     39.653 |   1.2172 |     40.522 |     2.7
   34 |   1.1859 |     39.851 |   1.2134 |     39.790 |     2.8
   35 |   1.1786 |     39.308 |   1.2120 |     39.885 |     2.9
   36 |   1.1828 |     39.582 |   1.2120 |     40.013 |     2.9
   37 |   1.1744 |     39.576 |   1.2134 |     40.299 |     3.0
   38 |   1.1710 |     39.280 |   1.2061 |     40.235 |     3.1
   39 |   1.1647 |     39.099 |   1.1897 |     39.536 |     3.2
   40 |   1.1583 |     39.083 |   1.1858 |     39.027 |     3.3
   41 |   1.1545 |     38.907 |   1.1896 |     38.740 |     3.4
   42 |   1.1456 |     38.534 |   1.1943 |     39.504 |     3.4
   43 |   1.1369 |     38.194 |   1.1756 |     38.391 |     3.5
   44 |   1.1347 |     37.996 |   1.1812 |     39.726 |     3.6
   45 |   1.1269 |     37.931 |   1.1886 |     39.345 |     3.7
   46 |   1.1262 |     37.574 |   1.1757 |     38.645 |     3.8
   47 |   1.1144 |     37.097 |   1.1691 |     37.977 |     3.8
   48 |   1.1101 |     37.492 |   1.1710 |     39.154 |     3.9
   49 |   1.1057 |     37.371 |   1.1783 |     39.281 |     4.0
   50 |   1.1016 |     37.360 |   1.1612 |     38.009 |     4.1
   51 |   1.0972 |     37.349 |   1.1715 |     38.899 |     4.2
   52 |   1.0906 |     36.768 |   1.1622 |     38.295 |     4.3
   53 |   1.0898 |     37.086 |   1.1504 |     38.391 |     4.3
   54 |   1.0887 |     36.828 |   1.1640 |     38.995 |     4.4
   55 |   1.0803 |     36.301 |   1.1534 |     38.136 |     4.5
   56 |   1.0856 |     36.658 |   1.1614 |     38.581 |     4.6
   57 |   1.0800 |     36.636 |   1.1401 |     37.659 |     4.7
   58 |   1.0655 |     35.950 |   1.1444 |     37.500 |     4.7
   59 |   1.0524 |     35.703 |   1.1447 |     38.009 |     4.8
   60 |   1.0453 |     35.429 |   1.1336 |     36.323 |     4.9
   61 |   1.0391 |     35.166 |   1.1564 |     37.723 |     5.0
   62 |   1.0498 |     35.692 |   1.1428 |     38.073 |     5.1
   63 |   1.0450 |     35.561 |   1.1569 |     37.850 |     5.2
   64 |   1.0371 |     35.259 |   1.1371 |     37.373 |     5.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,128,738

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2164 |     60.890 |   1.6229 |     48.887 |     0.0
    2 |   1.4641 |     45.809 |   1.3815 |     45.102 |     0.1
    3 |   1.3406 |     43.878 |   1.3064 |     42.207 |     0.1
    4 |   1.2640 |     41.283 |   1.2360 |     40.967 |     0.1
    5 |   1.2028 |     39.450 |   1.1846 |     39.154 |     0.2
    6 |   1.1405 |     37.256 |   1.1344 |     37.277 |     0.2
    7 |   1.0820 |     35.539 |   1.1073 |     36.355 |     0.2
    8 |   1.0287 |     33.481 |   1.0616 |     34.924 |     0.3
    9 |   0.9756 |     31.742 |   1.0327 |     33.397 |     0.3
   10 |   0.9258 |     30.162 |   1.0286 |     33.206 |     0.3
   11 |   0.8753 |     28.478 |   0.9940 |     32.570 |     0.4
   12 |   0.8343 |     26.986 |   0.9928 |     31.966 |     0.4
   13 |   0.7936 |     25.730 |   0.9845 |     31.711 |     0.4
   14 |   0.7466 |     23.881 |   0.9483 |     29.676 |     0.5
   15 |   0.6993 |     22.504 |   0.9406 |     30.089 |     0.5
   16 |   0.6638 |     21.242 |   0.9597 |     29.485 |     0.5
   17 |   0.6289 |     20.117 |   0.9362 |     28.467 |     0.6
   18 |   0.5965 |     19.042 |   0.9642 |     29.517 |     0.6
   19 |   0.5719 |     18.186 |   0.9784 |     29.644 |     0.6
   20 |   0.5444 |     17.522 |   0.9824 |     29.453 |     0.7
   21 |   0.5063 |     16.348 |   0.9570 |     28.117 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,322,466

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1852 |     59.617 |   1.6104 |     46.056 |     0.0
    2 |   1.4648 |     45.913 |   1.3730 |     44.402 |     0.1
    3 |   1.3520 |     44.141 |   1.3106 |     43.416 |     0.1
    4 |   1.2900 |     42.561 |   1.2636 |     42.080 |     0.2
    5 |   1.2372 |     40.888 |   1.2058 |     40.140 |     0.2
    6 |   1.1924 |     39.576 |   1.1775 |     39.090 |     0.3
    7 |   1.1420 |     37.618 |   1.1634 |     38.041 |     0.3
    8 |   1.0898 |     36.016 |   1.1065 |     36.578 |     0.3
    9 |   1.0439 |     34.540 |   1.0728 |     34.828 |     0.4
   10 |   0.9957 |     32.752 |   1.0394 |     33.238 |     0.4
   11 |   0.9487 |     31.276 |   1.0181 |     33.015 |     0.5
   12 |   0.9083 |     29.800 |   1.0025 |     32.284 |     0.5
   13 |   0.8724 |     28.517 |   0.9832 |     32.061 |     0.5
   14 |   0.8244 |     26.854 |   0.9845 |     31.934 |     0.6
   15 |   0.7913 |     26.009 |   0.9771 |     31.997 |     0.6
   16 |   0.7548 |     24.824 |   0.9561 |     29.739 |     0.7
   17 |   0.7222 |     23.486 |   0.9480 |     29.835 |     0.7
   18 |   0.6804 |     22.043 |   0.9450 |     29.358 |     0.7
   19 |   0.6500 |     21.094 |   0.9219 |     28.849 |     0.8
   20 |   0.6151 |     19.947 |   0.9320 |     28.562 |     0.8
   21 |   0.5859 |     18.960 |   0.9197 |     29.103 |     0.9
   22 |   0.5624 |     18.225 |   0.9273 |     28.117 |     0.9
   23 |   0.5393 |     17.380 |   0.9159 |     27.640 |     1.0
   24 |   0.5188 |     16.985 |   0.9168 |     28.435 |     1.0
   25 |   0.4851 |     15.789 |   0.9222 |     27.926 |     1.0
   26 |   0.4622 |     15.098 |   0.9305 |     27.195 |     1.1
   27 |   0.4403 |     14.072 |   0.9435 |     27.290 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 3,046,882

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3000 |     62.717 |   1.6813 |     48.919 |     0.1
    2 |   1.5054 |     46.412 |   1.4146 |     46.533 |     0.2
    3 |   1.4094 |     46.313 |   1.3908 |     45.802 |     0.3
    4 |   1.3958 |     46.154 |   1.3815 |     46.533 |     0.3
    5 |   1.3889 |     46.099 |   1.3769 |     45.802 |     0.4
    6 |   1.3865 |     46.116 |   1.3781 |     46.533 |     0.5
    7 |   1.3826 |     45.847 |   1.3652 |     45.293 |     0.6
    8 |   1.3657 |     45.205 |   1.3500 |     44.625 |     0.7
    9 |   1.3496 |     44.964 |   1.3482 |     44.148 |     0.8
   10 |   1.3395 |     44.860 |   1.3235 |     44.116 |     0.9
   11 |   1.3238 |     44.399 |   1.3142 |     43.989 |     0.9
   12 |   1.3163 |     44.157 |   1.3023 |     43.925 |     1.0
   13 |   1.3030 |     43.702 |   1.2906 |     42.939 |     1.1
   14 |   1.2979 |     43.488 |   1.2892 |     42.716 |     1.2
   15 |   1.2910 |     43.345 |   1.2726 |     42.080 |     1.3
   16 |   1.2813 |     42.846 |   1.2724 |     42.239 |     1.4
   17 |   1.2850 |     43.159 |   1.2724 |     42.557 |     1.5
   18 |   1.2735 |     42.731 |   1.2555 |     41.826 |     1.5
   19 |   1.2615 |     42.352 |   1.2461 |     41.380 |     1.6
   20 |   1.2509 |     41.941 |   1.2438 |     41.349 |     1.7
   21 |   1.2469 |     42.007 |   1.2381 |     41.190 |     1.8
   22 |   1.2426 |     41.820 |   1.2432 |     41.698 |     1.9
   23 |   1.2276 |     41.661 |   1.2295 |     40.872 |     2.0
   24 |   1.2204 |     41.370 |   1.2201 |     40.967 |     2.0
   25 |   1.2098 |     41.008 |   1.2147 |     40.617 |     2.1
   26 |   1.2001 |     40.526 |   1.2086 |     40.172 |     2.2
   27 |   1.1954 |     40.729 |   1.2019 |     41.031 |     2.3
   28 |   1.1787 |     39.988 |   1.2027 |     39.854 |     2.4
   29 |   1.1757 |     39.785 |   1.1901 |     40.108 |     2.5
   30 |   1.1706 |     39.796 |   1.2014 |     40.331 |     2.6
   31 |   1.1598 |     39.500 |   1.1766 |     39.440 |     2.6
   32 |   1.1523 |     39.116 |   1.1735 |     39.408 |     2.7
   33 |   1.1389 |     38.627 |   1.1778 |     39.536 |     2.8
   34 |   1.1322 |     38.578 |   1.1707 |     39.090 |     2.9
   35 |   1.1285 |     38.391 |   1.1628 |     39.154 |     3.0
   36 |   1.1148 |     37.783 |   1.1676 |     39.854 |     3.1
   37 |   1.1139 |     37.859 |   1.1500 |     38.359 |     3.2
   38 |   1.1045 |     37.448 |   1.1471 |     38.740 |     3.2
   39 |   1.0933 |     37.278 |   1.1406 |     37.723 |     3.3
   40 |   1.0784 |     36.702 |   1.1527 |     38.454 |     3.4
   41 |   1.0817 |     36.718 |   1.1439 |     38.518 |     3.5
   42 |   1.0700 |     36.647 |   1.1369 |     37.500 |     3.6
   43 |   1.0700 |     36.274 |   1.1316 |     36.927 |     3.7
   44 |   1.0533 |     36.005 |   1.1237 |     37.023 |     3.7
   45 |   1.0529 |     36.022 |   1.1251 |     37.500 |     3.8
   46 |   1.0392 |     35.709 |   1.1274 |     37.436 |     3.9
   47 |   1.0280 |     35.056 |   1.1247 |     37.055 |     4.0
   48 |   1.0403 |     35.572 |   1.1280 |     37.373 |     4.1
   49 |   1.0191 |     34.831 |   1.1155 |     37.532 |     4.2
   50 |   1.0190 |     34.924 |   1.1213 |     36.991 |     4.2
   51 |   0.9956 |     34.156 |   1.1195 |     36.800 |     4.3
   52 |   0.9892 |     33.915 |   1.1102 |     36.387 |     4.4
   53 |   0.9865 |     33.898 |   1.1046 |     36.546 |     4.5
   54 |   0.9788 |     33.547 |   1.1086 |     36.164 |     4.6
   55 |   0.9891 |     33.920 |   1.1072 |     36.419 |     4.7
   56 |   0.9805 |     33.470 |   1.1060 |     35.655 |     4.8
   57 |   0.9693 |     33.372 |   1.0968 |     36.291 |     4.8
   58 |   0.9536 |     32.510 |   1.1096 |     35.973 |     4.9
   59 |   0.9652 |     33.075 |   1.0958 |     36.578 |     5.0
   60 |   0.9702 |     33.366 |   1.1041 |     36.419 |     5.1
   61 |   0.9425 |     32.313 |   1.0958 |     36.101 |     5.2
   62 |   0.9447 |     32.467 |   1.0946 |     35.560 |     5.3
   63 |   0.9260 |     31.644 |   1.0799 |     35.623 |     5.3
   64 |   0.9142 |     31.430 |   1.0832 |     35.337 |     5.4
   65 |   0.9051 |     30.826 |   1.0925 |     35.337 |     5.5
   66 |   0.9056 |     31.199 |   1.1045 |     36.291 |     5.6
   67 |   0.9405 |     32.351 |   1.1004 |     35.910 |     5.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 483,650

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1623 |     58.449 |   1.5396 |     45.833 |     0.0
    2 |   1.4247 |     45.030 |   1.3339 |     43.511 |     0.0
    3 |   1.3012 |     42.325 |   1.2494 |     41.380 |     0.1
    4 |   1.2301 |     40.740 |   1.1913 |     39.313 |     0.1
    5 |   1.1680 |     38.786 |   1.1483 |     37.818 |     0.1
    6 |   1.1057 |     36.855 |   1.1109 |     36.228 |     0.1
    7 |   1.0415 |     34.063 |   1.0583 |     34.383 |     0.1
    8 |   0.9839 |     32.450 |   1.0271 |     32.856 |     0.2
    9 |   0.9222 |     29.817 |   0.9962 |     31.170 |     0.2
   10 |   0.8634 |     27.820 |   0.9692 |     31.107 |     0.2
   11 |   0.8119 |     26.218 |   0.9398 |     29.644 |     0.2
   12 |   0.7584 |     24.320 |   0.9379 |     28.753 |     0.2
   13 |   0.7112 |     22.608 |   0.9079 |     27.704 |     0.2
   14 |   0.6638 |     21.226 |   0.8934 |     27.576 |     0.3
   15 |   0.6117 |     19.349 |   0.8915 |     27.767 |     0.3
   16 |   0.5765 |     18.351 |   0.8869 |     26.877 |     0.3
   17 |   0.5369 |     17.040 |   0.8944 |     26.622 |     0.3
   18 |   0.5005 |     15.778 |   0.8844 |     25.732 |     0.3
   19 |   0.4741 |     14.801 |   0.9041 |     26.336 |     0.4
   20 |   0.4374 |     13.743 |   0.9012 |     26.240 |     0.4
   21 |   0.4060 |     12.667 |   0.9021 |     25.509 |     0.4
   22 |   0.3861 |     12.080 |   0.9242 |     25.573 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 264,898

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6128 |     70.200 |   1.9900 |     58.810 |     0.0
    2 |   1.7445 |     49.753 |   1.5540 |     45.802 |     0.0
    3 |   1.4935 |     46.171 |   1.4378 |     45.802 |     0.0
    4 |   1.4297 |     46.105 |   1.4103 |     45.802 |     0.1
    5 |   1.4085 |     46.121 |   1.3955 |     45.802 |     0.1
    6 |   1.3993 |     46.121 |   1.3891 |     45.770 |     0.1
    7 |   1.3939 |     46.143 |   1.3827 |     45.770 |     0.1
    8 |   1.3895 |     46.160 |   1.3807 |     45.802 |     0.1
    9 |   1.3841 |     45.995 |   1.3746 |     45.802 |     0.1
   10 |   1.3757 |     45.622 |   1.3595 |     45.324 |     0.1
   11 |   1.3566 |     45.090 |   1.3379 |     44.179 |     0.2
   12 |   1.3326 |     44.443 |   1.3208 |     44.466 |     0.2
   13 |   1.3146 |     44.530 |   1.3071 |     43.257 |     0.2
   14 |   1.2947 |     43.987 |   1.2974 |     44.020 |     0.2
   15 |   1.2756 |     43.466 |   1.2803 |     43.384 |     0.2
   16 |   1.2574 |     42.512 |   1.2719 |     41.762 |     0.2
   17 |   1.2442 |     42.138 |   1.2597 |     42.207 |     0.2
   18 |   1.2260 |     41.458 |   1.2392 |     41.126 |     0.3
   19 |   1.1989 |     40.624 |   1.2283 |     41.190 |     0.3
   20 |   1.1804 |     40.191 |   1.2233 |     40.299 |     0.3
   21 |   1.1609 |     39.593 |   1.2002 |     39.695 |     0.3
   22 |   1.1368 |     38.863 |   1.2024 |     39.218 |     0.3
   23 |   1.1197 |     38.276 |   1.1910 |     39.090 |     0.3
   24 |   1.0879 |     36.833 |   1.1915 |     38.677 |     0.3
   25 |   1.0669 |     36.164 |   1.1729 |     38.518 |     0.4
   26 |   1.0475 |     34.771 |   1.1697 |     38.295 |     0.4
   27 |   1.0172 |     34.145 |   1.1645 |     37.627 |     0.4
   28 |   0.9926 |     33.240 |   1.1566 |     36.323 |     0.4
   29 |   0.9722 |     31.956 |   1.1579 |     36.196 |     0.4
   30 |   0.9523 |     31.177 |   1.1666 |     36.482 |     0.4
   31 |   0.9383 |     30.919 |   1.1549 |     36.228 |     0.4
   32 |   0.9063 |     29.680 |   1.1525 |     36.069 |     0.5
   33 |   0.8883 |     29.087 |   1.1438 |     35.146 |     0.5
   34 |   0.8634 |     28.303 |   1.1366 |     35.146 |     0.5
   35 |   0.8408 |     27.310 |   1.1461 |     35.146 |     0.5
   36 |   0.8251 |     26.728 |   1.1356 |     34.606 |     0.5
   37 |   0.8067 |     26.443 |   1.1396 |     34.097 |     0.5
   38 |   0.7831 |     25.291 |   1.1325 |     33.556 |     0.5
   39 |   0.7603 |     24.556 |   1.1486 |     33.492 |     0.6
   40 |   0.7389 |     23.590 |   1.1423 |     33.683 |     0.6
   41 |   0.7136 |     22.597 |   1.1424 |     33.079 |     0.6
   42 |   0.7015 |     22.641 |   1.1592 |     33.270 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,402,882

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2411 |     60.983 |   1.6362 |     48.919 |     0.0
    2 |   1.4915 |     46.176 |   1.4174 |     46.533 |     0.1
    3 |   1.4041 |     45.792 |   1.3765 |     45.356 |     0.1
    4 |   1.3683 |     44.914 |   1.3429 |     44.020 |     0.2
    5 |   1.3442 |     44.284 |   1.3363 |     43.702 |     0.2
    6 |   1.3247 |     44.042 |   1.3086 |     43.861 |     0.2
    7 |   1.3067 |     43.526 |   1.2893 |     43.130 |     0.3
    8 |   1.2820 |     42.665 |   1.2763 |     42.271 |     0.3
    9 |   1.2642 |     42.018 |   1.2580 |     41.158 |     0.3
   10 |   1.2449 |     41.727 |   1.2491 |     41.412 |     0.4
   11 |   1.2283 |     41.200 |   1.2462 |     40.903 |     0.4
   12 |   1.1992 |     40.109 |   1.2126 |     40.204 |     0.5
   13 |   1.1807 |     39.670 |   1.1973 |     39.790 |     0.5
   14 |   1.1511 |     38.710 |   1.1911 |     39.790 |     0.5
   15 |   1.1252 |     37.722 |   1.1806 |     38.550 |     0.6
   16 |   1.0930 |     36.543 |   1.1541 |     37.882 |     0.6
   17 |   1.0593 |     35.434 |   1.1341 |     36.896 |     0.7
   18 |   1.0401 |     34.727 |   1.1140 |     36.132 |     0.7
   19 |   1.0153 |     34.222 |   1.0980 |     35.623 |     0.7
   20 |   0.9880 |     32.916 |   1.1048 |     36.260 |     0.8
   21 |   0.9623 |     31.863 |   1.0904 |     35.019 |     0.8
   22 |   0.9243 |     30.903 |   1.0746 |     35.878 |     0.9
   23 |   0.8983 |     30.108 |   1.0836 |     35.655 |     0.9
   24 |   0.8843 |     29.883 |   1.0562 |     34.892 |     0.9
   25 |   0.8367 |     27.913 |   1.0514 |     33.715 |     1.0
   26 |   0.8162 |     27.304 |   1.0507 |     33.620 |     1.0
   27 |   0.7876 |     26.382 |   1.0544 |     33.333 |     1.0
   28 |   0.7596 |     25.208 |   1.0547 |     33.365 |     1.1
   29 |   0.7376 |     24.830 |   1.0394 |     32.697 |     1.1
   30 |   0.7181 |     24.034 |   1.0588 |     32.634 |     1.2
   31 |   0.6858 |     22.795 |   1.0484 |     32.093 |     1.2
   32 |   0.6627 |     22.339 |   1.0547 |     32.093 |     1.2
   33 |   0.6584 |     21.977 |   1.0355 |     31.330 |     1.3
   34 |   0.6169 |     20.463 |   1.0344 |     31.807 |     1.3
   35 |   0.5962 |     19.821 |   1.0614 |     30.821 |     1.4
   36 |   0.5586 |     18.548 |   1.0741 |     32.506 |     1.4
   37 |   0.5388 |     17.731 |   1.0610 |     30.980 |     1.4
   38 |   0.5211 |     17.402 |   1.0700 |     31.393 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,898,786

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2254 |     60.945 |   1.6364 |     45.802 |     0.1
    2 |   1.4921 |     46.231 |   1.4243 |     45.802 |     0.2
    3 |   1.4133 |     46.154 |   1.3935 |     45.802 |     0.2
    4 |   1.3937 |     46.248 |   1.3766 |     46.533 |     0.3
    5 |   1.3639 |     45.041 |   1.3417 |     43.957 |     0.4
    6 |   1.3367 |     44.432 |   1.3212 |     43.925 |     0.5
    7 |   1.3136 |     43.861 |   1.3025 |     43.798 |     0.5
    8 |   1.2885 |     43.131 |   1.2636 |     42.207 |     0.6
    9 |   1.2515 |     41.908 |   1.2426 |     41.762 |     0.7
   10 |   1.2222 |     41.107 |   1.2322 |     41.094 |     0.8
   11 |   1.2052 |     40.476 |   1.2116 |     40.490 |     0.9
   12 |   1.1857 |     39.851 |   1.1783 |     39.536 |     0.9
   13 |   1.1501 |     39.061 |   1.1496 |     38.804 |     1.0
   14 |   1.1311 |     38.573 |   1.1640 |     39.758 |     1.1
   15 |   1.1078 |     37.525 |   1.1254 |     37.309 |     1.2
   16 |   1.0881 |     36.784 |   1.1326 |     38.104 |     1.2
   17 |   1.0679 |     36.219 |   1.0953 |     36.323 |     1.3
   18 |   1.0584 |     35.676 |   1.1050 |     36.641 |     1.4
   19 |   1.0353 |     34.891 |   1.0823 |     35.560 |     1.5
   20 |   1.0175 |     34.414 |   1.0664 |     35.178 |     1.5
   21 |   0.9913 |     33.251 |   1.0535 |     34.701 |     1.6
   22 |   0.9598 |     32.335 |   1.0453 |     34.351 |     1.7
   23 |   0.9400 |     31.605 |   1.0781 |     35.274 |     1.8
   24 |   0.9279 |     31.413 |   1.0323 |     33.302 |     1.9
   25 |   0.9044 |     30.354 |   1.0434 |     34.733 |     1.9
   26 |   0.8794 |     29.542 |   1.0091 |     33.079 |     2.0
   27 |   0.8595 |     29.038 |   1.0215 |     33.683 |     2.1
   28 |   0.8473 |     28.709 |   1.0265 |     33.174 |     2.2
   29 |   0.8318 |     28.138 |   1.0120 |     33.588 |     2.2
   30 |   0.8049 |     27.222 |   1.0097 |     32.793 |     2.3
   31 |   0.7976 |     26.882 |   1.0010 |     32.761 |     2.4
   32 |   0.7708 |     26.031 |   0.9907 |     32.029 |     2.5
   33 |   0.7423 |     24.896 |   0.9848 |     31.011 |     2.5
   34 |   0.7390 |     24.973 |   0.9901 |     31.139 |     2.6
   35 |   0.7134 |     23.842 |   0.9980 |     31.870 |     2.7
   36 |   0.6905 |     23.288 |   0.9843 |     31.202 |     2.8
   37 |   0.6866 |     22.838 |   0.9786 |     31.234 |     2.9
   38 |   0.6588 |     22.032 |   0.9845 |     30.248 |     2.9
   39 |   0.6419 |     21.374 |   0.9892 |     30.725 |     3.0
   40 |   0.6379 |     21.588 |   1.0195 |     32.125 |     3.1
   41 |   0.6341 |     21.072 |   1.0103 |     31.361 |     3.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 2,782,690

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1826 |     59.804 |   1.6207 |     45.865 |     0.1
    2 |   1.4865 |     46.302 |   1.4112 |     45.802 |     0.2
    3 |   1.4078 |     46.132 |   1.3896 |     45.802 |     0.2
    4 |   1.3876 |     45.578 |   1.3636 |     44.211 |     0.3
    5 |   1.3583 |     44.733 |   1.3379 |     43.989 |     0.4
    6 |   1.3319 |     44.284 |   1.3149 |     43.321 |     0.5
    7 |   1.3138 |     43.658 |   1.2994 |     43.034 |     0.6
    8 |   1.2938 |     43.236 |   1.2757 |     42.239 |     0.7
    9 |   1.2746 |     42.786 |   1.2616 |     41.921 |     0.8
   10 |   1.2565 |     41.881 |   1.2604 |     41.349 |     0.8
   11 |   1.2505 |     41.815 |   1.2359 |     40.490 |     0.9
   12 |   1.2241 |     40.888 |   1.2343 |     40.267 |     1.0
   13 |   1.2079 |     40.328 |   1.2267 |     40.267 |     1.1
   14 |   1.1933 |     39.774 |   1.2102 |     39.090 |     1.2
   15 |   1.1738 |     38.957 |   1.2033 |     38.550 |     1.3
   16 |   1.1587 |     38.688 |   1.1872 |     38.995 |     1.4
   17 |   1.1386 |     38.106 |   1.1815 |     39.059 |     1.4
   18 |   1.1214 |     37.569 |   1.1626 |     38.009 |     1.5
   19 |   1.1079 |     36.877 |   1.1539 |     37.373 |     1.6
   20 |   1.0897 |     36.192 |   1.1631 |     38.104 |     1.7
   21 |   1.0677 |     35.632 |   1.1479 |     37.405 |     1.8
   22 |   1.0648 |     35.616 |   1.1337 |     37.118 |     1.9
   23 |   1.0443 |     35.133 |   1.1250 |     36.800 |     1.9
   24 |   1.0351 |     34.760 |   1.1236 |     35.973 |     2.0
   25 |   1.0103 |     33.898 |   1.1099 |     35.878 |     2.1
   26 |   0.9937 |     33.278 |   1.1154 |     36.482 |     2.2
   27 |   0.9769 |     32.708 |   1.1083 |     36.101 |     2.3
   28 |   0.9691 |     32.587 |   1.0980 |     35.401 |     2.4
   29 |   0.9533 |     32.088 |   1.0937 |     34.796 |     2.4
   30 |   0.9369 |     31.342 |   1.0996 |     34.637 |     2.5
   31 |   0.9195 |     30.903 |   1.0868 |     34.892 |     2.6
   32 |   0.9142 |     30.903 |   1.1015 |     35.274 |     2.7
   33 |   0.9073 |     30.442 |   1.1095 |     35.401 |     2.8
   34 |   0.8932 |     30.042 |   1.1039 |     35.178 |     2.9
   35 |   0.8870 |     29.811 |   1.0715 |     34.256 |     2.9
   36 |   0.8697 |     29.334 |   1.0905 |     34.955 |     3.0
   37 |   0.8595 |     28.977 |   1.0822 |     34.733 |     3.1
   38 |   0.8502 |     28.824 |   1.1092 |     35.433 |     3.2
   39 |   0.8414 |     28.423 |   1.0870 |     33.556 |     3.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 2,011,458

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1553 |     58.811 |   1.5765 |     45.802 |     0.1
    2 |   1.4586 |     46.138 |   1.3754 |     45.388 |     0.1
    3 |   1.3551 |     44.349 |   1.3105 |     43.670 |     0.2
    4 |   1.2854 |     42.341 |   1.2493 |     41.508 |     0.2
    5 |   1.2299 |     40.707 |   1.2098 |     39.440 |     0.3
    6 |   1.1789 |     38.556 |   1.1618 |     37.786 |     0.4
    7 |   1.1290 |     37.064 |   1.1502 |     37.786 |     0.4
    8 |   1.0919 |     35.989 |   1.0981 |     35.941 |     0.5
    9 |   1.0473 |     34.288 |   1.0668 |     34.574 |     0.6
   10 |   1.0004 |     32.867 |   1.0403 |     33.079 |     0.6
   11 |   0.9622 |     31.506 |   1.0197 |     32.729 |     0.7
   12 |   0.9251 |     30.524 |   0.9952 |     32.793 |     0.7
   13 |   0.8873 |     28.928 |   0.9957 |     31.966 |     0.8
   14 |   0.8511 |     27.781 |   0.9660 |     30.916 |     0.9
   15 |   0.8114 |     26.503 |   0.9553 |     30.184 |     0.9
   16 |   0.7752 |     25.159 |   0.9448 |     29.930 |     1.0
   17 |   0.7488 |     24.205 |   0.9602 |     30.407 |     1.1
   18 |   0.7201 |     23.749 |   0.9413 |     29.580 |     1.1
   19 |   0.6991 |     22.690 |   0.9353 |     28.340 |     1.2
   20 |   0.6664 |     21.824 |   0.9337 |     29.485 |     1.2
   21 |   0.6260 |     20.611 |   0.9296 |     28.085 |     1.3
   22 |   0.6068 |     19.871 |   0.9466 |     28.880 |     1.4
   23 |   0.5802 |     19.102 |   0.9230 |     27.767 |     1.4
   24 |   0.5462 |     17.868 |   0.9090 |     27.894 |     1.5
   25 |   0.5296 |     17.385 |   0.9393 |     27.417 |     1.6
   26 |   0.5168 |     16.985 |   0.9551 |     28.085 |     1.6
   27 |   0.4995 |     16.540 |   0.9486 |     27.258 |     1.7
   28 |   0.4763 |     15.460 |   0.9399 |     27.226 |     1.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,123,170

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5473 |     67.468 |   1.9952 |     58.810 |     0.0
    2 |   1.7940 |     51.081 |   1.5976 |     45.802 |     0.1
    3 |   1.5266 |     46.143 |   1.4556 |     45.802 |     0.1
    4 |   1.4440 |     46.143 |   1.4166 |     45.802 |     0.2
    5 |   1.4171 |     46.143 |   1.4004 |     45.802 |     0.2
    6 |   1.4040 |     46.237 |   1.3892 |     45.802 |     0.2
    7 |   1.3956 |     46.116 |   1.3852 |     45.706 |     0.3
    8 |   1.3859 |     45.946 |   1.3735 |     45.038 |     0.3
    9 |   1.3690 |     45.167 |   1.3493 |     44.243 |     0.4
   10 |   1.3483 |     44.284 |   1.3316 |     43.448 |     0.4
   11 |   1.3323 |     43.894 |   1.3184 |     42.844 |     0.5
   12 |   1.3129 |     43.263 |   1.2948 |     42.525 |     0.5
   13 |   1.2987 |     42.950 |   1.2825 |     41.826 |     0.5
   14 |   1.2885 |     42.720 |   1.2812 |     42.303 |     0.6
   15 |   1.2793 |     42.276 |   1.2699 |     41.698 |     0.6
   16 |   1.2678 |     41.782 |   1.2619 |     41.062 |     0.7
   17 |   1.2550 |     41.370 |   1.2481 |     40.458 |     0.7
   18 |   1.2441 |     40.789 |   1.2364 |     40.363 |     0.7
   19 |   1.2341 |     40.558 |   1.2332 |     40.204 |     0.8
   20 |   1.2183 |     40.306 |   1.2248 |     40.553 |     0.8
   21 |   1.2094 |     40.087 |   1.2186 |     40.172 |     0.9
   22 |   1.2023 |     39.867 |   1.2124 |     39.599 |     0.9
   23 |   1.1932 |     39.664 |   1.2073 |     40.045 |     0.9
   24 |   1.1900 |     39.801 |   1.2028 |     39.408 |     1.0
   25 |   1.1805 |     39.500 |   1.1910 |     39.536 |     1.0
   26 |   1.1738 |     39.258 |   1.1908 |     39.726 |     1.1
   27 |   1.1620 |     38.891 |   1.1854 |     39.345 |     1.1
   28 |   1.1496 |     38.721 |   1.1793 |     38.963 |     1.2
   29 |   1.1464 |     38.523 |   1.1736 |     39.695 |     1.2
   30 |   1.1322 |     37.936 |   1.1582 |     38.740 |     1.2
   31 |   1.1229 |     37.645 |   1.1591 |     37.945 |     1.3
   32 |   1.1203 |     37.623 |   1.1415 |     37.818 |     1.3
   33 |   1.1084 |     37.234 |   1.1370 |     37.850 |     1.4
   34 |   1.0969 |     36.932 |   1.1330 |     37.023 |     1.4
   35 |   1.0879 |     36.647 |   1.1259 |     37.850 |     1.4
   36 |   1.0783 |     36.208 |   1.1210 |     37.023 |     1.5
   37 |   1.0733 |     36.170 |   1.1195 |     36.864 |     1.5
   38 |   1.0573 |     35.456 |   1.1118 |     36.069 |     1.6
   39 |   1.0467 |     35.550 |   1.1169 |     35.719 |     1.6
   40 |   1.0405 |     34.858 |   1.1038 |     36.228 |     1.6
   41 |   1.0280 |     34.409 |   1.0959 |     35.782 |     1.7
   42 |   1.0169 |     34.079 |   1.0964 |     35.655 |     1.7
   43 |   1.0132 |     33.745 |   1.1021 |     36.291 |     1.8
   44 |   1.0029 |     33.339 |   1.0964 |     35.687 |     1.8
   45 |   0.9968 |     33.366 |   1.0802 |     34.637 |     1.8
   46 |   0.9864 |     32.823 |   1.0852 |     34.478 |     1.9
   47 |   0.9867 |     32.801 |   1.0809 |     35.305 |     1.9
   48 |   0.9675 |     31.907 |   1.0838 |     34.987 |     2.0
   49 |   0.9539 |     31.430 |   1.0707 |     33.524 |     2.0
   50 |   0.9463 |     30.991 |   1.0732 |     33.047 |     2.1
   51 |   0.9462 |     31.155 |   1.0893 |     34.765 |     2.1
   52 |   0.9623 |     31.984 |   1.0814 |     33.620 |     2.1
   53 |   0.9375 |     31.133 |   1.0599 |     33.238 |     2.2
   54 |   0.9232 |     30.716 |   1.0554 |     33.492 |     2.2
   55 |   0.9135 |     30.327 |   1.0480 |     33.015 |     2.3
   56 |   0.8986 |     29.729 |   1.0569 |     33.015 |     2.3
   57 |   0.8891 |     29.438 |   1.0562 |     33.556 |     2.3
   58 |   0.8786 |     29.098 |   1.0529 |     32.793 |     2.4
   59 |   0.8833 |     29.433 |   1.0656 |     33.524 |     2.4
   60 |   0.8768 |     29.010 |   1.0402 |     32.220 |     2.5
   61 |   0.8652 |     28.840 |   1.0362 |     32.856 |     2.5
   62 |   0.8488 |     27.847 |   1.0340 |     32.156 |     2.5
   63 |   0.8484 |     28.259 |   1.0343 |     31.648 |     2.6
   64 |   0.8346 |     27.952 |   1.0196 |     31.616 |     2.6
   65 |   0.8282 |     27.738 |   1.0386 |     31.934 |     2.7
   66 |   0.8219 |     27.447 |   1.0521 |     32.793 |     2.7
   67 |   0.8141 |     27.063 |   1.0245 |     31.838 |     2.8
   68 |   0.8144 |     26.909 |   1.0253 |     31.648 |     2.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,243,362

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2360 |     61.214 |   1.6451 |     45.802 |     0.0
    2 |   1.4971 |     46.171 |   1.4175 |     45.802 |     0.1
    3 |   1.4112 |     46.237 |   1.3868 |     45.802 |     0.1
    4 |   1.3924 |     46.220 |   1.3763 |     45.802 |     0.2
    5 |   1.3751 |     45.726 |   1.3648 |     45.452 |     0.2
    6 |   1.3506 |     44.871 |   1.3269 |     44.402 |     0.2
    7 |   1.3360 |     44.733 |   1.3197 |     43.766 |     0.3
    8 |   1.3210 |     44.174 |   1.3063 |     43.225 |     0.3
    9 |   1.3080 |     43.856 |   1.3024 |     42.716 |     0.3
   10 |   1.2946 |     43.175 |   1.2742 |     42.239 |     0.4
   11 |   1.2762 |     42.786 |   1.2671 |     41.698 |     0.4
   12 |   1.2620 |     42.632 |   1.2601 |     41.826 |     0.5
   13 |   1.2454 |     41.815 |   1.2413 |     41.317 |     0.5
   14 |   1.2303 |     41.711 |   1.2325 |     40.649 |     0.5
   15 |   1.2138 |     40.997 |   1.2209 |     40.999 |     0.6
   16 |   1.1888 |     40.218 |   1.2055 |     39.854 |     0.6
   17 |   1.1770 |     39.971 |   1.2070 |     40.108 |     0.7
   18 |   1.1525 |     38.907 |   1.1862 |     39.854 |     0.7
   19 |   1.1266 |     37.848 |   1.1794 |     39.249 |     0.7
   20 |   1.1100 |     37.234 |   1.1664 |     38.073 |     0.8
   21 |   1.0899 |     36.389 |   1.1529 |     38.518 |     0.8
   22 |   1.0560 |     35.363 |   1.1426 |     36.991 |     0.8
   23 |   1.0304 |     34.255 |   1.1184 |     37.023 |     0.9
   24 |   1.0102 |     33.602 |   1.1123 |     36.578 |     0.9
   25 |   0.9861 |     32.938 |   1.1184 |     36.546 |     1.0
   26 |   0.9528 |     31.605 |   1.0909 |     35.305 |     1.0
   27 |   0.9315 |     30.843 |   1.0823 |     34.478 |     1.0
   28 |   0.9064 |     30.151 |   1.0626 |     33.651 |     1.1
   29 |   0.8809 |     29.257 |   1.0495 |     33.524 |     1.1
   30 |   0.8577 |     28.703 |   1.0499 |     33.492 |     1.2
   31 |   0.8362 |     27.825 |   1.0799 |     33.492 |     1.2
   32 |   0.8168 |     27.008 |   1.0421 |     32.475 |     1.2
   33 |   0.7951 |     26.322 |   1.0352 |     32.347 |     1.3
   34 |   0.7660 |     25.516 |   1.0524 |     32.824 |     1.3
   35 |   0.7495 |     25.110 |   1.0391 |     31.648 |     1.3
   36 |   0.7260 |     24.183 |   1.0410 |     32.538 |     1.4
   37 |   0.7005 |     23.162 |   1.0190 |     31.743 |     1.4
   38 |   0.6916 |     22.954 |   1.0430 |     31.711 |     1.5
   39 |   0.6737 |     22.641 |   1.0394 |     30.725 |     1.5
   40 |   0.6505 |     21.407 |   1.0355 |     30.630 |     1.5
   41 |   0.6286 |     20.628 |   1.0617 |     31.520 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 198,338

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5478 |     68.472 |   1.9790 |     54.071 |     0.0
    2 |   1.7372 |     48.458 |   1.5470 |     45.642 |     0.0
    3 |   1.4648 |     45.573 |   1.4038 |     44.307 |     0.0
    4 |   1.3692 |     44.388 |   1.3280 |     43.384 |     0.1
    5 |   1.3072 |     43.005 |   1.2843 |     42.303 |     0.1
    6 |   1.2601 |     41.140 |   1.2488 |     41.158 |     0.1
    7 |   1.2141 |     39.697 |   1.2190 |     39.599 |     0.1
    8 |   1.1763 |     38.616 |   1.1736 |     38.168 |     0.1
    9 |   1.1403 |     37.722 |   1.1567 |     37.595 |     0.1
   10 |   1.1040 |     36.449 |   1.1289 |     36.737 |     0.1
   11 |   1.0666 |     34.705 |   1.1011 |     35.782 |     0.1
   12 |   1.0323 |     33.394 |   1.0773 |     34.288 |     0.2
   13 |   0.9952 |     32.000 |   1.0593 |     33.429 |     0.2
   14 |   0.9535 |     30.382 |   1.0479 |     33.079 |     0.2
   15 |   0.9182 |     29.136 |   1.0398 |     32.856 |     0.2
   16 |   0.8857 |     27.968 |   1.0340 |     32.634 |     0.2
   17 |   0.8594 |     26.986 |   1.0128 |     32.029 |     0.2
   18 |   0.8186 |     25.582 |   0.9997 |     31.870 |     0.2
   19 |   0.7899 |     24.803 |   1.0049 |     31.011 |     0.3
   20 |   0.7625 |     24.188 |   1.0077 |     31.170 |     0.3
   21 |   0.7316 |     22.866 |   0.9898 |     31.011 |     0.3
   22 |   0.7051 |     22.059 |   0.9815 |     29.835 |     0.3
   23 |   0.6804 |     21.116 |   0.9820 |     29.262 |     0.3
   24 |   0.6548 |     20.200 |   0.9881 |     29.803 |     0.3
   25 |   0.6309 |     19.700 |   1.0036 |     28.976 |     0.3
   26 |   0.6058 |     18.642 |   0.9789 |     28.785 |     0.3
   27 |   0.5753 |     17.572 |   0.9798 |     28.785 |     0.4
   28 |   0.5641 |     17.320 |   0.9983 |     29.071 |     0.4
   29 |   0.5454 |     16.738 |   0.9889 |     27.863 |     0.4
   30 |   0.5203 |     15.964 |   0.9928 |     27.990 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,390,882

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1567 |     59.518 |   1.5650 |     45.802 |     0.0
    2 |   1.4486 |     45.957 |   1.3722 |     45.229 |     0.1
    3 |   1.3440 |     44.234 |   1.2915 |     42.525 |     0.1
    4 |   1.2798 |     42.138 |   1.2368 |     40.840 |     0.2
    5 |   1.2321 |     40.690 |   1.1960 |     39.567 |     0.2
    6 |   1.1762 |     38.633 |   1.1607 |     37.373 |     0.2
    7 |   1.1299 |     37.272 |   1.1200 |     36.609 |     0.3
    8 |   1.0760 |     34.858 |   1.0930 |     35.178 |     0.3
    9 |   1.0235 |     33.350 |   1.0538 |     33.938 |     0.4
   10 |   0.9872 |     32.275 |   1.0323 |     33.238 |     0.4
   11 |   0.9497 |     31.375 |   1.0145 |     32.665 |     0.5
   12 |   0.9113 |     29.729 |   0.9901 |     32.125 |     0.5
   13 |   0.8691 |     28.303 |   0.9803 |     31.775 |     0.5
   14 |   0.8309 |     27.392 |   0.9618 |     30.693 |     0.6
   15 |   0.7987 |     26.295 |   0.9741 |     30.153 |     0.6
   16 |   0.7716 |     25.225 |   0.9649 |     29.835 |     0.7
   17 |   0.7419 |     24.128 |   0.9381 |     30.121 |     0.7
   18 |   0.7093 |     23.157 |   0.9583 |     30.884 |     0.7
   19 |   0.6840 |     22.405 |   0.9386 |     28.849 |     0.8
   20 |   0.6588 |     21.341 |   0.9347 |     28.849 |     0.8
   21 |   0.6283 |     20.485 |   0.9470 |     30.184 |     0.9
   22 |   0.6060 |     19.673 |   0.9206 |     27.831 |     0.9
   23 |   0.5724 |     18.367 |   0.9574 |     29.389 |     0.9
   24 |   0.5617 |     18.356 |   0.9531 |     28.912 |     1.0
   25 |   0.5346 |     17.396 |   0.9560 |     28.276 |     1.0
   26 |   0.5203 |     16.738 |   0.9362 |     26.559 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 823,234

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3069 |     62.865 |   1.6903 |     48.982 |     0.0
    2 |   1.5224 |     46.664 |   1.4210 |     46.533 |     0.0
    3 |   1.4117 |     46.264 |   1.3902 |     45.802 |     0.1
    4 |   1.3936 |     46.050 |   1.3750 |     45.515 |     0.1
    5 |   1.3712 |     45.331 |   1.3522 |     44.179 |     0.1
    6 |   1.3277 |     44.015 |   1.2928 |     43.193 |     0.1
    7 |   1.2883 |     43.515 |   1.2722 |     43.321 |     0.2
    8 |   1.2535 |     42.632 |   1.2316 |     42.844 |     0.2
    9 |   1.2258 |     41.864 |   1.1955 |     40.840 |     0.2
   10 |   1.2030 |     40.855 |   1.1977 |     41.062 |     0.2
   11 |   1.1838 |     40.355 |   1.1682 |     39.440 |     0.3
   12 |   1.1570 |     39.061 |   1.1577 |     38.613 |     0.3
   13 |   1.1309 |     38.112 |   1.1262 |     37.818 |     0.3
   14 |   1.1114 |     37.936 |   1.1280 |     38.677 |     0.3
   15 |   1.0794 |     36.883 |   1.1148 |     36.991 |     0.3
   16 |   1.0499 |     35.808 |   1.0937 |     37.118 |     0.4
   17 |   1.0361 |     35.478 |   1.0947 |     36.641 |     0.4
   18 |   1.0475 |     35.720 |   1.1012 |     36.768 |     0.4
   19 |   1.0137 |     34.655 |   1.0712 |     35.337 |     0.4
   20 |   0.9758 |     33.196 |   1.0562 |     34.478 |     0.5
   21 |   0.9543 |     32.801 |   1.0578 |     34.288 |     0.5
   22 |   0.9334 |     31.847 |   1.0412 |     33.715 |     0.5
   23 |   0.9105 |     30.766 |   1.0439 |     33.333 |     0.5
   24 |   0.8903 |     30.124 |   1.0396 |     33.588 |     0.6
   25 |   0.8639 |     29.301 |   1.0474 |     32.793 |     0.6
   26 |   0.8460 |     28.906 |   1.0216 |     32.252 |     0.6
   27 |   0.8313 |     27.919 |   1.0248 |     32.156 |     0.6
   28 |   0.8131 |     27.085 |   1.0339 |     32.252 |     0.7
   29 |   0.7958 |     26.887 |   1.0183 |     31.330 |     0.7
   30 |   0.7673 |     25.785 |   1.0637 |     32.252 |     0.7
   31 |   0.7571 |     25.433 |   1.0271 |     31.298 |     0.7
   32 |   0.7385 |     24.589 |   1.0227 |     32.347 |     0.7
   33 |   0.7188 |     23.991 |   1.0336 |     31.552 |     0.8
   34 |   0.6998 |     23.255 |   1.0090 |     30.534 |     0.8
   35 |   0.6895 |     22.959 |   1.0284 |     31.170 |     0.8
   36 |   0.6645 |     22.191 |   1.0242 |     31.170 |     0.8
   37 |   0.6555 |     21.933 |   1.0209 |     30.248 |     0.9
   38 |   0.6244 |     20.666 |   1.0172 |     29.898 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 292,034

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5300 |     67.819 |   1.9910 |     58.556 |     0.0
    2 |   1.7608 |     49.874 |   1.5394 |     45.706 |     0.0
    3 |   1.4713 |     46.056 |   1.4036 |     45.802 |     0.1
    4 |   1.3811 |     45.205 |   1.3364 |     43.989 |     0.1
    5 |   1.3207 |     43.120 |   1.2748 |     41.190 |     0.1
    6 |   1.2676 |     41.294 |   1.2307 |     40.967 |     0.1
    7 |   1.2218 |     40.174 |   1.1962 |     39.440 |     0.1
    8 |   1.1861 |     39.192 |   1.1764 |     39.186 |     0.1
    9 |   1.1533 |     38.402 |   1.1490 |     38.104 |     0.2
   10 |   1.1167 |     37.163 |   1.1356 |     37.246 |     0.2
   11 |   1.0857 |     36.153 |   1.1068 |     36.482 |     0.2
   12 |   1.0535 |     35.023 |   1.0958 |     36.101 |     0.2
   13 |   1.0223 |     34.233 |   1.0751 |     34.637 |     0.2
   14 |   0.9937 |     32.878 |   1.0541 |     34.065 |     0.3
   15 |   0.9660 |     31.770 |   1.0588 |     33.556 |     0.3
   16 |   0.9298 |     30.409 |   1.0365 |     32.188 |     0.3
   17 |   0.9050 |     29.180 |   1.0094 |     31.584 |     0.3
   18 |   0.8759 |     28.116 |   1.0030 |     31.266 |     0.3
   19 |   0.8473 |     27.002 |   0.9838 |     30.884 |     0.3
   20 |   0.8209 |     26.262 |   0.9777 |     30.248 |     0.4
   21 |   0.7930 |     25.373 |   0.9856 |     30.916 |     0.4
   22 |   0.7659 |     24.369 |   0.9841 |     30.248 |     0.4
   23 |   0.7489 |     24.040 |   0.9611 |     29.294 |     0.4
   24 |   0.7267 |     22.937 |   0.9612 |     29.803 |     0.4
   25 |   0.7030 |     22.454 |   0.9657 |     29.294 |     0.4
   26 |   0.6823 |     21.856 |   0.9532 |     28.276 |     0.5
   27 |   0.6588 |     20.847 |   0.9561 |     28.785 |     0.5
   28 |   0.6507 |     20.490 |   0.9486 |     28.181 |     0.5
   29 |   0.6294 |     19.969 |   0.9682 |     28.562 |     0.5
   30 |   0.6098 |     19.410 |   0.9504 |     27.195 |     0.5
   31 |   0.6006 |     19.273 |   0.9531 |     27.513 |     0.5
   32 |   0.5851 |     18.494 |   0.9616 |     27.926 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 473,250

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5973 |     68.093 |   2.0324 |     58.810 |     0.0
    2 |   1.8186 |     51.295 |   1.6167 |     45.802 |     0.0
    3 |   1.5258 |     46.110 |   1.4522 |     45.802 |     0.1
    4 |   1.4370 |     46.176 |   1.4127 |     45.802 |     0.1
    5 |   1.4071 |     46.028 |   1.3862 |     45.483 |     0.1
    6 |   1.3791 |     45.732 |   1.3637 |     45.197 |     0.1
    7 |   1.3457 |     45.183 |   1.3132 |     44.338 |     0.2
    8 |   1.3120 |     44.294 |   1.2853 |     43.225 |     0.2
    9 |   1.2880 |     43.625 |   1.2837 |     44.307 |     0.2
   10 |   1.2638 |     43.093 |   1.2517 |     42.684 |     0.2
   11 |   1.2457 |     42.446 |   1.2307 |     42.239 |     0.2
   12 |   1.2252 |     41.573 |   1.2153 |     41.508 |     0.3
   13 |   1.2007 |     40.366 |   1.1970 |     40.617 |     0.3
   14 |   1.1784 |     39.555 |   1.1913 |     39.758 |     0.3
   15 |   1.1505 |     38.435 |   1.1644 |     38.613 |     0.3
   16 |   1.1278 |     38.068 |   1.1631 |     37.055 |     0.4
   17 |   1.1045 |     36.965 |   1.1346 |     37.087 |     0.4
   18 |   1.0860 |     36.471 |   1.1339 |     37.277 |     0.4
   19 |   1.0537 |     35.572 |   1.1048 |     36.959 |     0.4
   20 |   1.0368 |     35.072 |   1.0844 |     35.846 |     0.5
   21 |   1.0180 |     34.156 |   1.0915 |     35.274 |     0.5
   22 |   1.0052 |     34.063 |   1.0714 |     35.592 |     0.5
   23 |   0.9944 |     33.372 |   1.0764 |     35.560 |     0.5
   24 |   0.9758 |     33.108 |   1.0571 |     34.701 |     0.5
   25 |   0.9582 |     32.423 |   1.0632 |     34.669 |     0.6
   26 |   0.9395 |     31.847 |   1.0726 |     35.083 |     0.6
   27 |   0.9374 |     31.770 |   1.0662 |     34.256 |     0.6
   28 |   0.9105 |     30.892 |   1.0716 |     34.383 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,863,842

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2095 |     60.034 |   1.6346 |     48.919 |     0.1
    2 |   1.4931 |     46.143 |   1.4182 |     45.802 |     0.2
    3 |   1.4143 |     46.198 |   1.4017 |     45.802 |     0.2
    4 |   1.3978 |     46.198 |   1.3848 |     45.802 |     0.3
    5 |   1.3885 |     45.968 |   1.3733 |     45.324 |     0.4
    6 |   1.3693 |     44.898 |   1.3489 |     43.893 |     0.5
    7 |   1.3442 |     44.651 |   1.3324 |     44.116 |     0.5
    8 |   1.3347 |     44.316 |   1.3207 |     43.989 |     0.6
    9 |   1.3256 |     44.563 |   1.3077 |     43.670 |     0.7
   10 |   1.3099 |     43.795 |   1.2940 |     42.494 |     0.8
   11 |   1.2954 |     43.120 |   1.2892 |     42.557 |     0.9
   12 |   1.2868 |     43.137 |   1.2757 |     42.430 |     0.9
   13 |   1.2738 |     42.797 |   1.2600 |     42.176 |     1.0
   14 |   1.2592 |     42.292 |   1.2505 |     41.444 |     1.1
   15 |   1.2512 |     42.100 |   1.2468 |     41.571 |     1.2
   16 |   1.2450 |     41.957 |   1.2478 |     40.999 |     1.2
   17 |   1.2370 |     41.787 |   1.2389 |     41.062 |     1.3
   18 |   1.2304 |     41.327 |   1.2313 |     41.508 |     1.4
   19 |   1.2206 |     41.354 |   1.2234 |     40.903 |     1.5
   20 |   1.2059 |     40.630 |   1.2281 |     40.331 |     1.6
   21 |   1.1917 |     39.917 |   1.2158 |     40.267 |     1.6
   22 |   1.1831 |     39.725 |   1.2081 |     39.917 |     1.7
   23 |   1.1729 |     39.450 |   1.2115 |     39.631 |     1.8
   24 |   1.1665 |     39.324 |   1.1959 |     39.122 |     1.9
   25 |   1.1535 |     38.781 |   1.1995 |     40.140 |     1.9
   26 |   1.1392 |     38.446 |   1.1771 |     38.232 |     2.0
   27 |   1.1356 |     38.167 |   1.1818 |     39.090 |     2.1
   28 |   1.1276 |     37.788 |   1.1794 |     39.027 |     2.2
   29 |   1.1150 |     37.486 |   1.1676 |     38.454 |     2.3
   30 |   1.1074 |     37.470 |   1.1694 |     38.391 |     2.3
   31 |   1.0891 |     36.707 |   1.1571 |     37.945 |     2.4
   32 |   1.0827 |     36.499 |   1.1617 |     38.422 |     2.5
   33 |   1.0839 |     36.504 |   1.1649 |     38.295 |     2.6
   34 |   1.0685 |     36.186 |   1.1526 |     38.104 |     2.7
   35 |   1.0595 |     35.736 |   1.1462 |     37.882 |     2.7
   36 |   1.0426 |     35.489 |   1.1398 |     37.182 |     2.8
   37 |   1.0419 |     35.429 |   1.1573 |     38.136 |     2.9
   38 |   1.0421 |     35.676 |   1.1258 |     35.878 |     3.0
   39 |   1.0071 |     34.546 |   1.1400 |     37.246 |     3.0
   40 |   0.9876 |     33.739 |   1.1214 |     36.387 |     3.1
   41 |   0.9767 |     33.136 |   1.1296 |     36.164 |     3.2
   42 |   0.9655 |     32.851 |   1.1294 |     37.246 |     3.3
   43 |   0.9548 |     32.631 |   1.1259 |     36.164 |     3.4
   44 |   0.9438 |     32.264 |   1.1219 |     35.910 |     3.4
   45 |   0.9275 |     31.545 |   1.1009 |     35.019 |     3.5
   46 |   0.9229 |     31.276 |   1.1337 |     36.419 |     3.6
   47 |   0.9114 |     31.468 |   1.1150 |     35.337 |     3.7
   48 |   0.9018 |     30.607 |   1.1159 |     35.401 |     3.8
   49 |   0.8880 |     30.338 |   1.1233 |     35.719 |     3.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 456,546

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2528 |     61.235 |   1.6343 |     45.992 |     0.0
    2 |   1.4629 |     45.414 |   1.3616 |     43.511 |     0.0
    3 |   1.3146 |     42.813 |   1.2803 |     41.826 |     0.1
    4 |   1.2443 |     40.674 |   1.2169 |     39.122 |     0.1
    5 |   1.1793 |     38.446 |   1.1627 |     38.168 |     0.1
    6 |   1.1180 |     36.329 |   1.1105 |     36.291 |     0.1
    7 |   1.0568 |     34.540 |   1.0757 |     35.433 |     0.1
    8 |   0.9938 |     32.384 |   1.0419 |     33.874 |     0.1
    9 |   0.9334 |     30.470 |   1.0135 |     31.966 |     0.2
   10 |   0.8829 |     28.511 |   0.9984 |     31.552 |     0.2
   11 |   0.8193 |     26.306 |   0.9507 |     30.375 |     0.2
   12 |   0.7649 |     24.413 |   0.9514 |     29.930 |     0.2
   13 |   0.7098 |     22.504 |   0.9427 |     29.135 |     0.2
   14 |   0.6632 |     21.083 |   0.9424 |     29.548 |     0.2
   15 |   0.6076 |     19.251 |   0.9289 |     27.799 |     0.3
   16 |   0.5619 |     17.583 |   0.9400 |     28.276 |     0.3
   17 |   0.5208 |     16.217 |   0.9386 |     27.004 |     0.3
   18 |   0.4721 |     14.609 |   0.9434 |     26.622 |     0.3
   19 |   0.4326 |     13.156 |   0.9640 |     27.481 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 720,738

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3317 |     63.051 |   1.7115 |     48.919 |     0.0
    2 |   1.5327 |     46.730 |   1.4276 |     45.802 |     0.0
    3 |   1.4135 |     46.121 |   1.3910 |     45.802 |     0.1
    4 |   1.3867 |     45.935 |   1.3632 |     44.402 |     0.1
    5 |   1.3545 |     44.849 |   1.3398 |     44.084 |     0.1
    6 |   1.3285 |     44.481 |   1.3230 |     44.434 |     0.1
    7 |   1.3010 |     43.965 |   1.2931 |     43.989 |     0.1
    8 |   1.2784 |     43.241 |   1.2731 |     42.239 |     0.1
    9 |   1.2512 |     42.160 |   1.2555 |     41.889 |     0.2
   10 |   1.2226 |     40.986 |   1.2428 |     41.571 |     0.2
   11 |   1.1974 |     40.251 |   1.2195 |     40.776 |     0.2
   12 |   1.1652 |     39.598 |   1.2088 |     39.186 |     0.2
   13 |   1.1255 |     37.980 |   1.1922 |     39.249 |     0.2
   14 |   1.0921 |     36.987 |   1.1716 |     38.868 |     0.2
   15 |   1.0680 |     36.252 |   1.1690 |     38.836 |     0.3
   16 |   1.0221 |     34.458 |   1.1559 |     37.341 |     0.3
   17 |   0.9830 |     33.350 |   1.1461 |     37.277 |     0.3
   18 |   0.9550 |     31.907 |   1.1280 |     35.782 |     0.3
   19 |   0.9127 |     30.700 |   1.1502 |     35.464 |     0.3
   20 |   0.8739 |     29.191 |   1.1221 |     34.669 |     0.4
   21 |   0.8403 |     27.759 |   1.1193 |     35.337 |     0.4
   22 |   0.8044 |     26.635 |   1.0959 |     34.065 |     0.4
   23 |   0.7629 |     24.748 |   1.1094 |     33.461 |     0.4
   24 |   0.7249 |     23.766 |   1.1206 |     33.429 |     0.4
   25 |   0.6993 |     22.668 |   1.1238 |     32.475 |     0.4
   26 |   0.6700 |     21.654 |   1.1277 |     32.570 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 773,154

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2748 |     61.323 |   1.6420 |     48.919 |     0.0
    2 |   1.4838 |     46.385 |   1.4027 |     45.802 |     0.0
    3 |   1.3907 |     46.023 |   1.3557 |     45.833 |     0.1
    4 |   1.3414 |     44.569 |   1.3109 |     42.875 |     0.1
    5 |   1.2961 |     43.175 |   1.2762 |     42.366 |     0.1
    6 |   1.2614 |     42.385 |   1.2447 |     41.603 |     0.1
    7 |   1.2228 |     41.217 |   1.2123 |     40.426 |     0.1
    8 |   1.1887 |     40.323 |   1.1851 |     39.504 |     0.1
    9 |   1.1498 |     38.710 |   1.1757 |     39.027 |     0.2
   10 |   1.1091 |     37.601 |   1.1564 |     39.249 |     0.2
   11 |   1.0679 |     36.565 |   1.1341 |     38.041 |     0.2
   12 |   1.0392 |     35.500 |   1.1313 |     37.786 |     0.2
   13 |   0.9970 |     34.310 |   1.1289 |     36.737 |     0.2
   14 |   0.9612 |     32.521 |   1.1178 |     36.578 |     0.2
   15 |   0.9230 |     31.221 |   1.1008 |     35.146 |     0.3
   16 |   0.8849 |     29.734 |   1.1034 |     34.256 |     0.3
   17 |   0.8497 |     28.363 |   1.1041 |     33.461 |     0.3
   18 |   0.8101 |     27.156 |   1.0825 |     33.238 |     0.3
   19 |   0.7743 |     25.834 |   1.0960 |     32.729 |     0.3
   20 |   0.7456 |     24.589 |   1.0721 |     32.093 |     0.3
   21 |   0.7094 |     22.959 |   1.0683 |     31.870 |     0.4
   22 |   0.7010 |     23.146 |   1.1067 |     32.252 |     0.4
   23 |   0.6665 |     21.604 |   1.0789 |     31.679 |     0.4
   24 |   0.6250 |     20.205 |   1.0758 |     30.248 |     0.4
   25 |   0.5895 |     19.081 |   1.0805 |     30.025 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 887,074

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3327 |     62.662 |   1.6790 |     48.950 |     0.0
    2 |   1.5045 |     46.396 |   1.4189 |     45.802 |     0.0
    3 |   1.4035 |     46.209 |   1.3774 |     46.438 |     0.1
    4 |   1.3633 |     45.820 |   1.3301 |     45.006 |     0.1
    5 |   1.3324 |     45.150 |   1.3079 |     44.593 |     0.1
    6 |   1.2986 |     44.629 |   1.2773 |     44.148 |     0.1
    7 |   1.2729 |     43.883 |   1.2528 |     44.338 |     0.2
    8 |   1.2413 |     42.577 |   1.2158 |     41.062 |     0.2
    9 |   1.2073 |     40.981 |   1.1987 |     39.408 |     0.2
   10 |   1.1674 |     39.653 |   1.1783 |     38.804 |     0.2
   11 |   1.1318 |     38.167 |   1.1349 |     38.868 |     0.3
   12 |   1.1005 |     37.113 |   1.1203 |     37.786 |     0.3
   13 |   1.0671 |     36.016 |   1.1071 |     37.246 |     0.3
   14 |   1.0345 |     34.716 |   1.1085 |     36.641 |     0.3
   15 |   1.0013 |     33.695 |   1.0769 |     35.274 |     0.3
   16 |   0.9769 |     32.620 |   1.0758 |     34.860 |     0.4
   17 |   0.9512 |     31.622 |   1.0539 |     33.842 |     0.4
   18 |   0.9196 |     30.722 |   1.0453 |     33.365 |     0.4
   19 |   0.8976 |     29.921 |   1.0460 |     33.333 |     0.4
   20 |   0.8684 |     28.972 |   1.0490 |     32.156 |     0.5
   21 |   0.8429 |     28.023 |   1.0181 |     31.679 |     0.5
   22 |   0.8108 |     26.882 |   1.0181 |     32.061 |     0.5
   23 |   0.7935 |     26.108 |   1.0164 |     31.330 |     0.5
   24 |   0.7624 |     25.033 |   1.0240 |     30.344 |     0.6
   25 |   0.7482 |     24.495 |   1.0261 |     31.520 |     0.6
   26 |   0.7294 |     24.013 |   1.0166 |     30.598 |     0.6
   27 |   0.6919 |     22.690 |   1.0247 |     30.184 |     0.6
   28 |   0.6726 |     21.999 |   1.0157 |     29.835 |     0.6
   29 |   0.6506 |     21.045 |   1.0259 |     29.898 |     0.7
   30 |   0.6368 |     20.628 |   1.0063 |     29.039 |     0.7
   31 |   0.6100 |     19.574 |   1.0378 |     29.008 |     0.7
   32 |   0.5965 |     19.465 |   1.0202 |     28.467 |     0.7
   33 |   0.5764 |     18.707 |   1.0521 |     29.835 |     0.8
   34 |   0.5646 |     18.488 |   1.0634 |     29.167 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,535,330

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5380 |     67.621 |   1.9976 |     58.810 |     0.1
    2 |   1.7707 |     49.473 |   1.5681 |     45.802 |     0.2
    3 |   1.4987 |     46.105 |   1.4474 |     45.802 |     0.2
    4 |   1.4338 |     46.259 |   1.4093 |     45.802 |     0.3
    5 |   1.4105 |     46.215 |   1.3943 |     45.802 |     0.4
    6 |   1.4002 |     46.105 |   1.3902 |     45.802 |     0.5
    7 |   1.3940 |     46.110 |   1.3826 |     45.802 |     0.5
    8 |   1.3894 |     46.105 |   1.3798 |     45.802 |     0.6
    9 |   1.3873 |     46.105 |   1.3783 |     45.802 |     0.7
   10 |   1.3808 |     46.105 |   1.3725 |     45.802 |     0.8
   11 |   1.3753 |     46.056 |   1.3651 |     45.738 |     0.9
   12 |   1.3659 |     45.633 |   1.3490 |     44.020 |     0.9
   13 |   1.3541 |     44.657 |   1.3424 |     44.561 |     1.0
   14 |   1.3408 |     44.684 |   1.3266 |     44.211 |     1.1
   15 |   1.3334 |     44.706 |   1.3196 |     44.179 |     1.2
   16 |   1.3248 |     44.514 |   1.3131 |     43.734 |     1.3
   17 |   1.3184 |     43.954 |   1.3056 |     43.257 |     1.3
   18 |   1.3054 |     43.444 |   1.2972 |     42.684 |     1.4
   19 |   1.3013 |     43.378 |   1.2914 |     42.875 |     1.5
   20 |   1.2952 |     43.296 |   1.2903 |     42.176 |     1.6
   21 |   1.2920 |     43.236 |   1.2861 |     42.525 |     1.6
   22 |   1.2828 |     43.038 |   1.2820 |     42.017 |     1.7
   23 |   1.2766 |     42.704 |   1.2794 |     41.953 |     1.8
   24 |   1.2676 |     42.715 |   1.2892 |     42.684 |     1.9
   25 |   1.2633 |     42.330 |   1.2580 |     41.476 |     2.0
   26 |   1.2495 |     42.100 |   1.2575 |     41.285 |     2.0
   27 |   1.2425 |     41.469 |   1.2529 |     41.667 |     2.1
   28 |   1.2303 |     41.118 |   1.2514 |     41.158 |     2.2
   29 |   1.2252 |     41.036 |   1.2491 |     41.031 |     2.3
   30 |   1.2240 |     41.129 |   1.2612 |     41.539 |     2.3
   31 |   1.2162 |     41.036 |   1.2481 |     41.476 |     2.4
   32 |   1.2125 |     40.849 |   1.2455 |     41.476 |     2.5
   33 |   1.2017 |     40.608 |   1.2378 |     40.140 |     2.6
   34 |   1.1956 |     40.295 |   1.2366 |     40.553 |     2.7
   35 |   1.1908 |     39.867 |   1.2300 |     40.649 |     2.7
   36 |   1.1829 |     39.692 |   1.2166 |     40.299 |     2.8
   37 |   1.1753 |     39.670 |   1.2107 |     40.172 |     2.9
   38 |   1.1638 |     38.989 |   1.2110 |     40.331 |     3.0
   39 |   1.1583 |     38.754 |   1.2103 |     39.249 |     3.1
   40 |   1.1523 |     38.397 |   1.2211 |     40.108 |     3.1
   41 |   1.1457 |     38.479 |   1.2030 |     39.949 |     3.2
   42 |   1.1395 |     38.408 |   1.1932 |     40.108 |     3.3
   43 |   1.1370 |     38.117 |   1.1981 |     39.790 |     3.4
   44 |   1.1354 |     38.101 |   1.1967 |     39.695 |     3.4
   45 |   1.1214 |     37.640 |   1.1932 |     39.408 |     3.5
   46 |   1.1141 |     37.459 |   1.1833 |     39.186 |     3.6
   47 |   1.1020 |     36.998 |   1.1942 |     39.249 |     3.7
   48 |   1.0934 |     36.559 |   1.1797 |     38.550 |     3.7
   49 |   1.0962 |     36.927 |   1.1791 |     39.027 |     3.8
   50 |   1.0878 |     36.641 |   1.1836 |     38.613 |     3.9
   51 |   1.0846 |     36.576 |   1.1638 |     38.518 |     4.0
   52 |   1.0746 |     36.449 |   1.1787 |     38.295 |     4.1
   53 |   1.0677 |     36.076 |   1.1714 |     38.263 |     4.1
   54 |   1.0630 |     36.060 |   1.1836 |     38.454 |     4.2
   55 |   1.0460 |     35.242 |   1.1665 |     38.645 |     4.3
   56 |   1.0361 |     34.902 |   1.1556 |     37.564 |     4.4
   57 |   1.0272 |     34.601 |   1.1543 |     37.595 |     4.4
   58 |   1.0175 |     34.211 |   1.1491 |     38.009 |     4.5
   59 |   1.0129 |     34.206 |   1.1616 |     37.913 |     4.6
   60 |   1.0137 |     34.546 |   1.1476 |     37.277 |     4.7
   61 |   1.0168 |     34.573 |   1.1483 |     37.595 |     4.8
   62 |   1.0011 |     33.778 |   1.1483 |     36.927 |     4.8
   63 |   0.9910 |     33.465 |   1.1380 |     36.832 |     4.9
   64 |   0.9813 |     33.169 |   1.1335 |     36.991 |     5.0
   65 |   0.9693 |     32.713 |   1.1243 |     36.514 |     5.1
   66 |   0.9666 |     32.488 |   1.1398 |     36.896 |     5.2
   67 |   0.9600 |     32.428 |   1.1334 |     36.673 |     5.2
   68 |   0.9612 |     32.461 |   1.1411 |     36.291 |     5.3
   69 |   0.9490 |     31.984 |   1.1458 |     35.973 |     5.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 598,914

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2512 |     60.133 |   1.6380 |     48.919 |     0.0
    2 |   1.4613 |     45.556 |   1.3616 |     43.702 |     0.0
    3 |   1.3339 |     43.795 |   1.2911 |     42.716 |     0.1
    4 |   1.2661 |     41.606 |   1.2281 |     39.472 |     0.1
    5 |   1.2017 |     39.077 |   1.1845 |     38.645 |     0.1
    6 |   1.1432 |     37.645 |   1.1469 |     37.373 |     0.1
    7 |   1.0838 |     35.720 |   1.0984 |     36.069 |     0.1
    8 |   1.0222 |     33.942 |   1.0638 |     33.810 |     0.1
    9 |   0.9725 |     31.901 |   1.0345 |     33.938 |     0.2
   10 |   0.9231 |     30.579 |   1.0060 |     32.347 |     0.2
   11 |   0.8691 |     28.533 |   1.0043 |     31.902 |     0.2
   12 |   0.8204 |     26.426 |   0.9718 |     30.693 |     0.2
   13 |   0.7690 |     25.159 |   0.9487 |     29.898 |     0.2
   14 |   0.7264 |     23.316 |   0.9523 |     29.739 |     0.2
   15 |   0.6715 |     21.511 |   0.9352 |     28.594 |     0.3
   16 |   0.6279 |     20.304 |   0.9521 |     29.453 |     0.3
   17 |   0.5784 |     18.181 |   0.9486 |     29.008 |     0.3
   18 |   0.5392 |     17.089 |   0.9302 |     27.926 |     0.3
   19 |   0.5076 |     15.860 |   0.9442 |     28.053 |     0.3
   20 |   0.4691 |     14.692 |   0.9371 |     27.926 |     0.3
   21 |   0.4318 |     13.496 |   0.9426 |     27.449 |     0.4
   22 |   0.4036 |     12.481 |   0.9609 |     26.845 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 236,514

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5363 |     68.356 |   1.9362 |     54.198 |     0.0
    2 |   1.6914 |     48.585 |   1.5044 |     45.802 |     0.0
    3 |   1.4483 |     45.809 |   1.3856 |     45.452 |     0.0
    4 |   1.3615 |     44.322 |   1.3079 |     42.748 |     0.1
    5 |   1.2933 |     42.347 |   1.2566 |     41.698 |     0.1
    6 |   1.2434 |     41.113 |   1.2112 |     40.331 |     0.1
    7 |   1.1977 |     39.686 |   1.1776 |     39.186 |     0.1
    8 |   1.1591 |     38.573 |   1.1486 |     37.977 |     0.1
    9 |   1.1262 |     37.415 |   1.1432 |     38.073 |     0.1
   10 |   1.0867 |     35.857 |   1.0970 |     35.973 |     0.1
   11 |   1.0524 |     34.442 |   1.0709 |     33.938 |     0.2
   12 |   1.0181 |     32.966 |   1.0508 |     34.065 |     0.2
   13 |   0.9780 |     31.638 |   1.0175 |     33.111 |     0.2
   14 |   0.9426 |     30.453 |   1.0122 |     31.711 |     0.2
   15 |   0.9138 |     29.460 |   1.0008 |     31.838 |     0.2
   16 |   0.8761 |     27.743 |   0.9756 |     30.184 |     0.2
   17 |   0.8483 |     26.750 |   0.9704 |     29.612 |     0.2
   18 |   0.8195 |     26.289 |   0.9498 |     29.389 |     0.3
   19 |   0.7912 |     25.104 |   0.9404 |     28.880 |     0.3
   20 |   0.7679 |     24.259 |   0.9411 |     28.849 |     0.3
   21 |   0.7406 |     23.316 |   0.9274 |     28.276 |     0.3
   22 |   0.7166 |     22.608 |   0.9243 |     27.163 |     0.3
   23 |   0.6931 |     21.692 |   0.9199 |     27.831 |     0.3
   24 |   0.6721 |     21.204 |   0.9039 |     26.622 |     0.3
   25 |   0.6578 |     20.540 |   0.9114 |     27.385 |     0.4
   26 |   0.6354 |     20.074 |   0.8978 |     26.081 |     0.4
   27 |   0.6177 |     19.530 |   0.9011 |     26.399 |     0.4
   28 |   0.5961 |     18.598 |   0.9059 |     26.622 |     0.4
   29 |   0.5813 |     18.340 |   0.8942 |     25.477 |     0.4
   30 |   0.5681 |     17.846 |   0.8945 |     25.668 |     0.4
   31 |   0.5545 |     17.720 |   0.9017 |     25.795 |     0.4
   32 |   0.5397 |     17.067 |   0.9033 |     26.240 |     0.4
   33 |   0.5189 |     16.453 |   0.9118 |     26.018 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 730,850

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5256 |     67.320 |   1.9108 |     57.506 |     0.0
    2 |   1.7196 |     49.797 |   1.5440 |     45.865 |     0.1
    3 |   1.4894 |     46.209 |   1.4331 |     45.802 |     0.1
    4 |   1.4223 |     46.061 |   1.3971 |     45.802 |     0.1
    5 |   1.3946 |     46.023 |   1.3679 |     45.134 |     0.1
    6 |   1.3704 |     45.507 |   1.3493 |     45.706 |     0.2
    7 |   1.3401 |     44.843 |   1.3103 |     44.975 |     0.2
    8 |   1.3061 |     43.494 |   1.2785 |     43.130 |     0.2
    9 |   1.2794 |     42.506 |   1.2496 |     41.380 |     0.3
   10 |   1.2525 |     41.831 |   1.2392 |     40.872 |     0.3
   11 |   1.2293 |     41.080 |   1.2176 |     40.999 |     0.3
   12 |   1.2071 |     40.537 |   1.1998 |     40.204 |     0.3
   13 |   1.1865 |     39.763 |   1.1810 |     39.567 |     0.4
   14 |   1.1633 |     39.039 |   1.1643 |     38.995 |     0.4
   15 |   1.1446 |     38.391 |   1.1619 |     39.186 |     0.4
   16 |   1.1378 |     38.156 |   1.1474 |     38.327 |     0.4
   17 |   1.1150 |     37.601 |   1.1301 |     37.182 |     0.5
   18 |   1.1027 |     37.152 |   1.1280 |     37.500 |     0.5
   19 |   1.0842 |     36.301 |   1.1104 |     37.023 |     0.5
   20 |   1.0636 |     35.747 |   1.1119 |     36.641 |     0.6
   21 |   1.0509 |     35.456 |   1.1065 |     36.673 |     0.6
   22 |   1.0411 |     35.577 |   1.0900 |     36.260 |     0.6
   23 |   1.0279 |     34.820 |   1.1039 |     36.260 |     0.6
   24 |   1.0133 |     34.178 |   1.0843 |     36.896 |     0.7
   25 |   0.9944 |     33.498 |   1.0739 |     35.433 |     0.7
   26 |   0.9834 |     33.503 |   1.0586 |     34.733 |     0.7
   27 |   0.9662 |     32.768 |   1.0935 |     35.210 |     0.8
   28 |   0.9652 |     32.659 |   1.0652 |     34.224 |     0.8
   29 |   0.9464 |     31.808 |   1.0673 |     34.637 |     0.8
   30 |   0.9264 |     31.177 |   1.0602 |     34.478 |     0.8
   31 |   0.9104 |     31.194 |   1.0475 |     34.224 |     0.9
   32 |   0.8986 |     30.662 |   1.0489 |     33.524 |     0.9
   33 |   0.8846 |     30.086 |   1.0463 |     33.969 |     0.9
   34 |   0.8827 |     29.926 |   1.0459 |     34.351 |     0.9
   35 |   0.8654 |     29.147 |   1.0359 |     33.142 |     1.0
   36 |   0.8590 |     28.840 |   1.0375 |     34.033 |     1.0
   37 |   0.8444 |     28.259 |   1.0270 |     33.142 |     1.0
   38 |   0.8295 |     27.639 |   1.0071 |     31.520 |     1.1
   39 |   0.8097 |     27.156 |   1.0202 |     31.934 |     1.1
   40 |   0.8161 |     27.403 |   1.0037 |     32.188 |     1.1
   41 |   0.7936 |     26.673 |   1.0143 |     32.506 |     1.1
   42 |   0.7775 |     25.938 |   1.0058 |     32.347 |     1.2
   43 |   0.7696 |     25.614 |   1.0185 |     33.079 |     1.2
   44 |   0.7660 |     25.340 |   1.0142 |     31.616 |     1.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 325,314

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5743 |     68.137 |   2.0078 |     58.429 |     0.0
    2 |   1.7535 |     50.208 |   1.5534 |     45.802 |     0.0
    3 |   1.4894 |     46.138 |   1.4332 |     45.802 |     0.1
    4 |   1.4236 |     46.116 |   1.3990 |     45.802 |     0.1
    5 |   1.3980 |     46.105 |   1.3748 |     45.802 |     0.1
    6 |   1.3760 |     45.968 |   1.3614 |     45.197 |     0.1
    7 |   1.3480 |     45.255 |   1.3240 |     44.625 |     0.1
    8 |   1.3119 |     43.559 |   1.2915 |     43.416 |     0.1
    9 |   1.2827 |     42.676 |   1.2549 |     42.589 |     0.2
   10 |   1.2522 |     41.842 |   1.2253 |     40.204 |     0.2
   11 |   1.2254 |     40.778 |   1.2142 |     40.903 |     0.2
   12 |   1.2011 |     39.878 |   1.1986 |     39.726 |     0.2
   13 |   1.1767 |     39.187 |   1.1840 |     39.059 |     0.2
   14 |   1.1578 |     38.496 |   1.1647 |     38.772 |     0.3
   15 |   1.1368 |     38.024 |   1.1528 |     37.850 |     0.3
   16 |   1.1146 |     37.344 |   1.1390 |     37.977 |     0.3
   17 |   1.0952 |     37.130 |   1.1277 |     37.532 |     0.3
   18 |   1.0709 |     36.175 |   1.1173 |     37.150 |     0.3
   19 |   1.0495 |     35.555 |   1.1001 |     36.673 |     0.3
   20 |   1.0237 |     34.809 |   1.0945 |     36.005 |     0.4
   21 |   1.0056 |     33.948 |   1.0946 |     35.846 |     0.4
   22 |   0.9820 |     33.213 |   1.0740 |     35.051 |     0.4
   23 |   0.9642 |     32.439 |   1.0742 |     34.637 |     0.4
   24 |   0.9407 |     31.649 |   1.0528 |     34.288 |     0.4
   25 |   0.9145 |     30.492 |   1.0564 |     33.747 |     0.5
   26 |   0.9017 |     29.916 |   1.0425 |     33.842 |     0.5
   27 |   0.8850 |     29.361 |   1.0344 |     33.683 |     0.5
   28 |   0.8523 |     28.198 |   1.0353 |     32.602 |     0.5
   29 |   0.8271 |     27.156 |   1.0291 |     32.284 |     0.5
   30 |   0.8135 |     26.843 |   1.0203 |     32.188 |     0.5
   31 |   0.7953 |     26.218 |   1.0309 |     32.697 |     0.6
   32 |   0.7740 |     25.258 |   1.0310 |     32.665 |     0.6
   33 |   0.7643 |     24.808 |   1.0445 |     33.206 |     0.6
   34 |   0.7477 |     24.539 |   1.0171 |     32.316 |     0.6
   35 |   0.7242 |     23.661 |   1.0188 |     31.266 |     0.6
   36 |   0.7043 |     23.025 |   1.0365 |     31.107 |     0.7
   37 |   0.6991 |     22.817 |   1.0161 |     32.125 |     0.7
   38 |   0.6779 |     22.197 |   1.0194 |     30.948 |     0.7
   39 |   0.6545 |     21.077 |   1.0079 |     30.916 |     0.7
   40 |   0.6460 |     20.748 |   1.0450 |     31.552 |     0.7
   41 |   0.6290 |     20.315 |   1.0452 |     31.552 |     0.7
   42 |   0.6141 |     19.838 |   1.0200 |     30.439 |     0.8
   43 |   0.6010 |     19.426 |   1.0256 |     30.184 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 1,088,450

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2993 |     62.678 |   1.6689 |     48.919 |     0.0
    2 |   1.5040 |     46.478 |   1.4125 |     45.802 |     0.0
    3 |   1.4076 |     46.127 |   1.3871 |     45.802 |     0.1
    4 |   1.3905 |     46.204 |   1.3723 |     45.802 |     0.1
    5 |   1.3746 |     45.946 |   1.3532 |     44.148 |     0.1
    6 |   1.3492 |     44.810 |   1.3255 |     43.798 |     0.1
    7 |   1.3321 |     44.503 |   1.3264 |     43.607 |     0.2
    8 |   1.3077 |     43.751 |   1.2985 |     43.830 |     0.2
    9 |   1.2897 |     43.707 |   1.2879 |     43.480 |     0.2
   10 |   1.2573 |     42.665 |   1.2403 |     42.430 |     0.2
   11 |   1.2258 |     41.804 |   1.2043 |     40.840 |     0.3
   12 |   1.2055 |     40.893 |   1.1925 |     40.235 |     0.3
   13 |   1.1776 |     40.185 |   1.1786 |     39.663 |     0.3
   14 |   1.1539 |     39.110 |   1.1696 |     39.281 |     0.3
   15 |   1.1352 |     38.463 |   1.1539 |     38.772 |     0.4
   16 |   1.1194 |     37.684 |   1.1331 |     37.913 |     0.4
   17 |   1.0867 |     36.351 |   1.1297 |     37.627 |     0.4
   18 |   1.0668 |     35.758 |   1.1223 |     37.977 |     0.4
   19 |   1.0547 |     35.648 |   1.1149 |     37.023 |     0.5
   20 |   1.0294 |     34.705 |   1.1062 |     36.069 |     0.5
   21 |   0.9982 |     33.394 |   1.0950 |     35.751 |     0.5
   22 |   0.9783 |     32.697 |   1.0695 |     35.146 |     0.5
   23 |   0.9468 |     31.869 |   1.0773 |     34.574 |     0.6
   24 |   0.9368 |     31.314 |   1.0473 |     34.669 |     0.6
   25 |   0.9033 |     30.075 |   1.0609 |     34.319 |     0.6
   26 |   0.8797 |     29.647 |   1.0913 |     35.019 |     0.6
   27 |   0.8712 |     28.988 |   1.0471 |     33.461 |     0.7
   28 |   0.8447 |     28.100 |   1.0497 |     33.429 |     0.7
   29 |   0.8182 |     27.271 |   1.0511 |     34.065 |     0.7
   30 |   0.7826 |     25.658 |   1.0453 |     33.938 |     0.7
   31 |   0.7655 |     25.329 |   1.0141 |     32.316 |     0.8
   32 |   0.7376 |     24.501 |   1.0501 |     32.602 |     0.8
   33 |   0.7206 |     23.574 |   1.0511 |     31.838 |     0.8
   34 |   0.6951 |     22.685 |   1.0596 |     31.807 |     0.8
   35 |   0.6775 |     22.389 |   1.0808 |     32.602 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,177,762

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1784 |     59.063 |   1.5762 |     45.802 |     0.1
    2 |   1.4702 |     46.237 |   1.4120 |     45.802 |     0.1
    3 |   1.4070 |     46.160 |   1.3881 |     45.802 |     0.2
    4 |   1.3913 |     46.077 |   1.3728 |     45.802 |     0.2
    5 |   1.3709 |     45.287 |   1.3450 |     43.989 |     0.3
    6 |   1.3454 |     44.689 |   1.3316 |     44.052 |     0.4
    7 |   1.3249 |     44.130 |   1.3085 |     43.734 |     0.4
    8 |   1.3142 |     43.757 |   1.3005 |     42.907 |     0.5
    9 |   1.2964 |     43.291 |   1.2892 |     42.525 |     0.5
   10 |   1.2807 |     42.758 |   1.2742 |     42.207 |     0.6
   11 |   1.2667 |     42.336 |   1.2711 |     42.271 |     0.7
   12 |   1.2558 |     42.243 |   1.2624 |     41.953 |     0.7
   13 |   1.2434 |     41.743 |   1.2625 |     42.207 |     0.8
   14 |   1.2284 |     41.332 |   1.2431 |     41.539 |     0.8
   15 |   1.2164 |     41.047 |   1.2468 |     41.031 |     0.9
   16 |   1.1936 |     40.037 |   1.2262 |     40.394 |     1.0
   17 |   1.1761 |     39.242 |   1.2167 |     39.854 |     1.0
   18 |   1.1598 |     38.583 |   1.1996 |     38.931 |     1.1
   19 |   1.1439 |     38.073 |   1.1986 |     39.313 |     1.1
   20 |   1.1297 |     37.409 |   1.1751 |     38.836 |     1.2
   21 |   1.1108 |     36.762 |   1.1675 |     38.391 |     1.3
   22 |   1.0851 |     35.764 |   1.1507 |     37.087 |     1.3
   23 |   1.0700 |     35.572 |   1.1487 |     36.800 |     1.4
   24 |   1.0408 |     34.875 |   1.1272 |     36.355 |     1.4
   25 |   1.0198 |     34.030 |   1.1319 |     36.832 |     1.5
   26 |   0.9957 |     32.960 |   1.1082 |     35.941 |     1.6
   27 |   0.9680 |     31.890 |   1.1123 |     35.242 |     1.6
   28 |   0.9600 |     31.869 |   1.0996 |     35.464 |     1.7
   29 |   0.9324 |     30.985 |   1.0902 |     35.083 |     1.7
   30 |   0.9160 |     30.437 |   1.1052 |     34.669 |     1.8
   31 |   0.8963 |     30.042 |   1.0695 |     33.620 |     1.9
   32 |   0.8680 |     28.687 |   1.0737 |     34.288 |     1.9
   33 |   0.8513 |     28.226 |   1.0899 |     34.860 |     2.0
   34 |   0.8267 |     27.688 |   1.0791 |     33.906 |     2.0
   35 |   0.8079 |     26.997 |   1.0781 |     33.588 |     2.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 558,082

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2177 |     59.666 |   1.5813 |     45.802 |     0.0
    2 |   1.4532 |     45.957 |   1.3750 |     45.642 |     0.0
    3 |   1.3428 |     44.717 |   1.3048 |     44.338 |     0.0
    4 |   1.2920 |     43.576 |   1.2616 |     43.034 |     0.1
    5 |   1.2345 |     41.508 |   1.2276 |     40.872 |     0.1
    6 |   1.1814 |     39.681 |   1.1716 |     39.408 |     0.1
    7 |   1.1238 |     37.519 |   1.1329 |     37.405 |     0.1
    8 |   1.0716 |     35.928 |   1.1067 |     36.705 |     0.1
    9 |   1.0132 |     34.112 |   1.0813 |     34.860 |     0.1
   10 |   0.9482 |     32.170 |   1.0582 |     34.383 |     0.1
   11 |   0.9009 |     30.102 |   1.0319 |     32.538 |     0.2
   12 |   0.8467 |     28.171 |   0.9993 |     30.948 |     0.2
   13 |   0.7929 |     26.251 |   1.0096 |     30.948 |     0.2
   14 |   0.7402 |     23.870 |   1.0135 |     31.043 |     0.2
   15 |   0.6954 |     22.180 |   0.9985 |     30.089 |     0.2
   16 |   0.6598 |     20.973 |   0.9813 |     29.008 |     0.2
   17 |   0.6134 |     19.163 |   0.9723 |     28.085 |     0.2
   18 |   0.5680 |     17.747 |   0.9878 |     28.785 |     0.2
   19 |   0.5291 |     16.239 |   1.0015 |     27.926 |     0.3
   20 |   0.4937 |     15.109 |   1.0142 |     27.831 |     0.3
   21 |   0.4589 |     14.022 |   0.9997 |     26.877 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 2,782,690

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1751 |     59.167 |   1.5827 |     45.802 |     0.1
    2 |   1.4732 |     46.105 |   1.4060 |     45.642 |     0.2
    3 |   1.3971 |     45.545 |   1.3619 |     44.275 |     0.2
    4 |   1.3589 |     44.744 |   1.3342 |     44.052 |     0.3
    5 |   1.3234 |     43.653 |   1.2968 |     42.494 |     0.4
    6 |   1.2939 |     42.835 |   1.2756 |     42.844 |     0.5
    7 |   1.2657 |     42.078 |   1.2609 |     41.667 |     0.6
    8 |   1.2458 |     41.272 |   1.2372 |     41.031 |     0.7
    9 |   1.2200 |     40.460 |   1.2274 |     41.190 |     0.7
   10 |   1.2016 |     39.922 |   1.2078 |     39.885 |     0.8
   11 |   1.1788 |     39.214 |   1.1995 |     38.550 |     0.9
   12 |   1.1582 |     38.501 |   1.1845 |     39.567 |     1.0
   13 |   1.1335 |     38.002 |   1.1675 |     38.518 |     1.1
   14 |   1.1193 |     37.119 |   1.1383 |     37.691 |     1.2
   15 |   1.0949 |     36.395 |   1.1404 |     37.691 |     1.2
   16 |   1.0795 |     35.945 |   1.1185 |     37.309 |     1.3
   17 |   1.0621 |     35.561 |   1.1369 |     38.232 |     1.4
   18 |   1.0521 |     35.489 |   1.1139 |     37.309 |     1.5
   19 |   1.0280 |     34.376 |   1.0945 |     36.546 |     1.6
   20 |   1.0080 |     33.553 |   1.1057 |     36.291 |     1.7
   21 |   0.9964 |     33.322 |   1.0943 |     36.260 |     1.7
   22 |   0.9761 |     32.790 |   1.0821 |     35.592 |     1.8
   23 |   0.9670 |     32.686 |   1.0828 |     35.910 |     1.9
   24 |   0.9571 |     32.110 |   1.0774 |     36.355 |     2.0
   25 |   0.9347 |     31.688 |   1.0669 |     35.083 |     2.1
   26 |   0.9143 |     30.716 |   1.0567 |     34.128 |     2.2
   27 |   0.9014 |     30.261 |   1.0477 |     34.224 |     2.2
   28 |   0.8842 |     29.630 |   1.0529 |     34.033 |     2.3
   29 |   0.8691 |     29.131 |   1.0412 |     33.397 |     2.4
   30 |   0.8562 |     28.944 |   1.0664 |     34.097 |     2.5
   31 |   0.8547 |     28.813 |   1.0304 |     33.270 |     2.6
   32 |   0.8293 |     28.017 |   1.0335 |     32.665 |     2.7
   33 |   0.8068 |     27.112 |   1.0368 |     32.824 |     2.7
   34 |   0.7933 |     26.799 |   1.0219 |     32.570 |     2.8
   35 |   0.7784 |     26.251 |   1.0148 |     31.775 |     2.9
   36 |   0.7770 |     26.575 |   1.0272 |     32.156 |     3.0
   37 |   0.7608 |     26.108 |   1.0327 |     31.902 |     3.1
   38 |   0.7400 |     25.132 |   1.0171 |     32.220 |     3.2
   39 |   0.7240 |     24.830 |   0.9962 |     31.266 |     3.3
   40 |   0.7154 |     24.270 |   1.0026 |     31.361 |     3.3
   41 |   0.7040 |     23.612 |   0.9998 |     31.584 |     3.4
   42 |   0.6976 |     23.650 |   1.0158 |     31.934 |     3.5
   43 |   0.7052 |     23.930 |   1.0009 |     31.266 |     3.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 823,234

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2916 |     62.245 |   1.6428 |     48.919 |     0.0
    2 |   1.4937 |     46.396 |   1.4147 |     45.802 |     0.0
    3 |   1.4073 |     46.143 |   1.3804 |     45.802 |     0.1
    4 |   1.3787 |     45.633 |   1.3483 |     43.607 |     0.1
    5 |   1.3360 |     43.954 |   1.3054 |     42.939 |     0.1
    6 |   1.3031 |     43.219 |   1.2793 |     42.621 |     0.1
    7 |   1.2713 |     42.270 |   1.2455 |     41.571 |     0.2
    8 |   1.2435 |     41.442 |   1.2229 |     40.681 |     0.2
    9 |   1.2150 |     40.493 |   1.2161 |     40.553 |     0.2
   10 |   1.1916 |     40.120 |   1.1869 |     39.854 |     0.2
   11 |   1.1739 |     39.637 |   1.1872 |     40.045 |     0.3
   12 |   1.1540 |     38.869 |   1.1648 |     39.249 |     0.3
   13 |   1.1312 |     38.172 |   1.1685 |     38.709 |     0.3
   14 |   1.1175 |     37.854 |   1.1482 |     38.391 |     0.3
   15 |   1.0928 |     37.283 |   1.1540 |     38.486 |     0.4
   16 |   1.0802 |     36.647 |   1.1425 |     37.818 |     0.4
   17 |   1.0447 |     35.347 |   1.1122 |     37.246 |     0.4
   18 |   1.0181 |     34.409 |   1.1075 |     36.228 |     0.4
   19 |   0.9965 |     33.893 |   1.0944 |     36.005 |     0.4
   20 |   0.9661 |     32.351 |   1.0803 |     35.496 |     0.5
   21 |   0.9418 |     31.869 |   1.0693 |     34.860 |     0.5
   22 |   0.9189 |     31.194 |   1.0924 |     35.115 |     0.5
   23 |   0.8833 |     29.954 |   1.0640 |     34.510 |     0.5
   24 |   0.8593 |     29.038 |   1.0575 |     34.351 |     0.6
   25 |   0.8484 |     28.944 |   1.0331 |     32.983 |     0.6
   26 |   0.8056 |     26.788 |   1.0348 |     32.634 |     0.6
   27 |   0.7844 |     26.317 |   1.0436 |     32.411 |     0.6
   28 |   0.7417 |     24.627 |   1.0191 |     31.966 |     0.7
   29 |   0.7213 |     23.963 |   1.0320 |     32.125 |     0.7
   30 |   0.7011 |     23.052 |   1.0394 |     32.252 |     0.7
   31 |   0.6801 |     22.312 |   1.0150 |     30.693 |     0.7
   32 |   0.6574 |     21.610 |   1.0361 |     31.298 |     0.8
   33 |   0.6367 |     20.743 |   1.0639 |     31.966 |     0.8
   34 |   0.6160 |     20.326 |   1.0401 |     30.280 |     0.8
   35 |   0.5793 |     19.048 |   1.0361 |     30.598 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 930,146

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1035 |     57.653 |   1.5243 |     45.833 |     0.0
    2 |   1.4206 |     45.600 |   1.3372 |     43.543 |     0.1
    3 |   1.3036 |     42.561 |   1.2435 |     40.681 |     0.1
    4 |   1.2245 |     40.218 |   1.1770 |     38.645 |     0.1
    5 |   1.1588 |     38.062 |   1.1390 |     37.659 |     0.1
    6 |   1.0975 |     36.115 |   1.0982 |     35.910 |     0.2
    7 |   1.0382 |     34.233 |   1.0538 |     34.192 |     0.2
    8 |   0.9762 |     31.929 |   1.0240 |     32.347 |     0.2
    9 |   0.9235 |     30.009 |   0.9869 |     31.584 |     0.3
   10 |   0.8637 |     27.732 |   0.9520 |     30.344 |     0.3
   11 |   0.8142 |     26.437 |   0.9513 |     30.789 |     0.3
   12 |   0.7679 |     24.572 |   0.9344 |     29.389 |     0.3
   13 |   0.7303 |     23.382 |   0.9166 |     28.531 |     0.4
   14 |   0.6929 |     21.999 |   0.9061 |     27.704 |     0.4
   15 |   0.6543 |     20.743 |   0.8927 |     28.181 |     0.4
   16 |   0.6171 |     19.717 |   0.8867 |     26.749 |     0.5
   17 |   0.5909 |     18.625 |   0.9075 |     27.894 |     0.5
   18 |   0.5622 |     17.687 |   0.8966 |     26.081 |     0.5
   19 |   0.5290 |     16.590 |   0.8940 |     25.986 |     0.5
   20 |   0.4967 |     15.558 |   0.8772 |     24.809 |     0.6
   21 |   0.4687 |     15.059 |   0.8866 |     25.891 |     0.6
   22 |   0.4523 |     14.423 |   0.8979 |     25.159 |     0.6
   23 |   0.4330 |     13.968 |   0.8905 |     24.841 |     0.7
   24 |   0.4246 |     13.671 |   0.8892 |     25.064 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,847,074

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5669 |     67.605 |   2.0285 |     58.810 |     0.1
    2 |   1.8147 |     51.503 |   1.6109 |     48.664 |     0.1
    3 |   1.5330 |     46.302 |   1.4553 |     45.802 |     0.2
    4 |   1.4431 |     46.182 |   1.4121 |     45.802 |     0.3
    5 |   1.4144 |     46.204 |   1.3994 |     45.802 |     0.3
    6 |   1.4021 |     46.056 |   1.3881 |     45.802 |     0.4
    7 |   1.3954 |     46.127 |   1.3841 |     45.802 |     0.4
    8 |   1.3871 |     45.842 |   1.3735 |     45.229 |     0.5
    9 |   1.3719 |     44.997 |   1.3496 |     43.957 |     0.6
   10 |   1.3509 |     44.443 |   1.3330 |     43.957 |     0.6
   11 |   1.3394 |     44.393 |   1.3235 |     44.211 |     0.7
   12 |   1.3282 |     44.031 |   1.3082 |     43.257 |     0.8
   13 |   1.3165 |     43.664 |   1.3062 |     43.384 |     0.8
   14 |   1.3112 |     43.784 |   1.2996 |     43.321 |     0.9
   15 |   1.3009 |     43.510 |   1.2960 |     43.066 |     0.9
   16 |   1.2912 |     43.016 |   1.2813 |     42.621 |     1.0
   17 |   1.2839 |     42.846 |   1.2849 |     42.303 |     1.1
   18 |   1.2807 |     42.819 |   1.2757 |     42.271 |     1.1
   19 |   1.2702 |     42.391 |   1.2710 |     41.985 |     1.2
   20 |   1.2657 |     42.040 |   1.2680 |     42.176 |     1.3
   21 |   1.2572 |     41.908 |   1.2587 |     41.698 |     1.3
   22 |   1.2508 |     41.540 |   1.2478 |     41.412 |     1.4
   23 |   1.2392 |     41.502 |   1.2523 |     41.953 |     1.4
   24 |   1.2357 |     41.469 |   1.2489 |     41.444 |     1.5
   25 |   1.2275 |     41.299 |   1.2466 |     42.525 |     1.6
   26 |   1.2231 |     40.844 |   1.2400 |     42.080 |     1.6
   27 |   1.2166 |     40.794 |   1.2391 |     41.858 |     1.7
   28 |   1.2125 |     40.805 |   1.2262 |     41.444 |     1.8
   29 |   1.2004 |     40.641 |   1.2208 |     41.221 |     1.8
   30 |   1.1981 |     40.449 |   1.2079 |     40.585 |     1.9
   31 |   1.1873 |     40.070 |   1.2068 |     40.585 |     1.9
   32 |   1.1835 |     39.845 |   1.1913 |     40.426 |     2.0
   33 |   1.1738 |     39.812 |   1.2027 |     40.394 |     2.1
   34 |   1.1632 |     39.127 |   1.2023 |     39.758 |     2.1
   35 |   1.1619 |     39.214 |   1.1875 |     39.504 |     2.2
   36 |   1.1553 |     38.973 |   1.1920 |     40.045 |     2.3
   37 |   1.1530 |     38.578 |   1.2018 |     39.885 |     2.3
   38 |   1.1537 |     38.924 |   1.1953 |     39.631 |     2.4
   39 |   1.1434 |     38.424 |   1.1788 |     38.963 |     2.4
   40 |   1.1340 |     37.618 |   1.1608 |     38.518 |     2.5
   41 |   1.1244 |     37.700 |   1.1704 |     38.391 |     2.6
   42 |   1.1145 |     37.667 |   1.1658 |     38.168 |     2.6
   43 |   1.1133 |     37.623 |   1.1649 |     38.232 |     2.7
   44 |   1.1037 |     37.097 |   1.1635 |     38.581 |     2.8
   45 |   1.0943 |     36.707 |   1.1544 |     37.850 |     2.8
   46 |   1.0922 |     36.356 |   1.1480 |     38.104 |     2.9
   47 |   1.0854 |     36.499 |   1.1579 |     38.422 |     2.9
   48 |   1.0779 |     36.016 |   1.1525 |     38.104 |     3.0
   49 |   1.0805 |     35.923 |   1.1466 |     37.564 |     3.1
   50 |   1.0686 |     35.961 |   1.1408 |     37.087 |     3.1
   51 |   1.0570 |     35.577 |   1.1336 |     36.896 |     3.2
   52 |   1.0500 |     34.771 |   1.1444 |     36.991 |     3.3
   53 |   1.0515 |     35.116 |   1.1325 |     36.323 |     3.3
   54 |   1.0431 |     34.946 |   1.1167 |     36.641 |     3.4
   55 |   1.0366 |     34.590 |   1.1295 |     36.864 |     3.4
   56 |   1.0289 |     34.650 |   1.1264 |     36.260 |     3.5
   57 |   1.0280 |     34.573 |   1.1268 |     36.609 |     3.6
   58 |   1.0163 |     33.975 |   1.1375 |     36.737 |     3.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,110,210

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1345 |     58.021 |   1.5341 |     45.324 |     0.0
    2 |   1.4189 |     45.309 |   1.3298 |     44.497 |     0.1
    3 |   1.2933 |     42.149 |   1.2464 |     40.426 |     0.1
    4 |   1.2143 |     39.637 |   1.1765 |     38.836 |     0.1
    5 |   1.1483 |     37.684 |   1.1437 |     37.850 |     0.2
    6 |   1.0875 |     35.583 |   1.0767 |     35.146 |     0.2
    7 |   1.0205 |     32.922 |   1.0524 |     34.606 |     0.2
    8 |   0.9582 |     31.057 |   1.0242 |     32.697 |     0.3
    9 |   0.8970 |     28.868 |   0.9777 |     30.534 |     0.3
   10 |   0.8456 |     27.266 |   0.9655 |     30.916 |     0.3
   11 |   0.8000 |     25.620 |   0.9524 |     30.757 |     0.4
   12 |   0.7515 |     24.122 |   0.9546 |     29.039 |     0.4
   13 |   0.7044 |     22.619 |   0.9263 |     28.276 |     0.4
   14 |   0.6665 |     21.215 |   0.9355 |     28.912 |     0.5
   15 |   0.6228 |     19.914 |   0.9304 |     27.894 |     0.5
   16 |   0.5851 |     18.839 |   0.9110 |     27.481 |     0.5
   17 |   0.5620 |     17.846 |   0.8929 |     26.495 |     0.6
   18 |   0.5308 |     16.815 |   0.9022 |     26.495 |     0.6
   19 |   0.5098 |     16.403 |   0.9326 |     26.877 |     0.6
   20 |   0.4752 |     15.153 |   0.9215 |     26.781 |     0.7
   21 |   0.4463 |     14.198 |   0.9502 |     27.067 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 45 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 930,146

Training started
X_train.shape: torch.Size([3038, 702])
Y_train.shape: torch.Size([3038, 7])
X_dev.shape: torch.Size([524, 221])
Y_dev.shape: torch.Size([524, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0538 |     56.616 |   1.4940 |     45.611 |     0.0
    2 |   1.4134 |     45.276 |   1.3250 |     43.130 |     0.1
    3 |   1.2890 |     42.347 |   1.2326 |     40.585 |     0.1
    4 |   1.1904 |     39.631 |   1.1539 |     37.341 |     0.1
    5 |   1.1160 |     36.921 |   1.0997 |     36.323 |     0.1
    6 |   1.0408 |     34.452 |   1.0525 |     34.351 |     0.2
    7 |   0.9723 |     31.517 |   1.0111 |     32.379 |     0.2
    8 |   0.8978 |     28.846 |   0.9889 |     31.679 |     0.2
    9 |   0.8274 |     26.125 |   0.9306 |     29.167 |     0.2
   10 |   0.7675 |     24.177 |   0.9058 |     28.594 |     0.3
   11 |   0.7002 |     21.873 |   0.9195 |     28.244 |     0.3
   12 |   0.6532 |     20.490 |   0.8878 |     27.226 |     0.3
   13 |   0.6036 |     18.921 |   0.8825 |     27.036 |     0.4
   14 |   0.5459 |     16.815 |   0.8847 |     27.417 |     0.4
   15 |   0.5050 |     15.657 |   0.8809 |     26.686 |     0.4
   16 |   0.4644 |     14.121 |   0.8901 |     26.177 |     0.4
   17 |   0.4351 |     13.298 |   0.8835 |     25.795 |     0.5
   18 |   0.3936 |     12.042 |   0.8779 |     25.477 |     0.5
   19 |   0.3733 |     11.373 |   0.8988 |     25.000 |     0.5
   20 |   0.3397 |     10.248 |   0.9352 |     25.541 |     0.5
   21 |   0.3200 |      9.738 |   0.9379 |     25.859 |     0.6
   22 |   0.3031 |      9.244 |   0.9466 |     25.318 |     0.6
Early stopping

