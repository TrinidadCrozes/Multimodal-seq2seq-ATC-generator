Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 339,714

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5808 |     70.216 |   1.9861 |     59.851 |     0.0
    2 |   1.7504 |     49.173 |   1.5738 |     46.344 |     0.0
    3 |   1.4964 |     45.949 |   1.4549 |     46.344 |     0.1
    4 |   1.4319 |     45.960 |   1.4222 |     46.344 |     0.1
    5 |   1.4109 |     45.949 |   1.4108 |     46.344 |     0.1
    6 |   1.4006 |     45.949 |   1.4061 |     46.344 |     0.1
    7 |   1.3953 |     46.032 |   1.3999 |     46.437 |     0.1
    8 |   1.3908 |     45.999 |   1.3889 |     46.344 |     0.1
    9 |   1.3828 |     46.059 |   1.3832 |     46.344 |     0.1
   10 |   1.3729 |     45.833 |   1.3712 |     45.415 |     0.2
   11 |   1.3573 |     44.786 |   1.3520 |     45.601 |     0.2
   12 |   1.3362 |     44.538 |   1.3425 |     45.477 |     0.2
   13 |   1.3155 |     44.059 |   1.3326 |     44.579 |     0.2
   14 |   1.2958 |     43.436 |   1.3120 |     43.959 |     0.2
   15 |   1.2795 |     42.912 |   1.3047 |     44.145 |     0.2
   16 |   1.2662 |     42.686 |   1.2998 |     44.145 |     0.3
   17 |   1.2517 |     42.185 |   1.2794 |     43.804 |     0.3
   18 |   1.2353 |     41.793 |   1.2678 |     44.114 |     0.3
   19 |   1.2190 |     41.353 |   1.2492 |     43.185 |     0.3
   20 |   1.1985 |     40.443 |   1.2505 |     42.100 |     0.3
   21 |   1.1803 |     39.611 |   1.2421 |     42.038 |     0.3
   22 |   1.1589 |     39.385 |   1.2191 |     41.667 |     0.4
   23 |   1.1433 |     38.900 |   1.2116 |     41.543 |     0.4
   24 |   1.1267 |     38.569 |   1.2086 |     41.326 |     0.4
   25 |   1.1099 |     38.134 |   1.1986 |     40.892 |     0.4
   26 |   1.0903 |     37.362 |   1.1803 |     40.397 |     0.4
   27 |   1.0806 |     37.164 |   1.1834 |     40.149 |     0.4
   28 |   1.0626 |     36.447 |   1.1784 |     39.901 |     0.5
   29 |   1.0443 |     35.714 |   1.1656 |     39.653 |     0.5
   30 |   1.0195 |     34.524 |   1.1587 |     39.064 |     0.5
   31 |   1.0035 |     34.017 |   1.1567 |     38.786 |     0.5
   32 |   0.9827 |     33.306 |   1.1519 |     38.693 |     0.5
   33 |   0.9744 |     32.892 |   1.1515 |     37.546 |     0.5
   34 |   0.9504 |     31.757 |   1.1475 |     37.763 |     0.5
   35 |   0.9353 |     31.239 |   1.1330 |     37.732 |     0.6
   36 |   0.9074 |     30.341 |   1.1171 |     37.020 |     0.6
   37 |   0.8946 |     29.883 |   1.1155 |     36.617 |     0.6
   38 |   0.8759 |     29.056 |   1.1147 |     36.462 |     0.6
   39 |   0.8554 |     28.588 |   1.1203 |     36.586 |     0.6
   40 |   0.8444 |     28.180 |   1.1281 |     36.059 |     0.6
   41 |   0.8483 |     28.186 |   1.1009 |     35.533 |     0.7
   42 |   0.8116 |     26.758 |   1.0973 |     35.099 |     0.7
   43 |   0.7900 |     26.196 |   1.0909 |     35.037 |     0.7
   44 |   0.7699 |     25.540 |   1.1018 |     35.130 |     0.7
   45 |   0.7526 |     24.840 |   1.0942 |     34.665 |     0.7
   46 |   0.7387 |     24.173 |   1.1025 |     34.758 |     0.7
   47 |   0.7209 |     23.815 |   1.0958 |     35.099 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 860,578

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4939 |     66.540 |   1.9966 |     58.984 |     0.0
    2 |   1.7661 |     50.237 |   1.5771 |     46.344 |     0.1
    3 |   1.4953 |     45.629 |   1.4443 |     45.539 |     0.1
    4 |   1.4068 |     44.748 |   1.3850 |     45.167 |     0.1
    5 |   1.3540 |     43.364 |   1.3370 |     44.145 |     0.2
    6 |   1.3091 |     42.251 |   1.2954 |     43.030 |     0.2
    7 |   1.2734 |     41.534 |   1.2764 |     43.061 |     0.2
    8 |   1.2454 |     40.653 |   1.2452 |     41.791 |     0.3
    9 |   1.2093 |     39.545 |   1.2216 |     41.543 |     0.3
   10 |   1.1758 |     38.713 |   1.1953 |     40.428 |     0.3
   11 |   1.1475 |     37.858 |   1.1877 |     40.087 |     0.4
   12 |   1.1163 |     36.888 |   1.1628 |     38.724 |     0.4
   13 |   1.0870 |     35.902 |   1.1371 |     37.515 |     0.4
   14 |   1.0589 |     34.601 |   1.1159 |     36.462 |     0.5
   15 |   1.0378 |     33.636 |   1.1326 |     36.307 |     0.5
   16 |   1.0069 |     32.650 |   1.0876 |     35.781 |     0.5
   17 |   0.9924 |     32.077 |   1.0855 |     35.285 |     0.5
   18 |   0.9578 |     31.063 |   1.0660 |     35.223 |     0.6
   19 |   0.9331 |     30.175 |   1.0397 |     34.542 |     0.6
   20 |   0.9188 |     29.784 |   1.0529 |     34.170 |     0.6
   21 |   0.9231 |     29.905 |   1.0612 |     34.820 |     0.7
   22 |   0.8916 |     28.638 |   1.0367 |     34.015 |     0.7
   23 |   0.8578 |     27.298 |   1.0447 |     34.046 |     0.7
   24 |   0.8444 |     27.364 |   1.0226 |     32.838 |     0.8
   25 |   0.8182 |     26.394 |   1.0269 |     32.962 |     0.8
   26 |   0.7973 |     25.981 |   1.0211 |     32.528 |     0.8
   27 |   0.7770 |     25.132 |   1.0077 |     32.125 |     0.9
   28 |   0.7589 |     24.173 |   0.9865 |     31.537 |     0.9
   29 |   0.7396 |     23.997 |   0.9854 |     31.537 |     0.9
   30 |   0.7295 |     23.760 |   0.9869 |     31.939 |     1.0
   31 |   0.7128 |     23.225 |   0.9787 |     31.165 |     1.0
   32 |   0.6907 |     22.195 |   0.9829 |     30.793 |     1.0
   33 |   0.6811 |     21.759 |   0.9782 |     30.917 |     1.1
   34 |   0.6721 |     21.908 |   0.9892 |     31.134 |     1.1
   35 |   0.6473 |     20.960 |   0.9828 |     31.289 |     1.1
   36 |   0.6349 |     20.481 |   0.9902 |     30.824 |     1.2
   37 |   0.6279 |     20.139 |   0.9747 |     29.802 |     1.2
   38 |   0.6111 |     19.560 |   0.9859 |     30.731 |     1.2
   39 |   0.6023 |     19.748 |   0.9823 |     30.390 |     1.3
   40 |   0.5980 |     19.632 |   0.9781 |     30.235 |     1.3
   41 |   0.5973 |     19.538 |   0.9679 |     30.050 |     1.3
   42 |   0.5657 |     18.177 |   0.9580 |     28.934 |     1.4
   43 |   0.5732 |     18.463 |   1.0018 |     30.576 |     1.4
   44 |   0.5610 |     18.298 |   0.9929 |     29.864 |     1.4
   45 |   0.5483 |     17.741 |   1.0050 |     30.483 |     1.5
   46 |   0.5365 |     17.499 |   1.0045 |     30.266 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 2,490,978

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5744 |     69.544 |   1.9734 |     54.647 |     0.1
    2 |   1.7568 |     49.598 |   1.5892 |     46.344 |     0.2
    3 |   1.5087 |     45.949 |   1.4650 |     46.344 |     0.2
    4 |   1.4364 |     45.977 |   1.4271 |     46.344 |     0.3
    5 |   1.4119 |     45.971 |   1.4094 |     46.344 |     0.4
    6 |   1.4004 |     46.004 |   1.4011 |     46.344 |     0.5
    7 |   1.3918 |     45.916 |   1.3934 |     46.716 |     0.5
    8 |   1.3790 |     44.880 |   1.3736 |     45.508 |     0.6
    9 |   1.3571 |     44.549 |   1.3573 |     45.322 |     0.7
   10 |   1.3452 |     44.555 |   1.3525 |     45.353 |     0.8
   11 |   1.3360 |     44.417 |   1.3516 |     45.539 |     0.8
   12 |   1.3342 |     44.323 |   1.3392 |     45.322 |     0.9
   13 |   1.3221 |     44.064 |   1.3365 |     45.198 |     1.0
   14 |   1.3200 |     44.246 |   1.3336 |     45.384 |     1.1
   15 |   1.3126 |     43.871 |   1.3266 |     44.888 |     1.1
   16 |   1.3067 |     43.800 |   1.3255 |     44.703 |     1.2
   17 |   1.2997 |     43.507 |   1.3143 |     44.796 |     1.3
   18 |   1.2934 |     43.149 |   1.3056 |     44.083 |     1.4
   19 |   1.2854 |     43.271 |   1.3042 |     44.331 |     1.4
   20 |   1.2806 |     42.785 |   1.3050 |     44.114 |     1.5
   21 |   1.2787 |     42.708 |   1.2938 |     43.835 |     1.6
   22 |   1.2682 |     42.367 |   1.2957 |     44.052 |     1.7
   23 |   1.2640 |     42.300 |   1.2954 |     43.680 |     1.7
   24 |   1.2633 |     42.130 |   1.2842 |     43.928 |     1.8
   25 |   1.2560 |     42.003 |   1.2882 |     43.742 |     1.9
   26 |   1.2517 |     41.755 |   1.2763 |     43.556 |     2.0
   27 |   1.2445 |     41.430 |   1.2684 |     42.937 |     2.0
   28 |   1.2469 |     41.534 |   1.2716 |     43.154 |     2.1
   29 |   1.2464 |     41.634 |   1.2775 |     43.525 |     2.2
   30 |   1.2417 |     41.523 |   1.2681 |     43.061 |     2.3
   31 |   1.2340 |     41.209 |   1.2631 |     42.999 |     2.3
   32 |   1.2286 |     41.060 |   1.2640 |     43.216 |     2.4
   33 |   1.2302 |     41.424 |   1.2636 |     43.247 |     2.5
   34 |   1.2225 |     41.204 |   1.2527 |     42.751 |     2.6
   35 |   1.2163 |     41.093 |   1.2605 |     43.618 |     2.6
   36 |   1.2164 |     40.730 |   1.2487 |     42.875 |     2.7
   37 |   1.2187 |     40.862 |   1.2495 |     42.472 |     2.8
   38 |   1.2113 |     40.939 |   1.2503 |     42.286 |     2.9
   39 |   1.2058 |     40.504 |   1.2414 |     43.185 |     3.0
   40 |   1.2062 |     40.812 |   1.2525 |     42.999 |     3.0
   41 |   1.2044 |     40.305 |   1.2470 |     42.193 |     3.1
   42 |   1.1967 |     40.112 |   1.2428 |     42.441 |     3.2
   43 |   1.1867 |     39.776 |   1.2344 |     42.379 |     3.3
   44 |   1.1800 |     39.567 |   1.2410 |     42.100 |     3.3
   45 |   1.1820 |     39.539 |   1.2402 |     42.100 |     3.4
   46 |   1.1701 |     39.390 |   1.2307 |     41.667 |     3.5
   47 |   1.1671 |     39.175 |   1.2271 |     41.543 |     3.6
   48 |   1.1565 |     38.867 |   1.2198 |     41.295 |     3.6
   49 |   1.1566 |     38.652 |   1.2207 |     41.264 |     3.7
   50 |   1.1515 |     38.553 |   1.2207 |     41.945 |     3.8
   51 |   1.1493 |     38.514 |   1.2090 |     40.861 |     3.9
   52 |   1.1322 |     37.963 |   1.2043 |     40.985 |     3.9
   53 |   1.1360 |     37.963 |   1.2017 |     40.985 |     4.0
   54 |   1.1286 |     37.820 |   1.1968 |     41.202 |     4.1
   55 |   1.1247 |     37.891 |   1.2019 |     41.202 |     4.2
   56 |   1.1305 |     38.233 |   1.1992 |     40.737 |     4.2
   57 |   1.1256 |     37.836 |   1.2024 |     41.202 |     4.3
   58 |   1.1216 |     37.946 |   1.1875 |     40.799 |     4.4
   59 |   1.1070 |     37.169 |   1.1948 |     40.428 |     4.5
   60 |   1.1065 |     37.241 |   1.1995 |     40.366 |     4.5
   61 |   1.1038 |     37.280 |   1.1984 |     40.118 |     4.6
   62 |   1.1007 |     37.296 |   1.1867 |     40.489 |     4.7
   63 |   1.0900 |     36.673 |   1.1761 |     40.025 |     4.8
   64 |   1.0884 |     36.982 |   1.1962 |     39.653 |     4.8
   65 |   1.0940 |     37.081 |   1.1788 |     41.140 |     4.9
   66 |   1.0934 |     36.987 |   1.1644 |     39.219 |     5.0
   67 |   1.0750 |     36.370 |   1.1633 |     40.304 |     5.1
   68 |   1.0630 |     35.709 |   1.1663 |     39.715 |     5.1
   69 |   1.0648 |     35.841 |   1.1667 |     39.436 |     5.2
   70 |   1.0659 |     35.929 |   1.1702 |     40.118 |     5.3
   71 |   1.0598 |     36.039 |   1.1661 |     39.777 |     5.4
   72 |   1.0621 |     35.858 |   1.1579 |     39.157 |     5.5
   73 |   1.0463 |     35.444 |   1.1868 |     39.343 |     5.5
   74 |   1.0412 |     35.295 |   1.1729 |     40.335 |     5.6
   75 |   1.0360 |     35.141 |   1.1650 |     40.056 |     5.7
   76 |   1.0327 |     35.136 |   1.1681 |     40.366 |     5.8
   77 |   1.0251 |     34.838 |   1.1570 |     39.839 |     5.8
   78 |   1.0204 |     34.821 |   1.1687 |     39.591 |     5.9
   79 |   1.0297 |     35.202 |   1.1606 |     39.808 |     6.0
   80 |   1.0295 |     34.843 |   1.1714 |     40.025 |     6.1
   81 |   1.0156 |     34.612 |   1.1574 |     39.095 |     6.1
   82 |   1.0002 |     34.177 |   1.1469 |     38.631 |     6.2
   83 |   0.9925 |     33.813 |   1.1517 |     38.941 |     6.3
   84 |   0.9904 |     33.714 |   1.1516 |     38.290 |     6.4
   85 |   0.9867 |     33.565 |   1.1446 |     38.662 |     6.4
   86 |   0.9872 |     33.675 |   1.1392 |     38.445 |     6.5
   87 |   0.9852 |     33.399 |   1.1605 |     38.848 |     6.6
   88 |   0.9735 |     33.328 |   1.1537 |     38.693 |     6.7
   89 |   0.9820 |     33.444 |   1.1360 |     38.414 |     6.7
   90 |   0.9825 |     33.278 |   1.1431 |     38.755 |     6.8
   91 |   0.9650 |     32.694 |   1.1395 |     37.887 |     6.9
   92 |   0.9630 |     32.727 |   1.1519 |     38.817 |     7.0
   93 |   0.9613 |     32.694 |   1.1592 |     38.755 |     7.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,764,002

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4624 |     65.438 |   1.9973 |     57.807 |     0.1
    2 |   1.7642 |     49.620 |   1.5807 |     46.344 |     0.1
    3 |   1.4902 |     45.955 |   1.4459 |     46.933 |     0.2
    4 |   1.4196 |     45.955 |   1.4090 |     46.778 |     0.2
    5 |   1.3928 |     46.048 |   1.3928 |     46.406 |     0.3
    6 |   1.3752 |     45.464 |   1.3735 |     45.539 |     0.3
    7 |   1.3531 |     44.455 |   1.3587 |     45.694 |     0.4
    8 |   1.3309 |     43.794 |   1.3363 |     44.981 |     0.5
    9 |   1.3100 |     43.199 |   1.3216 |     44.734 |     0.5
   10 |   1.2895 |     42.604 |   1.3012 |     43.587 |     0.6
   11 |   1.2729 |     41.788 |   1.2882 |     42.751 |     0.6
   12 |   1.2528 |     41.226 |   1.2769 |     42.379 |     0.7
   13 |   1.2313 |     40.476 |   1.2636 |     42.286 |     0.8
   14 |   1.2075 |     40.008 |   1.2443 |     42.317 |     0.8
   15 |   1.1809 |     39.231 |   1.2268 |     41.140 |     0.9
   16 |   1.1691 |     38.911 |   1.2101 |     40.923 |     0.9
   17 |   1.1451 |     38.161 |   1.2082 |     41.233 |     1.0
   18 |   1.1186 |     37.395 |   1.1756 |     39.498 |     1.0
   19 |   1.1023 |     36.712 |   1.1749 |     39.157 |     1.1
   20 |   1.0909 |     36.508 |   1.1571 |     39.095 |     1.2
   21 |   1.0656 |     35.466 |   1.1472 |     37.546 |     1.2
   22 |   1.0467 |     34.606 |   1.1377 |     37.918 |     1.3
   23 |   1.0305 |     33.967 |   1.1214 |     37.485 |     1.3
   24 |   1.0112 |     33.659 |   1.1202 |     37.361 |     1.4
   25 |   0.9943 |     32.584 |   1.1082 |     37.082 |     1.4
   26 |   0.9829 |     32.314 |   1.1046 |     36.772 |     1.5
   27 |   0.9674 |     32.033 |   1.1047 |     36.648 |     1.6
   28 |   0.9507 |     31.261 |   1.0953 |     36.927 |     1.6
   29 |   0.9267 |     30.407 |   1.0804 |     36.369 |     1.7
   30 |   0.9072 |     30.026 |   1.0856 |     36.152 |     1.7
   31 |   0.8950 |     29.167 |   1.0730 |     36.338 |     1.8
   32 |   0.8813 |     28.858 |   1.0612 |     35.316 |     1.9
   33 |   0.8660 |     28.434 |   1.0687 |     36.152 |     1.9
   34 |   0.8495 |     27.871 |   1.0508 |     34.944 |     2.0
   35 |   0.8218 |     26.951 |   1.0368 |     34.418 |     2.0
   36 |   0.8129 |     26.350 |   1.0446 |     34.449 |     2.1
   37 |   0.8048 |     26.538 |   1.0400 |     33.953 |     2.1
   38 |   0.7799 |     25.568 |   1.0341 |     33.333 |     2.2
   39 |   0.7691 |     25.066 |   1.0443 |     33.581 |     2.3
   40 |   0.7675 |     24.989 |   1.0356 |     33.581 |     2.3
   41 |   0.7696 |     25.479 |   1.0422 |     33.488 |     2.4
   42 |   0.7500 |     24.559 |   1.0361 |     33.922 |     2.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 894,562

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0925 |     56.592 |   1.5198 |     46.066 |     0.0
    2 |   1.4157 |     45.530 |   1.3523 |     44.796 |     0.1
    3 |   1.2996 |     42.791 |   1.2640 |     41.853 |     0.1
    4 |   1.2190 |     40.190 |   1.2079 |     40.768 |     0.1
    5 |   1.1595 |     38.641 |   1.1736 |     39.622 |     0.1
    6 |   1.1037 |     36.547 |   1.1162 |     37.485 |     0.2
    7 |   1.0453 |     34.138 |   1.0972 |     37.299 |     0.2
    8 |   0.9913 |     32.275 |   1.0433 |     35.068 |     0.2
    9 |   0.9391 |     30.043 |   1.0142 |     32.993 |     0.2
   10 |   0.8886 |     28.682 |   0.9609 |     32.342 |     0.3
   11 |   0.8376 |     27.045 |   0.9356 |     30.607 |     0.3
   12 |   0.8042 |     25.981 |   0.9442 |     31.320 |     0.3
   13 |   0.7473 |     24.284 |   0.8951 |     29.213 |     0.3
   14 |   0.7077 |     22.828 |   0.8929 |     28.686 |     0.4
   15 |   0.6750 |     21.914 |   0.8800 |     27.943 |     0.4
   16 |   0.6431 |     20.492 |   0.8991 |     28.810 |     0.4
   17 |   0.6183 |     19.957 |   0.8709 |     27.726 |     0.4
   18 |   0.5841 |     18.623 |   0.8902 |     27.076 |     0.5
   19 |   0.5554 |     18.006 |   0.8891 |     27.881 |     0.5
   20 |   0.5393 |     17.350 |   0.9034 |     27.819 |     0.5
   21 |   0.5171 |     16.821 |   0.8642 |     26.766 |     0.5
   22 |   0.4813 |     15.311 |   0.8917 |     26.611 |     0.6
   23 |   0.4615 |     14.809 |   0.8758 |     25.867 |     0.6
   24 |   0.4441 |     14.269 |   0.8599 |     25.341 |     0.6
   25 |   0.4143 |     13.239 |   0.8696 |     25.496 |     0.6
   26 |   0.4055 |     13.194 |   0.9025 |     26.146 |     0.7
   27 |   0.3903 |     12.599 |   0.8809 |     25.031 |     0.7
   28 |   0.3757 |     12.037 |   0.8948 |     24.535 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 616,418

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1284 |     58.245 |   1.5357 |     46.190 |     0.0
    2 |   1.4058 |     44.825 |   1.3424 |     43.061 |     0.0
    3 |   1.2838 |     41.479 |   1.2615 |     42.007 |     0.0
    4 |   1.2007 |     39.341 |   1.2091 |     40.892 |     0.1
    5 |   1.1357 |     37.191 |   1.1406 |     38.135 |     0.1
    6 |   1.0686 |     34.943 |   1.1051 |     37.330 |     0.1
    7 |   1.0047 |     33.135 |   1.0725 |     35.688 |     0.1
    8 |   0.9486 |     30.842 |   1.0226 |     34.356 |     0.1
    9 |   0.8804 |     28.665 |   0.9892 |     32.342 |     0.2
   10 |   0.8240 |     26.852 |   0.9861 |     32.590 |     0.2
   11 |   0.7667 |     24.763 |   0.9458 |     31.010 |     0.2
   12 |   0.7096 |     22.162 |   0.9182 |     29.244 |     0.2
   13 |   0.6558 |     20.255 |   0.9078 |     29.523 |     0.2
   14 |   0.6030 |     18.915 |   0.8925 |     28.594 |     0.2
   15 |   0.5556 |     17.345 |   0.8851 |     26.890 |     0.3
   16 |   0.5124 |     15.901 |   0.8763 |     26.332 |     0.3
   17 |   0.4725 |     14.638 |   0.8881 |     26.642 |     0.3
   18 |   0.4429 |     13.889 |   0.8910 |     27.014 |     0.3
   19 |   0.4116 |     12.682 |   0.8694 |     25.403 |     0.3
   20 |   0.3668 |     11.012 |   0.8962 |     25.774 |     0.3
   21 |   0.3373 |     10.334 |   0.8910 |     25.341 |     0.4
   22 |   0.3124 |      9.425 |   0.8931 |     24.597 |     0.4
   23 |   0.2836 |      8.510 |   0.8959 |     25.186 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,745,442

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5169 |     67.014 |   2.0375 |     59.851 |     0.1
    2 |   1.7944 |     50.430 |   1.5863 |     46.344 |     0.1
    3 |   1.4987 |     45.971 |   1.4539 |     46.190 |     0.2
    4 |   1.4197 |     45.200 |   1.4057 |     45.508 |     0.2
    5 |   1.3829 |     44.560 |   1.3748 |     45.508 |     0.3
    6 |   1.3569 |     44.279 |   1.3552 |     45.415 |     0.4
    7 |   1.3399 |     43.954 |   1.3426 |     45.136 |     0.4
    8 |   1.3249 |     43.546 |   1.3309 |     44.950 |     0.5
    9 |   1.3120 |     43.474 |   1.3203 |     44.517 |     0.5
   10 |   1.2982 |     42.984 |   1.3078 |     44.083 |     0.6
   11 |   1.2828 |     42.835 |   1.2947 |     43.680 |     0.7
   12 |   1.2740 |     42.295 |   1.2865 |     43.711 |     0.7
   13 |   1.2661 |     41.865 |   1.2813 |     43.525 |     0.8
   14 |   1.2550 |     41.705 |   1.2676 |     43.432 |     0.9
   15 |   1.2476 |     41.380 |   1.2708 |     42.937 |     0.9
   16 |   1.2396 |     41.353 |   1.2606 |     43.123 |     1.0
   17 |   1.2293 |     40.790 |   1.2660 |     42.937 |     1.0
   18 |   1.2282 |     40.812 |   1.2533 |     42.503 |     1.1
   19 |   1.2187 |     40.465 |   1.2505 |     42.379 |     1.2
   20 |   1.2003 |     39.892 |   1.2364 |     42.224 |     1.2
   21 |   1.1972 |     39.738 |   1.2311 |     41.791 |     1.3
   22 |   1.1770 |     39.209 |   1.2217 |     41.667 |     1.3
   23 |   1.1686 |     38.883 |   1.2080 |     40.737 |     1.4
   24 |   1.1536 |     38.525 |   1.2015 |     41.481 |     1.5
   25 |   1.1455 |     38.250 |   1.1881 |     40.985 |     1.5
   26 |   1.1317 |     37.991 |   1.1823 |     40.366 |     1.6
   27 |   1.1164 |     37.467 |   1.1779 |     40.087 |     1.6
   28 |   1.1139 |     37.307 |   1.1682 |     40.304 |     1.7
   29 |   1.0957 |     36.646 |   1.1507 |     39.684 |     1.8
   30 |   1.0816 |     36.359 |   1.1564 |     39.343 |     1.8
   31 |   1.0749 |     36.006 |   1.1324 |     38.507 |     1.9
   32 |   1.0652 |     35.780 |   1.1335 |     38.724 |     2.0
   33 |   1.0508 |     35.224 |   1.1309 |     38.817 |     2.0
   34 |   1.0348 |     34.805 |   1.1053 |     36.958 |     2.1
   35 |   1.0273 |     34.651 |   1.1190 |     38.135 |     2.1
   36 |   1.0180 |     33.901 |   1.1093 |     37.577 |     2.2
   37 |   1.0021 |     33.664 |   1.1007 |     37.392 |     2.3
   38 |   0.9870 |     32.821 |   1.0859 |     36.059 |     2.3
   39 |   0.9765 |     32.485 |   1.1007 |     37.020 |     2.4
   40 |   0.9741 |     32.319 |   1.0841 |     36.276 |     2.4
   41 |   0.9567 |     31.978 |   1.0797 |     36.431 |     2.5
   42 |   0.9471 |     31.851 |   1.0700 |     35.936 |     2.6
   43 |   0.9341 |     31.244 |   1.0650 |     35.285 |     2.6
   44 |   0.9232 |     30.985 |   1.0636 |     35.068 |     2.7
   45 |   0.9153 |     30.622 |   1.0671 |     34.913 |     2.7
   46 |   0.9108 |     30.539 |   1.0611 |     35.347 |     2.8
   47 |   0.8976 |     30.374 |   1.0583 |     34.480 |     2.9
   48 |   0.8923 |     30.230 |   1.0506 |     35.409 |     2.9
   49 |   0.8877 |     29.778 |   1.0513 |     34.975 |     3.0
   50 |   0.8742 |     29.244 |   1.0439 |     34.572 |     3.0
   51 |   0.8547 |     28.489 |   1.0468 |     34.882 |     3.1
   52 |   0.8401 |     28.015 |   1.0268 |     33.798 |     3.2
   53 |   0.8357 |     27.998 |   1.0342 |     34.727 |     3.2
   54 |   0.8283 |     27.938 |   1.0392 |     34.511 |     3.3
   55 |   0.8220 |     27.552 |   1.0248 |     33.860 |     3.3
   56 |   0.8152 |     27.436 |   1.0241 |     33.519 |     3.4
   57 |   0.8052 |     27.127 |   1.0398 |     34.511 |     3.5
   58 |   0.8011 |     27.017 |   1.0255 |     34.170 |     3.5
   59 |   0.7900 |     26.433 |   1.0129 |     32.745 |     3.6
   60 |   0.7769 |     26.433 |   1.0167 |     33.302 |     3.6
   61 |   0.7771 |     26.240 |   1.0155 |     33.271 |     3.7
   62 |   0.7636 |     25.744 |   1.0084 |     32.962 |     3.8
   63 |   0.7595 |     25.524 |   1.0139 |     33.426 |     3.8
   64 |   0.7551 |     25.468 |   0.9978 |     33.488 |     3.9
   65 |   0.7407 |     24.802 |   1.0116 |     33.426 |     4.0
   66 |   0.7332 |     24.730 |   1.0154 |     32.745 |     4.0
   67 |   0.7275 |     24.350 |   1.0044 |     33.364 |     4.1
   68 |   0.7184 |     24.261 |   0.9892 |     32.156 |     4.1
   69 |   0.7150 |     24.250 |   0.9902 |     32.869 |     4.2
   70 |   0.7098 |     23.738 |   0.9953 |     32.466 |     4.3
   71 |   0.6985 |     23.336 |   1.0045 |     32.466 |     4.3
   72 |   0.6924 |     23.325 |   0.9912 |     32.497 |     4.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,865,762

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5501 |     68.171 |   1.9790 |     58.240 |     0.1
    2 |   1.7638 |     49.945 |   1.5826 |     46.344 |     0.1
    3 |   1.5073 |     45.977 |   1.4605 |     46.344 |     0.2
    4 |   1.4368 |     45.977 |   1.4279 |     46.344 |     0.2
    5 |   1.4125 |     45.982 |   1.4083 |     46.344 |     0.3
    6 |   1.4013 |     45.910 |   1.3975 |     46.623 |     0.4
    7 |   1.3866 |     46.037 |   1.3797 |     46.344 |     0.4
    8 |   1.3665 |     45.470 |   1.3762 |     45.880 |     0.5
    9 |   1.3469 |     44.571 |   1.3461 |     45.787 |     0.5
   10 |   1.3252 |     44.213 |   1.3282 |     45.105 |     0.6
   11 |   1.3091 |     43.970 |   1.3049 |     44.300 |     0.7
   12 |   1.2889 |     43.320 |   1.2911 |     43.711 |     0.7
   13 |   1.2761 |     43.056 |   1.2812 |     43.278 |     0.8
   14 |   1.2611 |     42.995 |   1.2750 |     43.494 |     0.9
   15 |   1.2471 |     42.157 |   1.2517 |     42.844 |     0.9
   16 |   1.2344 |     42.108 |   1.2504 |     43.154 |     1.0
   17 |   1.2244 |     41.793 |   1.2434 |     42.813 |     1.0
   18 |   1.2142 |     41.187 |   1.2358 |     42.162 |     1.1
   19 |   1.2011 |     40.686 |   1.2274 |     41.419 |     1.2
   20 |   1.1931 |     40.250 |   1.2207 |     41.140 |     1.2
   21 |   1.1803 |     39.754 |   1.2330 |     41.574 |     1.3
   22 |   1.1654 |     39.638 |   1.2210 |     41.295 |     1.3
   23 |   1.1615 |     39.457 |   1.2032 |     40.985 |     1.4
   24 |   1.1439 |     38.635 |   1.1834 |     40.489 |     1.5
   25 |   1.1355 |     38.448 |   1.1781 |     40.520 |     1.5
   26 |   1.1427 |     38.481 |   1.1912 |     40.582 |     1.6
   27 |   1.1159 |     37.803 |   1.1607 |     39.994 |     1.6
   28 |   1.1458 |     38.828 |   1.1846 |     40.304 |     1.7
   29 |   1.1225 |     38.420 |   1.1678 |     40.675 |     1.8
   30 |   1.0997 |     37.577 |   1.1722 |     40.861 |     1.8
   31 |   1.0934 |     37.224 |   1.1624 |     40.118 |     1.9
   32 |   1.0860 |     37.081 |   1.1391 |     39.188 |     2.0
   33 |   1.0755 |     36.883 |   1.1411 |     38.786 |     2.0
   34 |   1.0639 |     36.249 |   1.1438 |     39.281 |     2.1
   35 |   1.0664 |     36.216 |   1.1266 |     38.321 |     2.1
   36 |   1.0467 |     35.874 |   1.1188 |     37.825 |     2.2
   37 |   1.0310 |     35.042 |   1.1181 |     37.515 |     2.3
   38 |   1.0187 |     34.849 |   1.1026 |     37.918 |     2.3
   39 |   1.0123 |     34.474 |   1.0910 |     37.639 |     2.4
   40 |   1.0030 |     34.066 |   1.1061 |     37.454 |     2.4
   41 |   0.9867 |     33.388 |   1.0940 |     37.144 |     2.5
   42 |   0.9773 |     33.256 |   1.0795 |     36.059 |     2.6
   43 |   0.9719 |     32.942 |   1.0716 |     35.998 |     2.6
   44 |   0.9563 |     32.325 |   1.0651 |     35.688 |     2.7
   45 |   0.9459 |     31.884 |   1.0528 |     34.975 |     2.7
   46 |   0.9417 |     32.055 |   1.0502 |     35.130 |     2.8
   47 |   0.9273 |     31.178 |   1.0482 |     35.378 |     2.9
   48 |   0.9132 |     30.963 |   1.0367 |     34.696 |     2.9
   49 |   0.9048 |     30.401 |   1.0383 |     35.192 |     3.0
   50 |   0.9048 |     30.737 |   1.0427 |     34.913 |     3.1
   51 |   0.9001 |     30.313 |   1.0454 |     34.944 |     3.1
   52 |   0.8808 |     29.674 |   1.0412 |     34.387 |     3.2
   53 |   0.8834 |     29.828 |   1.0322 |     33.953 |     3.2
   54 |   0.8713 |     29.481 |   1.0150 |     34.294 |     3.3
   55 |   0.8566 |     28.819 |   1.0135 |     33.116 |     3.4
   56 |   0.8591 |     28.660 |   1.0018 |     33.519 |     3.4
   57 |   0.8561 |     28.836 |   1.0019 |     33.891 |     3.5
   58 |   0.8508 |     28.825 |   1.0115 |     33.178 |     3.5
   59 |   0.8263 |     27.601 |   0.9922 |     33.333 |     3.6
   60 |   0.8237 |     27.607 |   0.9990 |     32.559 |     3.7
   61 |   0.8139 |     27.585 |   1.0043 |     32.311 |     3.7
   62 |   0.8148 |     27.662 |   0.9965 |     34.325 |     3.8
   63 |   0.8079 |     27.337 |   0.9912 |     32.466 |     3.9
   64 |   0.7967 |     26.797 |   0.9920 |     32.249 |     3.9
   65 |   0.7875 |     26.521 |   0.9742 |     32.466 |     4.0
   66 |   0.7883 |     26.505 |   0.9806 |     32.466 |     4.0
   67 |   0.7767 |     26.025 |   0.9859 |     32.249 |     4.1
   68 |   0.7847 |     26.317 |   0.9832 |     31.908 |     4.2
   69 |   0.7756 |     26.306 |   0.9645 |     32.249 |     4.2
   70 |   0.7695 |     25.446 |   0.9768 |     32.342 |     4.3
   71 |   0.7502 |     25.485 |   0.9713 |     30.917 |     4.3
   72 |   0.7406 |     24.537 |   0.9697 |     31.227 |     4.4
   73 |   0.7360 |     24.802 |   0.9737 |     31.041 |     4.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 250,594

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5702 |     67.422 |   1.9851 |     59.634 |     0.0
    2 |   1.7498 |     49.581 |   1.5697 |     46.344 |     0.0
    3 |   1.4994 |     45.944 |   1.4555 |     46.344 |     0.0
    4 |   1.4320 |     45.977 |   1.4070 |     46.344 |     0.1
    5 |   1.3952 |     45.988 |   1.3863 |     46.066 |     0.1
    6 |   1.3623 |     45.337 |   1.3430 |     44.455 |     0.1
    7 |   1.3239 |     43.502 |   1.3108 |     44.052 |     0.1
    8 |   1.2827 |     42.526 |   1.2885 |     43.371 |     0.1
    9 |   1.2530 |     41.562 |   1.2565 |     42.100 |     0.1
   10 |   1.2253 |     40.752 |   1.2410 |     41.512 |     0.1
   11 |   1.1941 |     39.627 |   1.2247 |     40.458 |     0.2
   12 |   1.1670 |     38.729 |   1.2052 |     40.304 |     0.2
   13 |   1.1412 |     38.167 |   1.1860 |     40.273 |     0.2
   14 |   1.1185 |     37.555 |   1.1769 |     39.095 |     0.2
   15 |   1.0913 |     36.613 |   1.1587 |     38.817 |     0.2
   16 |   1.0657 |     35.571 |   1.1365 |     38.135 |     0.2
   17 |   1.0396 |     34.684 |   1.1352 |     38.042 |     0.2
   18 |   1.0240 |     33.785 |   1.1227 |     37.423 |     0.2
   19 |   0.9972 |     32.854 |   1.1096 |     36.896 |     0.3
   20 |   0.9741 |     32.314 |   1.0985 |     37.020 |     0.3
   21 |   0.9514 |     31.382 |   1.0725 |     34.665 |     0.3
   22 |   0.9278 |     30.478 |   1.0861 |     35.409 |     0.3
   23 |   0.9091 |     29.938 |   1.0754 |     35.533 |     0.3
   24 |   0.8805 |     28.715 |   1.0628 |     34.139 |     0.3
   25 |   0.8600 |     28.175 |   1.0710 |     34.356 |     0.3
   26 |   0.8475 |     27.778 |   1.0435 |     33.395 |     0.4
   27 |   0.8221 |     26.466 |   1.0356 |     33.240 |     0.4
   28 |   0.8009 |     25.953 |   1.0324 |     32.962 |     0.4
   29 |   0.7755 |     25.364 |   1.0184 |     31.877 |     0.4
   30 |   0.7584 |     24.410 |   1.0280 |     32.249 |     0.4
   31 |   0.7436 |     23.903 |   1.0070 |     31.227 |     0.4
   32 |   0.7250 |     23.545 |   1.0001 |     30.545 |     0.4
   33 |   0.7123 |     22.542 |   1.0120 |     31.382 |     0.5
   34 |   0.6943 |     22.327 |   1.0253 |     31.537 |     0.5
   35 |   0.6806 |     21.500 |   1.0142 |     31.599 |     0.5
   36 |   0.6624 |     21.170 |   1.0036 |     30.576 |     0.5
   37 |   0.6527 |     20.971 |   0.9967 |     30.297 |     0.5
   38 |   0.6341 |     20.293 |   1.0062 |     30.576 |     0.5
   39 |   0.6235 |     20.001 |   0.9996 |     29.585 |     0.5
   40 |   0.6101 |     19.307 |   0.9949 |     28.965 |     0.5
   41 |   0.5895 |     18.541 |   0.9971 |     29.616 |     0.6
   42 |   0.5723 |     17.945 |   0.9985 |     28.872 |     0.6
   43 |   0.5614 |     17.692 |   1.0039 |     29.337 |     0.6
   44 |   0.5609 |     17.631 |   0.9915 |     28.717 |     0.6
   45 |   0.5382 |     17.190 |   0.9921 |     28.377 |     0.6
   46 |   0.5338 |     16.711 |   1.0327 |     29.182 |     0.6
   47 |   0.5253 |     16.755 |   1.0179 |     28.346 |     0.6
   48 |   0.5129 |     16.286 |   1.0183 |     28.253 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 416,546

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6157 |     68.364 |   2.0514 |     59.851 |     0.0
    2 |   1.7961 |     50.099 |   1.5963 |     46.344 |     0.0
    3 |   1.5155 |     46.015 |   1.4674 |     47.150 |     0.1
    4 |   1.4405 |     46.037 |   1.4259 |     46.344 |     0.1
    5 |   1.4150 |     46.026 |   1.4120 |     46.344 |     0.1
    6 |   1.4011 |     46.114 |   1.4008 |     46.344 |     0.1
    7 |   1.3944 |     46.092 |   1.3976 |     46.344 |     0.1
    8 |   1.3908 |     46.021 |   1.3947 |     46.344 |     0.2
    9 |   1.3885 |     46.043 |   1.3948 |     46.066 |     0.2
   10 |   1.3864 |     45.933 |   1.3919 |     47.150 |     0.2
   11 |   1.3836 |     45.944 |   1.3847 |     45.787 |     0.2
   12 |   1.3765 |     45.861 |   1.3812 |     46.375 |     0.2
   13 |   1.3600 |     44.902 |   1.3599 |     45.260 |     0.3
   14 |   1.3411 |     44.522 |   1.3433 |     45.601 |     0.3
   15 |   1.3293 |     44.555 |   1.3360 |     45.136 |     0.3
   16 |   1.3191 |     44.296 |   1.3371 |     45.074 |     0.3
   17 |   1.3185 |     44.257 |   1.3344 |     45.260 |     0.3
   18 |   1.3040 |     43.877 |   1.3146 |     45.105 |     0.4
   19 |   1.2946 |     43.833 |   1.3039 |     44.919 |     0.4
   20 |   1.2873 |     43.596 |   1.3019 |     44.145 |     0.4
   21 |   1.2787 |     43.144 |   1.2968 |     43.959 |     0.4
   22 |   1.2640 |     42.411 |   1.2894 |     44.238 |     0.4
   23 |   1.2546 |     42.207 |   1.2836 |     43.185 |     0.5
   24 |   1.2414 |     41.716 |   1.2836 |     43.649 |     0.5
   25 |   1.2311 |     41.314 |   1.2685 |     42.875 |     0.5
   26 |   1.2220 |     41.165 |   1.2646 |     43.030 |     0.5
   27 |   1.2141 |     40.823 |   1.2629 |     42.162 |     0.5
   28 |   1.2036 |     40.454 |   1.2651 |     42.627 |     0.6
   29 |   1.1943 |     40.349 |   1.2474 |     42.534 |     0.6
   30 |   1.1937 |     40.101 |   1.2365 |     41.481 |     0.6
   31 |   1.1822 |     39.771 |   1.2363 |     42.100 |     0.6
   32 |   1.1644 |     39.473 |   1.2303 |     41.605 |     0.6
   33 |   1.1535 |     38.999 |   1.2244 |     41.326 |     0.7
   34 |   1.1460 |     38.977 |   1.2159 |     41.233 |     0.7
   35 |   1.1302 |     38.371 |   1.2194 |     41.171 |     0.7
   36 |   1.1245 |     38.509 |   1.2221 |     41.450 |     0.7
   37 |   1.1096 |     38.002 |   1.2167 |     41.295 |     0.7
   38 |   1.1002 |     37.467 |   1.2065 |     40.737 |     0.8
   39 |   1.0871 |     36.921 |   1.1974 |     40.025 |     0.8
   40 |   1.0680 |     36.282 |   1.1920 |     40.118 |     0.8
   41 |   1.0545 |     35.692 |   1.1949 |     40.211 |     0.8
   42 |   1.0549 |     35.648 |   1.1959 |     39.560 |     0.8
   43 |   1.0476 |     35.075 |   1.1952 |     39.622 |     0.9
   44 |   1.0288 |     34.524 |   1.2124 |     40.149 |     0.9
   45 |   1.0162 |     34.193 |   1.1802 |     39.033 |     0.9
   46 |   0.9982 |     33.725 |   1.1928 |     39.715 |     0.9
   47 |   0.9901 |     33.207 |   1.1805 |     38.662 |     0.9
   48 |   0.9741 |     32.407 |   1.1747 |     38.383 |     1.0
   49 |   0.9592 |     32.066 |   1.1823 |     38.352 |     1.0
   50 |   0.9503 |     31.691 |   1.1789 |     38.352 |     1.0
   51 |   0.9359 |     31.333 |   1.1621 |     37.887 |     1.0
   52 |   0.9210 |     30.754 |   1.1622 |     38.166 |     1.0
   53 |   0.9135 |     30.456 |   1.1530 |     37.670 |     1.1
   54 |   0.9003 |     30.181 |   1.1479 |     36.803 |     1.1
   55 |   0.8876 |     29.740 |   1.1507 |     37.268 |     1.1
   56 |   0.8757 |     29.145 |   1.1751 |     37.639 |     1.1
   57 |   0.8637 |     28.693 |   1.1366 |     36.276 |     1.1
   58 |   0.8483 |     28.164 |   1.1461 |     36.741 |     1.2
   59 |   0.8232 |     27.425 |   1.1451 |     36.586 |     1.2
   60 |   0.8066 |     26.560 |   1.1407 |     35.440 |     1.2
   61 |   0.7978 |     26.483 |   1.1405 |     35.936 |     1.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,207,394

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2326 |     60.665 |   1.6334 |     46.530 |     0.0
    2 |   1.4881 |     46.098 |   1.4275 |     46.344 |     0.1
    3 |   1.4087 |     46.032 |   1.4016 |     46.344 |     0.1
    4 |   1.3919 |     45.949 |   1.3897 |     46.221 |     0.2
    5 |   1.3675 |     44.874 |   1.3647 |     46.159 |     0.2
    6 |   1.3382 |     44.042 |   1.3485 |     45.074 |     0.2
    7 |   1.3148 |     43.634 |   1.3224 |     44.331 |     0.3
    8 |   1.3027 |     43.122 |   1.3123 |     43.928 |     0.3
    9 |   1.2847 |     42.532 |   1.2956 |     43.463 |     0.4
   10 |   1.2686 |     42.289 |   1.2806 |     43.123 |     0.4
   11 |   1.2543 |     41.744 |   1.2897 |     44.269 |     0.4
   12 |   1.2473 |     41.595 |   1.2850 |     43.340 |     0.5
   13 |   1.2319 |     41.011 |   1.2522 |     42.937 |     0.5
   14 |   1.2173 |     40.410 |   1.2426 |     42.689 |     0.5
   15 |   1.2006 |     40.278 |   1.2317 |     41.791 |     0.6
   16 |   1.1830 |     39.672 |   1.2146 |     41.047 |     0.6
   17 |   1.1688 |     39.082 |   1.2109 |     41.450 |     0.7
   18 |   1.1483 |     38.597 |   1.1927 |     40.644 |     0.7
   19 |   1.1259 |     38.084 |   1.1833 |     39.498 |     0.7
   20 |   1.0982 |     37.081 |   1.1693 |     39.436 |     0.8
   21 |   1.0711 |     35.648 |   1.1575 |     38.879 |     0.8
   22 |   1.0471 |     34.948 |   1.1376 |     38.104 |     0.9
   23 |   1.0201 |     34.127 |   1.1373 |     37.887 |     0.9
   24 |   1.0047 |     33.333 |   1.1223 |     36.462 |     0.9
   25 |   0.9784 |     32.126 |   1.1170 |     36.617 |     1.0
   26 |   0.9508 |     31.570 |   1.0825 |     35.316 |     1.0
   27 |   0.9201 |     30.787 |   1.0841 |     35.254 |     1.1
   28 |   0.8987 |     29.635 |   1.0643 |     34.572 |     1.1
   29 |   0.8682 |     29.056 |   1.0643 |     34.108 |     1.1
   30 |   0.8415 |     28.274 |   1.0677 |     33.953 |     1.2
   31 |   0.8160 |     27.232 |   1.0508 |     33.209 |     1.2
   32 |   0.7853 |     26.042 |   1.0186 |     32.404 |     1.3
   33 |   0.7647 |     25.105 |   1.0176 |     32.311 |     1.3
   34 |   0.7342 |     24.322 |   1.0290 |     32.962 |     1.3
   35 |   0.7095 |     23.374 |   1.0115 |     32.249 |     1.4
   36 |   0.6776 |     22.217 |   1.0332 |     31.908 |     1.4
   37 |   0.6636 |     21.903 |   1.0034 |     29.895 |     1.5
   38 |   0.6260 |     20.547 |   1.0001 |     30.824 |     1.5
   39 |   0.6089 |     19.968 |   1.0238 |     31.537 |     1.5
   40 |   0.5883 |     19.246 |   1.0298 |     30.328 |     1.6
   41 |   0.5690 |     18.667 |   1.0329 |     30.452 |     1.6
   42 |   0.5450 |     17.758 |   1.0335 |     30.979 |     1.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 207,650

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5326 |     67.394 |   1.9182 |     50.929 |     0.0
    2 |   1.6684 |     47.625 |   1.5010 |     46.283 |     0.0
    3 |   1.4342 |     45.718 |   1.3859 |     45.756 |     0.0
    4 |   1.3437 |     44.064 |   1.3181 |     42.782 |     0.1
    5 |   1.2789 |     41.402 |   1.2709 |     41.729 |     0.1
    6 |   1.2231 |     39.324 |   1.2262 |     40.273 |     0.1
    7 |   1.1759 |     37.935 |   1.1908 |     39.684 |     0.1
    8 |   1.1320 |     37.307 |   1.1578 |     39.529 |     0.1
    9 |   1.0906 |     35.560 |   1.1341 |     39.064 |     0.1
   10 |   1.0524 |     34.667 |   1.1079 |     37.887 |     0.1
   11 |   1.0177 |     33.212 |   1.0890 |     36.989 |     0.1
   12 |   0.9728 |     31.470 |   1.0545 |     35.254 |     0.2
   13 |   0.9282 |     29.541 |   1.0292 |     34.325 |     0.2
   14 |   0.8835 |     27.712 |   1.0048 |     33.488 |     0.2
   15 |   0.8413 |     26.687 |   1.0021 |     32.838 |     0.2
   16 |   0.8061 |     25.573 |   0.9721 |     32.218 |     0.2
   17 |   0.7662 |     23.854 |   0.9647 |     30.328 |     0.2
   18 |   0.7279 |     22.575 |   0.9648 |     30.576 |     0.2
   19 |   0.6951 |     21.396 |   0.9501 |     30.700 |     0.2
   20 |   0.6600 |     20.321 |   0.9352 |     29.709 |     0.3
   21 |   0.6274 |     19.152 |   0.9307 |     29.337 |     0.3
   22 |   0.5975 |     18.182 |   0.9279 |     29.585 |     0.3
   23 |   0.5701 |     17.345 |   0.9192 |     28.501 |     0.3
   24 |   0.5557 |     16.518 |   0.9130 |     28.563 |     0.3
   25 |   0.5211 |     15.603 |   0.9141 |     28.408 |     0.3
   26 |   0.4988 |     14.931 |   0.9362 |     28.470 |     0.3
   27 |   0.4785 |     14.357 |   0.9382 |     27.478 |     0.3
   28 |   0.4600 |     13.569 |   0.9173 |     27.169 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 383,266

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5330 |     66.165 |   1.9811 |     59.201 |     0.0
    2 |   1.7562 |     50.033 |   1.5711 |     46.344 |     0.0
    3 |   1.4998 |     45.899 |   1.4507 |     46.344 |     0.1
    4 |   1.4272 |     46.059 |   1.4090 |     46.344 |     0.1
    5 |   1.3932 |     45.696 |   1.3858 |     45.539 |     0.1
    6 |   1.3639 |     44.478 |   1.3569 |     45.601 |     0.1
    7 |   1.3413 |     44.274 |   1.3423 |     45.043 |     0.2
    8 |   1.3251 |     43.827 |   1.3271 |     44.548 |     0.2
    9 |   1.3070 |     43.689 |   1.3046 |     44.672 |     0.2
   10 |   1.2858 |     42.863 |   1.3098 |     44.486 |     0.2
   11 |   1.2653 |     42.256 |   1.2723 |     42.906 |     0.2
   12 |   1.2444 |     41.104 |   1.2547 |     41.729 |     0.3
   13 |   1.2222 |     40.294 |   1.2418 |     41.976 |     0.3
   14 |   1.2038 |     40.129 |   1.2362 |     41.729 |     0.3
   15 |   1.1848 |     39.721 |   1.2138 |     41.202 |     0.3
   16 |   1.1739 |     39.407 |   1.2125 |     40.861 |     0.4
   17 |   1.1538 |     38.812 |   1.2059 |     41.047 |     0.4
   18 |   1.1319 |     38.393 |   1.1918 |     40.520 |     0.4
   19 |   1.1126 |     37.858 |   1.1843 |     40.242 |     0.4
   20 |   1.1056 |     37.329 |   1.1826 |     40.118 |     0.4
   21 |   1.0839 |     36.883 |   1.1595 |     39.715 |     0.5
   22 |   1.0643 |     36.078 |   1.1521 |     38.848 |     0.5
   23 |   1.0434 |     35.378 |   1.1550 |     38.290 |     0.5
   24 |   1.0306 |     34.711 |   1.1508 |     38.724 |     0.5
   25 |   1.0176 |     34.204 |   1.1514 |     39.157 |     0.5
   26 |   0.9963 |     33.069 |   1.1284 |     37.144 |     0.6
   27 |   0.9793 |     32.909 |   1.1151 |     37.175 |     0.6
   28 |   0.9656 |     32.584 |   1.1087 |     36.896 |     0.6
   29 |   0.9462 |     31.559 |   1.0989 |     36.183 |     0.6
   30 |   0.9316 |     31.074 |   1.0975 |     36.276 |     0.7
   31 |   0.9186 |     30.748 |   1.0789 |     35.037 |     0.7
   32 |   0.8981 |     29.712 |   1.0869 |     35.719 |     0.7
   33 |   0.8800 |     29.161 |   1.0744 |     35.626 |     0.7
   34 |   0.8675 |     28.963 |   1.0701 |     34.356 |     0.7
   35 |   0.8536 |     28.720 |   1.0598 |     34.294 |     0.8
   36 |   0.8318 |     27.811 |   1.0654 |     34.263 |     0.8
   37 |   0.8209 |     27.061 |   1.0366 |     33.209 |     0.8
   38 |   0.8057 |     26.813 |   1.0498 |     34.077 |     0.8
   39 |   0.7876 |     25.976 |   1.0675 |     33.922 |     0.9
   40 |   0.7739 |     25.281 |   1.0545 |     33.612 |     0.9
   41 |   0.7624 |     25.094 |   1.0432 |     33.705 |     0.9
   42 |   0.7502 |     24.686 |   1.0327 |     32.435 |     0.9
   43 |   0.7282 |     24.069 |   1.0425 |     32.466 |     0.9
   44 |   0.7243 |     23.699 |   1.0335 |     32.094 |     1.0
   45 |   0.7055 |     23.275 |   1.0251 |     31.691 |     1.0
   46 |   0.6901 |     22.735 |   1.0354 |     32.001 |     1.0
   47 |   0.6832 |     22.509 |   1.0245 |     31.629 |     1.0
   48 |   0.6726 |     21.886 |   1.0389 |     31.970 |     1.1
   49 |   0.6634 |     21.759 |   1.0389 |     31.815 |     1.1
   50 |   0.6528 |     21.230 |   1.0294 |     30.979 |     1.1
   51 |   0.6488 |     21.368 |   1.0348 |     31.010 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 435,170

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4562 |     66.110 |   1.8927 |     50.248 |     0.0
    2 |   1.6724 |     47.884 |   1.5073 |     46.252 |     0.0
    3 |   1.4447 |     45.773 |   1.3942 |     45.725 |     0.1
    4 |   1.3531 |     44.290 |   1.3337 |     43.928 |     0.1
    5 |   1.2805 |     41.220 |   1.2623 |     42.100 |     0.1
    6 |   1.2186 |     39.335 |   1.2269 |     40.613 |     0.1
    7 |   1.1804 |     38.442 |   1.1910 |     39.498 |     0.1
    8 |   1.1361 |     36.938 |   1.1724 |     39.560 |     0.1
    9 |   1.1030 |     36.045 |   1.1305 |     37.082 |     0.2
   10 |   1.0578 |     33.835 |   1.1044 |     36.214 |     0.2
   11 |   1.0206 |     32.435 |   1.0850 |     35.812 |     0.2
   12 |   0.9818 |     31.046 |   1.0587 |     34.170 |     0.2
   13 |   0.9465 |     29.812 |   1.0420 |     33.829 |     0.2
   14 |   0.9101 |     28.538 |   1.0173 |     32.652 |     0.2
   15 |   0.8808 |     27.993 |   1.0200 |     32.745 |     0.3
   16 |   0.8459 |     26.582 |   1.0048 |     32.125 |     0.3
   17 |   0.8224 |     25.871 |   0.9848 |     31.041 |     0.3
   18 |   0.7938 |     24.818 |   0.9580 |     30.731 |     0.3
   19 |   0.7730 |     24.250 |   0.9638 |     30.328 |     0.3
   20 |   0.7408 |     23.187 |   0.9438 |     30.081 |     0.3
   21 |   0.7243 |     22.702 |   0.9408 |     29.833 |     0.4
   22 |   0.7009 |     21.792 |   0.9489 |     29.678 |     0.4
   23 |   0.6757 |     21.357 |   0.9307 |     29.430 |     0.4
   24 |   0.6493 |     20.431 |   0.9246 |     27.881 |     0.4
   25 |   0.6253 |     19.411 |   0.9284 |     28.284 |     0.4
   26 |   0.6101 |     19.059 |   0.9323 |     28.439 |     0.4
   27 |   0.5978 |     18.612 |   0.9340 |     28.284 |     0.5
   28 |   0.5699 |     17.852 |   0.9071 |     28.098 |     0.5
   29 |   0.5579 |     17.504 |   0.9181 |     27.571 |     0.5
   30 |   0.5507 |     17.526 |   0.9304 |     28.315 |     0.5
   31 |   0.5320 |     16.567 |   0.9285 |     27.850 |     0.5
   32 |   0.5135 |     15.829 |   0.9173 |     27.014 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 669,986

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1361 |     57.766 |   1.5300 |     46.314 |     0.0
    2 |   1.4040 |     44.687 |   1.3348 |     44.672 |     0.0
    3 |   1.2726 |     41.226 |   1.2642 |     41.914 |     0.1
    4 |   1.1957 |     39.137 |   1.1877 |     39.219 |     0.1
    5 |   1.1239 |     36.894 |   1.1287 |     37.856 |     0.1
    6 |   1.0584 |     34.640 |   1.0924 |     36.555 |     0.1
    7 |   0.9951 |     32.319 |   1.0539 |     35.192 |     0.2
    8 |   0.9295 |     29.867 |   1.0151 |     33.457 |     0.2
    9 |   0.8642 |     27.612 |   0.9823 |     32.373 |     0.2
   10 |   0.8095 |     25.909 |   0.9508 |     30.545 |     0.2
   11 |   0.7699 |     24.438 |   0.9352 |     30.545 |     0.3
   12 |   0.6929 |     21.820 |   0.8937 |     28.810 |     0.3
   13 |   0.6451 |     20.144 |   0.8920 |     28.903 |     0.3
   14 |   0.5888 |     18.601 |   0.8821 |     27.416 |     0.3
   15 |   0.5466 |     17.130 |   0.8756 |     27.107 |     0.4
   16 |   0.5031 |     15.542 |   0.8930 |     26.983 |     0.4
   17 |   0.4683 |     14.517 |   0.8729 |     25.558 |     0.4
   18 |   0.4222 |     13.101 |   0.8763 |     25.372 |     0.4
   19 |   0.3870 |     11.784 |   0.8764 |     25.527 |     0.5
   20 |   0.3624 |     10.979 |   0.8806 |     24.349 |     0.5
   21 |   0.3316 |     10.125 |   0.8918 |     24.597 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 1,830,562

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5877 |     68.932 |   2.0061 |     59.851 |     0.7
    2 |   1.7748 |     50.331 |   1.5892 |     46.344 |     1.5
    3 |   1.5039 |     45.949 |   1.4583 |     46.344 |     2.2
    4 |   1.4334 |     45.977 |   1.4260 |     46.344 |     3.0
    5 |   1.4086 |     45.949 |   1.4059 |     46.344 |     3.7
    6 |   1.3967 |     46.081 |   1.3999 |     46.344 |     4.5
    7 |   1.3881 |     45.988 |   1.3849 |     46.344 |     5.3
    8 |   1.3702 |     45.899 |   1.3648 |     46.344 |     6.0
    9 |   1.3535 |     45.536 |   1.3506 |     45.539 |     6.8
   10 |   1.3389 |     45.288 |   1.3400 |     45.570 |     7.5
   11 |   1.3218 |     45.045 |   1.3222 |     45.043 |     8.3
   12 |   1.3072 |     44.775 |   1.3196 |     45.415 |     9.0
   13 |   1.2949 |     44.715 |   1.3070 |     45.229 |     9.8
   14 |   1.2847 |     44.615 |   1.2923 |     44.827 |    10.5
   15 |   1.2732 |     44.086 |   1.2905 |     44.796 |    11.3
   16 |   1.2669 |     43.767 |   1.2808 |     43.959 |    12.0
   17 |   1.2582 |     43.436 |   1.2799 |     44.672 |    12.8
   18 |   1.2455 |     42.411 |   1.2686 |     43.897 |    13.6
   19 |   1.2340 |     41.804 |   1.2489 |     42.534 |    14.3
   20 |   1.2155 |     41.231 |   1.2304 |     43.030 |    15.1
   21 |   1.2015 |     40.939 |   1.2359 |     42.100 |    15.8
   22 |   1.1928 |     40.542 |   1.2134 |     41.605 |    16.6
   23 |   1.1855 |     40.212 |   1.2231 |     41.945 |    17.4
   24 |   1.1664 |     39.644 |   1.2085 |     41.512 |    18.1
   25 |   1.1575 |     39.093 |   1.2082 |     41.822 |    18.9
   26 |   1.1410 |     38.768 |   1.1823 |     40.892 |    19.7
   27 |   1.1268 |     38.294 |   1.1879 |     41.109 |    20.4
   28 |   1.1272 |     38.112 |   1.1913 |     41.357 |    21.2
   29 |   1.1164 |     38.046 |   1.1820 |     40.211 |    21.9
   30 |   1.1155 |     37.610 |   1.1826 |     40.706 |    22.7
   31 |   1.1067 |     37.522 |   1.1774 |     41.388 |    23.4
   32 |   1.0894 |     37.021 |   1.1629 |     40.211 |    24.2
   33 |   1.0931 |     37.280 |   1.1911 |     40.861 |    24.9
   34 |   1.0826 |     36.728 |   1.1741 |     40.242 |    25.7
   35 |   1.0655 |     36.475 |   1.1483 |     39.684 |    26.4
   36 |   1.0605 |     36.304 |   1.1499 |     40.335 |    27.2
   37 |   1.0671 |     36.469 |   1.1528 |     39.994 |    27.9
   38 |   1.0611 |     36.139 |   1.1591 |     39.591 |    28.7
   39 |   1.0333 |     34.998 |   1.1361 |     38.724 |    29.5
   40 |   1.0239 |     34.921 |   1.1198 |     38.755 |    30.2
   41 |   1.0047 |     34.039 |   1.1243 |     38.414 |    31.0
   42 |   0.9967 |     33.708 |   1.1390 |     39.312 |    31.8
   43 |   0.9983 |     34.199 |   1.1377 |     38.228 |    32.5
   44 |   0.9889 |     33.708 |   1.1203 |     37.980 |    33.3
   45 |   0.9778 |     33.140 |   1.1112 |     38.104 |    34.0
   46 |   0.9548 |     32.429 |   1.0833 |     37.268 |    34.8
   47 |   0.9527 |     32.722 |   1.1108 |     38.073 |    35.6
   48 |   0.9659 |     33.025 |   1.0922 |     37.206 |    36.3
   49 |   0.9436 |     31.994 |   1.1008 |     37.423 |    37.1
   50 |   0.9410 |     31.785 |   1.1075 |     37.082 |    37.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,778,722

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5141 |     67.196 |   1.9900 |     59.851 |     0.7
    2 |   1.7684 |     50.369 |   1.5812 |     46.344 |     1.5
    3 |   1.4990 |     45.988 |   1.4549 |     46.344 |     2.3
    4 |   1.4328 |     46.026 |   1.4225 |     46.344 |     3.0
    5 |   1.4109 |     46.037 |   1.4052 |     46.344 |     3.8
    6 |   1.4011 |     45.993 |   1.3991 |     46.344 |     4.6
    7 |   1.3949 |     45.944 |   1.3936 |     46.344 |     5.3
    8 |   1.3911 |     46.021 |   1.3940 |     46.314 |     6.1
    9 |   1.3857 |     45.916 |   1.3881 |     46.252 |     6.8
   10 |   1.3770 |     45.839 |   1.3805 |     46.159 |     7.6
   11 |   1.3629 |     44.709 |   1.3616 |     45.601 |     8.4
   12 |   1.3464 |     44.483 |   1.3491 |     45.446 |     9.2
   13 |   1.3356 |     44.119 |   1.3487 |     45.198 |     9.9
   14 |   1.3273 |     43.822 |   1.3367 |     45.136 |    10.7
   15 |   1.3196 |     43.574 |   1.3350 |     45.167 |    11.5
   16 |   1.3110 |     43.359 |   1.3296 |     44.672 |    12.2
   17 |   1.3050 |     43.078 |   1.3159 |     44.300 |    13.0
   18 |   1.2957 |     42.604 |   1.3158 |     44.145 |    13.7
   19 |   1.2896 |     42.598 |   1.3135 |     44.362 |    14.5
   20 |   1.2798 |     42.433 |   1.2973 |     43.680 |    15.3
   21 |   1.2770 |     42.350 |   1.2910 |     43.773 |    16.0
   22 |   1.2699 |     42.190 |   1.2849 |     43.371 |    16.8
   23 |   1.2632 |     42.135 |   1.2852 |     43.278 |    17.6
   24 |   1.2581 |     41.909 |   1.2777 |     43.742 |    18.3
   25 |   1.2504 |     41.788 |   1.2769 |     43.587 |    19.1
   26 |   1.2470 |     41.634 |   1.2744 |     43.432 |    19.9
   27 |   1.2397 |     41.391 |   1.2767 |     43.432 |    20.6
   28 |   1.2338 |     41.314 |   1.2722 |     42.751 |    21.4
   29 |   1.2241 |     41.022 |   1.2627 |     43.680 |    22.1
   30 |   1.2288 |     41.165 |   1.2598 |     42.844 |    22.9
   31 |   1.2132 |     40.691 |   1.2531 |     42.534 |    23.7
   32 |   1.2099 |     40.526 |   1.2463 |     42.503 |    24.4
   33 |   1.2019 |     40.443 |   1.2332 |     41.791 |    25.2
   34 |   1.2020 |     40.129 |   1.2458 |     42.379 |    26.0
   35 |   1.1950 |     40.261 |   1.2402 |     42.007 |    26.7
   36 |   1.1870 |     40.052 |   1.2352 |     42.472 |    27.5
   37 |   1.1831 |     39.699 |   1.2276 |     41.822 |    28.3
   38 |   1.1694 |     39.396 |   1.2215 |     41.481 |    29.0
   39 |   1.1675 |     39.198 |   1.2147 |     41.512 |    29.8
   40 |   1.1601 |     39.137 |   1.2153 |     41.945 |    30.6
   41 |   1.1524 |     38.806 |   1.2048 |     41.326 |    31.4
   42 |   1.1419 |     38.509 |   1.2106 |     41.264 |    32.1
   43 |   1.1355 |     38.178 |   1.2084 |     41.884 |    32.9
   44 |   1.1266 |     37.935 |   1.2010 |     40.273 |    33.7
   45 |   1.1142 |     37.561 |   1.1913 |     40.954 |    34.4
   46 |   1.1178 |     37.461 |   1.1866 |     40.458 |    35.2
   47 |   1.1117 |     37.456 |   1.1831 |     40.335 |    36.0
   48 |   1.1070 |     37.213 |   1.1728 |     39.622 |    36.7
   49 |   1.0987 |     36.982 |   1.1760 |     40.087 |    37.5
   50 |   1.0971 |     36.888 |   1.1725 |     39.002 |    38.3
   51 |   1.0840 |     36.547 |   1.1747 |     40.458 |    39.0
   52 |   1.0752 |     36.144 |   1.1757 |     39.808 |    39.8
   53 |   1.0650 |     35.841 |   1.1686 |     39.498 |    40.5
   54 |   1.0675 |     35.935 |   1.1632 |     39.467 |    41.3
   55 |   1.0571 |     35.648 |   1.1614 |     38.631 |    42.1
   56 |   1.0538 |     35.450 |   1.1629 |     39.033 |    42.8
   57 |   1.0487 |     35.207 |   1.1590 |     39.095 |    43.6
   58 |   1.0636 |     36.012 |   1.1761 |     39.250 |    44.3
   59 |   1.0573 |     35.588 |   1.1481 |     38.414 |    45.1
   60 |   1.0435 |     35.240 |   1.1381 |     38.352 |    45.8
   61 |   1.0372 |     35.158 |   1.1472 |     38.538 |    46.6
   62 |   1.0330 |     35.058 |   1.1395 |     38.321 |    47.4
   63 |   1.0215 |     34.381 |   1.1409 |     37.732 |    48.1
   64 |   1.0100 |     34.166 |   1.1394 |     38.476 |    48.9
   65 |   1.0142 |     34.232 |   1.1310 |     37.825 |    49.7
   66 |   0.9941 |     33.460 |   1.1277 |     37.546 |    50.4
   67 |   0.9972 |     33.681 |   1.1174 |     36.958 |    51.2
   68 |   0.9876 |     33.201 |   1.1190 |     37.546 |    52.0
   69 |   0.9832 |     32.970 |   1.1228 |     36.338 |    52.7
   70 |   0.9753 |     32.700 |   1.1225 |     37.701 |    53.5
   71 |   0.9613 |     32.468 |   1.1359 |     37.701 |    54.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 755,106

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2160 |     59.199 |   1.5728 |     46.344 |     0.0
    2 |   1.4548 |     46.026 |   1.3940 |     46.344 |     0.1
    3 |   1.3732 |     45.866 |   1.3460 |     45.229 |     0.1
    4 |   1.3227 |     44.235 |   1.2991 |     44.362 |     0.1
    5 |   1.2664 |     42.510 |   1.2645 |     42.255 |     0.2
    6 |   1.2276 |     40.873 |   1.2388 |     41.636 |     0.2
    7 |   1.1848 |     39.401 |   1.2174 |     40.954 |     0.2
    8 |   1.1474 |     38.255 |   1.1806 |     40.025 |     0.2
    9 |   1.1204 |     37.528 |   1.1466 |     39.219 |     0.3
   10 |   1.0748 |     36.084 |   1.1350 |     39.002 |     0.3
   11 |   1.0332 |     34.750 |   1.1093 |     37.454 |     0.3
   12 |   0.9984 |     33.399 |   1.0875 |     36.679 |     0.4
   13 |   0.9557 |     31.944 |   1.0648 |     35.533 |     0.4
   14 |   0.9214 |     30.765 |   1.0226 |     33.643 |     0.4
   15 |   0.8706 |     28.753 |   1.0180 |     33.147 |     0.5
   16 |   0.8367 |     27.260 |   1.0093 |     32.714 |     0.5
   17 |   0.8022 |     26.444 |   0.9879 |     32.373 |     0.5
   18 |   0.7421 |     23.859 |   0.9780 |     31.382 |     0.6
   19 |   0.7195 |     23.010 |   0.9770 |     30.700 |     0.6
   20 |   0.6876 |     22.338 |   0.9431 |     29.926 |     0.6
   21 |   0.6458 |     21.010 |   0.9642 |     29.368 |     0.6
   22 |   0.6226 |     19.863 |   0.9377 |     28.222 |     0.7
   23 |   0.6012 |     19.384 |   0.9474 |     28.191 |     0.7
   24 |   0.5639 |     18.403 |   0.9330 |     27.850 |     0.7
   25 |   0.5331 |     17.091 |   0.9229 |     27.045 |     0.8
   26 |   0.5127 |     16.402 |   0.9275 |     27.107 |     0.8
   27 |   0.4940 |     16.093 |   0.9513 |     27.014 |     0.8
   28 |   0.4727 |     15.234 |   0.9404 |     26.611 |     0.9
   29 |   0.4458 |     14.622 |   0.9526 |     26.921 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 692,130

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5645 |     67.593 |   1.9862 |     59.851 |     0.0
    2 |   1.7635 |     49.835 |   1.5994 |     46.344 |     0.0
    3 |   1.5085 |     46.010 |   1.4560 |     46.344 |     0.1
    4 |   1.4296 |     45.999 |   1.4186 |     46.344 |     0.1
    5 |   1.4079 |     45.971 |   1.4066 |     46.344 |     0.1
    6 |   1.3995 |     45.993 |   1.3998 |     47.243 |     0.1
    7 |   1.3927 |     46.159 |   1.3959 |     46.344 |     0.2
    8 |   1.3890 |     46.109 |   1.3936 |     46.314 |     0.2
    9 |   1.3883 |     46.131 |   1.3896 |     46.344 |     0.2
   10 |   1.3837 |     45.949 |   1.3825 |     46.406 |     0.2
   11 |   1.3746 |     45.679 |   1.3705 |     45.477 |     0.3
   12 |   1.3545 |     44.544 |   1.3585 |     45.694 |     0.3
   13 |   1.3412 |     44.637 |   1.3464 |     45.384 |     0.3
   14 |   1.3297 |     44.571 |   1.3430 |     45.446 |     0.3
   15 |   1.3207 |     44.235 |   1.3400 |     45.477 |     0.4
   16 |   1.3171 |     44.202 |   1.3253 |     45.384 |     0.4
   17 |   1.3078 |     44.092 |   1.3149 |     45.105 |     0.4
   18 |   1.3011 |     43.590 |   1.3147 |     44.827 |     0.5
   19 |   1.2929 |     43.447 |   1.3023 |     44.331 |     0.5
   20 |   1.2825 |     42.819 |   1.3068 |     44.021 |     0.5
   21 |   1.2735 |     42.582 |   1.2892 |     44.238 |     0.5
   22 |   1.2635 |     42.190 |   1.2881 |     43.835 |     0.6
   23 |   1.2527 |     41.810 |   1.2879 |     43.866 |     0.6
   24 |   1.2454 |     41.595 |   1.2765 |     43.525 |     0.6
   25 |   1.2360 |     41.402 |   1.2745 |     43.216 |     0.6
   26 |   1.2295 |     41.364 |   1.2621 |     42.999 |     0.7
   27 |   1.2196 |     41.033 |   1.2698 |     42.813 |     0.7
   28 |   1.2148 |     40.735 |   1.2706 |     42.844 |     0.7
   29 |   1.2104 |     40.757 |   1.2644 |     42.968 |     0.7
   30 |   1.1991 |     40.289 |   1.2448 |     42.379 |     0.8
   31 |   1.1868 |     39.870 |   1.2474 |     42.069 |     0.8
   32 |   1.1765 |     39.627 |   1.2349 |     41.760 |     0.8
   33 |   1.1678 |     39.473 |   1.2395 |     41.419 |     0.8
   34 |   1.1571 |     38.850 |   1.2258 |     41.481 |     0.9
   35 |   1.1474 |     38.299 |   1.2196 |     41.171 |     0.9
   36 |   1.1333 |     37.754 |   1.2230 |     41.078 |     0.9
   37 |   1.1256 |     37.847 |   1.2097 |     41.233 |     0.9
   38 |   1.1161 |     37.478 |   1.1906 |     40.273 |     1.0
   39 |   1.1024 |     37.252 |   1.1885 |     40.211 |     1.0
   40 |   1.0883 |     36.541 |   1.1730 |     39.870 |     1.0
   41 |   1.0723 |     35.957 |   1.1632 |     39.188 |     1.0
   42 |   1.0629 |     35.819 |   1.1689 |     39.467 |     1.1
   43 |   1.0523 |     35.064 |   1.1617 |     38.724 |     1.1
   44 |   1.0437 |     35.257 |   1.1675 |     38.941 |     1.1
   45 |   1.0402 |     35.103 |   1.1391 |     38.476 |     1.1
   46 |   1.0234 |     34.656 |   1.1497 |     37.794 |     1.2
   47 |   1.0128 |     34.033 |   1.1365 |     38.166 |     1.2
   48 |   0.9997 |     33.901 |   1.1224 |     37.980 |     1.2
   49 |   0.9931 |     33.752 |   1.1247 |     37.980 |     1.2
   50 |   0.9756 |     32.854 |   1.1210 |     37.515 |     1.3
   51 |   0.9597 |     32.303 |   1.1253 |     37.082 |     1.3
   52 |   0.9525 |     31.950 |   1.1205 |     37.268 |     1.3
   53 |   0.9457 |     31.801 |   1.1156 |     37.113 |     1.3
   54 |   0.9333 |     31.625 |   1.1125 |     36.214 |     1.4
   55 |   0.9237 |     31.057 |   1.1187 |     36.927 |     1.4
   56 |   0.9079 |     30.418 |   1.1000 |     36.059 |     1.4
   57 |   0.8945 |     29.845 |   1.0936 |     36.276 |     1.4
   58 |   0.8958 |     30.258 |   1.0998 |     35.936 |     1.5
   59 |   0.8848 |     29.905 |   1.0990 |     35.006 |     1.5
   60 |   0.8738 |     29.310 |   1.0985 |     35.285 |     1.5
   61 |   0.8708 |     29.371 |   1.0747 |     35.254 |     1.5
   62 |   0.8616 |     29.310 |   1.0943 |     35.192 |     1.6
   63 |   0.8475 |     28.582 |   1.0690 |     35.254 |     1.6
   64 |   0.8461 |     28.373 |   1.0850 |     34.851 |     1.6
   65 |   0.8357 |     28.219 |   1.0892 |     34.696 |     1.6
   66 |   0.8195 |     27.761 |   1.0874 |     35.750 |     1.7
   67 |   0.8092 |     27.061 |   1.0995 |     36.214 |     1.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,142,882

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2135 |     60.422 |   1.6280 |     49.442 |     0.7
    2 |   1.4907 |     46.142 |   1.4320 |     47.181 |     1.5
    3 |   1.4049 |     45.866 |   1.3957 |     46.375 |     2.2
    4 |   1.3699 |     44.764 |   1.3641 |     45.539 |     3.0
    5 |   1.3424 |     44.323 |   1.3611 |     45.415 |     3.8
    6 |   1.3280 |     43.915 |   1.3381 |     44.672 |     4.5
    7 |   1.3085 |     43.469 |   1.3069 |     43.773 |     5.3
    8 |   1.2901 |     42.879 |   1.3075 |     43.649 |     6.1
    9 |   1.2835 |     42.582 |   1.3032 |     44.300 |     6.8
   10 |   1.2703 |     42.251 |   1.2973 |     43.494 |     7.6
   11 |   1.2565 |     41.804 |   1.2774 |     43.309 |     8.3
   12 |   1.2485 |     41.512 |   1.2786 |     43.463 |     9.1
   13 |   1.2347 |     41.127 |   1.2724 |     42.627 |     9.9
   14 |   1.2216 |     40.702 |   1.2583 |     42.596 |    10.7
   15 |   1.2047 |     40.272 |   1.2360 |     42.038 |    11.4
   16 |   1.1860 |     39.942 |   1.2343 |     41.976 |    12.2
   17 |   1.1761 |     39.247 |   1.2191 |     41.512 |    13.0
   18 |   1.1662 |     39.175 |   1.2091 |     41.171 |    13.8
   19 |   1.1498 |     38.514 |   1.2005 |     40.458 |    14.5
   20 |   1.1344 |     37.930 |   1.1961 |     40.366 |    15.3
   21 |   1.1181 |     37.483 |   1.1984 |     39.839 |    16.1
   22 |   1.1067 |     37.169 |   1.1615 |     39.157 |    16.9
   23 |   1.0836 |     36.243 |   1.1765 |     39.374 |    17.6
   24 |   1.0744 |     36.524 |   1.1725 |     39.312 |    18.4
   25 |   1.0651 |     35.444 |   1.1615 |     38.290 |    19.2
   26 |   1.0398 |     34.739 |   1.1548 |     37.856 |    19.9
   27 |   1.0235 |     34.011 |   1.1654 |     38.600 |    20.7
   28 |   1.0078 |     33.614 |   1.1745 |     38.971 |    21.5
   29 |   0.9982 |     33.162 |   1.1524 |     38.042 |    22.2
   30 |   0.9821 |     32.733 |   1.1319 |     36.834 |    23.0
   31 |   0.9568 |     31.851 |   1.1238 |     37.361 |    23.8
   32 |   0.9481 |     31.807 |   1.1116 |     36.431 |    24.5
   33 |   0.9381 |     31.448 |   1.1310 |     37.361 |    25.3
   34 |   0.9252 |     30.936 |   1.1273 |     37.144 |    26.1
   35 |   0.9063 |     30.346 |   1.1173 |     36.090 |    26.8
   36 |   0.9023 |     30.324 |   1.1087 |     36.245 |    27.6
   37 |   0.8907 |     29.547 |   1.0950 |     36.059 |    28.3
   38 |   0.8737 |     29.189 |   1.0974 |     35.626 |    29.1
   39 |   0.8500 |     28.483 |   1.1152 |     35.161 |    29.9
   40 |   0.8431 |     28.191 |   1.1111 |     34.572 |    30.6
   41 |   0.8372 |     28.131 |   1.1188 |     35.099 |    31.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 494,178

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6419 |     70.409 |   2.0820 |     59.851 |     0.0
    2 |   1.8609 |     52.640 |   1.6520 |     46.344 |     0.0
    3 |   1.5511 |     46.114 |   1.4833 |     46.344 |     0.1
    4 |   1.4545 |     46.021 |   1.4346 |     46.221 |     0.1
    5 |   1.4217 |     45.971 |   1.4130 |     46.344 |     0.1
    6 |   1.4071 |     46.054 |   1.4058 |     46.344 |     0.1
    7 |   1.3954 |     45.966 |   1.3868 |     46.623 |     0.1
    8 |   1.3818 |     45.674 |   1.3764 |     46.344 |     0.1
    9 |   1.3643 |     45.056 |   1.3580 |     45.322 |     0.2
   10 |   1.3415 |     44.147 |   1.3396 |     45.415 |     0.2
   11 |   1.3223 |     43.987 |   1.3406 |     45.353 |     0.2
   12 |   1.3097 |     43.485 |   1.3183 |     44.455 |     0.2
   13 |   1.2938 |     42.725 |   1.2992 |     43.773 |     0.2
   14 |   1.2762 |     42.174 |   1.2837 |     43.185 |     0.3
   15 |   1.2569 |     41.529 |   1.2975 |     43.773 |     0.3
   16 |   1.2427 |     40.939 |   1.2540 |     41.914 |     0.3
   17 |   1.2206 |     40.559 |   1.2432 |     41.791 |     0.3
   18 |   1.1991 |     39.859 |   1.2218 |     41.295 |     0.3
   19 |   1.1835 |     39.638 |   1.2125 |     41.419 |     0.4
   20 |   1.1678 |     39.225 |   1.2090 |     40.799 |     0.4
   21 |   1.1505 |     38.586 |   1.1915 |     40.706 |     0.4
   22 |   1.1356 |     38.575 |   1.1852 |     40.366 |     0.4
   23 |   1.1243 |     38.029 |   1.1742 |     40.025 |     0.4
   24 |   1.1247 |     38.272 |   1.1639 |     40.180 |     0.4
   25 |   1.1031 |     37.748 |   1.1620 |     39.591 |     0.5
   26 |   1.0851 |     37.004 |   1.1650 |     40.180 |     0.5
   27 |   1.0681 |     36.580 |   1.1445 |     38.941 |     0.5
   28 |   1.0573 |     36.304 |   1.1527 |     39.312 |     0.5
   29 |   1.0535 |     35.896 |   1.1347 |     39.002 |     0.5
   30 |   1.0306 |     35.334 |   1.1265 |     37.887 |     0.6
   31 |   1.0143 |     34.656 |   1.1174 |     37.670 |     0.6
   32 |   0.9990 |     34.017 |   1.1140 |     37.423 |     0.6
   33 |   0.9897 |     33.515 |   1.1067 |     37.237 |     0.6
   34 |   0.9774 |     33.168 |   1.1095 |     37.206 |     0.6
   35 |   0.9634 |     32.661 |   1.0998 |     36.555 |     0.7
   36 |   0.9572 |     32.468 |   1.0885 |     35.998 |     0.7
   37 |   0.9429 |     31.724 |   1.0871 |     36.555 |     0.7
   38 |   0.9219 |     31.129 |   1.0724 |     35.688 |     0.7
   39 |   0.9100 |     30.583 |   1.0642 |     34.449 |     0.7
   40 |   0.8990 |     30.131 |   1.0556 |     34.418 |     0.7
   41 |   0.8912 |     29.916 |   1.0673 |     35.006 |     0.8
   42 |   0.8760 |     29.817 |   1.0612 |     34.634 |     0.8
   43 |   0.8695 |     28.996 |   1.0583 |     34.046 |     0.8
   44 |   0.8588 |     28.836 |   1.0496 |     34.046 |     0.8
   45 |   0.8442 |     28.186 |   1.0437 |     33.395 |     0.8
   46 |   0.8347 |     28.031 |   1.0388 |     33.302 |     0.9
   47 |   0.8234 |     27.607 |   1.0419 |     33.767 |     0.9
   48 |   0.8106 |     26.995 |   1.0285 |     32.745 |     0.9
   49 |   0.8044 |     26.720 |   1.0284 |     33.116 |     0.9
   50 |   0.7931 |     26.483 |   1.0240 |     31.475 |     0.9
   51 |   0.7806 |     25.716 |   1.0176 |     31.970 |     1.0
   52 |   0.7770 |     25.794 |   1.0126 |     31.722 |     1.0
   53 |   0.7638 |     25.705 |   1.0621 |     32.404 |     1.0
   54 |   0.7584 |     25.209 |   1.0095 |     31.289 |     1.0
   55 |   0.7384 |     24.476 |   1.0077 |     31.599 |     1.0
   56 |   0.7380 |     24.146 |   1.0083 |     30.948 |     1.0
   57 |   0.7342 |     24.416 |   0.9892 |     30.545 |     1.1
   58 |   0.7131 |     23.424 |   1.0082 |     31.134 |     1.1
   59 |   0.7046 |     23.236 |   0.9922 |     30.886 |     1.1
   60 |   0.7028 |     23.082 |   0.9935 |     30.019 |     1.1
   61 |   0.6889 |     22.525 |   0.9918 |     30.545 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,074,274

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5011 |     66.623 |   1.9869 |     57.280 |     0.5
    2 |   1.7530 |     49.603 |   1.5528 |     46.344 |     1.0
    3 |   1.4798 |     45.955 |   1.4251 |     46.344 |     1.5
    4 |   1.4053 |     45.685 |   1.3808 |     45.601 |     2.0
    5 |   1.3575 |     44.814 |   1.3351 |     44.950 |     2.5
    6 |   1.3055 |     42.708 |   1.2962 |     43.247 |     3.0
    7 |   1.2584 |     41.033 |   1.2589 |     41.698 |     3.5
    8 |   1.2228 |     40.223 |   1.2303 |     41.605 |     4.0
    9 |   1.1908 |     39.005 |   1.2157 |     40.892 |     4.5
   10 |   1.1602 |     38.222 |   1.1872 |     39.653 |     5.0
   11 |   1.1363 |     37.627 |   1.1695 |     39.374 |     5.5
   12 |   1.1129 |     36.580 |   1.1678 |     39.498 |     6.0
   13 |   1.0937 |     36.111 |   1.1479 |     38.662 |     6.5
   14 |   1.0628 |     34.805 |   1.1191 |     37.144 |     7.1
   15 |   1.0298 |     33.796 |   1.1223 |     37.732 |     7.6
   16 |   1.0060 |     32.534 |   1.0884 |     35.905 |     8.1
   17 |   0.9761 |     31.537 |   1.0631 |     34.696 |     8.6
   18 |   0.9525 |     30.842 |   1.0414 |     34.139 |     9.1
   19 |   0.9369 |     30.297 |   1.0307 |     33.860 |     9.6
   20 |   0.9151 |     29.349 |   1.0189 |     33.519 |    10.1
   21 |   0.8883 |     28.687 |   1.0193 |     33.860 |    10.6
   22 |   0.8812 |     28.566 |   1.0106 |     33.055 |    11.1
   23 |   0.8635 |     27.734 |   0.9911 |     32.776 |    11.7
   24 |   0.8418 |     27.194 |   0.9830 |     31.320 |    12.2
   25 |   0.8211 |     26.483 |   0.9792 |     32.435 |    12.6
   26 |   0.8027 |     26.058 |   0.9881 |     31.970 |    13.1
   27 |   0.7911 |     25.860 |   0.9707 |     31.784 |    13.7
   28 |   0.7786 |     25.314 |   0.9627 |     31.568 |    14.2
   29 |   0.7474 |     24.223 |   0.9599 |     30.452 |    14.7
   30 |   0.7371 |     24.002 |   0.9502 |     30.112 |    15.2
   31 |   0.7286 |     23.705 |   0.9385 |     30.545 |    15.7
   32 |   0.6984 |     22.757 |   0.9381 |     29.368 |    16.2
   33 |   0.6889 |     22.349 |   0.9277 |     29.430 |    16.7
   34 |   0.6801 |     22.079 |   0.9284 |     29.647 |    17.2
   35 |   0.6593 |     21.153 |   0.9310 |     30.050 |    17.7
   36 |   0.6611 |     21.291 |   0.9303 |     29.368 |    18.2
   37 |   0.6457 |     21.032 |   0.9238 |     28.934 |    18.7
   38 |   0.6293 |     20.343 |   0.9311 |     29.492 |    19.2
   39 |   0.6178 |     20.045 |   0.9225 |     29.244 |    19.7
   40 |   0.6030 |     19.444 |   0.9268 |     28.934 |    20.2
   41 |   0.5945 |     19.301 |   0.9353 |     28.098 |    20.7
   42 |   0.5758 |     18.397 |   0.9254 |     28.408 |    21.2
   43 |   0.5833 |     19.119 |   0.9429 |     28.625 |    21.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,141,794

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5483 |     68.414 |   1.9824 |     59.851 |     0.5
    2 |   1.7614 |     50.336 |   1.5755 |     46.344 |     1.0
    3 |   1.5046 |     45.982 |   1.4600 |     47.119 |     1.5
    4 |   1.4324 |     46.076 |   1.4091 |     46.344 |     2.0
    5 |   1.4017 |     45.982 |   1.3929 |     46.344 |     2.5
    6 |   1.3815 |     45.910 |   1.3693 |     45.570 |     3.0
    7 |   1.3568 |     45.244 |   1.3495 |     45.229 |     3.5
    8 |   1.3339 |     45.161 |   1.3304 |     45.415 |     4.0
    9 |   1.3132 |     44.637 |   1.3078 |     44.548 |     4.6
   10 |   1.2943 |     44.246 |   1.2977 |     43.742 |     5.1
   11 |   1.2763 |     42.995 |   1.2864 |     43.587 |     5.6
   12 |   1.2509 |     42.014 |   1.2567 |     42.875 |     6.1
   13 |   1.2291 |     41.226 |   1.2502 |     42.410 |     6.6
   14 |   1.2134 |     40.713 |   1.2345 |     41.109 |     7.1
   15 |   1.1957 |     39.920 |   1.2241 |     41.543 |     7.6
   16 |   1.1762 |     39.616 |   1.2042 |     41.450 |     8.1
   17 |   1.1597 |     39.032 |   1.1881 |     40.489 |     8.6
   18 |   1.1462 |     38.553 |   1.1889 |     40.458 |     9.1
   19 |   1.1312 |     37.864 |   1.1834 |     39.622 |     9.6
   20 |   1.1130 |     37.219 |   1.1529 |     39.591 |    10.1
   21 |   1.0922 |     36.772 |   1.1479 |     38.569 |    10.6
   22 |   1.0801 |     36.249 |   1.1510 |     39.560 |    11.1
   23 |   1.0701 |     35.825 |   1.1311 |     38.538 |    11.6
   24 |   1.0511 |     35.505 |   1.1238 |     38.383 |    12.2
   25 |   1.0445 |     34.981 |   1.1080 |     37.670 |    12.7
   26 |   1.0339 |     34.408 |   1.1204 |     38.538 |    13.2
   27 |   1.0167 |     33.962 |   1.0991 |     37.670 |    13.7
   28 |   1.0126 |     33.802 |   1.1044 |     37.299 |    14.2
   29 |   1.0009 |     33.675 |   1.0824 |     37.639 |    14.7
   30 |   0.9753 |     32.611 |   1.0735 |     36.865 |    15.2
   31 |   0.9665 |     32.424 |   1.0788 |     36.121 |    15.7
   32 |   0.9584 |     31.955 |   1.0804 |     36.555 |    16.2
   33 |   0.9445 |     31.823 |   1.0671 |     35.037 |    16.8
   34 |   0.9269 |     31.063 |   1.0543 |     35.998 |    17.3
   35 |   0.9131 |     30.616 |   1.0556 |     34.758 |    17.8
   36 |   0.9023 |     29.795 |   1.0457 |     35.347 |    18.3
   37 |   0.8958 |     29.878 |   1.0497 |     34.603 |    18.8
   38 |   0.8835 |     29.679 |   1.0140 |     33.922 |    19.3
   39 |   0.8649 |     28.682 |   1.0260 |     33.736 |    19.8
   40 |   0.8668 |     28.593 |   1.0252 |     33.798 |    20.3
   41 |   0.8521 |     28.423 |   1.0176 |     33.488 |    20.8
   42 |   0.8912 |     29.663 |   1.0409 |     34.232 |    21.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 343,938

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6196 |     70.244 |   2.0292 |     59.851 |     0.0
    2 |   1.7900 |     49.829 |   1.5986 |     46.344 |     0.0
    3 |   1.5158 |     45.949 |   1.4624 |     46.344 |     0.0
    4 |   1.4354 |     45.960 |   1.4128 |     47.150 |     0.1
    5 |   1.3911 |     45.696 |   1.3717 |     46.097 |     0.1
    6 |   1.3480 |     45.040 |   1.3356 |     44.950 |     0.1
    7 |   1.3074 |     44.450 |   1.3151 |     44.796 |     0.1
    8 |   1.2729 |     43.331 |   1.2763 |     42.472 |     0.1
    9 |   1.2366 |     40.934 |   1.2443 |     41.822 |     0.1
   10 |   1.1929 |     39.842 |   1.2153 |     41.140 |     0.2
   11 |   1.1636 |     39.291 |   1.1914 |     40.458 |     0.2
   12 |   1.1275 |     38.007 |   1.1803 |     39.963 |     0.2
   13 |   1.1003 |     36.916 |   1.1571 |     39.095 |     0.2
   14 |   1.0660 |     35.610 |   1.1355 |     38.817 |     0.2
   15 |   1.0364 |     34.678 |   1.1214 |     38.507 |     0.2
   16 |   1.0054 |     33.422 |   1.0996 |     36.896 |     0.2
   17 |   0.9674 |     32.033 |   1.0839 |     37.020 |     0.3
   18 |   0.9414 |     31.178 |   1.0715 |     35.502 |     0.3
   19 |   0.9145 |     30.076 |   1.0628 |     34.665 |     0.3
   20 |   0.8926 |     29.156 |   1.0394 |     33.860 |     0.3
   21 |   0.8615 |     27.469 |   1.0454 |     33.953 |     0.3
   22 |   0.8389 |     26.946 |   1.0488 |     33.736 |     0.3
   23 |   0.8109 |     26.295 |   1.0519 |     33.055 |     0.4
   24 |   0.7905 |     25.303 |   1.0363 |     34.077 |     0.4
   25 |   0.7600 |     24.328 |   1.0265 |     32.590 |     0.4
   26 |   0.7429 |     23.716 |   1.0164 |     31.753 |     0.4
   27 |   0.7187 |     22.823 |   1.0068 |     31.537 |     0.4
   28 |   0.6856 |     21.886 |   1.0267 |     31.041 |     0.4
   29 |   0.6693 |     21.087 |   1.0211 |     31.072 |     0.4
   30 |   0.6525 |     20.332 |   1.0139 |     30.638 |     0.5
   31 |   0.6204 |     19.466 |   1.0273 |     30.452 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 335,426

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5722 |     68.452 |   1.9834 |     58.829 |     0.0
    2 |   1.7591 |     49.785 |   1.5794 |     46.344 |     0.0
    3 |   1.5026 |     46.004 |   1.4584 |     46.344 |     0.0
    4 |   1.4348 |     46.070 |   1.4227 |     46.252 |     0.1
    5 |   1.4038 |     45.977 |   1.3915 |     46.283 |     0.1
    6 |   1.3751 |     44.974 |   1.3704 |     45.291 |     0.1
    7 |   1.3421 |     43.888 |   1.3427 |     44.919 |     0.1
    8 |   1.3115 |     43.232 |   1.3174 |     43.959 |     0.1
    9 |   1.2835 |     42.284 |   1.2949 |     43.401 |     0.1
   10 |   1.2576 |     41.319 |   1.2749 |     42.844 |     0.2
   11 |   1.2335 |     40.487 |   1.2716 |     42.782 |     0.2
   12 |   1.2113 |     39.914 |   1.2392 |     41.729 |     0.2
   13 |   1.1869 |     39.412 |   1.2260 |     41.543 |     0.2
   14 |   1.1620 |     38.630 |   1.2109 |     40.954 |     0.2
   15 |   1.1400 |     38.161 |   1.2028 |     40.706 |     0.2
   16 |   1.1247 |     37.963 |   1.2020 |     41.357 |     0.3
   17 |   1.1038 |     37.197 |   1.1828 |     39.529 |     0.3
   18 |   1.0757 |     36.326 |   1.1729 |     39.188 |     0.3
   19 |   1.0562 |     35.830 |   1.1507 |     38.321 |     0.3
   20 |   1.0279 |     34.799 |   1.1575 |     38.104 |     0.3
   21 |   1.0063 |     33.642 |   1.1518 |     37.701 |     0.3
   22 |   0.9855 |     32.870 |   1.1339 |     37.268 |     0.3
   23 |   0.9609 |     31.680 |   1.1351 |     37.144 |     0.4
   24 |   0.9485 |     31.625 |   1.1145 |     35.998 |     0.4
   25 |   0.9136 |     30.142 |   1.1216 |     35.936 |     0.4
   26 |   0.8945 |     29.503 |   1.1035 |     35.967 |     0.4
   27 |   0.8691 |     28.417 |   1.0908 |     35.471 |     0.4
   28 |   0.8488 |     27.596 |   1.0936 |     35.192 |     0.4
   29 |   0.8294 |     27.199 |   1.1028 |     35.781 |     0.5
   30 |   0.8091 |     26.246 |   1.0933 |     35.223 |     0.5
   31 |   0.7833 |     25.298 |   1.0911 |     35.006 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 709,986

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5907 |     69.516 |   2.0210 |     59.851 |     0.0
    2 |   1.8007 |     51.135 |   1.6128 |     49.442 |     0.0
    3 |   1.5201 |     46.054 |   1.4681 |     46.344 |     0.1
    4 |   1.4389 |     45.966 |   1.4280 |     47.150 |     0.1
    5 |   1.4156 |     46.021 |   1.4114 |     46.344 |     0.1
    6 |   1.4027 |     45.944 |   1.4059 |     47.150 |     0.1
    7 |   1.3961 |     46.037 |   1.3979 |     46.344 |     0.2
    8 |   1.3921 |     46.048 |   1.3912 |     46.344 |     0.2
    9 |   1.3872 |     45.888 |   1.3843 |     47.119 |     0.2
   10 |   1.3759 |     45.988 |   1.3730 |     46.344 |     0.2
   11 |   1.3540 |     45.541 |   1.3455 |     45.105 |     0.3
   12 |   1.3313 |     45.117 |   1.3299 |     45.322 |     0.3
   13 |   1.3166 |     44.902 |   1.3149 |     44.765 |     0.3
   14 |   1.3025 |     44.610 |   1.3054 |     44.517 |     0.3
   15 |   1.2856 |     44.207 |   1.2986 |     44.176 |     0.4
   16 |   1.2686 |     43.204 |   1.2719 |     43.990 |     0.4
   17 |   1.2476 |     42.466 |   1.2544 |     43.247 |     0.4
   18 |   1.2235 |     41.435 |   1.2365 |     41.945 |     0.4
   19 |   1.2065 |     40.619 |   1.2230 |     41.388 |     0.5
   20 |   1.1899 |     40.360 |   1.2269 |     42.038 |     0.5
   21 |   1.1787 |     39.859 |   1.1956 |     41.388 |     0.5
   22 |   1.1638 |     39.644 |   1.1912 |     40.675 |     0.5
   23 |   1.1448 |     39.164 |   1.1853 |     40.892 |     0.6
   24 |   1.1278 |     38.437 |   1.1660 |     40.025 |     0.6
   25 |   1.1150 |     37.809 |   1.1635 |     39.808 |     0.6
   26 |   1.0968 |     37.076 |   1.1542 |     39.405 |     0.6
   27 |   1.0896 |     37.092 |   1.1493 |     38.910 |     0.7
   28 |   1.0715 |     36.150 |   1.1498 |     38.693 |     0.7
   29 |   1.0580 |     35.874 |   1.1455 |     39.188 |     0.7
   30 |   1.0429 |     35.169 |   1.1161 |     37.701 |     0.7
   31 |   1.0332 |     35.042 |   1.1214 |     38.197 |     0.8
   32 |   1.0175 |     34.055 |   1.1166 |     37.825 |     0.8
   33 |   1.0046 |     33.940 |   1.1157 |     37.237 |     0.8
   34 |   0.9965 |     33.344 |   1.0981 |     36.958 |     0.8
   35 |   0.9798 |     33.063 |   1.0855 |     36.710 |     0.9
   36 |   0.9642 |     32.407 |   1.0898 |     36.865 |     0.9
   37 |   0.9431 |     31.636 |   1.0922 |     36.741 |     0.9
   38 |   0.9408 |     31.878 |   1.0895 |     35.409 |     0.9
   39 |   0.9281 |     31.509 |   1.0805 |     35.378 |     1.0
   40 |   0.9210 |     30.903 |   1.0678 |     34.696 |     1.0
   41 |   0.9057 |     30.412 |   1.0860 |     36.772 |     1.0
   42 |   0.8987 |     29.988 |   1.0686 |     35.223 |     1.0
   43 |   0.8836 |     29.751 |   1.0624 |     34.882 |     1.1
   44 |   0.8629 |     28.709 |   1.0777 |     34.944 |     1.1
   45 |   0.8609 |     28.897 |   1.0549 |     34.356 |     1.1
   46 |   0.8476 |     28.533 |   1.0659 |     35.099 |     1.1
   47 |   0.8373 |     27.960 |   1.0428 |     33.674 |     1.2
   48 |   0.8257 |     27.706 |   1.0530 |     33.860 |     1.2
   49 |   0.8226 |     27.315 |   1.0630 |     34.139 |     1.2
   50 |   0.8193 |     27.431 |   1.0497 |     34.387 |     1.2
   51 |   0.7962 |     26.698 |   1.0445 |     33.612 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,141,794

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4947 |     65.906 |   1.9355 |     59.108 |     0.5
    2 |   1.7186 |     49.002 |   1.5419 |     46.344 |     1.0
    3 |   1.4863 |     45.949 |   1.4471 |     46.344 |     1.5
    4 |   1.4271 |     46.032 |   1.4134 |     46.344 |     2.0
    5 |   1.4051 |     45.944 |   1.4028 |     47.150 |     2.5
    6 |   1.3960 |     46.219 |   1.3919 |     46.344 |     3.0
    7 |   1.3862 |     45.916 |   1.3864 |     47.150 |     3.5
    8 |   1.3824 |     46.015 |   1.3762 |     46.344 |     4.0
    9 |   1.3655 |     45.745 |   1.3677 |     45.973 |     4.5
   10 |   1.3475 |     45.012 |   1.3408 |     44.734 |     5.0
   11 |   1.3275 |     44.235 |   1.3288 |     44.486 |     5.6
   12 |   1.3040 |     43.519 |   1.3126 |     44.919 |     6.0
   13 |   1.2886 |     43.188 |   1.2946 |     43.680 |     6.6
   14 |   1.2671 |     42.477 |   1.2818 |     43.742 |     7.0
   15 |   1.2533 |     42.025 |   1.2671 |     43.340 |     7.6
   16 |   1.2374 |     41.457 |   1.2550 |     42.286 |     8.1
   17 |   1.2271 |     41.176 |   1.2451 |     42.038 |     8.6
   18 |   1.2107 |     40.724 |   1.2318 |     42.348 |     9.1
   19 |   1.1959 |     40.201 |   1.2265 |     41.729 |     9.6
   20 |   1.1835 |     39.732 |   1.2187 |     41.822 |    10.1
   21 |   1.1685 |     39.412 |   1.1984 |     41.295 |    10.6
   22 |   1.1518 |     38.983 |   1.1882 |     40.830 |    11.1
   23 |   1.1327 |     38.332 |   1.1824 |     41.047 |    11.6
   24 |   1.1182 |     37.897 |   1.1685 |     40.304 |    12.1
   25 |   1.1015 |     37.577 |   1.1634 |     39.870 |    12.6
   26 |   1.0902 |     37.098 |   1.1699 |     40.706 |    13.1
   27 |   1.0729 |     36.552 |   1.1441 |     40.087 |    13.6
   28 |   1.0534 |     35.648 |   1.1360 |     39.188 |    14.2
   29 |   1.0443 |     35.373 |   1.1328 |     37.887 |    14.7
   30 |   1.0276 |     34.397 |   1.1284 |     38.073 |    15.2
   31 |   1.0171 |     34.232 |   1.1259 |     38.197 |    15.7
   32 |   1.0076 |     33.813 |   1.1129 |     37.608 |    16.2
   33 |   0.9885 |     33.311 |   1.1082 |     36.865 |    16.7
   34 |   0.9681 |     32.457 |   1.0978 |     36.710 |    17.2
   35 |   0.9615 |     31.994 |   1.1011 |     36.059 |    17.7
   36 |   0.9508 |     31.779 |   1.0851 |     35.750 |    18.2
   37 |   0.9324 |     31.355 |   1.0711 |     35.936 |    18.7
   38 |   0.9159 |     30.572 |   1.0756 |     35.626 |    19.2
   39 |   0.9112 |     30.721 |   1.0606 |     35.812 |    19.7
   40 |   0.8941 |     29.773 |   1.0575 |     35.347 |    20.2
   41 |   0.8769 |     29.172 |   1.0503 |     35.130 |    20.8
   42 |   0.8683 |     29.117 |   1.0443 |     34.975 |    21.3
   43 |   0.8568 |     28.070 |   1.0384 |     34.170 |    21.8
   44 |   0.8409 |     27.767 |   1.0435 |     34.572 |    22.3
   45 |   0.8337 |     27.431 |   1.0496 |     34.449 |    22.8
   46 |   0.8157 |     27.083 |   1.0565 |     34.511 |    23.3
   47 |   0.8128 |     26.890 |   1.0454 |     34.480 |    23.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 501,730

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6166 |     69.428 |   2.0190 |     59.851 |     0.0
    2 |   1.7902 |     51.290 |   1.5812 |     46.344 |     0.0
    3 |   1.5034 |     46.098 |   1.4537 |     47.150 |     0.0
    4 |   1.4299 |     46.015 |   1.4112 |     46.344 |     0.1
    5 |   1.3959 |     45.894 |   1.3774 |     46.344 |     0.1
    6 |   1.3683 |     45.381 |   1.3556 |     45.074 |     0.1
    7 |   1.3427 |     44.935 |   1.3400 |     45.043 |     0.1
    8 |   1.3184 |     44.665 |   1.3160 |     44.703 |     0.1
    9 |   1.2975 |     44.450 |   1.3020 |     44.300 |     0.1
   10 |   1.2812 |     43.673 |   1.2963 |     44.114 |     0.2
   11 |   1.2649 |     43.530 |   1.2783 |     43.649 |     0.2
   12 |   1.2526 |     42.819 |   1.2693 |     43.154 |     0.2
   13 |   1.2311 |     42.113 |   1.2585 |     42.937 |     0.2
   14 |   1.2158 |     40.956 |   1.2427 |     42.379 |     0.2
   15 |   1.2005 |     40.245 |   1.2246 |     40.892 |     0.2
   16 |   1.1802 |     39.346 |   1.2079 |     40.861 |     0.3
   17 |   1.1542 |     38.542 |   1.1968 |     40.397 |     0.3
   18 |   1.1343 |     38.139 |   1.1760 |     40.025 |     0.3
   19 |   1.1195 |     37.428 |   1.1665 |     39.405 |     0.3
   20 |   1.0987 |     36.591 |   1.1554 |     38.786 |     0.3
   21 |   1.0811 |     36.221 |   1.1384 |     38.538 |     0.3
   22 |   1.0739 |     35.676 |   1.1478 |     38.166 |     0.4
   23 |   1.0668 |     35.747 |   1.1438 |     38.414 |     0.4
   24 |   1.0529 |     35.461 |   1.1238 |     37.670 |     0.4
   25 |   1.0328 |     34.419 |   1.1251 |     37.268 |     0.4
   26 |   1.0187 |     34.132 |   1.1373 |     37.949 |     0.4
   27 |   1.0143 |     34.144 |   1.1188 |     37.670 |     0.4
   28 |   0.9960 |     33.444 |   1.1081 |     36.152 |     0.5
   29 |   0.9851 |     32.898 |   1.0962 |     36.121 |     0.5
   30 |   0.9664 |     32.617 |   1.0924 |     35.564 |     0.5
   31 |   0.9587 |     32.170 |   1.1033 |     35.905 |     0.5
   32 |   0.9538 |     32.132 |   1.0855 |     35.533 |     0.5
   33 |   0.9375 |     31.592 |   1.0910 |     35.471 |     0.5
   34 |   0.9247 |     30.765 |   1.0973 |     36.029 |     0.6
   35 |   0.9157 |     30.561 |   1.0803 |     35.161 |     0.6
   36 |   0.9081 |     30.511 |   1.0780 |     34.449 |     0.6
   37 |   0.8882 |     29.415 |   1.0741 |     34.418 |     0.6
   38 |   0.8890 |     29.674 |   1.0642 |     34.108 |     0.6
   39 |   0.8823 |     29.266 |   1.0528 |     34.139 |     0.6
   40 |   0.8670 |     28.560 |   1.0658 |     33.953 |     0.7
   41 |   0.8569 |     28.467 |   1.0594 |     33.891 |     0.7
   42 |   0.8498 |     28.301 |   1.0539 |     33.643 |     0.7
   43 |   0.8339 |     27.287 |   1.0422 |     33.178 |     0.7
   44 |   0.8253 |     27.221 |   1.0495 |     33.024 |     0.7
   45 |   0.8217 |     27.409 |   1.0476 |     32.869 |     0.7
   46 |   0.8065 |     26.764 |   1.0379 |     32.342 |     0.8
   47 |   0.7956 |     26.725 |   1.0505 |     32.590 |     0.8
   48 |   0.7998 |     26.422 |   1.0403 |     32.590 |     0.8
   49 |   0.7861 |     26.064 |   1.0410 |     32.931 |     0.8
   50 |   0.7669 |     25.502 |   1.0513 |     32.993 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 643,426

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4698 |     66.016 |   1.9724 |     54.988 |     0.0
    2 |   1.7560 |     49.994 |   1.5704 |     46.344 |     0.1
    3 |   1.4965 |     45.938 |   1.4495 |     45.911 |     0.1
    4 |   1.4153 |     45.365 |   1.3960 |     45.942 |     0.1
    5 |   1.3709 |     44.395 |   1.3639 |     43.959 |     0.1
    6 |   1.3355 |     43.623 |   1.3281 |     44.517 |     0.2
    7 |   1.3019 |     42.433 |   1.2973 |     43.432 |     0.2
    8 |   1.2655 |     41.060 |   1.2673 |     42.627 |     0.2
    9 |   1.2336 |     40.090 |   1.2459 |     41.326 |     0.2
   10 |   1.2063 |     39.512 |   1.2148 |     40.737 |     0.3
   11 |   1.1751 |     38.834 |   1.2018 |     39.994 |     0.3
   12 |   1.1487 |     37.787 |   1.1800 |     39.963 |     0.3
   13 |   1.1200 |     37.384 |   1.1667 |     38.848 |     0.3
   14 |   1.0950 |     36.332 |   1.1369 |     37.763 |     0.4
   15 |   1.0643 |     35.543 |   1.1205 |     37.423 |     0.4
   16 |   1.0428 |     34.309 |   1.1137 |     36.276 |     0.4
   17 |   1.0185 |     33.592 |   1.0895 |     36.369 |     0.4
   18 |   0.9896 |     32.330 |   1.0825 |     35.347 |     0.5
   19 |   0.9643 |     31.250 |   1.0726 |     35.192 |     0.5
   20 |   0.9345 |     30.390 |   1.0516 |     34.232 |     0.5
   21 |   0.9106 |     29.056 |   1.0472 |     33.674 |     0.5
   22 |   0.8969 |     28.693 |   1.0274 |     33.395 |     0.6
   23 |   0.8720 |     27.579 |   1.0187 |     32.590 |     0.6
   24 |   0.8509 |     27.425 |   1.0238 |     32.621 |     0.6
   25 |   0.8162 |     25.992 |   1.0033 |     31.382 |     0.6
   26 |   0.7987 |     25.568 |   0.9984 |     31.103 |     0.7
   27 |   0.7728 |     24.587 |   0.9903 |     30.669 |     0.7
   28 |   0.7559 |     24.013 |   0.9876 |     31.475 |     0.7
   29 |   0.7408 |     23.611 |   0.9863 |     31.351 |     0.7
   30 |   0.7217 |     23.247 |   0.9592 |     29.926 |     0.8
   31 |   0.7036 |     22.002 |   0.9547 |     30.545 |     0.8
   32 |   0.6738 |     21.473 |   0.9487 |     30.452 |     0.8
   33 |   0.6706 |     21.418 |   0.9465 |     28.594 |     0.8
   34 |   0.6498 |     20.685 |   0.9429 |     28.965 |     0.9
   35 |   0.6249 |     19.918 |   0.9504 |     29.895 |     0.9
   36 |   0.6248 |     20.139 |   0.9639 |     29.461 |     0.9
   37 |   0.6083 |     19.274 |   0.9511 |     28.470 |     0.9
   38 |   0.5876 |     18.733 |   0.9861 |     29.926 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,207,778

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2805 |     62.213 |   1.6515 |     46.716 |     0.0
    2 |   1.4890 |     46.048 |   1.4232 |     46.190 |     0.1
    3 |   1.4092 |     45.922 |   1.4010 |     46.314 |     0.1
    4 |   1.3861 |     45.425 |   1.3843 |     45.911 |     0.2
    5 |   1.3546 |     44.329 |   1.3461 |     45.291 |     0.2
    6 |   1.3293 |     43.816 |   1.3292 |     44.981 |     0.2
    7 |   1.3076 |     42.945 |   1.3159 |     44.424 |     0.3
    8 |   1.2854 |     42.449 |   1.2944 |     43.835 |     0.3
    9 |   1.2701 |     42.411 |   1.2861 |     43.525 |     0.4
   10 |   1.2528 |     41.612 |   1.2729 |     43.525 |     0.4
   11 |   1.2333 |     41.204 |   1.2514 |     41.760 |     0.5
   12 |   1.2112 |     40.195 |   1.2383 |     41.016 |     0.5
   13 |   1.1902 |     39.523 |   1.2261 |     40.923 |     0.5
   14 |   1.1669 |     39.093 |   1.2027 |     40.242 |     0.6
   15 |   1.1345 |     38.139 |   1.1758 |     39.126 |     0.6
   16 |   1.1024 |     37.026 |   1.1584 |     38.724 |     0.7
   17 |   1.0764 |     36.310 |   1.1634 |     39.467 |     0.7
   18 |   1.0463 |     35.069 |   1.1266 |     37.423 |     0.7
   19 |   1.0195 |     34.281 |   1.1057 |     36.617 |     0.8
   20 |   0.9873 |     32.903 |   1.0923 |     36.431 |     0.8
   21 |   0.9695 |     32.336 |   1.0730 |     35.874 |     0.9
   22 |   0.9444 |     31.443 |   1.0682 |     35.254 |     0.9
   23 |   0.9147 |     30.280 |   1.0678 |     34.851 |     0.9
   24 |   0.8894 |     29.530 |   1.0542 |     34.325 |     1.0
   25 |   0.8635 |     28.682 |   1.0410 |     34.387 |     1.0
   26 |   0.8344 |     27.739 |   1.0162 |     32.714 |     1.1
   27 |   0.8221 |     27.105 |   1.0293 |     33.055 |     1.1
   28 |   0.7901 |     26.020 |   1.0195 |     32.621 |     1.2
   29 |   0.7636 |     25.226 |   1.0234 |     32.807 |     1.2
   30 |   0.7461 |     24.515 |   1.0205 |     33.209 |     1.2
   31 |   0.7291 |     24.030 |   0.9887 |     31.444 |     1.3
   32 |   0.7031 |     23.148 |   0.9926 |     31.691 |     1.3
   33 |   0.6926 |     22.823 |   0.9902 |     30.886 |     1.4
   34 |   0.6723 |     22.007 |   0.9821 |     30.824 |     1.4
   35 |   0.6438 |     20.916 |   0.9756 |     30.235 |     1.4
   36 |   0.6333 |     20.773 |   0.9624 |     30.576 |     1.5
   37 |   0.6076 |     19.869 |   0.9948 |     31.134 |     1.5
   38 |   0.5960 |     19.990 |   0.9853 |     30.266 |     1.6
   39 |   0.5711 |     18.855 |   0.9864 |     29.523 |     1.6
   40 |   0.5459 |     17.901 |   0.9840 |     29.895 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 606,146

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2785 |     61.839 |   1.6653 |     49.473 |     0.0
    2 |   1.5006 |     45.999 |   1.4163 |     46.344 |     0.1
    3 |   1.3811 |     45.034 |   1.3701 |     45.291 |     0.1
    4 |   1.3137 |     42.934 |   1.3022 |     43.247 |     0.1
    5 |   1.2604 |     41.733 |   1.2506 |     41.853 |     0.1
    6 |   1.2108 |     40.388 |   1.2363 |     40.954 |     0.2
    7 |   1.1736 |     39.313 |   1.2047 |     40.861 |     0.2
    8 |   1.1321 |     38.205 |   1.1815 |     40.180 |     0.2
    9 |   1.0985 |     37.257 |   1.1419 |     39.126 |     0.2
   10 |   1.0521 |     35.588 |   1.1345 |     39.095 |     0.3
   11 |   1.0127 |     33.956 |   1.1073 |     36.741 |     0.3
   12 |   0.9620 |     32.088 |   1.0832 |     36.152 |     0.3
   13 |   0.9164 |     30.043 |   1.0604 |     34.789 |     0.3
   14 |   0.8641 |     28.114 |   1.0335 |     33.209 |     0.4
   15 |   0.8224 |     26.565 |   1.0157 |     32.900 |     0.4
   16 |   0.7772 |     25.237 |   1.0042 |     32.745 |     0.4
   17 |   0.7252 |     23.049 |   0.9806 |     31.010 |     0.4
   18 |   0.6825 |     21.555 |   0.9792 |     30.328 |     0.5
   19 |   0.6403 |     20.381 |   0.9970 |     30.514 |     0.5
   20 |   0.6010 |     19.108 |   0.9800 |     29.399 |     0.5
   21 |   0.5591 |     17.780 |   0.9982 |     30.483 |     0.5
   22 |   0.5257 |     16.689 |   0.9878 |     29.461 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 426,018

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0322 |     54.933 |   1.4426 |     46.035 |     0.0
    2 |   1.3658 |     44.990 |   1.3172 |     44.548 |     0.0
    3 |   1.2685 |     41.854 |   1.2413 |     41.357 |     0.1
    4 |   1.1833 |     39.021 |   1.1822 |     40.335 |     0.1
    5 |   1.1148 |     36.822 |   1.1404 |     38.259 |     0.1
    6 |   1.0517 |     34.854 |   1.0711 |     35.936 |     0.1
    7 |   0.9884 |     32.292 |   1.0441 |     35.068 |     0.1
    8 |   0.9280 |     30.131 |   0.9950 |     32.621 |     0.1
    9 |   0.8653 |     27.789 |   0.9781 |     32.001 |     0.2
   10 |   0.8141 |     25.920 |   0.9375 |     30.731 |     0.2
   11 |   0.7570 |     23.732 |   0.9090 |     29.492 |     0.2
   12 |   0.7102 |     22.371 |   0.8833 |     27.447 |     0.2
   13 |   0.6617 |     20.905 |   0.8793 |     27.230 |     0.2
   14 |   0.6275 |     19.665 |   0.8600 |     26.828 |     0.3
   15 |   0.5865 |     18.496 |   0.8449 |     25.836 |     0.3
   16 |   0.5462 |     17.003 |   0.8655 |     26.549 |     0.3
   17 |   0.5177 |     16.149 |   0.8636 |     25.558 |     0.3
   18 |   0.4877 |     15.190 |   0.8297 |     24.257 |     0.3
   19 |   0.4585 |     14.098 |   0.8438 |     24.380 |     0.3
   20 |   0.4355 |     13.547 |   0.8435 |     24.690 |     0.4
   21 |   0.4176 |     12.957 |   0.8460 |     24.133 |     0.4
   22 |   0.3909 |     11.993 |   0.8506 |     23.823 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 842,722

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5175 |     66.838 |   2.0051 |     57.962 |     0.0
    2 |   1.7603 |     49.757 |   1.5649 |     46.344 |     0.1
    3 |   1.4852 |     45.773 |   1.4389 |     46.190 |     0.1
    4 |   1.4044 |     45.260 |   1.3884 |     45.601 |     0.1
    5 |   1.3599 |     43.954 |   1.3508 |     44.703 |     0.2
    6 |   1.3232 |     43.276 |   1.3249 |     43.866 |     0.2
    7 |   1.2904 |     42.510 |   1.3000 |     43.742 |     0.2
    8 |   1.2606 |     41.270 |   1.2728 |     42.565 |     0.3
    9 |   1.2285 |     40.173 |   1.2573 |     42.441 |     0.3
   10 |   1.2007 |     39.407 |   1.2395 |     41.667 |     0.3
   11 |   1.1679 |     38.564 |   1.2251 |     41.326 |     0.4
   12 |   1.1526 |     38.068 |   1.1991 |     40.304 |     0.4
   13 |   1.1185 |     37.009 |   1.1678 |     39.157 |     0.4
   14 |   1.0831 |     35.483 |   1.1386 |     37.701 |     0.5
   15 |   1.0535 |     34.706 |   1.1351 |     37.825 |     0.5
   16 |   1.0345 |     34.336 |   1.1144 |     36.834 |     0.5
   17 |   1.0046 |     32.755 |   1.0934 |     36.121 |     0.6
   18 |   0.9760 |     32.049 |   1.0900 |     36.307 |     0.6
   19 |   0.9548 |     31.167 |   1.0745 |     35.316 |     0.6
   20 |   0.9327 |     30.236 |   1.0752 |     35.037 |     0.7
   21 |   0.9164 |     30.208 |   1.0681 |     34.944 |     0.7
   22 |   0.8956 |     29.310 |   1.0480 |     35.130 |     0.7
   23 |   0.8731 |     28.368 |   1.0466 |     33.798 |     0.7
   24 |   0.8623 |     28.136 |   1.0359 |     33.829 |     0.8
   25 |   0.8431 |     27.574 |   1.0269 |     33.209 |     0.8
   26 |   0.8308 |     27.050 |   1.0240 |     32.993 |     0.8
   27 |   0.8061 |     26.257 |   1.0173 |     33.271 |     0.9
   28 |   0.7834 |     25.739 |   1.0145 |     32.962 |     0.9
   29 |   0.7639 |     24.923 |   0.9860 |     30.886 |     0.9
   30 |   0.7519 |     24.719 |   0.9929 |     31.722 |     1.0
   31 |   0.7319 |     24.002 |   0.9943 |     31.165 |     1.0
   32 |   0.7254 |     23.688 |   0.9918 |     31.506 |     1.0
   33 |   0.6999 |     22.757 |   0.9959 |     31.599 |     1.1
   34 |   0.6924 |     22.525 |   0.9856 |     30.638 |     1.1
   35 |   0.6797 |     22.140 |   0.9859 |     31.010 |     1.1
   36 |   0.6617 |     21.550 |   0.9913 |     30.638 |     1.2
   37 |   0.6612 |     21.627 |   0.9885 |     31.382 |     1.2
   38 |   0.6417 |     20.828 |   0.9707 |     30.266 |     1.2
   39 |   0.6246 |     20.084 |   0.9781 |     30.204 |     1.3
   40 |   0.6072 |     19.632 |   0.9672 |     30.235 |     1.3
   41 |   0.6030 |     19.505 |   0.9739 |     29.554 |     1.3
   42 |   0.5977 |     19.384 |   0.9815 |     29.306 |     1.4
   43 |   0.5910 |     19.125 |   0.9733 |     29.399 |     1.4
   44 |   0.5814 |     19.031 |   0.9988 |     30.081 |     1.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 255,202

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3809 |     60.962 |   1.7263 |     49.380 |     0.0
    2 |   1.5322 |     46.627 |   1.4195 |     46.004 |     0.0
    3 |   1.3764 |     45.244 |   1.3424 |     44.393 |     0.0
    4 |   1.3105 |     43.645 |   1.2905 |     43.309 |     0.1
    5 |   1.2596 |     41.843 |   1.2457 |     40.520 |     0.1
    6 |   1.2087 |     39.462 |   1.2053 |     40.613 |     0.1
    7 |   1.1627 |     38.046 |   1.1765 |     39.467 |     0.1
    8 |   1.1153 |     36.905 |   1.1443 |     38.879 |     0.1
    9 |   1.0714 |     35.207 |   1.1021 |     37.856 |     0.1
   10 |   1.0322 |     34.298 |   1.0864 |     37.020 |     0.1
   11 |   0.9928 |     32.418 |   1.0586 |     36.059 |     0.1
   12 |   0.9593 |     31.151 |   1.0332 |     34.944 |     0.2
   13 |   0.9208 |     29.591 |   1.0045 |     33.519 |     0.2
   14 |   0.8917 |     28.682 |   0.9826 |     32.435 |     0.2
   15 |   0.8583 |     27.205 |   0.9529 |     30.948 |     0.2
   16 |   0.8164 |     25.959 |   0.9491 |     30.917 |     0.2
   17 |   0.7927 |     25.331 |   0.9185 |     29.678 |     0.2
   18 |   0.7628 |     24.140 |   0.9146 |     29.678 |     0.2
   19 |   0.7383 |     23.462 |   0.9069 |     29.213 |     0.3
   20 |   0.7215 |     22.895 |   0.8911 |     28.532 |     0.3
   21 |   0.6957 |     22.206 |   0.8920 |     29.027 |     0.3
   22 |   0.6712 |     21.076 |   0.8756 |     28.160 |     0.3
   23 |   0.6500 |     20.216 |   0.8695 |     27.447 |     0.3
   24 |   0.6308 |     19.841 |   0.8627 |     26.766 |     0.3
   25 |   0.6097 |     19.246 |   0.8507 |     26.580 |     0.3
   26 |   0.5854 |     18.243 |   0.8702 |     27.323 |     0.4
   27 |   0.5756 |     17.940 |   0.8688 |     26.673 |     0.4
   28 |   0.5632 |     17.626 |   0.8511 |     26.487 |     0.4
   29 |   0.5502 |     17.405 |   0.8659 |     26.363 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,243,490

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2778 |     61.624 |   1.6736 |     49.442 |     0.0
    2 |   1.5033 |     46.098 |   1.4283 |     46.344 |     0.1
    3 |   1.4097 |     46.092 |   1.4016 |     47.150 |     0.1
    4 |   1.3787 |     45.277 |   1.3687 |     45.415 |     0.2
    5 |   1.3431 |     44.235 |   1.3465 |     45.136 |     0.2
    6 |   1.3324 |     44.235 |   1.3357 |     44.765 |     0.2
    7 |   1.3127 |     43.574 |   1.3210 |     44.362 |     0.3
    8 |   1.2995 |     43.166 |   1.3193 |     44.672 |     0.3
    9 |   1.2843 |     42.752 |   1.3003 |     43.928 |     0.4
   10 |   1.2659 |     42.119 |   1.2859 |     44.114 |     0.4
   11 |   1.2537 |     42.091 |   1.2646 |     43.154 |     0.5
   12 |   1.2372 |     41.264 |   1.2661 |     42.937 |     0.5
   13 |   1.2238 |     40.923 |   1.2419 |     41.791 |     0.5
   14 |   1.2039 |     40.112 |   1.2381 |     42.162 |     0.6
   15 |   1.1828 |     39.484 |   1.2310 |     41.822 |     0.6
   16 |   1.1634 |     39.242 |   1.2149 |     41.264 |     0.7
   17 |   1.1416 |     37.968 |   1.1897 |     39.746 |     0.7
   18 |   1.1248 |     37.820 |   1.1903 |     40.335 |     0.7
   19 |   1.0976 |     36.844 |   1.1765 |     39.901 |     0.8
   20 |   1.0823 |     36.194 |   1.1668 |     39.064 |     0.8
   21 |   1.0632 |     35.615 |   1.1550 |     38.321 |     0.9
   22 |   1.0358 |     34.695 |   1.1480 |     37.485 |     0.9
   23 |   1.0173 |     34.017 |   1.1526 |     38.042 |     1.0
   24 |   1.0016 |     33.295 |   1.1289 |     36.307 |     1.0
   25 |   0.9825 |     32.518 |   1.1361 |     37.454 |     1.0
   26 |   0.9695 |     32.385 |   1.1251 |     36.927 |     1.1
   27 |   0.9437 |     31.498 |   1.1184 |     36.493 |     1.1
   28 |   0.9270 |     31.151 |   1.0929 |     35.688 |     1.2
   29 |   0.9015 |     30.319 |   1.1229 |     36.772 |     1.2
   30 |   0.8790 |     28.979 |   1.0979 |     35.037 |     1.2
   31 |   0.8492 |     28.125 |   1.0952 |     35.254 |     1.3
   32 |   0.8303 |     27.662 |   1.0988 |     34.665 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 700,834

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2274 |     60.064 |   1.6172 |     46.623 |     0.0
    2 |   1.4780 |     46.026 |   1.4149 |     46.221 |     0.1
    3 |   1.3959 |     46.081 |   1.3709 |     45.849 |     0.1
    4 |   1.3372 |     43.871 |   1.3094 |     43.928 |     0.1
    5 |   1.2820 |     42.273 |   1.2802 |     42.441 |     0.2
    6 |   1.2447 |     40.879 |   1.2509 |     42.224 |     0.2
    7 |   1.2057 |     39.925 |   1.2244 |     41.295 |     0.2
    8 |   1.1693 |     39.561 |   1.1935 |     40.675 |     0.2
    9 |   1.1238 |     37.842 |   1.1677 |     39.560 |     0.3
   10 |   1.0819 |     36.701 |   1.1339 |     38.693 |     0.3
   11 |   1.0468 |     35.058 |   1.1078 |     37.175 |     0.3
   12 |   1.0037 |     33.763 |   1.0899 |     36.245 |     0.4
   13 |   0.9593 |     31.911 |   1.0659 |     34.665 |     0.4
   14 |   0.9205 |     30.363 |   1.0775 |     34.603 |     0.4
   15 |   0.8745 |     28.924 |   1.0384 |     33.798 |     0.4
   16 |   0.8346 |     27.745 |   1.0274 |     32.838 |     0.5
   17 |   0.7947 |     26.317 |   1.0298 |     32.652 |     0.5
   18 |   0.7489 |     24.179 |   0.9906 |     30.979 |     0.5
   19 |   0.6962 |     22.382 |   0.9876 |     30.483 |     0.6
   20 |   0.6528 |     20.778 |   0.9916 |     30.112 |     0.6
   21 |   0.6136 |     19.621 |   1.0042 |     30.917 |     0.6
   22 |   0.5796 |     18.353 |   0.9811 |     29.182 |     0.7
   23 |   0.5446 |     17.328 |   1.0001 |     29.027 |     0.7
   24 |   0.5183 |     16.397 |   0.9628 |     28.005 |     0.7
   25 |   0.4729 |     14.897 |   0.9759 |     28.067 |     0.7
   26 |   0.4482 |     13.933 |   0.9697 |     27.540 |     0.8
   27 |   0.4199 |     13.205 |   1.0068 |     27.602 |     0.8
   28 |   0.4003 |     12.511 |   0.9910 |     27.416 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 523,170

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2725 |     62.054 |   1.6347 |     49.442 |     0.0
    2 |   1.4877 |     46.274 |   1.4171 |     46.375 |     0.0
    3 |   1.3913 |     45.944 |   1.3747 |     46.406 |     0.1
    4 |   1.3393 |     44.615 |   1.3261 |     45.260 |     0.1
    5 |   1.2826 |     42.802 |   1.2816 |     43.587 |     0.1
    6 |   1.2415 |     41.099 |   1.2642 |     42.689 |     0.1
    7 |   1.2081 |     40.041 |   1.2457 |     42.007 |     0.2
    8 |   1.1733 |     38.927 |   1.1962 |     40.489 |     0.2
    9 |   1.1262 |     37.632 |   1.1674 |     39.343 |     0.2
   10 |   1.0935 |     36.734 |   1.1475 |     39.250 |     0.2
   11 |   1.0547 |     35.086 |   1.1166 |     36.555 |     0.2
   12 |   1.0085 |     33.256 |   1.1074 |     36.462 |     0.3
   13 |   0.9755 |     32.562 |   1.0853 |     35.812 |     0.3
   14 |   0.9271 |     30.958 |   1.0672 |     35.316 |     0.3
   15 |   0.8921 |     29.442 |   1.0352 |     33.984 |     0.3
   16 |   0.8541 |     27.877 |   1.0223 |     33.488 |     0.3
   17 |   0.8063 |     26.334 |   1.0038 |     31.691 |     0.4
   18 |   0.7619 |     24.950 |   1.0031 |     31.722 |     0.4
   19 |   0.7301 |     23.666 |   0.9864 |     30.607 |     0.4
   20 |   0.6921 |     22.360 |   0.9836 |     30.359 |     0.4
   21 |   0.6592 |     21.015 |   0.9813 |     30.204 |     0.5
   22 |   0.6375 |     20.674 |   0.9638 |     28.748 |     0.5
   23 |   0.5980 |     18.932 |   0.9674 |     28.563 |     0.5
   24 |   0.5716 |     18.188 |   0.9688 |     28.284 |     0.5
   25 |   0.5317 |     16.854 |   0.9769 |     29.151 |     0.5
   26 |   0.5156 |     16.248 |   0.9859 |     28.160 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 649,570

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5464 |     68.337 |   2.0046 |     55.019 |     0.0
    2 |   1.7590 |     49.653 |   1.5711 |     46.344 |     0.0
    3 |   1.5005 |     45.949 |   1.4585 |     46.344 |     0.1
    4 |   1.4343 |     46.026 |   1.4239 |     46.344 |     0.1
    5 |   1.4055 |     46.010 |   1.3918 |     46.344 |     0.1
    6 |   1.3820 |     45.850 |   1.3809 |     46.283 |     0.1
    7 |   1.3610 |     45.425 |   1.3532 |     45.694 |     0.2
    8 |   1.3296 |     43.645 |   1.3336 |     44.919 |     0.2
    9 |   1.3011 |     42.841 |   1.3120 |     43.742 |     0.2
   10 |   1.2829 |     42.130 |   1.2929 |     43.123 |     0.2
   11 |   1.2566 |     41.292 |   1.2788 |     42.906 |     0.2
   12 |   1.2359 |     40.553 |   1.2678 |     42.379 |     0.3
   13 |   1.2117 |     40.008 |   1.2463 |     41.760 |     0.3
   14 |   1.1956 |     39.710 |   1.2556 |     42.317 |     0.3
   15 |   1.1771 |     39.242 |   1.2220 |     41.667 |     0.3
   16 |   1.1606 |     38.679 |   1.2243 |     41.667 |     0.4
   17 |   1.1471 |     38.431 |   1.2159 |     40.923 |     0.4
   18 |   1.1260 |     37.787 |   1.1979 |     40.118 |     0.4
   19 |   1.1066 |     37.109 |   1.1713 |     38.971 |     0.4
   20 |   1.0922 |     36.629 |   1.1838 |     39.777 |     0.5
   21 |   1.0710 |     36.106 |   1.1595 |     39.405 |     0.5
   22 |   1.0458 |     35.174 |   1.1495 |     39.219 |     0.5
   23 |   1.0254 |     34.204 |   1.1503 |     37.825 |     0.5
   24 |   1.0061 |     33.151 |   1.1310 |     37.454 |     0.5
   25 |   0.9844 |     32.578 |   1.1239 |     36.927 |     0.6
   26 |   0.9559 |     31.437 |   1.1226 |     35.936 |     0.6
   27 |   0.9415 |     31.134 |   1.1105 |     36.121 |     0.6
   28 |   0.9257 |     30.484 |   1.0894 |     35.657 |     0.6
   29 |   0.9067 |     29.856 |   1.1033 |     35.874 |     0.7
   30 |   0.9134 |     30.071 |   1.1225 |     36.493 |     0.7
   31 |   0.8948 |     29.365 |   1.0823 |     34.913 |     0.7
   32 |   0.8613 |     28.075 |   1.0973 |     34.882 |     0.7
   33 |   0.8414 |     27.453 |   1.0936 |     34.170 |     0.8
   34 |   0.8293 |     27.122 |   1.0898 |     35.905 |     0.8
   35 |   0.8083 |     26.472 |   1.0923 |     34.758 |     0.8
   36 |   0.7881 |     25.573 |   1.0791 |     34.294 |     0.8
   37 |   0.7701 |     25.050 |   1.0862 |     34.542 |     0.8
   38 |   0.7553 |     24.642 |   1.0711 |     33.457 |     0.9
   39 |   0.7274 |     23.446 |   1.0793 |     33.519 |     0.9
   40 |   0.7154 |     22.972 |   1.0869 |     34.325 |     0.9
   41 |   0.7023 |     22.740 |   1.0641 |     32.962 |     0.9
   42 |   0.7235 |     23.606 |   1.0974 |     33.705 |     1.0
   43 |   0.6969 |     22.272 |   1.0453 |     31.970 |     1.0
   44 |   0.6728 |     21.980 |   1.0688 |     33.024 |     1.0
   45 |   0.6447 |     20.888 |   1.0668 |     31.753 |     1.0
   46 |   0.6311 |     20.045 |   1.0539 |     31.413 |     1.1
   47 |   0.6277 |     20.536 |   1.0801 |     32.528 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,339,490

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2828 |     62.456 |   1.6471 |     49.442 |     0.0
    2 |   1.4955 |     46.208 |   1.4286 |     46.344 |     0.1
    3 |   1.4129 |     46.153 |   1.4043 |     46.344 |     0.1
    4 |   1.3963 |     45.977 |   1.3928 |     46.344 |     0.2
    5 |   1.3844 |     46.054 |   1.3827 |     46.344 |     0.2
    6 |   1.3686 |     45.431 |   1.3740 |     45.725 |     0.3
    7 |   1.3426 |     44.417 |   1.3533 |     45.322 |     0.3
    8 |   1.3242 |     43.910 |   1.3323 |     45.043 |     0.4
    9 |   1.3129 |     43.706 |   1.3268 |     44.765 |     0.4
   10 |   1.3016 |     43.287 |   1.3124 |     44.486 |     0.4
   11 |   1.2804 |     42.626 |   1.3051 |     43.835 |     0.5
   12 |   1.2691 |     42.119 |   1.2938 |     43.432 |     0.5
   13 |   1.2569 |     41.832 |   1.2885 |     43.773 |     0.6
   14 |   1.2447 |     41.408 |   1.2828 |     43.618 |     0.6
   15 |   1.2298 |     41.237 |   1.2700 |     43.216 |     0.7
   16 |   1.2256 |     40.917 |   1.2662 |     42.782 |     0.7
   17 |   1.2077 |     40.553 |   1.2584 |     42.255 |     0.8
   18 |   1.1954 |     40.338 |   1.2530 |     42.658 |     0.8
   19 |   1.1827 |     39.727 |   1.2369 |     42.441 |     0.9
   20 |   1.1703 |     39.385 |   1.2178 |     41.078 |     0.9
   21 |   1.1513 |     38.569 |   1.2086 |     41.078 |     0.9
   22 |   1.1344 |     38.316 |   1.2105 |     41.078 |     1.0
   23 |   1.1235 |     37.985 |   1.1982 |     40.954 |     1.0
   24 |   1.1073 |     37.021 |   1.2051 |     41.171 |     1.1
   25 |   1.0889 |     36.728 |   1.1582 |     38.755 |     1.1
   26 |   1.0703 |     35.924 |   1.1502 |     38.259 |     1.2
   27 |   1.0502 |     35.169 |   1.1619 |     38.600 |     1.2
   28 |   1.0343 |     34.651 |   1.1454 |     37.051 |     1.3
   29 |   1.0148 |     34.099 |   1.1407 |     37.701 |     1.3
   30 |   0.9998 |     33.080 |   1.1241 |     37.175 |     1.3
   31 |   0.9818 |     32.788 |   1.1219 |     36.834 |     1.4
   32 |   0.9546 |     31.790 |   1.1146 |     36.493 |     1.4
   33 |   0.9385 |     31.410 |   1.0973 |     36.090 |     1.5
   34 |   0.9153 |     30.556 |   1.0838 |     35.068 |     1.5
   35 |   0.9041 |     30.236 |   1.0906 |     35.998 |     1.6
   36 |   0.8873 |     29.883 |   1.0590 |     34.727 |     1.6
   37 |   0.8710 |     29.266 |   1.0601 |     34.572 |     1.7
   38 |   0.8511 |     28.549 |   1.0498 |     34.480 |     1.7
   39 |   0.8243 |     27.486 |   1.0472 |     34.201 |     1.7
   40 |   0.8136 |     27.232 |   1.0473 |     33.426 |     1.8
   41 |   0.7975 |     26.797 |   1.0617 |     33.643 |     1.8
   42 |   0.7887 |     26.736 |   1.0361 |     32.962 |     1.9
   43 |   0.7581 |     25.612 |   1.0556 |     34.387 |     1.9
   44 |   0.7437 |     24.879 |   1.0419 |     33.147 |     2.0
   45 |   0.7251 |     24.438 |   1.0383 |     33.055 |     2.0
   46 |   0.7023 |     23.694 |   1.0068 |     31.877 |     2.1
   47 |   0.6849 |     23.082 |   1.0220 |     32.249 |     2.1
   48 |   0.6664 |     22.542 |   1.0207 |     31.599 |     2.1
   49 |   0.6628 |     22.222 |   1.0255 |     31.351 |     2.2
   50 |   0.6467 |     21.616 |   1.0404 |     31.939 |     2.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 917,858

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5819 |     68.893 |   1.9793 |     59.851 |     0.0
    2 |   1.7783 |     49.774 |   1.5888 |     46.344 |     0.1
    3 |   1.5129 |     45.982 |   1.4589 |     47.150 |     0.1
    4 |   1.4379 |     46.098 |   1.4235 |     46.344 |     0.1
    5 |   1.4131 |     45.877 |   1.4102 |     46.344 |     0.2
    6 |   1.4033 |     45.966 |   1.4025 |     46.314 |     0.2
    7 |   1.3954 |     45.988 |   1.3927 |     46.344 |     0.2
    8 |   1.3908 |     45.938 |   1.3939 |     46.344 |     0.3
    9 |   1.3837 |     45.977 |   1.3832 |     46.221 |     0.3
   10 |   1.3713 |     45.337 |   1.3687 |     45.849 |     0.3
   11 |   1.3533 |     44.726 |   1.3530 |     45.632 |     0.4
   12 |   1.3419 |     44.472 |   1.3459 |     45.446 |     0.4
   13 |   1.3355 |     44.461 |   1.3394 |     45.322 |     0.4
   14 |   1.3253 |     44.433 |   1.3326 |     45.229 |     0.5
   15 |   1.3216 |     44.323 |   1.3295 |     45.074 |     0.5
   16 |   1.3164 |     44.301 |   1.3191 |     45.353 |     0.5
   17 |   1.3071 |     44.218 |   1.3197 |     45.601 |     0.6
   18 |   1.2963 |     44.185 |   1.3237 |     45.601 |     0.6
   19 |   1.2927 |     43.954 |   1.3038 |     45.384 |     0.6
   20 |   1.2857 |     43.794 |   1.3135 |     44.331 |     0.7
   21 |   1.2827 |     43.331 |   1.2979 |     44.083 |     0.7
   22 |   1.2740 |     42.940 |   1.2905 |     43.804 |     0.7
   23 |   1.2669 |     42.780 |   1.2886 |     43.773 |     0.8
   24 |   1.2582 |     42.146 |   1.2851 |     43.587 |     0.8
   25 |   1.2519 |     41.937 |   1.2930 |     43.618 |     0.8
   26 |   1.2459 |     41.755 |   1.2650 |     42.751 |     0.9
   27 |   1.2416 |     41.799 |   1.2774 |     43.401 |     0.9
   28 |   1.2327 |     41.590 |   1.2617 |     43.092 |     0.9
   29 |   1.2225 |     40.983 |   1.2655 |     43.401 |     1.0
   30 |   1.2178 |     40.928 |   1.2573 |     41.976 |     1.0
   31 |   1.2101 |     40.664 |   1.2484 |     41.760 |     1.0
   32 |   1.2027 |     40.542 |   1.2574 |     42.038 |     1.1
   33 |   1.1960 |     40.063 |   1.2467 |     41.884 |     1.1
   34 |   1.1979 |     40.449 |   1.2470 |     41.976 |     1.1
   35 |   1.1850 |     40.184 |   1.2419 |     42.441 |     1.2
   36 |   1.1895 |     40.360 |   1.2517 |     42.658 |     1.2
   37 |   1.1824 |     39.886 |   1.2485 |     42.534 |     1.2
   38 |   1.1871 |     40.223 |   1.2419 |     42.007 |     1.3
   39 |   1.1673 |     39.324 |   1.2355 |     42.131 |     1.3
   40 |   1.1571 |     39.010 |   1.2231 |     41.698 |     1.3
   41 |   1.1587 |     39.407 |   1.2215 |     41.574 |     1.4
   42 |   1.1645 |     39.638 |   1.2102 |     41.233 |     1.4
   43 |   1.1463 |     38.679 |   1.2220 |     41.171 |     1.4
   44 |   1.1556 |     39.220 |   1.2146 |     40.273 |     1.5
   45 |   1.1341 |     38.724 |   1.2251 |     42.069 |     1.5
   46 |   1.1243 |     38.277 |   1.2016 |     40.799 |     1.5
   47 |   1.1214 |     38.095 |   1.2119 |     40.582 |     1.6
   48 |   1.1158 |     37.610 |   1.1993 |     40.458 |     1.6
   49 |   1.1146 |     37.770 |   1.2044 |     40.304 |     1.6
   50 |   1.1114 |     37.478 |   1.1854 |     40.056 |     1.7
   51 |   1.1017 |     37.456 |   1.1972 |     40.242 |     1.7
   52 |   1.1153 |     37.781 |   1.1886 |     40.211 |     1.7
   53 |   1.0933 |     36.822 |   1.1826 |     40.149 |     1.8
   54 |   1.0810 |     36.447 |   1.1834 |     39.932 |     1.8
   55 |   1.0885 |     36.535 |   1.1906 |     40.366 |     1.8
   56 |   1.0895 |     36.839 |   1.1782 |     39.405 |     1.9
   57 |   1.0860 |     36.739 |   1.1820 |     39.870 |     1.9
   58 |   1.0844 |     36.547 |   1.1805 |     39.560 |     1.9
   59 |   1.0921 |     36.866 |   1.1700 |     38.879 |     2.0
   60 |   1.0691 |     35.869 |   1.1564 |     38.693 |     2.0
   61 |   1.0631 |     35.488 |   1.1602 |     39.312 |     2.0
   62 |   1.0595 |     35.725 |   1.1595 |     39.219 |     2.1
   63 |   1.0480 |     35.565 |   1.1494 |     38.228 |     2.1
   64 |   1.0448 |     35.251 |   1.1514 |     38.538 |     2.1
   65 |   1.0380 |     34.932 |   1.1622 |     38.879 |     2.2
   66 |   1.0380 |     34.640 |   1.1594 |     38.197 |     2.2
   67 |   1.0435 |     35.323 |   1.1856 |     39.126 |     2.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 1,062,370

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2317 |     59.888 |   1.6189 |     46.344 |     0.0
    2 |   1.4703 |     46.004 |   1.4075 |     46.344 |     0.1
    3 |   1.3779 |     45.927 |   1.3579 |     46.314 |     0.1
    4 |   1.3362 |     45.249 |   1.3311 |     45.291 |     0.1
    5 |   1.3013 |     43.860 |   1.2987 |     43.959 |     0.2
    6 |   1.2506 |     42.504 |   1.2571 |     43.494 |     0.2
    7 |   1.2121 |     41.369 |   1.2331 |     42.224 |     0.2
    8 |   1.1793 |     40.046 |   1.2039 |     40.706 |     0.3
    9 |   1.1388 |     38.459 |   1.1828 |     40.861 |     0.3
   10 |   1.1006 |     36.855 |   1.1384 |     38.228 |     0.3
   11 |   1.0547 |     35.031 |   1.1251 |     37.701 |     0.4
   12 |   1.0147 |     33.769 |   1.0916 |     36.431 |     0.4
   13 |   0.9782 |     32.352 |   1.0866 |     36.214 |     0.4
   14 |   0.9284 |     30.693 |   1.0462 |     33.798 |     0.5
   15 |   0.8912 |     29.734 |   1.0263 |     33.922 |     0.5
   16 |   0.8598 |     28.097 |   1.0165 |     32.931 |     0.5
   17 |   0.8148 |     26.670 |   1.0305 |     31.784 |     0.6
   18 |   0.7840 |     25.805 |   0.9841 |     31.970 |     0.6
   19 |   0.7369 |     23.903 |   1.0074 |     31.877 |     0.6
   20 |   0.7061 |     22.972 |   1.0087 |     30.979 |     0.7
   21 |   0.6862 |     21.897 |   0.9780 |     30.390 |     0.7
   22 |   0.6460 |     20.591 |   0.9553 |     29.182 |     0.7
   23 |   0.6083 |     19.566 |   0.9788 |     29.647 |     0.8
   24 |   0.5829 |     18.722 |   0.9844 |     29.275 |     0.8
   25 |   0.5520 |     17.389 |   0.9728 |     28.810 |     0.8
   26 |   0.5163 |     16.474 |   1.0112 |     28.965 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,189,922

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2438 |     60.791 |   1.6450 |     49.442 |     0.0
    2 |   1.4968 |     46.026 |   1.4268 |     46.344 |     0.1
    3 |   1.4088 |     46.010 |   1.4038 |     46.375 |     0.1
    4 |   1.3769 |     45.244 |   1.3618 |     45.353 |     0.2
    5 |   1.3451 |     44.274 |   1.3422 |     45.229 |     0.2
    6 |   1.3231 |     43.673 |   1.3217 |     44.579 |     0.3
    7 |   1.3000 |     43.022 |   1.3167 |     43.866 |     0.3
    8 |   1.2831 |     42.714 |   1.3069 |     43.587 |     0.3
    9 |   1.2683 |     41.826 |   1.2841 |     43.401 |     0.4
   10 |   1.2474 |     41.567 |   1.2789 |     42.968 |     0.4
   11 |   1.2368 |     41.044 |   1.2749 |     43.154 |     0.5
   12 |   1.2209 |     40.669 |   1.2469 |     43.061 |     0.5
   13 |   1.1995 |     40.118 |   1.2352 |     42.379 |     0.5
   14 |   1.1846 |     39.721 |   1.2214 |     41.481 |     0.6
   15 |   1.1665 |     39.220 |   1.2100 |     40.520 |     0.6
   16 |   1.1506 |     38.321 |   1.2039 |     40.892 |     0.7
   17 |   1.1279 |     37.836 |   1.1680 |     39.033 |     0.7
   18 |   1.1144 |     37.269 |   1.1711 |     39.684 |     0.8
   19 |   1.0920 |     36.613 |   1.1733 |     39.870 |     0.8
   20 |   1.0781 |     36.210 |   1.1559 |     38.755 |     0.8
   21 |   1.0570 |     35.367 |   1.1435 |     37.670 |     0.9
   22 |   1.0414 |     34.739 |   1.1345 |     36.834 |     0.9
   23 |   1.0233 |     34.127 |   1.1124 |     36.741 |     1.0
   24 |   1.0040 |     33.460 |   1.1061 |     35.905 |     1.0
   25 |   0.9838 |     32.804 |   1.1080 |     36.338 |     1.1
   26 |   0.9684 |     32.143 |   1.0944 |     36.865 |     1.1
   27 |   0.9467 |     31.972 |   1.0799 |     35.812 |     1.1
   28 |   0.9370 |     31.371 |   1.0873 |     35.378 |     1.2
   29 |   0.9197 |     30.710 |   1.0678 |     35.006 |     1.2
   30 |   0.8998 |     30.164 |   1.0820 |     35.719 |     1.3
   31 |   0.8814 |     29.332 |   1.0816 |     35.316 |     1.3
   32 |   0.8657 |     28.853 |   1.0642 |     34.387 |     1.3
   33 |   0.8498 |     28.505 |   1.0667 |     34.139 |     1.4
   34 |   0.8249 |     27.425 |   1.0596 |     33.798 |     1.4
   35 |   0.8081 |     26.852 |   1.0517 |     33.302 |     1.5
   36 |   0.7959 |     26.918 |   1.0749 |     34.232 |     1.5
   37 |   0.7913 |     26.560 |   1.0571 |     33.984 |     1.6
   38 |   0.7704 |     25.959 |   1.0498 |     32.869 |     1.6
   39 |   0.7540 |     25.121 |   1.0644 |     33.271 |     1.6
   40 |   0.7406 |     24.807 |   1.0543 |     32.838 |     1.7
   41 |   0.7184 |     23.898 |   1.0578 |     31.753 |     1.7
   42 |   0.7096 |     23.760 |   1.0497 |     32.900 |     1.8
   43 |   0.6963 |     23.402 |   1.0551 |     32.094 |     1.8
   44 |   0.6851 |     23.413 |   1.0734 |     32.342 |     1.8
   45 |   0.6656 |     22.404 |   1.0482 |     31.629 |     1.9
   46 |   0.6523 |     21.996 |   1.0421 |     31.351 |     1.9
   47 |   0.6489 |     22.046 |   1.0506 |     30.979 |     2.0
   48 |   0.6430 |     21.996 |   1.0612 |     31.970 |     2.0
   49 |   0.6212 |     21.015 |   1.0698 |     31.196 |     2.1
   50 |   0.6127 |     20.971 |   1.0653 |     31.041 |     2.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,322,018

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2983 |     62.671 |   1.6747 |     49.442 |     0.0
    2 |   1.5132 |     46.401 |   1.4419 |     46.344 |     0.1
    3 |   1.4165 |     45.927 |   1.4156 |     46.344 |     0.1
    4 |   1.3985 |     46.147 |   1.3991 |     46.344 |     0.2
    5 |   1.3913 |     46.065 |   1.3936 |     46.375 |     0.2
    6 |   1.3875 |     45.718 |   1.3859 |     45.973 |     0.3
    7 |   1.3792 |     45.596 |   1.3707 |     45.291 |     0.3
    8 |   1.3555 |     44.483 |   1.3598 |     45.198 |     0.4
    9 |   1.3359 |     44.070 |   1.3436 |     45.229 |     0.4
   10 |   1.3210 |     43.761 |   1.3303 |     44.703 |     0.5
   11 |   1.3084 |     43.535 |   1.3216 |     45.105 |     0.5
   12 |   1.2920 |     42.918 |   1.3032 |     43.804 |     0.5
   13 |   1.2838 |     42.471 |   1.2978 |     43.649 |     0.6
   14 |   1.2731 |     42.394 |   1.2919 |     43.587 |     0.6
   15 |   1.2619 |     41.926 |   1.2813 |     42.937 |     0.7
   16 |   1.2480 |     41.716 |   1.2853 |     43.649 |     0.7
   17 |   1.2345 |     41.248 |   1.2718 |     43.587 |     0.8
   18 |   1.2263 |     41.319 |   1.2560 |     43.340 |     0.8
   19 |   1.2194 |     41.044 |   1.2529 |     42.627 |     0.9
   20 |   1.2087 |     40.923 |   1.2479 |     42.999 |     0.9
   21 |   1.2010 |     40.614 |   1.2434 |     42.937 |     1.0
   22 |   1.1895 |     40.250 |   1.2308 |     42.317 |     1.0
   23 |   1.1726 |     39.616 |   1.2283 |     41.450 |     1.0
   24 |   1.1633 |     39.473 |   1.2164 |     41.264 |     1.1
   25 |   1.1548 |     39.115 |   1.2216 |     41.016 |     1.1
   26 |   1.1429 |     38.806 |   1.2281 |     40.861 |     1.2
   27 |   1.1355 |     38.509 |   1.1993 |     40.520 |     1.2
   28 |   1.1217 |     37.693 |   1.1936 |     40.056 |     1.3
   29 |   1.1016 |     37.070 |   1.1958 |     39.839 |     1.3
   30 |   1.0997 |     37.186 |   1.1826 |     40.025 |     1.4
   31 |   1.0843 |     36.486 |   1.1752 |     39.219 |     1.4
   32 |   1.0747 |     36.227 |   1.1659 |     38.971 |     1.4
   33 |   1.0636 |     35.731 |   1.1725 |     38.476 |     1.5
   34 |   1.0524 |     35.317 |   1.1696 |     38.135 |     1.5
   35 |   1.0397 |     35.058 |   1.1598 |     38.073 |     1.6
   36 |   1.0319 |     34.584 |   1.1539 |     37.732 |     1.6
   37 |   1.0246 |     34.529 |   1.1658 |     37.949 |     1.7
   38 |   1.0257 |     34.342 |   1.1642 |     37.887 |     1.7
   39 |   1.0163 |     34.177 |   1.1448 |     37.113 |     1.8
   40 |   0.9936 |     33.196 |   1.1437 |     37.732 |     1.8
   41 |   0.9886 |     33.008 |   1.1339 |     36.400 |     1.9
   42 |   0.9779 |     32.821 |   1.1395 |     36.617 |     1.9
   43 |   0.9611 |     32.281 |   1.1375 |     36.896 |     1.9
   44 |   0.9499 |     32.286 |   1.1248 |     36.493 |     2.0
   45 |   0.9467 |     32.082 |   1.1375 |     36.741 |     2.0
   46 |   0.9423 |     31.801 |   1.1083 |     36.029 |     2.1
   47 |   0.9249 |     31.189 |   1.1106 |     35.781 |     2.1
   48 |   0.9080 |     30.666 |   1.1145 |     35.998 |     2.2
   49 |   0.9054 |     30.247 |   1.1040 |     35.936 |     2.2
   50 |   0.9014 |     30.390 |   1.0954 |     35.440 |     2.3
   51 |   0.8868 |     30.060 |   1.1247 |     35.533 |     2.3
   52 |   0.8761 |     29.839 |   1.1118 |     35.874 |     2.4
   53 |   0.8751 |     29.613 |   1.1168 |     36.214 |     2.4
   54 |   0.8634 |     29.178 |   1.1145 |     35.843 |     2.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 2,457,698

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5646 |     68.160 |   2.0525 |     59.851 |     1.0
    2 |   1.8193 |     51.670 |   1.6065 |     46.344 |     2.0
    3 |   1.5223 |     46.015 |   1.4672 |     46.004 |     3.0
    4 |   1.4389 |     45.977 |   1.4245 |     47.150 |     4.0
    5 |   1.4130 |     46.026 |   1.4096 |     46.344 |     5.0
    6 |   1.4017 |     46.037 |   1.4015 |     46.344 |     6.0
    7 |   1.3946 |     45.955 |   1.3991 |     46.344 |     7.1
    8 |   1.3898 |     45.955 |   1.3915 |     46.530 |     8.1
    9 |   1.3847 |     46.026 |   1.3827 |     46.344 |     9.1
   10 |   1.3751 |     46.120 |   1.3752 |     46.344 |    10.1
   11 |   1.3597 |     45.117 |   1.3610 |     45.508 |    11.1
   12 |   1.3485 |     44.709 |   1.3519 |     45.725 |    12.1
   13 |   1.3384 |     44.643 |   1.3392 |     45.446 |    13.1
   14 |   1.3325 |     44.406 |   1.3421 |     45.291 |    14.2
   15 |   1.3244 |     44.141 |   1.3323 |     45.291 |    15.2
   16 |   1.3150 |     43.888 |   1.3393 |     44.888 |    16.2
   17 |   1.3206 |     43.849 |   1.3251 |     44.796 |    17.2
   18 |   1.3099 |     43.634 |   1.3179 |     44.610 |    18.2
   19 |   1.2996 |     43.304 |   1.3089 |     43.959 |    19.2
   20 |   1.2965 |     43.320 |   1.3118 |     44.114 |    20.2
   21 |   1.2890 |     42.890 |   1.2979 |     43.959 |    21.3
   22 |   1.2841 |     43.050 |   1.3004 |     44.548 |    22.3
   23 |   1.2814 |     42.593 |   1.3032 |     44.517 |    23.3
   24 |   1.2783 |     42.471 |   1.2969 |     43.959 |    24.3
   25 |   1.2687 |     42.389 |   1.2892 |     44.114 |    25.3
   26 |   1.2676 |     42.383 |   1.2840 |     43.711 |    26.3
   27 |   1.2619 |     42.267 |   1.2810 |     44.052 |    27.3
   28 |   1.2560 |     42.058 |   1.2828 |     44.176 |    28.3
   29 |   1.2485 |     41.876 |   1.2775 |     43.556 |    29.3
   30 |   1.2503 |     41.871 |   1.2679 |     42.658 |    30.3
   31 |   1.2423 |     41.838 |   1.2732 |     43.371 |    31.3
   32 |   1.2383 |     41.364 |   1.2585 |     43.030 |    32.4
   33 |   1.2264 |     41.308 |   1.2609 |     42.782 |    33.4
   34 |   1.2270 |     41.441 |   1.2599 |     42.875 |    34.4
   35 |   1.2207 |     41.242 |   1.2455 |     42.534 |    35.4
   36 |   1.2145 |     41.016 |   1.2491 |     42.751 |    36.4
   37 |   1.2179 |     40.868 |   1.2400 |     42.441 |    37.4
   38 |   1.1987 |     40.300 |   1.2389 |     42.131 |    38.4
   39 |   1.2019 |     40.377 |   1.2366 |     42.100 |    39.4
   40 |   1.1961 |     40.333 |   1.2267 |     41.264 |    40.4
   41 |   1.1922 |     40.278 |   1.2318 |     41.202 |    41.4
   42 |   1.1810 |     39.925 |   1.2306 |     42.441 |    42.4
   43 |   1.1815 |     39.738 |   1.2150 |     41.233 |    43.4
   44 |   1.1776 |     39.506 |   1.2050 |     41.140 |    44.4
   45 |   1.1701 |     39.539 |   1.1980 |     41.264 |    45.5
   46 |   1.1612 |     39.214 |   1.2132 |     41.047 |    46.5
   47 |   1.1643 |     39.324 |   1.1932 |     40.056 |    47.5
   48 |   1.1582 |     39.010 |   1.1994 |     40.892 |    48.5
   49 |   1.1524 |     38.558 |   1.1937 |     40.118 |    49.5
   50 |   1.1437 |     38.161 |   1.2005 |     40.985 |    50.6
   51 |   1.1403 |     38.007 |   1.1912 |     39.901 |    51.6
   52 |   1.1459 |     38.409 |   1.2023 |     39.529 |    52.6
   53 |   1.1351 |     38.029 |   1.1879 |     40.273 |    53.6
   54 |   1.1390 |     38.393 |   1.1870 |     39.436 |    54.6
   55 |   1.1292 |     37.891 |   1.1913 |     39.994 |    55.6
   56 |   1.1233 |     37.346 |   1.1780 |     38.538 |    56.6
   57 |   1.1160 |     37.445 |   1.1814 |     39.746 |    57.7
   58 |   1.1064 |     37.070 |   1.1665 |     39.343 |    58.7
   59 |   1.0928 |     36.447 |   1.1717 |     38.817 |    59.7
   60 |   1.1092 |     36.910 |   1.1772 |     39.963 |    60.7
   61 |   1.1075 |     37.307 |   1.1737 |     39.560 |    61.7
   62 |   1.0966 |     36.420 |   1.1646 |     39.343 |    62.7
   63 |   1.0855 |     36.056 |   1.1675 |     38.848 |    63.7
   64 |   1.0792 |     36.547 |   1.1723 |     38.971 |    64.8
   65 |   1.0800 |     36.414 |   1.1763 |     39.281 |    65.8
   66 |   1.0748 |     36.023 |   1.1686 |     38.507 |    66.8
   67 |   1.0723 |     35.979 |   1.1426 |     38.135 |    67.8
   68 |   1.0590 |     35.758 |   1.1592 |     39.591 |    68.8
   69 |   1.0762 |     35.830 |   1.1519 |     39.312 |    69.8
   70 |   1.0797 |     36.310 |   1.1737 |     39.095 |    70.9
   71 |   1.0602 |     35.747 |   1.1497 |     37.918 |    71.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,466,978

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5639 |     68.458 |   2.0237 |     59.851 |     1.0
    2 |   1.7674 |     49.598 |   1.5833 |     46.344 |     1.9
    3 |   1.5123 |     46.021 |   1.4689 |     46.344 |     2.9
    4 |   1.4422 |     45.916 |   1.4319 |     47.150 |     3.9
    5 |   1.4161 |     46.164 |   1.4129 |     46.344 |     4.9
    6 |   1.4034 |     46.065 |   1.4058 |     46.344 |     6.0
    7 |   1.3964 |     45.905 |   1.3977 |     46.344 |     7.0
    8 |   1.3843 |     45.387 |   1.3783 |     45.942 |     8.0
    9 |   1.3620 |     44.720 |   1.3681 |     45.570 |     9.0
   10 |   1.3488 |     44.687 |   1.3597 |     45.508 |    10.0
   11 |   1.3349 |     44.428 |   1.3478 |     45.601 |    11.0
   12 |   1.3251 |     44.130 |   1.3396 |     45.601 |    12.0
   13 |   1.3181 |     43.838 |   1.3307 |     45.167 |    13.0
   14 |   1.3147 |     43.590 |   1.3256 |     44.796 |    14.0
   15 |   1.3043 |     43.364 |   1.3198 |     44.610 |    15.0
   16 |   1.2912 |     42.868 |   1.3041 |     43.835 |    16.0
   17 |   1.2800 |     42.460 |   1.3081 |     43.959 |    17.0
   18 |   1.2728 |     42.367 |   1.2953 |     43.835 |    18.0
   19 |   1.2622 |     42.130 |   1.2821 |     42.875 |    19.0
   20 |   1.2533 |     41.782 |   1.2723 |     42.689 |    20.0
   21 |   1.2490 |     41.485 |   1.2721 |     43.154 |    21.0
   22 |   1.2441 |     41.264 |   1.2660 |     43.030 |    22.1
   23 |   1.2375 |     40.978 |   1.2622 |     42.472 |    23.1
   24 |   1.2274 |     40.421 |   1.2605 |     42.441 |    24.1
   25 |   1.2203 |     40.239 |   1.2509 |     41.853 |    25.1
   26 |   1.2116 |     39.931 |   1.2513 |     41.853 |    26.1
   27 |   1.2090 |     40.278 |   1.2603 |     41.945 |    27.1
   28 |   1.2186 |     40.482 |   1.2460 |     42.410 |    28.1
   29 |   1.1981 |     39.859 |   1.2325 |     41.698 |    29.1
   30 |   1.1911 |     39.820 |   1.2267 |     41.791 |    30.1
   31 |   1.1874 |     39.649 |   1.2328 |     41.543 |    31.1
   32 |   1.1751 |     39.203 |   1.2258 |     41.388 |    32.1
   33 |   1.1779 |     39.424 |   1.2183 |     40.861 |    33.1
   34 |   1.1670 |     39.082 |   1.2243 |     41.481 |    34.1
   35 |   1.1697 |     39.021 |   1.2136 |     40.706 |    35.1
   36 |   1.1522 |     38.470 |   1.2095 |     40.582 |    36.1
   37 |   1.1554 |     38.646 |   1.2089 |     40.861 |    37.1
   38 |   1.1430 |     38.376 |   1.2006 |     40.335 |    38.1
   39 |   1.1402 |     38.272 |   1.1968 |     40.273 |    39.2
   40 |   1.1337 |     38.250 |   1.1975 |     40.489 |    40.2
   41 |   1.1218 |     37.483 |   1.1867 |     39.467 |    41.2
   42 |   1.1130 |     37.241 |   1.1847 |     40.149 |    42.2
   43 |   1.1128 |     37.252 |   1.2029 |     40.335 |    43.2
   44 |   1.1275 |     37.875 |   1.1915 |     40.520 |    44.2
   45 |   1.1114 |     37.114 |   1.1952 |     40.397 |    45.2
   46 |   1.1074 |     36.910 |   1.1936 |     40.458 |    46.3
   47 |   1.0916 |     36.618 |   1.1844 |     40.551 |    47.3
   48 |   1.0901 |     36.861 |   1.1818 |     40.118 |    48.3
   49 |   1.0868 |     36.690 |   1.1690 |     39.994 |    49.3
   50 |   1.0783 |     36.365 |   1.1694 |     39.746 |    50.3
   51 |   1.0746 |     36.276 |   1.1609 |     38.941 |    51.3
   52 |   1.0761 |     36.243 |   1.1706 |     39.436 |    52.3
   53 |   1.0637 |     35.808 |   1.1693 |     39.064 |    53.3
   54 |   1.0571 |     35.946 |   1.1730 |     39.281 |    54.3
   55 |   1.0514 |     35.351 |   1.1581 |     38.879 |    55.4
   56 |   1.0464 |     35.301 |   1.1566 |     38.786 |    56.4
   57 |   1.0355 |     34.794 |   1.1647 |     38.971 |    57.4
   58 |   1.0347 |     34.981 |   1.1533 |     38.476 |    58.4
   59 |   1.0219 |     34.601 |   1.1520 |     38.352 |    59.4
   60 |   1.0251 |     34.623 |   1.1591 |     38.879 |    60.5
   61 |   1.0175 |     34.226 |   1.1631 |     38.910 |    61.5
   62 |   1.0130 |     34.276 |   1.1506 |     38.011 |    62.5
   63 |   1.0104 |     34.204 |   1.1623 |     38.631 |    63.5
   64 |   1.0124 |     34.155 |   1.1287 |     37.546 |    64.5
   65 |   1.0137 |     34.425 |   1.1410 |     38.290 |    65.5
   66 |   1.0144 |     34.381 |   1.1463 |     38.352 |    66.5
   67 |   0.9979 |     33.620 |   1.1311 |     37.701 |    67.5
   68 |   0.9884 |     33.372 |   1.1169 |     36.958 |    68.6
   69 |   0.9883 |     33.581 |   1.1351 |     37.144 |    69.6
   70 |   0.9718 |     32.903 |   1.1169 |     36.741 |    70.6
   71 |   0.9643 |     32.606 |   1.1174 |     36.772 |    71.6
   72 |   0.9638 |     32.551 |   1.1317 |     37.206 |    72.6
   73 |   0.9592 |     32.490 |   1.1233 |     36.648 |    73.6
   74 |   0.9473 |     31.994 |   1.1304 |     36.958 |    74.6
   75 |   0.9503 |     31.933 |   1.1099 |     36.958 |    75.6
   76 |   0.9455 |     31.834 |   1.1147 |     36.989 |    76.6
   77 |   0.9432 |     31.537 |   1.1054 |     36.834 |    77.7
   78 |   0.9347 |     31.338 |   1.1271 |     36.648 |    78.7
   79 |   0.9356 |     31.498 |   1.1183 |     36.803 |    79.7
   80 |   0.9259 |     30.881 |   1.1278 |     36.834 |    80.7
   81 |   0.9316 |     31.669 |   1.1203 |     36.834 |    81.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 802,178

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3338 |     62.390 |   1.7275 |     49.442 |     0.0
    2 |   1.5319 |     46.632 |   1.4304 |     46.344 |     0.1
    3 |   1.4086 |     45.955 |   1.4040 |     46.375 |     0.1
    4 |   1.3658 |     45.563 |   1.3482 |     45.756 |     0.1
    5 |   1.3271 |     45.211 |   1.3187 |     45.012 |     0.1
    6 |   1.2930 |     44.544 |   1.3037 |     45.632 |     0.2
    7 |   1.2689 |     43.469 |   1.2731 |     43.773 |     0.2
    8 |   1.2456 |     42.493 |   1.2514 |     42.999 |     0.2
    9 |   1.2108 |     40.680 |   1.2246 |     41.853 |     0.3
   10 |   1.1718 |     39.468 |   1.1949 |     40.180 |     0.3
   11 |   1.1362 |     38.283 |   1.1692 |     39.746 |     0.3
   12 |   1.1069 |     37.252 |   1.1489 |     39.622 |     0.3
   13 |   1.0761 |     36.580 |   1.1295 |     38.569 |     0.4
   14 |   1.0491 |     35.306 |   1.1245 |     37.980 |     0.4
   15 |   1.0122 |     34.254 |   1.1076 |     37.392 |     0.4
   16 |   0.9850 |     33.350 |   1.1054 |     37.980 |     0.5
   17 |   0.9536 |     32.226 |   1.0677 |     35.533 |     0.5
   18 |   0.9300 |     31.393 |   1.0435 |     34.449 |     0.5
   19 |   0.9051 |     30.396 |   1.0422 |     35.316 |     0.6
   20 |   0.8673 |     28.544 |   1.0481 |     34.634 |     0.6
   21 |   0.8427 |     28.070 |   1.0191 |     32.590 |     0.6
   22 |   0.8223 |     27.469 |   1.0243 |     33.302 |     0.6
   23 |   0.8031 |     26.714 |   1.0024 |     32.683 |     0.7
   24 |   0.7747 |     25.265 |   1.0010 |     32.528 |     0.7
   25 |   0.7382 |     24.008 |   0.9998 |     31.444 |     0.7
   26 |   0.7175 |     23.369 |   1.0080 |     31.227 |     0.8
   27 |   0.6952 |     22.757 |   0.9880 |     31.134 |     0.8
   28 |   0.6624 |     21.610 |   0.9886 |     30.576 |     0.8
   29 |   0.6535 |     21.335 |   0.9788 |     30.483 |     0.8
   30 |   0.6273 |     20.481 |   0.9678 |     28.903 |     0.9
   31 |   0.5997 |     19.533 |   0.9820 |     29.461 |     0.9
   32 |   0.5812 |     18.778 |   0.9703 |     29.120 |     0.9
   33 |   0.5649 |     18.017 |   0.9461 |     28.965 |     1.0
   34 |   0.5472 |     17.289 |   0.9760 |     29.120 |     1.0
   35 |   0.5437 |     17.675 |   0.9925 |     28.129 |     1.0
   36 |   0.5200 |     16.507 |   0.9772 |     28.717 |     1.0
   37 |   0.4933 |     15.862 |   0.9640 |     27.788 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,865,762

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5422 |     67.984 |   1.9707 |     58.984 |     0.7
    2 |   1.7476 |     49.008 |   1.5629 |     46.344 |     1.5
    3 |   1.4914 |     45.971 |   1.4427 |     46.344 |     2.2
    4 |   1.4254 |     45.988 |   1.4167 |     46.375 |     3.0
    5 |   1.4044 |     46.092 |   1.4044 |     46.344 |     3.7
    6 |   1.3851 |     45.640 |   1.3808 |     45.570 |     4.5
    7 |   1.3576 |     44.808 |   1.3448 |     45.539 |     5.3
    8 |   1.3277 |     44.439 |   1.3266 |     44.579 |     6.0
    9 |   1.3064 |     43.855 |   1.3033 |     44.021 |     6.8
   10 |   1.2787 |     43.144 |   1.2762 |     43.835 |     7.5
   11 |   1.2611 |     42.576 |   1.2742 |     42.999 |     8.3
   12 |   1.2399 |     42.317 |   1.2591 |     42.906 |     9.1
   13 |   1.2276 |     41.810 |   1.2576 |     43.525 |     9.8
   14 |   1.2094 |     40.823 |   1.2357 |     42.596 |    10.6
   15 |   1.1995 |     40.581 |   1.2223 |     41.481 |    11.3
   16 |   1.1839 |     39.892 |   1.2169 |     41.419 |    12.1
   17 |   1.1702 |     39.545 |   1.2096 |     41.388 |    12.9
   18 |   1.1586 |     38.955 |   1.1896 |     40.830 |    13.6
   19 |   1.1524 |     38.768 |   1.1812 |     40.273 |    14.4
   20 |   1.1277 |     37.632 |   1.1802 |     39.684 |    15.2
   21 |   1.1221 |     37.726 |   1.1736 |     39.498 |    15.9
   22 |   1.1050 |     37.125 |   1.1706 |     40.087 |    16.7
   23 |   1.0883 |     36.602 |   1.1674 |     39.994 |    17.4
   24 |   1.0806 |     36.249 |   1.1632 |     39.405 |    18.2
   25 |   1.0647 |     35.924 |   1.1440 |     38.445 |    19.0
   26 |   1.0641 |     35.720 |   1.1511 |     39.343 |    19.7
   27 |   1.0549 |     35.593 |   1.1346 |     38.073 |    20.5
   28 |   1.0397 |     35.317 |   1.1226 |     37.670 |    21.3
   29 |   1.0270 |     34.816 |   1.1324 |     37.949 |    22.0
   30 |   1.0161 |     34.347 |   1.1123 |     37.515 |    22.8
   31 |   1.0007 |     33.636 |   1.0966 |     36.896 |    23.6
   32 |   0.9914 |     33.460 |   1.0992 |     36.617 |    24.3
   33 |   0.9819 |     32.964 |   1.0850 |     36.152 |    25.1
   34 |   0.9747 |     32.501 |   1.0783 |     36.369 |    25.8
   35 |   0.9583 |     31.994 |   1.0692 |     35.316 |    26.6
   36 |   0.9489 |     31.619 |   1.0735 |     36.307 |    27.3
   37 |   0.9365 |     31.476 |   1.0550 |     35.657 |    28.1
   38 |   0.9262 |     31.233 |   1.0641 |     35.502 |    28.9
   39 |   0.9112 |     30.820 |   1.0522 |     35.161 |    29.7
   40 |   0.9060 |     30.214 |   1.0531 |     35.781 |    30.4
   41 |   0.8918 |     29.878 |   1.0417 |     35.316 |    31.1
   42 |   0.8829 |     29.668 |   1.0355 |     34.480 |    31.9
   43 |   0.8728 |     29.470 |   1.0517 |     34.634 |    32.7
   44 |   0.8622 |     28.742 |   1.0414 |     34.603 |    33.4
   45 |   0.8564 |     28.627 |   1.0351 |     35.099 |    34.2
   46 |   0.8772 |     29.095 |   1.0780 |     35.688 |    34.9
   47 |   0.8914 |     30.104 |   1.0122 |     34.232 |    35.7
   48 |   0.8405 |     28.340 |   1.0232 |     34.449 |    36.5
   49 |   0.8291 |     27.381 |   1.0091 |     32.745 |    37.2
   50 |   0.8009 |     26.631 |   1.0309 |     33.705 |    38.0
   51 |   0.7988 |     26.389 |   0.9961 |     33.519 |    38.8
   52 |   0.7816 |     26.157 |   1.0099 |     33.457 |    39.5
   53 |   0.7728 |     25.865 |   0.9976 |     32.001 |    40.3
   54 |   0.7598 |     25.375 |   1.0150 |     32.900 |    41.1
   55 |   0.7435 |     24.807 |   0.9976 |     32.497 |    41.8
   56 |   0.7430 |     24.713 |   0.9800 |     32.187 |    42.6
   57 |   0.7385 |     24.923 |   0.9973 |     32.745 |    43.4
   58 |   0.7375 |     24.504 |   1.0141 |     32.869 |    44.1
   59 |   0.7191 |     24.091 |   0.9946 |     32.838 |    44.9
   60 |   0.7220 |     24.212 |   0.9962 |     31.413 |    45.7
   61 |   0.7151 |     23.705 |   0.9732 |     31.815 |    46.4
   62 |   0.7095 |     24.035 |   0.9618 |     30.793 |    47.2
   63 |   0.6954 |     23.479 |   0.9595 |     30.328 |    47.9
   64 |   0.6770 |     22.327 |   0.9728 |     31.258 |    48.7
   65 |   0.6653 |     22.426 |   0.9653 |     30.514 |    49.5
   66 |   0.6749 |     22.399 |   0.9654 |     30.328 |    50.2
   67 |   0.6660 |     22.184 |   0.9852 |     31.165 |    51.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,339,874

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3200 |     62.467 |   1.6972 |     49.442 |     0.0
    2 |   1.5195 |     46.384 |   1.4310 |     46.344 |     0.1
    3 |   1.4153 |     45.922 |   1.4042 |     47.150 |     0.1
    4 |   1.3971 |     46.120 |   1.3966 |     46.344 |     0.2
    5 |   1.3897 |     46.037 |   1.3911 |     46.344 |     0.2
    6 |   1.3781 |     46.010 |   1.3728 |     46.190 |     0.3
    7 |   1.3570 |     45.007 |   1.3523 |     45.477 |     0.3
    8 |   1.3359 |     44.544 |   1.3481 |     45.787 |     0.3
    9 |   1.3242 |     44.555 |   1.3367 |     45.291 |     0.4
   10 |   1.3126 |     44.053 |   1.3238 |     45.415 |     0.4
   11 |   1.2952 |     43.524 |   1.3069 |     44.362 |     0.5
   12 |   1.2816 |     42.885 |   1.3018 |     44.021 |     0.5
   13 |   1.2668 |     42.245 |   1.2907 |     43.649 |     0.6
   14 |   1.2573 |     42.168 |   1.2692 |     43.185 |     0.6
   15 |   1.2428 |     41.700 |   1.2731 |     44.145 |     0.6
   16 |   1.2288 |     41.424 |   1.2706 |     43.525 |     0.7
   17 |   1.2234 |     41.308 |   1.2580 |     43.030 |     0.7
   18 |   1.2132 |     41.187 |   1.2544 |     43.247 |     0.8
   19 |   1.2042 |     40.956 |   1.2346 |     42.193 |     0.8
   20 |   1.1905 |     40.256 |   1.2383 |     42.286 |     0.9
   21 |   1.1792 |     39.886 |   1.2357 |     42.100 |     0.9
   22 |   1.1684 |     39.539 |   1.2264 |     40.861 |     1.0
   23 |   1.1494 |     38.999 |   1.2116 |     41.357 |     1.0
   24 |   1.1418 |     38.713 |   1.2012 |     41.016 |     1.0
   25 |   1.1359 |     38.553 |   1.2126 |     41.419 |     1.1
   26 |   1.1349 |     38.420 |   1.1922 |     40.087 |     1.1
   27 |   1.1090 |     37.864 |   1.1866 |     39.591 |     1.2
   28 |   1.1027 |     37.539 |   1.1837 |     39.312 |     1.2
   29 |   1.0937 |     37.004 |   1.1796 |     39.157 |     1.3
   30 |   1.0886 |     36.861 |   1.1759 |     39.033 |     1.3
   31 |   1.0691 |     35.852 |   1.1798 |     38.693 |     1.3
   32 |   1.0575 |     35.301 |   1.1678 |     38.817 |     1.4
   33 |   1.0498 |     35.130 |   1.1451 |     38.352 |     1.4
   34 |   1.0281 |     34.816 |   1.1589 |     38.197 |     1.5
   35 |   1.0317 |     34.645 |   1.1581 |     38.259 |     1.5
   36 |   1.0170 |     34.458 |   1.1674 |     38.476 |     1.6
   37 |   1.0281 |     34.540 |   1.1479 |     37.887 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,088,482

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3172 |     62.296 |   1.7081 |     49.442 |     0.0
    2 |   1.5350 |     46.699 |   1.4363 |     47.150 |     0.1
    3 |   1.4147 |     45.988 |   1.4064 |     46.344 |     0.1
    4 |   1.3978 |     46.070 |   1.3946 |     46.344 |     0.1
    5 |   1.3880 |     45.999 |   1.3892 |     46.530 |     0.2
    6 |   1.3677 |     45.348 |   1.3575 |     45.663 |     0.2
    7 |   1.3446 |     44.555 |   1.3392 |     45.446 |     0.2
    8 |   1.3318 |     44.389 |   1.3316 |     45.384 |     0.3
    9 |   1.3170 |     44.202 |   1.3290 |     45.136 |     0.3
   10 |   1.2990 |     43.722 |   1.3160 |     44.919 |     0.4
   11 |   1.2898 |     43.381 |   1.3108 |     44.610 |     0.4
   12 |   1.2770 |     42.863 |   1.3007 |     43.340 |     0.4
   13 |   1.2633 |     42.174 |   1.2837 |     43.680 |     0.5
   14 |   1.2473 |     41.584 |   1.2846 |     43.928 |     0.5
   15 |   1.2359 |     41.656 |   1.2778 |     43.494 |     0.5
   16 |   1.2195 |     41.116 |   1.2751 |     43.216 |     0.6
   17 |   1.2073 |     40.691 |   1.2660 |     42.720 |     0.6
   18 |   1.1935 |     40.410 |   1.2415 |     42.038 |     0.6
   19 |   1.1788 |     39.782 |   1.2617 |     42.069 |     0.7
   20 |   1.1704 |     39.446 |   1.2315 |     41.419 |     0.7
   21 |   1.1502 |     38.806 |   1.2307 |     41.264 |     0.8
   22 |   1.1336 |     38.101 |   1.2177 |     40.087 |     0.8
   23 |   1.1205 |     37.809 |   1.2185 |     41.450 |     0.8
   24 |   1.1046 |     37.213 |   1.2099 |     40.304 |     0.9
   25 |   1.0960 |     36.833 |   1.1907 |     39.622 |     0.9
   26 |   1.0706 |     35.962 |   1.1990 |     39.436 |     0.9
   27 |   1.0709 |     35.775 |   1.1812 |     39.498 |     1.0
   28 |   1.0564 |     35.428 |   1.1955 |     38.848 |     1.0
   29 |   1.0419 |     34.877 |   1.1736 |     38.941 |     1.0
   30 |   1.0205 |     34.529 |   1.1841 |     39.188 |     1.1
   31 |   1.0157 |     34.072 |   1.1782 |     38.848 |     1.1
   32 |   0.9982 |     33.499 |   1.1675 |     38.104 |     1.1
   33 |   0.9937 |     33.394 |   1.1629 |     37.515 |     1.2
   34 |   0.9717 |     32.518 |   1.1615 |     37.732 |     1.2
   35 |   0.9762 |     32.451 |   1.1377 |     36.958 |     1.3
   36 |   0.9494 |     31.537 |   1.1928 |     38.321 |     1.3
   37 |   0.9372 |     31.107 |   1.1475 |     36.648 |     1.3
   38 |   0.9206 |     30.864 |   1.1401 |     36.493 |     1.4
   39 |   0.9053 |     30.236 |   1.1503 |     36.029 |     1.4
   40 |   0.8867 |     29.630 |   1.1255 |     35.626 |     1.4
   41 |   0.8769 |     29.304 |   1.1234 |     35.719 |     1.5
   42 |   0.8556 |     28.621 |   1.1320 |     35.688 |     1.5
   43 |   0.8580 |     28.764 |   1.1216 |     35.223 |     1.5
   44 |   0.8539 |     28.500 |   1.1305 |     35.843 |     1.6
   45 |   0.8403 |     27.921 |   1.1259 |     35.347 |     1.6
   46 |   0.8258 |     27.386 |   1.1092 |     35.130 |     1.7
   47 |   0.8172 |     27.122 |   1.1101 |     34.665 |     1.7
   48 |   0.8075 |     27.028 |   1.1291 |     35.750 |     1.7
   49 |   0.7875 |     26.003 |   1.1349 |     35.533 |     1.8
   50 |   0.7752 |     26.102 |   1.1106 |     33.798 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,122,274

Training started
X_train.shape: torch.Size([3024, 702])
Y_train.shape: torch.Size([3024, 7])
X_dev.shape: torch.Size([538, 295])
Y_dev.shape: torch.Size([538, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6141 |     70.855 |   2.0418 |     59.851 |     0.5
    2 |   1.7813 |     50.755 |   1.5739 |     46.344 |     1.0
    3 |   1.5003 |     45.949 |   1.4570 |     46.344 |     1.5
    4 |   1.4347 |     45.955 |   1.4267 |     46.344 |     2.0
    5 |   1.4147 |     46.026 |   1.4112 |     46.344 |     2.5
    6 |   1.4032 |     46.026 |   1.4021 |     46.344 |     3.0
    7 |   1.3966 |     45.944 |   1.3996 |     46.344 |     3.5
    8 |   1.3907 |     45.933 |   1.3935 |     47.181 |     4.0
    9 |   1.3821 |     45.536 |   1.3796 |     45.384 |     4.5
   10 |   1.3617 |     44.737 |   1.3587 |     45.477 |     5.0
   11 |   1.3445 |     44.643 |   1.3513 |     45.601 |     5.6
   12 |   1.3339 |     44.406 |   1.3466 |     45.415 |     6.1
   13 |   1.3284 |     44.560 |   1.3379 |     45.229 |     6.6
   14 |   1.3216 |     44.285 |   1.3383 |     45.663 |     7.1
   15 |   1.3145 |     44.163 |   1.3316 |     45.105 |     7.6
   16 |   1.3083 |     43.976 |   1.3320 |     45.539 |     8.1
   17 |   1.3063 |     43.948 |   1.3267 |     44.950 |     8.6
   18 |   1.2993 |     43.706 |   1.3259 |     44.888 |     9.1
   19 |   1.2944 |     43.678 |   1.3179 |     45.415 |     9.6
   20 |   1.2905 |     43.706 |   1.3168 |     44.827 |    10.1
   21 |   1.2828 |     43.574 |   1.3063 |     44.610 |    10.7
   22 |   1.2771 |     43.397 |   1.3059 |     43.959 |    11.2
