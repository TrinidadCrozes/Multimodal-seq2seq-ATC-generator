{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a67c3-3164-402b-9c3d-ed5f98d41c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))\n",
    "from seq2seq import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multimodalbilstm_hyp import hyperparametersselection\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566324b4-cf15-44bc-9f49-c6c019367e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa18d3e-cd26-4b6a-85c0-cc550fb60feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string that simulates a list to a real list\n",
    "def convert_string_list(element):\n",
    "    # Delete [] of the string\n",
    "    element = element[0:len(element)]\n",
    "    # Create a list that contains each code as e.g. 'A'\n",
    "    ATC_list = list(element.split('; '))\n",
    "    for index, code in enumerate(ATC_list):\n",
    "        # Delete '' of the code\n",
    "        ATC_list[index] = code[0:len(code)]\n",
    "    return ATC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e165f52-d611-4847-a003-d336dd9fe491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicate_rows(df):\n",
    "    # Duplicate each compound the number of ATC codes associated to it, copying its SMILES in new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        atc_codes = row['ATC Codes']\n",
    "        atc_codes_list = convert_string_list(atc_codes)\n",
    "        \n",
    "        if len(atc_codes_list) > 1:\n",
    "            for code in atc_codes_list:\n",
    "                if len(code) == 5:\n",
    "                    new_row = row.copy()\n",
    "                    new_row['ATC Codes'] = code\n",
    "                    new_rows.append(new_row)\n",
    "        else:\n",
    "            if len(atc_codes_list[0]) == 5:\n",
    "                new_rows.append(row)\n",
    "    \n",
    "    new_set = pd.DataFrame(new_rows)\n",
    "    new_set = new_set.reset_index(drop=True)\n",
    "\n",
    "    return new_set\n",
    "\n",
    "def extract_descriptors(df):\n",
    "    \"\"\"\n",
    "    Extract molecular descriptors from your dataset.\n",
    "    You'll need to implement this based on your descriptor source.\n",
    "    \n",
    "    Returns FloatTensor of shape (n_molecules, descriptor_dimension)\n",
    "    \"\"\"\n",
    "    descriptors = df.iloc[:, 2:-5].values\n",
    "    # Convert to numpy for easier handling\n",
    "    if isinstance(descriptors, torch.Tensor):\n",
    "        desc_array = descriptors.numpy()\n",
    "    else:\n",
    "        desc_array = np.array(descriptors)\n",
    "    \n",
    "    # Replace infinite values with NaN first\n",
    "    desc_array[np.isinf(desc_array)] = np.nan\n",
    "    \n",
    "    # Calculate median for each feature (column-wise)\n",
    "    medians = np.nanmedian(desc_array, axis=0)\n",
    "    \n",
    "    # Replace NaN values with corresponding median\n",
    "    for i in range(desc_array.shape[1]):\n",
    "        mask = np.isnan(desc_array[:, i])\n",
    "        desc_array[mask, i] = medians[i]\n",
    "    return torch.tensor(desc_array, dtype=torch.float32)\n",
    "    \n",
    "# Create vocabularies\n",
    "# Tokenize the data\n",
    "def source(df):\n",
    "    source = []\n",
    "    for compound in df['Neutralized SMILES']:\n",
    "        # A list containing each SMILES character separated\n",
    "        source.append(list(compound))\n",
    "    return source\n",
    "def target(df):\n",
    "    target = []\n",
    "    for codes in df['ATC Codes']:  \n",
    "        code = convert_string_list(codes) \n",
    "        # A list of lists, each one containing each ATC code character separated \n",
    "        for c in code:\n",
    "            list_c = list(c)\n",
    "            target.append(list_c)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3256e6-ad40-454b-80a0-e415b76ab19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Encoder embedding dimension: 64\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 64\n",
      "Encoder hidden units: 32\n",
      "Encoder layers: 4\n",
      "Decoder hidden units: 128\n",
      "Decoder layers: 3\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 700,834\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3024, 702])\n",
      "Y_train.shape: torch.Size([3024, 7])\n",
      "X_dev.shape: torch.Size([538, 295])\n",
      "Y_dev.shape: torch.Size([538, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.2379 |     61.012 |   1.6209 |     47.088 |     0.0\n",
      "    2 |   1.4786 |     45.955 |   1.4095 |     46.344 |     0.0\n",
      "    3 |   1.3892 |     45.420 |   1.3673 |     45.260 |     0.1\n",
      "    4 |   1.3287 |     43.816 |   1.3183 |     44.021 |     0.1\n",
      "    5 |   1.2820 |     42.317 |   1.2832 |     41.945 |     0.1\n",
      "    6 |   1.2331 |     40.669 |   1.2409 |     41.698 |     0.1\n",
      "    7 |   1.1918 |     39.561 |   1.2147 |     40.551 |     0.2\n",
      "    8 |   1.1545 |     38.470 |   1.1846 |     39.870 |     0.2\n",
      "    9 |   1.1174 |     37.346 |   1.1651 |     39.405 |     0.2\n",
      "   10 |   1.0731 |     36.045 |   1.1540 |     38.104 |     0.2\n",
      "   11 |   1.0340 |     34.959 |   1.1281 |     37.144 |     0.2\n",
      "   12 |   0.9944 |     33.372 |   1.0849 |     35.936 |     0.3\n",
      "   13 |   0.9463 |     31.603 |   1.0709 |     35.223 |     0.3\n",
      "   14 |   0.9052 |     29.845 |   1.0713 |     35.099 |     0.3\n",
      "   15 |   0.8659 |     28.500 |   1.0412 |     33.271 |     0.3\n",
      "   16 |   0.8177 |     26.659 |   1.0436 |     33.736 |     0.3\n",
      "   17 |   0.7796 |     25.281 |   1.0220 |     33.271 |     0.4\n",
      "   18 |   0.7337 |     23.550 |   1.0251 |     32.528 |     0.4\n",
      "   19 |   0.6914 |     22.388 |   1.0057 |     31.320 |     0.4\n",
      "   20 |   0.6435 |     20.685 |   0.9965 |     30.731 |     0.4\n",
      "   21 |   0.6108 |     19.367 |   1.0013 |     30.173 |     0.4\n",
      "   22 |   0.5717 |     18.304 |   1.0264 |     30.421 |     0.5\n",
      "   23 |   0.5376 |     16.937 |   1.0461 |     30.390 |     0.5\n",
      "   24 |   0.5062 |     15.978 |   1.0453 |     30.297 |     0.5\n",
      "Early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trini\\AppData\\Local\\Temp\\ipykernel_18064\\4247647854.py:193: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Encoder embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 128\n",
      "Encoder hidden units: 32\n",
      "Encoder layers: 3\n",
      "Decoder hidden units: 128\n",
      "Decoder layers: 3\n",
      "Dropout: 0.2\n",
      "Trainable parameters: 669,954\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3028, 649])\n",
      "Y_train.shape: torch.Size([3028, 7])\n",
      "X_dev.shape: torch.Size([534, 702])\n",
      "Y_dev.shape: torch.Size([534, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.1896 |     59.616 |   1.5852 |     45.350 |     0.0\n",
      "    2 |   1.4617 |     46.186 |   1.3880 |     45.318 |     0.0\n",
      "    3 |   1.3674 |     45.767 |   1.3320 |     44.507 |     0.1\n",
      "    4 |   1.3211 |     44.721 |   1.2850 |     43.071 |     0.1\n",
      "    5 |   1.2829 |     44.199 |   1.2613 |     42.697 |     0.1\n",
      "    6 |   1.2528 |     43.274 |   1.2550 |     41.729 |     0.1\n",
      "    7 |   1.2173 |     41.595 |   1.2010 |     39.451 |     0.1\n",
      "    8 |   1.1701 |     39.564 |   1.1598 |     38.015 |     0.2\n",
      "    9 |   1.1201 |     37.852 |   1.1263 |     36.517 |     0.2\n",
      "   10 |   1.0807 |     36.669 |   1.0844 |     35.955 |     0.2\n",
      "   11 |   1.0344 |     35.001 |   1.0611 |     34.956 |     0.2\n",
      "   12 |   0.9931 |     33.317 |   1.0338 |     33.989 |     0.2\n",
      "   13 |   0.9458 |     31.666 |   1.0100 |     32.834 |     0.3\n",
      "   14 |   0.9165 |     30.471 |   1.0005 |     33.021 |     0.3\n",
      "   15 |   0.8727 |     28.820 |   0.9785 |     31.586 |     0.3\n",
      "   16 |   0.8352 |     27.246 |   0.9484 |     30.680 |     0.3\n",
      "   17 |   0.7986 |     25.974 |   0.9434 |     30.119 |     0.3\n",
      "   18 |   0.7632 |     24.444 |   0.9250 |     29.182 |     0.4\n",
      "   19 |   0.7282 |     23.707 |   0.9141 |     28.527 |     0.4\n",
      "   20 |   0.6980 |     22.490 |   0.9146 |     28.589 |     0.4\n",
      "   21 |   0.6637 |     21.202 |   0.9124 |     27.809 |     0.4\n",
      "   22 |   0.6443 |     20.707 |   0.9068 |     27.903 |     0.4\n",
      "   23 |   0.6078 |     19.710 |   0.8962 |     26.654 |     0.5\n",
      "   24 |   0.5881 |     18.830 |   0.8846 |     26.124 |     0.5\n",
      "   25 |   0.5750 |     18.169 |   0.9189 |     26.779 |     0.5\n",
      "   26 |   0.5462 |     17.520 |   0.8867 |     25.624 |     0.5\n",
      "   27 |   0.5327 |     17.019 |   0.8823 |     25.843 |     0.5\n",
      "   28 |   0.5115 |     16.402 |   0.8927 |     25.218 |     0.5\n",
      "   29 |   0.4900 |     15.709 |   0.9168 |     26.124 |     0.6\n",
      "   30 |   0.4698 |     14.955 |   0.8988 |     25.343 |     0.6\n",
      "   31 |   0.4548 |     14.647 |   0.8996 |     25.468 |     0.6\n",
      "Early stopping\n",
      "\n",
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 44 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Encoder embedding dimension: 64\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 32\n",
      "Encoder hidden units: 64\n",
      "Encoder layers: 3\n",
      "Decoder hidden units: 128\n",
      "Decoder layers: 2\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 842,018\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3021, 702])\n",
      "Y_train.shape: torch.Size([3021, 7])\n",
      "X_dev.shape: torch.Size([541, 250])\n",
      "Y_dev.shape: torch.Size([541, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.2652 |     61.707 |   1.6905 |     50.370 |     0.0\n",
      "    2 |   1.5058 |     45.962 |   1.4105 |     44.455 |     0.1\n",
      "    3 |   1.3676 |     44.180 |   1.3209 |     43.161 |     0.1\n",
      "    4 |   1.3039 |     42.729 |   1.2761 |     41.836 |     0.1\n",
      "    5 |   1.2427 |     41.040 |   1.2379 |     41.158 |     0.1\n",
      "    6 |   1.1867 |     39.485 |   1.1897 |     39.895 |     0.2\n",
      "    7 |   1.1337 |     37.294 |   1.1461 |     37.307 |     0.2\n",
      "    8 |   1.0767 |     35.209 |   1.1141 |     36.383 |     0.2\n",
      "    9 |   1.0249 |     33.615 |   1.0833 |     35.521 |     0.2\n",
      "   10 |   0.9865 |     32.180 |   1.0521 |     34.258 |     0.3\n",
      "   11 |   0.9341 |     30.790 |   1.0379 |     33.765 |     0.3\n",
      "   12 |   0.8792 |     29.118 |   1.0091 |     32.224 |     0.3\n",
      "   13 |   0.8377 |     27.507 |   1.0004 |     31.670 |     0.4\n",
      "   14 |   0.8056 |     25.869 |   0.9830 |     31.238 |     0.4\n",
      "   15 |   0.7680 |     25.014 |   0.9849 |     31.670 |     0.4\n",
      "   16 |   0.7398 |     24.412 |   0.9783 |     31.608 |     0.4\n",
      "   17 |   0.6979 |     22.509 |   0.9632 |     31.146 |     0.5\n",
      "   18 |   0.6568 |     21.240 |   0.9669 |     30.838 |     0.5\n",
      "   19 |   0.6261 |     20.170 |   0.9430 |     29.328 |     0.5\n",
      "   20 |   0.5934 |     19.249 |   0.9593 |     29.698 |     0.5\n",
      "   21 |   0.5728 |     18.553 |   0.9387 |     29.174 |     0.6\n",
      "   22 |   0.5403 |     17.456 |   0.9614 |     29.698 |     0.6\n",
      "   23 |   0.5198 |     16.573 |   0.9744 |     29.113 |     0.6\n",
      "   24 |   0.4896 |     15.282 |   0.9661 |     29.051 |     0.7\n",
      "   25 |   0.4739 |     15.254 |   0.9604 |     28.651 |     0.7\n",
      "Early stopping\n",
      "\n",
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 43 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Encoder embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 64\n",
      "Encoder hidden units: 128\n",
      "Encoder layers: 2\n",
      "Decoder hidden units: 128\n",
      "Decoder layers: 4\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,654,818\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3042, 702])\n",
      "Y_train.shape: torch.Size([3042, 7])\n",
      "X_dev.shape: torch.Size([520, 467])\n",
      "Y_dev.shape: torch.Size([520, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.2911 |     63.489 |   1.6453 |     49.135 |     0.0\n",
      "    2 |   1.4807 |     46.165 |   1.4421 |     46.859 |     0.1\n",
      "    3 |   1.4137 |     46.220 |   1.4148 |     46.346 |     0.1\n",
      "    4 |   1.3938 |     46.077 |   1.4038 |     46.346 |     0.2\n",
      "    5 |   1.3877 |     46.017 |   1.3979 |     46.827 |     0.2\n",
      "    6 |   1.3876 |     46.159 |   1.4049 |     46.346 |     0.2\n",
      "    7 |   1.3830 |     46.050 |   1.3990 |     46.827 |     0.3\n",
      "    8 |   1.3789 |     46.055 |   1.3872 |     46.346 |     0.3\n",
      "    9 |   1.3727 |     46.099 |   1.3823 |     46.346 |     0.4\n",
      "   10 |   1.3513 |     45.666 |   1.3617 |     45.224 |     0.4\n",
      "   11 |   1.3315 |     44.587 |   1.3393 |     44.968 |     0.5\n",
      "   12 |   1.3153 |     44.368 |   1.3330 |     44.840 |     0.5\n",
      "   13 |   1.3053 |     43.754 |   1.3240 |     43.558 |     0.5\n",
      "   14 |   1.2899 |     43.162 |   1.3094 |     43.269 |     0.6\n",
      "   15 |   1.2761 |     42.949 |   1.3014 |     42.788 |     0.6\n",
      "   16 |   1.2620 |     42.527 |   1.2992 |     42.756 |     0.7\n",
      "   17 |   1.2473 |     42.258 |   1.2871 |     42.853 |     0.7\n",
      "   18 |   1.2431 |     42.132 |   1.2734 |     42.949 |     0.7\n",
      "   19 |   1.2261 |     41.864 |   1.2659 |     42.821 |     0.8\n",
      "   20 |   1.2180 |     41.667 |   1.2700 |     42.468 |     0.8\n",
      "   21 |   1.2122 |     41.639 |   1.2781 |     42.692 |     0.9\n",
      "   22 |   1.2263 |     41.623 |   1.2723 |     42.564 |     0.9\n",
      "   23 |   1.1898 |     41.185 |   1.2471 |     42.468 |     0.9\n",
      "   24 |   1.1827 |     41.228 |   1.2415 |     41.891 |     1.0\n",
      "   25 |   1.1793 |     40.768 |   1.2381 |     41.795 |     1.0\n",
      "   26 |   1.1689 |     40.565 |   1.2405 |     40.641 |     1.1\n",
      "   27 |   1.1591 |     40.045 |   1.2360 |     42.308 |     1.1\n",
      "   28 |   1.1519 |     39.782 |   1.2211 |     41.058 |     1.2\n",
      "   29 |   1.1317 |     38.905 |   1.2190 |     40.929 |     1.2\n",
      "   30 |   1.1214 |     38.719 |   1.1996 |     39.840 |     1.2\n",
      "   31 |   1.1345 |     38.757 |   1.2053 |     40.353 |     1.3\n",
      "   32 |   1.1031 |     37.864 |   1.1906 |     39.487 |     1.3\n",
      "   33 |   1.0913 |     37.037 |   1.1892 |     39.359 |     1.4\n",
      "   34 |   1.1133 |     38.051 |   1.1726 |     38.462 |     1.4\n",
      "   35 |   1.0761 |     36.686 |   1.1800 |     38.333 |     1.4\n",
      "   36 |   1.0786 |     36.769 |   1.1860 |     38.846 |     1.5\n",
      "   37 |   1.0485 |     35.651 |   1.1948 |     38.814 |     1.5\n",
      "   38 |   1.0413 |     35.454 |   1.1715 |     38.365 |     1.6\n",
      "   39 |   1.0375 |     35.202 |   1.1708 |     37.276 |     1.6\n",
      "   40 |   1.0216 |     34.144 |   1.1649 |     37.756 |     1.7\n",
      "   41 |   1.0386 |     35.300 |   1.1606 |     37.853 |     1.7\n",
      "   42 |   1.0000 |     33.848 |   1.1258 |     36.282 |     1.7\n",
      "   43 |   0.9996 |     33.536 |   1.1571 |     36.090 |     1.8\n",
      "   44 |   0.9727 |     32.796 |   1.1582 |     37.756 |     1.8\n",
      "   45 |   0.9503 |     32.161 |   1.1458 |     37.212 |     1.9\n",
      "   46 |   0.9365 |     31.481 |   1.1472 |     36.859 |     1.9\n",
      "Early stopping\n",
      "\n",
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Encoder embedding dimension: 32\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 128\n",
      "Encoder hidden units: 32\n",
      "Encoder layers: 2\n",
      "Decoder hidden units: 64\n",
      "Decoder layers: 3\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 259,490\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3027, 702])\n",
      "Y_train.shape: torch.Size([3027, 7])\n",
      "X_dev.shape: torch.Size([535, 258])\n",
      "Y_dev.shape: torch.Size([535, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.5746 |     68.957 |   1.9913 |     54.611 |     0.0\n",
      "    2 |   1.7264 |     49.014 |   1.5413 |     45.763 |     0.0\n",
      "    3 |   1.4776 |     46.036 |   1.4447 |     45.763 |     0.0\n",
      "    4 |   1.4157 |     46.140 |   1.3982 |     45.763 |     0.1\n",
      "    5 |   1.3730 |     45.320 |   1.3573 |     44.579 |     0.1\n",
      "    6 |   1.3352 |     44.180 |   1.3255 |     43.738 |     0.1\n",
      "    7 |   1.3022 |     43.723 |   1.3136 |     43.769 |     0.1\n",
      "    8 |   1.2719 |     42.897 |   1.2706 |     42.399 |     0.1\n",
      "    9 |   1.2327 |     41.824 |   1.2566 |     42.679 |     0.1\n",
      "   10 |   1.1964 |     40.040 |   1.2222 |     40.467 |     0.1\n",
      "   11 |   1.1522 |     38.597 |   1.2012 |     40.000 |     0.1\n",
      "   12 |   1.1181 |     37.711 |   1.1689 |     39.813 |     0.2\n",
      "   13 |   1.0798 |     36.692 |   1.1561 |     38.692 |     0.2\n",
      "   14 |   1.0562 |     35.965 |   1.1424 |     38.536 |     0.2\n",
      "   15 |   1.0198 |     34.616 |   1.1269 |     37.072 |     0.2\n",
      "   16 |   0.9863 |     33.042 |   1.1101 |     37.290 |     0.2\n",
      "   17 |   0.9553 |     31.885 |   1.1100 |     36.916 |     0.2\n",
      "   18 |   0.9258 |     30.657 |   1.0892 |     36.168 |     0.2\n",
      "   19 |   0.8947 |     29.534 |   1.0789 |     35.389 |     0.3\n",
      "   20 |   0.8720 |     28.774 |   1.0807 |     35.296 |     0.3\n",
      "   21 |   0.8438 |     27.921 |   1.0744 |     34.766 |     0.3\n",
      "   22 |   0.8188 |     27.056 |   1.0639 |     34.673 |     0.3\n",
      "   23 |   0.7930 |     26.087 |   1.0787 |     34.268 |     0.3\n",
      "   24 |   0.7646 |     24.744 |   1.0804 |     33.489 |     0.3\n",
      "   25 |   0.7337 |     23.863 |   1.0528 |     32.991 |     0.3\n",
      "   26 |   0.7202 |     23.263 |   1.0512 |     31.620 |     0.3\n",
      "   27 |   0.6940 |     22.052 |   1.0822 |     32.741 |     0.4\n",
      "   28 |   0.6852 |     21.985 |   1.0663 |     32.430 |     0.4\n",
      "   29 |   0.6574 |     21.000 |   1.0826 |     32.025 |     0.4\n",
      "   30 |   0.6393 |     20.570 |   1.0641 |     31.558 |     0.4\n",
      "Early stopping\n",
      "\n",
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Encoder embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 32\n",
      "Encoder hidden units: 64\n",
      "Encoder layers: 3\n",
      "Decoder hidden units: 128\n",
      "Decoder layers: 2\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 877,730\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3025, 702])\n",
      "Y_train.shape: torch.Size([3025, 7])\n",
      "X_dev.shape: torch.Size([537, 467])\n",
      "Y_dev.shape: torch.Size([537, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.1954 |     59.851 |   1.5821 |     46.182 |     0.7\n",
      "    2 |   1.4581 |     45.240 |   1.3889 |     45.282 |     1.5\n",
      "    3 |   1.3366 |     42.992 |   1.3068 |     42.644 |     2.2\n",
      "    4 |   1.2594 |     40.992 |   1.2365 |     40.627 |     2.9\n",
      "    5 |   1.1858 |     38.931 |   1.1879 |     39.168 |     3.7\n",
      "    6 |   1.1143 |     36.270 |   1.1556 |     37.337 |     4.4\n",
      "    7 |   1.0568 |     34.331 |   1.1161 |     36.747 |     5.2\n",
      "    8 |   1.0047 |     33.036 |   1.0938 |     35.475 |     5.9\n",
      "    9 |   0.9539 |     31.030 |   1.0590 |     34.606 |     6.7\n",
      "   10 |   0.9012 |     29.229 |   1.0411 |     33.333 |     7.4\n",
      "   11 |   0.8561 |     28.022 |   1.0394 |     33.302 |     8.1\n",
      "   12 |   0.8036 |     26.132 |   1.0284 |     33.302 |     8.9\n",
      "   13 |   0.7578 |     24.331 |   1.0305 |     31.968 |     9.6\n",
      "   14 |   0.7174 |     23.069 |   1.0140 |     31.782 |    10.4\n",
      "   15 |   0.6766 |     21.499 |   1.0089 |     31.378 |    11.1\n",
      "   16 |   0.6465 |     20.656 |   1.0084 |     31.099 |    11.9\n",
      "   17 |   0.6171 |     19.741 |   1.0209 |     30.726 |    12.6\n",
      "   18 |   0.5699 |     18.088 |   1.0058 |     31.130 |    13.3\n",
      "   19 |   0.5377 |     17.234 |   1.0122 |     30.323 |    14.1\n",
      "   20 |   0.4991 |     15.598 |   0.9985 |     29.392 |    14.8\n",
      "   21 |   0.4786 |     15.311 |   1.0302 |     29.609 |    15.6\n",
      "   22 |   0.4510 |     14.083 |   1.0215 |     28.864 |    16.3\n",
      "   23 |   0.4235 |     13.355 |   1.0539 |     29.268 |    17.0\n",
      "   24 |   0.3975 |     12.336 |   1.0284 |     29.081 |    17.8\n",
      "Early stopping\n",
      "\n",
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Encoder embedding dimension: 128\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 64\n",
      "Encoder hidden units: 128\n",
      "Encoder layers: 2\n",
      "Decoder hidden units: 128\n",
      "Decoder layers: 3\n",
      "Dropout: 0.0\n",
      "Trainable parameters: 1,522,978\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3038, 702])\n",
      "Y_train.shape: torch.Size([3038, 7])\n",
      "X_dev.shape: torch.Size([524, 221])\n",
      "Y_dev.shape: torch.Size([524, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 1e-05\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.2093 |     60.550 |   1.6192 |     45.802 |     0.0\n",
      "    2 |   1.4879 |     46.231 |   1.4181 |     45.802 |     0.1\n",
      "    3 |   1.4122 |     46.198 |   1.3901 |     45.802 |     0.1\n",
      "    4 |   1.3967 |     46.269 |   1.3853 |     45.802 |     0.2\n",
      "    5 |   1.3875 |     46.039 |   1.3823 |     46.597 |     0.2\n",
      "    6 |   1.3746 |     45.529 |   1.3507 |     44.275 |     0.3\n",
      "    7 |   1.3479 |     44.607 |   1.3316 |     44.497 |     0.3\n",
      "    8 |   1.3235 |     43.718 |   1.3089 |     43.352 |     0.3\n",
      "    9 |   1.3027 |     43.625 |   1.3036 |     43.130 |     0.4\n",
      "   10 |   1.2962 |     43.400 |   1.2786 |     41.953 |     0.4\n",
      "   11 |   1.2777 |     42.835 |   1.2787 |     42.366 |     0.5\n",
      "   12 |   1.2671 |     42.544 |   1.2726 |     42.971 |     0.5\n",
      "   13 |   1.2523 |     41.985 |   1.2571 |     41.539 |     0.5\n",
      "   14 |   1.2418 |     41.760 |   1.2551 |     41.508 |     0.6\n",
      "   15 |   1.2243 |     41.211 |   1.2497 |     41.380 |     0.6\n",
      "   16 |   1.2095 |     40.822 |   1.2305 |     41.221 |     0.7\n",
      "   17 |   1.1876 |     40.388 |   1.2126 |     40.458 |     0.7\n",
      "   18 |   1.1846 |     40.487 |   1.2235 |     40.553 |     0.8\n",
      "   19 |   1.1778 |     40.312 |   1.1911 |     39.758 |     0.8\n",
      "   20 |   1.1599 |     39.812 |   1.1942 |     39.981 |     0.8\n",
      "   21 |   1.1370 |     38.929 |   1.1904 |     40.235 |     0.9\n",
      "   22 |   1.1223 |     38.556 |   1.1736 |     39.822 |     0.9\n",
      "   23 |   1.1046 |     37.722 |   1.1820 |     38.740 |     1.0\n",
      "   24 |   1.0860 |     37.355 |   1.1750 |     39.059 |     1.0\n",
      "   25 |   1.0754 |     36.581 |   1.1767 |     38.868 |     1.0\n",
      "   26 |   1.0559 |     36.005 |   1.1491 |     37.150 |     1.1\n",
      "   27 |   1.0385 |     35.336 |   1.1482 |     37.405 |     1.1\n",
      "   28 |   1.0190 |     34.463 |   1.1420 |     37.564 |     1.2\n",
      "   29 |   0.9997 |     33.898 |   1.1134 |     35.814 |     1.2\n",
      "   30 |   0.9812 |     33.564 |   1.1352 |     36.450 |     1.2\n",
      "   31 |   0.9714 |     32.883 |   1.1163 |     36.132 |     1.3\n",
      "   32 |   0.9509 |     32.121 |   1.1088 |     35.337 |     1.3\n",
      "   33 |   0.9205 |     31.090 |   1.1014 |     35.146 |     1.4\n",
      "   34 |   0.9108 |     30.481 |   1.0962 |     34.892 |     1.4\n",
      "   35 |   0.8960 |     29.921 |   1.0862 |     34.097 |     1.5\n",
      "   36 |   0.8694 |     29.257 |   1.0839 |     33.906 |     1.5\n",
      "   37 |   0.8453 |     28.292 |   1.0864 |     34.447 |     1.5\n",
      "   38 |   0.8194 |     27.063 |   1.0859 |     34.001 |     1.6\n",
      "   39 |   0.8037 |     26.536 |   1.0886 |     34.128 |     1.6\n",
      "   40 |   0.7851 |     26.092 |   1.0568 |     32.538 |     1.7\n",
      "   41 |   0.7667 |     25.669 |   1.0752 |     32.793 |     1.7\n",
      "   42 |   0.7467 |     24.654 |   1.0693 |     32.316 |     1.7\n",
      "   43 |   0.7286 |     24.457 |   1.0928 |     33.492 |     1.8\n",
      "   44 |   0.7204 |     23.853 |   1.0719 |     31.902 |     1.8\n",
      "Early stopping\n",
      "\n",
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 33 items>\n",
      "Encoder embedding dimension: 64\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 64\n",
      "Encoder hidden units: 128\n",
      "Encoder layers: 2\n",
      "Decoder hidden units: 128\n",
      "Decoder layers: 2\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 1,322,337\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3025, 702])\n",
      "Y_train.shape: torch.Size([3025, 7])\n",
      "X_dev.shape: torch.Size([537, 337])\n",
      "Y_dev.shape: torch.Size([537, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.2043 |     60.039 |   1.6368 |     47.331 |     0.0\n",
      "    2 |   1.4675 |     45.003 |   1.3888 |     46.027 |     0.1\n",
      "    3 |   1.3368 |     43.846 |   1.3070 |     44.072 |     0.1\n",
      "    4 |   1.2713 |     41.725 |   1.2634 |     42.955 |     0.2\n",
      "    5 |   1.2215 |     40.198 |   1.2132 |     39.634 |     0.2\n",
      "    6 |   1.1654 |     38.397 |   1.1682 |     38.454 |     0.2\n",
      "    7 |   1.1222 |     36.788 |   1.1264 |     37.989 |     0.3\n",
      "    8 |   1.0737 |     35.554 |   1.1007 |     35.692 |     0.3\n",
      "    9 |   1.0283 |     33.625 |   1.0765 |     35.754 |     0.4\n",
      "   10 |   0.9809 |     32.358 |   1.0453 |     34.947 |     0.4\n",
      "   11 |   0.9300 |     30.430 |   1.0257 |     32.899 |     0.4\n",
      "   12 |   0.8950 |     29.614 |   0.9940 |     32.464 |     0.5\n",
      "   13 |   0.8644 |     28.523 |   0.9665 |     31.440 |     0.5\n",
      "   14 |   0.8079 |     26.722 |   0.9686 |     31.316 |     0.6\n",
      "   15 |   0.7718 |     25.350 |   0.9709 |     31.068 |     0.6\n",
      "   16 |   0.7368 |     24.116 |   0.9444 |     30.168 |     0.7\n",
      "   17 |   0.7053 |     23.201 |   0.9538 |     29.919 |     0.7\n",
      "   18 |   0.6781 |     22.143 |   0.9486 |     29.423 |     0.7\n",
      "   19 |   0.6393 |     20.815 |   0.9505 |     29.795 |     0.8\n",
      "   20 |   0.6119 |     20.006 |   0.9184 |     28.212 |     0.8\n",
      "   21 |   0.5854 |     19.019 |   0.9211 |     28.740 |     0.9\n",
      "   22 |   0.5591 |     18.424 |   0.9166 |     27.623 |     0.9\n",
      "   23 |   0.5322 |     17.091 |   0.9232 |     28.895 |     0.9\n",
      "   24 |   0.5091 |     16.656 |   0.9127 |     27.498 |     1.0\n",
      "   25 |   0.5113 |     16.496 |   0.9399 |     28.243 |     1.0\n",
      "   26 |   0.4681 |     15.433 |   0.9236 |     27.840 |     1.1\n",
      "   27 |   0.4484 |     14.777 |   0.9199 |     26.878 |     1.1\n",
      "   28 |   0.4150 |     13.482 |   0.9274 |     27.343 |     1.1\n",
      "Early stopping\n",
      "\n",
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 45 items>\n",
      "Target index: <Seq2Seq Index with 33 items>\n",
      "Encoder embedding dimension: 64\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 32\n",
      "Encoder hidden units: 64\n",
      "Encoder layers: 2\n",
      "Decoder hidden units: 64\n",
      "Decoder layers: 4\n",
      "Dropout: 0.1\n",
      "Trainable parameters: 491,585\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3033, 702])\n",
      "Y_train.shape: torch.Size([3033, 7])\n",
      "X_dev.shape: torch.Size([529, 267])\n",
      "Y_dev.shape: torch.Size([529, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.6221 |     70.293 |   2.0654 |     58.727 |     0.0\n",
      "    2 |   1.7987 |     50.962 |   1.5791 |     45.432 |     0.0\n",
      "    3 |   1.5046 |     46.285 |   1.4504 |     45.432 |     0.1\n",
      "    4 |   1.4381 |     46.417 |   1.4231 |     45.432 |     0.1\n",
      "    5 |   1.4151 |     46.351 |   1.4075 |     45.432 |     0.1\n",
      "    6 |   1.4039 |     46.285 |   1.3959 |     45.432 |     0.1\n",
      "    7 |   1.3933 |     46.291 |   1.3819 |     45.432 |     0.1\n",
      "    8 |   1.3768 |     46.230 |   1.3620 |     44.928 |     0.1\n",
      "    9 |   1.3565 |     45.642 |   1.3400 |     45.022 |     0.2\n",
      "   10 |   1.3371 |     45.439 |   1.3288 |     44.739 |     0.2\n",
      "   11 |   1.3229 |     45.120 |   1.3154 |     44.455 |     0.2\n",
      "   12 |   1.3040 |     44.703 |   1.3026 |     43.762 |     0.2\n",
      "   13 |   1.2856 |     43.917 |   1.2694 |     42.092 |     0.2\n",
      "   14 |   1.2570 |     42.856 |   1.2570 |     42.376 |     0.2\n",
      "   15 |   1.2420 |     42.483 |   1.2482 |     41.934 |     0.3\n",
      "   16 |   1.2234 |     41.713 |   1.2299 |     40.674 |     0.3\n",
      "   17 |   1.2077 |     40.823 |   1.2099 |     39.887 |     0.3\n",
      "   18 |   1.1870 |     40.186 |   1.2014 |     39.918 |     0.3\n",
      "   19 |   1.1675 |     39.367 |   1.1865 |     39.445 |     0.3\n",
      "   20 |   1.1655 |     39.361 |   1.1885 |     39.698 |     0.3\n",
      "   21 |   1.1426 |     38.449 |   1.1709 |     38.595 |     0.4\n",
      "   22 |   1.1276 |     38.164 |   1.1755 |     38.626 |     0.4\n",
      "   23 |   1.1157 |     37.784 |   1.1566 |     38.689 |     0.4\n",
      "   24 |   1.1023 |     37.367 |   1.1612 |     38.563 |     0.4\n",
      "   25 |   1.0904 |     36.685 |   1.1476 |     38.280 |     0.4\n",
      "   26 |   1.0806 |     36.427 |   1.1380 |     38.437 |     0.4\n",
      "   27 |   1.0552 |     35.592 |   1.1428 |     37.744 |     0.5\n",
      "   28 |   1.0467 |     35.306 |   1.1334 |     37.146 |     0.5\n",
      "   29 |   1.0360 |     34.861 |   1.1374 |     37.587 |     0.5\n",
      "   30 |   1.0224 |     34.548 |   1.1182 |     36.641 |     0.5\n",
      "   31 |   1.0017 |     33.734 |   1.1329 |     37.524 |     0.5\n",
      "   32 |   1.0074 |     34.235 |   1.1055 |     35.507 |     0.5\n",
      "   33 |   0.9862 |     33.350 |   1.1087 |     36.767 |     0.6\n",
      "   34 |   0.9738 |     32.866 |   1.1135 |     36.169 |     0.6\n",
      "   35 |   0.9576 |     32.350 |   1.1070 |     36.043 |     0.6\n",
      "   36 |   0.9529 |     31.899 |   1.0992 |     35.444 |     0.6\n",
      "   37 |   0.9305 |     31.152 |   1.1122 |     35.948 |     0.6\n",
      "   38 |   0.9176 |     30.646 |   1.0953 |     34.846 |     0.6\n",
      "   39 |   0.9140 |     30.503 |   1.0998 |     35.066 |     0.7\n",
      "   40 |   0.8976 |     29.855 |   1.0965 |     35.098 |     0.7\n",
      "   41 |   0.8815 |     29.811 |   1.1011 |     35.035 |     0.7\n",
      "   42 |   0.8763 |     29.393 |   1.1201 |     36.169 |     0.7\n",
      "   43 |   0.8718 |     28.888 |   1.0863 |     35.224 |     0.7\n",
      "   44 |   0.8572 |     28.954 |   1.0865 |     34.058 |     0.7\n",
      "   45 |   0.8347 |     28.075 |   1.0792 |     33.365 |     0.8\n",
      "   46 |   0.8214 |     27.514 |   1.0730 |     33.680 |     0.8\n",
      "   47 |   0.8187 |     27.250 |   1.0928 |     34.058 |     0.8\n",
      "   48 |   0.8051 |     27.063 |   1.0795 |     33.396 |     0.8\n",
      "   49 |   0.8082 |     26.992 |   1.0845 |     33.617 |     0.8\n",
      "   50 |   0.7938 |     26.547 |   1.0972 |     33.774 |     0.9\n",
      "Early stopping\n",
      "\n",
      "Model: Seq2Seq Multimodal Bi-LSTM\n",
      "Source index: <Seq2Seq Index with 46 items>\n",
      "Target index: <Seq2Seq Index with 34 items>\n",
      "Encoder embedding dimension: 64\n",
      "Descriptors dimension: 1136\n",
      "Decoder embedding dimension: 128\n",
      "Encoder hidden units: 128\n",
      "Encoder layers: 3\n",
      "Decoder hidden units: 128\n",
      "Decoder layers: 3\n",
      "Dropout: 0.2\n",
      "Trainable parameters: 2,177,826\n",
      "\n",
      "Training started\n",
      "X_train.shape: torch.Size([3017, 702])\n",
      "Y_train.shape: torch.Size([3017, 7])\n",
      "X_dev.shape: torch.Size([545, 323])\n",
      "Y_dev.shape: torch.Size([545, 7])\n",
      "Epochs: 150\n",
      "Learning rate: 0.001\n",
      "Weight decay: 0.0001\n",
      "Epoch | Train                 | Development           | Minutes\n",
      "      | Loss     | Error Rate | Loss     | Error Rate |\n",
      "---------------------------------------------------------------\n",
      "    1 |   2.2170 |     60.883 |   1.5763 |     45.963 |     0.1\n",
      "    2 |   1.4755 |     46.221 |   1.3949 |     45.963 |     0.1\n",
      "    3 |   1.4045 |     46.282 |   1.3767 |     45.994 |     0.2\n",
      "    4 |   1.3781 |     45.824 |   1.3527 |     45.076 |     0.2\n",
      "    5 |   1.3449 |     44.630 |   1.3387 |     45.015 |     0.3\n",
      "    6 |   1.3245 |     44.222 |   1.3258 |     44.618 |     0.4\n",
      "    7 |   1.3006 |     43.642 |   1.2965 |     42.538 |     0.4\n",
      "    8 |   1.2765 |     42.454 |   1.2892 |     43.058 |     0.5\n",
      "    9 |   1.2525 |     41.708 |   1.2499 |     41.988 |     0.6\n",
      "   10 |   1.2261 |     41.111 |   1.2373 |     41.988 |     0.6\n",
      "   11 |   1.2018 |     40.316 |   1.2184 |     40.826 |     0.7\n",
      "   12 |   1.1818 |     39.813 |   1.2046 |     40.826 |     0.7\n",
      "   13 |   1.1598 |     39.239 |   1.2019 |     41.009 |     0.8\n",
      "   14 |   1.1428 |     38.924 |   1.1831 |     40.398 |     0.9\n",
      "   15 |   1.1282 |     38.532 |   1.1872 |     39.755 |     0.9\n",
      "   16 |   1.1068 |     38.095 |   1.1608 |     40.306 |     1.0\n",
      "   17 |   1.0909 |     37.366 |   1.1508 |     39.052 |     1.0\n",
      "   18 |   1.0650 |     36.250 |   1.1235 |     37.492 |     1.1\n",
      "   19 |   1.0373 |     35.488 |   1.1250 |     37.523 |     1.2\n",
      "   20 |   1.0256 |     34.687 |   1.1070 |     36.758 |     1.2\n",
      "   21 |   1.0060 |     34.317 |   1.0990 |     36.177 |     1.3\n",
      "   22 |   0.9815 |     33.322 |   1.0844 |     35.382 |     1.4\n",
      "   23 |   0.9549 |     31.996 |   1.0640 |     35.168 |     1.4\n",
      "   24 |   0.9328 |     31.444 |   1.0616 |     34.220 |     1.5\n",
      "   25 |   0.9193 |     31.019 |   1.0707 |     35.443 |     1.5\n",
      "   26 |   0.9084 |     30.759 |   1.0460 |     33.333 |     1.6\n",
      "   27 |   0.8730 |     29.450 |   1.0541 |     33.486 |     1.7\n",
      "   28 |   0.8629 |     29.279 |   1.0381 |     33.089 |     1.7\n",
      "   29 |   0.8499 |     28.527 |   1.0445 |     33.211 |     1.8\n",
      "   30 |   0.8196 |     27.461 |   1.0227 |     32.661 |     1.8\n",
      "   31 |   0.8107 |     27.334 |   1.0115 |     32.324 |     1.9\n",
      "   32 |   0.7781 |     26.450 |   1.0123 |     31.560 |     2.0\n",
      "   33 |   0.7611 |     25.240 |   1.0240 |     31.774 |     2.0\n",
      "   34 |   0.7565 |     25.351 |   1.0026 |     31.468 |     2.1\n",
      "   35 |   0.7307 |     24.263 |   1.0059 |     31.376 |     2.2\n",
      "   36 |   0.7782 |     25.561 |   1.1159 |     34.985 |     2.2\n",
      "   37 |   0.8670 |     29.218 |   1.0159 |     31.835 |     2.3\n",
      "   38 |   0.7454 |     24.727 |   0.9936 |     31.468 |     2.3\n",
      "   39 |   0.7141 |     23.793 |   1.0021 |     30.642 |     2.4\n",
      "   40 |   0.6839 |     22.859 |   0.9813 |     30.398 |     2.5\n",
      "   41 |   0.6719 |     22.207 |   0.9717 |     30.245 |     2.5\n",
      "   42 |   0.6528 |     21.616 |   1.0121 |     30.398 |     2.6\n",
      "   43 |   0.6313 |     21.031 |   0.9816 |     30.489 |     2.7\n",
      "   44 |   0.6140 |     20.462 |   0.9928 |     30.826 |     2.7\n",
      "   45 |   0.6040 |     20.125 |   0.9661 |     29.664 |     2.8\n",
      "   46 |   0.6007 |     19.998 |   0.9800 |     29.786 |     2.8\n",
      "   47 |   0.5793 |     19.390 |   0.9605 |     28.593 |     2.9\n",
      "   48 |   0.5808 |     19.672 |   0.9708 |     28.899 |     3.0\n",
      "   49 |   0.5747 |     19.202 |   0.9818 |     29.052 |     3.0\n",
      "   50 |   0.5605 |     18.584 |   0.9769 |     28.563 |     3.1\n",
      "   51 |   0.5440 |     17.976 |   0.9573 |     28.349 |     3.1\n",
      "   52 |   0.5290 |     17.810 |   0.9832 |     28.869 |     3.2\n",
      "   53 |   0.5198 |     17.186 |   0.9715 |     28.563 |     3.3\n",
      "   54 |   0.5048 |     16.622 |   0.9745 |     28.930 |     3.3\n",
      "   55 |   0.5118 |     17.120 |   0.9650 |     28.502 |     3.4\n",
      "Early stopping\n",
      "\n",
      "Mean: Precision            0.088874\n",
      "Recall               0.233796\n",
      "F1                   0.125463\n",
      "Precision_level3     0.170018\n",
      "Recall_level3        0.429157\n",
      "F1_level3            0.236748\n",
      "Precision_level2     0.260359\n",
      "Recall_level2        0.576721\n",
      "F1_level2            0.342421\n",
      "Precision level 1    0.507008\n",
      "Precision level 2    0.745996\n",
      "Precision level 3    0.623500\n",
      "Precision level 4    0.436674\n",
      "Recall level 1       0.646158\n",
      "Recall level 2       0.813904\n",
      "Recall level 3       0.731138\n",
      "Recall level 4       0.591816\n",
      "dtype: float64\n",
      "Std: Precision            0.020123\n",
      "Recall               0.055807\n",
      "F1                   0.028997\n",
      "Precision_level3     0.026456\n",
      "Recall_level3        0.072380\n",
      "F1_level3            0.037853\n",
      "Precision_level2     0.033662\n",
      "Recall_level2        0.071131\n",
      "F1_level2            0.040990\n",
      "Precision level 1    0.068788\n",
      "Precision level 2    0.033291\n",
      "Precision level 3    0.032567\n",
      "Precision level 4    0.070223\n",
      "Recall level 1       0.060544\n",
      "Recall level 2       0.035847\n",
      "Recall level 3       0.038950\n",
      "Recall level 4       0.052910\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 47899, 2025, 1, 20, 99, 1020, 345, 78] \n",
    "columns = [\n",
    "    'Seed', \n",
    "    'Precision', 'Recall', 'F1',\n",
    "    'Precision_level3', 'Recall_level3', 'F1_level3',\n",
    "    'Precision_level2', 'Recall_level2', 'F1_level2',\n",
    "    'Precision level 1', 'Precision level 2', 'Precision level 3', 'Precision level 4',\n",
    "    'Recall level 1', 'Recall level 2', 'Recall level 3', 'Recall level 4',\n",
    "    '#Compounds that have at least one match'\n",
    "]\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seeds(seed)\n",
    "\n",
    "    train_set = pd.read_csv(f'../Datasets/Rep_train_set{seed}.csv')\n",
    "    test_set = pd.read_csv(f'../Datasets/Rep_test_set{seed}.csv')\n",
    "    val_set = pd.read_csv(f'../Datasets/Rep_val_set{seed}.csv')\n",
    "    \n",
    "    new_train_set = multiplicate_rows(train_set)\n",
    "    new_val_set = multiplicate_rows(val_set)\n",
    "    new_test_set = multiplicate_rows(test_set)\n",
    "    \n",
    "    train_descriptors = extract_descriptors(new_train_set)\n",
    "    test_descriptors = extract_descriptors(new_test_set)\n",
    "    test_descriptors2 = extract_descriptors(test_set)\n",
    "    val_descriptors = extract_descriptors(new_val_set)\n",
    "    val_descriptors2 = extract_descriptors(val_set)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_descriptors = torch.tensor(scaler.fit_transform(train_descriptors.numpy()), dtype=torch.float32)\n",
    "    val_descriptors = torch.tensor(scaler.transform(val_descriptors.numpy()), dtype=torch.float32)\n",
    "    test_descriptors = torch.tensor(scaler.transform(test_descriptors.numpy()), dtype=torch.float32)\n",
    "    val_descriptors2 = torch.tensor(scaler.transform(val_descriptors2.numpy()), dtype=torch.float32)\n",
    "    test_descriptors2 = torch.tensor(scaler.transform(test_descriptors2.numpy()), dtype=torch.float32)\n",
    "    \n",
    "    source_train = source(new_train_set)\n",
    "    source_test = source(new_test_set)\n",
    "    # Test set without duplicated compounds\n",
    "    source_test2 = source(test_set)\n",
    "    source_val = source(new_val_set)\n",
    "    # Val set without duplicated compounds\n",
    "    source_val2 = source(val_set)\n",
    "    \n",
    "    target_train = target(new_train_set)\n",
    "    target_test = target(new_test_set)\n",
    "    target_val = target(new_val_set)\n",
    "    \n",
    "    # An Index object represents a mapping from the vocabulary to integers (indices) to feed into the models\n",
    "    source_index = index.Index(source_train)\n",
    "    target_index = index.Index(target_train)\n",
    "    \n",
    "    # Create tensors\n",
    "    X_train = source_index.text2tensor(source_train)\n",
    "    y_train = target_index.text2tensor(target_train)\n",
    "    X_val = source_index.text2tensor(source_val)\n",
    "    X_val2 = source_index.text2tensor(source_val2)\n",
    "    y_val = target_index.text2tensor(target_val)     \n",
    "    X_test = source_index.text2tensor(source_test)\n",
    "    X_test2 = source_index.text2tensor(source_test2)\n",
    "    y_test = target_index.text2tensor(target_test)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        X_train = X_train.to(\"cuda\")\n",
    "        y_train = y_train.to(\"cuda\")\n",
    "        train_descriptors = train_descriptors.to(\"cuda\") \n",
    "        test_descriptors = test_descriptors.to(\"cuda\")\n",
    "        test_descriptors2 = test_descriptors2.to(\"cuda\")\n",
    "        val_descriptors = val_descriptors.to(\"cuda\")\n",
    "        val_descriptors2 = val_descriptors2.to(\"cuda\")\n",
    "        X_val = X_val.to(\"cuda\")\n",
    "        X_val2 = X_val2.to(\"cuda\")\n",
    "        y_val = y_val.to(\"cuda\")\n",
    "        X_test= X_test.to(\"cuda\")\n",
    "        y_test = y_test.to(\"cuda\")\n",
    "        X_test2 = X_test2.to(\"cuda\")\n",
    "\n",
    "    if os.path.exists(f\"s_mmbilstm_results{seed}.csv\"):\n",
    "        best_hyperparameters = (pd.read_csv(f\"s_mmbilstm_results{seed}.csv\")).loc[0]\n",
    "    else:\n",
    "        best_hyperparameters = hyperparametersselection(seed, source_index, target_index, X_train, X_val, X_val2, train_descriptors, val_descriptors, val_descriptors2, y_train, y_val)\n",
    "\n",
    "    model = multimodal_models.MultimodalBiLSTM(\n",
    "                source_index, \n",
    "                target_index,\n",
    "                encoder_embedding_dimension = best_hyperparameters['encoder_embedding_dim'],\n",
    "                descriptors_dimension = train_descriptors.shape[1],\n",
    "                decoder_embedding_dimension = best_hyperparameters['decoder_embedding_dim'],\n",
    "                encoder_hidden_units = int(best_hyperparameters['enc_hidden_units']), \n",
    "                encoder_layers = best_hyperparameters['enc_layers'],\n",
    "                decoder_hidden_units = int(best_hyperparameters['dec_hidden_units']),\n",
    "                decoder_layers = best_hyperparameters['dec_layers'],\n",
    "                dropout = best_hyperparameters['dropout'])   \n",
    "    model.to(\"cuda\")\n",
    "    q = model.fit(X_train, \n",
    "            train_descriptors,\n",
    "            y_train,\n",
    "            X_val, \n",
    "            val_descriptors,\n",
    "            y_val, \n",
    "            batch_size = 32, \n",
    "            epochs = 150, \n",
    "            learning_rate = best_hyperparameters['learning_rate'], \n",
    "            weight_decay = best_hyperparameters['weight_decay'],\n",
    "            progress_bar = 0, \n",
    "            save_path = None)\n",
    "    model.load_state_dict(torch.load(\"best_multimodalmodel.pth\", weights_only=True))\n",
    "    loss, error_rate = model.evaluate(X_test, test_descriptors, y_test, batch_size = 32) \n",
    "\n",
    "    predictions, log_probabilities = search_algorithms.multimodal_beam_search(\n",
    "        model, \n",
    "        X_test2, # Make predictions with test set \n",
    "        test_descriptors2,\n",
    "        predictions = 6, # max length of the predicted sequence\n",
    "        beam_width = 10,\n",
    "        batch_size = 32, \n",
    "        progress_bar = 0\n",
    "    )\n",
    "    output_beam = [target_index.tensor2text(p) for p in predictions]\n",
    "\n",
    "    predictions_clean = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            if len(clean_pred) == 5:\n",
    "                interm.append(clean_pred)\n",
    "            if len(interm) == 3:\n",
    "                break\n",
    "        predictions_clean.append(interm)\n",
    "    predictions_clean_level3 = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            pred_3 = clean_pred[0:4]\n",
    "            if len(pred_3) == 4 and pred_3 not in interm:\n",
    "                interm.append(pred_3)\n",
    "        predictions_clean_level3.append(interm[0:3])\n",
    "    predictions_clean_level2 = []\n",
    "    for preds in output_beam:\n",
    "        interm = []\n",
    "        for pred in preds:\n",
    "            clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "            pred_2 = clean_pred[0:3]\n",
    "            if len(pred_2) == 3 and pred_2 not in interm:\n",
    "                interm.append(pred_2)\n",
    "        predictions_clean_level2.append(interm[0:3])\n",
    "    precision_1, precision_2, precision_3, precision_4 = defined_metrics.precision(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes')\n",
    "    recall_1, recall_2, recall_3, recall_4, counter_compound_match = defined_metrics.recall(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes')\n",
    "    precisions, recalls, f1s = defined_metrics.complete_metrics(predictions_clean, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_level3, recalls_level3, f1s_level3 = defined_metrics.complete_metrics_level3(predictions_clean_level3, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_level2, recalls_level2, f1s_level2 = defined_metrics.complete_metrics_level2(predictions_clean_level2, f'../Datasets/Rep_test_set{seed}.csv', 'ATC Codes', 3)\n",
    "    precisions_average = sum(precisions)/len(precisions)\n",
    "    recalls_average = sum(recalls)/len(recalls)\n",
    "    f1s_average = sum(f1s)/len(f1s)\n",
    "\n",
    "    precisions_average_level3 = sum(precisions_level3)/len(precisions_level3)\n",
    "    recalls_average_level3 = sum(recalls_level3)/len(recalls_level3)\n",
    "    f1s_average_level3 = sum(f1s_level3)/len(f1s_level3)\n",
    "\n",
    "    precisions_average_level2 = sum(precisions_level2)/len(precisions_level2)\n",
    "    recalls_average_level2 = sum(recalls_level2)/len(recalls_level2)\n",
    "    f1s_average_level2 = sum(f1s_level2)/len(f1s_level2)\n",
    "    \n",
    "    metrics = {\n",
    "        'Precision': precisions_average, \n",
    "        'Recall': recalls_average,\n",
    "        'F1': f1s_average,\n",
    "        'Precision_level3': precisions_average_level3, \n",
    "        'Recall_level3': recalls_average_level3,\n",
    "        'F1_level3': f1s_average_level3,\n",
    "        'Precision_level2': precisions_average_level2, \n",
    "        'Recall_level2': recalls_average_level2,\n",
    "        'F1_level2': f1s_average_level2,\n",
    "        'Precision level 1': precision_1,\n",
    "        'Precision level 2': precision_2,\n",
    "        'Precision level 3': precision_3,\n",
    "        'Precision level 4': precision_4,\n",
    "        'Recall level 1': recall_1,\n",
    "        'Recall level 2': recall_2,\n",
    "        'Recall level 3': recall_3,\n",
    "        'Recall level 4': recall_4,\n",
    "        '#Compounds that have at least one match': counter_compound_match\n",
    "    }\n",
    "    \n",
    "    # Build the row\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "metrics_df.to_csv(\"multimodalbilstm_metrics.csv\", index=False)\n",
    "print(\"Mean:\", metrics_df.mean(numeric_only=True))\n",
    "print(\"Std:\", metrics_df.std(numeric_only=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
