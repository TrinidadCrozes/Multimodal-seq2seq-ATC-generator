Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 2,177,826

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2166 |     59.684 |   1.5736 |     45.963 |     0.1
    2 |   1.4773 |     46.111 |   1.3995 |     45.963 |     0.1
    3 |   1.4127 |     46.188 |   1.3789 |     45.963 |     0.2
    4 |   1.3930 |     46.105 |   1.3619 |     46.024 |     0.2
    5 |   1.3700 |     45.321 |   1.3401 |     45.107 |     0.3
    6 |   1.3416 |     44.636 |   1.3390 |     44.648 |     0.4
    7 |   1.3209 |     44.398 |   1.3259 |     44.434 |     0.4
    8 |   1.2966 |     43.509 |   1.2935 |     43.884 |     0.5
    9 |   1.2668 |     42.946 |   1.2658 |     42.661 |     0.5
   10 |   1.2407 |     41.697 |   1.2306 |     42.202 |     0.6
   11 |   1.2151 |     41.327 |   1.2099 |     41.468 |     0.7
   12 |   1.1892 |     40.438 |   1.2030 |     40.183 |     0.7
   13 |   1.1650 |     39.940 |   1.2009 |     40.275 |     0.8
   14 |   1.1472 |     39.300 |   1.1894 |     40.642 |     0.8
   15 |   1.1185 |     38.327 |   1.1859 |     39.602 |     0.9
   16 |   1.0937 |     37.029 |   1.1358 |     38.746 |     1.0
   17 |   1.0770 |     36.742 |   1.1394 |     38.012 |     1.0
   18 |   1.0596 |     36.162 |   1.1407 |     37.125 |     1.1
   19 |   1.0306 |     34.775 |   1.1060 |     35.657 |     1.1
   20 |   1.0022 |     33.819 |   1.0977 |     35.902 |     1.2
   21 |   0.9856 |     33.494 |   1.0949 |     36.361 |     1.3
   22 |   0.9656 |     32.610 |   1.0837 |     35.199 |     1.3
   23 |   0.9470 |     31.914 |   1.0678 |     35.168 |     1.4
   24 |   0.9261 |     31.118 |   1.0515 |     35.138 |     1.4
   25 |   0.9013 |     30.632 |   1.0520 |     33.700 |     1.5
   26 |   0.8960 |     30.240 |   1.0436 |     34.251 |     1.6
   27 |   0.8690 |     29.113 |   1.0360 |     33.028 |     1.6
   28 |   0.8598 |     28.676 |   1.0388 |     33.242 |     1.7
   29 |   0.8373 |     27.991 |   1.0171 |     32.538 |     1.7
   30 |   0.8187 |     27.467 |   1.0340 |     32.905 |     1.8
   31 |   0.7974 |     26.715 |   0.9996 |     32.049 |     1.9
   32 |   0.7816 |     25.771 |   1.0185 |     31.162 |     1.9
   33 |   0.7952 |     26.246 |   1.0008 |     31.743 |     2.0
   34 |   0.7537 |     25.030 |   1.0072 |     31.193 |     2.0
   35 |   0.7529 |     25.108 |   0.9981 |     31.193 |     2.1
   36 |   0.7301 |     24.323 |   1.0055 |     31.560 |     2.2
   37 |   0.7128 |     23.804 |   0.9864 |     30.642 |     2.2
   38 |   0.7341 |     24.334 |   0.9875 |     30.856 |     2.3
   39 |   0.6971 |     22.937 |   0.9714 |     30.612 |     2.3
   40 |   0.6682 |     22.125 |   0.9655 |     30.550 |     2.4
   41 |   0.6550 |     21.710 |   0.9747 |     29.847 |     2.5
   42 |   0.6563 |     21.904 |   0.9567 |     30.092 |     2.5
   43 |   0.6372 |     21.081 |   0.9649 |     29.572 |     2.6
   44 |   0.6150 |     20.086 |   0.9729 |     29.388 |     2.6
   45 |   0.6129 |     20.733 |   0.9789 |     29.694 |     2.7
   46 |   0.5865 |     19.412 |   0.9852 |     29.419 |     2.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 402,210

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5034 |     65.230 |   1.9169 |     53.700 |     0.0
    2 |   1.7075 |     48.508 |   1.5172 |     45.963 |     0.0
    3 |   1.4750 |     46.094 |   1.4172 |     45.963 |     0.1
    4 |   1.4202 |     46.155 |   1.3881 |     45.963 |     0.1
    5 |   1.3957 |     46.100 |   1.3659 |     45.963 |     0.1
    6 |   1.3735 |     46.056 |   1.3492 |     45.902 |     0.1
    7 |   1.3517 |     45.398 |   1.3358 |     45.015 |     0.2
    8 |   1.3227 |     44.653 |   1.3085 |     44.709 |     0.2
    9 |   1.3063 |     44.630 |   1.2904 |     44.312 |     0.2
   10 |   1.2798 |     44.061 |   1.2770 |     43.119 |     0.2
   11 |   1.2486 |     42.377 |   1.2500 |     42.263 |     0.2
   12 |   1.2255 |     41.426 |   1.2334 |     42.294 |     0.3
   13 |   1.2052 |     40.780 |   1.2199 |     41.315 |     0.3
   14 |   1.1807 |     40.112 |   1.2037 |     40.734 |     0.3
   15 |   1.1571 |     39.029 |   1.1883 |     40.122 |     0.3
   16 |   1.1361 |     38.725 |   1.1725 |     39.083 |     0.4
   17 |   1.1155 |     37.443 |   1.1746 |     38.930 |     0.4
   18 |   1.0892 |     36.432 |   1.1427 |     38.073 |     0.4
   19 |   1.0751 |     36.140 |   1.1406 |     37.890 |     0.4
   20 |   1.0495 |     35.245 |   1.1322 |     36.636 |     0.4
   21 |   1.0247 |     34.179 |   1.1187 |     36.881 |     0.5
   22 |   1.0016 |     33.400 |   1.0992 |     35.657 |     0.5
   23 |   0.9854 |     32.632 |   1.1003 |     35.719 |     0.5
   24 |   0.9696 |     31.925 |   1.1171 |     37.064 |     0.5
   25 |   0.9451 |     30.958 |   1.0996 |     35.657 |     0.6
   26 |   0.9269 |     30.698 |   1.0674 |     34.404 |     0.6
   27 |   0.9066 |     30.013 |   1.0575 |     33.976 |     0.6
   28 |   0.8870 |     29.262 |   1.0841 |     34.251 |     0.6
   29 |   0.8773 |     28.781 |   1.0639 |     33.823 |     0.6
   30 |   0.8595 |     28.422 |   1.0564 |     33.884 |     0.7
   31 |   0.8389 |     27.456 |   1.0383 |     33.364 |     0.7
   32 |   0.8226 |     27.080 |   1.0637 |     33.333 |     0.7
   33 |   0.8035 |     26.152 |   1.0440 |     32.875 |     0.7
   34 |   0.7954 |     25.898 |   1.0474 |     33.242 |     0.8
   35 |   0.7718 |     25.119 |   1.0188 |     32.446 |     0.8
   36 |   0.7580 |     24.771 |   1.0556 |     32.569 |     0.8
   37 |   0.7410 |     24.042 |   1.0222 |     31.437 |     0.8
   38 |   0.7274 |     23.428 |   1.0165 |     32.294 |     0.8
   39 |   0.7215 |     23.136 |   1.0166 |     31.468 |     0.9
   40 |   0.7019 |     22.605 |   1.0083 |     31.407 |     0.9
   41 |   0.6822 |     21.821 |   1.0090 |     30.917 |     0.9
   42 |   0.6688 |     21.335 |   1.0183 |     30.887 |     0.9
   43 |   0.6590 |     21.357 |   1.0176 |     30.336 |     1.0
   44 |   0.6460 |     20.340 |   0.9981 |     30.275 |     1.0
   45 |   0.6398 |     20.208 |   0.9988 |     30.581 |     1.0
   46 |   0.6273 |     20.009 |   1.0225 |     31.040 |     1.0
   47 |   0.6166 |     19.788 |   1.0114 |     30.459 |     1.0
   48 |   0.6050 |     19.291 |   1.0193 |     30.673 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,142,882

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2050 |     59.513 |   1.5726 |     46.024 |     0.1
    2 |   1.4728 |     46.166 |   1.4037 |     45.963 |     0.1
    3 |   1.4005 |     45.835 |   1.3725 |     45.719 |     0.2
    4 |   1.3636 |     44.813 |   1.3536 |     44.801 |     0.2
    5 |   1.3345 |     44.316 |   1.3423 |     44.343 |     0.3
    6 |   1.3200 |     44.017 |   1.3113 |     43.670 |     0.3
    7 |   1.2947 |     43.100 |   1.2964 |     42.844 |     0.4
    8 |   1.2791 |     42.785 |   1.2910 |     43.211 |     0.5
    9 |   1.2670 |     42.316 |   1.2779 |     42.538 |     0.5
   10 |   1.2420 |     41.493 |   1.2760 |     42.294 |     0.6
   11 |   1.2344 |     41.399 |   1.2611 |     42.599 |     0.6
   12 |   1.2132 |     40.725 |   1.2474 |     41.162 |     0.7
   13 |   1.1884 |     39.946 |   1.2314 |     41.040 |     0.7
   14 |   1.1650 |     39.150 |   1.2218 |     41.223 |     0.8
   15 |   1.1482 |     38.847 |   1.2056 |     40.092 |     0.9
   16 |   1.1159 |     37.642 |   1.1926 |     38.991 |     0.9
   17 |   1.1005 |     36.720 |   1.1800 |     39.052 |     1.0
   18 |   1.0745 |     36.173 |   1.1899 |     38.746 |     1.0
   19 |   1.0501 |     35.217 |   1.1580 |     38.196 |     1.1
   20 |   1.0206 |     34.123 |   1.1379 |     37.462 |     1.1
   21 |   0.9917 |     33.245 |   1.1360 |     37.064 |     1.2
   22 |   0.9748 |     32.665 |   1.1293 |     36.024 |     1.3
   23 |   0.9541 |     31.632 |   1.1121 |     35.627 |     1.3
   24 |   0.9205 |     30.665 |   1.1100 |     35.902 |     1.4
   25 |   0.8974 |     29.809 |   1.0929 |     35.229 |     1.4
   26 |   0.8901 |     29.582 |   1.0990 |     36.055 |     1.5
   27 |   0.8570 |     28.649 |   1.0779 |     34.526 |     1.5
   28 |   0.8351 |     27.848 |   1.1003 |     34.465 |     1.6
   29 |   0.8121 |     26.991 |   1.0934 |     34.190 |     1.7
   30 |   0.8011 |     26.599 |   1.0899 |     33.884 |     1.7
   31 |   0.7656 |     25.119 |   1.0583 |     33.058 |     1.8
   32 |   0.7437 |     24.478 |   1.0658 |     33.700 |     1.8
   33 |   0.7202 |     23.616 |   1.0755 |     33.303 |     1.9
   34 |   0.7128 |     23.649 |   1.0585 |     32.966 |     1.9
   35 |   0.6871 |     22.627 |   1.0573 |     32.630 |     2.0
   36 |   0.6696 |     22.103 |   1.0499 |     32.722 |     2.1
   37 |   0.6457 |     21.169 |   1.1015 |     32.538 |     2.1
   38 |   0.6406 |     21.069 |   1.0757 |     31.896 |     2.2
   39 |   0.6149 |     20.014 |   1.0868 |     32.049 |     2.2
   40 |   0.5928 |     19.561 |   1.0797 |     32.813 |     2.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,288,290

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1898 |     59.855 |   1.6247 |     45.963 |     0.0
    2 |   1.4821 |     45.702 |   1.3826 |     44.220 |     0.1
    3 |   1.3453 |     43.929 |   1.3239 |     42.630 |     0.1
    4 |   1.2754 |     41.802 |   1.2769 |     41.743 |     0.2
    5 |   1.2187 |     40.189 |   1.2208 |     39.113 |     0.2
    6 |   1.1633 |     38.079 |   1.1807 |     38.410 |     0.2
    7 |   1.1058 |     36.333 |   1.1535 |     37.615 |     0.3
    8 |   1.0520 |     34.792 |   1.1066 |     35.382 |     0.3
    9 |   1.0038 |     33.007 |   1.0894 |     34.832 |     0.4
   10 |   0.9564 |     31.306 |   1.0635 |     34.159 |     0.4
   11 |   0.9045 |     29.444 |   1.0612 |     33.609 |     0.4
   12 |   0.8624 |     28.295 |   1.0466 |     32.997 |     0.5
   13 |   0.8244 |     27.025 |   1.0429 |     33.823 |     0.5
   14 |   0.7815 |     25.500 |   1.0124 |     31.804 |     0.5
   15 |   0.7422 |     23.931 |   0.9798 |     30.214 |     0.6
   16 |   0.7095 |     22.876 |   0.9701 |     30.428 |     0.6
   17 |   0.6591 |     21.191 |   0.9740 |     30.459 |     0.7
   18 |   0.6199 |     19.600 |   0.9628 |     29.817 |     0.7
   19 |   0.5853 |     18.633 |   0.9444 |     29.755 |     0.7
   20 |   0.5484 |     17.274 |   0.9607 |     29.205 |     0.8
   21 |   0.5192 |     16.186 |   0.9517 |     28.379 |     0.8
   22 |   0.4894 |     15.584 |   0.9605 |     29.602 |     0.9
   23 |   0.4633 |     14.545 |   0.9360 |     27.492 |     0.9
   24 |   0.4445 |     13.717 |   0.9437 |     27.859 |     0.9
   25 |   0.4312 |     13.733 |   0.9276 |     27.064 |     1.0
   26 |   0.3905 |     12.225 |   0.9493 |     27.125 |     1.0
   27 |   0.3649 |     11.330 |   0.9552 |     27.859 |     1.1
   28 |   0.3578 |     11.159 |   0.9625 |     27.920 |     1.1
   29 |   0.3511 |     10.988 |   0.9583 |     26.911 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 615,810

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2278 |     60.761 |   1.5874 |     46.024 |     0.0
    2 |   1.4790 |     46.105 |   1.3995 |     46.361 |     0.0
    3 |   1.3926 |     45.945 |   1.3514 |     45.076 |     0.1
    4 |   1.3325 |     43.885 |   1.3283 |     44.740 |     0.1
    5 |   1.2944 |     43.056 |   1.2936 |     42.630 |     0.1
    6 |   1.2644 |     41.388 |   1.2487 |     42.110 |     0.1
    7 |   1.2255 |     40.206 |   1.2377 |     41.070 |     0.1
    8 |   1.1907 |     39.471 |   1.2024 |     39.969 |     0.2
    9 |   1.1419 |     38.355 |   1.1818 |     38.930 |     0.2
   10 |   1.1036 |     37.222 |   1.1768 |     38.869 |     0.2
   11 |   1.0616 |     35.985 |   1.1453 |     36.911 |     0.2
   12 |   1.0211 |     34.615 |   1.1388 |     37.462 |     0.2
   13 |   0.9798 |     33.035 |   1.1333 |     36.239 |     0.2
   14 |   0.9407 |     31.317 |   1.1164 |     36.300 |     0.3
   15 |   0.9023 |     30.024 |   1.0868 |     33.884 |     0.3
   16 |   0.8513 |     27.931 |   1.0705 |     32.905 |     0.3
   17 |   0.8188 |     27.080 |   1.0678 |     32.936 |     0.3
   18 |   0.7695 |     25.505 |   1.0489 |     32.294 |     0.3
   19 |   0.7314 |     24.174 |   1.0200 |     31.437 |     0.4
   20 |   0.6792 |     22.246 |   1.0279 |     30.979 |     0.4
   21 |   0.6525 |     21.020 |   1.0523 |     30.183 |     0.4
   22 |   0.6288 |     20.434 |   1.0008 |     30.245 |     0.4
   23 |   0.5891 |     19.020 |   0.9995 |     29.144 |     0.4
   24 |   0.5600 |     18.026 |   0.9666 |     29.480 |     0.5
   25 |   0.5729 |     18.617 |   0.9778 |     28.716 |     0.5
   26 |   0.5128 |     16.672 |   1.0038 |     28.624 |     0.5
   27 |   0.4806 |     15.247 |   0.9597 |     27.615 |     0.5
   28 |   0.4505 |     14.402 |   0.9896 |     28.043 |     0.5
   29 |   0.4186 |     13.391 |   0.9644 |     27.125 |     0.6
   30 |   0.3945 |     12.678 |   0.9846 |     27.370 |     0.6
   31 |   0.3850 |     12.137 |   1.0229 |     27.768 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,392,290

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3276 |     62.855 |   1.7159 |     53.639 |     0.0
    2 |   1.5350 |     46.674 |   1.4217 |     45.963 |     0.1
    3 |   1.4181 |     46.133 |   1.3904 |     46.361 |     0.1
    4 |   1.3982 |     46.266 |   1.3732 |     45.963 |     0.1
    5 |   1.3840 |     46.210 |   1.3660 |     45.933 |     0.2
    6 |   1.3594 |     45.094 |   1.3370 |     44.985 |     0.2
    7 |   1.3273 |     44.205 |   1.3104 |     44.251 |     0.3
    8 |   1.3036 |     43.758 |   1.2949 |     43.976 |     0.3
    9 |   1.2938 |     43.691 |   1.2698 |     43.486 |     0.3
   10 |   1.2716 |     43.194 |   1.2544 |     43.150 |     0.4
   11 |   1.2556 |     42.680 |   1.2521 |     42.966 |     0.4
   12 |   1.2381 |     42.189 |   1.2342 |     42.294 |     0.4
   13 |   1.2135 |     41.150 |   1.2203 |     41.865 |     0.5
   14 |   1.1923 |     40.504 |   1.2235 |     41.835 |     0.5
   15 |   1.1726 |     39.764 |   1.2118 |     40.765 |     0.5
   16 |   1.1583 |     39.520 |   1.1959 |     40.489 |     0.6
   17 |   1.1417 |     38.615 |   1.1847 |     39.694 |     0.6
   18 |   1.1288 |     38.266 |   1.1772 |     39.602 |     0.6
   19 |   1.1187 |     38.128 |   1.1627 |     39.083 |     0.7
   20 |   1.0962 |     37.537 |   1.1521 |     37.920 |     0.7
   21 |   1.0779 |     36.626 |   1.1445 |     38.257 |     0.7
   22 |   1.0555 |     35.952 |   1.1082 |     37.401 |     0.8
   23 |   1.0337 |     34.720 |   1.1327 |     37.401 |     0.8
   24 |   1.0149 |     34.261 |   1.1084 |     36.514 |     0.9
   25 |   0.9948 |     33.494 |   1.0762 |     35.872 |     0.9
   26 |   0.9693 |     32.267 |   1.0780 |     34.985 |     0.9
   27 |   0.9473 |     31.726 |   1.0819 |     36.116 |     1.0
   28 |   0.9281 |     31.405 |   1.0687 |     35.138 |     1.0
   29 |   0.9099 |     30.831 |   1.0685 |     35.443 |     1.0
   30 |   0.8911 |     29.798 |   1.0558 |     34.557 |     1.1
   31 |   0.8624 |     28.870 |   1.0594 |     34.159 |     1.1
   32 |   0.8490 |     28.505 |   1.0423 |     34.037 |     1.1
   33 |   0.8204 |     27.544 |   1.0440 |     33.639 |     1.2
   34 |   0.8053 |     27.290 |   1.0223 |     33.394 |     1.2
   35 |   0.7801 |     26.445 |   1.0264 |     33.119 |     1.2
   36 |   0.7798 |     25.970 |   1.0219 |     33.700 |     1.3
   37 |   0.7674 |     25.456 |   1.0156 |     31.774 |     1.3
   38 |   0.7379 |     24.716 |   1.0096 |     31.315 |     1.3
   39 |   0.7171 |     24.075 |   0.9865 |     31.437 |     1.4
   40 |   0.6961 |     23.263 |   1.0105 |     31.498 |     1.4
   41 |   0.6697 |     22.252 |   1.0151 |     30.459 |     1.5
   42 |   0.6539 |     21.721 |   1.0010 |     30.765 |     1.5
   43 |   0.6389 |     21.550 |   0.9862 |     30.703 |     1.5
   44 |   0.6326 |     21.075 |   0.9800 |     29.969 |     1.6
   45 |   0.6160 |     20.445 |   0.9808 |     29.847 |     1.6
   46 |   0.5982 |     19.661 |   0.9736 |     30.092 |     1.6
   47 |   0.5868 |     19.407 |   0.9739 |     30.306 |     1.7
   48 |   0.5626 |     18.722 |   0.9694 |     29.939 |     1.7
   49 |   0.5516 |     18.191 |   1.0122 |     29.633 |     1.7
   50 |   0.5462 |     17.854 |   0.9566 |     28.226 |     1.8
   51 |   0.5245 |     17.335 |   0.9554 |     28.532 |     1.8
   52 |   0.5073 |     16.595 |   0.9848 |     28.807 |     1.8
   53 |   0.5019 |     16.562 |   0.9728 |     28.410 |     1.9
   54 |   0.4959 |     16.501 |   0.9852 |     29.480 |     1.9
   55 |   0.4837 |     15.960 |   0.9822 |     28.135 |     1.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 684,258

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3314 |     62.921 |   1.6985 |     48.746 |     0.0
    2 |   1.5304 |     46.741 |   1.4165 |     45.963 |     0.0
    3 |   1.4145 |     46.166 |   1.3865 |     47.034 |     0.0
    4 |   1.3727 |     45.636 |   1.3412 |     44.618 |     0.1
    5 |   1.3242 |     43.763 |   1.3312 |     43.976 |     0.1
    6 |   1.2898 |     43.012 |   1.2746 |     42.905 |     0.1
    7 |   1.2607 |     42.316 |   1.2498 |     43.119 |     0.1
    8 |   1.2245 |     41.487 |   1.2292 |     41.621 |     0.1
    9 |   1.1895 |     40.299 |   1.1991 |     41.315 |     0.1
   10 |   1.1611 |     39.277 |   1.1884 |     40.428 |     0.1
   11 |   1.1254 |     38.184 |   1.1733 |     39.602 |     0.2
   12 |   1.0935 |     36.852 |   1.1606 |     38.685 |     0.2
   13 |   1.0561 |     35.709 |   1.1323 |     38.654 |     0.2
   14 |   1.0218 |     34.725 |   1.1033 |     36.758 |     0.2
   15 |   0.9801 |     33.168 |   1.1009 |     36.728 |     0.2
   16 |   0.9498 |     31.892 |   1.0730 |     36.147 |     0.2
   17 |   0.9158 |     31.002 |   1.0530 |     34.832 |     0.3
   18 |   0.8762 |     29.444 |   1.0484 |     34.312 |     0.3
   19 |   0.8423 |     28.367 |   1.0481 |     33.976 |     0.3
   20 |   0.8154 |     27.340 |   1.0758 |     34.404 |     0.3
   21 |   0.7787 |     25.892 |   1.0434 |     34.128 |     0.3
   22 |   0.7522 |     24.881 |   1.0472 |     32.538 |     0.3
   23 |   0.7304 |     24.196 |   1.0502 |     32.416 |     0.3
   24 |   0.6906 |     22.876 |   1.0256 |     32.508 |     0.4
   25 |   0.6706 |     21.915 |   1.0379 |     31.774 |     0.4
   26 |   0.6321 |     20.202 |   1.0609 |     31.590 |     0.4
   27 |   0.6061 |     19.572 |   1.0255 |     30.459 |     0.4
   28 |   0.5876 |     19.003 |   1.0445 |     31.223 |     0.4
   29 |   0.5574 |     18.103 |   1.0415 |     29.725 |     0.4
   30 |   0.5391 |     17.241 |   1.0434 |     29.633 |     0.5
   31 |   0.5117 |     15.998 |   1.0790 |     30.612 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 377,218

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5841 |     69.711 |   2.0049 |     58.654 |     0.0
    2 |   1.7846 |     50.724 |   1.5623 |     45.963 |     0.0
    3 |   1.5080 |     46.155 |   1.4419 |     45.963 |     0.1
    4 |   1.4395 |     46.194 |   1.4056 |     45.963 |     0.1
    5 |   1.4117 |     46.144 |   1.3894 |     46.422 |     0.1
    6 |   1.3963 |     46.177 |   1.3700 |     45.963 |     0.1
    7 |   1.3757 |     45.807 |   1.3578 |     45.505 |     0.1
    8 |   1.3580 |     44.829 |   1.3323 |     45.015 |     0.2
    9 |   1.3309 |     43.769 |   1.3097 |     44.281 |     0.2
   10 |   1.3017 |     43.354 |   1.2967 |     43.761 |     0.2
   11 |   1.2833 |     42.857 |   1.2752 |     43.242 |     0.2
   12 |   1.2634 |     42.128 |   1.2666 |     43.517 |     0.2
   13 |   1.2441 |     41.714 |   1.2498 |     42.355 |     0.2
   14 |   1.2229 |     41.078 |   1.2366 |     41.560 |     0.3
   15 |   1.2029 |     40.145 |   1.2277 |     41.101 |     0.3
   16 |   1.1821 |     39.377 |   1.2056 |     40.887 |     0.3
   17 |   1.1700 |     39.427 |   1.2057 |     40.459 |     0.3
   18 |   1.1511 |     38.725 |   1.1933 |     40.000 |     0.3
   19 |   1.1274 |     38.515 |   1.1743 |     39.755 |     0.4
   20 |   1.1167 |     37.935 |   1.1796 |     40.000 |     0.4
   21 |   1.1000 |     37.609 |   1.1700 |     39.633 |     0.4
   22 |   1.0859 |     37.366 |   1.1706 |     39.052 |     0.4
   23 |   1.0701 |     36.797 |   1.1595 |     39.113 |     0.4
   24 |   1.0509 |     36.228 |   1.1609 |     38.563 |     0.4
   25 |   1.0366 |     35.830 |   1.1480 |     38.930 |     0.5
   26 |   1.0151 |     35.278 |   1.1606 |     38.654 |     0.5
   27 |   0.9976 |     34.637 |   1.1331 |     37.339 |     0.5
   28 |   0.9888 |     33.781 |   1.1254 |     37.523 |     0.5
   29 |   0.9652 |     33.035 |   1.1310 |     36.972 |     0.5
   30 |   0.9633 |     32.516 |   1.1181 |     36.758 |     0.6
   31 |   0.9413 |     31.969 |   1.0925 |     35.657 |     0.6
   32 |   0.9252 |     31.367 |   1.0776 |     34.862 |     0.6
   33 |   0.9096 |     30.836 |   1.0915 |     35.505 |     0.6
   34 |   0.8941 |     30.002 |   1.0862 |     35.229 |     0.6
   35 |   0.8758 |     29.185 |   1.0715 |     34.312 |     0.6
   36 |   0.8592 |     28.671 |   1.1043 |     35.229 |     0.7
   37 |   0.8543 |     29.201 |   1.0749 |     34.434 |     0.7
   38 |   0.8442 |     28.527 |   1.0634 |     34.128 |     0.7
   39 |   0.8183 |     27.577 |   1.0599 |     33.394 |     0.7
   40 |   0.7984 |     26.422 |   1.0712 |     34.434 |     0.7
   41 |   0.7936 |     26.550 |   1.0452 |     33.456 |     0.8
   42 |   0.7820 |     25.986 |   1.0544 |     33.731 |     0.8
   43 |   0.7705 |     25.577 |   1.0483 |     32.722 |     0.8
   44 |   0.7638 |     25.340 |   1.0523 |     32.875 |     0.8
   45 |   0.7478 |     24.881 |   1.0350 |     32.752 |     0.8
   46 |   0.7324 |     24.356 |   1.0795 |     32.416 |     0.9
   47 |   0.7272 |     23.843 |   1.0627 |     31.988 |     0.9
   48 |   0.7079 |     23.274 |   1.0473 |     33.028 |     0.9
   49 |   0.6930 |     22.738 |   1.0370 |     31.988 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 377,218

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6266 |     70.484 |   2.0228 |     58.654 |     0.0
    2 |   1.7965 |     50.895 |   1.5832 |     45.963 |     0.0
    3 |   1.5146 |     46.094 |   1.4375 |     45.963 |     0.1
    4 |   1.4360 |     46.078 |   1.4006 |     45.963 |     0.1
    5 |   1.4040 |     46.089 |   1.3707 |     45.810 |     0.1
    6 |   1.3702 |     45.840 |   1.3415 |     45.443 |     0.1
    7 |   1.3312 |     45.172 |   1.3090 |     45.107 |     0.1
    8 |   1.2986 |     44.282 |   1.2873 |     43.914 |     0.1
    9 |   1.2705 |     43.586 |   1.2622 |     43.547 |     0.2
   10 |   1.2445 |     42.575 |   1.2509 |     43.578 |     0.2
   11 |   1.2231 |     41.907 |   1.2294 |     42.385 |     0.2
   12 |   1.1986 |     41.211 |   1.2049 |     40.979 |     0.2
   13 |   1.1744 |     40.034 |   1.2001 |     40.703 |     0.2
   14 |   1.1529 |     38.852 |   1.1833 |     40.061 |     0.3
   15 |   1.1303 |     37.775 |   1.1516 |     39.083 |     0.3
   16 |   1.0973 |     36.825 |   1.1309 |     38.440 |     0.3
   17 |   1.0734 |     36.073 |   1.1263 |     37.890 |     0.3
   18 |   1.0582 |     36.112 |   1.1085 |     37.829 |     0.3
   19 |   1.0280 |     34.792 |   1.0932 |     36.850 |     0.3
   20 |   1.0068 |     34.394 |   1.0828 |     36.820 |     0.4
   21 |   0.9915 |     33.803 |   1.0804 |     36.330 |     0.4
   22 |   0.9712 |     32.797 |   1.0631 |     35.443 |     0.4
   23 |   0.9510 |     32.416 |   1.0536 |     35.535 |     0.4
   24 |   0.9354 |     31.842 |   1.0564 |     34.954 |     0.4
   25 |   0.9180 |     31.135 |   1.0503 |     35.382 |     0.5
   26 |   0.9069 |     30.781 |   1.0457 |     34.740 |     0.5
   27 |   0.9021 |     30.566 |   1.0366 |     34.893 |     0.5
   28 |   0.8771 |     29.754 |   1.0538 |     34.526 |     0.5
   29 |   0.8722 |     29.218 |   1.0283 |     32.936 |     0.5
   30 |   0.8497 |     28.676 |   1.0304 |     33.639 |     0.5
   31 |   0.8334 |     28.085 |   1.0268 |     33.058 |     0.6
   32 |   0.8223 |     27.378 |   1.0441 |     34.679 |     0.6
   33 |   0.8021 |     26.831 |   1.0383 |     32.691 |     0.6
   34 |   0.7964 |     26.472 |   0.9972 |     32.202 |     0.6
   35 |   0.7869 |     26.086 |   1.0286 |     32.171 |     0.6
   36 |   0.7688 |     25.456 |   1.0156 |     31.865 |     0.7
   37 |   0.7664 |     25.605 |   1.0065 |     31.621 |     0.7
   38 |   0.7380 |     24.406 |   1.0072 |     32.018 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,143,586

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1888 |     59.656 |   1.5691 |     45.963 |     0.1
    2 |   1.4687 |     46.183 |   1.4093 |     45.963 |     0.1
    3 |   1.4086 |     46.089 |   1.3824 |     45.963 |     0.2
    4 |   1.3943 |     46.078 |   1.3703 |     45.963 |     0.2
    5 |   1.3699 |     45.382 |   1.3491 |     44.465 |     0.3
    6 |   1.3463 |     44.835 |   1.3346 |     44.954 |     0.3
    7 |   1.3281 |     44.492 |   1.3254 |     44.404 |     0.4
    8 |   1.3139 |     43.785 |   1.3106 |     43.364 |     0.5
    9 |   1.2956 |     43.305 |   1.2979 |     42.722 |     0.5
   10 |   1.2786 |     42.874 |   1.2931 |     43.150 |     0.6
   11 |   1.2648 |     42.338 |   1.2907 |     43.119 |     0.6
   12 |   1.2506 |     42.001 |   1.2752 |     42.661 |     0.7
   13 |   1.2288 |     41.327 |   1.2649 |     42.324 |     0.8
   14 |   1.2133 |     40.935 |   1.2549 |     41.529 |     0.8
   15 |   1.1952 |     40.145 |   1.2378 |     41.407 |     0.9
   16 |   1.1712 |     39.454 |   1.2200 |     41.131 |     0.9
   17 |   1.1531 |     38.460 |   1.2167 |     40.642 |     1.0
   18 |   1.1305 |     38.101 |   1.2088 |     40.428 |     1.0
   19 |   1.1221 |     37.642 |   1.1873 |     39.358 |     1.1
   20 |   1.0921 |     37.007 |   1.1801 |     39.358 |     1.2
   21 |   1.0684 |     36.007 |   1.1677 |     38.257 |     1.2
   22 |   1.0501 |     35.305 |   1.1566 |     38.257 |     1.3
   23 |   1.0283 |     34.466 |   1.1236 |     36.850 |     1.3
   24 |   1.0101 |     33.676 |   1.1433 |     36.942 |     1.4
   25 |   0.9819 |     33.184 |   1.1131 |     36.972 |     1.5
   26 |   0.9520 |     31.659 |   1.1069 |     35.474 |     1.5
   27 |   0.9328 |     31.400 |   1.1200 |     36.116 |     1.6
   28 |   0.9153 |     30.792 |   1.1110 |     35.505 |     1.6
   29 |   0.8842 |     29.477 |   1.0877 |     34.465 |     1.7
   30 |   0.8630 |     28.914 |   1.1030 |     35.505 |     1.7
   31 |   0.8460 |     28.190 |   1.0862 |     34.251 |     1.8
   32 |   0.8174 |     27.152 |   1.0655 |     33.700 |     1.9
   33 |   0.7953 |     26.616 |   1.0596 |     33.792 |     1.9
   34 |   0.7765 |     25.610 |   1.0601 |     33.394 |     2.0
   35 |   0.7713 |     25.378 |   1.0506 |     32.966 |     2.0
   36 |   0.7625 |     25.207 |   1.0649 |     32.538 |     2.1
   37 |   0.7205 |     24.058 |   1.0531 |     32.141 |     2.2
   38 |   0.7062 |     23.323 |   1.0530 |     33.272 |     2.2
   39 |   0.6913 |     23.136 |   1.0193 |     31.498 |     2.3
   40 |   0.6575 |     21.699 |   1.0448 |     31.927 |     2.3
   41 |   0.6452 |     21.489 |   1.0485 |     31.407 |     2.4
   42 |   0.6224 |     20.666 |   1.0486 |     31.468 |     2.5
   43 |   0.5956 |     19.561 |   1.0319 |     31.651 |     2.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 541,602

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2123 |     61.104 |   1.6161 |     46.453 |     0.0
    2 |   1.4582 |     44.846 |   1.3638 |     43.761 |     0.0
    3 |   1.3179 |     42.791 |   1.2910 |     42.294 |     0.1
    4 |   1.2408 |     40.730 |   1.2266 |     40.061 |     0.1
    5 |   1.1741 |     38.559 |   1.1880 |     38.746 |     0.1
    6 |   1.1026 |     36.002 |   1.1417 |     36.789 |     0.1
    7 |   1.0356 |     34.024 |   1.0976 |     35.321 |     0.2
    8 |   0.9772 |     31.676 |   1.0793 |     34.312 |     0.2
    9 |   0.9150 |     29.687 |   1.0524 |     32.997 |     0.2
   10 |   0.8611 |     28.091 |   1.0364 |     32.661 |     0.2
   11 |   0.8129 |     26.063 |   1.0190 |     32.171 |     0.2
   12 |   0.7566 |     24.417 |   0.9870 |     29.939 |     0.3
   13 |   0.7097 |     22.760 |   0.9852 |     30.520 |     0.3
   14 |   0.6531 |     20.915 |   0.9548 |     29.786 |     0.3
   15 |   0.6061 |     19.230 |   0.9339 |     28.471 |     0.3
   16 |   0.5879 |     18.816 |   0.9518 |     28.624 |     0.3
   17 |   0.5334 |     16.589 |   0.9412 |     28.287 |     0.4
   18 |   0.4875 |     15.407 |   0.9277 |     27.554 |     0.4
   19 |   0.4474 |     14.043 |   0.9467 |     27.798 |     0.4
   20 |   0.4192 |     13.214 |   0.9031 |     27.890 |     0.4
   21 |   0.3815 |     11.745 |   0.9231 |     27.554 |     0.4
   22 |   0.3670 |     11.408 |   0.9243 |     27.431 |     0.5
   23 |   0.3306 |     10.120 |   0.9447 |     27.401 |     0.5
   24 |   0.3040 |      9.342 |   0.9322 |     26.942 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 879,138

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4719 |     65.893 |   1.9003 |     53.700 |     0.0
    2 |   1.6959 |     48.724 |   1.4926 |     45.994 |     0.1
    3 |   1.4563 |     45.973 |   1.3936 |     45.657 |     0.1
    4 |   1.3927 |     45.663 |   1.3594 |     45.138 |     0.1
    5 |   1.3532 |     44.735 |   1.3257 |     43.303 |     0.2
    6 |   1.3043 |     42.940 |   1.2843 |     42.080 |     0.2
    7 |   1.2613 |     41.338 |   1.2516 |     41.376 |     0.2
    8 |   1.2321 |     40.294 |   1.2332 |     40.550 |     0.3
    9 |   1.1982 |     39.659 |   1.1987 |     39.419 |     0.3
   10 |   1.1628 |     38.664 |   1.1719 |     38.685 |     0.3
   11 |   1.1350 |     37.576 |   1.1573 |     38.716 |     0.4
   12 |   1.1016 |     36.725 |   1.1368 |     37.309 |     0.4
   13 |   1.0726 |     35.178 |   1.1153 |     36.422 |     0.4
   14 |   1.0442 |     33.836 |   1.0831 |     34.985 |     0.5
   15 |   1.0033 |     32.449 |   1.0673 |     34.434 |     0.5
   16 |   0.9872 |     32.046 |   1.0631 |     34.159 |     0.5
   17 |   0.9641 |     31.201 |   1.0597 |     34.037 |     0.6
   18 |   0.9385 |     30.345 |   1.0500 |     33.364 |     0.6
   19 |   0.9147 |     29.671 |   1.0292 |     33.211 |     0.6
   20 |   0.8916 |     28.770 |   1.0342 |     33.058 |     0.7
   21 |   0.8707 |     28.422 |   1.0331 |     32.263 |     0.7
   22 |   0.8518 |     27.638 |   1.0052 |     32.232 |     0.7
   23 |   0.8223 |     26.494 |   1.0089 |     32.844 |     0.8
   24 |   0.8068 |     26.080 |   1.0125 |     32.202 |     0.8
   25 |   0.7888 |     25.881 |   0.9889 |     32.110 |     0.8
   26 |   0.7778 |     25.384 |   0.9793 |     31.774 |     0.9
   27 |   0.7564 |     24.616 |   1.0035 |     30.795 |     0.9
   28 |   0.7515 |     24.627 |   0.9987 |     31.315 |     0.9
   29 |   0.7329 |     23.804 |   0.9775 |     30.367 |     1.0
   30 |   0.7121 |     23.053 |   0.9781 |     30.550 |     1.0
   31 |   0.6949 |     22.633 |   0.9737 |     30.122 |     1.0
   32 |   0.6817 |     22.086 |   0.9627 |     29.908 |     1.1
   33 |   0.6747 |     21.743 |   0.9593 |     29.725 |     1.1
   34 |   0.6617 |     21.578 |   0.9645 |     29.939 |     1.1
   35 |   0.6373 |     20.534 |   0.9468 |     29.205 |     1.2
   36 |   0.6256 |     20.186 |   0.9523 |     29.297 |     1.2
   37 |   0.6188 |     20.152 |   0.9623 |     29.113 |     1.2
   38 |   0.6124 |     19.838 |   0.9677 |     29.847 |     1.3
   39 |   0.5953 |     19.313 |   0.9605 |     30.000 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 420,770

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4968 |     67.517 |   1.9310 |     56.820 |     0.0
    2 |   1.7198 |     49.127 |   1.5302 |     45.963 |     0.0
    3 |   1.4843 |     46.133 |   1.4216 |     45.963 |     0.1
    4 |   1.4190 |     46.078 |   1.3835 |     45.872 |     0.1
    5 |   1.3916 |     45.978 |   1.3673 |     45.963 |     0.1
    6 |   1.3659 |     45.669 |   1.3439 |     45.535 |     0.1
    7 |   1.3338 |     44.581 |   1.3152 |     43.486 |     0.2
    8 |   1.3064 |     43.238 |   1.2995 |     43.211 |     0.2
    9 |   1.2715 |     42.310 |   1.2689 |     42.141 |     0.2
   10 |   1.2422 |     41.548 |   1.2396 |     41.651 |     0.2
   11 |   1.2180 |     40.620 |   1.2270 |     41.254 |     0.2
   12 |   1.1923 |     39.631 |   1.2204 |     40.428 |     0.3
   13 |   1.1652 |     38.753 |   1.1925 |     39.480 |     0.3
   14 |   1.1334 |     37.548 |   1.1800 |     39.144 |     0.3
   15 |   1.1097 |     36.941 |   1.1577 |     38.593 |     0.3
   16 |   1.0751 |     36.018 |   1.1299 |     37.645 |     0.3
   17 |   1.0394 |     34.924 |   1.1233 |     37.920 |     0.4
   18 |   1.0094 |     34.217 |   1.1325 |     36.575 |     0.4
   19 |   0.9800 |     32.814 |   1.1264 |     36.575 |     0.4
   20 |   0.9504 |     31.704 |   1.0988 |     35.352 |     0.4
   21 |   0.9164 |     30.516 |   1.0912 |     36.269 |     0.4
   22 |   0.8898 |     29.560 |   1.0732 |     35.046 |     0.5
   23 |   0.8631 |     28.450 |   1.0668 |     34.251 |     0.5
   24 |   0.8307 |     27.212 |   1.0803 |     34.098 |     0.5
   25 |   0.8038 |     26.329 |   1.0889 |     33.976 |     0.5
   26 |   0.7831 |     25.152 |   1.0406 |     32.630 |     0.6
   27 |   0.7565 |     24.423 |   1.0438 |     32.875 |     0.6
   28 |   0.7412 |     23.721 |   1.0635 |     31.407 |     0.6
   29 |   0.7177 |     22.649 |   1.0347 |     31.957 |     0.6
   30 |   0.6849 |     22.042 |   1.0518 |     31.957 |     0.6
   31 |   0.6644 |     20.782 |   1.0458 |     31.743 |     0.7
   32 |   0.6460 |     20.556 |   1.0315 |     31.315 |     0.7
   33 |   0.6203 |     19.456 |   1.0381 |     30.520 |     0.7
   34 |   0.6025 |     18.799 |   1.0368 |     31.407 |     0.7
   35 |   0.5922 |     18.528 |   1.0357 |     30.000 |     0.7
   36 |   0.5639 |     17.462 |   1.0503 |     30.581 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 2,456,738

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5713 |     68.147 |   2.0004 |     53.761 |     0.1
    2 |   1.7733 |     50.144 |   1.5633 |     45.963 |     0.2
    3 |   1.5033 |     46.089 |   1.4388 |     45.963 |     0.2
    4 |   1.4355 |     46.089 |   1.4050 |     45.963 |     0.3
    5 |   1.4125 |     46.089 |   1.3920 |     45.963 |     0.4
    6 |   1.4029 |     46.232 |   1.3854 |     46.361 |     0.5
    7 |   1.3985 |     46.161 |   1.3795 |     45.963 |     0.5
    8 |   1.3933 |     46.083 |   1.3767 |     45.963 |     0.6
    9 |   1.3896 |     46.028 |   1.3692 |     45.902 |     0.7
   10 |   1.3789 |     45.387 |   1.3625 |     44.862 |     0.8
   11 |   1.3651 |     44.901 |   1.3455 |     44.771 |     0.8
   12 |   1.3508 |     44.857 |   1.3439 |     44.495 |     0.9
   13 |   1.3400 |     44.575 |   1.3438 |     44.526 |     1.0
   14 |   1.3332 |     44.608 |   1.3413 |     44.557 |     1.1
   15 |   1.3268 |     44.443 |   1.3284 |     44.709 |     1.2
   16 |   1.3190 |     44.327 |   1.3288 |     44.373 |     1.2
   17 |   1.3109 |     43.885 |   1.3232 |     44.404 |     1.3
   18 |   1.3078 |     44.205 |   1.3160 |     44.434 |     1.4
   19 |   1.3052 |     44.188 |   1.3250 |     45.046 |     1.5
   20 |   1.2992 |     43.526 |   1.3177 |     44.190 |     1.5
   21 |   1.2886 |     43.288 |   1.3154 |     43.853 |     1.6
   22 |   1.2847 |     43.167 |   1.3032 |     43.578 |     1.7
   23 |   1.2800 |     42.951 |   1.3056 |     44.037 |     1.8
   24 |   1.2785 |     42.951 |   1.2978 |     44.006 |     1.8
   25 |   1.2707 |     42.481 |   1.2892 |     43.058 |     1.9
   26 |   1.2694 |     42.487 |   1.2948 |     43.119 |     2.0
   27 |   1.2685 |     42.332 |   1.2886 |     43.670 |     2.1
   28 |   1.2587 |     42.023 |   1.2869 |     42.416 |     2.2
   29 |   1.2536 |     41.785 |   1.2903 |     43.150 |     2.2
   30 |   1.2536 |     41.868 |   1.2831 |     43.028 |     2.3
   31 |   1.2615 |     42.349 |   1.2931 |     43.639 |     2.4
   32 |   1.2497 |     41.968 |   1.2762 |     42.538 |     2.5
   33 |   1.2461 |     41.819 |   1.2835 |     42.630 |     2.5
   34 |   1.2367 |     41.531 |   1.2654 |     42.049 |     2.6
   35 |   1.2356 |     41.614 |   1.2783 |     42.508 |     2.7
   36 |   1.2307 |     41.233 |   1.2769 |     42.508 |     2.8
   37 |   1.2349 |     41.465 |   1.2729 |     42.263 |     2.9
   38 |   1.2238 |     40.957 |   1.2662 |     42.263 |     2.9
   39 |   1.2174 |     40.940 |   1.2636 |     41.835 |     3.0
   40 |   1.2093 |     40.946 |   1.2538 |     41.743 |     3.1
   41 |   1.1943 |     40.012 |   1.2516 |     41.682 |     3.2
   42 |   1.1953 |     40.244 |   1.2586 |     41.865 |     3.2
   43 |   1.1864 |     39.791 |   1.2629 |     42.569 |     3.3
   44 |   1.1955 |     40.460 |   1.2518 |     42.263 |     3.4
   45 |   1.1769 |     39.973 |   1.2522 |     42.569 |     3.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,323,234

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1610 |     58.347 |   1.5294 |     45.933 |     0.0
    2 |   1.4275 |     45.641 |   1.3490 |     44.801 |     0.1
    3 |   1.3208 |     43.846 |   1.2830 |     42.263 |     0.1
    4 |   1.2414 |     41.178 |   1.2169 |     40.153 |     0.2
    5 |   1.1745 |     38.979 |   1.1849 |     39.664 |     0.2
    6 |   1.1205 |     37.200 |   1.1324 |     37.064 |     0.2
    7 |   1.0657 |     35.107 |   1.1016 |     35.749 |     0.3
    8 |   1.0159 |     33.350 |   1.0564 |     34.373 |     0.3
    9 |   0.9575 |     31.273 |   1.0437 |     32.722 |     0.4
   10 |   0.9107 |     29.809 |   1.0199 |     31.988 |     0.4
   11 |   0.8677 |     28.223 |   1.0257 |     32.477 |     0.4
   12 |   0.8294 |     26.958 |   0.9909 |     31.101 |     0.5
   13 |   0.7915 |     25.489 |   0.9807 |     31.101 |     0.5
   14 |   0.7571 |     24.340 |   0.9509 |     28.991 |     0.6
   15 |   0.7251 |     23.351 |   0.9581 |     28.196 |     0.6
   16 |   0.6938 |     22.451 |   0.9674 |     29.205 |     0.6
   17 |   0.6593 |     20.953 |   0.9251 |     28.073 |     0.7
   18 |   0.6288 |     20.147 |   0.9505 |     28.440 |     0.7
   19 |   0.6035 |     19.153 |   0.9386 |     28.960 |     0.8
   20 |   0.5764 |     18.633 |   0.9169 |     27.737 |     0.8
   21 |   0.5608 |     17.948 |   0.9013 |     27.156 |     0.9
   22 |   0.5421 |     17.462 |   0.9268 |     28.257 |     0.9
   23 |   0.5171 |     16.661 |   0.9170 |     27.890 |     0.9
   24 |   0.4929 |     15.744 |   0.9067 |     27.401 |     1.0
   25 |   0.4767 |     15.407 |   0.9175 |     27.125 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 914,850

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4480 |     65.705 |   1.8769 |     52.844 |     0.0
    2 |   1.6801 |     48.928 |   1.4955 |     45.963 |     0.1
    3 |   1.4501 |     45.923 |   1.3868 |     45.810 |     0.1
    4 |   1.3677 |     44.586 |   1.3343 |     43.700 |     0.2
    5 |   1.3136 |     43.183 |   1.2839 |     42.324 |     0.2
    6 |   1.2680 |     41.846 |   1.2480 |     41.284 |     0.2
    7 |   1.2290 |     40.730 |   1.2191 |     40.948 |     0.3
    8 |   1.1937 |     39.443 |   1.1951 |     39.572 |     0.3
    9 |   1.1620 |     38.443 |   1.1801 |     39.297 |     0.3
   10 |   1.1331 |     37.604 |   1.1582 |     37.829 |     0.4
   11 |   1.0984 |     36.256 |   1.1384 |     36.942 |     0.4
   12 |   1.0693 |     35.156 |   1.1155 |     35.474 |     0.4
   13 |   1.0361 |     33.659 |   1.0963 |     35.260 |     0.5
   14 |   1.0018 |     32.361 |   1.0749 |     34.128 |     0.5
   15 |   0.9700 |     31.665 |   1.0544 |     33.486 |     0.6
   16 |   0.9414 |     30.842 |   1.0409 |     33.609 |     0.6
   17 |   0.9184 |     29.908 |   1.0329 |     33.609 |     0.6
   18 |   0.8938 |     29.035 |   1.0428 |     33.150 |     0.7
   19 |   0.8895 |     29.157 |   1.0380 |     32.783 |     0.7
   20 |   0.8628 |     27.820 |   1.0084 |     32.446 |     0.7
   21 |   0.8234 |     26.494 |   0.9896 |     30.948 |     0.8
   22 |   0.8046 |     25.859 |   0.9811 |     30.306 |     0.8
   23 |   0.7769 |     24.743 |   0.9782 |     30.826 |     0.9
   24 |   0.7557 |     24.058 |   0.9888 |     31.131 |     0.9
   25 |   0.7515 |     24.025 |   0.9774 |     30.489 |     0.9
   26 |   0.7203 |     22.981 |   0.9767 |     30.795 |     1.0
   27 |   0.7068 |     22.754 |   0.9555 |     29.358 |     1.0
   28 |   0.6861 |     21.760 |   0.9379 |     29.235 |     1.0
   29 |   0.6675 |     21.257 |   0.9523 |     29.541 |     1.1
   30 |   0.6532 |     20.998 |   0.9603 |     29.817 |     1.1
   31 |   0.6315 |     20.268 |   0.9412 |     28.563 |     1.2
   32 |   0.6184 |     19.838 |   0.9478 |     28.869 |     1.2
   33 |   0.6053 |     19.142 |   0.9281 |     28.502 |     1.2
   34 |   0.5912 |     18.821 |   0.9421 |     28.012 |     1.3
   35 |   0.5741 |     18.617 |   0.9527 |     28.991 |     1.3
   36 |   0.5751 |     18.644 |   0.9262 |     28.685 |     1.3
   37 |   0.5620 |     18.048 |   0.9472 |     28.379 |     1.4
   38 |   0.5490 |     17.700 |   0.9253 |     28.287 |     1.4
   39 |   0.5263 |     16.987 |   0.9357 |     27.737 |     1.4
   40 |   0.5032 |     16.020 |   0.9270 |     27.645 |     1.5
   41 |   0.4987 |     16.042 |   0.9475 |     28.104 |     1.5
   42 |   0.4911 |     15.838 |   0.9183 |     27.523 |     1.6
   43 |   0.4782 |     15.540 |   0.9507 |     27.615 |     1.6
   44 |   0.4769 |     15.374 |   0.9554 |     27.676 |     1.6
   45 |   0.4702 |     15.308 |   0.9671 |     27.737 |     1.7
   46 |   0.4688 |     15.286 |   0.9453 |     27.523 |     1.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 587,106

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2538 |     61.076 |   1.6068 |     48.746 |     0.0
    2 |   1.4832 |     46.558 |   1.3953 |     45.963 |     0.0
    3 |   1.3733 |     45.697 |   1.3451 |     45.229 |     0.0
    4 |   1.3208 |     44.724 |   1.2937 |     44.404 |     0.1
    5 |   1.2713 |     42.807 |   1.2503 |     41.988 |     0.1
    6 |   1.2209 |     41.100 |   1.2296 |     40.979 |     0.1
    7 |   1.1807 |     39.576 |   1.1862 |     40.275 |     0.1
    8 |   1.1434 |     38.526 |   1.1546 |     38.532 |     0.1
    9 |   1.0968 |     36.880 |   1.1140 |     37.706 |     0.1
   10 |   1.0423 |     34.902 |   1.0994 |     36.850 |     0.2
   11 |   0.9945 |     33.179 |   1.0684 |     35.260 |     0.2
   12 |   0.9512 |     31.433 |   1.0481 |     33.823 |     0.2
   13 |   0.9103 |     30.350 |   1.0394 |     34.373 |     0.2
   14 |   0.8707 |     29.140 |   1.0121 |     33.119 |     0.2
   15 |   0.8224 |     26.903 |   1.0088 |     32.477 |     0.2
   16 |   0.7893 |     25.826 |   0.9863 |     31.621 |     0.2
   17 |   0.7499 |     24.693 |   0.9775 |     30.367 |     0.3
   18 |   0.7068 |     23.036 |   0.9878 |     31.223 |     0.3
   19 |   0.6920 |     22.500 |   1.0033 |     30.673 |     0.3
   20 |   0.6492 |     21.136 |   0.9584 |     29.388 |     0.3
   21 |   0.6259 |     20.164 |   0.9516 |     28.838 |     0.3
   22 |   0.6019 |     19.103 |   0.9530 |     29.541 |     0.3
   23 |   0.5773 |     18.429 |   0.9491 |     27.859 |     0.3
   24 |   0.5571 |     18.020 |   0.9388 |     28.257 |     0.4
   25 |   0.5347 |     17.031 |   0.9321 |     28.624 |     0.4
   26 |   0.5117 |     16.451 |   0.9378 |     27.645 |     0.4
   27 |   0.4905 |     15.755 |   0.9238 |     27.217 |     0.4
   28 |   0.4746 |     15.197 |   0.9385 |     26.728 |     0.4
   29 |   0.4543 |     14.391 |   0.9329 |     26.330 |     0.4
   30 |   0.4330 |     13.805 |   0.9349 |     26.483 |     0.5
   31 |   0.4305 |     13.998 |   0.9249 |     25.596 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,768,482

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5891 |     68.103 |   1.9879 |     53.761 |     0.1
    2 |   1.7832 |     51.044 |   1.5857 |     45.963 |     0.1
    3 |   1.5245 |     46.100 |   1.4503 |     45.963 |     0.2
    4 |   1.4442 |     46.094 |   1.4101 |     45.963 |     0.2
    5 |   1.4198 |     46.089 |   1.3932 |     45.963 |     0.3
    6 |   1.4099 |     46.105 |   1.3863 |     45.963 |     0.4
    7 |   1.3999 |     46.127 |   1.3842 |     45.963 |     0.4
    8 |   1.3959 |     46.089 |   1.3813 |     45.963 |     0.5
    9 |   1.3948 |     46.122 |   1.3745 |     45.963 |     0.5
   10 |   1.3910 |     46.161 |   1.3729 |     45.963 |     0.6
   11 |   1.3899 |     46.094 |   1.3702 |     45.963 |     0.7
   12 |   1.3886 |     46.144 |   1.3728 |     45.963 |     0.7
   13 |   1.3851 |     46.133 |   1.3664 |     45.933 |     0.8
   14 |   1.3805 |     46.094 |   1.3637 |     45.933 |     0.8
   15 |   1.3719 |     46.116 |   1.3614 |     45.963 |     0.9
   16 |   1.3656 |     46.023 |   1.3568 |     46.055 |     1.0
   17 |   1.3564 |     45.813 |   1.3545 |     45.657 |     1.0
   18 |   1.3543 |     45.730 |   1.3463 |     45.443 |     1.1
   19 |   1.3464 |     45.332 |   1.3487 |     45.505 |     1.2
   20 |   1.3462 |     45.050 |   1.3439 |     44.862 |     1.2
   21 |   1.3358 |     44.901 |   1.3423 |     44.985 |     1.3
   22 |   1.3271 |     44.630 |   1.3304 |     44.434 |     1.3
   23 |   1.3079 |     43.349 |   1.3053 |     43.517 |     1.4
   24 |   1.2971 |     43.062 |   1.3179 |     44.312 |     1.5
   25 |   1.2836 |     42.714 |   1.3049 |     43.914 |     1.5
   26 |   1.2733 |     42.498 |   1.2869 |     43.700 |     1.6
   27 |   1.2643 |     42.476 |   1.2855 |     43.242 |     1.6
   28 |   1.2689 |     42.774 |   1.2934 |     43.945 |     1.7
   29 |   1.2627 |     42.653 |   1.2735 |     43.150 |     1.8
   30 |   1.2537 |     42.537 |   1.2649 |     42.691 |     1.8
   31 |   1.2535 |     42.216 |   1.2713 |     42.997 |     1.9
   32 |   1.2387 |     42.034 |   1.2710 |     42.905 |     1.9
   33 |   1.2373 |     41.741 |   1.2694 |     42.997 |     2.0
   34 |   1.2358 |     42.017 |   1.2630 |     43.028 |     2.1
   35 |   1.2258 |     41.404 |   1.2583 |     42.294 |     2.1
   36 |   1.2200 |     41.587 |   1.2489 |     42.355 |     2.2
   37 |   1.2228 |     41.366 |   1.2527 |     43.058 |     2.2
   38 |   1.2177 |     41.382 |   1.2460 |     42.171 |     2.3
   39 |   1.2067 |     40.984 |   1.2649 |     42.049 |     2.4
   40 |   1.2001 |     40.653 |   1.2499 |     41.927 |     2.4
   41 |   1.1958 |     40.714 |   1.2457 |     41.590 |     2.5
   42 |   1.1862 |     40.388 |   1.2419 |     41.804 |     2.5
   43 |   1.1814 |     40.089 |   1.2656 |     41.529 |     2.6
   44 |   1.1812 |     40.239 |   1.2594 |     41.957 |     2.7
   45 |   1.1796 |     39.869 |   1.2590 |     42.110 |     2.7
   46 |   1.1705 |     39.824 |   1.2465 |     41.101 |     2.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,175,074

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6126 |     69.650 |   2.0372 |     58.654 |     0.0
    2 |   1.7921 |     51.066 |   1.5662 |     45.963 |     0.1
    3 |   1.5115 |     46.172 |   1.4417 |     45.963 |     0.1
    4 |   1.4403 |     46.089 |   1.4071 |     45.963 |     0.2
    5 |   1.4174 |     46.111 |   1.3932 |     45.963 |     0.2
    6 |   1.4053 |     46.205 |   1.3824 |     45.963 |     0.2
    7 |   1.3992 |     46.188 |   1.3759 |     45.963 |     0.3
    8 |   1.3936 |     46.083 |   1.3703 |     46.147 |     0.3
    9 |   1.3709 |     45.862 |   1.3450 |     45.199 |     0.4
   10 |   1.3455 |     45.326 |   1.3209 |     45.382 |     0.4
   11 |   1.3274 |     45.420 |   1.3239 |     45.291 |     0.4
   12 |   1.3171 |     45.172 |   1.2971 |     45.046 |     0.5
   13 |   1.2985 |     44.923 |   1.2829 |     44.862 |     0.5
   14 |   1.2781 |     44.222 |   1.2805 |     44.343 |     0.6
   15 |   1.2688 |     44.106 |   1.2709 |     44.312 |     0.6
   16 |   1.2617 |     43.669 |   1.2615 |     43.547 |     0.6
   17 |   1.2431 |     42.885 |   1.2582 |     42.966 |     0.7
   18 |   1.2284 |     42.459 |   1.2371 |     42.905 |     0.7
   19 |   1.2114 |     41.294 |   1.2256 |     41.468 |     0.8
   20 |   1.1947 |     40.631 |   1.2500 |     41.498 |     0.8
   21 |   1.1903 |     40.288 |   1.2075 |     41.498 |     0.8
   22 |   1.1685 |     39.902 |   1.2143 |     40.795 |     0.9
   23 |   1.1553 |     39.344 |   1.1887 |     39.939 |     0.9
   24 |   1.1403 |     38.653 |   1.1943 |     40.581 |     1.0
   25 |   1.1440 |     38.587 |   1.1790 |     39.908 |     1.0
   26 |   1.1237 |     38.244 |   1.1707 |     40.000 |     1.1
   27 |   1.1142 |     37.841 |   1.1639 |     39.419 |     1.1
   28 |   1.0991 |     37.548 |   1.1655 |     38.838 |     1.1
   29 |   1.0839 |     37.095 |   1.1651 |     38.899 |     1.2
   30 |   1.0756 |     36.466 |   1.1602 |     38.777 |     1.2
   31 |   1.0551 |     35.609 |   1.1432 |     37.982 |     1.3
   32 |   1.0364 |     35.101 |   1.1478 |     38.012 |     1.3
   33 |   1.0412 |     35.223 |   1.1414 |     38.165 |     1.3
   34 |   1.0302 |     34.748 |   1.1436 |     37.309 |     1.4
   35 |   1.0110 |     34.317 |   1.1106 |     36.942 |     1.4
   36 |   1.0074 |     34.007 |   1.1178 |     37.462 |     1.5
   37 |   0.9956 |     33.715 |   1.1288 |     36.606 |     1.5
   38 |   0.9864 |     33.720 |   1.1230 |     36.514 |     1.5
   39 |   0.9975 |     33.444 |   1.1481 |     36.850 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,778,722

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5306 |     67.203 |   1.9660 |     53.823 |     0.1
    2 |   1.7431 |     49.392 |   1.5346 |     45.963 |     0.1
    3 |   1.4827 |     46.161 |   1.4224 |     45.963 |     0.2
    4 |   1.4236 |     46.089 |   1.3940 |     46.422 |     0.2
    5 |   1.4056 |     46.161 |   1.3869 |     45.963 |     0.3
    6 |   1.3983 |     46.144 |   1.3775 |     45.994 |     0.4
    7 |   1.3927 |     46.155 |   1.3713 |     45.963 |     0.4
    8 |   1.3874 |     46.089 |   1.3701 |     45.963 |     0.5
    9 |   1.3839 |     45.934 |   1.3615 |     45.474 |     0.6
   10 |   1.3740 |     45.448 |   1.3564 |     44.985 |     0.6
   11 |   1.3595 |     44.995 |   1.3456 |     45.199 |     0.7
   12 |   1.3464 |     44.829 |   1.3380 |     44.893 |     0.7
   13 |   1.3368 |     44.619 |   1.3326 |     44.771 |     0.8
   14 |   1.3288 |     44.653 |   1.3274 |     44.832 |     0.9
   15 |   1.3236 |     44.437 |   1.3224 |     44.404 |     0.9
   16 |   1.3149 |     44.271 |   1.3224 |     44.862 |     1.0
   17 |   1.3094 |     44.006 |   1.3061 |     43.731 |     1.1
   18 |   1.3031 |     43.708 |   1.3019 |     44.037 |     1.1
   19 |   1.2947 |     43.332 |   1.3001 |     43.670 |     1.2
   20 |   1.2864 |     42.841 |   1.2956 |     43.456 |     1.2
   21 |   1.2749 |     42.564 |   1.2898 |     43.578 |     1.3
   22 |   1.2665 |     42.426 |   1.2840 |     42.813 |     1.4
   23 |   1.2557 |     41.946 |   1.2760 |     42.844 |     1.4
   24 |   1.2494 |     42.272 |   1.2695 |     42.569 |     1.5
   25 |   1.2394 |     41.664 |   1.2791 |     42.385 |     1.6
   26 |   1.2268 |     41.012 |   1.2709 |     42.202 |     1.6
   27 |   1.2201 |     40.973 |   1.2659 |     42.141 |     1.7
   28 |   1.2171 |     40.946 |   1.2604 |     41.743 |     1.7
   29 |   1.2152 |     40.907 |   1.2679 |     41.437 |     1.8
   30 |   1.2097 |     40.857 |   1.2535 |     41.713 |     1.9
   31 |   1.1937 |     40.261 |   1.2361 |     41.651 |     1.9
   32 |   1.1870 |     40.266 |   1.2428 |     41.835 |     2.0
   33 |   1.1728 |     39.504 |   1.2353 |     40.826 |     2.0
   34 |   1.1678 |     39.090 |   1.2368 |     40.398 |     2.1
   35 |   1.1527 |     38.697 |   1.2324 |     40.183 |     2.2
   36 |   1.1503 |     38.675 |   1.2284 |     39.939 |     2.2
   37 |   1.1397 |     38.128 |   1.2183 |     40.428 |     2.3
   38 |   1.1312 |     37.946 |   1.2104 |     40.245 |     2.4
   39 |   1.1191 |     37.548 |   1.2068 |     39.847 |     2.4
   40 |   1.1099 |     37.344 |   1.2063 |     40.092 |     2.5
   41 |   1.1105 |     37.465 |   1.1974 |     39.694 |     2.5
   42 |   1.1018 |     36.709 |   1.1994 |     38.685 |     2.6
   43 |   1.1001 |     36.869 |   1.2023 |     39.511 |     2.7
   44 |   1.0843 |     36.841 |   1.1930 |     39.052 |     2.7
   45 |   1.0785 |     36.261 |   1.1792 |     38.287 |     2.8
   46 |   1.0646 |     35.880 |   1.1789 |     38.257 |     2.9
   47 |   1.0637 |     35.919 |   1.1681 |     38.471 |     2.9
   48 |   1.0463 |     35.322 |   1.1572 |     37.492 |     3.0
   49 |   1.0421 |     35.040 |   1.1654 |     37.278 |     3.0
   50 |   1.0329 |     34.770 |   1.1683 |     37.217 |     3.1
   51 |   1.0285 |     34.366 |   1.1542 |     37.462 |     3.2
   52 |   1.0049 |     33.803 |   1.1437 |     36.789 |     3.2
   53 |   1.0067 |     33.864 |   1.1432 |     37.217 |     3.3
   54 |   1.0005 |     34.079 |   1.1455 |     36.544 |     3.4
   55 |   0.9871 |     33.140 |   1.1362 |     37.095 |     3.4
   56 |   0.9817 |     33.234 |   1.1531 |     36.758 |     3.5
   57 |   0.9842 |     33.499 |   1.1728 |     37.125 |     3.5
   58 |   0.9781 |     33.079 |   1.1266 |     36.208 |     3.6
   59 |   0.9552 |     32.483 |   1.1265 |     35.963 |     3.7
   60 |   0.9500 |     32.333 |   1.1220 |     35.872 |     3.7
   61 |   0.9325 |     31.488 |   1.1035 |     35.566 |     3.8
   62 |   0.9257 |     31.289 |   1.1047 |     36.330 |     3.9
   63 |   0.9393 |     32.190 |   1.1074 |     36.789 |     3.9
   64 |   0.9208 |     30.974 |   1.1249 |     35.566 |     4.0
   65 |   0.9084 |     30.754 |   1.1121 |     35.688 |     4.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 669,858

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4693 |     65.971 |   1.9706 |     56.239 |     0.0
    2 |   1.7623 |     49.785 |   1.5704 |     45.963 |     0.1
    3 |   1.4953 |     45.846 |   1.4200 |     45.688 |     0.1
    4 |   1.4042 |     45.001 |   1.3744 |     44.740 |     0.1
    5 |   1.3566 |     44.045 |   1.3373 |     44.128 |     0.1
    6 |   1.3213 |     43.106 |   1.3220 |     42.875 |     0.2
    7 |   1.2888 |     42.620 |   1.2881 |     42.722 |     0.2
    8 |   1.2627 |     41.570 |   1.2774 |     42.355 |     0.2
    9 |   1.2353 |     40.951 |   1.2640 |     41.407 |     0.2
   10 |   1.2059 |     39.913 |   1.2336 |     40.367 |     0.3
   11 |   1.1778 |     39.134 |   1.2338 |     40.000 |     0.3
   12 |   1.1498 |     37.913 |   1.2231 |     39.572 |     0.3
   13 |   1.1175 |     36.808 |   1.1846 |     38.349 |     0.4
   14 |   1.0890 |     35.725 |   1.1766 |     37.890 |     0.4
   15 |   1.0598 |     34.781 |   1.1537 |     36.728 |     0.4
   16 |   1.0279 |     33.433 |   1.1484 |     36.514 |     0.4
   17 |   1.0051 |     32.499 |   1.1282 |     35.505 |     0.5
   18 |   0.9791 |     31.847 |   1.1076 |     35.382 |     0.5
   19 |   0.9523 |     30.986 |   1.1050 |     35.963 |     0.5
   20 |   0.9262 |     30.240 |   1.0859 |     34.648 |     0.5
   21 |   0.8962 |     28.582 |   1.0830 |     34.251 |     0.6
   22 |   0.8724 |     28.273 |   1.0784 |     34.312 |     0.6
   23 |   0.8561 |     27.599 |   1.0652 |     32.905 |     0.6
   24 |   0.8442 |     27.235 |   1.0713 |     32.630 |     0.6
   25 |   0.8176 |     26.025 |   1.0461 |     32.018 |     0.7
   26 |   0.7905 |     25.213 |   1.0489 |     32.232 |     0.7
   27 |   0.7602 |     24.544 |   1.0281 |     32.141 |     0.7
   28 |   0.7456 |     23.870 |   1.0427 |     32.355 |     0.8
   29 |   0.7278 |     23.384 |   1.0493 |     31.927 |     0.8
   30 |   0.7021 |     22.362 |   1.0416 |     32.263 |     0.8
   31 |   0.6725 |     21.268 |   1.0474 |     30.887 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 587,106

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2216 |     60.866 |   1.5692 |     48.777 |     0.0
    2 |   1.4613 |     46.078 |   1.3907 |     45.780 |     0.0
    3 |   1.3760 |     45.608 |   1.3342 |     44.618 |     0.0
    4 |   1.3207 |     44.398 |   1.2946 |     44.373 |     0.1
    5 |   1.2703 |     43.017 |   1.2452 |     42.110 |     0.1
    6 |   1.2244 |     41.134 |   1.2090 |     40.917 |     0.1
    7 |   1.1751 |     39.609 |   1.1889 |     40.153 |     0.1
    8 |   1.1364 |     38.322 |   1.1669 |     39.235 |     0.1
    9 |   1.0949 |     37.554 |   1.1242 |     38.349 |     0.1
   10 |   1.0497 |     35.538 |   1.1110 |     36.728 |     0.1
   11 |   1.0079 |     34.156 |   1.1072 |     37.095 |     0.2
   12 |   0.9706 |     32.726 |   1.0655 |     35.933 |     0.2
   13 |   0.9374 |     31.361 |   1.0653 |     34.648 |     0.2
   14 |   0.8949 |     29.903 |   1.0468 |     33.517 |     0.2
   15 |   0.8598 |     28.141 |   1.0147 |     32.752 |     0.2
   16 |   0.8234 |     26.947 |   0.9957 |     31.376 |     0.2
   17 |   0.7872 |     25.710 |   0.9978 |     31.590 |     0.3
   18 |   0.7543 |     24.445 |   0.9862 |     30.245 |     0.3
   19 |   0.7283 |     23.489 |   0.9831 |     29.847 |     0.3
   20 |   0.7059 |     22.705 |   0.9862 |     29.755 |     0.3
   21 |   0.6758 |     21.511 |   0.9701 |     28.593 |     0.3
   22 |   0.6458 |     20.473 |   0.9606 |     28.654 |     0.3
   23 |   0.6253 |     19.832 |   0.9829 |     29.174 |     0.3
   24 |   0.5995 |     19.048 |   0.9651 |     28.104 |     0.4
   25 |   0.5816 |     18.534 |   0.9534 |     27.156 |     0.4
   26 |   0.5557 |     17.650 |   0.9612 |     27.401 |     0.4
   27 |   0.5344 |     16.805 |   0.9577 |     27.676 |     0.4
   28 |   0.5260 |     16.650 |   0.9345 |     27.339 |     0.4
   29 |   0.4992 |     15.672 |   0.9188 |     26.514 |     0.4
   30 |   0.4822 |     15.076 |   0.9091 |     24.985 |     0.4
   31 |   0.4706 |     14.938 |   0.9435 |     26.208 |     0.5
   32 |   0.4571 |     14.402 |   0.9407 |     25.841 |     0.5
   33 |   0.4315 |     13.496 |   0.9170 |     25.596 |     0.5
   34 |   0.4271 |     13.557 |   0.9775 |     26.697 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 274,594

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6256 |     70.175 |   2.0622 |     58.654 |     0.0
    2 |   1.8123 |     51.243 |   1.5875 |     45.963 |     0.0
    3 |   1.5169 |     46.089 |   1.4440 |     45.963 |     0.0
    4 |   1.4392 |     46.100 |   1.4071 |     45.963 |     0.1
    5 |   1.4122 |     46.150 |   1.3867 |     46.361 |     0.1
    6 |   1.3931 |     46.072 |   1.3636 |     45.810 |     0.1
    7 |   1.3689 |     45.282 |   1.3479 |     45.199 |     0.1
    8 |   1.3464 |     44.818 |   1.3319 |     44.587 |     0.1
    9 |   1.3327 |     44.730 |   1.3167 |     44.618 |     0.1
   10 |   1.3125 |     44.282 |   1.3072 |     44.801 |     0.1
   11 |   1.2973 |     44.177 |   1.3085 |     44.251 |     0.2
   12 |   1.2784 |     43.365 |   1.2795 |     43.639 |     0.2
   13 |   1.2584 |     42.841 |   1.2640 |     42.966 |     0.2
   14 |   1.2424 |     42.001 |   1.2722 |     42.813 |     0.2
   15 |   1.2255 |     41.399 |   1.2512 |     41.835 |     0.2
   16 |   1.2018 |     40.183 |   1.2446 |     41.774 |     0.2
   17 |   1.1851 |     39.846 |   1.2374 |     42.110 |     0.2
   18 |   1.1585 |     39.018 |   1.2151 |     41.009 |     0.3
   19 |   1.1388 |     38.703 |   1.2309 |     40.642 |     0.3
   20 |   1.1223 |     38.255 |   1.2112 |     40.459 |     0.3
   21 |   1.1044 |     37.775 |   1.1876 |     39.480 |     0.3
   22 |   1.0733 |     36.339 |   1.1784 |     39.083 |     0.3
   23 |   1.0635 |     36.366 |   1.1681 |     39.052 |     0.3
   24 |   1.0439 |     35.322 |   1.1634 |     38.410 |     0.3
   25 |   1.0239 |     34.648 |   1.1779 |     38.807 |     0.4
   26 |   1.0059 |     34.134 |   1.1488 |     37.890 |     0.4
   27 |   0.9876 |     33.394 |   1.1272 |     37.462 |     0.4
   28 |   0.9722 |     32.698 |   1.1212 |     36.942 |     0.4
   29 |   0.9406 |     31.809 |   1.1385 |     36.758 |     0.4
   30 |   0.9227 |     30.687 |   1.1003 |     35.443 |     0.4
   31 |   0.9009 |     29.881 |   1.1045 |     35.719 |     0.4
   32 |   0.8790 |     28.571 |   1.1163 |     35.321 |     0.4
   33 |   0.8580 |     28.339 |   1.0890 |     34.862 |     0.5
   34 |   0.8388 |     27.555 |   1.0908 |     34.832 |     0.5
   35 |   0.8245 |     27.411 |   1.1068 |     34.709 |     0.5
   36 |   0.8081 |     26.892 |   1.0857 |     34.373 |     0.5
   37 |   0.7888 |     26.019 |   1.0885 |     33.364 |     0.5
   38 |   0.7750 |     25.439 |   1.1139 |     34.801 |     0.5
   39 |   0.7555 |     24.633 |   1.0814 |     33.609 |     0.5
   40 |   0.7255 |     23.506 |   1.1007 |     34.190 |     0.6
   41 |   0.7097 |     22.953 |   1.0900 |     33.578 |     0.6
   42 |   0.6971 |     22.428 |   1.0784 |     33.211 |     0.6
   43 |   0.6800 |     21.716 |   1.0795 |     33.150 |     0.6
   44 |   0.6697 |     21.821 |   1.0875 |     32.783 |     0.6
   45 |   0.6554 |     21.119 |   1.0960 |     32.997 |     0.6
   46 |   0.6434 |     20.556 |   1.0685 |     32.018 |     0.6
   47 |   0.6323 |     20.246 |   1.1028 |     32.569 |     0.7
   48 |   0.6124 |     19.473 |   1.0890 |     32.049 |     0.7
   49 |   0.6041 |     19.003 |   1.0944 |     31.651 |     0.7
   50 |   0.5965 |     18.987 |   1.0882 |     31.498 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 527,458

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5673 |     68.926 |   1.9923 |     53.761 |     0.0
    2 |   1.7759 |     50.210 |   1.5787 |     45.963 |     0.0
    3 |   1.5121 |     46.089 |   1.4433 |     45.963 |     0.1
    4 |   1.4376 |     46.094 |   1.4088 |     45.963 |     0.1
    5 |   1.4120 |     46.210 |   1.3891 |     45.963 |     0.1
    6 |   1.4015 |     46.177 |   1.3766 |     45.749 |     0.1
    7 |   1.3907 |     46.056 |   1.3693 |     45.933 |     0.1
    8 |   1.3792 |     45.597 |   1.3579 |     44.924 |     0.2
    9 |   1.3564 |     44.669 |   1.3384 |     44.495 |     0.2
   10 |   1.3374 |     44.664 |   1.3273 |     44.618 |     0.2
   11 |   1.3198 |     44.260 |   1.3284 |     44.832 |     0.2
   12 |   1.3125 |     44.012 |   1.3190 |     44.159 |     0.2
   13 |   1.3034 |     43.818 |   1.3158 |     44.526 |     0.2
   14 |   1.2908 |     43.316 |   1.3034 |     44.190 |     0.3
   15 |   1.2794 |     42.968 |   1.2956 |     42.966 |     0.3
   16 |   1.2713 |     42.653 |   1.3118 |     44.312 |     0.3
   17 |   1.2602 |     42.255 |   1.2745 |     42.691 |     0.3
   18 |   1.2385 |     41.272 |   1.2731 |     42.783 |     0.3
   19 |   1.2237 |     41.255 |   1.2599 |     41.774 |     0.4
   20 |   1.2056 |     40.200 |   1.2618 |     41.804 |     0.4
   21 |   1.1953 |     40.001 |   1.2718 |     41.682 |     0.4
   22 |   1.1818 |     39.565 |   1.2543 |     41.254 |     0.4
   23 |   1.1708 |     39.377 |   1.2509 |     41.896 |     0.4
   24 |   1.1579 |     39.056 |   1.2341 |     40.917 |     0.5
   25 |   1.1399 |     38.719 |   1.2380 |     40.673 |     0.5
   26 |   1.1242 |     38.217 |   1.2270 |     40.428 |     0.5
   27 |   1.1140 |     37.830 |   1.2202 |     40.520 |     0.5
   28 |   1.1055 |     37.620 |   1.2246 |     40.459 |     0.5
   29 |   1.0859 |     36.996 |   1.2128 |     40.306 |     0.6
   30 |   1.0802 |     37.140 |   1.1901 |     40.489 |     0.6
   31 |   1.0644 |     36.372 |   1.2123 |     39.664 |     0.6
   32 |   1.0446 |     35.466 |   1.2047 |     39.572 |     0.6
   33 |   1.0329 |     35.035 |   1.1746 |     38.807 |     0.6
   34 |   1.0184 |     34.499 |   1.2098 |     39.052 |     0.7
   35 |   1.0082 |     34.079 |   1.1981 |     39.205 |     0.7
   36 |   0.9823 |     33.112 |   1.1868 |     38.379 |     0.7
   37 |   0.9626 |     32.262 |   1.1819 |     37.737 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,832,482

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4710 |     65.451 |   1.9758 |     57.951 |     0.1
    2 |   1.7307 |     48.862 |   1.5309 |     45.963 |     0.1
    3 |   1.4802 |     46.150 |   1.4176 |     46.024 |     0.2
    4 |   1.4093 |     46.100 |   1.3776 |     45.872 |     0.2
    5 |   1.3711 |     45.194 |   1.3478 |     45.291 |     0.3
    6 |   1.3402 |     44.233 |   1.3209 |     43.517 |     0.4
    7 |   1.3035 |     43.056 |   1.3041 |     43.242 |     0.4
    8 |   1.2729 |     42.332 |   1.2617 |     42.416 |     0.5
    9 |   1.2400 |     41.321 |   1.2586 |     41.223 |     0.5
   10 |   1.2165 |     40.614 |   1.2464 |     40.856 |     0.6
   11 |   1.1896 |     39.730 |   1.2147 |     40.245 |     0.7
   12 |   1.1687 |     39.316 |   1.2136 |     39.052 |     0.7
   13 |   1.1450 |     38.344 |   1.1939 |     39.358 |     0.8
   14 |   1.1218 |     37.885 |   1.1704 |     38.807 |     0.8
   15 |   1.0906 |     36.874 |   1.1622 |     38.165 |     0.9
   16 |   1.0644 |     35.510 |   1.1397 |     36.942 |     0.9
   17 |   1.0610 |     35.433 |   1.1557 |     38.410 |     1.0
   18 |   1.0449 |     34.864 |   1.1356 |     36.697 |     1.1
   19 |   1.0164 |     34.018 |   1.1318 |     36.422 |     1.1
   20 |   0.9923 |     32.809 |   1.1062 |     35.902 |     1.2
   21 |   0.9690 |     31.709 |   1.1041 |     35.841 |     1.2
   22 |   0.9571 |     31.439 |   1.0829 |     34.067 |     1.3
   23 |   0.9142 |     29.627 |   1.0664 |     33.853 |     1.4
   24 |   0.9211 |     30.135 |   1.0665 |     34.251 |     1.4
   25 |   0.9045 |     29.853 |   1.0558 |     33.456 |     1.5
   26 |   0.8793 |     28.781 |   1.0594 |     33.394 |     1.5
   27 |   0.8618 |     28.234 |   1.0645 |     32.049 |     1.6
   28 |   0.8400 |     27.345 |   1.0483 |     32.722 |     1.7
   29 |   0.8216 |     26.991 |   1.0472 |     32.599 |     1.7
   30 |   0.8076 |     26.334 |   1.0316 |     32.171 |     1.8
   31 |   0.7843 |     25.445 |   1.0201 |     31.957 |     1.8
   32 |   0.7655 |     25.019 |   1.0149 |     31.468 |     1.9
   33 |   0.7438 |     24.008 |   1.0122 |     31.529 |     2.0
   34 |   0.7300 |     23.655 |   1.0098 |     31.468 |     2.0
   35 |   0.7192 |     23.301 |   0.9940 |     30.887 |     2.1
   36 |   0.7079 |     22.810 |   1.0079 |     31.101 |     2.1
   37 |   0.6922 |     22.158 |   1.0036 |     31.560 |     2.2
   38 |   0.6858 |     21.760 |   1.0239 |     31.437 |     2.3
   39 |   0.6760 |     21.727 |   0.9866 |     31.284 |     2.3
   40 |   0.6586 |     21.379 |   0.9876 |     30.642 |     2.4
   41 |   0.6370 |     20.539 |   1.0003 |     31.437 |     2.4
   42 |   0.6340 |     20.528 |   0.9885 |     30.826 |     2.5
   43 |   0.6198 |     20.059 |   0.9636 |     29.572 |     2.6
   44 |   0.6023 |     19.628 |   0.9923 |     30.306 |     2.6
   45 |   0.6049 |     19.572 |   0.9885 |     30.306 |     2.7
   46 |   0.5866 |     18.755 |   0.9874 |     30.612 |     2.7
   47 |   0.5720 |     18.528 |   0.9720 |     30.336 |     2.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 851,298

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5228 |     67.849 |   1.9801 |     58.165 |     0.0
    2 |   1.7797 |     51.166 |   1.5753 |     46.024 |     0.1
    3 |   1.5137 |     46.100 |   1.4386 |     45.963 |     0.1
    4 |   1.4272 |     45.890 |   1.3884 |     44.924 |     0.1
    5 |   1.3750 |     44.172 |   1.3498 |     44.281 |     0.2
    6 |   1.3368 |     43.238 |   1.3225 |     43.456 |     0.2
    7 |   1.3107 |     42.752 |   1.2974 |     42.508 |     0.2
    8 |   1.2842 |     42.056 |   1.2959 |     42.110 |     0.3
    9 |   1.2593 |     41.332 |   1.2687 |     41.896 |     0.3
   10 |   1.2342 |     40.692 |   1.2640 |     40.306 |     0.3
   11 |   1.2153 |     39.786 |   1.2427 |     40.214 |     0.4
   12 |   1.1945 |     39.239 |   1.2331 |     39.419 |     0.4
   13 |   1.1713 |     38.576 |   1.2097 |     39.021 |     0.4
   14 |   1.1482 |     37.852 |   1.2028 |     38.991 |     0.5
   15 |   1.1264 |     37.090 |   1.1941 |     38.349 |     0.5
   16 |   1.1112 |     36.344 |   1.1823 |     37.768 |     0.5
   17 |   1.0833 |     35.571 |   1.1907 |     37.798 |     0.6
   18 |   1.0665 |     34.819 |   1.1658 |     37.768 |     0.6
   19 |   1.0401 |     33.963 |   1.1549 |     36.422 |     0.6
   20 |   1.0315 |     33.604 |   1.1405 |     35.780 |     0.7
   21 |   1.0060 |     32.764 |   1.1199 |     35.749 |     0.7
   22 |   0.9956 |     32.262 |   1.1165 |     35.138 |     0.7
   23 |   0.9690 |     31.593 |   1.1128 |     35.229 |     0.8
   24 |   0.9466 |     30.754 |   1.0913 |     34.312 |     0.8
   25 |   0.9275 |     29.776 |   1.0733 |     34.067 |     0.8
   26 |   0.9115 |     29.113 |   1.0975 |     34.220 |     0.9
   27 |   0.9023 |     29.168 |   1.0842 |     33.853 |     0.9
   28 |   0.8837 |     28.693 |   1.0701 |     33.394 |     0.9
   29 |   0.8592 |     28.019 |   1.0658 |     33.792 |     1.0
   30 |   0.8460 |     27.096 |   1.0678 |     33.578 |     1.0
   31 |   0.8294 |     26.815 |   1.0460 |     33.058 |     1.0
   32 |   0.8233 |     26.677 |   1.0589 |     33.364 |     1.1
   33 |   0.8094 |     26.572 |   1.0407 |     32.263 |     1.1
   34 |   0.7893 |     25.621 |   1.0306 |     32.110 |     1.2
   35 |   0.7719 |     24.942 |   1.0499 |     32.844 |     1.2
   36 |   0.7669 |     25.097 |   1.0456 |     33.089 |     1.2
   37 |   0.7510 |     24.599 |   1.0267 |     31.376 |     1.3
   38 |   0.7396 |     23.876 |   1.0153 |     31.407 |     1.3
   39 |   0.7327 |     23.694 |   1.0328 |     32.018 |     1.3
   40 |   0.7172 |     23.257 |   1.0489 |     32.355 |     1.4
   41 |   0.7114 |     23.401 |   1.0391 |     32.385 |     1.4
   42 |   0.6872 |     22.351 |   1.0471 |     32.141 |     1.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,523,106

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2438 |     61.192 |   1.6326 |     45.963 |     0.0
    2 |   1.5025 |     46.199 |   1.4068 |     46.361 |     0.1
    3 |   1.4199 |     46.161 |   1.3895 |     45.963 |     0.1
    4 |   1.3970 |     46.133 |   1.3711 |     45.872 |     0.2
    5 |   1.3739 |     45.536 |   1.3442 |     44.801 |     0.2
    6 |   1.3423 |     44.735 |   1.3251 |     44.771 |     0.3
    7 |   1.3184 |     43.664 |   1.3178 |     43.547 |     0.3
    8 |   1.2996 |     43.382 |   1.2906 |     42.722 |     0.3
    9 |   1.2774 |     42.272 |   1.2770 |     42.997 |     0.4
   10 |   1.2546 |     41.642 |   1.2567 |     41.774 |     0.4
   11 |   1.2295 |     41.012 |   1.2382 |     41.590 |     0.5
   12 |   1.2144 |     40.741 |   1.2276 |     40.856 |     0.5
   13 |   1.1873 |     39.736 |   1.2113 |     40.398 |     0.5
   14 |   1.1635 |     39.272 |   1.1875 |     40.245 |     0.6
   15 |   1.1422 |     38.742 |   1.1811 |     40.061 |     0.6
   16 |   1.1244 |     38.427 |   1.1635 |     39.480 |     0.7
   17 |   1.1138 |     37.543 |   1.1540 |     37.645 |     0.7
   18 |   1.0789 |     36.223 |   1.1295 |     37.645 |     0.8
   19 |   1.0515 |     35.444 |   1.1145 |     37.462 |     0.8
   20 |   1.0279 |     34.516 |   1.1019 |     36.636 |     0.8
   21 |   1.0032 |     33.521 |   1.0871 |     36.147 |     0.9
   22 |   0.9899 |     32.991 |   1.0897 |     36.024 |     0.9
   23 |   0.9762 |     32.687 |   1.0845 |     35.657 |     1.0
   24 |   0.9536 |     32.008 |   1.0806 |     35.046 |     1.0
   25 |   0.9347 |     31.008 |   1.0712 |     36.177 |     1.0
   26 |   0.9147 |     30.720 |   1.0668 |     34.648 |     1.1
   27 |   0.8891 |     29.555 |   1.0573 |     34.495 |     1.1
   28 |   0.8713 |     29.229 |   1.0347 |     33.761 |     1.2
   29 |   0.8446 |     28.234 |   1.0481 |     33.761 |     1.2
   30 |   0.8334 |     28.096 |   1.0329 |     33.914 |     1.3
   31 |   0.8298 |     27.925 |   1.0417 |     32.905 |     1.3
   32 |   0.8026 |     26.881 |   1.0276 |     32.813 |     1.3
   33 |   0.7752 |     25.920 |   1.0327 |     32.294 |     1.4
   34 |   0.7500 |     24.903 |   1.0331 |     32.355 |     1.4
   35 |   0.7396 |     24.666 |   1.0080 |     31.835 |     1.5
   36 |   0.7128 |     23.660 |   1.0050 |     31.254 |     1.5
   37 |   0.6962 |     23.053 |   1.0057 |     31.437 |     1.5
   38 |   0.6958 |     23.229 |   1.0030 |     31.254 |     1.6
   39 |   0.6820 |     22.655 |   1.0075 |     31.131 |     1.6
   40 |   0.6530 |     21.583 |   1.0171 |     31.376 |     1.7
   41 |   0.6335 |     20.981 |   1.0085 |     30.979 |     1.7
   42 |   0.6374 |     21.163 |   1.0076 |     30.887 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 748,514

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2872 |     62.010 |   1.6417 |     48.777 |     0.0
    2 |   1.4940 |     46.282 |   1.3966 |     45.321 |     0.0
    3 |   1.3768 |     44.730 |   1.3415 |     44.220 |     0.1
    4 |   1.3217 |     43.863 |   1.3038 |     43.394 |     0.1
    5 |   1.2753 |     42.669 |   1.2629 |     42.691 |     0.1
    6 |   1.2415 |     41.576 |   1.2396 |     41.070 |     0.1
    7 |   1.2032 |     40.189 |   1.2093 |     40.795 |     0.1
    8 |   1.1724 |     39.393 |   1.1962 |     40.336 |     0.1
    9 |   1.1461 |     38.371 |   1.1923 |     40.153 |     0.2
   10 |   1.1204 |     37.697 |   1.1628 |     39.205 |     0.2
   11 |   1.0896 |     37.079 |   1.1376 |     38.440 |     0.2
   12 |   1.0529 |     35.554 |   1.1182 |     36.942 |     0.2
   13 |   1.0266 |     34.748 |   1.1108 |     36.269 |     0.2
   14 |   0.9882 |     33.129 |   1.0981 |     35.596 |     0.3
   15 |   0.9735 |     32.891 |   1.0836 |     35.046 |     0.3
   16 |   0.9292 |     30.986 |   1.0812 |     35.352 |     0.3
   17 |   0.9016 |     29.941 |   1.0437 |     33.211 |     0.3
   18 |   0.8704 |     28.925 |   1.0338 |     32.722 |     0.3
   19 |   0.8397 |     28.185 |   1.0346 |     33.578 |     0.3
   20 |   0.8085 |     26.721 |   1.0215 |     31.927 |     0.4
   21 |   0.7796 |     25.594 |   0.9921 |     31.743 |     0.4
   22 |   0.7458 |     24.638 |   0.9916 |     30.765 |     0.4
   23 |   0.7231 |     23.660 |   0.9758 |     31.621 |     0.4
   24 |   0.7031 |     23.279 |   0.9494 |     29.694 |     0.4
   25 |   0.6710 |     21.981 |   0.9769 |     30.336 |     0.5
   26 |   0.6454 |     21.081 |   0.9814 |     30.245 |     0.5
   27 |   0.6291 |     20.628 |   0.9702 |     29.817 |     0.5
   28 |   0.6057 |     19.677 |   0.9558 |     28.869 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 302,434

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6151 |     70.346 |   2.0134 |     58.654 |     0.0
    2 |   1.7718 |     50.398 |   1.5555 |     45.963 |     0.0
    3 |   1.5008 |     46.089 |   1.4377 |     45.963 |     0.0
    4 |   1.4319 |     46.094 |   1.4100 |     45.902 |     0.1
    5 |   1.4038 |     46.072 |   1.3758 |     45.933 |     0.1
    6 |   1.3770 |     45.619 |   1.3522 |     45.199 |     0.1
    7 |   1.3530 |     44.951 |   1.3300 |     45.199 |     0.1
    8 |   1.3297 |     44.730 |   1.3222 |     45.015 |     0.1
    9 |   1.3190 |     44.553 |   1.3130 |     44.709 |     0.1
   10 |   1.3030 |     44.028 |   1.2975 |     43.945 |     0.1
   11 |   1.2855 |     43.498 |   1.2938 |     43.731 |     0.2
   12 |   1.2679 |     42.708 |   1.2870 |     43.058 |     0.2
   13 |   1.2459 |     41.211 |   1.2715 |     42.110 |     0.2
   14 |   1.2180 |     40.421 |   1.2515 |     41.621 |     0.2
   15 |   1.1913 |     39.587 |   1.2410 |     41.223 |     0.2
   16 |   1.1660 |     39.228 |   1.2247 |     40.581 |     0.2
   17 |   1.1398 |     38.410 |   1.2311 |     40.520 |     0.2
   18 |   1.1187 |     37.797 |   1.2072 |     40.092 |     0.3
   19 |   1.0957 |     37.427 |   1.2020 |     39.083 |     0.3
   20 |   1.0714 |     36.769 |   1.1869 |     39.541 |     0.3
   21 |   1.0503 |     36.029 |   1.1980 |     39.174 |     0.3
   22 |   1.0257 |     35.217 |   1.1888 |     38.991 |     0.3
   23 |   0.9955 |     34.604 |   1.1288 |     38.073 |     0.3
   24 |   0.9693 |     33.239 |   1.1326 |     37.370 |     0.3
   25 |   0.9486 |     32.449 |   1.1326 |     37.309 |     0.4
   26 |   0.9258 |     31.074 |   1.1476 |     36.483 |     0.4
   27 |   0.8977 |     30.074 |   1.1382 |     36.972 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 325,378

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6213 |     70.661 |   2.0206 |     58.654 |     0.0
    2 |   1.7878 |     50.409 |   1.5742 |     45.963 |     0.0
    3 |   1.5108 |     46.199 |   1.4407 |     45.963 |     0.1
    4 |   1.4360 |     46.089 |   1.4010 |     45.963 |     0.1
    5 |   1.4092 |     46.089 |   1.3834 |     46.055 |     0.1
    6 |   1.3878 |     46.155 |   1.3696 |     45.902 |     0.1
    7 |   1.3661 |     45.663 |   1.3475 |     45.291 |     0.1
    8 |   1.3421 |     44.824 |   1.3232 |     44.037 |     0.1
    9 |   1.3102 |     43.885 |   1.3004 |     44.373 |     0.2
   10 |   1.2741 |     42.476 |   1.2702 |     43.028 |     0.2
   11 |   1.2283 |     41.134 |   1.2324 |     41.223 |     0.2
   12 |   1.1887 |     40.150 |   1.2072 |     40.642 |     0.2
   13 |   1.1526 |     38.841 |   1.1891 |     40.306 |     0.2
   14 |   1.1226 |     37.985 |   1.1802 |     39.052 |     0.2
   15 |   1.0884 |     36.990 |   1.1667 |     38.043 |     0.2
   16 |   1.0581 |     35.654 |   1.1375 |     37.431 |     0.3
   17 |   1.0226 |     33.952 |   1.1453 |     36.544 |     0.3
   18 |   0.9998 |     33.295 |   1.1227 |     36.269 |     0.3
   19 |   0.9788 |     32.565 |   1.1231 |     36.514 |     0.3
   20 |   0.9493 |     31.334 |   1.1268 |     36.116 |     0.3
   21 |   0.9197 |     30.538 |   1.0999 |     34.251 |     0.3
   22 |   0.8954 |     29.295 |   1.0918 |     34.098 |     0.4
   23 |   0.8715 |     28.693 |   1.1044 |     34.495 |     0.4
   24 |   0.8485 |     28.091 |   1.0825 |     33.945 |     0.4
   25 |   0.8182 |     26.743 |   1.0522 |     33.150 |     0.4
   26 |   0.7924 |     25.666 |   1.0579 |     33.333 |     0.4
   27 |   0.7685 |     25.135 |   1.0452 |     32.446 |     0.4
   28 |   0.7347 |     23.473 |   1.0458 |     32.936 |     0.5
   29 |   0.7207 |     23.130 |   1.0522 |     31.988 |     0.5
   30 |   0.6951 |     22.196 |   1.0507 |     32.599 |     0.5
   31 |   0.6758 |     21.655 |   1.0436 |     32.630 |     0.5
   32 |   0.6580 |     20.998 |   1.0557 |     31.590 |     0.5
   33 |   0.6264 |     19.755 |   1.0481 |     31.101 |     0.5
   34 |   0.6078 |     18.838 |   1.0468 |     31.193 |     0.6
   35 |   0.5903 |     18.451 |   1.0309 |     30.245 |     0.6
   36 |   0.5701 |     17.799 |   1.0453 |     30.612 |     0.6
   37 |   0.5475 |     17.092 |   1.0583 |     30.550 |     0.6
   38 |   0.5199 |     16.070 |   1.0687 |     30.612 |     0.6
   39 |   0.5150 |     15.827 |   1.0644 |     30.061 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 368,930

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4421 |     64.838 |   1.8261 |     48.930 |     0.0
    2 |   1.6320 |     47.089 |   1.4717 |     45.627 |     0.0
    3 |   1.4282 |     45.630 |   1.3737 |     45.046 |     0.1
    4 |   1.3519 |     44.084 |   1.3283 |     42.966 |     0.1
    5 |   1.2869 |     42.316 |   1.2788 |     42.141 |     0.1
    6 |   1.2357 |     40.664 |   1.2522 |     40.826 |     0.1
    7 |   1.1923 |     39.487 |   1.2075 |     40.183 |     0.1
    8 |   1.1554 |     38.178 |   1.1696 |     38.563 |     0.2
    9 |   1.1116 |     36.725 |   1.1526 |     37.920 |     0.2
   10 |   1.0732 |     35.062 |   1.1316 |     37.584 |     0.2
   11 |   1.0343 |     33.626 |   1.1137 |     35.994 |     0.2
   12 |   0.9915 |     32.090 |   1.0870 |     34.893 |     0.3
   13 |   0.9559 |     30.770 |   1.0964 |     34.526 |     0.3
   14 |   0.9198 |     29.638 |   1.0566 |     33.364 |     0.3
   15 |   0.8851 |     28.472 |   1.0472 |     33.058 |     0.3
   16 |   0.8482 |     27.058 |   1.0249 |     32.875 |     0.3
   17 |   0.8072 |     25.649 |   1.0162 |     32.477 |     0.4
   18 |   0.7740 |     24.345 |   1.0192 |     32.171 |     0.4
   19 |   0.7445 |     23.583 |   1.0065 |     31.804 |     0.4
   20 |   0.7161 |     22.456 |   0.9918 |     30.765 |     0.4
   21 |   0.6854 |     21.583 |   0.9761 |     31.315 |     0.4
   22 |   0.6605 |     20.744 |   0.9955 |     30.398 |     0.5
   23 |   0.6244 |     19.307 |   0.9766 |     30.550 |     0.5
   24 |   0.5969 |     18.434 |   0.9760 |     29.908 |     0.5
   25 |   0.5712 |     17.512 |   0.9754 |     29.755 |     0.5
   26 |   0.5420 |     16.727 |   0.9515 |     28.777 |     0.5
   27 |   0.5212 |     15.833 |   0.9519 |     29.480 |     0.6
   28 |   0.5052 |     15.705 |   0.9848 |     30.275 |     0.6
   29 |   0.4854 |     14.860 |   0.9489 |     28.226 |     0.6
   30 |   0.4628 |     14.081 |   0.9662 |     28.624 |     0.6
   31 |   0.4529 |     13.844 |   0.9772 |     28.502 |     0.6
   32 |   0.4319 |     12.877 |   0.9683 |     28.104 |     0.7
   33 |   0.4230 |     12.927 |   0.9848 |     29.327 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 805,794

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2670 |     61.656 |   1.6460 |     48.746 |     0.0
    2 |   1.5031 |     46.658 |   1.4073 |     45.963 |     0.0
    3 |   1.4086 |     46.172 |   1.3873 |     45.963 |     0.1
    4 |   1.3905 |     46.067 |   1.3637 |     46.208 |     0.1
    5 |   1.3585 |     44.907 |   1.3333 |     44.801 |     0.1
    6 |   1.3396 |     44.592 |   1.3260 |     44.434 |     0.1
    7 |   1.3162 |     43.956 |   1.3262 |     44.954 |     0.2
    8 |   1.2989 |     43.520 |   1.3045 |     43.792 |     0.2
    9 |   1.2820 |     43.211 |   1.3034 |     43.884 |     0.2
   10 |   1.2601 |     42.399 |   1.2740 |     43.089 |     0.2
   11 |   1.2416 |     41.912 |   1.2593 |     42.477 |     0.2
   12 |   1.2121 |     40.730 |   1.2515 |     42.141 |     0.3
   13 |   1.1950 |     39.968 |   1.2543 |     41.682 |     0.3
   14 |   1.1757 |     39.349 |   1.2316 |     41.468 |     0.3
   15 |   1.1602 |     39.371 |   1.2336 |     41.193 |     0.3
   16 |   1.1176 |     37.714 |   1.2160 |     40.061 |     0.3
   17 |   1.1012 |     37.101 |   1.2143 |     39.878 |     0.4
   18 |   1.0690 |     36.040 |   1.1843 |     38.685 |     0.4
   19 |   1.0368 |     35.383 |   1.1793 |     38.838 |     0.4
   20 |   1.0095 |     34.632 |   1.1593 |     38.012 |     0.4
   21 |   0.9932 |     33.709 |   1.1762 |     37.768 |     0.5
   22 |   0.9643 |     32.726 |   1.1231 |     36.422 |     0.5
   23 |   0.9281 |     30.986 |   1.1095 |     35.199 |     0.5
   24 |   0.8908 |     29.754 |   1.1161 |     36.300 |     0.5
   25 |   0.8582 |     28.627 |   1.1068 |     35.780 |     0.5
   26 |   0.8320 |     27.688 |   1.1076 |     35.291 |     0.6
   27 |   0.8198 |     27.306 |   1.0954 |     35.015 |     0.6
   28 |   0.7956 |     26.566 |   1.0890 |     34.098 |     0.6
   29 |   0.7593 |     25.318 |   1.0895 |     34.526 |     0.6
   30 |   0.7267 |     24.141 |   1.0718 |     33.792 |     0.6
   31 |   0.7033 |     23.379 |   1.0943 |     34.098 |     0.7
   32 |   0.6817 |     22.351 |   1.0948 |     33.884 |     0.7
   33 |   0.6554 |     21.340 |   1.0980 |     33.517 |     0.7
   34 |   0.6413 |     21.224 |   1.1023 |     32.752 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 643,426

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4664 |     65.479 |   1.8643 |     49.235 |     0.0
    2 |   1.6579 |     48.078 |   1.4903 |     45.963 |     0.0
    3 |   1.4424 |     45.824 |   1.3930 |     44.985 |     0.1
    4 |   1.3635 |     44.216 |   1.3348 |     43.914 |     0.1
    5 |   1.3063 |     42.437 |   1.3068 |     42.263 |     0.1
    6 |   1.2680 |     41.261 |   1.2776 |     41.223 |     0.1
    7 |   1.2268 |     40.399 |   1.2467 |     40.520 |     0.2
    8 |   1.1841 |     39.001 |   1.2133 |     40.122 |     0.2
    9 |   1.1455 |     38.405 |   1.1950 |     38.746 |     0.2
   10 |   1.1048 |     37.101 |   1.1535 |     37.431 |     0.2
   11 |   1.0680 |     35.538 |   1.1327 |     36.881 |     0.3
   12 |   1.0338 |     34.151 |   1.1269 |     36.269 |     0.3
   13 |   0.9989 |     32.864 |   1.1012 |     34.740 |     0.3
   14 |   0.9586 |     31.035 |   1.0920 |     35.657 |     0.3
   15 |   0.9245 |     29.831 |   1.0659 |     33.547 |     0.4
   16 |   0.8949 |     28.654 |   1.0742 |     33.853 |     0.4
   17 |   0.8619 |     27.787 |   1.0783 |     34.037 |     0.4
   18 |   0.8442 |     27.224 |   1.0598 |     32.966 |     0.4
   19 |   0.8024 |     25.677 |   1.0467 |     32.263 |     0.4
   20 |   0.7635 |     24.263 |   1.0517 |     32.844 |     0.5
   21 |   0.7407 |     23.368 |   1.0604 |     32.080 |     0.5
   22 |   0.7116 |     22.522 |   1.0113 |     30.734 |     0.5
   23 |   0.6871 |     21.650 |   1.0283 |     31.437 |     0.5
   24 |   0.6642 |     21.108 |   1.0275 |     30.917 |     0.6
   25 |   0.6457 |     20.257 |   1.0010 |     31.254 |     0.6
   26 |   0.6201 |     19.528 |   1.0070 |     30.612 |     0.6
   27 |   0.5929 |     18.683 |   0.9931 |     30.612 |     0.6
   28 |   0.5734 |     18.070 |   0.9959 |     30.214 |     0.7
   29 |   0.5654 |     17.882 |   1.0052 |     30.306 |     0.7
   30 |   0.5385 |     16.650 |   1.0246 |     31.254 |     0.7
   31 |   0.5133 |     16.065 |   1.0153 |     30.122 |     0.7
   32 |   0.4894 |     14.993 |   0.9822 |     29.511 |     0.8
   33 |   0.4828 |     15.081 |   0.9977 |     29.633 |     0.8
   34 |   0.4742 |     14.910 |   1.0334 |     29.847 |     0.8
   35 |   0.4831 |     15.368 |   1.0076 |     30.092 |     0.8
   36 |   0.4551 |     14.197 |   0.9973 |     29.113 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 2,309,922

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3346 |     63.833 |   1.7118 |     53.547 |     0.1
    2 |   1.5395 |     46.824 |   1.4219 |     45.963 |     0.1
    3 |   1.4183 |     46.083 |   1.3922 |     46.361 |     0.2
    4 |   1.4024 |     46.293 |   1.3809 |     45.963 |     0.2
    5 |   1.3935 |     46.183 |   1.3753 |     45.963 |     0.3
    6 |   1.3860 |     46.304 |   1.3583 |     45.841 |     0.4
    7 |   1.3613 |     45.498 |   1.3219 |     45.046 |     0.4
    8 |   1.3230 |     44.382 |   1.2997 |     44.159 |     0.5
    9 |   1.2966 |     44.172 |   1.2794 |     43.761 |     0.6
   10 |   1.2720 |     43.553 |   1.2850 |     43.700 |     0.6
   11 |   1.2591 |     43.360 |   1.2610 |     43.150 |     0.7
   12 |   1.2443 |     42.951 |   1.2590 |     42.905 |     0.7
   13 |   1.2280 |     42.343 |   1.2323 |     42.508 |     0.8
   14 |   1.2076 |     41.896 |   1.2226 |     41.804 |     0.9
   15 |   1.1882 |     41.067 |   1.2238 |     41.896 |     0.9
   16 |   1.1780 |     40.570 |   1.1993 |     41.468 |     1.0
   17 |   1.1589 |     39.929 |   1.1960 |     40.979 |     1.0
   18 |   1.1483 |     39.631 |   1.1875 |     40.459 |     1.1
   19 |   1.1340 |     38.747 |   1.1742 |     39.878 |     1.2
   20 |   1.1201 |     38.686 |   1.1584 |     39.725 |     1.2
   21 |   1.1028 |     37.725 |   1.1532 |     39.725 |     1.3
   22 |   1.0999 |     37.747 |   1.1667 |     38.685 |     1.3
   23 |   1.0819 |     37.305 |   1.1511 |     39.083 |     1.4
   24 |   1.0645 |     36.156 |   1.1351 |     37.829 |     1.5
   25 |   1.0503 |     35.626 |   1.1432 |     38.165 |     1.5
   26 |   1.0481 |     35.720 |   1.1158 |     37.370 |     1.6
   27 |   1.0178 |     34.394 |   1.0981 |     36.881 |     1.7
   28 |   0.9970 |     33.648 |   1.0950 |     35.872 |     1.7
   29 |   0.9763 |     32.875 |   1.0864 |     35.657 |     1.8
   30 |   0.9598 |     32.367 |   1.0718 |     35.780 |     1.8
   31 |   0.9505 |     32.223 |   1.0914 |     36.177 |     1.9
   32 |   0.9370 |     31.499 |   1.0770 |     35.933 |     2.0
   33 |   0.9263 |     31.433 |   1.0620 |     34.648 |     2.0
   34 |   0.9145 |     30.632 |   1.0532 |     35.107 |     2.1
   35 |   0.9043 |     30.748 |   1.0543 |     34.862 |     2.1
   36 |   0.8871 |     29.737 |   1.0808 |     35.413 |     2.2
   37 |   0.8790 |     29.814 |   1.0793 |     35.749 |     2.3
   38 |   0.8628 |     29.339 |   1.0519 |     34.679 |     2.3
   39 |   0.8458 |     28.455 |   1.0462 |     34.128 |     2.4
   40 |   0.8351 |     28.052 |   1.0235 |     33.486 |     2.5
   41 |   0.8235 |     27.317 |   1.0409 |     33.486 |     2.5
   42 |   0.8022 |     26.677 |   1.0209 |     32.813 |     2.6
   43 |   0.8076 |     26.969 |   1.0256 |     32.661 |     2.6
   44 |   0.7816 |     26.533 |   1.0384 |     33.150 |     2.7
   45 |   0.7646 |     25.693 |   1.0041 |     31.682 |     2.8
   46 |   0.7610 |     25.749 |   1.0185 |     31.988 |     2.8
   47 |   0.7371 |     24.572 |   1.0048 |     31.254 |     2.9
   48 |   0.7294 |     24.329 |   0.9953 |     31.284 |     3.0
   49 |   0.7172 |     24.042 |   1.0125 |     32.385 |     3.0
   50 |   0.7060 |     23.511 |   1.0089 |     31.407 |     3.1
   51 |   0.6980 |     23.721 |   0.9960 |     32.049 |     3.1
   52 |   0.6896 |     23.014 |   1.0035 |     30.734 |     3.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,339,490

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2865 |     63.164 |   1.6337 |     48.838 |     0.0
    2 |   1.5030 |     46.332 |   1.4088 |     45.963 |     0.1
    3 |   1.4129 |     46.199 |   1.3840 |     45.963 |     0.1
    4 |   1.3991 |     46.139 |   1.3743 |     45.963 |     0.1
    5 |   1.3926 |     46.150 |   1.3663 |     45.657 |     0.2
    6 |   1.3756 |     45.321 |   1.3482 |     45.199 |     0.2
    7 |   1.3534 |     44.686 |   1.3552 |     44.893 |     0.3
    8 |   1.3365 |     44.404 |   1.3263 |     44.557 |     0.3
    9 |   1.3239 |     44.454 |   1.3246 |     44.190 |     0.3
   10 |   1.3171 |     44.028 |   1.3126 |     44.006 |     0.4
   11 |   1.3019 |     43.813 |   1.3133 |     44.067 |     0.4
   12 |   1.2928 |     43.492 |   1.3002 |     43.914 |     0.4
   13 |   1.2800 |     43.028 |   1.2959 |     44.128 |     0.5
   14 |   1.2661 |     42.592 |   1.2926 |     43.914 |     0.5
   15 |   1.2527 |     42.145 |   1.2827 |     43.119 |     0.5
   16 |   1.2410 |     41.802 |   1.2696 |     42.783 |     0.6
   17 |   1.2299 |     41.426 |   1.2768 |     42.875 |     0.6
   18 |   1.2128 |     40.763 |   1.2709 |     41.713 |     0.6
   19 |   1.1989 |     40.388 |   1.2773 |     41.743 |     0.7
   20 |   1.1919 |     40.167 |   1.2608 |     41.590 |     0.7
   21 |   1.1843 |     40.045 |   1.2474 |     41.896 |     0.7
   22 |   1.1672 |     39.526 |   1.2458 |     40.765 |     0.8
   23 |   1.1579 |     39.266 |   1.2411 |     41.101 |     0.8
   24 |   1.1453 |     38.935 |   1.2330 |     40.183 |     0.9
   25 |   1.1241 |     38.432 |   1.2240 |     41.131 |     0.9
   26 |   1.1102 |     37.681 |   1.2131 |     40.428 |     0.9
   27 |   1.0940 |     36.858 |   1.2006 |     39.817 |     1.0
   28 |   1.0814 |     36.510 |   1.2054 |     39.450 |     1.0
   29 |   1.0685 |     35.814 |   1.1801 |     39.083 |     1.0
   30 |   1.0565 |     35.554 |   1.1894 |     39.358 |     1.1
   31 |   1.0314 |     34.527 |   1.1811 |     38.869 |     1.1
   32 |   1.0151 |     34.079 |   1.1806 |     37.554 |     1.1
   33 |   0.9978 |     33.173 |   1.1854 |     37.584 |     1.2
   34 |   0.9947 |     33.394 |   1.1652 |     38.196 |     1.2
   35 |   0.9708 |     32.549 |   1.1584 |     37.462 |     1.2
   36 |   0.9501 |     31.858 |   1.1580 |     37.920 |     1.3
   37 |   0.9428 |     31.831 |   1.1671 |     38.104 |     1.3
   38 |   0.9305 |     31.124 |   1.1668 |     37.798 |     1.3
   39 |   0.9217 |     30.776 |   1.1548 |     37.034 |     1.4
   40 |   0.9027 |     30.091 |   1.1491 |     35.963 |     1.4
   41 |   0.8947 |     29.803 |   1.1470 |     36.850 |     1.5
   42 |   0.8820 |     29.544 |   1.1414 |     36.728 |     1.5
   43 |   0.8610 |     28.991 |   1.1410 |     36.116 |     1.5
   44 |   0.8490 |     28.649 |   1.1365 |     35.168 |     1.6
   45 |   0.8434 |     28.328 |   1.1701 |     35.749 |     1.6
   46 |   0.8347 |     27.859 |   1.1330 |     36.024 |     1.6
   47 |   0.8175 |     27.201 |   1.1565 |     35.933 |     1.7
   48 |   0.7977 |     26.693 |   1.1909 |     35.505 |     1.7
   49 |   0.7852 |     26.086 |   1.1374 |     35.015 |     1.7
   50 |   0.7897 |     26.494 |   1.1622 |     35.657 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 894,562

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4878 |     66.357 |   1.9145 |     58.104 |     0.0
    2 |   1.7068 |     48.431 |   1.5219 |     45.963 |     0.1
    3 |   1.4806 |     46.089 |   1.4273 |     45.963 |     0.1
    4 |   1.4282 |     46.089 |   1.3980 |     45.963 |     0.1
    5 |   1.4085 |     46.100 |   1.3853 |     45.963 |     0.2
    6 |   1.4005 |     46.183 |   1.3781 |     45.963 |     0.2
    7 |   1.3914 |     46.100 |   1.3701 |     45.963 |     0.2
    8 |   1.3816 |     46.100 |   1.3680 |     45.963 |     0.3
    9 |   1.3698 |     46.061 |   1.3572 |     45.933 |     0.3
   10 |   1.3637 |     45.724 |   1.3513 |     45.443 |     0.3
   11 |   1.3452 |     45.360 |   1.3456 |     45.535 |     0.4
   12 |   1.3267 |     44.360 |   1.3196 |     44.098 |     0.4
   13 |   1.3090 |     43.387 |   1.3073 |     44.251 |     0.4
   14 |   1.2854 |     42.857 |   1.2863 |     43.150 |     0.5
   15 |   1.2684 |     42.277 |   1.2771 |     43.242 |     0.5
   16 |   1.2457 |     41.708 |   1.2680 |     42.661 |     0.5
   17 |   1.2294 |     41.316 |   1.2409 |     41.560 |     0.5
   18 |   1.2080 |     40.294 |   1.2265 |     41.193 |     0.6
   19 |   1.1926 |     40.040 |   1.2154 |     41.376 |     0.6
   20 |   1.1762 |     39.686 |   1.2052 |     41.284 |     0.6
   21 |   1.1572 |     39.139 |   1.1945 |     40.061 |     0.7
   22 |   1.1426 |     38.532 |   1.1953 |     40.183 |     0.7
   23 |   1.1252 |     38.189 |   1.1844 |     39.541 |     0.7
   24 |   1.1063 |     37.631 |   1.1868 |     39.327 |     0.8
   25 |   1.0934 |     36.963 |   1.1792 |     39.144 |     0.8
   26 |   1.0800 |     36.455 |   1.1527 |     38.318 |     0.8
   27 |   1.0671 |     35.996 |   1.1533 |     38.685 |     0.9
   28 |   1.0531 |     35.532 |   1.1638 |     38.502 |     0.9
   29 |   1.0373 |     34.941 |   1.1498 |     38.073 |     0.9
   30 |   1.0140 |     33.947 |   1.1511 |     36.850 |     1.0
   31 |   0.9954 |     33.195 |   1.1362 |     37.003 |     1.0
   32 |   0.9759 |     32.704 |   1.1390 |     37.584 |     1.0
   33 |   0.9738 |     32.234 |   1.1369 |     36.116 |     1.1
   34 |   0.9544 |     31.908 |   1.1349 |     37.278 |     1.1
   35 |   0.9403 |     31.416 |   1.1357 |     36.086 |     1.1
   36 |   0.9130 |     30.157 |   1.1116 |     35.841 |     1.1
   37 |   0.8919 |     29.312 |   1.1183 |     35.321 |     1.2
   38 |   0.8749 |     28.698 |   1.0953 |     35.107 |     1.2
   39 |   0.8620 |     28.113 |   1.1056 |     35.076 |     1.2
   40 |   0.8531 |     27.953 |   1.1000 |     34.557 |     1.3
   41 |   0.8277 |     26.627 |   1.0791 |     33.823 |     1.3
   42 |   0.8157 |     26.494 |   1.1214 |     34.220 |     1.3
   43 |   0.7981 |     25.975 |   1.0806 |     34.128 |     1.4
   44 |   0.7806 |     25.445 |   1.0835 |     33.670 |     1.4
   45 |   0.7577 |     24.506 |   1.0721 |     33.517 |     1.4
   46 |   0.7529 |     24.511 |   1.0637 |     32.936 |     1.5
   47 |   0.7350 |     23.705 |   1.0582 |     33.425 |     1.5
   48 |   0.7172 |     22.931 |   1.0737 |     32.508 |     1.5
   49 |   0.7090 |     22.881 |   1.0630 |     31.590 |     1.6
   50 |   0.6922 |     22.103 |   1.0722 |     32.232 |     1.6
   51 |   0.6804 |     21.616 |   1.0531 |     32.599 |     1.6
   52 |   0.6624 |     21.186 |   1.0501 |     31.101 |     1.7
   53 |   0.6431 |     20.285 |   1.0481 |     31.468 |     1.7
   54 |   0.6305 |     19.799 |   1.0654 |     31.743 |     1.7
   55 |   0.6147 |     19.263 |   1.0521 |     31.529 |     1.7
   56 |   0.6015 |     19.114 |   1.0410 |     30.245 |     1.8
   57 |   0.5921 |     18.727 |   1.0892 |     30.612 |     1.8
   58 |   0.5808 |     18.341 |   1.0704 |     30.336 |     1.8
   59 |   0.5597 |     17.694 |   1.0620 |     30.581 |     1.9
   60 |   0.5454 |     17.208 |   1.0747 |     30.979 |     1.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 1,207,778

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2539 |     61.595 |   1.6368 |     48.777 |     0.0
    2 |   1.5008 |     46.575 |   1.4065 |     45.963 |     0.1
    3 |   1.4050 |     46.100 |   1.3779 |     45.963 |     0.1
    4 |   1.3649 |     44.757 |   1.3533 |     44.924 |     0.1
    5 |   1.3352 |     44.487 |   1.3314 |     44.587 |     0.2
    6 |   1.3130 |     43.840 |   1.3080 |     44.159 |     0.2
    7 |   1.2990 |     43.608 |   1.3117 |     43.853 |     0.2
    8 |   1.2775 |     42.642 |   1.2855 |     43.578 |     0.3
    9 |   1.2527 |     42.078 |   1.2717 |     42.171 |     0.3
   10 |   1.2335 |     41.559 |   1.2713 |     42.385 |     0.3
   11 |   1.2152 |     40.946 |   1.2567 |     41.529 |     0.4
   12 |   1.1976 |     40.415 |   1.2331 |     41.284 |     0.4
   13 |   1.1777 |     39.449 |   1.2512 |     40.856 |     0.5
   14 |   1.1502 |     38.460 |   1.2312 |     40.581 |     0.5
   15 |   1.1373 |     37.642 |   1.2231 |     38.838 |     0.5
   16 |   1.1223 |     37.664 |   1.2263 |     39.266 |     0.6
   17 |   1.0972 |     36.769 |   1.2002 |     38.349 |     0.6
   18 |   1.0740 |     35.681 |   1.1855 |     38.043 |     0.6
   19 |   1.0523 |     34.670 |   1.1937 |     38.471 |     0.7
   20 |   1.0333 |     33.775 |   1.1726 |     37.309 |     0.7
   21 |   1.0181 |     33.598 |   1.1549 |     36.024 |     0.7
   22 |   0.9805 |     32.206 |   1.1317 |     36.422 |     0.8
   23 |   0.9724 |     31.836 |   1.1376 |     35.933 |     0.8
   24 |   0.9503 |     31.289 |   1.1137 |     34.709 |     0.8
   25 |   0.9306 |     30.494 |   1.1367 |     35.076 |     0.9
   26 |   0.9106 |     29.986 |   1.1119 |     34.801 |     0.9
   27 |   0.8982 |     29.400 |   1.1045 |     34.587 |     0.9
   28 |   0.8751 |     28.759 |   1.0931 |     34.281 |     1.0
   29 |   0.8640 |     28.489 |   1.1062 |     34.128 |     1.0
   30 |   0.8554 |     28.268 |   1.1047 |     33.578 |     1.0
   31 |   0.8265 |     27.489 |   1.0814 |     33.364 |     1.1
   32 |   0.7989 |     26.318 |   1.0763 |     32.813 |     1.1
   33 |   0.7831 |     26.069 |   1.0857 |     34.373 |     1.1
   34 |   0.7813 |     26.041 |   1.0775 |     33.761 |     1.2
   35 |   0.7711 |     25.461 |   1.0565 |     32.263 |     1.2
   36 |   0.7446 |     24.671 |   1.0547 |     32.355 |     1.2
   37 |   0.7289 |     24.047 |   1.0598 |     32.232 |     1.3
   38 |   0.7269 |     24.019 |   1.0916 |     34.006 |     1.3
   39 |   0.7124 |     24.058 |   1.0676 |     32.691 |     1.4
   40 |   0.6881 |     22.666 |   1.0591 |     32.202 |     1.4
   41 |   0.6616 |     21.583 |   1.0408 |     31.682 |     1.4
   42 |   0.6537 |     21.600 |   1.0707 |     32.936 |     1.5
   43 |   0.6444 |     21.252 |   1.0483 |     31.988 |     1.5
   44 |   0.6358 |     21.191 |   1.0641 |     32.080 |     1.5
   45 |   0.6126 |     20.329 |   1.0801 |     32.294 |     1.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,224,994

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5932 |     68.015 |   2.0528 |     58.654 |     0.0
    2 |   1.8205 |     51.497 |   1.5930 |     48.746 |     0.1
    3 |   1.5200 |     46.337 |   1.4459 |     45.963 |     0.1
    4 |   1.4436 |     46.045 |   1.4076 |     45.963 |     0.2
    5 |   1.4162 |     46.116 |   1.3935 |     45.963 |     0.2
    6 |   1.4078 |     46.116 |   1.3845 |     45.963 |     0.2
    7 |   1.4002 |     46.100 |   1.3826 |     45.963 |     0.3
    8 |   1.3945 |     46.078 |   1.3798 |     46.361 |     0.3
    9 |   1.3922 |     46.100 |   1.3757 |     45.963 |     0.4
   10 |   1.3879 |     46.089 |   1.3735 |     45.963 |     0.4
   11 |   1.3863 |     46.067 |   1.3754 |     45.841 |     0.5
   12 |   1.3818 |     46.056 |   1.3683 |     45.933 |     0.5
   13 |   1.3730 |     46.144 |   1.3599 |     46.116 |     0.5
   14 |   1.3650 |     45.835 |   1.3528 |     45.627 |     0.6
   15 |   1.3470 |     44.940 |   1.3320 |     44.862 |     0.6
   16 |   1.3352 |     44.769 |   1.3256 |     44.832 |     0.7
   17 |   1.3240 |     44.697 |   1.3322 |     44.832 |     0.7
   18 |   1.3141 |     44.371 |   1.3195 |     44.832 |     0.8
   19 |   1.3063 |     44.001 |   1.3110 |     44.618 |     0.8
   20 |   1.2984 |     43.929 |   1.3134 |     44.526 |     0.8
   21 |   1.2903 |     43.542 |   1.2999 |     43.517 |     0.9
   22 |   1.2823 |     43.045 |   1.2954 |     43.700 |     0.9
   23 |   1.2722 |     42.680 |   1.2897 |     43.303 |     1.0
   24 |   1.2635 |     42.476 |   1.2813 |     43.333 |     1.0
   25 |   1.2550 |     42.172 |   1.2726 |     42.966 |     1.0
   26 |   1.2430 |     42.040 |   1.2734 |     43.058 |     1.1
   27 |   1.2354 |     41.863 |   1.2719 |     43.119 |     1.1
   28 |   1.2339 |     41.758 |   1.2735 |     42.661 |     1.2
   29 |   1.2278 |     41.802 |   1.2676 |     42.538 |     1.2
   30 |   1.2228 |     41.460 |   1.2655 |     43.211 |     1.3
   31 |   1.2160 |     41.482 |   1.2525 |     42.141 |     1.3
   32 |   1.2120 |     41.233 |   1.2657 |     42.844 |     1.3
   33 |   1.1979 |     41.018 |   1.2412 |     41.835 |     1.4
   34 |   1.1948 |     40.935 |   1.2499 |     42.263 |     1.4
   35 |   1.1938 |     40.681 |   1.2584 |     41.621 |     1.5
   36 |   1.1839 |     40.316 |   1.2492 |     41.865 |     1.5
   37 |   1.1823 |     40.366 |   1.2426 |     41.743 |     1.5
   38 |   1.1748 |     40.117 |   1.2398 |     42.080 |     1.6
   39 |   1.1715 |     39.857 |   1.2509 |     41.651 |     1.6
   40 |   1.1634 |     39.664 |   1.2514 |     41.804 |     1.7
   41 |   1.1569 |     39.681 |   1.2319 |     41.284 |     1.7
   42 |   1.1495 |     39.631 |   1.2425 |     41.346 |     1.7
   43 |   1.1399 |     39.090 |   1.2445 |     41.376 |     1.8
   44 |   1.1470 |     39.134 |   1.2399 |     41.437 |     1.8
   45 |   1.1347 |     38.742 |   1.2466 |     41.621 |     1.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 877,858

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1855 |     59.308 |   1.5659 |     45.963 |     0.0
    2 |   1.4513 |     45.420 |   1.3728 |     44.251 |     0.1
    3 |   1.3421 |     44.122 |   1.3127 |     43.700 |     0.1
    4 |   1.2848 |     42.548 |   1.2634 |     42.661 |     0.1
    5 |   1.2319 |     40.957 |   1.2298 |     40.856 |     0.1
    6 |   1.1745 |     39.023 |   1.2197 |     39.817 |     0.2
    7 |   1.1256 |     36.941 |   1.1628 |     37.431 |     0.2
    8 |   1.0723 |     35.344 |   1.1415 |     35.474 |     0.2
    9 |   1.0196 |     33.411 |   1.1134 |     35.291 |     0.3
   10 |   0.9783 |     32.251 |   1.0974 |     34.220 |     0.3
   11 |   0.9263 |     30.179 |   1.0874 |     34.190 |     0.3
   12 |   0.8885 |     29.350 |   1.0611 |     32.752 |     0.3
   13 |   0.8529 |     27.997 |   1.0626 |     34.037 |     0.4
   14 |   0.8207 |     26.853 |   1.0371 |     32.599 |     0.4
   15 |   0.7711 |     25.224 |   1.0354 |     31.927 |     0.4
   16 |   0.7217 |     23.484 |   1.0099 |     31.621 |     0.5
   17 |   0.6959 |     22.445 |   0.9907 |     30.703 |     0.5
   18 |   0.6583 |     21.268 |   0.9866 |     30.948 |     0.5
   19 |   0.6286 |     20.451 |   0.9773 |     29.969 |     0.6
   20 |   0.6004 |     19.705 |   0.9839 |     30.031 |     0.6
   21 |   0.5731 |     18.727 |   0.9719 |     29.480 |     0.6
   22 |   0.5446 |     17.628 |   0.9785 |     29.174 |     0.6
   23 |   0.5254 |     17.031 |   0.9798 |     29.205 |     0.7
   24 |   0.4873 |     15.871 |   0.9853 |     29.297 |     0.7
   25 |   0.4650 |     14.954 |   0.9713 |     28.960 |     0.7
   26 |   0.4493 |     14.584 |   0.9831 |     28.593 |     0.8
   27 |   0.4325 |     14.037 |   0.9898 |     28.073 |     0.8
   28 |   0.4137 |     13.540 |   0.9848 |     28.287 |     0.8
   29 |   0.3967 |     13.043 |   0.9781 |     28.563 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 302,434

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6350 |     70.832 |   2.0580 |     58.654 |     0.0
    2 |   1.8431 |     52.420 |   1.6225 |     45.994 |     0.0
    3 |   1.5432 |     46.111 |   1.4666 |     45.963 |     0.0
    4 |   1.4542 |     46.094 |   1.4177 |     46.361 |     0.1
    5 |   1.4242 |     46.227 |   1.3967 |     45.963 |     0.1
    6 |   1.4091 |     46.039 |   1.3801 |     45.535 |     0.1
    7 |   1.3824 |     45.415 |   1.3621 |     45.229 |     0.1
    8 |   1.3524 |     45.177 |   1.3271 |     45.107 |     0.1
    9 |   1.3261 |     44.757 |   1.3133 |     45.107 |     0.1
   10 |   1.3039 |     44.260 |   1.3014 |     44.985 |     0.2
   11 |   1.2750 |     43.647 |   1.2623 |     42.477 |     0.2
   12 |   1.2439 |     42.089 |   1.2489 |     42.080 |     0.2
   13 |   1.2140 |     41.156 |   1.2266 |     41.682 |     0.2
   14 |   1.1874 |     40.101 |   1.2079 |     40.612 |     0.2
   15 |   1.1635 |     39.393 |   1.2080 |     40.122 |     0.2
   16 |   1.1477 |     38.731 |   1.1885 |     39.144 |     0.2
   17 |   1.1272 |     38.421 |   1.1936 |     40.336 |     0.3
   18 |   1.1079 |     37.648 |   1.1767 |     38.930 |     0.3
   19 |   1.0883 |     36.963 |   1.1757 |     38.807 |     0.3
   20 |   1.0672 |     36.057 |   1.1739 |     39.786 |     0.3
   21 |   1.0544 |     35.709 |   1.1578 |     38.685 |     0.3
   22 |   1.0298 |     34.897 |   1.1522 |     38.043 |     0.3
   23 |   1.0119 |     34.051 |   1.1303 |     37.187 |     0.3
   24 |   0.9914 |     33.488 |   1.1298 |     36.422 |     0.4
   25 |   0.9739 |     32.720 |   1.1262 |     37.217 |     0.4
   26 |   0.9613 |     32.173 |   1.1194 |     35.841 |     0.4
   27 |   0.9380 |     31.135 |   1.1014 |     34.954 |     0.4
   28 |   0.9264 |     30.947 |   1.0974 |     35.199 |     0.4
   29 |   0.9130 |     30.698 |   1.1066 |     34.495 |     0.4
   30 |   0.8847 |     29.168 |   1.0933 |     34.067 |     0.4
   31 |   0.8800 |     29.096 |   1.0808 |     34.526 |     0.5
   32 |   0.8604 |     28.251 |   1.0622 |     34.343 |     0.5
   33 |   0.8475 |     27.732 |   1.0489 |     33.823 |     0.5
   34 |   0.8357 |     27.456 |   1.0448 |     33.456 |     0.5
   35 |   0.8164 |     26.583 |   1.0682 |     34.587 |     0.5
   36 |   0.7996 |     25.815 |   1.0441 |     32.783 |     0.5
   37 |   0.7959 |     26.047 |   1.0575 |     32.813 |     0.5
   38 |   0.7777 |     25.229 |   1.0236 |     32.355 |     0.6
   39 |   0.7677 |     25.069 |   1.0378 |     33.609 |     0.6
   40 |   0.7614 |     24.594 |   1.0287 |     31.896 |     0.6
   41 |   0.7432 |     24.152 |   1.0461 |     31.988 |     0.6
   42 |   0.7303 |     23.798 |   1.0229 |     31.560 |     0.6
   43 |   0.7201 |     23.229 |   1.0132 |     31.865 |     0.6
   44 |   0.7076 |     22.743 |   1.0221 |     31.284 |     0.7
   45 |   0.6926 |     22.257 |   1.0107 |     30.520 |     0.7
   46 |   0.6848 |     22.080 |   1.0146 |     30.979 |     0.7
   47 |   0.6760 |     21.843 |   1.0500 |     31.131 |     0.7
   48 |   0.6632 |     21.186 |   1.0378 |     31.804 |     0.7
   49 |   0.6560 |     20.887 |   1.0192 |     30.856 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,105,954

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2971 |     63.374 |   1.6701 |     48.746 |     0.0
    2 |   1.5203 |     46.592 |   1.4200 |     45.963 |     0.1
    3 |   1.4163 |     46.094 |   1.3876 |     45.963 |     0.1
    4 |   1.4005 |     46.183 |   1.3794 |     45.902 |     0.1
    5 |   1.3849 |     46.172 |   1.3670 |     45.627 |     0.1
    6 |   1.3656 |     45.884 |   1.3423 |     45.413 |     0.2
    7 |   1.3339 |     44.316 |   1.3116 |     44.465 |     0.2
    8 |   1.2982 |     43.691 |   1.2868 |     44.220 |     0.2
    9 |   1.2628 |     42.885 |   1.2599 |     42.966 |     0.2
   10 |   1.2465 |     42.432 |   1.2377 |     42.966 |     0.3
   11 |   1.2285 |     42.067 |   1.2363 |     42.599 |     0.3
   12 |   1.2126 |     41.653 |   1.2096 |     42.049 |     0.3
   13 |   1.1908 |     41.023 |   1.2006 |     40.612 |     0.3
   14 |   1.1649 |     39.775 |   1.2042 |     41.131 |     0.4
   15 |   1.1605 |     39.736 |   1.1960 |     41.101 |     0.4
   16 |   1.1418 |     39.195 |   1.1784 |     40.122 |     0.4
   17 |   1.1272 |     38.951 |   1.1795 |     39.602 |     0.4
   18 |   1.1121 |     38.394 |   1.1545 |     38.930 |     0.5
   19 |   1.0965 |     37.769 |   1.1534 |     38.930 |     0.5
   20 |   1.0711 |     36.852 |   1.1363 |     38.287 |     0.5
   21 |   1.0594 |     36.703 |   1.1276 |     38.196 |     0.6
   22 |   1.0319 |     35.339 |   1.1201 |     37.064 |     0.6
   23 |   1.0209 |     34.632 |   1.1042 |     36.422 |     0.6
   24 |   1.0022 |     34.311 |   1.1030 |     36.422 |     0.6
   25 |   0.9800 |     33.140 |   1.0826 |     35.719 |     0.7
   26 |   0.9499 |     32.273 |   1.0783 |     36.147 |     0.7
   27 |   0.9407 |     31.880 |   1.0580 |     35.352 |     0.7
   28 |   0.9222 |     31.472 |   1.0743 |     35.168 |     0.7
   29 |   0.9055 |     30.726 |   1.0914 |     34.893 |     0.8
   30 |   0.8903 |     29.792 |   1.0468 |     33.486 |     0.8
   31 |   0.8688 |     29.494 |   1.0352 |     34.067 |     0.8
   32 |   0.8562 |     28.588 |   1.0659 |     34.404 |     0.8
   33 |   0.8333 |     27.969 |   1.0549 |     33.914 |     0.9
   34 |   0.8189 |     27.516 |   1.0537 |     33.731 |     0.9
   35 |   0.8033 |     26.494 |   1.0477 |     33.639 |     0.9
   36 |   0.7848 |     26.196 |   1.0307 |     31.682 |     0.9
   37 |   0.7709 |     25.588 |   1.0261 |     32.049 |     1.0
   38 |   0.7534 |     24.881 |   1.0299 |     32.844 |     1.0
   39 |   0.7535 |     24.820 |   1.0256 |     32.171 |     1.0
   40 |   0.7226 |     24.008 |   1.0232 |     31.651 |     1.1
   41 |   0.7061 |     23.180 |   1.0248 |     31.560 |     1.1
   42 |   0.6838 |     22.417 |   1.0270 |     30.948 |     1.1
   43 |   0.6906 |     22.638 |   1.0165 |     31.774 |     1.1
   44 |   0.6681 |     22.069 |   1.0010 |     30.398 |     1.2
   45 |   0.6399 |     20.970 |   1.0397 |     31.315 |     1.2
   46 |   0.6342 |     20.639 |   1.0513 |     30.887 |     1.2
   47 |   0.6344 |     20.887 |   1.0251 |     30.489 |     1.2
   48 |   0.6207 |     20.075 |   1.0175 |     30.459 |     1.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 474,050

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1337 |     56.911 |   1.4751 |     45.719 |     0.0
    2 |   1.3880 |     44.360 |   1.3230 |     43.609 |     0.0
    3 |   1.2670 |     41.570 |   1.2362 |     40.856 |     0.1
    4 |   1.1940 |     39.504 |   1.1894 |     39.480 |     0.1
    5 |   1.1221 |     37.421 |   1.1374 |     38.440 |     0.1
    6 |   1.0593 |     35.377 |   1.1051 |     35.963 |     0.1
    7 |   0.9927 |     32.339 |   1.0842 |     34.465 |     0.1
    8 |   0.9280 |     30.024 |   1.0315 |     32.294 |     0.1
    9 |   0.8609 |     27.627 |   1.0254 |     31.804 |     0.2
   10 |   0.8048 |     25.412 |   0.9768 |     31.498 |     0.2
   11 |   0.7440 |     23.627 |   0.9775 |     30.306 |     0.2
   12 |   0.6968 |     22.202 |   0.9454 |     28.838 |     0.2
   13 |   0.6404 |     20.158 |   0.9375 |     28.869 |     0.2
   14 |   0.5847 |     18.285 |   0.9316 |     27.982 |     0.2
   15 |   0.5437 |     16.871 |   0.9089 |     28.440 |     0.3
   16 |   0.5041 |     15.700 |   0.9054 |     27.737 |     0.3
   17 |   0.4626 |     14.319 |   0.8974 |     26.667 |     0.3
   18 |   0.4329 |     13.131 |   0.8988 |     27.034 |     0.3
   19 |   0.4019 |     12.325 |   0.8798 |     26.269 |     0.3
   20 |   0.3613 |     11.093 |   0.8990 |     26.239 |     0.3
   21 |   0.3431 |     10.424 |   0.9071 |     26.483 |     0.4
   22 |   0.3168 |      9.651 |   0.9178 |     25.688 |     0.4
   23 |   0.3023 |      8.982 |   0.9099 |     26.422 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 310,658

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4394 |     63.242 |   1.8327 |     49.205 |     0.0
    2 |   1.6429 |     48.685 |   1.4664 |     46.024 |     0.0
    3 |   1.4280 |     45.702 |   1.3642 |     44.985 |     0.1
    4 |   1.3448 |     44.177 |   1.3031 |     43.058 |     0.1
    5 |   1.2846 |     42.476 |   1.2659 |     42.294 |     0.1
    6 |   1.2371 |     40.879 |   1.2228 |     40.245 |     0.1
    7 |   1.1936 |     39.603 |   1.2006 |     39.052 |     0.1
    8 |   1.1536 |     38.106 |   1.1697 |     39.419 |     0.1
    9 |   1.1179 |     36.836 |   1.1415 |     37.554 |     0.2
   10 |   1.0771 |     35.598 |   1.1054 |     35.994 |     0.2
   11 |   1.0410 |     34.449 |   1.0966 |     35.413 |     0.2
   12 |   1.0063 |     33.284 |   1.0789 |     34.037 |     0.2
   13 |   0.9704 |     32.052 |   1.0529 |     33.853 |     0.2
   14 |   0.9401 |     30.422 |   1.0379 |     33.089 |     0.3
   15 |   0.9097 |     29.091 |   1.0287 |     32.569 |     0.3
   16 |   0.8834 |     28.185 |   1.0176 |     31.560 |     0.3
   17 |   0.8501 |     27.135 |   1.0120 |     30.581 |     0.3
   18 |   0.8243 |     26.058 |   1.0108 |     30.183 |     0.3
   19 |   0.7991 |     25.340 |   1.0055 |     30.581 |     0.3
   20 |   0.7776 |     24.671 |   0.9914 |     30.092 |     0.4
   21 |   0.7529 |     24.119 |   0.9714 |     29.511 |     0.4
   22 |   0.7249 |     22.793 |   0.9868 |     29.388 |     0.4
   23 |   0.7091 |     22.368 |   0.9470 |     28.379 |     0.4
   24 |   0.6828 |     21.478 |   0.9622 |     29.113 |     0.4
   25 |   0.6670 |     21.197 |   0.9656 |     28.838 |     0.4
   26 |   0.6389 |     20.081 |   0.9518 |     28.960 |     0.5
   27 |   0.6245 |     19.705 |   0.9371 |     28.440 |     0.5
   28 |   0.6056 |     18.860 |   0.9349 |     28.287 |     0.5
   29 |   0.5879 |     18.639 |   0.9492 |     27.339 |     0.5
   30 |   0.5799 |     18.213 |   0.9531 |     27.492 |     0.5
   31 |   0.5626 |     17.865 |   0.9314 |     27.768 |     0.6
   32 |   0.5474 |     17.247 |   0.9386 |     27.615 |     0.6
   33 |   0.5265 |     16.611 |   0.9299 |     27.554 |     0.6
   34 |   0.5240 |     16.291 |   0.9401 |     27.523 |     0.6
   35 |   0.5220 |     16.413 |   0.9238 |     27.462 |     0.6
   36 |   0.4928 |     15.484 |   0.9335 |     26.514 |     0.6
   37 |   0.4922 |     15.529 |   0.9315 |     26.177 |     0.7
   38 |   0.4723 |     14.899 |   0.9287 |     27.003 |     0.7
   39 |   0.4671 |     14.938 |   0.9237 |     25.933 |     0.7
   40 |   0.4626 |     14.573 |   0.9217 |     27.462 |     0.7
   41 |   0.4454 |     13.927 |   0.9376 |     26.850 |     0.7
   42 |   0.4424 |     13.954 |   0.9078 |     26.361 |     0.7
   43 |   0.4370 |     13.733 |   0.9333 |     26.147 |     0.8
   44 |   0.4155 |     12.921 |   0.9209 |     26.330 |     0.8
   45 |   0.4134 |     13.369 |   0.9554 |     26.239 |     0.8
   46 |   0.4067 |     12.601 |   0.9536 |     26.391 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 2,418,018

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4976 |     66.871 |   1.9833 |     54.495 |     0.1
    2 |   1.7852 |     50.823 |   1.5758 |     46.024 |     0.2
    3 |   1.5140 |     46.078 |   1.4383 |     45.963 |     0.2
    4 |   1.4335 |     46.111 |   1.4022 |     45.963 |     0.3
    5 |   1.4019 |     45.995 |   1.3710 |     45.994 |     0.4
    6 |   1.3719 |     45.161 |   1.3524 |     44.862 |     0.5
    7 |   1.3420 |     44.332 |   1.3359 |     44.434 |     0.6
    8 |   1.3149 |     43.631 |   1.3147 |     44.128 |     0.6
    9 |   1.2988 |     43.194 |   1.3047 |     43.578 |     0.7
   10 |   1.2722 |     42.150 |   1.2854 |     42.385 |     0.8
   11 |   1.2554 |     41.819 |   1.2783 |     42.813 |     0.9
   12 |   1.2406 |     41.178 |   1.2550 |     42.018 |     1.0
   13 |   1.2271 |     41.139 |   1.2527 |     42.080 |     1.1
   14 |   1.2041 |     40.404 |   1.2391 |     41.070 |     1.1
   15 |   1.1799 |     39.637 |   1.2350 |     40.459 |     1.2
   16 |   1.1614 |     39.145 |   1.2116 |     39.786 |     1.3
   17 |   1.1445 |     38.344 |   1.1995 |     39.480 |     1.4
   18 |   1.1218 |     37.543 |   1.1854 |     38.502 |     1.5
   19 |   1.0969 |     36.515 |   1.1933 |     39.419 |     1.5
   20 |   1.0899 |     36.195 |   1.1792 |     39.817 |     1.6
   21 |   1.0766 |     35.968 |   1.1655 |     38.624 |     1.7
   22 |   1.0570 |     35.366 |   1.1609 |     38.196 |     1.8
   23 |   1.0456 |     34.825 |   1.1603 |     37.554 |     1.9
   24 |   1.0409 |     34.637 |   1.1531 |     37.859 |     1.9
   25 |   1.0200 |     33.709 |   1.1441 |     37.309 |     2.0
   26 |   1.0048 |     33.234 |   1.1549 |     37.554 |     2.1
   27 |   0.9926 |     33.201 |   1.1121 |     36.330 |     2.2
   28 |   0.9801 |     32.693 |   1.1181 |     36.300 |     2.3
   29 |   0.9705 |     32.173 |   1.1264 |     36.544 |     2.3
   30 |   0.9540 |     31.892 |   1.1390 |     37.248 |     2.4
   31 |   0.9494 |     31.577 |   1.0935 |     35.474 |     2.5
   32 |   0.9291 |     31.096 |   1.1033 |     35.627 |     2.6
   33 |   0.9194 |     31.107 |   1.0823 |     35.229 |     2.7
   34 |   0.9246 |     31.024 |   1.1006 |     35.260 |     2.8
   35 |   0.9117 |     30.555 |   1.1053 |     35.168 |     2.8
   36 |   0.8897 |     29.395 |   1.0770 |     34.924 |     2.9
   37 |   0.8705 |     29.107 |   1.0946 |     35.260 |     3.0
   38 |   0.8698 |     29.190 |   1.0918 |     34.740 |     3.1
   39 |   0.8572 |     28.848 |   1.0916 |     35.015 |     3.2
   40 |   0.8393 |     27.826 |   1.0880 |     35.321 |     3.2
   41 |   0.8393 |     28.113 |   1.0657 |     34.281 |     3.3
   42 |   0.8247 |     27.870 |   1.0882 |     34.373 |     3.4
   43 |   0.8136 |     27.511 |   1.0749 |     34.037 |     3.5
   44 |   0.8069 |     26.726 |   1.0883 |     34.618 |     3.6
   45 |   0.8113 |     27.163 |   1.0872 |     34.832 |     3.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 467,746

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5611 |     68.241 |   1.9813 |     56.758 |     0.0
    2 |   1.7765 |     51.127 |   1.5577 |     45.963 |     0.0
    3 |   1.4985 |     46.133 |   1.4365 |     45.963 |     0.1
    4 |   1.4323 |     46.094 |   1.4000 |     45.963 |     0.1
    5 |   1.4023 |     46.100 |   1.3790 |     45.963 |     0.1
    6 |   1.3800 |     46.023 |   1.3500 |     45.657 |     0.1
    7 |   1.3558 |     45.376 |   1.3359 |     45.749 |     0.1
    8 |   1.3353 |     45.409 |   1.3065 |     45.199 |     0.1
    9 |   1.3026 |     44.846 |   1.2853 |     44.434 |     0.2
   10 |   1.2716 |     43.266 |   1.2595 |     43.242 |     0.2
   11 |   1.2495 |     42.702 |   1.2410 |     42.508 |     0.2
   12 |   1.2288 |     42.095 |   1.2258 |     41.896 |     0.2
   13 |   1.2062 |     41.200 |   1.2070 |     41.376 |     0.2
   14 |   1.1870 |     40.587 |   1.1891 |     40.336 |     0.2
   15 |   1.1644 |     39.885 |   1.1845 |     39.358 |     0.3
   16 |   1.1396 |     38.896 |   1.1722 |     39.266 |     0.3
   17 |   1.1224 |     37.941 |   1.1481 |     38.196 |     0.3
   18 |   1.1017 |     37.316 |   1.1416 |     38.012 |     0.3
   19 |   1.0728 |     36.084 |   1.1284 |     36.972 |     0.3
   20 |   1.0562 |     35.223 |   1.1215 |     36.453 |     0.4
   21 |   1.0360 |     34.753 |   1.1109 |     36.911 |     0.4
   22 |   1.0172 |     33.748 |   1.1040 |     36.116 |     0.4
   23 |   0.9969 |     33.068 |   1.1043 |     35.780 |     0.4
   24 |   0.9788 |     32.411 |   1.0930 |     35.474 |     0.4
   25 |   0.9572 |     31.643 |   1.0902 |     34.954 |     0.4
   26 |   0.9373 |     31.240 |   1.0661 |     34.648 |     0.5
   27 |   0.9248 |     30.461 |   1.0714 |     34.281 |     0.5
   28 |   0.8940 |     29.356 |   1.0515 |     33.823 |     0.5
   29 |   0.8829 |     29.146 |   1.0568 |     34.281 |     0.5
   30 |   0.8619 |     28.301 |   1.0583 |     32.783 |     0.5
   31 |   0.8488 |     28.074 |   1.0419 |     32.997 |     0.6
   32 |   0.8254 |     26.842 |   1.0605 |     32.783 |     0.6
   33 |   0.8147 |     26.544 |   1.0462 |     32.813 |     0.6
   34 |   0.7900 |     25.749 |   1.0381 |     32.538 |     0.6
   35 |   0.7810 |     25.671 |   1.0500 |     33.119 |     0.6
   36 |   0.7703 |     25.025 |   1.0505 |     32.324 |     0.6
   37 |   0.7522 |     24.522 |   1.0369 |     32.722 |     0.7
   38 |   0.7366 |     23.743 |   1.0246 |     31.835 |     0.7
   39 |   0.7186 |     23.368 |   1.0339 |     31.713 |     0.7
   40 |   0.7068 |     23.047 |   1.0209 |     31.254 |     0.7
   41 |   0.6891 |     22.036 |   1.0273 |     30.826 |     0.7
   42 |   0.6814 |     21.937 |   1.0201 |     31.162 |     0.8
   43 |   0.6581 |     21.290 |   1.0179 |     30.887 |     0.8
   44 |   0.6456 |     20.937 |   1.0154 |     29.939 |     0.8
   45 |   0.6353 |     20.628 |   1.0190 |     29.939 |     0.8
   46 |   0.6250 |     20.031 |   1.0001 |     30.306 |     0.8
   47 |   0.6137 |     19.749 |   1.0020 |     30.214 |     0.8
   48 |   0.6069 |     19.672 |   1.0044 |     31.040 |     0.9
   49 |   0.6041 |     19.699 |   1.0139 |     29.755 |     0.9
   50 |   0.5819 |     18.672 |   1.0044 |     29.144 |     0.9
   51 |   0.5717 |     18.462 |   0.9964 |     29.266 |     0.9
   52 |   0.5601 |     17.921 |   0.9988 |     29.388 |     0.9
   53 |   0.5523 |     17.772 |   1.0270 |     29.602 |     1.0
   54 |   0.5391 |     17.203 |   1.0181 |     29.786 |     1.0
   55 |   0.5346 |     17.103 |   1.0252 |     29.908 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 567,778

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2371 |     60.452 |   1.5725 |     45.963 |     0.0
    2 |   1.4653 |     46.210 |   1.3847 |     45.902 |     0.0
    3 |   1.3800 |     46.039 |   1.3333 |     44.801 |     0.0
    4 |   1.3227 |     44.912 |   1.2969 |     44.006 |     0.1
    5 |   1.2839 |     43.984 |   1.2607 |     43.731 |     0.1
    6 |   1.2516 |     42.559 |   1.2446 |     42.691 |     0.1
    7 |   1.2067 |     40.498 |   1.2008 |     40.459 |     0.1
    8 |   1.1612 |     39.233 |   1.1665 |     39.541 |     0.1
    9 |   1.1119 |     37.753 |   1.1423 |     38.318 |     0.1
   10 |   1.0717 |     36.377 |   1.1329 |     37.676 |     0.2
   11 |   1.0225 |     34.245 |   1.0889 |     35.596 |     0.2
   12 |   0.9763 |     32.842 |   1.0711 |     34.343 |     0.2
   13 |   0.9345 |     31.295 |   1.0471 |     33.547 |     0.2
   14 |   0.8938 |     29.726 |   1.0157 |     32.905 |     0.2
   15 |   0.8461 |     27.848 |   1.0080 |     32.080 |     0.2
   16 |   0.8090 |     26.467 |   1.0079 |     31.407 |     0.2
   17 |   0.7802 |     25.588 |   0.9794 |     31.254 |     0.3
   18 |   0.7453 |     24.251 |   0.9542 |     30.673 |     0.3
   19 |   0.7101 |     23.141 |   0.9342 |     30.459 |     0.3
   20 |   0.6840 |     22.108 |   0.9407 |     29.694 |     0.3
   21 |   0.6526 |     21.097 |   0.9274 |     29.205 |     0.3
   22 |   0.6270 |     20.390 |   0.9136 |     28.043 |     0.3
   23 |   0.5964 |     19.385 |   0.9285 |     28.563 |     0.3
   24 |   0.5721 |     18.241 |   0.9184 |     27.829 |     0.4
   25 |   0.5504 |     17.888 |   0.9010 |     28.104 |     0.4
   26 |   0.5299 |     16.965 |   0.9206 |     27.920 |     0.4
   27 |   0.5082 |     16.219 |   0.9089 |     26.728 |     0.4
   28 |   0.4911 |     15.468 |   0.9071 |     26.972 |     0.4
   29 |   0.4736 |     15.065 |   0.9415 |     26.850 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 207,650

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.4862 |     66.313 |   1.8967 |     50.612 |     0.0
    2 |   1.6651 |     47.967 |   1.4834 |     45.688 |     0.0
    3 |   1.4338 |     45.564 |   1.3701 |     44.924 |     0.0
    4 |   1.3433 |     43.603 |   1.3147 |     42.599 |     0.1
    5 |   1.2771 |     41.045 |   1.2634 |     40.520 |     0.1
    6 |   1.2126 |     39.233 |   1.2190 |     39.817 |     0.1
    7 |   1.1621 |     38.139 |   1.1974 |     38.838 |     0.1
    8 |   1.1152 |     36.736 |   1.1538 |     37.431 |     0.1
    9 |   1.0655 |     35.151 |   1.1222 |     36.208 |     0.1
   10 |   1.0251 |     33.836 |   1.1088 |     35.076 |     0.1
   11 |   0.9796 |     32.129 |   1.0854 |     34.404 |     0.1
   12 |   0.9394 |     30.654 |   1.0721 |     34.587 |     0.2
   13 |   0.9017 |     29.129 |   1.0646 |     33.670 |     0.2
   14 |   0.8572 |     27.560 |   1.0392 |     32.355 |     0.2
   15 |   0.8181 |     26.030 |   1.0347 |     32.018 |     0.2
   16 |   0.7852 |     25.135 |   1.0231 |     31.315 |     0.2
   17 |   0.7526 |     24.158 |   1.0154 |     30.489 |     0.2
   18 |   0.7184 |     22.556 |   1.0121 |     30.703 |     0.2
   19 |   0.6872 |     21.456 |   1.0015 |     29.511 |     0.2
   20 |   0.6580 |     20.639 |   1.0081 |     30.550 |     0.3
   21 |   0.6299 |     19.760 |   0.9854 |     29.266 |     0.3
   22 |   0.6005 |     18.666 |   0.9764 |     29.266 |     0.3
   23 |   0.5791 |     18.053 |   0.9730 |     28.624 |     0.3
   24 |   0.5504 |     16.854 |   0.9700 |     29.144 |     0.3
   25 |   0.5296 |     16.390 |   0.9513 |     28.349 |     0.3
   26 |   0.5085 |     15.971 |   0.9709 |     28.135 |     0.3
   27 |   0.4792 |     14.341 |   0.9522 |     28.165 |     0.4
   28 |   0.4615 |     14.142 |   0.9812 |     28.257 |     0.4
   29 |   0.4461 |     13.446 |   0.9786 |     28.593 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,091,170

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2340 |     61.540 |   1.6437 |     48.746 |     0.1
    2 |   1.5037 |     46.210 |   1.4154 |     45.963 |     0.1
    3 |   1.4180 |     46.172 |   1.3887 |     45.963 |     0.2
    4 |   1.3999 |     46.127 |   1.3830 |     45.810 |     0.2
    5 |   1.3937 |     46.017 |   1.3665 |     45.596 |     0.3
    6 |   1.3700 |     45.050 |   1.3513 |     44.954 |     0.3
    7 |   1.3441 |     44.531 |   1.3389 |     45.291 |     0.4
    8 |   1.3261 |     43.874 |   1.3217 |     44.190 |     0.5
    9 |   1.3120 |     43.669 |   1.3097 |     43.945 |     0.5
   10 |   1.2959 |     43.039 |   1.3021 |     43.425 |     0.6
   11 |   1.2796 |     42.609 |   1.2846 |     43.486 |     0.6
   12 |   1.2609 |     42.283 |   1.2783 |     42.202 |     0.7
   13 |   1.2473 |     41.962 |   1.2744 |     42.385 |     0.8
   14 |   1.2308 |     41.426 |   1.2594 |     41.988 |     0.8
   15 |   1.2169 |     40.752 |   1.2643 |     41.743 |     0.9
   16 |   1.2041 |     40.344 |   1.2511 |     40.979 |     0.9
   17 |   1.1798 |     39.692 |   1.2362 |     40.612 |     1.0
   18 |   1.1671 |     39.095 |   1.2292 |     40.398 |     1.1
   19 |   1.1534 |     38.913 |   1.2141 |     40.459 |     1.1
   20 |   1.1362 |     38.399 |   1.2071 |     39.144 |     1.2
   21 |   1.1158 |     37.907 |   1.2126 |     39.511 |     1.2
   22 |   1.1126 |     37.736 |   1.2029 |     39.725 |     1.3
   23 |   1.0933 |     37.305 |   1.1883 |     38.532 |     1.3
   24 |   1.0869 |     36.968 |   1.1983 |     38.991 |     1.4
   25 |   1.0687 |     36.051 |   1.2079 |     38.716 |     1.5
   26 |   1.0567 |     36.123 |   1.1903 |     38.807 |     1.5
   27 |   1.0479 |     35.526 |   1.1834 |     38.624 |     1.6
   28 |   1.0285 |     34.582 |   1.1700 |     38.716 |     1.6
   29 |   1.0088 |     34.156 |   1.1722 |     38.379 |     1.7
   30 |   1.0441 |     35.549 |   1.1921 |     37.523 |     1.8
   31 |   0.9905 |     33.411 |   1.1639 |     36.728 |     1.8
   32 |   0.9816 |     32.980 |   1.1918 |     37.706 |     1.9
   33 |   0.9653 |     32.505 |   1.1739 |     37.859 |     1.9
   34 |   0.9530 |     32.256 |   1.1832 |     37.615 |     2.0
   35 |   0.9364 |     31.715 |   1.1518 |     36.820 |     2.1
   36 |   0.9194 |     31.151 |   1.1712 |     35.963 |     2.1
   37 |   0.9036 |     30.660 |   1.1571 |     36.177 |     2.2
   38 |   0.8828 |     29.787 |   1.1583 |     36.239 |     2.2
   39 |   0.8734 |     29.317 |   1.1692 |     36.911 |     2.3
   40 |   0.8748 |     29.759 |   1.1422 |     36.391 |     2.4
   41 |   0.8553 |     28.925 |   1.1475 |     35.382 |     2.4
   42 |   0.8268 |     27.804 |   1.1451 |     35.229 |     2.5
   43 |   0.8077 |     26.936 |   1.1570 |     36.300 |     2.5
   44 |   0.7987 |     26.881 |   1.1565 |     36.697 |     2.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 1,374,434

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2355 |     61.419 |   1.6199 |     48.746 |     0.0
    2 |   1.4829 |     46.293 |   1.4096 |     45.963 |     0.1
    3 |   1.4101 |     46.089 |   1.3893 |     45.963 |     0.1
    4 |   1.3954 |     46.155 |   1.4089 |     45.994 |     0.1
    5 |   1.3775 |     45.603 |   1.3452 |     44.832 |     0.2
    6 |   1.3467 |     44.481 |   1.3245 |     44.465 |     0.2
    7 |   1.3242 |     44.056 |   1.3231 |     44.067 |     0.2
    8 |   1.2980 |     43.189 |   1.3010 |     43.884 |     0.3
    9 |   1.2830 |     42.719 |   1.2934 |     43.578 |     0.3
   10 |   1.2773 |     42.780 |   1.2872 |     42.691 |     0.3
   11 |   1.2571 |     41.780 |   1.2964 |     42.813 |     0.4
   12 |   1.2477 |     41.609 |   1.2743 |     43.089 |     0.4
   13 |   1.2338 |     40.951 |   1.2716 |     42.355 |     0.4
   14 |   1.2162 |     40.835 |   1.2612 |     42.385 |     0.5
   15 |   1.2081 |     40.592 |   1.2541 |     41.988 |     0.5
   16 |   1.1793 |     39.730 |   1.2533 |     41.376 |     0.5
   17 |   1.1704 |     39.200 |   1.2512 |     41.651 |     0.6
   18 |   1.1565 |     38.499 |   1.2425 |     41.162 |     0.6
   19 |   1.1288 |     37.863 |   1.2135 |     39.939 |     0.6
   20 |   1.1180 |     37.548 |   1.2007 |     39.664 |     0.7
   21 |   1.0988 |     36.830 |   1.2106 |     39.450 |     0.7
   22 |   1.0799 |     36.350 |   1.2030 |     39.694 |     0.7
   23 |   1.0552 |     35.250 |   1.1994 |     38.287 |     0.7
   24 |   1.0332 |     34.433 |   1.1937 |     37.829 |     0.8
   25 |   1.0175 |     33.615 |   1.1931 |     37.676 |     0.8
   26 |   0.9963 |     32.913 |   1.1616 |     37.309 |     0.8
   27 |   0.9679 |     32.129 |   1.1671 |     36.422 |     0.9
   28 |   0.9425 |     31.240 |   1.1444 |     36.239 |     0.9
   29 |   0.9277 |     30.372 |   1.1137 |     35.413 |     0.9
   30 |   0.9085 |     30.317 |   1.1358 |     35.841 |     1.0
   31 |   0.8798 |     29.229 |   1.1233 |     36.269 |     1.0
   32 |   0.8569 |     28.527 |   1.0842 |     34.954 |     1.0
   33 |   0.8189 |     26.975 |   1.0751 |     34.312 |     1.1
   34 |   0.7908 |     26.207 |   1.0912 |     33.700 |     1.1
   35 |   0.7645 |     25.058 |   1.0811 |     33.456 |     1.1
   36 |   0.7573 |     24.948 |   1.0714 |     33.119 |     1.2
   37 |   0.7315 |     24.290 |   1.0529 |     32.691 |     1.2
   38 |   0.7075 |     23.461 |   1.0961 |     33.670 |     1.2
   39 |   0.6903 |     22.705 |   1.0657 |     32.508 |     1.3
   40 |   0.6639 |     21.859 |   1.0719 |     33.761 |     1.3
   41 |   0.6438 |     21.014 |   1.0795 |     32.630 |     1.3
   42 |   0.6234 |     20.186 |   1.0403 |     31.560 |     1.4
   43 |   0.6011 |     19.760 |   1.0979 |     32.385 |     1.4
   44 |   0.5921 |     19.534 |   1.0811 |     32.294 |     1.4
   45 |   0.5718 |     18.722 |   1.0969 |     31.346 |     1.5
   46 |   0.5441 |     17.738 |   1.0635 |     31.162 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 34 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 700,706

Training started
X_train.shape: torch.Size([3017, 702])
Y_train.shape: torch.Size([3017, 7])
X_dev.shape: torch.Size([545, 323])
Y_dev.shape: torch.Size([545, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5942 |     67.970 |   1.9807 |     58.257 |     0.0
    2 |   1.7781 |     50.276 |   1.5691 |     45.963 |     0.1
    3 |   1.5097 |     46.105 |   1.4390 |     45.963 |     0.1
    4 |   1.4379 |     46.127 |   1.4051 |     45.963 |     0.1
    5 |   1.4147 |     46.161 |   1.3906 |     45.963 |     0.1
    6 |   1.4039 |     46.139 |   1.3833 |     45.963 |     0.2
    7 |   1.3999 |     46.089 |   1.3796 |     46.544 |     0.2
    8 |   1.3963 |     46.221 |   1.3783 |     45.963 |     0.2
    9 |   1.3927 |     46.177 |   1.3752 |     45.963 |     0.2
   10 |   1.3882 |     46.205 |   1.3726 |     45.963 |     0.3
   11 |   1.3878 |     46.078 |   1.3707 |     45.780 |     0.3
   12 |   1.3828 |     46.000 |   1.3817 |     46.116 |     0.3
   13 |   1.3785 |     46.155 |   1.3657 |     45.933 |     0.3
   14 |   1.3703 |     46.139 |   1.3574 |     45.963 |     0.4
   15 |   1.3606 |     45.746 |   1.3560 |     45.168 |     0.4
   16 |   1.3457 |     44.934 |   1.3377 |     45.229 |     0.4
   17 |   1.3315 |     44.608 |   1.3336 |     44.557 |     0.4
   18 |   1.3209 |     44.360 |   1.3218 |     44.618 |     0.5
   19 |   1.3099 |     44.360 |   1.3185 |     44.404 |     0.5
   20 |   1.3041 |     44.509 |   1.3129 |     44.281 |     0.5
   21 |   1.2932 |     43.929 |   1.3052 |     43.792 |     0.6
   22 |   1.2822 |     43.625 |   1.2944 |     43.761 |     0.6
   23 |   1.2739 |     43.404 |   1.3053 |     43.731 |     0.6
   24 |   1.2696 |     42.774 |   1.3099 |     44.037 |     0.6
   25 |   1.2623 |     42.730 |   1.2951 |     43.394 |     0.7
   26 |   1.2502 |     42.542 |   1.2842 |     42.722 |     0.7
   27 |   1.2415 |     41.979 |   1.2829 |     42.997 |     0.7
   28 |   1.2331 |     41.852 |   1.2791 |     42.508 |     0.7
   29 |   1.2222 |     41.266 |   1.2726 |     42.538 |     0.8
   30 |   1.2185 |     41.321 |   1.2691 |     42.599 |     0.8
   31 |   1.2084 |     41.001 |   1.2659 |     42.018 |     0.8
   32 |   1.2036 |     40.741 |   1.2516 |     41.896 |     0.8
   33 |   1.1927 |     40.388 |   1.2530 |     41.498 |     0.9
   34 |   1.1827 |     40.078 |   1.2500 |     41.774 |     0.9
   35 |   1.1807 |     39.835 |   1.2339 |     40.948 |     0.9
   36 |   1.1741 |     39.548 |   1.2329 |     41.009 |     0.9
   37 |   1.1594 |     39.206 |   1.2290 |     40.612 |     1.0
   38 |   1.1567 |     39.062 |   1.2413 |     40.917 |     1.0
   39 |   1.1524 |     39.244 |   1.2293 |     40.214 |     1.0
   40 |   1.1464 |     38.471 |   1.2492 |     40.642 |     1.0
   41 |   1.1406 |     38.543 |   1.2268 |     40.581 |     1.1
   42 |   1.1296 |     37.985 |   1.2373 |     40.183 |     1.1
   43 |   1.1317 |     37.935 |   1.2270 |     39.694 |     1.1
   44 |   1.1169 |     37.620 |   1.2247 |     40.336 |     1.1
   45 |   1.1065 |     37.245 |   1.2194 |     40.183 |     1.2
   46 |   1.0956 |     37.057 |   1.2340 |     39.878 |     1.2
   47 |   1.0864 |     36.642 |   1.2178 |     39.602 |     1.2
   48 |   1.0908 |     36.687 |   1.2201 |     39.113 |     1.3
   49 |   1.0902 |     36.670 |   1.2101 |     39.602 |     1.3
   50 |   1.0752 |     36.068 |   1.2247 |     39.358 |     1.3
   51 |   1.0718 |     36.189 |   1.2322 |     38.899 |     1.3
   52 |   1.0682 |     35.919 |   1.2152 |     38.440 |     1.4
   53 |   1.0601 |     35.654 |   1.2218 |     38.869 |     1.4
Early stopping

