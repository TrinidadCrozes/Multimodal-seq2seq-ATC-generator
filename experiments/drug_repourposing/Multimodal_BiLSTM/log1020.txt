Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,322,337

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1827 |     59.967 |   1.6241 |     47.300 |     0.0
    2 |   1.4662 |     45.124 |   1.3876 |     45.872 |     0.1
    3 |   1.3342 |     42.904 |   1.2999 |     43.886 |     0.1
    4 |   1.2634 |     41.339 |   1.2325 |     41.092 |     0.2
    5 |   1.2121 |     40.099 |   1.1878 |     40.192 |     0.2
    6 |   1.1613 |     38.336 |   1.1550 |     39.044 |     0.2
    7 |   1.1164 |     36.733 |   1.1261 |     37.337 |     0.3
    8 |   1.0656 |     34.683 |   1.0899 |     35.009 |     0.3
    9 |   1.0165 |     33.361 |   1.0658 |     35.071 |     0.4
   10 |   0.9825 |     32.231 |   1.0236 |     33.985 |     0.4
   11 |   0.9336 |     30.391 |   1.0235 |     33.613 |     0.4
   12 |   0.8962 |     29.229 |   0.9942 |     32.464 |     0.5
   13 |   0.8541 |     27.791 |   0.9736 |     31.502 |     0.5
   14 |   0.8163 |     26.771 |   0.9544 |     30.881 |     0.6
   15 |   0.7769 |     25.306 |   0.9468 |     30.354 |     0.6
   16 |   0.7445 |     24.204 |   0.9352 |     30.012 |     0.6
   17 |   0.7171 |     23.300 |   0.9331 |     29.423 |     0.7
   18 |   0.6760 |     21.774 |   0.9472 |     30.695 |     0.7
   19 |   0.6433 |     20.854 |   0.9160 |     29.236 |     0.8
   20 |   0.6235 |     20.149 |   0.9298 |     29.578 |     0.8
   21 |   0.5841 |     18.826 |   0.9293 |     29.112 |     0.8
   22 |   0.5616 |     18.226 |   0.9350 |     28.430 |     0.9
   23 |   0.5427 |     17.642 |   0.9316 |     27.995 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 2,246,049

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1983 |     60.132 |   1.5919 |     47.083 |     0.1
    2 |   1.4703 |     45.945 |   1.4276 |     47.083 |     0.1
    3 |   1.4078 |     45.923 |   1.4017 |     47.052 |     0.2
    4 |   1.3925 |     45.972 |   1.4042 |     47.083 |     0.3
    5 |   1.3835 |     45.554 |   1.3794 |     45.748 |     0.3
    6 |   1.3592 |     44.534 |   1.3621 |     45.407 |     0.4
    7 |   1.3382 |     44.331 |   1.3426 |     46.089 |     0.4
    8 |   1.3212 |     44.298 |   1.3256 |     45.065 |     0.5
    9 |   1.3071 |     43.598 |   1.3109 |     44.072 |     0.6
   10 |   1.2928 |     43.129 |   1.2989 |     44.103 |     0.6
   11 |   1.2804 |     42.634 |   1.2963 |     44.444 |     0.7
   12 |   1.2659 |     42.287 |   1.2881 |     44.165 |     0.8
   13 |   1.2493 |     41.879 |   1.2736 |     43.513 |     0.8
   14 |   1.2370 |     41.537 |   1.2666 |     43.079 |     0.9
   15 |   1.2244 |     41.047 |   1.2585 |     42.644 |     0.9
   16 |   1.2061 |     40.612 |   1.2451 |     42.303 |     1.0
   17 |   1.1903 |     40.083 |   1.2359 |     41.589 |     1.1
   18 |   1.1783 |     39.807 |   1.2167 |     40.999 |     1.1
   19 |   1.1658 |     39.185 |   1.2191 |     41.651 |     1.2
   20 |   1.1478 |     38.656 |   1.2046 |     40.813 |     1.3
   21 |   1.1334 |     38.397 |   1.2043 |     40.937 |     1.3
   22 |   1.1181 |     37.736 |   1.2039 |     40.720 |     1.4
   23 |   1.1061 |     37.399 |   1.1886 |     39.727 |     1.5
   24 |   1.0930 |     36.799 |   1.1785 |     39.230 |     1.5
   25 |   1.0881 |     36.634 |   1.1589 |     38.796 |     1.6
   26 |   1.0635 |     36.099 |   1.1476 |     37.865 |     1.6
   27 |   1.0492 |     35.207 |   1.1429 |     38.206 |     1.7
   28 |   1.0230 |     34.650 |   1.1294 |     37.554 |     1.8
   29 |   1.0063 |     34.110 |   1.1095 |     37.492 |     1.8
   30 |   0.9883 |     33.609 |   1.1133 |     37.306 |     1.9
   31 |   0.9677 |     32.821 |   1.1135 |     36.747 |     2.0
   32 |   0.9618 |     32.474 |   1.0977 |     35.909 |     2.0
   33 |   0.9360 |     31.471 |   1.1002 |     36.220 |     2.1
   34 |   0.9104 |     30.650 |   1.0684 |     35.289 |     2.2
   35 |   0.8932 |     30.182 |   1.0670 |     34.637 |     2.2
   36 |   0.8752 |     29.747 |   1.0675 |     35.413 |     2.3
   37 |   0.8549 |     28.821 |   1.0519 |     34.699 |     2.3
   38 |   0.8433 |     28.336 |   1.0664 |     34.575 |     2.4
   39 |   0.8397 |     28.160 |   1.0635 |     34.358 |     2.5
   40 |   0.8183 |     27.824 |   1.0630 |     34.140 |     2.5
   41 |   0.7957 |     26.821 |   1.0575 |     33.768 |     2.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 916,545

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2912 |     62.579 |   1.6831 |     49.565 |     0.0
    2 |   1.5074 |     46.154 |   1.4369 |     47.083 |     0.0
    3 |   1.4106 |     45.873 |   1.4137 |     47.083 |     0.1
    4 |   1.3886 |     45.928 |   1.3949 |     47.020 |     0.1
    5 |   1.3633 |     44.793 |   1.3585 |     45.376 |     0.1
    6 |   1.3371 |     44.298 |   1.3526 |     45.376 |     0.1
    7 |   1.3216 |     43.669 |   1.3273 |     44.569 |     0.2
    8 |   1.3033 |     43.333 |   1.3040 |     44.103 |     0.2
    9 |   1.2871 |     42.705 |   1.3003 |     44.010 |     0.2
   10 |   1.2715 |     42.160 |   1.2905 |     43.296 |     0.2
   11 |   1.2535 |     41.697 |   1.2828 |     43.700 |     0.2
   12 |   1.2398 |     41.163 |   1.2575 |     42.924 |     0.3
   13 |   1.2193 |     40.694 |   1.2521 |     42.365 |     0.3
   14 |   1.1957 |     39.912 |   1.2445 |     42.179 |     0.3
   15 |   1.1789 |     39.157 |   1.2140 |     40.937 |     0.3
   16 |   1.1605 |     38.479 |   1.2011 |     40.472 |     0.3
   17 |   1.1381 |     37.835 |   1.1885 |     40.068 |     0.4
   18 |   1.1172 |     37.427 |   1.1740 |     39.696 |     0.4
   19 |   1.1050 |     37.196 |   1.1787 |     39.665 |     0.4
   20 |   1.0810 |     36.353 |   1.1317 |     38.361 |     0.4
   21 |   1.0603 |     35.829 |   1.1459 |     38.703 |     0.5
   22 |   1.0358 |     35.201 |   1.1176 |     37.554 |     0.5
   23 |   1.0076 |     34.105 |   1.1109 |     38.175 |     0.5
   24 |   0.9915 |     33.344 |   1.1184 |     37.213 |     0.5
   25 |   0.9719 |     32.639 |   1.0892 |     36.840 |     0.5
   26 |   0.9377 |     31.421 |   1.0912 |     36.809 |     0.6
   27 |   0.9144 |     30.782 |   1.0706 |     36.127 |     0.6
   28 |   0.8912 |     30.160 |   1.0639 |     35.382 |     0.6
   29 |   0.8663 |     29.366 |   1.0787 |     35.506 |     0.6
   30 |   0.8505 |     28.424 |   1.0648 |     34.916 |     0.6
   31 |   0.8101 |     27.174 |   1.0404 |     33.551 |     0.7
   32 |   0.7904 |     26.573 |   1.0605 |     34.358 |     0.7
   33 |   0.7703 |     25.532 |   1.0341 |     33.054 |     0.7
   34 |   0.7477 |     25.190 |   1.0493 |     32.806 |     0.7
   35 |   0.7260 |     24.253 |   1.0355 |     32.526 |     0.8
   36 |   0.7061 |     23.394 |   1.0523 |     32.744 |     0.8
   37 |   0.6940 |     23.157 |   1.0322 |     31.750 |     0.8
   38 |   0.6636 |     21.730 |   1.0456 |     32.154 |     0.8
   39 |   0.6597 |     21.769 |   1.0404 |     31.750 |     0.8
   40 |   0.6322 |     21.129 |   1.0399 |     31.099 |     0.9
   41 |   0.6232 |     20.545 |   1.0659 |     32.216 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,466,849

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5022 |     67.366 |   1.9604 |     55.525 |     0.1
    2 |   1.7237 |     48.518 |   1.5553 |     47.083 |     0.2
    3 |   1.4822 |     45.846 |   1.4510 |     47.083 |     0.2
    4 |   1.4250 |     45.846 |   1.4215 |     47.083 |     0.3
    5 |   1.4011 |     45.846 |   1.4068 |     47.083 |     0.4
    6 |   1.3862 |     45.862 |   1.3880 |     47.083 |     0.5
    7 |   1.3713 |     45.829 |   1.3758 |     46.400 |     0.5
    8 |   1.3553 |     44.672 |   1.3635 |     45.562 |     0.6
    9 |   1.3368 |     44.402 |   1.3441 |     45.872 |     0.7
   10 |   1.3273 |     44.264 |   1.3326 |     45.282 |     0.8
   11 |   1.3106 |     44.000 |   1.3206 |     44.910 |     0.9
   12 |   1.3078 |     43.636 |   1.3237 |     45.717 |     0.9
   13 |   1.3012 |     43.559 |   1.3207 |     45.003 |     1.0
   14 |   1.2924 |     43.267 |   1.3090 |     45.407 |     1.1
   15 |   1.2859 |     43.052 |   1.3143 |     44.848 |     1.2
   16 |   1.2775 |     42.452 |   1.2971 |     44.103 |     1.2
   17 |   1.2662 |     42.039 |   1.2696 |     43.234 |     1.3
   18 |   1.2588 |     42.094 |   1.2745 |     43.824 |     1.4
   19 |   1.2476 |     41.807 |   1.2687 |     43.762 |     1.5
   20 |   1.2416 |     41.818 |   1.2736 |     43.451 |     1.5
   21 |   1.2335 |     41.421 |   1.2660 |     43.606 |     1.6
   22 |   1.2237 |     41.460 |   1.2530 |     43.203 |     1.7
   23 |   1.2165 |     40.799 |   1.2481 |     42.800 |     1.8
   24 |   1.2055 |     40.287 |   1.2524 |     42.675 |     1.9
   25 |   1.1979 |     40.094 |   1.2354 |     41.930 |     1.9
   26 |   1.1868 |     39.967 |   1.2494 |     42.024 |     2.0
   27 |   1.1892 |     40.259 |   1.2295 |     41.558 |     2.1
   28 |   1.1762 |     39.559 |   1.2230 |     41.124 |     2.2
   29 |   1.1705 |     39.499 |   1.2133 |     40.844 |     2.2
   30 |   1.1678 |     39.421 |   1.2061 |     40.503 |     2.3
   31 |   1.1620 |     39.394 |   1.2031 |     40.906 |     2.4
   32 |   1.1517 |     38.915 |   1.2170 |     41.558 |     2.5
   33 |   1.1469 |     38.826 |   1.2178 |     40.875 |     2.6
   34 |   1.1348 |     38.386 |   1.1886 |     40.037 |     2.6
   35 |   1.1324 |     38.573 |   1.1908 |     40.099 |     2.7
   36 |   1.1166 |     37.785 |   1.2159 |     40.410 |     2.8
   37 |   1.1170 |     37.625 |   1.1816 |     40.286 |     2.9
   38 |   1.1200 |     37.857 |   1.1968 |     39.820 |     2.9
   39 |   1.1064 |     37.300 |   1.1799 |     39.354 |     3.0
   40 |   1.0937 |     36.893 |   1.1758 |     39.013 |     3.1
   41 |   1.0829 |     36.573 |   1.1721 |     39.168 |     3.2
   42 |   1.0760 |     36.678 |   1.1901 |     39.727 |     3.2
   43 |   1.0775 |     36.496 |   1.1686 |     39.292 |     3.3
   44 |   1.0699 |     36.149 |   1.1670 |     39.758 |     3.4
   45 |   1.0720 |     36.127 |   1.1586 |     39.013 |     3.5
   46 |   1.0739 |     36.419 |   1.1513 |     38.392 |     3.6
   47 |   1.0627 |     35.719 |   1.1619 |     39.665 |     3.6
   48 |   1.0603 |     35.730 |   1.1608 |     38.454 |     3.7
   49 |   1.0606 |     35.780 |   1.1501 |     38.765 |     3.8
   50 |   1.0478 |     35.256 |   1.1562 |     38.858 |     3.9
   51 |   1.0408 |     34.964 |   1.1497 |     38.641 |     3.9
   52 |   1.0305 |     35.069 |   1.1541 |     38.113 |     4.0
   53 |   1.0346 |     34.848 |   1.1464 |     37.709 |     4.1
   54 |   1.0169 |     34.342 |   1.1470 |     38.579 |     4.2
   55 |   1.0181 |     34.358 |   1.1439 |     37.647 |     4.3
   56 |   1.0032 |     33.642 |   1.1462 |     37.989 |     4.3
   57 |   0.9998 |     33.680 |   1.1421 |     37.306 |     4.4
   58 |   0.9994 |     33.581 |   1.1369 |     37.772 |     4.5
   59 |   0.9996 |     33.791 |   1.1236 |     37.989 |     4.6
   60 |   0.9970 |     33.950 |   1.1438 |     37.554 |     4.6
   61 |   0.9824 |     33.129 |   1.1466 |     37.927 |     4.7
   62 |   0.9906 |     33.521 |   1.1498 |     37.554 |     4.8
   63 |   0.9995 |     33.482 |   1.1250 |     37.585 |     4.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 2,732,257

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1396 |     58.270 |   1.5814 |     47.083 |     0.1
    2 |   1.4483 |     45.719 |   1.4079 |     46.058 |     0.2
    3 |   1.3678 |     44.612 |   1.3507 |     45.593 |     0.2
    4 |   1.3232 |     43.796 |   1.3254 |     43.793 |     0.3
    5 |   1.2820 |     42.270 |   1.2737 |     43.420 |     0.4
    6 |   1.2399 |     41.041 |   1.2416 |     42.117 |     0.5
    7 |   1.2002 |     39.499 |   1.2047 |     40.192 |     0.5
    8 |   1.1643 |     38.727 |   1.1788 |     40.037 |     0.6
    9 |   1.1239 |     37.383 |   1.1563 |     39.479 |     0.7
   10 |   1.0901 |     35.829 |   1.1227 |     38.020 |     0.8
   11 |   1.0490 |     34.755 |   1.0908 |     36.406 |     0.9
   12 |   1.0082 |     33.570 |   1.0732 |     35.661 |     0.9
   13 |   0.9819 |     32.590 |   1.0659 |     36.065 |     1.0
   14 |   0.9496 |     31.978 |   1.0481 |     34.823 |     1.1
   15 |   0.9161 |     30.689 |   1.0405 |     34.854 |     1.2
   16 |   0.8929 |     30.110 |   1.0209 |     34.420 |     1.2
   17 |   0.8702 |     29.157 |   1.0084 |     33.644 |     1.3
   18 |   0.8489 |     28.309 |   1.0084 |     33.892 |     1.4
   19 |   0.8301 |     27.691 |   1.0172 |     32.992 |     1.5
   20 |   0.8075 |     27.014 |   0.9931 |     32.154 |     1.6
   21 |   0.7850 |     26.242 |   0.9821 |     32.030 |     1.6
   22 |   0.7520 |     24.749 |   0.9899 |     32.061 |     1.7
   23 |   0.7419 |     24.733 |   0.9758 |     31.906 |     1.8
   24 |   0.7052 |     23.482 |   0.9586 |     30.819 |     1.9
   25 |   0.6690 |     22.088 |   0.9583 |     30.509 |     1.9
   26 |   0.6532 |     21.609 |   0.9680 |     30.850 |     2.0
   27 |   0.6208 |     20.545 |   0.9620 |     30.540 |     2.1
   28 |   0.6032 |     20.044 |   0.9610 |     29.826 |     2.2
   29 |   0.5865 |     19.444 |   0.9462 |     28.585 |     2.3
   30 |   0.5660 |     18.837 |   0.9395 |     29.143 |     2.3
   31 |   0.5484 |     18.121 |   0.9652 |     29.330 |     2.4
   32 |   0.5356 |     17.736 |   0.9615 |     28.461 |     2.5
   33 |   0.5101 |     16.661 |   0.9766 |     28.119 |     2.6
   34 |   0.4881 |     16.182 |   0.9741 |     29.019 |     2.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 2,898,593

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2091 |     59.906 |   1.6278 |     47.083 |     0.1
    2 |   1.4781 |     45.873 |   1.4287 |     47.083 |     0.2
    3 |   1.4075 |     45.884 |   1.4031 |     47.083 |     0.2
    4 |   1.3945 |     45.846 |   1.3964 |     47.114 |     0.3
    5 |   1.3832 |     45.956 |   1.3879 |     47.083 |     0.4
    6 |   1.3609 |     45.052 |   1.3595 |     45.593 |     0.5
    7 |   1.3375 |     44.435 |   1.3457 |     46.493 |     0.6
    8 |   1.3214 |     44.033 |   1.3280 |     44.879 |     0.6
    9 |   1.3048 |     43.499 |   1.3155 |     44.941 |     0.7
   10 |   1.2908 |     42.970 |   1.2972 |     44.382 |     0.8
   11 |   1.2711 |     42.738 |   1.2831 |     44.475 |     0.9
   12 |   1.2594 |     42.138 |   1.2789 |     43.979 |     1.0
   13 |   1.2444 |     41.554 |   1.2732 |     43.017 |     1.0
   14 |   1.2258 |     41.196 |   1.2681 |     43.172 |     1.1
   15 |   1.2097 |     40.369 |   1.2461 |     41.775 |     1.2
   16 |   1.1908 |     39.780 |   1.2393 |     41.651 |     1.3
   17 |   1.1870 |     39.923 |   1.2355 |     41.341 |     1.3
   18 |   1.1750 |     39.377 |   1.2225 |     40.844 |     1.4
   19 |   1.1614 |     38.970 |   1.2218 |     40.596 |     1.5
   20 |   1.1521 |     38.860 |   1.1960 |     39.944 |     1.6
   21 |   1.1341 |     38.347 |   1.2089 |     39.944 |     1.7
   22 |   1.1217 |     37.636 |   1.1863 |     39.510 |     1.7
   23 |   1.1137 |     37.581 |   1.1764 |     39.354 |     1.8
   24 |   1.0954 |     37.041 |   1.1720 |     38.920 |     1.9
   25 |   1.0809 |     36.573 |   1.1587 |     38.765 |     2.0
   26 |   1.0618 |     35.862 |   1.1681 |     38.920 |     2.1
   27 |   1.0605 |     35.713 |   1.1542 |     37.616 |     2.1
   28 |   1.0391 |     35.052 |   1.1458 |     38.299 |     2.2
   29 |   1.0232 |     34.512 |   1.1382 |     38.268 |     2.3
   30 |   1.0134 |     34.000 |   1.1294 |     37.709 |     2.4
   31 |   0.9873 |     33.311 |   1.1331 |     37.678 |     2.5
   32 |   0.9674 |     32.518 |   1.1341 |     37.368 |     2.5
   33 |   0.9653 |     32.590 |   1.1203 |     36.468 |     2.6
   34 |   0.9516 |     31.818 |   1.1113 |     36.313 |     2.7
   35 |   0.9316 |     31.603 |   1.1087 |     35.444 |     2.8
   36 |   0.9226 |     31.063 |   1.1143 |     35.661 |     2.8
   37 |   0.9043 |     30.567 |   1.1199 |     36.313 |     2.9
   38 |   0.8879 |     29.862 |   1.1208 |     36.002 |     3.0
   39 |   0.8651 |     29.218 |   1.1087 |     35.071 |     3.1
   40 |   0.8498 |     28.281 |   1.0978 |     34.389 |     3.2
   41 |   0.8474 |     28.292 |   1.1002 |     35.102 |     3.2
   42 |   0.8229 |     27.840 |   1.0912 |     34.389 |     3.3
   43 |   0.8090 |     27.146 |   1.0896 |     34.327 |     3.4
   44 |   0.7954 |     26.915 |   1.1026 |     34.202 |     3.5
   45 |   0.7740 |     26.011 |   1.0901 |     34.078 |     3.6
   46 |   0.7634 |     25.994 |   1.0937 |     34.544 |     3.6
   47 |   0.7483 |     25.135 |   1.1042 |     34.233 |     3.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 2,079,073

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1921 |     60.055 |   1.6277 |     47.083 |     0.1
    2 |   1.4803 |     45.912 |   1.4184 |     46.617 |     0.1
    3 |   1.3792 |     44.948 |   1.3613 |     45.655 |     0.2
    4 |   1.3338 |     43.857 |   1.3177 |     44.351 |     0.3
    5 |   1.2914 |     42.573 |   1.2886 |     43.482 |     0.3
    6 |   1.2644 |     41.614 |   1.2725 |     42.334 |     0.4
    7 |   1.2342 |     40.634 |   1.2418 |     41.775 |     0.4
    8 |   1.2041 |     39.868 |   1.2189 |     40.441 |     0.5
    9 |   1.1737 |     38.843 |   1.1966 |     40.130 |     0.6
   10 |   1.1451 |     37.956 |   1.1744 |     39.510 |     0.6
   11 |   1.1193 |     37.074 |   1.1626 |     39.354 |     0.7
   12 |   1.0928 |     36.545 |   1.1678 |     39.385 |     0.8
   13 |   1.0662 |     35.493 |   1.1409 |     38.579 |     0.8
   14 |   1.0372 |     34.612 |   1.1095 |     37.213 |     0.9
   15 |   1.0080 |     33.802 |   1.0949 |     36.220 |     1.0
   16 |   0.9844 |     32.909 |   1.0700 |     35.475 |     1.0
   17 |   0.9544 |     31.873 |   1.0623 |     35.568 |     1.1
   18 |   0.9346 |     31.504 |   1.0359 |     34.078 |     1.2
   19 |   0.9006 |     29.917 |   1.0349 |     33.582 |     1.2
   20 |   0.8863 |     29.669 |   1.0065 |     32.961 |     1.3
   21 |   0.8581 |     28.490 |   1.0067 |     33.613 |     1.3
   22 |   0.8373 |     27.879 |   1.0027 |     32.402 |     1.4
   23 |   0.7993 |     26.237 |   0.9867 |     32.340 |     1.5
   24 |   0.7851 |     26.237 |   1.0174 |     32.713 |     1.5
   25 |   0.7645 |     25.636 |   0.9968 |     32.713 |     1.6
   26 |   0.7440 |     24.898 |   0.9929 |     31.813 |     1.7
   27 |   0.7349 |     24.325 |   0.9908 |     32.154 |     1.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 616,641

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2262 |     60.860 |   1.5869 |     47.176 |     0.0
    2 |   1.4357 |     44.832 |   1.3628 |     44.507 |     0.0
    3 |   1.3181 |     42.837 |   1.3018 |     43.544 |     0.1
    4 |   1.2508 |     40.634 |   1.2383 |     41.155 |     0.1
    5 |   1.1955 |     39.052 |   1.1883 |     39.385 |     0.1
    6 |   1.1404 |     37.174 |   1.1370 |     37.492 |     0.1
    7 |   1.0815 |     35.438 |   1.1186 |     36.934 |     0.1
    8 |   1.0246 |     33.394 |   1.0707 |     35.475 |     0.1
    9 |   0.9678 |     31.713 |   1.0332 |     33.209 |     0.2
   10 |   0.9156 |     29.923 |   1.0032 |     33.395 |     0.2
   11 |   0.8608 |     27.851 |   0.9964 |     32.371 |     0.2
   12 |   0.8193 |     26.474 |   0.9872 |     32.154 |     0.2
   13 |   0.7757 |     24.920 |   0.9525 |     30.137 |     0.2
   14 |   0.7154 |     22.926 |   0.9269 |     29.609 |     0.2
   15 |   0.6611 |     20.970 |   0.9109 |     28.895 |     0.3
   16 |   0.6172 |     19.686 |   0.9078 |     29.330 |     0.3
   17 |   0.5756 |     18.000 |   0.9107 |     28.119 |     0.3
   18 |   0.5326 |     16.793 |   0.8985 |     27.592 |     0.3
   19 |   0.4987 |     15.713 |   0.8990 |     26.847 |     0.3
   20 |   0.4561 |     14.171 |   0.9088 |     26.940 |     0.3
   21 |   0.4174 |     12.744 |   0.9107 |     26.878 |     0.4
   22 |   0.3901 |     12.187 |   0.9279 |     26.878 |     0.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 486,113

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5369 |     67.934 |   1.9507 |     54.997 |     0.0
    2 |   1.7464 |     49.691 |   1.5772 |     47.083 |     0.0
    3 |   1.4971 |     45.846 |   1.4554 |     47.083 |     0.1
    4 |   1.4265 |     45.862 |   1.4206 |     47.083 |     0.1
    5 |   1.3962 |     45.807 |   1.3947 |     47.083 |     0.1
    6 |   1.3662 |     45.179 |   1.3641 |     46.182 |     0.1
    7 |   1.3427 |     44.766 |   1.3503 |     46.617 |     0.1
    8 |   1.3238 |     44.634 |   1.3217 |     45.903 |     0.1
    9 |   1.3003 |     43.945 |   1.2942 |     45.655 |     0.2
   10 |   1.2731 |     42.705 |   1.2641 |     42.520 |     0.2
   11 |   1.2443 |     41.212 |   1.2316 |     41.651 |     0.2
   12 |   1.2120 |     40.336 |   1.2200 |     42.520 |     0.2
   13 |   1.1895 |     40.160 |   1.1943 |     41.465 |     0.2
   14 |   1.1626 |     39.295 |   1.1815 |     41.279 |     0.3
   15 |   1.1319 |     38.446 |   1.1576 |     40.534 |     0.3
   16 |   1.1055 |     37.328 |   1.1385 |     39.758 |     0.3
   17 |   1.0871 |     37.163 |   1.1298 |     39.479 |     0.3
   18 |   1.0624 |     36.171 |   1.0989 |     38.082 |     0.3
   19 |   1.0359 |     35.080 |   1.0918 |     37.585 |     0.3
   20 |   1.0155 |     33.868 |   1.0748 |     36.375 |     0.4
   21 |   0.9864 |     32.931 |   1.0740 |     36.623 |     0.4
   22 |   0.9736 |     32.457 |   1.0603 |     34.389 |     0.4
   23 |   0.9585 |     32.149 |   1.0398 |     35.071 |     0.4
   24 |   0.9385 |     31.278 |   1.0235 |     34.295 |     0.4
   25 |   0.9389 |     31.433 |   1.0452 |     34.202 |     0.5
   26 |   0.9022 |     29.945 |   1.0372 |     34.109 |     0.5
   27 |   0.8858 |     29.455 |   1.0150 |     33.551 |     0.5
   28 |   0.8640 |     28.700 |   1.0009 |     32.557 |     0.5
   29 |   0.8420 |     27.978 |   1.0306 |     33.861 |     0.5
   30 |   0.8375 |     27.702 |   1.0158 |     33.240 |     0.5
   31 |   0.8211 |     27.317 |   1.0032 |     32.061 |     0.6
   32 |   0.7948 |     26.176 |   0.9785 |     31.533 |     0.6
   33 |   0.7787 |     25.780 |   1.0034 |     32.526 |     0.6
   34 |   0.7669 |     25.135 |   1.0067 |     31.782 |     0.6
   35 |   0.7552 |     25.003 |   1.0204 |     31.595 |     0.6
   36 |   0.7341 |     23.857 |   1.0011 |     30.912 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 712,289

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5817 |     68.843 |   2.0205 |     59.404 |     0.0
    2 |   1.7905 |     50.837 |   1.5857 |     47.083 |     0.1
    3 |   1.5060 |     45.857 |   1.4617 |     47.083 |     0.1
    4 |   1.4334 |     45.840 |   1.4218 |     47.114 |     0.1
    5 |   1.4044 |     45.835 |   1.4005 |     47.083 |     0.1
    6 |   1.3860 |     45.769 |   1.3828 |     46.772 |     0.2
    7 |   1.3661 |     45.570 |   1.3629 |     46.679 |     0.2
    8 |   1.3411 |     45.163 |   1.3277 |     45.779 |     0.2
    9 |   1.3131 |     43.747 |   1.2949 |     44.382 |     0.3
   10 |   1.2823 |     42.970 |   1.2656 |     43.544 |     0.3
   11 |   1.2597 |     42.452 |   1.2498 |     43.017 |     0.3
   12 |   1.2458 |     42.160 |   1.2413 |     43.513 |     0.3
   13 |   1.2271 |     41.636 |   1.2126 |     42.334 |     0.4
   14 |   1.2072 |     41.146 |   1.2134 |     42.427 |     0.4
   15 |   1.1839 |     40.055 |   1.1898 |     41.496 |     0.4
   16 |   1.1692 |     39.416 |   1.1732 |     41.186 |     0.5
   17 |   1.1479 |     38.760 |   1.1675 |     40.192 |     0.5
   18 |   1.1309 |     38.006 |   1.1296 |     39.696 |     0.5
   19 |   1.1123 |     37.168 |   1.1316 |     38.392 |     0.5
   20 |   1.0975 |     36.837 |   1.1267 |     39.354 |     0.6
   21 |   1.0795 |     36.347 |   1.1208 |     38.330 |     0.6
   22 |   1.0709 |     36.017 |   1.1082 |     38.765 |     0.6
   23 |   1.0509 |     35.047 |   1.0821 |     37.027 |     0.6
   24 |   1.0322 |     34.837 |   1.0701 |     36.654 |     0.7
   25 |   1.0210 |     34.094 |   1.0838 |     37.213 |     0.7
   26 |   1.0062 |     33.653 |   1.0589 |     35.971 |     0.7
   27 |   0.9981 |     33.410 |   1.0497 |     35.351 |     0.8
   28 |   0.9821 |     32.623 |   1.0574 |     34.606 |     0.8
   29 |   0.9662 |     32.226 |   1.0361 |     34.854 |     0.8
   30 |   0.9511 |     31.383 |   1.0364 |     34.295 |     0.8
   31 |   0.9404 |     31.207 |   1.0300 |     34.295 |     0.9
   32 |   0.9220 |     30.457 |   1.0372 |     33.923 |     0.9
   33 |   0.9180 |     30.446 |   1.0114 |     33.551 |     0.9
   34 |   0.9014 |     29.658 |   1.0242 |     33.085 |     1.0
   35 |   0.9100 |     30.165 |   1.0047 |     33.644 |     1.0
   36 |   0.8857 |     29.455 |   1.0167 |     33.364 |     1.0
   37 |   0.8685 |     28.981 |   1.0084 |     32.433 |     1.0
   38 |   0.8567 |     28.347 |   0.9985 |     32.557 |     1.1
   39 |   0.8479 |     28.039 |   1.0067 |     32.371 |     1.1
   40 |   0.8362 |     27.725 |   0.9911 |     31.782 |     1.1
   41 |   0.8231 |     27.019 |   0.9949 |     31.626 |     1.2
   42 |   0.8111 |     27.262 |   1.0035 |     32.619 |     1.2
   43 |   0.8059 |     26.799 |   0.9873 |     31.502 |     1.2
   44 |   0.8189 |     27.510 |   1.0065 |     32.247 |     1.2
   45 |   0.8013 |     26.545 |   0.9868 |     32.061 |     1.3
   46 |   0.7841 |     25.829 |   0.9894 |     31.844 |     1.3
   47 |   0.7684 |     25.377 |   0.9949 |     30.881 |     1.3
   48 |   0.7559 |     25.344 |   0.9716 |     31.161 |     1.4
   49 |   0.7425 |     24.556 |   0.9746 |     30.726 |     1.4
   50 |   0.7321 |     24.187 |   0.9631 |     29.795 |     1.4
   51 |   0.7278 |     24.253 |   0.9828 |     30.975 |     1.4
   52 |   0.7210 |     24.094 |   1.0074 |     31.223 |     1.5
   53 |   0.7232 |     24.083 |   0.9728 |     30.695 |     1.5
   54 |   0.7071 |     23.515 |   0.9770 |     30.416 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 2,732,257

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1806 |     59.218 |   1.6043 |     47.300 |     0.1
    2 |   1.4604 |     45.444 |   1.3878 |     45.903 |     0.2
    3 |   1.3512 |     44.127 |   1.3313 |     44.972 |     0.2
    4 |   1.2945 |     42.424 |   1.2724 |     43.358 |     0.3
    5 |   1.2476 |     41.019 |   1.2374 |     41.868 |     0.4
    6 |   1.2053 |     39.791 |   1.1976 |     39.634 |     0.5
    7 |   1.1583 |     38.198 |   1.1512 |     39.168 |     0.6
    8 |   1.1236 |     37.218 |   1.1271 |     37.120 |     0.7
    9 |   1.0850 |     36.050 |   1.1035 |     37.213 |     0.7
   10 |   1.0435 |     34.865 |   1.0751 |     35.909 |     0.8
   11 |   1.0097 |     33.609 |   1.0528 |     35.630 |     0.9
   12 |   0.9852 |     32.722 |   1.0827 |     35.971 |     1.0
   13 |   0.9587 |     31.829 |   1.0214 |     33.582 |     1.1
   14 |   0.9250 |     30.391 |   1.0234 |     34.202 |     1.2
   15 |   0.8988 |     29.873 |   1.0014 |     33.457 |     1.2
   16 |   0.8694 |     28.628 |   1.0023 |     32.775 |     1.3
   17 |   0.8500 |     28.187 |   0.9649 |     31.130 |     1.4
   18 |   0.8262 |     27.036 |   0.9885 |     32.247 |     1.5
   19 |   0.8115 |     26.804 |   0.9771 |     31.968 |     1.6
   20 |   0.7884 |     26.132 |   0.9743 |     31.099 |     1.7
   21 |   0.7631 |     24.981 |   0.9754 |     31.719 |     1.7
   22 |   0.7482 |     24.887 |   0.9514 |     31.006 |     1.8
   23 |   0.7224 |     23.840 |   0.9346 |     29.950 |     1.9
   24 |   0.7034 |     23.196 |   0.9552 |     30.757 |     2.0
   25 |   0.6970 |     23.322 |   0.9492 |     30.788 |     2.1
   26 |   0.6745 |     22.446 |   0.9571 |     30.137 |     2.2
   27 |   0.6515 |     21.741 |   0.9509 |     30.012 |     2.2
   28 |   0.6520 |     21.587 |   0.9196 |     29.826 |     2.3
   29 |   0.6379 |     21.196 |   0.9389 |     29.236 |     2.4
   30 |   0.6282 |     20.727 |   0.9464 |     29.081 |     2.5
   31 |   0.6133 |     20.320 |   0.9502 |     29.857 |     2.6
   32 |   0.6063 |     20.375 |   0.9375 |     28.895 |     2.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 2,697,377

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1894 |     59.785 |   1.6497 |     49.503 |     0.1
    2 |   1.4918 |     45.989 |   1.4264 |     47.083 |     0.2
    3 |   1.4079 |     45.868 |   1.4038 |     47.083 |     0.2
    4 |   1.3927 |     45.967 |   1.3995 |     47.083 |     0.3
    5 |   1.3882 |     45.862 |   1.3880 |     47.083 |     0.4
    6 |   1.3712 |     45.179 |   1.3629 |     46.120 |     0.5
    7 |   1.3434 |     44.545 |   1.3436 |     45.220 |     0.6
    8 |   1.3251 |     44.066 |   1.3239 |     45.220 |     0.7
    9 |   1.3060 |     43.554 |   1.3206 |     44.972 |     0.8
   10 |   1.2895 |     42.667 |   1.2912 |     44.041 |     0.8
   11 |   1.2702 |     42.143 |   1.2842 |     43.544 |     0.9
   12 |   1.2527 |     41.697 |   1.2724 |     42.893 |     1.0
   13 |   1.2310 |     41.124 |   1.2518 |     42.396 |     1.1
   14 |   1.2198 |     40.760 |   1.2450 |     41.962 |     1.2
   15 |   1.2012 |     40.110 |   1.2435 |     41.465 |     1.3
   16 |   1.1872 |     39.581 |   1.2200 |     41.217 |     1.3
   17 |   1.1728 |     39.262 |   1.2289 |     40.751 |     1.4
   18 |   1.1559 |     38.468 |   1.1987 |     39.603 |     1.5
   19 |   1.1405 |     38.397 |   1.1873 |     39.448 |     1.6
   20 |   1.1304 |     38.066 |   1.1985 |     40.068 |     1.7
   21 |   1.1095 |     37.647 |   1.1997 |     40.192 |     1.8
   22 |   1.1017 |     37.019 |   1.1705 |     39.292 |     1.8
   23 |   1.0896 |     36.975 |   1.1775 |     39.137 |     1.9
   24 |   1.0768 |     36.446 |   1.1462 |     38.641 |     2.0
   25 |   1.0611 |     36.099 |   1.1689 |     39.168 |     2.1
   26 |   1.0456 |     35.383 |   1.1427 |     38.113 |     2.2
   27 |   1.0307 |     34.920 |   1.1378 |     37.927 |     2.3
   28 |   1.0223 |     34.656 |   1.1469 |     37.368 |     2.4
   29 |   1.0066 |     34.264 |   1.1482 |     38.734 |     2.4
   30 |   0.9987 |     33.868 |   1.1255 |     37.120 |     2.5
   31 |   0.9883 |     33.625 |   1.1187 |     37.120 |     2.6
   32 |   0.9804 |     33.603 |   1.1277 |     36.934 |     2.7
   33 |   0.9675 |     32.694 |   1.1112 |     36.189 |     2.8
   34 |   0.9402 |     31.972 |   1.1189 |     36.716 |     2.9
   35 |   0.9356 |     31.592 |   1.1071 |     36.158 |     2.9
   36 |   0.9237 |     31.008 |   1.1144 |     35.878 |     3.0
   37 |   0.9161 |     30.937 |   1.1193 |     36.344 |     3.1
   38 |   0.9059 |     30.479 |   1.1180 |     36.872 |     3.2
   39 |   0.8916 |     29.912 |   1.0962 |     35.196 |     3.3
   40 |   0.8809 |     29.702 |   1.1045 |     35.754 |     3.4
   41 |   0.8591 |     29.168 |   1.1005 |     35.102 |     3.4
   42 |   0.8528 |     29.008 |   1.1061 |     35.040 |     3.5
   43 |   0.8345 |     28.342 |   1.0979 |     34.606 |     3.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 1,489,313

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1854 |     59.890 |   1.5834 |     47.083 |     0.0
    2 |   1.4700 |     45.857 |   1.4302 |     47.083 |     0.1
    3 |   1.4041 |     45.967 |   1.4006 |     47.114 |     0.1
    4 |   1.3796 |     46.028 |   1.3867 |     47.362 |     0.2
    5 |   1.3550 |     44.854 |   1.3489 |     45.562 |     0.2
    6 |   1.3283 |     43.934 |   1.3217 |     44.289 |     0.3
    7 |   1.3005 |     43.036 |   1.2983 |     43.420 |     0.3
    8 |   1.2800 |     42.193 |   1.2659 |     43.358 |     0.3
    9 |   1.2534 |     41.824 |   1.2656 |     43.203 |     0.4
   10 |   1.2317 |     40.848 |   1.2543 |     42.831 |     0.4
   11 |   1.2134 |     40.446 |   1.2431 |     42.210 |     0.5
   12 |   1.1954 |     40.138 |   1.2190 |     41.527 |     0.5
   13 |   1.1745 |     39.284 |   1.2043 |     41.651 |     0.5
   14 |   1.1570 |     39.229 |   1.2179 |     41.930 |     0.6
   15 |   1.1428 |     38.882 |   1.1729 |     40.068 |     0.6
   16 |   1.1057 |     37.543 |   1.1409 |     39.261 |     0.7
   17 |   1.0672 |     36.314 |   1.1256 |     38.392 |     0.7
   18 |   1.0382 |     34.975 |   1.1007 |     36.406 |     0.8
   19 |   0.9975 |     33.537 |   1.0916 |     36.934 |     0.8
   20 |   0.9703 |     32.689 |   1.0729 |     34.730 |     0.8
   21 |   0.9439 |     31.383 |   1.0540 |     35.258 |     0.9
   22 |   0.9259 |     31.069 |   1.0459 |     34.978 |     0.9
   23 |   0.8877 |     29.686 |   1.0383 |     33.861 |     1.0
   24 |   0.8542 |     28.419 |   1.0161 |     33.364 |     1.0
   25 |   0.8317 |     27.835 |   1.0027 |     32.371 |     1.0
   26 |   0.8032 |     26.419 |   0.9907 |     32.775 |     1.1
   27 |   0.7913 |     26.006 |   1.0151 |     32.526 |     1.1
   28 |   0.7591 |     24.959 |   0.9770 |     30.944 |     1.2
   29 |   0.7373 |     24.590 |   1.0035 |     32.154 |     1.2
   30 |   0.7202 |     24.121 |   1.0287 |     32.030 |     1.3
   31 |   0.6949 |     23.129 |   0.9605 |     30.230 |     1.3
   32 |   0.6694 |     22.650 |   0.9775 |     30.354 |     1.3
   33 |   0.6475 |     21.482 |   0.9652 |     29.609 |     1.4
   34 |   0.6142 |     20.331 |   0.9639 |     29.361 |     1.4
   35 |   0.5955 |     19.967 |   0.9767 |     29.609 |     1.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 605,953

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2867 |     61.410 |   1.6750 |     49.783 |     0.0
    2 |   1.5033 |     46.441 |   1.4241 |     47.083 |     0.0
    3 |   1.3855 |     45.708 |   1.3640 |     46.834 |     0.1
    4 |   1.3266 |     43.747 |   1.3073 |     44.507 |     0.1
    5 |   1.2803 |     42.573 |   1.2593 |     42.862 |     0.1
    6 |   1.2441 |     41.532 |   1.2265 |     41.651 |     0.1
    7 |   1.2097 |     40.083 |   1.2078 |     41.279 |     0.1
    8 |   1.1716 |     39.146 |   1.1845 |     40.782 |     0.2
    9 |   1.1412 |     38.287 |   1.1473 |     39.851 |     0.2
   10 |   1.1102 |     37.570 |   1.1200 |     38.113 |     0.2
   11 |   1.0761 |     36.198 |   1.1025 |     37.616 |     0.2
   12 |   1.0341 |     34.904 |   1.0839 |     37.027 |     0.2
   13 |   1.0018 |     33.846 |   1.0758 |     36.654 |     0.2
   14 |   0.9724 |     32.606 |   1.0562 |     35.164 |     0.3
   15 |   0.9340 |     31.306 |   1.0357 |     34.482 |     0.3
   16 |   0.9066 |     30.033 |   1.0141 |     33.178 |     0.3
   17 |   0.8654 |     28.804 |   1.0178 |     32.837 |     0.3
   18 |   0.8324 |     27.510 |   0.9936 |     31.906 |     0.3
   19 |   0.8048 |     26.182 |   0.9833 |     31.223 |     0.4
   20 |   0.7731 |     25.410 |   1.0016 |     31.875 |     0.4
   21 |   0.7411 |     24.468 |   0.9894 |     30.664 |     0.4
   22 |   0.7090 |     23.207 |   1.0057 |     30.788 |     0.4
   23 |   0.6786 |     22.072 |   0.9738 |     29.640 |     0.4
   24 |   0.6524 |     21.212 |   0.9716 |     29.392 |     0.5
   25 |   0.6269 |     20.452 |   0.9603 |     29.454 |     0.5
   26 |   0.5987 |     19.466 |   0.9666 |     28.461 |     0.5
   27 |   0.5805 |     18.733 |   0.9621 |     28.523 |     0.5
   28 |   0.5570 |     17.923 |   0.9635 |     27.933 |     0.5
   29 |   0.5406 |     17.631 |   0.9904 |     29.174 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 669,825

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2458 |     60.860 |   1.6249 |     47.517 |     0.0
    2 |   1.4700 |     45.868 |   1.4000 |     47.083 |     0.0
    3 |   1.3618 |     45.444 |   1.3464 |     45.841 |     0.1
    4 |   1.3109 |     44.270 |   1.2902 |     45.003 |     0.1
    5 |   1.2642 |     42.259 |   1.2391 |     42.241 |     0.1
    6 |   1.2096 |     40.171 |   1.1856 |     40.751 |     0.1
    7 |   1.1625 |     38.997 |   1.1549 |     39.075 |     0.1
    8 |   1.1160 |     37.774 |   1.1131 |     38.454 |     0.2
    9 |   1.0624 |     36.182 |   1.0928 |     37.803 |     0.2
   10 |   1.0194 |     34.397 |   1.0624 |     36.685 |     0.2
   11 |   0.9685 |     32.336 |   1.0262 |     34.668 |     0.2
   12 |   0.9240 |     30.672 |   1.0161 |     33.457 |     0.2
   13 |   0.8854 |     29.096 |   0.9916 |     32.806 |     0.2
   14 |   0.8391 |     27.713 |   0.9769 |     31.937 |     0.3
   15 |   0.7998 |     26.011 |   0.9653 |     31.099 |     0.3
   16 |   0.7679 |     25.019 |   0.9345 |     29.299 |     0.3
   17 |   0.7229 |     23.592 |   0.9195 |     28.957 |     0.3
   18 |   0.6843 |     22.215 |   0.9358 |     29.702 |     0.3
   19 |   0.6477 |     20.595 |   0.9340 |     27.281 |     0.4
   20 |   0.6137 |     19.466 |   0.9268 |     27.529 |     0.4
   21 |   0.5833 |     18.452 |   0.9035 |     27.002 |     0.4
   22 |   0.5531 |     17.691 |   0.9244 |     26.940 |     0.4
   23 |   0.5216 |     16.490 |   0.8966 |     25.729 |     0.4
   24 |   0.4919 |     15.339 |   0.9216 |     26.133 |     0.5
   25 |   0.4679 |     14.617 |   0.9483 |     26.133 |     0.5
   26 |   0.4529 |     14.397 |   0.9229 |     25.264 |     0.5
   27 |   0.4346 |     13.939 |   0.9336 |     25.885 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 893,729

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5476 |     67.675 |   1.9981 |     59.404 |     0.0
    2 |   1.7839 |     50.457 |   1.5971 |     47.083 |     0.1
    3 |   1.5114 |     45.895 |   1.4672 |     47.083 |     0.1
    4 |   1.4411 |     45.862 |   1.4308 |     47.083 |     0.1
    5 |   1.4157 |     45.901 |   1.4177 |     47.083 |     0.2
    6 |   1.4048 |     45.835 |   1.4049 |     47.083 |     0.2
    7 |   1.3964 |     45.884 |   1.4014 |     47.083 |     0.2
    8 |   1.3908 |     45.912 |   1.3980 |     47.083 |     0.3
    9 |   1.3874 |     45.752 |   1.3867 |     46.648 |     0.3
   10 |   1.3724 |     45.140 |   1.3705 |     45.562 |     0.3
   11 |   1.3527 |     44.303 |   1.3555 |     45.593 |     0.4
   12 |   1.3416 |     44.353 |   1.3443 |     45.593 |     0.4
   13 |   1.3315 |     44.226 |   1.3430 |     45.345 |     0.5
   14 |   1.3215 |     43.796 |   1.3273 |     45.313 |     0.5
   15 |   1.3136 |     43.587 |   1.3136 |     44.444 |     0.5
   16 |   1.3017 |     43.107 |   1.3039 |     44.196 |     0.6
   17 |   1.2895 |     42.738 |   1.2951 |     44.444 |     0.6
   18 |   1.2831 |     42.672 |   1.2883 |     44.103 |     0.6
   19 |   1.2738 |     42.347 |   1.2960 |     44.631 |     0.7
   20 |   1.2658 |     42.198 |   1.2854 |     44.569 |     0.7
   21 |   1.2608 |     42.452 |   1.2821 |     44.755 |     0.7
   22 |   1.2546 |     42.347 |   1.2676 |     43.265 |     0.8
   23 |   1.2430 |     41.669 |   1.2549 |     43.420 |     0.8
   24 |   1.2343 |     41.471 |   1.2496 |     42.955 |     0.8
   25 |   1.2198 |     40.959 |   1.2605 |     43.296 |     0.9
   26 |   1.2103 |     40.959 |   1.2281 |     41.868 |     0.9
   27 |   1.1930 |     40.446 |   1.2353 |     41.962 |     0.9
   28 |   1.1903 |     40.121 |   1.2145 |     41.558 |     1.0
   29 |   1.1731 |     39.466 |   1.2066 |     41.061 |     1.0
   30 |   1.1674 |     39.427 |   1.2003 |     41.372 |     1.0
   31 |   1.1528 |     39.196 |   1.1853 |     40.348 |     1.1
   32 |   1.1341 |     38.424 |   1.1793 |     39.944 |     1.1
   33 |   1.1289 |     38.325 |   1.1663 |     39.323 |     1.1
   34 |   1.1192 |     37.719 |   1.1668 |     39.354 |     1.2
   35 |   1.1059 |     37.102 |   1.1677 |     39.603 |     1.2
   36 |   1.1012 |     37.394 |   1.1468 |     38.703 |     1.3
   37 |   1.0850 |     36.551 |   1.1366 |     38.144 |     1.3
   38 |   1.0696 |     36.253 |   1.1309 |     38.485 |     1.3
   39 |   1.0538 |     35.317 |   1.1257 |     37.523 |     1.4
   40 |   1.0421 |     35.289 |   1.1180 |     38.175 |     1.4
   41 |   1.0324 |     35.008 |   1.1124 |     37.523 |     1.4
   42 |   1.0245 |     34.832 |   1.0973 |     36.530 |     1.5
   43 |   1.0218 |     34.705 |   1.0995 |     37.337 |     1.5
   44 |   1.0106 |     34.105 |   1.0942 |     37.089 |     1.5
   45 |   1.0039 |     33.956 |   1.0825 |     36.654 |     1.6
   46 |   0.9869 |     33.284 |   1.0855 |     36.313 |     1.6
   47 |   0.9768 |     32.953 |   1.0845 |     36.158 |     1.6
   48 |   0.9703 |     32.893 |   1.0923 |     36.872 |     1.7
   49 |   0.9532 |     32.121 |   1.0689 |     35.506 |     1.7
   50 |   0.9518 |     32.160 |   1.0675 |     35.847 |     1.7
   51 |   0.9362 |     31.576 |   1.0680 |     35.723 |     1.8
   52 |   0.9305 |     31.240 |   1.0727 |     35.382 |     1.8
   53 |   0.9245 |     31.102 |   1.0681 |     35.909 |     1.8
   54 |   0.9149 |     30.672 |   1.0505 |     35.537 |     1.9
   55 |   0.9021 |     30.264 |   1.0373 |     35.133 |     1.9
   56 |   0.9091 |     30.612 |   1.0556 |     35.133 |     1.9
   57 |   0.8890 |     29.928 |   1.0616 |     34.885 |     2.0
   58 |   0.8884 |     29.928 |   1.0477 |     34.202 |     2.0
   59 |   0.8736 |     29.168 |   1.0488 |     33.892 |     2.1
   60 |   0.8621 |     29.196 |   1.0292 |     34.140 |     2.1
   61 |   0.8588 |     29.047 |   1.0327 |     33.985 |     2.1
   62 |   0.8442 |     28.353 |   1.0403 |     33.985 |     2.2
   63 |   0.8456 |     28.446 |   1.0479 |     33.892 |     2.2
   64 |   0.8373 |     27.972 |   1.0322 |     33.675 |     2.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 953,473

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5979 |     70.050 |   2.0228 |     55.028 |     0.0
    2 |   1.7732 |     50.309 |   1.5828 |     47.083 |     0.1
    3 |   1.4964 |     45.868 |   1.4546 |     47.083 |     0.1
    4 |   1.4286 |     45.912 |   1.4215 |     47.083 |     0.1
    5 |   1.4080 |     45.835 |   1.4051 |     47.083 |     0.2
    6 |   1.3967 |     45.829 |   1.4059 |     47.083 |     0.2
    7 |   1.3921 |     45.923 |   1.4038 |     47.114 |     0.3
    8 |   1.3887 |     45.890 |   1.4026 |     47.083 |     0.3
    9 |   1.3862 |     45.851 |   1.3940 |     47.083 |     0.3
   10 |   1.3842 |     45.950 |   1.3898 |     47.083 |     0.4
   11 |   1.3811 |     45.868 |   1.3896 |     47.083 |     0.4
   12 |   1.3735 |     45.835 |   1.3759 |     46.896 |     0.4
   13 |   1.3629 |     45.647 |   1.3648 |     46.772 |     0.5
   14 |   1.3523 |     44.887 |   1.3658 |     45.593 |     0.5
   15 |   1.3360 |     44.496 |   1.3425 |     46.369 |     0.6
   16 |   1.3248 |     44.435 |   1.3302 |     45.686 |     0.6
   17 |   1.3128 |     44.226 |   1.3241 |     45.469 |     0.6
   18 |   1.3082 |     44.077 |   1.3258 |     45.593 |     0.7
   19 |   1.3005 |     43.471 |   1.3136 |     45.376 |     0.7
   20 |   1.2875 |     42.837 |   1.3117 |     44.972 |     0.7
   21 |   1.2804 |     42.650 |   1.2870 |     44.382 |     0.8
   22 |   1.2719 |     42.402 |   1.2831 |     44.631 |     0.8
   23 |   1.2613 |     42.198 |   1.2879 |     44.507 |     0.9
   24 |   1.2548 |     41.829 |   1.2719 |     43.420 |     0.9
   25 |   1.2479 |     41.807 |   1.2639 |     43.793 |     0.9
   26 |   1.2410 |     41.658 |   1.2543 |     42.768 |     1.0
   27 |   1.2336 |     41.306 |   1.2645 |     43.669 |     1.0
   28 |   1.2332 |     41.399 |   1.2622 |     43.234 |     1.0
   29 |   1.2226 |     41.168 |   1.2479 |     43.141 |     1.1
   30 |   1.2198 |     41.008 |   1.2496 |     42.737 |     1.1
   31 |   1.2179 |     41.146 |   1.2447 |     42.458 |     1.1
   32 |   1.2045 |     40.639 |   1.2370 |     42.365 |     1.2
   33 |   1.1992 |     40.749 |   1.2305 |     41.837 |     1.2
   34 |   1.1992 |     40.672 |   1.2410 |     42.458 |     1.3
   35 |   1.1851 |     40.320 |   1.2314 |     42.582 |     1.3
   36 |   1.1831 |     40.264 |   1.2406 |     42.117 |     1.3
   37 |   1.1679 |     39.895 |   1.2266 |     42.117 |     1.4
   38 |   1.1624 |     39.642 |   1.2238 |     41.527 |     1.4
   39 |   1.1543 |     39.240 |   1.2186 |     41.061 |     1.4
   40 |   1.1535 |     39.052 |   1.2298 |     41.744 |     1.5
   41 |   1.1552 |     39.433 |   1.2213 |     41.155 |     1.5
   42 |   1.1345 |     38.512 |   1.2132 |     40.534 |     1.6
   43 |   1.1305 |     38.220 |   1.2040 |     40.037 |     1.6
   44 |   1.1338 |     38.672 |   1.1953 |     40.068 |     1.6
   45 |   1.1285 |     38.601 |   1.1996 |     40.410 |     1.7
   46 |   1.1205 |     38.132 |   1.2181 |     40.255 |     1.7
   47 |   1.1192 |     38.061 |   1.1957 |     39.944 |     1.7
   48 |   1.1000 |     37.587 |   1.1918 |     40.534 |     1.8
   49 |   1.0880 |     37.019 |   1.1970 |     39.479 |     1.8
   50 |   1.0924 |     37.234 |   1.1993 |     40.317 |     1.9
   51 |   1.0904 |     37.118 |   1.2054 |     39.696 |     1.9
   52 |   1.0917 |     37.366 |   1.1962 |     39.975 |     1.9
   53 |   1.0724 |     36.766 |   1.1861 |     39.168 |     2.0
   54 |   1.0614 |     36.463 |   1.1808 |     38.734 |     2.0
   55 |   1.0637 |     36.733 |   1.1798 |     39.044 |     2.0
   56 |   1.0521 |     36.253 |   1.1807 |     39.230 |     2.1
   57 |   1.0537 |     36.298 |   1.2029 |     39.913 |     2.1
   58 |   1.0547 |     36.099 |   1.1844 |     39.168 |     2.1
   59 |   1.0538 |     35.917 |   1.2004 |     39.354 |     2.2
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 2,452,065

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5440 |     68.876 |   2.0660 |     59.404 |     0.1
    2 |   1.8272 |     51.824 |   1.6172 |     47.114 |     0.2
    3 |   1.5132 |     45.846 |   1.4593 |     47.083 |     0.3
    4 |   1.4284 |     45.835 |   1.4136 |     46.958 |     0.4
    5 |   1.3995 |     45.229 |   1.3981 |     46.524 |     0.4
    6 |   1.3767 |     44.590 |   1.3813 |     45.593 |     0.5
    7 |   1.3585 |     44.512 |   1.3618 |     45.469 |     0.6
    8 |   1.3450 |     44.325 |   1.3509 |     45.593 |     0.7
    9 |   1.3276 |     44.050 |   1.3318 |     45.065 |     0.8
   10 |   1.3152 |     43.499 |   1.3157 |     44.258 |     0.9
   11 |   1.3018 |     43.174 |   1.2994 |     44.134 |     0.9
   12 |   1.2863 |     42.540 |   1.2991 |     44.134 |     1.0
   13 |   1.2716 |     42.171 |   1.2950 |     44.103 |     1.1
   14 |   1.2636 |     42.028 |   1.2696 |     43.451 |     1.2
   15 |   1.2507 |     41.471 |   1.2773 |     43.544 |     1.3
   16 |   1.2441 |     41.289 |   1.2631 |     42.489 |     1.4
   17 |   1.2347 |     41.003 |   1.2627 |     42.924 |     1.4
   18 |   1.2312 |     40.804 |   1.2573 |     41.713 |     1.5
   19 |   1.2167 |     40.364 |   1.2429 |     41.651 |     1.6
   20 |   1.2014 |     39.719 |   1.2340 |     41.155 |     1.7
   21 |   1.1926 |     39.366 |   1.2364 |     41.372 |     1.8
   22 |   1.1899 |     39.377 |   1.2192 |     40.968 |     1.9
   23 |   1.1768 |     38.948 |   1.2100 |     40.844 |     1.9
   24 |   1.1608 |     38.782 |   1.1942 |     39.665 |     2.0
   25 |   1.1494 |     38.231 |   1.1749 |     38.734 |     2.1
   26 |   1.1450 |     38.149 |   1.1925 |     39.665 |     2.2
   27 |   1.1330 |     37.989 |   1.1689 |     38.889 |     2.3
   28 |   1.1191 |     37.366 |   1.1668 |     39.106 |     2.4
   29 |   1.1125 |     37.372 |   1.1587 |     38.703 |     2.4
   30 |   1.1003 |     36.893 |   1.1662 |     39.137 |     2.5
   31 |   1.0927 |     36.689 |   1.1580 |     38.765 |     2.6
   32 |   1.0900 |     36.645 |   1.1672 |     38.423 |     2.7
   33 |   1.0772 |     36.132 |   1.1491 |     38.423 |     2.8
   34 |   1.0708 |     35.785 |   1.1397 |     38.113 |     2.9
   35 |   1.0548 |     35.510 |   1.1335 |     37.772 |     2.9
   36 |   1.0472 |     35.537 |   1.1265 |     37.709 |     3.0
   37 |   1.0417 |     34.915 |   1.1328 |     38.268 |     3.1
   38 |   1.0323 |     34.992 |   1.1228 |     37.803 |     3.2
   39 |   1.0168 |     34.264 |   1.1125 |     37.927 |     3.3
   40 |   1.0084 |     33.978 |   1.1128 |     37.275 |     3.4
   41 |   0.9898 |     33.234 |   1.0923 |     36.344 |     3.5
   42 |   0.9752 |     32.815 |   1.0884 |     36.468 |     3.5
   43 |   0.9789 |     32.920 |   1.0905 |     36.158 |     3.6
   44 |   0.9723 |     32.777 |   1.0824 |     36.468 |     3.7
   45 |   0.9536 |     31.983 |   1.0928 |     36.282 |     3.8
   46 |   0.9458 |     31.934 |   1.0789 |     36.065 |     3.9
   47 |   0.9353 |     31.669 |   1.0773 |     35.630 |     4.0
   48 |   0.9366 |     31.923 |   1.0741 |     35.444 |     4.0
   49 |   0.9263 |     31.025 |   1.0718 |     35.040 |     4.1
   50 |   0.9170 |     30.843 |   1.0708 |     35.289 |     4.2
   51 |   0.9136 |     30.876 |   1.0783 |     35.692 |     4.3
   52 |   0.9112 |     30.634 |   1.0595 |     34.947 |     4.4
   53 |   0.8885 |     29.774 |   1.0513 |     35.009 |     4.5
   54 |   0.8803 |     29.664 |   1.0549 |     34.761 |     4.5
   55 |   0.8819 |     29.515 |   1.0545 |     34.668 |     4.6
   56 |   0.8666 |     29.124 |   1.0683 |     34.947 |     4.7
   57 |   0.8773 |     29.311 |   1.0513 |     34.109 |     4.8
   58 |   0.8609 |     28.909 |   1.0364 |     33.892 |     4.9
   59 |   0.8544 |     28.678 |   1.0847 |     34.854 |     5.0
   60 |   0.8663 |     29.196 |   1.0371 |     33.892 |     5.0
   61 |   0.8336 |     27.939 |   1.0322 |     34.016 |     5.1
   62 |   0.8456 |     28.645 |   1.0393 |     33.457 |     5.2
   63 |   0.8202 |     27.482 |   1.0260 |     33.551 |     5.3
   64 |   0.8134 |     27.416 |   1.0325 |     33.489 |     5.4
   65 |   0.8007 |     26.876 |   1.0267 |     32.651 |     5.5
   66 |   0.7995 |     27.273 |   1.0286 |     33.644 |     5.5
   67 |   0.7988 |     27.085 |   1.0396 |     33.582 |     5.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 690,977

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2463 |     61.052 |   1.6375 |     47.083 |     0.0
    2 |   1.4796 |     45.950 |   1.4243 |     47.083 |     0.0
    3 |   1.3781 |     44.650 |   1.3590 |     44.972 |     0.1
    4 |   1.3264 |     43.146 |   1.3231 |     43.731 |     0.1
    5 |   1.2826 |     41.879 |   1.2872 |     42.831 |     0.1
    6 |   1.2489 |     40.832 |   1.2454 |     42.334 |     0.1
    7 |   1.2102 |     40.072 |   1.2191 |     41.527 |     0.2
    8 |   1.1682 |     39.107 |   1.1955 |     40.751 |     0.2
    9 |   1.1339 |     37.890 |   1.1757 |     39.510 |     0.2
   10 |   1.0947 |     37.251 |   1.1499 |     38.889 |     0.2
   11 |   1.0583 |     35.846 |   1.1144 |     36.903 |     0.2
   12 |   1.0138 |     33.994 |   1.1124 |     36.872 |     0.3
   13 |   0.9698 |     32.303 |   1.0814 |     35.754 |     0.3
   14 |   0.9301 |     30.997 |   1.0697 |     34.854 |     0.3
   15 |   0.8839 |     29.091 |   1.0521 |     34.233 |     0.3
   16 |   0.8418 |     27.928 |   1.0374 |     32.682 |     0.3
   17 |   0.7956 |     26.474 |   1.0176 |     32.371 |     0.4
   18 |   0.7541 |     24.727 |   0.9932 |     31.068 |     0.4
   19 |   0.7216 |     23.427 |   1.0007 |     30.757 |     0.4
   20 |   0.6744 |     21.989 |   0.9956 |     31.037 |     0.4
   21 |   0.6438 |     21.113 |   0.9865 |     30.074 |     0.5
   22 |   0.6095 |     19.774 |   0.9699 |     29.019 |     0.5
   23 |   0.5550 |     17.642 |   0.9811 |     29.609 |     0.5
   24 |   0.5275 |     16.826 |   0.9974 |     28.926 |     0.5
   25 |   0.4948 |     15.950 |   0.9952 |     29.392 |     0.5
   26 |   0.4652 |     14.843 |   1.0104 |     28.616 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 720,609

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3007 |     61.653 |   1.7046 |     49.441 |     0.0
    2 |   1.5200 |     46.595 |   1.4475 |     47.083 |     0.0
    3 |   1.4110 |     45.868 |   1.4013 |     47.083 |     0.1
    4 |   1.3821 |     45.631 |   1.3817 |     45.469 |     0.1
    5 |   1.3525 |     44.303 |   1.3505 |     45.655 |     0.1
    6 |   1.3259 |     43.824 |   1.3230 |     44.600 |     0.1
    7 |   1.3005 |     43.212 |   1.3103 |     44.848 |     0.1
    8 |   1.2745 |     42.298 |   1.2659 |     42.737 |     0.2
    9 |   1.2517 |     41.262 |   1.2512 |     42.551 |     0.2
   10 |   1.2201 |     40.782 |   1.2153 |     41.806 |     0.2
   11 |   1.1948 |     40.242 |   1.1928 |     41.372 |     0.2
   12 |   1.1749 |     39.570 |   1.1861 |     40.751 |     0.2
   13 |   1.1517 |     38.700 |   1.1677 |     40.410 |     0.2
   14 |   1.1248 |     38.116 |   1.1511 |     39.882 |     0.3
   15 |   1.1067 |     37.388 |   1.1289 |     39.354 |     0.3
   16 |   1.0778 |     36.843 |   1.1109 |     38.889 |     0.3
   17 |   1.0489 |     35.873 |   1.0920 |     36.996 |     0.3
   18 |   1.0239 |     34.760 |   1.0774 |     36.406 |     0.3
   19 |   0.9990 |     33.658 |   1.0828 |     36.189 |     0.4
   20 |   0.9728 |     32.931 |   1.0644 |     36.499 |     0.4
   21 |   0.9498 |     31.895 |   1.0521 |     35.071 |     0.4
   22 |   0.9289 |     31.322 |   1.0149 |     34.233 |     0.4
   23 |   0.9011 |     30.287 |   1.0187 |     33.147 |     0.4
   24 |   0.8856 |     29.758 |   1.0176 |     33.768 |     0.5
   25 |   0.8542 |     28.926 |   1.0148 |     33.768 |     0.5
   26 |   0.8392 |     28.292 |   1.0317 |     33.209 |     0.5
   27 |   0.8140 |     27.256 |   0.9888 |     31.378 |     0.5
   28 |   0.7905 |     26.904 |   0.9836 |     32.247 |     0.5
   29 |   0.7669 |     25.846 |   1.0000 |     31.719 |     0.6
   30 |   0.7532 |     25.377 |   0.9973 |     32.061 |     0.6
   31 |   0.7335 |     24.694 |   1.0049 |     31.130 |     0.6
   32 |   0.7102 |     23.791 |   0.9929 |     31.254 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 859,425

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1495 |     58.446 |   1.5711 |     46.865 |     0.0
    2 |   1.4302 |     45.041 |   1.3616 |     45.313 |     0.0
    3 |   1.3013 |     42.044 |   1.2735 |     42.427 |     0.1
    4 |   1.2289 |     40.121 |   1.2133 |     40.689 |     0.1
    5 |   1.1631 |     38.055 |   1.1622 |     38.579 |     0.1
    6 |   1.1092 |     36.303 |   1.1190 |     37.213 |     0.1
    7 |   1.0506 |     34.507 |   1.0768 |     35.909 |     0.2
    8 |   0.9968 |     32.793 |   1.0590 |     35.351 |     0.2
    9 |   0.9363 |     30.441 |   1.0183 |     33.178 |     0.2
   10 |   0.8839 |     28.683 |   0.9940 |     32.557 |     0.2
   11 |   0.8195 |     26.435 |   0.9624 |     30.695 |     0.3
   12 |   0.7614 |     24.562 |   0.9528 |     30.447 |     0.3
   13 |   0.7174 |     23.014 |   0.9289 |     29.888 |     0.3
   14 |   0.6615 |     20.854 |   0.9346 |     29.702 |     0.3
   15 |   0.6190 |     19.603 |   0.8938 |     27.685 |     0.4
   16 |   0.5671 |     17.796 |   0.9094 |     27.871 |     0.4
   17 |   0.5255 |     16.485 |   0.9026 |     27.685 |     0.4
   18 |   0.4829 |     15.140 |   0.9224 |     27.747 |     0.4
   19 |   0.4447 |     13.851 |   0.9093 |     26.909 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 2,829,473

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2424 |     61.945 |   1.6521 |     47.083 |     0.1
    2 |   1.4930 |     45.956 |   1.4248 |     47.020 |     0.2
    3 |   1.4064 |     45.813 |   1.4015 |     47.083 |     0.2
    4 |   1.3935 |     46.028 |   1.4033 |     47.083 |     0.3
    5 |   1.3885 |     45.895 |   1.3956 |     47.083 |     0.4
    6 |   1.3837 |     45.857 |   1.3844 |     46.151 |     0.5
    7 |   1.3662 |     44.639 |   1.3619 |     45.872 |     0.6
    8 |   1.3477 |     44.567 |   1.3504 |     45.531 |     0.7
    9 |   1.3336 |     44.264 |   1.3389 |     45.810 |     0.8
   10 |   1.3247 |     44.000 |   1.3300 |     45.096 |     0.8
   11 |   1.3163 |     43.680 |   1.3271 |     45.500 |     0.9
   12 |   1.3054 |     43.504 |   1.3072 |     44.507 |     1.0
   13 |   1.2955 |     43.113 |   1.3049 |     44.600 |     1.1
   14 |   1.2847 |     42.904 |   1.2936 |     44.382 |     1.2
   15 |   1.2732 |     42.573 |   1.2869 |     44.041 |     1.3
   16 |   1.2619 |     42.198 |   1.2741 |     43.948 |     1.4
   17 |   1.2577 |     42.325 |   1.2688 |     43.451 |     1.4
   18 |   1.2478 |     42.022 |   1.2688 |     43.203 |     1.5
   19 |   1.2421 |     41.763 |   1.2661 |     42.831 |     1.6
   20 |   1.2337 |     41.769 |   1.2582 |     42.706 |     1.7
   21 |   1.2264 |     41.449 |   1.2526 |     42.396 |     1.8
   22 |   1.2129 |     41.174 |   1.2470 |     41.279 |     1.9
   23 |   1.2098 |     40.848 |   1.2464 |     40.968 |     1.9
   24 |   1.2015 |     40.567 |   1.2418 |     41.092 |     2.0
   25 |   1.1877 |     40.248 |   1.2071 |     40.968 |     2.1
   26 |   1.1790 |     40.099 |   1.2092 |     40.875 |     2.2
   27 |   1.1665 |     39.592 |   1.1975 |     39.727 |     2.3
   28 |   1.1541 |     39.410 |   1.1990 |     40.441 |     2.4
   29 |   1.1482 |     38.893 |   1.2097 |     40.006 |     2.5
   30 |   1.1438 |     38.782 |   1.1903 |     40.068 |     2.5
   31 |   1.1260 |     38.408 |   1.1773 |     38.827 |     2.6
   32 |   1.1240 |     38.110 |   1.1967 |     40.286 |     2.7
   33 |   1.1226 |     38.248 |   1.1733 |     39.975 |     2.8
   34 |   1.1078 |     37.829 |   1.1641 |     39.044 |     2.9
   35 |   1.1014 |     37.780 |   1.1543 |     39.013 |     3.0
   36 |   1.0887 |     37.124 |   1.1732 |     39.354 |     3.0
   37 |   1.0872 |     37.041 |   1.1704 |     39.789 |     3.1
   38 |   1.0829 |     37.350 |   1.1559 |     38.920 |     3.2
   39 |   1.0705 |     36.738 |   1.1624 |     39.479 |     3.3
   40 |   1.0678 |     36.562 |   1.1483 |     38.082 |     3.4
   41 |   1.0588 |     36.055 |   1.1448 |     38.392 |     3.5
   42 |   1.0441 |     35.598 |   1.1376 |     38.361 |     3.5
   43 |   1.0406 |     35.769 |   1.1316 |     37.834 |     3.6
   44 |   1.0335 |     35.592 |   1.1548 |     38.734 |     3.7
   45 |   1.0307 |     35.339 |   1.1380 |     37.989 |     3.8
   46 |   1.0257 |     35.262 |   1.1494 |     39.292 |     3.9
   47 |   1.0223 |     34.975 |   1.1381 |     37.989 |     4.0
   48 |   1.0114 |     34.623 |   1.1227 |     36.965 |     4.1
   49 |   0.9997 |     34.287 |   1.1194 |     37.647 |     4.1
   50 |   0.9809 |     33.713 |   1.1301 |     38.020 |     4.2
   51 |   0.9887 |     33.691 |   1.1271 |     37.896 |     4.3
   52 |   0.9702 |     33.273 |   1.1231 |     37.306 |     4.4
   53 |   0.9579 |     32.738 |   1.1091 |     37.058 |     4.5
   54 |   0.9490 |     32.380 |   1.1040 |     37.430 |     4.6
   55 |   0.9444 |     32.028 |   1.0999 |     36.189 |     4.7
   56 |   0.9321 |     31.846 |   1.1222 |     37.120 |     4.7
   57 |   0.9433 |     32.446 |   1.1005 |     36.344 |     4.8
   58 |   0.9274 |     31.543 |   1.0966 |     36.158 |     4.9
   59 |   0.9240 |     31.570 |   1.0991 |     36.158 |     5.0
   60 |   0.9049 |     31.201 |   1.0975 |     36.468 |     5.1
   61 |   0.8983 |     30.832 |   1.0900 |     35.723 |     5.2
   62 |   0.8867 |     30.623 |   1.1000 |     35.258 |     5.2
   63 |   0.8921 |     30.760 |   1.1016 |     35.630 |     5.3
   64 |   0.9109 |     31.300 |   1.0922 |     35.537 |     5.4
   65 |   0.9028 |     31.124 |   1.1098 |     35.351 |     5.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 1,174,881

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5781 |     69.978 |   2.0103 |     54.935 |     0.0
    2 |   1.7998 |     50.777 |   1.6147 |     47.114 |     0.1
    3 |   1.5246 |     45.961 |   1.4683 |     47.083 |     0.1
    4 |   1.4380 |     45.857 |   1.4264 |     47.083 |     0.2
    5 |   1.4118 |     45.857 |   1.4118 |     47.083 |     0.2
    6 |   1.3981 |     45.862 |   1.4059 |     47.083 |     0.2
    7 |   1.3910 |     45.923 |   1.3951 |     47.083 |     0.3
    8 |   1.3868 |     45.818 |   1.3930 |     47.083 |     0.3
    9 |   1.3816 |     45.736 |   1.3914 |     47.020 |     0.4
   10 |   1.3725 |     45.052 |   1.3754 |     45.779 |     0.4
   11 |   1.3576 |     44.579 |   1.3602 |     45.500 |     0.5
   12 |   1.3455 |     44.501 |   1.3485 |     45.810 |     0.5
   13 |   1.3377 |     44.424 |   1.3382 |     45.500 |     0.5
   14 |   1.3274 |     44.325 |   1.3381 |     45.810 |     0.6
   15 |   1.3226 |     44.149 |   1.3316 |     45.593 |     0.6
   16 |   1.3147 |     44.028 |   1.3203 |     46.120 |     0.7
   17 |   1.3090 |     44.000 |   1.3137 |     45.407 |     0.7
   18 |   1.3034 |     43.769 |   1.3143 |     45.655 |     0.8
   19 |   1.2961 |     43.405 |   1.3055 |     44.972 |     0.8
   20 |   1.2844 |     42.804 |   1.2914 |     44.382 |     0.8
   21 |   1.2773 |     42.397 |   1.2910 |     44.382 |     0.9
   22 |   1.2751 |     42.556 |   1.2850 |     43.793 |     0.9
   23 |   1.2675 |     42.143 |   1.2768 |     44.475 |     1.0
   24 |   1.2585 |     42.039 |   1.2714 |     43.917 |     1.0
   25 |   1.2560 |     42.050 |   1.2897 |     44.538 |     1.0
   26 |   1.2501 |     42.121 |   1.2624 |     43.575 |     1.1
   27 |   1.2502 |     41.994 |   1.2562 |     43.296 |     1.1
   28 |   1.2418 |     41.851 |   1.2652 |     43.762 |     1.2
   29 |   1.2350 |     41.769 |   1.2565 |     43.358 |     1.2
   30 |   1.2279 |     41.466 |   1.2500 |     43.637 |     1.3
   31 |   1.2219 |     41.730 |   1.2384 |     42.831 |     1.3
   32 |   1.2190 |     41.284 |   1.2435 |     43.420 |     1.3
   33 |   1.2098 |     41.135 |   1.2215 |     42.241 |     1.4
   34 |   1.1999 |     40.694 |   1.2183 |     42.427 |     1.4
   35 |   1.1889 |     40.551 |   1.2163 |     42.241 |     1.5
   36 |   1.1843 |     40.617 |   1.2247 |     42.024 |     1.5
   37 |   1.1862 |     40.463 |   1.2254 |     42.086 |     1.5
   38 |   1.1800 |     40.259 |   1.2041 |     41.589 |     1.6
   39 |   1.1728 |     39.895 |   1.2090 |     41.558 |     1.6
   40 |   1.1660 |     39.669 |   1.2037 |     41.186 |     1.7
   41 |   1.1740 |     39.824 |   1.2073 |     41.030 |     1.7
   42 |   1.1671 |     39.967 |   1.2028 |     40.565 |     1.8
   43 |   1.1561 |     39.355 |   1.1917 |     40.472 |     1.8
   44 |   1.1490 |     38.942 |   1.1861 |     40.410 |     1.8
   45 |   1.1354 |     38.612 |   1.1874 |     40.130 |     1.9
   46 |   1.1290 |     38.562 |   1.1827 |     40.006 |     1.9
   47 |   1.1246 |     38.143 |   1.1976 |     40.720 |     2.0
   48 |   1.1277 |     38.270 |   1.1691 |     39.292 |     2.0
   49 |   1.1156 |     38.099 |   1.1811 |     39.044 |     2.0
   50 |   1.1038 |     37.377 |   1.1726 |     39.696 |     2.1
   51 |   1.1030 |     37.410 |   1.1689 |     39.448 |     2.1
   52 |   1.1007 |     37.096 |   1.1673 |     38.641 |     2.2
   53 |   1.0957 |     37.229 |   1.1605 |     39.541 |     2.2
   54 |   1.0814 |     36.749 |   1.1591 |     39.044 |     2.3
   55 |   1.0735 |     36.386 |   1.1697 |     39.354 |     2.3
   56 |   1.0718 |     36.556 |   1.1575 |     38.454 |     2.3
   57 |   1.0666 |     36.507 |   1.1432 |     38.082 |     2.4
   58 |   1.0541 |     35.741 |   1.1442 |     37.958 |     2.4
   59 |   1.0451 |     35.477 |   1.1494 |     38.392 |     2.5
   60 |   1.0502 |     35.741 |   1.1244 |     36.685 |     2.5
   61 |   1.0424 |     35.455 |   1.1399 |     37.554 |     2.5
   62 |   1.0343 |     35.267 |   1.1252 |     36.996 |     2.6
   63 |   1.0301 |     34.926 |   1.1172 |     36.654 |     2.6
   64 |   1.0189 |     34.639 |   1.1328 |     37.709 |     2.7
   65 |   1.0093 |     34.033 |   1.1194 |     36.996 |     2.7
   66 |   1.0121 |     34.325 |   1.1400 |     36.872 |     2.8
   67 |   1.0098 |     34.314 |   1.1352 |     37.616 |     2.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 435,425

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0465 |     56.628 |   1.4552 |     46.741 |     0.0
    2 |   1.3671 |     44.579 |   1.3114 |     44.848 |     0.0
    3 |   1.2657 |     42.105 |   1.2401 |     41.217 |     0.0
    4 |   1.1827 |     38.837 |   1.1685 |     39.479 |     0.1
    5 |   1.0959 |     36.342 |   1.0889 |     36.996 |     0.1
    6 |   1.0298 |     33.851 |   1.0430 |     34.730 |     0.1
    7 |   0.9610 |     31.372 |   1.0049 |     33.023 |     0.1
    8 |   0.8943 |     28.942 |   0.9465 |     30.478 |     0.1
    9 |   0.8281 |     26.650 |   0.9176 |     29.454 |     0.1
   10 |   0.7635 |     24.446 |   0.9064 |     30.043 |     0.1
   11 |   0.7063 |     22.342 |   0.8724 |     27.778 |     0.1
   12 |   0.6550 |     20.529 |   0.8728 |     27.654 |     0.2
   13 |   0.6023 |     18.457 |   0.8460 |     26.226 |     0.2
   14 |   0.5500 |     17.014 |   0.8354 |     25.698 |     0.2
   15 |   0.5079 |     15.240 |   0.8359 |     25.264 |     0.2
   16 |   0.4737 |     14.490 |   0.8465 |     25.388 |     0.2
   17 |   0.4344 |     13.262 |   0.8337 |     25.295 |     0.2
   18 |   0.4047 |     12.452 |   0.8468 |     25.109 |     0.2
   19 |   0.3770 |     11.592 |   0.8662 |     25.450 |     0.3
   20 |   0.3491 |     10.705 |   0.8495 |     24.178 |     0.3
   21 |   0.3263 |      9.857 |   0.8856 |     24.457 |     0.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 927,009

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5872 |     69.438 |   2.0153 |     59.404 |     0.0
    2 |   1.7740 |     50.105 |   1.5740 |     47.083 |     0.1
    3 |   1.4968 |     45.868 |   1.4543 |     47.083 |     0.1
    4 |   1.4296 |     45.939 |   1.4185 |     47.083 |     0.1
    5 |   1.4065 |     45.961 |   1.4099 |     47.083 |     0.2
    6 |   1.3954 |     45.846 |   1.4006 |     47.083 |     0.2
    7 |   1.3895 |     45.851 |   1.3958 |     47.083 |     0.2
    8 |   1.3857 |     45.868 |   1.3874 |     47.114 |     0.3
    9 |   1.3786 |     45.851 |   1.3856 |     47.114 |     0.3
   10 |   1.3646 |     45.587 |   1.3661 |     46.679 |     0.3
   11 |   1.3438 |     44.959 |   1.3555 |     47.020 |     0.4
   12 |   1.3282 |     44.931 |   1.3253 |     46.307 |     0.4
   13 |   1.3139 |     44.556 |   1.3171 |     46.338 |     0.4
   14 |   1.2989 |     44.121 |   1.2926 |     45.469 |     0.5
   15 |   1.2851 |     43.642 |   1.2757 |     45.376 |     0.5
   16 |   1.2714 |     43.350 |   1.2764 |     44.910 |     0.5
   17 |   1.2593 |     42.904 |   1.2549 |     44.134 |     0.6
   18 |   1.2486 |     42.551 |   1.2480 |     44.103 |     0.6
   19 |   1.2298 |     41.983 |   1.2296 |     43.234 |     0.7
   20 |   1.2259 |     41.653 |   1.2208 |     42.272 |     0.7
   21 |   1.2079 |     40.650 |   1.2045 |     42.179 |     0.7
   22 |   1.1978 |     40.667 |   1.2008 |     41.124 |     0.8
   23 |   1.1832 |     40.303 |   1.2028 |     41.962 |     0.8
   24 |   1.1625 |     39.355 |   1.1803 |     41.186 |     0.8
   25 |   1.1532 |     39.273 |   1.1730 |     40.472 |     0.9
   26 |   1.1535 |     39.322 |   1.1600 |     40.348 |     0.9
   27 |   1.1349 |     38.667 |   1.1577 |     40.410 |     0.9
   28 |   1.1257 |     38.353 |   1.1472 |     39.448 |     1.0
   29 |   1.1085 |     37.581 |   1.1423 |     39.727 |     1.0
   30 |   1.1026 |     37.548 |   1.1309 |     39.013 |     1.0
   31 |   1.0891 |     37.118 |   1.1198 |     39.168 |     1.1
   32 |   1.0793 |     36.694 |   1.1165 |     38.423 |     1.1
   33 |   1.0721 |     36.424 |   1.1184 |     38.113 |     1.1
   34 |   1.0587 |     35.906 |   1.1142 |     37.120 |     1.2
   35 |   1.0519 |     35.444 |   1.1122 |     37.865 |     1.2
   36 |   1.0400 |     35.135 |   1.1073 |     37.772 |     1.2
   37 |   1.0231 |     34.672 |   1.0878 |     37.244 |     1.3
   38 |   1.0167 |     34.512 |   1.0794 |     36.499 |     1.3
   39 |   1.0017 |     34.281 |   1.0673 |     36.189 |     1.3
   40 |   0.9975 |     33.807 |   1.0556 |     36.251 |     1.4
   41 |   0.9780 |     32.959 |   1.0642 |     36.313 |     1.4
   42 |   0.9666 |     32.672 |   1.0597 |     35.909 |     1.4
   43 |   0.9574 |     32.556 |   1.0558 |     35.196 |     1.5
   44 |   0.9448 |     32.061 |   1.0413 |     34.761 |     1.5
   45 |   0.9383 |     31.989 |   1.0375 |     34.202 |     1.5
   46 |   0.9212 |     31.212 |   1.0340 |     34.233 |     1.6
   47 |   0.9218 |     31.179 |   1.0369 |     35.413 |     1.6
   48 |   0.9050 |     30.744 |   1.0215 |     34.109 |     1.6
   49 |   0.8944 |     30.567 |   1.0460 |     35.351 |     1.7
   50 |   0.8951 |     30.248 |   1.0358 |     34.171 |     1.7
   51 |   0.8776 |     29.719 |   1.0395 |     34.171 |     1.7
   52 |   0.8744 |     29.675 |   1.0239 |     33.116 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 1,427,745

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2626 |     61.912 |   1.6596 |     49.441 |     0.0
    2 |   1.4946 |     46.017 |   1.4359 |     47.083 |     0.1
    3 |   1.4107 |     45.873 |   1.4152 |     47.207 |     0.1
    4 |   1.3939 |     45.884 |   1.3981 |     47.083 |     0.2
    5 |   1.3795 |     45.840 |   1.3754 |     47.114 |     0.2
    6 |   1.3529 |     45.620 |   1.3459 |     46.214 |     0.2
    7 |   1.3174 |     43.752 |   1.2912 |     44.631 |     0.3
    8 |   1.2716 |     43.118 |   1.2619 |     44.320 |     0.3
    9 |   1.2421 |     42.766 |   1.2521 |     43.731 |     0.3
   10 |   1.2277 |     42.072 |   1.2347 |     43.513 |     0.4
   11 |   1.2017 |     41.085 |   1.2007 |     42.520 |     0.4
   12 |   1.1817 |     40.298 |   1.1955 |     41.496 |     0.5
   13 |   1.1649 |     39.647 |   1.1864 |     41.155 |     0.5
   14 |   1.1461 |     39.256 |   1.1629 |     41.030 |     0.5
   15 |   1.1206 |     38.292 |   1.1500 |     40.534 |     0.6
   16 |   1.1064 |     38.033 |   1.1453 |     39.789 |     0.6
   17 |   1.0855 |     37.047 |   1.1264 |     39.541 |     0.6
   18 |   1.0700 |     36.545 |   1.1049 |     38.889 |     0.7
   19 |   1.0472 |     35.774 |   1.0904 |     37.306 |     0.7
   20 |   1.0287 |     35.124 |   1.0815 |     36.468 |     0.8
   21 |   1.0044 |     34.127 |   1.0526 |     35.630 |     0.8
   22 |   0.9849 |     33.256 |   1.0723 |     36.313 |     0.8
   23 |   0.9712 |     33.085 |   1.0529 |     35.630 |     0.9
   24 |   0.9499 |     32.287 |   1.0565 |     35.444 |     0.9
   25 |   0.9435 |     32.083 |   1.0348 |     35.164 |     0.9
   26 |   0.9147 |     31.118 |   1.0311 |     34.854 |     1.0
   27 |   0.8845 |     30.143 |   1.0180 |     33.426 |     1.0
   28 |   0.8721 |     29.658 |   1.0291 |     34.544 |     1.1
   29 |   0.8548 |     28.909 |   1.0205 |     33.830 |     1.1
   30 |   0.8399 |     28.601 |   1.0385 |     33.768 |     1.1
   31 |   0.8145 |     27.647 |   1.0192 |     34.327 |     1.2
   32 |   0.8016 |     27.273 |   1.0072 |     32.682 |     1.2
   33 |   0.7831 |     26.248 |   0.9913 |     31.626 |     1.3
   34 |   0.7592 |     25.675 |   0.9904 |     32.682 |     1.3
   35 |   0.7406 |     24.716 |   0.9899 |     32.651 |     1.3
   36 |   0.7264 |     24.523 |   0.9813 |     31.750 |     1.4
   37 |   0.7086 |     23.736 |   0.9767 |     31.285 |     1.4
   38 |   0.6925 |     23.273 |   0.9629 |     30.012 |     1.4
   39 |   0.6802 |     22.523 |   1.0052 |     31.068 |     1.5
   40 |   0.6635 |     22.281 |   0.9867 |     29.671 |     1.5
   41 |   0.6437 |     21.300 |   0.9819 |     30.416 |     1.6
   42 |   0.6284 |     20.909 |   0.9612 |     30.261 |     1.6
   43 |   0.6225 |     20.755 |   0.9856 |     30.074 |     1.6
   44 |   0.5993 |     19.983 |   0.9637 |     28.864 |     1.7
   45 |   0.5873 |     19.350 |   1.0024 |     30.168 |     1.7
   46 |   0.5748 |     18.634 |   0.9518 |     28.305 |     1.7
   47 |   0.5532 |     18.231 |   0.9941 |     29.702 |     1.8
   48 |   0.5396 |     17.956 |   0.9712 |     29.236 |     1.8
   49 |   0.5304 |     17.758 |   0.9605 |     28.274 |     1.9
   50 |   0.5054 |     16.716 |   0.9901 |     28.554 |     1.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 2,045,473

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1239 |     58.275 |   1.5577 |     47.207 |     0.1
    2 |   1.4344 |     45.807 |   1.3934 |     46.958 |     0.1
    3 |   1.3375 |     44.061 |   1.3094 |     43.948 |     0.2
    4 |   1.2662 |     41.625 |   1.2604 |     42.862 |     0.2
    5 |   1.2199 |     40.457 |   1.2021 |     40.813 |     0.3
    6 |   1.1545 |     38.171 |   1.1582 |     39.044 |     0.4
    7 |   1.1039 |     36.909 |   1.1261 |     37.927 |     0.4
    8 |   1.0534 |     34.716 |   1.0725 |     35.444 |     0.5
    9 |   1.0134 |     33.388 |   1.0537 |     34.513 |     0.5
   10 |   0.9684 |     31.647 |   1.0702 |     35.847 |     0.6
   11 |   0.9202 |     30.000 |   1.0137 |     32.806 |     0.7
   12 |   0.8773 |     28.656 |   1.0094 |     32.371 |     0.7
   13 |   0.8377 |     27.240 |   0.9860 |     32.123 |     0.8
   14 |   0.7983 |     26.457 |   0.9515 |     30.912 |     0.8
   15 |   0.7610 |     24.942 |   0.9715 |     31.161 |     0.9
   16 |   0.7384 |     24.220 |   0.9433 |     30.292 |     1.0
   17 |   0.6910 |     22.325 |   0.9388 |     30.571 |     1.0
   18 |   0.6539 |     21.129 |   0.9232 |     29.423 |     1.1
   19 |   0.6172 |     20.083 |   0.9214 |     29.019 |     1.1
   20 |   0.5858 |     18.843 |   0.9423 |     28.895 |     1.2
   21 |   0.5523 |     17.796 |   0.9294 |     28.212 |     1.3
   22 |   0.5430 |     17.796 |   0.9540 |     28.616 |     1.3
   23 |   0.5088 |     16.523 |   0.9412 |     28.119 |     1.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.0
Trainable parameters: 343,745

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5295 |     68.766 |   1.9601 |     56.859 |     0.0
    2 |   1.7140 |     48.567 |   1.5402 |     47.083 |     0.0
    3 |   1.4662 |     45.846 |   1.4280 |     47.083 |     0.1
    4 |   1.3943 |     45.763 |   1.3911 |     46.927 |     0.1
    5 |   1.3515 |     44.959 |   1.3507 |     46.493 |     0.1
    6 |   1.3183 |     44.275 |   1.3107 |     45.531 |     0.1
    7 |   1.2908 |     43.730 |   1.2915 |     45.251 |     0.1
    8 |   1.2644 |     42.887 |   1.2628 |     44.786 |     0.1
    9 |   1.2299 |     41.752 |   1.2398 |     43.358 |     0.2
   10 |   1.2000 |     40.336 |   1.2109 |     42.055 |     0.2
   11 |   1.1653 |     39.466 |   1.1951 |     41.620 |     0.2
   12 |   1.1312 |     38.375 |   1.1589 |     40.441 |     0.2
   13 |   1.1016 |     37.548 |   1.1383 |     38.579 |     0.2
   14 |   1.0655 |     35.884 |   1.1316 |     39.354 |     0.2
   15 |   1.0390 |     34.893 |   1.1153 |     38.330 |     0.3
   16 |   1.0068 |     34.160 |   1.1048 |     37.989 |     0.3
   17 |   0.9797 |     32.871 |   1.0908 |     36.996 |     0.3
   18 |   0.9540 |     31.961 |   1.0619 |     35.878 |     0.3
   19 |   0.9216 |     30.815 |   1.0671 |     36.189 |     0.3
   20 |   0.8946 |     29.928 |   1.0592 |     34.482 |     0.3
   21 |   0.8796 |     29.256 |   1.0380 |     34.792 |     0.4
   22 |   0.8426 |     27.824 |   1.0462 |     34.544 |     0.4
   23 |   0.8212 |     26.948 |   1.0316 |     33.768 |     0.4
   24 |   0.7933 |     25.917 |   1.0301 |     33.085 |     0.4
   25 |   0.7685 |     25.118 |   1.0288 |     32.526 |     0.4
   26 |   0.7504 |     24.529 |   1.0415 |     32.961 |     0.4
   27 |   0.7281 |     23.488 |   1.0283 |     32.154 |     0.5
   28 |   0.7042 |     22.639 |   1.0293 |     31.006 |     0.5
   29 |   0.6828 |     22.193 |   1.0323 |     31.844 |     0.5
   30 |   0.6559 |     21.234 |   1.0310 |     31.006 |     0.5
   31 |   0.6376 |     20.446 |   1.0503 |     31.316 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 454,689

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6022 |     69.190 |   2.0072 |     59.404 |     0.0
    2 |   1.7660 |     49.774 |   1.5773 |     47.083 |     0.0
    3 |   1.4991 |     45.862 |   1.4517 |     47.083 |     0.1
    4 |   1.4305 |     45.840 |   1.4228 |     47.083 |     0.1
    5 |   1.4095 |     45.873 |   1.4108 |     47.083 |     0.1
    6 |   1.3980 |     45.824 |   1.3995 |     47.083 |     0.1
    7 |   1.3831 |     45.857 |   1.3766 |     47.114 |     0.2
    8 |   1.3592 |     45.317 |   1.3532 |     46.338 |     0.2
    9 |   1.3355 |     45.058 |   1.3260 |     46.462 |     0.2
   10 |   1.3185 |     45.069 |   1.2994 |     45.562 |     0.2
   11 |   1.3006 |     44.804 |   1.2938 |     45.779 |     0.3
   12 |   1.2835 |     44.303 |   1.2723 |     45.500 |     0.3
   13 |   1.2750 |     44.336 |   1.2888 |     45.934 |     0.3
   14 |   1.2670 |     43.802 |   1.2537 |     44.972 |     0.3
   15 |   1.2486 |     43.069 |   1.2492 |     44.631 |     0.3
   16 |   1.2383 |     42.815 |   1.2530 |     44.165 |     0.4
   17 |   1.2291 |     42.705 |   1.2320 |     43.327 |     0.4
   18 |   1.2159 |     41.961 |   1.2219 |     43.017 |     0.4
   19 |   1.2061 |     41.631 |   1.2163 |     43.265 |     0.4
   20 |   1.1951 |     41.372 |   1.2147 |     42.800 |     0.5
   21 |   1.1826 |     40.810 |   1.1980 |     42.613 |     0.5
   22 |   1.1708 |     40.419 |   1.1897 |     41.837 |     0.5
   23 |   1.1599 |     40.314 |   1.1864 |     41.775 |     0.5
   24 |   1.1418 |     39.466 |   1.1673 |     41.092 |     0.5
   25 |   1.1323 |     39.410 |   1.1762 |     41.496 |     0.6
   26 |   1.1210 |     38.837 |   1.1739 |     41.155 |     0.6
   27 |   1.1178 |     39.129 |   1.1744 |     41.465 |     0.6
   28 |   1.0996 |     38.105 |   1.1620 |     40.099 |     0.6
   29 |   1.0889 |     37.515 |   1.1577 |     39.230 |     0.7
   30 |   1.0784 |     37.295 |   1.1314 |     38.827 |     0.7
   31 |   1.0659 |     36.672 |   1.1329 |     38.454 |     0.7
   32 |   1.0565 |     36.479 |   1.1471 |     39.106 |     0.7
   33 |   1.0419 |     35.504 |   1.1298 |     38.423 |     0.8
   34 |   1.0304 |     35.587 |   1.1137 |     37.120 |     0.8
   35 |   1.0154 |     34.716 |   1.1118 |     36.965 |     0.8
   36 |   1.0098 |     34.441 |   1.1189 |     37.865 |     0.8
   37 |   1.0001 |     34.353 |   1.1046 |     36.189 |     0.8
   38 |   0.9881 |     34.044 |   1.1124 |     36.996 |     0.9
   39 |   0.9811 |     33.758 |   1.1036 |     36.623 |     0.9
   40 |   0.9782 |     33.548 |   1.1079 |     36.809 |     0.9
   41 |   0.9503 |     32.369 |   1.0910 |     35.971 |     0.9
   42 |   0.9438 |     32.237 |   1.0820 |     35.971 |     1.0
   43 |   0.9354 |     31.972 |   1.0771 |     36.158 |     1.0
   44 |   0.9198 |     31.168 |   1.0783 |     35.723 |     1.0
   45 |   0.9109 |     31.196 |   1.0715 |     35.164 |     1.0
   46 |   0.9033 |     30.700 |   1.0836 |     35.661 |     1.0
   47 |   0.8909 |     30.237 |   1.0735 |     34.420 |     1.1
   48 |   0.8874 |     30.105 |   1.0773 |     34.916 |     1.1
   49 |   0.8754 |     29.923 |   1.0916 |     35.040 |     1.1
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 231,553

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5952 |     69.537 |   2.0357 |     56.331 |     0.0
    2 |   1.7990 |     50.887 |   1.6102 |     47.145 |     0.0
    3 |   1.5203 |     45.873 |   1.4714 |     47.083 |     0.0
    4 |   1.4387 |     45.840 |   1.4269 |     47.083 |     0.1
    5 |   1.4033 |     45.835 |   1.3959 |     47.083 |     0.1
    6 |   1.3759 |     45.521 |   1.3690 |     46.058 |     0.1
    7 |   1.3504 |     44.507 |   1.3438 |     45.469 |     0.1
    8 |   1.3276 |     43.857 |   1.3223 |     44.755 |     0.1
    9 |   1.3001 |     43.207 |   1.2968 |     43.948 |     0.1
   10 |   1.2800 |     43.014 |   1.2759 |     44.165 |     0.1
   11 |   1.2625 |     42.248 |   1.2590 |     44.072 |     0.2
   12 |   1.2375 |     41.537 |   1.2392 |     42.334 |     0.2
   13 |   1.2184 |     40.573 |   1.2241 |     42.303 |     0.2
   14 |   1.1988 |     39.901 |   1.2143 |     42.458 |     0.2
   15 |   1.1838 |     39.592 |   1.1830 |     40.565 |     0.2
   16 |   1.1653 |     39.157 |   1.1751 |     40.999 |     0.2
   17 |   1.1461 |     38.551 |   1.1560 |     39.261 |     0.2
   18 |   1.1291 |     38.154 |   1.1475 |     39.572 |     0.2
   19 |   1.1154 |     37.658 |   1.1336 |     38.734 |     0.3
   20 |   1.0946 |     37.091 |   1.1361 |     39.385 |     0.3
   21 |   1.0817 |     36.612 |   1.1395 |     38.703 |     0.3
   22 |   1.0685 |     35.780 |   1.1151 |     38.113 |     0.3
   23 |   1.0481 |     35.273 |   1.0986 |     37.430 |     0.3
   24 |   1.0297 |     34.672 |   1.0873 |     36.809 |     0.3
   25 |   1.0145 |     34.000 |   1.0844 |     36.002 |     0.3
   26 |   0.9917 |     33.300 |   1.0749 |     35.661 |     0.4
   27 |   0.9834 |     32.793 |   1.0723 |     34.699 |     0.4
   28 |   0.9634 |     31.950 |   1.0612 |     34.730 |     0.4
   29 |   0.9434 |     31.196 |   1.0641 |     34.854 |     0.4
   30 |   0.9329 |     30.986 |   1.0529 |     34.389 |     0.4
   31 |   0.9096 |     30.094 |   1.0455 |     34.078 |     0.4
   32 |   0.8954 |     29.333 |   1.0367 |     33.520 |     0.4
   33 |   0.8803 |     28.837 |   1.0284 |     32.961 |     0.5
   34 |   0.8592 |     28.474 |   1.0201 |     32.588 |     0.5
   35 |   0.8449 |     27.901 |   1.0345 |     32.744 |     0.5
   36 |   0.8329 |     27.278 |   1.0128 |     31.719 |     0.5
   37 |   0.8184 |     26.926 |   1.0160 |     31.254 |     0.5
   38 |   0.7929 |     26.182 |   1.0136 |     32.061 |     0.5
   39 |   0.7835 |     25.879 |   1.0135 |     31.937 |     0.5
   40 |   0.7758 |     25.543 |   0.9903 |     31.316 |     0.6
   41 |   0.7605 |     25.058 |   0.9895 |     31.626 |     0.6
   42 |   0.7474 |     24.760 |   0.9891 |     30.726 |     0.6
   43 |   0.7387 |     24.198 |   0.9887 |     30.540 |     0.6
   44 |   0.7235 |     23.752 |   0.9869 |     30.633 |     0.6
   45 |   0.7136 |     23.355 |   0.9956 |     30.354 |     0.6
   46 |   0.6957 |     22.711 |   0.9916 |     31.161 |     0.6
   47 |   0.6877 |     22.584 |   0.9956 |     30.043 |     0.7
   48 |   0.6716 |     22.160 |   1.0039 |     30.385 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 1,057,665

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2178 |     60.342 |   1.6304 |     47.734 |     0.0
    2 |   1.4738 |     45.581 |   1.3983 |     46.214 |     0.1
    3 |   1.3652 |     44.320 |   1.3472 |     45.158 |     0.1
    4 |   1.3131 |     43.019 |   1.3044 |     43.855 |     0.1
    5 |   1.2760 |     41.829 |   1.2826 |     43.358 |     0.2
    6 |   1.2357 |     40.694 |   1.2440 |     41.930 |     0.2
    7 |   1.2017 |     39.791 |   1.2238 |     41.248 |     0.2
    8 |   1.1593 |     38.314 |   1.1817 |     39.851 |     0.3
    9 |   1.1167 |     36.893 |   1.1417 |     38.610 |     0.3
   10 |   1.0798 |     35.504 |   1.1176 |     37.182 |     0.3
   11 |   1.0375 |     34.380 |   1.0803 |     35.940 |     0.4
   12 |   1.0088 |     33.344 |   1.0573 |     34.327 |     0.4
   13 |   0.9726 |     32.264 |   1.0541 |     34.327 |     0.4
   14 |   0.9358 |     31.091 |   1.0451 |     34.047 |     0.5
   15 |   0.9087 |     30.028 |   1.0407 |     34.016 |     0.5
   16 |   0.8735 |     28.871 |   1.0125 |     33.116 |     0.6
   17 |   0.8458 |     27.989 |   1.0102 |     32.682 |     0.6
   18 |   0.8215 |     27.333 |   0.9981 |     32.061 |     0.6
   19 |   0.7930 |     26.220 |   0.9791 |     31.657 |     0.7
   20 |   0.7541 |     24.898 |   0.9838 |     31.192 |     0.7
   21 |   0.7399 |     24.259 |   0.9725 |     31.782 |     0.7
   22 |   0.7152 |     23.769 |   0.9679 |     31.099 |     0.8
   23 |   0.6904 |     23.014 |   0.9598 |     30.447 |     0.8
   24 |   0.6635 |     22.033 |   0.9829 |     31.192 |     0.8
   25 |   0.6448 |     21.466 |   0.9673 |     30.074 |     0.9
   26 |   0.6245 |     20.545 |   0.9579 |     29.981 |     0.9
   27 |   0.6063 |     20.457 |   0.9606 |     29.702 |     0.9
   28 |   0.5828 |     19.455 |   0.9560 |     28.554 |     1.0
   29 |   0.5653 |     18.716 |   0.9617 |     29.733 |     1.0
   30 |   0.5421 |     18.011 |   0.9577 |     28.802 |     1.0
   31 |   0.5319 |     17.603 |   0.9524 |     29.019 |     1.1
   32 |   0.5172 |     17.278 |   0.9590 |     29.174 |     1.1
   33 |   0.5011 |     16.689 |   0.9729 |     28.833 |     1.1
   34 |   0.4763 |     15.862 |   0.9734 |     28.367 |     1.2
   35 |   0.4705 |     15.807 |   0.9631 |     28.430 |     1.2
   36 |   0.4496 |     14.826 |   0.9494 |     27.716 |     1.2
   37 |   0.4427 |     14.997 |   0.9717 |     28.243 |     1.3
   38 |   0.4393 |     14.606 |   0.9870 |     27.809 |     1.3
   39 |   0.4188 |     14.066 |   0.9689 |     27.561 |     1.4
   40 |   0.4121 |     13.763 |   0.9812 |     26.971 |     1.4
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 387,297

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3735 |     62.336 |   1.8206 |     49.597 |     0.0
    2 |   1.6083 |     46.744 |   1.4805 |     46.927 |     0.0
    3 |   1.4196 |     45.052 |   1.3867 |     45.965 |     0.1
    4 |   1.3440 |     44.050 |   1.3297 |     44.910 |     0.1
    5 |   1.2748 |     41.609 |   1.2604 |     41.837 |     0.1
    6 |   1.2212 |     39.983 |   1.2184 |     40.906 |     0.1
    7 |   1.1663 |     38.545 |   1.1806 |     40.379 |     0.1
    8 |   1.1184 |     36.854 |   1.1561 |     39.230 |     0.2
    9 |   1.0738 |     34.904 |   1.1080 |     36.499 |     0.2
   10 |   1.0280 |     33.003 |   1.0899 |     35.537 |     0.2
   11 |   0.9817 |     31.736 |   1.0501 |     34.637 |     0.2
   12 |   0.9341 |     29.686 |   1.0296 |     32.930 |     0.2
   13 |   0.8898 |     28.209 |   0.9914 |     31.130 |     0.3
   14 |   0.8539 |     26.694 |   0.9968 |     31.564 |     0.3
   15 |   0.8193 |     25.642 |   0.9640 |     30.447 |     0.3
   16 |   0.7811 |     24.061 |   0.9370 |     29.050 |     0.3
   17 |   0.7528 |     23.289 |   0.9562 |     29.981 |     0.4
   18 |   0.7042 |     21.851 |   0.9427 |     28.926 |     0.4
   19 |   0.6727 |     20.452 |   0.9347 |     29.050 |     0.4
   20 |   0.6412 |     19.791 |   0.9326 |     28.647 |     0.4
   21 |   0.6106 |     18.634 |   0.9306 |     29.268 |     0.4
   22 |   0.5873 |     17.967 |   0.9246 |     28.336 |     0.5
   23 |   0.5591 |     17.168 |   0.9243 |     27.809 |     0.5
   24 |   0.5368 |     16.176 |   0.9139 |     27.033 |     0.5
   25 |   0.5084 |     15.317 |   0.9164 |     26.878 |     0.5
   26 |   0.4946 |     14.860 |   0.9303 |     27.747 |     0.5
   27 |   0.4674 |     14.011 |   0.9222 |     27.095 |     0.6
   28 |   0.4464 |     13.251 |   0.9485 |     27.405 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 730,273

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3117 |     63.939 |   1.6797 |     49.441 |     0.0
    2 |   1.4993 |     46.099 |   1.4262 |     47.083 |     0.0
    3 |   1.4027 |     45.950 |   1.4031 |     47.083 |     0.1
    4 |   1.3792 |     45.741 |   1.3847 |     46.214 |     0.1
    5 |   1.3485 |     44.474 |   1.3437 |     45.313 |     0.1
    6 |   1.3212 |     43.868 |   1.3302 |     45.376 |     0.1
    7 |   1.2921 |     43.030 |   1.3086 |     45.065 |     0.1
    8 |   1.2748 |     42.452 |   1.2815 |     43.917 |     0.2
    9 |   1.2486 |     41.686 |   1.2600 |     43.203 |     0.2
   10 |   1.2343 |     41.427 |   1.2463 |     42.862 |     0.2
   11 |   1.2119 |     40.959 |   1.2145 |     42.055 |     0.2
   12 |   1.1804 |     39.895 |   1.2019 |     41.682 |     0.2
   13 |   1.1637 |     39.124 |   1.1945 |     41.248 |     0.3
   14 |   1.1398 |     38.661 |   1.1667 |     40.348 |     0.3
   15 |   1.1151 |     38.094 |   1.1597 |     39.417 |     0.3
   16 |   1.0905 |     37.361 |   1.1588 |     39.230 |     0.3
   17 |   1.0713 |     36.656 |   1.1306 |     38.051 |     0.3
   18 |   1.0436 |     35.466 |   1.1117 |     38.516 |     0.4
   19 |   1.0155 |     34.882 |   1.1018 |     37.151 |     0.4
   20 |   1.0048 |     34.468 |   1.0774 |     35.847 |     0.4
   21 |   0.9758 |     33.416 |   1.0656 |     35.444 |     0.4
   22 |   0.9546 |     32.474 |   1.0547 |     34.823 |     0.4
   23 |   0.9180 |     31.344 |   1.0456 |     34.482 |     0.4
   24 |   0.8970 |     30.452 |   1.0466 |     33.985 |     0.5
   25 |   0.8864 |     29.807 |   1.0520 |     34.171 |     0.5
   26 |   0.8623 |     29.300 |   1.0157 |     33.085 |     0.5
   27 |   0.8376 |     28.110 |   1.0181 |     33.489 |     0.5
   28 |   0.8126 |     27.289 |   1.0241 |     32.744 |     0.5
   29 |   0.7901 |     26.314 |   1.0280 |     32.868 |     0.6
   30 |   0.7659 |     25.295 |   1.0195 |     31.906 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 886,945

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2674 |     62.738 |   1.6465 |     49.441 |     0.0
    2 |   1.4881 |     46.127 |   1.4239 |     47.083 |     0.0
    3 |   1.3996 |     45.851 |   1.3987 |     47.114 |     0.1
    4 |   1.3671 |     45.614 |   1.3592 |     46.648 |     0.1
    5 |   1.3315 |     44.540 |   1.3295 |     45.500 |     0.1
    6 |   1.2968 |     43.444 |   1.2963 |     44.910 |     0.1
    7 |   1.2731 |     42.942 |   1.2669 |     43.700 |     0.2
    8 |   1.2484 |     42.441 |   1.2434 |     44.103 |     0.2
    9 |   1.2178 |     41.455 |   1.2224 |     41.868 |     0.2
   10 |   1.1914 |     40.204 |   1.2052 |     41.962 |     0.2
   11 |   1.1798 |     40.033 |   1.2004 |     40.441 |     0.3
   12 |   1.1482 |     38.733 |   1.1700 |     39.944 |     0.3
   13 |   1.1186 |     38.088 |   1.1433 |     39.696 |     0.3
   14 |   1.0886 |     36.815 |   1.1273 |     39.044 |     0.3
   15 |   1.0673 |     36.044 |   1.1011 |     38.020 |     0.4
   16 |   1.0432 |     35.372 |   1.0906 |     37.089 |     0.4
   17 |   1.0162 |     34.534 |   1.0801 |     36.840 |     0.4
   18 |   0.9948 |     33.642 |   1.0667 |     35.723 |     0.4
   19 |   0.9672 |     32.678 |   1.0481 |     35.382 |     0.4
   20 |   0.9400 |     31.471 |   1.0640 |     35.816 |     0.5
   21 |   0.9187 |     30.920 |   1.0421 |     34.699 |     0.5
   22 |   0.9005 |     30.380 |   1.0342 |     33.799 |     0.5
   23 |   0.8781 |     29.565 |   1.0240 |     33.395 |     0.5
   24 |   0.8494 |     28.766 |   1.0280 |     33.706 |     0.6
   25 |   0.8341 |     27.950 |   1.0107 |     33.116 |     0.6
   26 |   0.8080 |     27.140 |   1.0147 |     32.868 |     0.6
   27 |   0.7907 |     26.573 |   1.0091 |     31.968 |     0.6
   28 |   0.7760 |     26.083 |   1.0276 |     32.651 |     0.7
   29 |   0.7618 |     25.482 |   0.9850 |     30.850 |     0.7
   30 |   0.7243 |     24.325 |   0.9975 |     30.509 |     0.7
   31 |   0.7160 |     23.758 |   0.9866 |     30.695 |     0.7
   32 |   0.6960 |     23.273 |   0.9838 |     30.975 |     0.8
   33 |   0.6763 |     22.397 |   0.9858 |     30.168 |     0.8
   34 |   0.6558 |     21.752 |   0.9882 |     30.478 |     0.8
   35 |   0.6504 |     21.433 |   0.9818 |     29.516 |     0.8
   36 |   0.6357 |     21.074 |   0.9885 |     29.733 |     0.8
   37 |   0.6203 |     20.656 |   0.9892 |     30.043 |     0.9
   38 |   0.5908 |     19.449 |   1.0066 |     30.540 |     0.9
   39 |   0.5902 |     19.521 |   1.0034 |     29.236 |     0.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 416,449

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6267 |     70.523 |   2.0325 |     59.404 |     0.0
    2 |   1.8051 |     51.041 |   1.6244 |     49.441 |     0.0
    3 |   1.5259 |     46.342 |   1.4699 |     47.083 |     0.1
    4 |   1.4347 |     45.873 |   1.4313 |     47.083 |     0.1
    5 |   1.4094 |     45.846 |   1.4086 |     47.052 |     0.1
    6 |   1.3948 |     45.857 |   1.3951 |     47.083 |     0.1
    7 |   1.3809 |     45.851 |   1.3979 |     47.083 |     0.1
    8 |   1.3689 |     45.526 |   1.3749 |     46.151 |     0.2
    9 |   1.3479 |     44.518 |   1.3565 |     45.593 |     0.2
   10 |   1.3299 |     44.287 |   1.3371 |     45.438 |     0.2
   11 |   1.3111 |     44.143 |   1.3260 |     45.438 |     0.2
   12 |   1.2996 |     43.702 |   1.3070 |     45.096 |     0.2
   13 |   1.2837 |     43.300 |   1.3017 |     43.979 |     0.3
   14 |   1.2662 |     42.518 |   1.2837 |     43.886 |     0.3
   15 |   1.2467 |     41.934 |   1.2677 |     43.420 |     0.3
   16 |   1.2268 |     41.218 |   1.2584 |     43.358 |     0.3
   17 |   1.2120 |     40.738 |   1.2506 |     42.613 |     0.4
   18 |   1.1918 |     40.055 |   1.2279 |     41.558 |     0.4
   19 |   1.1741 |     39.427 |   1.2318 |     42.024 |     0.4
   20 |   1.1611 |     39.140 |   1.2111 |     40.813 |     0.4
   21 |   1.1447 |     38.650 |   1.1988 |     41.403 |     0.4
   22 |   1.1299 |     38.413 |   1.1922 |     40.968 |     0.5
   23 |   1.1048 |     37.267 |   1.1895 |     40.627 |     0.5
   24 |   1.0933 |     37.256 |   1.1729 |     39.603 |     0.5
   25 |   1.0841 |     36.810 |   1.1659 |     39.199 |     0.5
   26 |   1.0595 |     35.879 |   1.1555 |     39.448 |     0.5
   27 |   1.0460 |     35.554 |   1.1559 |     38.734 |     0.6
   28 |   1.0257 |     34.755 |   1.1493 |     38.734 |     0.6
   29 |   1.0111 |     34.264 |   1.1370 |     37.803 |     0.6
   30 |   0.9993 |     33.956 |   1.1402 |     38.858 |     0.6
   31 |   0.9800 |     33.344 |   1.1494 |     38.392 |     0.6
   32 |   0.9595 |     32.336 |   1.1386 |     38.641 |     0.7
   33 |   0.9446 |     31.818 |   1.1575 |     38.361 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.1
Trainable parameters: 947,937

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5018 |     66.689 |   1.9545 |     56.797 |     0.0
    2 |   1.7410 |     49.879 |   1.5667 |     47.083 |     0.1
    3 |   1.4930 |     45.857 |   1.4574 |     47.114 |     0.1
    4 |   1.4291 |     45.851 |   1.4272 |     47.083 |     0.1
    5 |   1.4073 |     45.807 |   1.4078 |     47.114 |     0.2
    6 |   1.3952 |     45.868 |   1.3959 |     47.083 |     0.2
    7 |   1.3805 |     45.835 |   1.3830 |     47.083 |     0.3
    8 |   1.3723 |     45.758 |   1.3756 |     47.083 |     0.3
    9 |   1.3578 |     45.444 |   1.3633 |     45.748 |     0.3
   10 |   1.3426 |     44.562 |   1.3447 |     45.810 |     0.4
   11 |   1.3292 |     44.231 |   1.3387 |     46.431 |     0.4
   12 |   1.3158 |     43.829 |   1.3208 |     44.972 |     0.4
   13 |   1.3038 |     43.758 |   1.3096 |     45.096 |     0.5
   14 |   1.2940 |     43.306 |   1.3075 |     45.158 |     0.5
   15 |   1.2779 |     42.617 |   1.3012 |     44.413 |     0.6
   16 |   1.2712 |     42.237 |   1.2906 |     44.103 |     0.6
   17 |   1.2598 |     41.785 |   1.2696 |     42.862 |     0.6
   18 |   1.2424 |     41.416 |   1.2640 |     42.955 |     0.7
   19 |   1.2306 |     40.964 |   1.2432 |     41.993 |     0.7
   20 |   1.2186 |     40.694 |   1.2305 |     42.086 |     0.7
   21 |   1.1983 |     40.044 |   1.2157 |     41.775 |     0.8
   22 |   1.1837 |     39.928 |   1.1959 |     41.061 |     0.8
   23 |   1.1687 |     39.179 |   1.1948 |     41.434 |     0.9
   24 |   1.1525 |     38.926 |   1.1731 |     40.192 |     0.9
   25 |   1.1442 |     38.810 |   1.1639 |     39.913 |     0.9
   26 |   1.1299 |     38.220 |   1.1688 |     40.410 |     1.0
   27 |   1.1129 |     37.967 |   1.1548 |     39.789 |     1.0
   28 |   1.1037 |     37.394 |   1.1544 |     40.130 |     1.0
   29 |   1.0838 |     36.694 |   1.1392 |     38.858 |     1.1
   30 |   1.0697 |     36.160 |   1.1284 |     38.175 |     1.1
   31 |   1.0650 |     36.242 |   1.1145 |     37.461 |     1.1
   32 |   1.0495 |     35.482 |   1.1103 |     37.058 |     1.2
   33 |   1.0245 |     34.545 |   1.1037 |     37.089 |     1.2
   34 |   1.0094 |     33.796 |   1.0871 |     35.754 |     1.3
   35 |   1.0051 |     33.642 |   1.0890 |     36.561 |     1.3
   36 |   0.9856 |     33.218 |   1.0666 |     35.351 |     1.3
   37 |   0.9755 |     32.689 |   1.0707 |     35.630 |     1.4
   38 |   0.9562 |     32.364 |   1.0679 |     35.785 |     1.4
   39 |   0.9443 |     31.956 |   1.0544 |     34.730 |     1.4
   40 |   0.9389 |     31.664 |   1.0567 |     34.885 |     1.5
   41 |   0.9199 |     30.843 |   1.0486 |     34.327 |     1.5
   42 |   0.9054 |     30.716 |   1.0455 |     34.451 |     1.6
   43 |   0.8973 |     30.110 |   1.0299 |     34.730 |     1.6
   44 |   0.8913 |     30.039 |   1.0513 |     34.854 |     1.6
   45 |   0.8707 |     28.909 |   1.0178 |     33.209 |     1.7
   46 |   0.8596 |     28.661 |   1.0234 |     33.830 |     1.7
   47 |   0.8442 |     28.215 |   1.0270 |     34.109 |     1.7
   48 |   0.8338 |     27.862 |   1.0232 |     33.457 |     1.8
   49 |   0.8205 |     27.477 |   1.0323 |     33.457 |     1.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.2
Trainable parameters: 2,010,593

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2080 |     60.105 |   1.6661 |     47.734 |     0.1
    2 |   1.5027 |     45.824 |   1.4144 |     46.586 |     0.1
    3 |   1.3738 |     44.171 |   1.3464 |     45.003 |     0.2
    4 |   1.3181 |     43.058 |   1.3077 |     44.134 |     0.2
    5 |   1.2776 |     41.901 |   1.2763 |     44.041 |     0.3
    6 |   1.2371 |     40.986 |   1.2376 |     42.675 |     0.4
    7 |   1.2019 |     39.840 |   1.2178 |     40.999 |     0.4
    8 |   1.1702 |     38.876 |   1.1782 |     40.006 |     0.5
    9 |   1.1363 |     37.592 |   1.1435 |     38.299 |     0.6
   10 |   1.1028 |     36.661 |   1.1360 |     37.834 |     0.6
   11 |   1.0701 |     35.697 |   1.1134 |     37.554 |     0.7
   12 |   1.0489 |     34.694 |   1.0771 |     35.630 |     0.7
   13 |   1.0126 |     33.675 |   1.0646 |     35.071 |     0.8
   14 |   0.9795 |     32.667 |   1.0572 |     34.854 |     0.9
   15 |   0.9588 |     31.741 |   1.0653 |     35.630 |     0.9
   16 |   0.9327 |     31.036 |   1.0490 |     35.071 |     1.0
   17 |   0.9202 |     30.760 |   1.0366 |     34.078 |     1.1
   18 |   0.8889 |     29.311 |   1.0299 |     33.737 |     1.1
   19 |   0.8611 |     28.700 |   0.9987 |     32.495 |     1.2
   20 |   0.8353 |     27.906 |   1.0242 |     33.768 |     1.2
   21 |   0.8251 |     27.675 |   1.0165 |     34.047 |     1.3
   22 |   0.7967 |     26.463 |   0.9840 |     31.875 |     1.4
   23 |   0.7704 |     25.410 |   0.9931 |     31.875 |     1.4
   24 |   0.7568 |     25.019 |   0.9856 |     32.433 |     1.5
   25 |   0.7356 |     24.678 |   0.9793 |     31.006 |     1.6
   26 |   0.7084 |     23.510 |   0.9832 |     31.595 |     1.6
   27 |   0.6870 |     22.672 |   0.9805 |     31.099 |     1.7
   28 |   0.6735 |     22.413 |   0.9565 |     29.733 |     1.7
   29 |   0.6493 |     21.928 |   0.9496 |     30.074 |     1.8
   30 |   0.6399 |     21.278 |   0.9688 |     29.950 |     1.9
   31 |   0.6195 |     20.882 |   0.9624 |     29.609 |     1.9
   32 |   0.6325 |     21.129 |   0.9727 |     30.540 |     2.0
   33 |   0.5980 |     20.050 |   0.9582 |     30.106 |     2.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 3
Dropout: 0.2
Trainable parameters: 363,073

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5582 |     67.554 |   1.9645 |     55.680 |     0.0
    2 |   1.7247 |     48.959 |   1.5478 |     47.114 |     0.0
    3 |   1.4799 |     45.873 |   1.4370 |     47.083 |     0.1
    4 |   1.4078 |     45.620 |   1.3878 |     46.493 |     0.1
    5 |   1.3723 |     45.273 |   1.3611 |     45.872 |     0.1
    6 |   1.3453 |     45.036 |   1.3378 |     45.593 |     0.1
    7 |   1.3199 |     44.253 |   1.3152 |     45.158 |     0.1
    8 |   1.3009 |     43.978 |   1.3119 |     44.724 |     0.1
    9 |   1.2808 |     43.355 |   1.2805 |     44.475 |     0.2
   10 |   1.2587 |     42.722 |   1.2707 |     44.010 |     0.2
   11 |   1.2390 |     42.121 |   1.2492 |     43.824 |     0.2
   12 |   1.2223 |     41.961 |   1.2301 |     43.141 |     0.2
   13 |   1.1916 |     40.771 |   1.2135 |     42.831 |     0.2
   14 |   1.1699 |     39.840 |   1.2036 |     40.689 |     0.3
   15 |   1.1520 |     39.074 |   1.1672 |     40.317 |     0.3
   16 |   1.1158 |     37.840 |   1.1626 |     38.951 |     0.3
   17 |   1.0933 |     37.168 |   1.1422 |     38.330 |     0.3
   18 |   1.0670 |     35.989 |   1.1180 |     38.392 |     0.3
   19 |   1.0428 |     35.080 |   1.1221 |     37.803 |     0.3
   20 |   1.0204 |     34.397 |   1.0998 |     36.840 |     0.4
   21 |   1.0006 |     33.526 |   1.0704 |     35.971 |     0.4
   22 |   0.9734 |     32.705 |   1.0575 |     34.978 |     0.4
   23 |   0.9569 |     32.215 |   1.0506 |     34.978 |     0.4
   24 |   0.9424 |     31.587 |   1.0445 |     34.513 |     0.4
   25 |   0.9174 |     30.490 |   1.0200 |     33.333 |     0.5
   26 |   0.8936 |     29.515 |   1.0291 |     33.551 |     0.5
   27 |   0.8759 |     29.218 |   1.0181 |     33.551 |     0.5
   28 |   0.8601 |     28.435 |   1.0060 |     32.837 |     0.5
   29 |   0.8487 |     28.099 |   1.0051 |     32.464 |     0.5
   30 |   0.8266 |     27.113 |   1.0067 |     31.813 |     0.5
   31 |   0.8189 |     26.893 |   0.9882 |     31.719 |     0.6
   32 |   0.7962 |     26.083 |   1.0023 |     31.657 |     0.6
   33 |   0.7837 |     25.785 |   1.0002 |     31.595 |     0.6
   34 |   0.7607 |     24.898 |   0.9816 |     30.975 |     0.6
   35 |   0.7574 |     24.788 |   0.9740 |     30.106 |     0.6
   36 |   0.7380 |     24.149 |   0.9574 |     29.764 |     0.7
   37 |   0.7330 |     24.182 |   0.9636 |     29.888 |     0.7
   38 |   0.7137 |     23.322 |   0.9690 |     30.168 |     0.7
   39 |   0.7065 |     23.179 |   0.9610 |     29.019 |     0.7
   40 |   0.6846 |     22.138 |   0.9622 |     29.268 |     0.7
   41 |   0.6842 |     22.402 |   0.9552 |     28.430 |     0.7
   42 |   0.6743 |     21.840 |   0.9760 |     28.988 |     0.8
   43 |   0.6614 |     21.262 |   0.9723 |     28.430 |     0.8
   44 |   0.6473 |     21.091 |   0.9750 |     29.050 |     0.8
   45 |   0.6346 |     20.540 |   0.9578 |     28.926 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 917,761

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5983 |     69.978 |   2.0361 |     59.404 |     0.0
    2 |   1.7860 |     51.003 |   1.5898 |     47.083 |     0.1
    3 |   1.5040 |     46.000 |   1.4585 |     47.083 |     0.1
    4 |   1.4309 |     45.813 |   1.4195 |     47.083 |     0.1
    5 |   1.4088 |     45.846 |   1.4066 |     47.083 |     0.2
    6 |   1.3979 |     45.906 |   1.4007 |     46.555 |     0.2
    7 |   1.3918 |     45.851 |   1.3962 |     47.114 |     0.2
    8 |   1.3821 |     45.868 |   1.3856 |     47.083 |     0.3
    9 |   1.3756 |     45.912 |   1.3790 |     47.083 |     0.3
   10 |   1.3678 |     45.824 |   1.3766 |     47.424 |     0.3
   11 |   1.3607 |     45.686 |   1.3706 |     47.455 |     0.4
   12 |   1.3520 |     45.477 |   1.3541 |     46.865 |     0.4
   13 |   1.3272 |     44.534 |   1.3197 |     45.282 |     0.4
   14 |   1.3031 |     43.846 |   1.2940 |     45.282 |     0.5
   15 |   1.2878 |     43.796 |   1.2876 |     45.065 |     0.5
   16 |   1.2732 |     43.339 |   1.2668 |     44.134 |     0.5
   17 |   1.2635 |     43.267 |   1.2620 |     43.979 |     0.6
   18 |   1.2639 |     42.942 |   1.2540 |     44.444 |     0.6
   19 |   1.2473 |     42.612 |   1.2591 |     44.165 |     0.6
   20 |   1.2349 |     42.204 |   1.2294 |     43.265 |     0.7
   21 |   1.2179 |     41.614 |   1.2292 |     44.103 |     0.7
   22 |   1.2164 |     41.449 |   1.2084 |     42.768 |     0.7
   23 |   1.2072 |     41.482 |   1.2111 |     42.924 |     0.8
   24 |   1.1930 |     41.245 |   1.2127 |     42.831 |     0.8
   25 |   1.1864 |     40.617 |   1.1812 |     41.372 |     0.9
   26 |   1.1753 |     40.391 |   1.1813 |     41.279 |     0.9
   27 |   1.1645 |     40.072 |   1.1671 |     40.751 |     0.9
   28 |   1.1574 |     39.763 |   1.1583 |     40.751 |     1.0
   29 |   1.1457 |     39.477 |   1.1547 |     39.727 |     1.0
   30 |   1.1348 |     38.931 |   1.1475 |     39.882 |     1.0
   31 |   1.1311 |     38.639 |   1.1343 |     39.448 |     1.1
   32 |   1.1239 |     38.534 |   1.1471 |     40.099 |     1.1
   33 |   1.1178 |     38.446 |   1.1292 |     39.292 |     1.1
   34 |   1.1048 |     37.928 |   1.1316 |     39.199 |     1.2
   35 |   1.1011 |     37.934 |   1.1284 |     38.703 |     1.2
   36 |   1.0870 |     37.102 |   1.1187 |     38.206 |     1.2
   37 |   1.0787 |     36.567 |   1.1165 |     37.958 |     1.3
   38 |   1.0711 |     36.733 |   1.1054 |     38.454 |     1.3
   39 |   1.0562 |     35.675 |   1.1158 |     37.772 |     1.3
   40 |   1.0611 |     35.928 |   1.0903 |     37.182 |     1.4
   41 |   1.0440 |     35.410 |   1.0942 |     37.647 |     1.4
   42 |   1.0424 |     35.372 |   1.0930 |     37.523 |     1.4
   43 |   1.0366 |     35.295 |   1.0881 |     36.468 |     1.5
   44 |   1.0342 |     34.915 |   1.0930 |     37.585 |     1.5
   45 |   1.0252 |     34.788 |   1.0755 |     36.096 |     1.5
   46 |   1.0110 |     33.879 |   1.0854 |     36.375 |     1.6
   47 |   0.9982 |     33.570 |   1.0577 |     35.351 |     1.6
   48 |   1.0034 |     33.846 |   1.0658 |     35.196 |     1.6
   49 |   0.9814 |     33.521 |   1.0679 |     36.313 |     1.7
   50 |   0.9722 |     32.975 |   1.0547 |     35.413 |     1.7
   51 |   0.9578 |     32.435 |   1.0429 |     34.575 |     1.7
   52 |   0.9531 |     32.028 |   1.0560 |     35.537 |     1.8
   53 |   0.9578 |     32.000 |   1.0608 |     36.127 |     1.8
   54 |   0.9472 |     31.906 |   1.0507 |     35.164 |     1.8
   55 |   0.9405 |     31.620 |   1.0468 |     34.233 |     1.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 834,625

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3000 |     62.397 |   1.6764 |     49.441 |     0.0
    2 |   1.5056 |     46.397 |   1.4366 |     47.083 |     0.0
    3 |   1.4040 |     45.917 |   1.4010 |     47.083 |     0.1
    4 |   1.3827 |     45.884 |   1.3825 |     46.338 |     0.1
    5 |   1.3501 |     44.909 |   1.3423 |     45.003 |     0.1
    6 |   1.3167 |     43.857 |   1.2996 |     44.413 |     0.1
    7 |   1.2792 |     42.959 |   1.2762 |     44.196 |     0.2
    8 |   1.2390 |     41.592 |   1.2278 |     42.458 |     0.2
    9 |   1.2100 |     40.645 |   1.2067 |     41.341 |     0.2
   10 |   1.1881 |     39.791 |   1.1994 |     41.527 |     0.2
   11 |   1.1592 |     38.915 |   1.1784 |     40.813 |     0.3
   12 |   1.1375 |     38.645 |   1.1568 |     40.720 |     0.3
   13 |   1.1090 |     37.559 |   1.1506 |     40.348 |     0.3
   14 |   1.0914 |     36.986 |   1.1265 |     38.920 |     0.3
   15 |   1.0680 |     36.463 |   1.1161 |     39.106 |     0.4
   16 |   1.0484 |     36.017 |   1.1041 |     37.616 |     0.4
   17 |   1.0191 |     34.567 |   1.0875 |     37.182 |     0.4
   18 |   1.0018 |     33.824 |   1.0895 |     37.709 |     0.4
   19 |   0.9847 |     33.289 |   1.0863 |     37.089 |     0.4
   20 |   0.9559 |     32.650 |   1.0809 |     36.313 |     0.5
   21 |   0.9335 |     31.824 |   1.0734 |     35.723 |     0.5
   22 |   0.9137 |     31.025 |   1.0691 |     35.196 |     0.5
   23 |   0.8952 |     30.424 |   1.0466 |     35.289 |     0.5
   24 |   0.8727 |     29.152 |   1.0512 |     34.606 |     0.6
   25 |   0.8483 |     28.408 |   1.0343 |     33.892 |     0.6
   26 |   0.8362 |     28.463 |   1.0171 |     33.582 |     0.6
   27 |   0.8138 |     27.570 |   1.0306 |     33.551 |     0.6
   28 |   0.7878 |     26.386 |   1.0028 |     32.651 |     0.7
   29 |   0.7700 |     25.879 |   1.0184 |     32.992 |     0.7
   30 |   0.7593 |     25.284 |   1.0132 |     31.844 |     0.7
   31 |   0.7338 |     24.567 |   1.0061 |     32.216 |     0.7
   32 |   0.7087 |     23.620 |   1.0241 |     31.626 |     0.8
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 2,257,345

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2680 |     62.253 |   1.6698 |     49.441 |     0.1
    2 |   1.5020 |     46.050 |   1.4281 |     47.083 |     0.1
    3 |   1.4114 |     45.967 |   1.4063 |     47.083 |     0.2
    4 |   1.3958 |     45.840 |   1.3993 |     47.083 |     0.2
    5 |   1.3885 |     45.934 |   1.3972 |     47.083 |     0.3
    6 |   1.3784 |     45.895 |   1.3876 |     47.176 |     0.4
    7 |   1.3649 |     45.025 |   1.3672 |     45.779 |     0.4
    8 |   1.3440 |     44.457 |   1.3427 |     44.755 |     0.5
    9 |   1.3274 |     44.061 |   1.3307 |     45.469 |     0.6
   10 |   1.3158 |     43.702 |   1.3234 |     45.158 |     0.6
   11 |   1.3077 |     43.725 |   1.3135 |     44.755 |     0.7
   12 |   1.2928 |     42.931 |   1.2999 |     44.444 |     0.8
   13 |   1.2863 |     42.700 |   1.2937 |     45.034 |     0.8
   14 |   1.2768 |     42.727 |   1.2987 |     44.538 |     0.9
   15 |   1.2711 |     42.606 |   1.2869 |     44.134 |     0.9
   16 |   1.2640 |     42.248 |   1.2810 |     43.917 |     1.0
   17 |   1.2536 |     42.105 |   1.2774 |     43.762 |     1.1
   18 |   1.2477 |     42.138 |   1.2864 |     44.103 |     1.1
   19 |   1.2474 |     42.017 |   1.2685 |     43.948 |     1.2
   20 |   1.2369 |     41.862 |   1.2593 |     43.296 |     1.3
   21 |   1.2276 |     41.686 |   1.2488 |     42.706 |     1.3
   22 |   1.2215 |     41.410 |   1.2602 |     43.172 |     1.4
   23 |   1.2091 |     40.920 |   1.2506 |     42.241 |     1.4
   24 |   1.2058 |     41.036 |   1.2502 |     42.582 |     1.5
   25 |   1.1960 |     40.788 |   1.2307 |     42.086 |     1.6
   26 |   1.1930 |     40.545 |   1.2353 |     42.210 |     1.6
   27 |   1.1812 |     40.072 |   1.2230 |     41.186 |     1.7
   28 |   1.1746 |     39.658 |   1.2094 |     41.092 |     1.8
   29 |   1.1713 |     39.846 |   1.2027 |     41.124 |     1.8
   30 |   1.1559 |     39.008 |   1.1993 |     40.782 |     1.9
   31 |   1.1460 |     39.107 |   1.2023 |     40.782 |     2.0
   32 |   1.1355 |     38.661 |   1.1799 |     40.472 |     2.0
   33 |   1.1256 |     38.656 |   1.1851 |     39.944 |     2.1
   34 |   1.1208 |     37.890 |   1.1874 |     40.410 |     2.1
   35 |   1.1064 |     37.873 |   1.1720 |     39.727 |     2.2
   36 |   1.0921 |     37.339 |   1.1763 |     39.944 |     2.3
   37 |   1.0900 |     37.080 |   1.1894 |     39.975 |     2.3
   38 |   1.0868 |     37.229 |   1.1704 |     39.417 |     2.4
   39 |   1.0751 |     36.683 |   1.1884 |     40.037 |     2.5
   40 |   1.0798 |     36.804 |   1.1698 |     39.354 |     2.5
   41 |   1.0643 |     36.287 |   1.1657 |     39.541 |     2.6
   42 |   1.0472 |     35.994 |   1.1566 |     38.330 |     2.7
   43 |   1.0375 |     35.625 |   1.1454 |     38.237 |     2.7
   44 |   1.0332 |     35.455 |   1.1449 |     38.485 |     2.8
   45 |   1.0240 |     35.267 |   1.1475 |     38.547 |     2.8
   46 |   1.0116 |     35.008 |   1.1445 |     38.268 |     2.9
   47 |   1.0034 |     34.242 |   1.1682 |     38.268 |     3.0
   48 |   0.9913 |     34.248 |   1.1537 |     37.989 |     3.0
   49 |   0.9778 |     33.322 |   1.1479 |     37.834 |     3.1
   50 |   0.9730 |     33.306 |   1.1328 |     37.213 |     3.2
   51 |   0.9770 |     33.736 |   1.1286 |     37.523 |     3.2
   52 |   0.9543 |     32.419 |   1.1210 |     37.182 |     3.3
   53 |   0.9327 |     31.675 |   1.1245 |     36.096 |     3.4
   54 |   0.9360 |     31.912 |   1.1363 |     37.337 |     3.4
   55 |   0.9295 |     31.686 |   1.1310 |     36.934 |     3.5
   56 |   0.9193 |     31.576 |   1.1274 |     36.344 |     3.5
   57 |   0.9017 |     30.893 |   1.1173 |     35.816 |     3.6
   58 |   0.8916 |     30.496 |   1.0997 |     35.382 |     3.7
   59 |   0.8819 |     30.110 |   1.1192 |     36.778 |     3.7
   60 |   0.8658 |     29.377 |   1.1264 |     35.692 |     3.8
   61 |   0.8703 |     29.581 |   1.1148 |     35.940 |     3.9
   62 |   0.8476 |     29.135 |   1.1332 |     35.537 |     3.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 64
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 1,109,985

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.0852 |     56.733 |   1.5040 |     46.958 |     0.0
    2 |   1.3938 |     44.590 |   1.3289 |     44.320 |     0.1
    3 |   1.2954 |     42.369 |   1.2620 |     42.613 |     0.1
    4 |   1.2187 |     40.298 |   1.1957 |     40.689 |     0.1
    5 |   1.1620 |     38.419 |   1.1385 |     37.958 |     0.2
    6 |   1.0891 |     36.033 |   1.0976 |     36.406 |     0.2
    7 |   1.0224 |     33.466 |   1.0627 |     35.816 |     0.2
    8 |   0.9685 |     31.669 |   1.0086 |     33.520 |     0.3
    9 |   0.9042 |     29.614 |   0.9750 |     32.495 |     0.3
   10 |   0.8517 |     28.143 |   0.9567 |     31.844 |     0.4
   11 |   0.7941 |     25.708 |   0.9210 |     29.516 |     0.4
   12 |   0.7393 |     23.884 |   0.9032 |     29.330 |     0.4
   13 |   0.6989 |     22.661 |   0.9018 |     28.554 |     0.5
   14 |   0.6530 |     21.025 |   0.8767 |     27.126 |     0.5
   15 |   0.6180 |     19.647 |   0.8596 |     26.195 |     0.5
   16 |   0.5883 |     18.837 |   0.8677 |     26.785 |     0.6
   17 |   0.5512 |     17.736 |   0.8779 |     26.847 |     0.6
   18 |   0.5130 |     16.264 |   0.8866 |     27.312 |     0.6
   19 |   0.4760 |     15.284 |   0.8669 |     26.350 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.2
Trainable parameters: 666,625

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 0.0001
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.3097 |     62.435 |   1.6991 |     49.441 |     0.0
    2 |   1.5135 |     46.490 |   1.4344 |     47.083 |     0.0
    3 |   1.4077 |     45.895 |   1.4028 |     47.083 |     0.1
    4 |   1.3851 |     45.862 |   1.3937 |     47.083 |     0.1
    5 |   1.3668 |     45.515 |   1.3571 |     45.003 |     0.1
    6 |   1.3214 |     43.300 |   1.3099 |     44.041 |     0.1
    7 |   1.2847 |     42.700 |   1.2720 |     43.203 |     0.1
    8 |   1.2499 |     41.879 |   1.2496 |     43.017 |     0.1
    9 |   1.2168 |     40.804 |   1.2179 |     42.396 |     0.1
   10 |   1.1861 |     40.160 |   1.2040 |     41.775 |     0.2
   11 |   1.1588 |     38.909 |   1.1844 |     40.844 |     0.2
   12 |   1.1346 |     38.039 |   1.1621 |     40.130 |     0.2
   13 |   1.1087 |     37.157 |   1.1380 |     39.013 |     0.2
   14 |   1.0898 |     36.948 |   1.1391 |     38.547 |     0.2
   15 |   1.0747 |     36.292 |   1.1022 |     37.958 |     0.2
   16 |   1.0489 |     35.669 |   1.1221 |     38.672 |     0.2
   17 |   1.0231 |     34.882 |   1.1174 |     37.709 |     0.3
   18 |   1.0098 |     34.452 |   1.1028 |     37.461 |     0.3
   19 |   0.9863 |     33.592 |   1.0838 |     36.282 |     0.3
   20 |   0.9741 |     33.179 |   1.0784 |     36.034 |     0.3
   21 |   0.9443 |     31.939 |   1.0752 |     35.630 |     0.3
   22 |   0.9281 |     31.361 |   1.0792 |     36.282 |     0.3
   23 |   0.9091 |     30.826 |   1.0604 |     34.233 |     0.4
   24 |   0.8889 |     30.198 |   1.0519 |     33.923 |     0.4
   25 |   0.8669 |     28.948 |   1.0280 |     33.178 |     0.4
   26 |   0.8422 |     28.441 |   1.0262 |     33.209 |     0.4
   27 |   0.8234 |     27.697 |   1.0290 |     32.495 |     0.4
   28 |   0.8084 |     26.848 |   1.0349 |     32.806 |     0.4
   29 |   0.7943 |     26.397 |   1.0174 |     32.744 |     0.4
   30 |   0.7803 |     26.446 |   1.0214 |     31.285 |     0.5
   31 |   0.7543 |     25.014 |   1.0130 |     31.968 |     0.5
   32 |   0.7374 |     24.463 |   1.0290 |     31.564 |     0.5
   33 |   0.7304 |     24.303 |   0.9965 |     30.447 |     0.5
   34 |   0.7013 |     23.102 |   1.0100 |     30.788 |     0.5
   35 |   0.6725 |     22.193 |   1.0172 |     30.850 |     0.5
   36 |   0.6686 |     22.121 |   1.0292 |     30.571 |     0.6
   37 |   0.6407 |     21.179 |   1.0365 |     30.354 |     0.6
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 64
Encoder layers: 3
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 692,001

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5785 |     69.063 |   2.0389 |     59.342 |     0.0
    2 |   1.8094 |     51.278 |   1.6188 |     47.207 |     0.1
    3 |   1.5253 |     45.840 |   1.4694 |     47.083 |     0.1
    4 |   1.4403 |     45.961 |   1.4268 |     47.083 |     0.1
    5 |   1.4121 |     45.796 |   1.4118 |     47.083 |     0.1
    6 |   1.4027 |     45.989 |   1.4063 |     47.083 |     0.2
    7 |   1.3935 |     46.000 |   1.4004 |     47.083 |     0.2
    8 |   1.3883 |     45.840 |   1.3965 |     47.083 |     0.2
    9 |   1.3861 |     45.851 |   1.3891 |     47.083 |     0.2
   10 |   1.3781 |     45.311 |   1.3801 |     46.245 |     0.3
   11 |   1.3628 |     44.755 |   1.3585 |     45.624 |     0.3
   12 |   1.3490 |     44.617 |   1.3507 |     45.469 |     0.3
   13 |   1.3374 |     44.479 |   1.3363 |     45.282 |     0.3
   14 |   1.3312 |     44.259 |   1.3325 |     45.469 |     0.4
   15 |   1.3269 |     44.176 |   1.3358 |     46.369 |     0.4
   16 |   1.3192 |     44.083 |   1.3270 |     44.972 |     0.4
   17 |   1.3141 |     43.884 |   1.3158 |     44.724 |     0.4
   18 |   1.3048 |     43.829 |   1.3154 |     45.624 |     0.5
   19 |   1.3004 |     43.455 |   1.3132 |     44.817 |     0.5
   20 |   1.2904 |     43.256 |   1.3043 |     45.003 |     0.5
   21 |   1.2797 |     42.760 |   1.2907 |     44.413 |     0.6
   22 |   1.2731 |     42.512 |   1.2914 |     44.382 |     0.6
   23 |   1.2652 |     42.435 |   1.2864 |     44.041 |     0.6
   24 |   1.2598 |     42.325 |   1.2817 |     43.793 |     0.6
   25 |   1.2531 |     42.028 |   1.2731 |     43.389 |     0.7
   26 |   1.2462 |     41.829 |   1.2697 |     43.358 |     0.7
   27 |   1.2368 |     41.592 |   1.2608 |     43.110 |     0.7
   28 |   1.2285 |     41.201 |   1.2561 |     42.737 |     0.7
   29 |   1.2198 |     40.893 |   1.2535 |     42.551 |     0.8
   30 |   1.2129 |     40.804 |   1.2439 |     42.644 |     0.8
   31 |   1.2052 |     40.683 |   1.2450 |     42.582 |     0.8
   32 |   1.1973 |     40.325 |   1.2466 |     42.396 |     0.8
   33 |   1.1886 |     39.950 |   1.2347 |     42.365 |     0.9
   34 |   1.1780 |     39.857 |   1.2283 |     41.589 |     0.9
   35 |   1.1707 |     39.824 |   1.2299 |     41.496 |     0.9
   36 |   1.1679 |     39.471 |   1.2241 |     41.744 |     1.0
   37 |   1.1616 |     39.289 |   1.2297 |     41.124 |     1.0
   38 |   1.1531 |     38.986 |   1.2113 |     40.658 |     1.0
   39 |   1.1364 |     38.171 |   1.2066 |     41.030 |     1.0
   40 |   1.1345 |     38.540 |   1.2125 |     40.968 |     1.1
   41 |   1.1164 |     37.857 |   1.2016 |     40.534 |     1.1
   42 |   1.1144 |     37.631 |   1.1847 |     39.975 |     1.1
   43 |   1.1069 |     37.471 |   1.1956 |     40.037 |     1.1
   44 |   1.0867 |     36.683 |   1.1789 |     39.572 |     1.2
   45 |   1.0880 |     36.694 |   1.1883 |     39.168 |     1.2
   46 |   1.0732 |     36.116 |   1.1718 |     38.423 |     1.2
   47 |   1.0660 |     36.198 |   1.1725 |     39.075 |     1.2
   48 |   1.0578 |     36.022 |   1.1730 |     39.230 |     1.3
   49 |   1.0438 |     35.372 |   1.1608 |     37.927 |     1.3
   50 |   1.0326 |     34.882 |   1.1635 |     38.765 |     1.3
   51 |   1.0276 |     34.661 |   1.1700 |     38.703 |     1.4
   52 |   1.0170 |     34.231 |   1.1470 |     37.927 |     1.4
   53 |   1.0048 |     33.763 |   1.1545 |     38.516 |     1.4
   54 |   0.9990 |     33.642 |   1.1469 |     38.330 |     1.4
   55 |   0.9880 |     33.295 |   1.1545 |     38.113 |     1.5
   56 |   0.9827 |     33.262 |   1.1354 |     37.213 |     1.5
   57 |   0.9729 |     32.760 |   1.1266 |     36.872 |     1.5
   58 |   0.9639 |     32.463 |   1.1328 |     37.182 |     1.5
   59 |   0.9450 |     31.598 |   1.1230 |     36.282 |     1.6
   60 |   0.9434 |     31.647 |   1.1454 |     37.989 |     1.6
   61 |   0.9307 |     31.273 |   1.1443 |     37.027 |     1.6
   62 |   0.9276 |     31.118 |   1.1352 |     37.368 |     1.6
   63 |   0.9077 |     30.253 |   1.1304 |     36.251 |     1.7
   64 |   0.8990 |     30.099 |   1.1201 |     36.406 |     1.7
   65 |   0.8902 |     29.967 |   1.1478 |     37.151 |     1.7
   66 |   0.8913 |     29.774 |   1.1368 |     36.840 |     1.8
   67 |   0.8871 |     29.477 |   1.1453 |     36.654 |     1.8
   68 |   0.8741 |     29.069 |   1.1477 |     36.840 |     1.8
   69 |   0.8651 |     28.860 |   1.1135 |     35.258 |     1.8
   70 |   0.8535 |     28.540 |   1.1153 |     36.127 |     1.9
   71 |   0.8361 |     27.917 |   1.1346 |     35.413 |     1.9
   72 |   0.8303 |     27.747 |   1.1375 |     36.530 |     1.9
   73 |   0.8290 |     27.747 |   1.1384 |     35.816 |     1.9
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 416,449

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.6169 |     71.174 |   2.0626 |     59.404 |     0.0
    2 |   1.8039 |     50.391 |   1.6117 |     47.145 |     0.0
    3 |   1.5170 |     45.884 |   1.4657 |     47.083 |     0.1
    4 |   1.4380 |     45.912 |   1.4259 |     47.083 |     0.1
    5 |   1.4105 |     45.846 |   1.4111 |     47.083 |     0.1
    6 |   1.3973 |     45.884 |   1.4006 |     47.114 |     0.1
    7 |   1.3852 |     45.840 |   1.3872 |     47.052 |     0.2
    8 |   1.3701 |     45.405 |   1.3725 |     45.934 |     0.2
    9 |   1.3485 |     44.441 |   1.3579 |     45.655 |     0.2
   10 |   1.3282 |     43.807 |   1.3273 |     44.662 |     0.2
   11 |   1.3039 |     43.532 |   1.3267 |     44.879 |     0.2
   12 |   1.2873 |     42.749 |   1.3121 |     44.072 |     0.3
   13 |   1.2682 |     42.171 |   1.2999 |     44.258 |     0.3
   14 |   1.2545 |     41.636 |   1.2888 |     43.979 |     0.3
   15 |   1.2386 |     41.317 |   1.2672 |     43.358 |     0.3
   16 |   1.2223 |     40.860 |   1.2710 |     44.786 |     0.3
   17 |   1.2085 |     40.468 |   1.2416 |     42.086 |     0.4
   18 |   1.1933 |     40.094 |   1.2386 |     42.458 |     0.4
   19 |   1.1741 |     39.609 |   1.2306 |     41.930 |     0.4
   20 |   1.1559 |     39.074 |   1.2193 |     41.651 |     0.4
   21 |   1.1388 |     38.424 |   1.2060 |     41.030 |     0.4
   22 |   1.1226 |     37.708 |   1.1909 |     40.813 |     0.5
   23 |   1.1019 |     36.716 |   1.1790 |     39.572 |     0.5
   24 |   1.0872 |     36.468 |   1.1736 |     39.696 |     0.5
   25 |   1.0693 |     35.928 |   1.1821 |     39.913 |     0.5
   26 |   1.0617 |     35.609 |   1.1639 |     39.261 |     0.6
   27 |   1.0402 |     35.300 |   1.1506 |     38.641 |     0.6
   28 |   1.0221 |     34.540 |   1.1407 |     37.958 |     0.6
   29 |   0.9985 |     33.631 |   1.1411 |     37.089 |     0.6
   30 |   0.9797 |     32.623 |   1.1557 |     37.461 |     0.6
   31 |   0.9657 |     32.490 |   1.1364 |     37.213 |     0.7
   32 |   0.9381 |     31.190 |   1.1209 |     36.592 |     0.7
   33 |   0.9209 |     30.722 |   1.1119 |     36.561 |     0.7
   34 |   0.9033 |     29.829 |   1.1271 |     36.002 |     0.7
   35 |   0.8875 |     29.240 |   1.1225 |     35.971 |     0.7
   36 |   0.8731 |     28.424 |   1.1120 |     35.102 |     0.8
   37 |   0.8542 |     28.501 |   1.0988 |     34.637 |     0.8
   38 |   0.8453 |     27.989 |   1.1126 |     35.289 |     0.8
   39 |   0.8265 |     27.394 |   1.1054 |     34.792 |     0.8
   40 |   0.8093 |     26.793 |   1.0949 |     34.171 |     0.8
   41 |   0.7911 |     26.017 |   1.1075 |     34.295 |     0.9
   42 |   0.7822 |     25.510 |   1.1043 |     33.364 |     0.9
   43 |   0.7736 |     25.102 |   1.0945 |     33.489 |     0.9
   44 |   0.7416 |     24.094 |   1.0997 |     33.520 |     0.9
   45 |   0.7440 |     24.149 |   1.0967 |     33.333 |     0.9
   46 |   0.7268 |     23.377 |   1.0989 |     32.744 |     1.0
   47 |   0.7094 |     23.003 |   1.1233 |     33.582 |     1.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 128
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 4
Dropout: 0.1
Trainable parameters: 867,617

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.2822 |     63.190 |   1.6770 |     49.752 |     0.0
    2 |   1.4991 |     46.209 |   1.4271 |     47.083 |     0.0
    3 |   1.4030 |     45.873 |   1.3995 |     47.083 |     0.1
    4 |   1.3681 |     45.455 |   1.3525 |     45.965 |     0.1
    5 |   1.3269 |     43.934 |   1.3277 |     45.065 |     0.1
    6 |   1.2951 |     43.201 |   1.2884 |     44.600 |     0.1
    7 |   1.2656 |     42.590 |   1.2685 |     44.258 |     0.2
    8 |   1.2370 |     41.399 |   1.2400 |     42.117 |     0.2
    9 |   1.2106 |     40.529 |   1.2108 |     41.806 |     0.2
   10 |   1.1826 |     39.642 |   1.2084 |     41.341 |     0.2
   11 |   1.1580 |     39.185 |   1.1763 |     39.789 |     0.3
   12 |   1.1353 |     38.523 |   1.1691 |     40.130 |     0.3
   13 |   1.1131 |     37.691 |   1.1496 |     39.448 |     0.3
   14 |   1.0861 |     37.129 |   1.1264 |     38.237 |     0.3
   15 |   1.0628 |     36.512 |   1.1183 |     37.989 |     0.4
   16 |   1.0326 |     35.339 |   1.0989 |     36.778 |     0.4
   17 |   1.0096 |     34.545 |   1.0885 |     36.965 |     0.4
   18 |   0.9801 |     33.036 |   1.0715 |     36.282 |     0.4
   19 |   0.9561 |     32.490 |   1.0612 |     35.785 |     0.5
   20 |   0.9231 |     31.096 |   1.0616 |     34.947 |     0.5
   21 |   0.8945 |     29.824 |   1.0600 |     34.637 |     0.5
   22 |   0.8704 |     29.587 |   1.0576 |     34.202 |     0.5
   23 |   0.8465 |     28.562 |   1.0295 |     33.457 |     0.5
   24 |   0.8204 |     27.752 |   1.0289 |     33.240 |     0.6
   25 |   0.7954 |     27.003 |   1.0223 |     33.054 |     0.6
   26 |   0.7674 |     25.939 |   1.0273 |     31.999 |     0.6
   27 |   0.7438 |     25.085 |   1.0094 |     31.533 |     0.6
   28 |   0.7161 |     24.143 |   1.0302 |     32.371 |     0.7
   29 |   0.6969 |     23.361 |   1.0140 |     30.975 |     0.7
   30 |   0.6749 |     22.645 |   1.0268 |     31.502 |     0.7
   31 |   0.6541 |     21.934 |   1.0240 |     31.316 |     0.7
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 128
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 4
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.1
Trainable parameters: 587,873

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1715 |     58.981 |   1.5547 |     46.865 |     0.0
    2 |   1.4139 |     44.287 |   1.3312 |     43.979 |     0.0
    3 |   1.2836 |     41.719 |   1.2491 |     41.962 |     0.1
    4 |   1.2061 |     39.581 |   1.1791 |     39.385 |     0.1
    5 |   1.1389 |     37.444 |   1.1294 |     37.554 |     0.1
    6 |   1.0813 |     35.631 |   1.0838 |     36.127 |     0.1
    7 |   1.0169 |     33.581 |   1.0505 |     34.699 |     0.2
    8 |   0.9512 |     30.981 |   0.9940 |     32.061 |     0.2
    9 |   0.8854 |     28.804 |   0.9718 |     31.564 |     0.2
   10 |   0.8319 |     26.815 |   0.9179 |     29.857 |     0.2
   11 |   0.7776 |     24.667 |   0.8971 |     28.492 |     0.3
   12 |   0.7225 |     22.848 |   0.8884 |     28.523 |     0.3
   13 |   0.6820 |     21.725 |   0.8669 |     27.281 |     0.3
   14 |   0.6246 |     19.713 |   0.8518 |     26.691 |     0.3
   15 |   0.5907 |     18.518 |   0.8557 |     26.226 |     0.4
   16 |   0.5412 |     17.041 |   0.8366 |     25.698 |     0.4
   17 |   0.5072 |     15.802 |   0.8266 |     25.357 |     0.4
   18 |   0.4626 |     14.512 |   0.8487 |     25.388 |     0.4
   19 |   0.4383 |     13.857 |   0.8352 |     24.798 |     0.4
   20 |   0.4116 |     13.036 |   0.8485 |     24.457 |     0.5
   21 |   0.3866 |     12.083 |   0.8655 |     26.133 |     0.5
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 3
Decoder hidden units: 128
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 1,958,913

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.1858 |     59.581 |   1.6463 |     47.083 |     0.1
    2 |   1.4818 |     45.846 |   1.4207 |     47.083 |     0.1
    3 |   1.3866 |     45.339 |   1.3798 |     45.996 |     0.2
    4 |   1.3474 |     44.287 |   1.3443 |     46.027 |     0.2
    5 |   1.3162 |     43.680 |   1.3237 |     44.662 |     0.3
    6 |   1.2868 |     42.700 |   1.2930 |     43.855 |     0.3
    7 |   1.2596 |     41.449 |   1.2698 |     42.520 |     0.4
    8 |   1.2349 |     40.799 |   1.2541 |     42.334 |     0.5
    9 |   1.2070 |     39.994 |   1.2393 |     41.775 |     0.5
   10 |   1.1740 |     39.355 |   1.2155 |     40.565 |     0.6
   11 |   1.1492 |     38.204 |   1.1995 |     40.844 |     0.6
   12 |   1.1299 |     37.824 |   1.1806 |     39.385 |     0.7
   13 |   1.1057 |     37.240 |   1.1710 |     39.106 |     0.8
   14 |   1.0778 |     36.253 |   1.1546 |     38.703 |     0.8
   15 |   1.0529 |     35.361 |   1.1257 |     37.741 |     0.9
   16 |   1.0282 |     34.309 |   1.1117 |     37.523 |     0.9
   17 |   1.0124 |     33.934 |   1.1308 |     37.182 |     1.0
   18 |   0.9945 |     33.240 |   1.1053 |     36.592 |     1.1
   19 |   0.9671 |     32.237 |   1.1081 |     37.151 |     1.1
   20 |   0.9513 |     31.653 |   1.0970 |     36.344 |     1.2
   21 |   0.9281 |     30.678 |   1.0894 |     35.754 |     1.2
   22 |   0.9084 |     30.518 |   1.0714 |     34.823 |     1.3
   23 |   0.8738 |     29.344 |   1.0614 |     33.923 |     1.3
   24 |   0.8560 |     28.711 |   1.0615 |     35.071 |     1.4
   25 |   0.8384 |     28.182 |   1.0606 |     33.582 |     1.5
   26 |   0.8128 |     27.245 |   1.0528 |     33.582 |     1.5
   27 |   0.7896 |     26.182 |   1.0760 |     34.233 |     1.6
   28 |   0.7699 |     25.774 |   1.0527 |     33.923 |     1.6
   29 |   0.7702 |     25.675 |   1.0436 |     33.830 |     1.7
   30 |   0.7504 |     25.107 |   1.0429 |     33.085 |     1.8
   31 |   0.7088 |     23.477 |   1.0565 |     32.961 |     1.8
   32 |   0.6812 |     22.314 |   1.0563 |     32.992 |     1.9
   33 |   0.6735 |     22.413 |   1.0464 |     33.023 |     1.9
   34 |   0.6616 |     22.198 |   1.0730 |     33.861 |     2.0
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 32
Descriptors dimension: 1136
Decoder embedding dimension: 32
Encoder hidden units: 128
Encoder layers: 4
Decoder hidden units: 64
Decoder layers: 4
Dropout: 0.0
Trainable parameters: 2,456,641

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5948 |     70.320 |   2.0993 |     54.966 |     0.1
    2 |   1.8374 |     51.058 |   1.6398 |     47.083 |     0.2
    3 |   1.5348 |     45.851 |   1.4817 |     47.083 |     0.2
    4 |   1.4462 |     45.846 |   1.4328 |     47.083 |     0.3
    5 |   1.4137 |     45.901 |   1.4122 |     47.083 |     0.4
    6 |   1.4005 |     45.846 |   1.4054 |     47.083 |     0.5
    7 |   1.3939 |     45.846 |   1.3995 |     47.083 |     0.5
    8 |   1.3902 |     45.862 |   1.3962 |     47.083 |     0.6
    9 |   1.3854 |     45.923 |   1.3941 |     47.083 |     0.7
   10 |   1.3807 |     45.912 |   1.4028 |     47.269 |     0.8
   11 |   1.3707 |     45.438 |   1.3719 |     45.686 |     0.9
   12 |   1.3531 |     44.634 |   1.3495 |     45.345 |     0.9
   13 |   1.3435 |     44.529 |   1.3505 |     45.841 |     1.0
   14 |   1.3355 |     44.474 |   1.3455 |     45.469 |     1.1
   15 |   1.3309 |     44.419 |   1.3422 |     46.276 |     1.2
   16 |   1.3237 |     44.369 |   1.3419 |     46.245 |     1.2
   17 |   1.3202 |     44.165 |   1.3273 |     45.345 |     1.3
   18 |   1.3142 |     44.160 |   1.3263 |     45.438 |     1.4
   19 |   1.3087 |     43.923 |   1.3223 |     45.748 |     1.5
   20 |   1.3038 |     43.813 |   1.3305 |     45.469 |     1.6
   21 |   1.3014 |     43.851 |   1.3129 |     45.500 |     1.6
   22 |   1.2922 |     43.383 |   1.3097 |     45.469 |     1.7
   23 |   1.2943 |     43.240 |   1.3109 |     44.507 |     1.8
   24 |   1.2991 |     43.631 |   1.3082 |     45.313 |     1.9
   25 |   1.2900 |     43.036 |   1.3033 |     44.662 |     2.0
   26 |   1.2830 |     42.700 |   1.3009 |     44.569 |     2.0
   27 |   1.2744 |     42.545 |   1.2933 |     44.662 |     2.1
   28 |   1.2753 |     42.837 |   1.2946 |     44.972 |     2.2
   29 |   1.2670 |     42.408 |   1.2821 |     44.010 |     2.3
   30 |   1.2605 |     42.259 |   1.2873 |     43.948 |     2.3
   31 |   1.2565 |     42.050 |   1.2824 |     43.513 |     2.4
   32 |   1.2546 |     42.187 |   1.2875 |     43.762 |     2.5
   33 |   1.2487 |     41.950 |   1.2704 |     43.793 |     2.6
   34 |   1.2420 |     41.774 |   1.2810 |     43.296 |     2.7
   35 |   1.2396 |     41.631 |   1.2692 |     43.824 |     2.7
   36 |   1.2369 |     41.675 |   1.2695 |     43.886 |     2.8
   37 |   1.2380 |     41.917 |   1.2810 |     44.569 |     2.9
   38 |   1.2337 |     41.818 |   1.2617 |     43.637 |     3.0
   39 |   1.2230 |     41.444 |   1.2614 |     43.451 |     3.1
   40 |   1.2237 |     41.185 |   1.2559 |     43.079 |     3.1
   41 |   1.2164 |     40.882 |   1.2589 |     42.365 |     3.2
   42 |   1.2177 |     40.904 |   1.2620 |     42.055 |     3.3
   43 |   1.2087 |     40.479 |   1.2443 |     42.148 |     3.4
   44 |   1.1982 |     40.270 |   1.2344 |     41.837 |     3.4
   45 |   1.1947 |     40.281 |   1.2473 |     42.396 |     3.5
   46 |   1.1891 |     39.862 |   1.2275 |     42.148 |     3.6
   47 |   1.1929 |     40.303 |   1.2300 |     41.558 |     3.7
   48 |   1.1834 |     39.939 |   1.2247 |     41.186 |     3.8
   49 |   1.1759 |     39.669 |   1.2327 |     41.465 |     3.8
   50 |   1.1813 |     39.868 |   1.2331 |     41.155 |     3.9
   51 |   1.1700 |     39.405 |   1.2243 |     40.658 |     4.0
   52 |   1.1583 |     39.196 |   1.2262 |     41.496 |     4.1
   53 |   1.1536 |     39.003 |   1.2138 |     40.410 |     4.1
   54 |   1.1531 |     39.036 |   1.2166 |     40.503 |     4.2
   55 |   1.1490 |     38.876 |   1.2359 |     41.713 |     4.3
   56 |   1.1538 |     38.782 |   1.2092 |     40.503 |     4.4
   57 |   1.1421 |     38.623 |   1.2031 |     40.379 |     4.5
   58 |   1.1378 |     38.760 |   1.2052 |     40.255 |     4.5
   59 |   1.1333 |     38.353 |   1.2063 |     40.813 |     4.6
   60 |   1.1322 |     38.402 |   1.1924 |     40.255 |     4.7
   61 |   1.1329 |     38.287 |   1.2097 |     41.061 |     4.8
   62 |   1.1292 |     38.171 |   1.1930 |     40.348 |     4.9
   63 |   1.1181 |     38.099 |   1.1930 |     40.379 |     4.9
   64 |   1.1099 |     37.702 |   1.1925 |     39.851 |     5.0
   65 |   1.1044 |     37.675 |   1.1783 |     39.510 |     5.1
   66 |   1.1025 |     37.460 |   1.1953 |     39.323 |     5.2
   67 |   1.0973 |     37.179 |   1.1831 |     39.789 |     5.2
   68 |   1.0953 |     37.311 |   1.1948 |     40.037 |     5.3
   69 |   1.0857 |     36.678 |   1.1772 |     39.479 |     5.4
   70 |   1.0851 |     36.623 |   1.1755 |     39.044 |     5.5
   71 |   1.0912 |     37.135 |   1.1663 |     38.330 |     5.6
   72 |   1.0724 |     36.523 |   1.1737 |     39.168 |     5.6
   73 |   1.0709 |     36.496 |   1.1770 |     38.516 |     5.7
   74 |   1.0659 |     35.824 |   1.1560 |     38.547 |     5.8
   75 |   1.0544 |     35.917 |   1.1573 |     38.672 |     5.9
   76 |   1.0561 |     36.061 |   1.1518 |     38.113 |     5.9
   77 |   1.0477 |     35.466 |   1.1591 |     38.796 |     6.0
   78 |   1.0461 |     35.713 |   1.1529 |     38.330 |     6.1
   79 |   1.0375 |     35.080 |   1.1634 |     38.454 |     6.2
   80 |   1.0473 |     35.559 |   1.1724 |     38.765 |     6.3
Early stopping

Model: Seq2Seq Multimodal Bi-LSTM
Source index: <Seq2Seq Index with 46 items>
Target index: <Seq2Seq Index with 33 items>
Encoder embedding dimension: 64
Descriptors dimension: 1136
Decoder embedding dimension: 64
Encoder hidden units: 32
Encoder layers: 2
Decoder hidden units: 64
Decoder layers: 2
Dropout: 0.0
Trainable parameters: 217,185

Training started
X_train.shape: torch.Size([3025, 702])
Y_train.shape: torch.Size([3025, 7])
X_dev.shape: torch.Size([537, 337])
Y_dev.shape: torch.Size([537, 7])
Epochs: 500
Learning rate: 0.001
Weight decay: 1e-05
Epoch | Train                 | Development           | Minutes
      | Loss     | Error Rate | Loss     | Error Rate |
---------------------------------------------------------------
    1 |   2.5183 |     65.691 |   1.8909 |     53.073 |     0.0
    2 |   1.6470 |     47.559 |   1.4996 |     46.834 |     0.0
    3 |   1.4228 |     45.080 |   1.3755 |     46.027 |     0.0
    4 |   1.3314 |     43.207 |   1.2980 |     42.893 |     0.1
    5 |   1.2633 |     41.218 |   1.2452 |     42.396 |     0.1
    6 |   1.2050 |     39.548 |   1.1900 |     39.603 |     0.1
    7 |   1.1547 |     37.565 |   1.1594 |     38.579 |     0.1
    8 |   1.1030 |     35.994 |   1.1164 |     37.337 |     0.1
    9 |   1.0569 |     34.457 |   1.0910 |     36.499 |     0.1
   10 |   1.0092 |     32.413 |   1.0603 |     33.706 |     0.1
   11 |   0.9630 |     30.848 |   1.0276 |     33.551 |     0.1
   12 |   0.9231 |     29.658 |   1.0055 |     31.782 |     0.2
   13 |   0.8829 |     27.769 |   0.9744 |     31.440 |     0.2
   14 |   0.8394 |     26.011 |   0.9785 |     30.354 |     0.2
   15 |   0.7989 |     24.882 |   0.9509 |     29.857 |     0.2
   16 |   0.7584 |     23.383 |   0.9445 |     29.205 |     0.2
   17 |   0.7153 |     21.994 |   0.9247 |     28.461 |     0.2
   18 |   0.6824 |     21.019 |   0.9230 |     28.336 |     0.2
   19 |   0.6466 |     19.752 |   0.9106 |     27.964 |     0.3
   20 |   0.6180 |     18.760 |   0.9159 |     27.964 |     0.3
   21 |   0.5860 |     17.791 |   0.9183 |     27.592 |     0.3
   22 |   0.5615 |     16.981 |   0.8998 |     27.064 |     0.3
   23 |   0.5316 |     15.989 |   0.9188 |     26.971 |     0.3
   24 |   0.5037 |     15.135 |   0.9167 |     26.288 |     0.3
   25 |   0.4867 |     14.672 |   0.9211 |     26.723 |     0.3
   26 |   0.4652 |     13.835 |   0.9493 |     26.288 |     0.4
Early stopping

