{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9606e0f7-ce9d-43af-8fd2-72cd6ba96d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split \n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "from seq2seq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55df232-7689-4fa5-a968-0c5add5759dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2d1c6a-f935-470f-943c-b16f544beceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string that simulates a list to a real list\n",
    "def convert_string_list(element):\n",
    "    # Delete [] of the string\n",
    "    element = element[0:len(element)]\n",
    "    # Create a list that contains each code as e.g. 'A'\n",
    "    ATC_list = list(element.split('; '))\n",
    "    for index, code in enumerate(ATC_list):\n",
    "        # Delete '' of the code\n",
    "        ATC_list[index] = code[0:len(code)] \n",
    "    return ATC_list\n",
    "\n",
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def create_partitions(df, seed):\n",
    "    # Create a new column that indicates if the compound has more than 1 ATC code associated (1) or not (0)\n",
    "    df['multiple_ATC'] = df['ATC Codes'].apply(lambda x: len(convert_string_list(x)) > 1)\n",
    "    \n",
    "    # Divide the dataset depending on multiple_ATC column\n",
    "    group_more_than_one = df[df['multiple_ATC']]  # Compounds with more than one ATC code associated\n",
    "    group_one = df[~df['multiple_ATC']]          # Compounds with just one ATC code associated\n",
    "\n",
    "    conteo_longitudes = Counter(len(convert_string_list(codes)) for codes in group_more_than_one['ATC Codes'])\n",
    "    group_more_than_one = group_more_than_one.reset_index(drop=True)\n",
    "    group_one = group_one.reset_index(drop=True)\n",
    "\n",
    "    # Divide each set into train, validation and test subsets\n",
    "    train_more, test_more = train_test_split(group_more_than_one, test_size=0.2, random_state=seed)\n",
    "    train_one, test_one = train_test_split(group_one, test_size=0.2, random_state=seed)\n",
    "    train_more, val_more = train_test_split(train_more, test_size=0.15, random_state=seed)\n",
    "    train_one, val_one = train_test_split(train_one, test_size=0.15, random_state=seed)\n",
    "    \n",
    "    # Combine each set\n",
    "    train_set = pd.concat([train_more, train_one])\n",
    "    test_set = pd.concat([test_more, test_one])\n",
    "    val_set = pd.concat([val_more, val_one])\n",
    "    train_set = shuffle(train_set, random_state = seed)\n",
    "    test_set = shuffle(test_set, random_state = seed)\n",
    "    val_set = shuffle(val_set, random_state = seed)\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def multiplicate_rows(df):\n",
    "    # Duplicate each compound the number of ATC codes associated to it, copying its SMILES in new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        atc_codes = row['ATC Codes']\n",
    "        atc_codes_list = convert_string_list(atc_codes)\n",
    "        \n",
    "        if len(atc_codes_list) > 1:\n",
    "            for code in atc_codes_list:\n",
    "                if len(code) == 5:\n",
    "                    new_row = row.copy()\n",
    "                    new_row['ATC Codes'] = code\n",
    "                    new_rows.append(new_row)\n",
    "        else:\n",
    "            if len(atc_codes_list[0]) == 5:\n",
    "                new_rows.append(row)\n",
    "    \n",
    "    new_set = pd.DataFrame(new_rows)\n",
    "    new_set = new_set.reset_index(drop=True)\n",
    "\n",
    "    return new_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d828d612-7497-4982-bcd8-4b021c556939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(78)\n",
    "    \n",
    "train_set = pd.read_csv(f'train_set.csv')\n",
    "test_set = pd.read_csv(f'test_set.csv')\n",
    "val_set = pd.read_csv(f'val_set.csv')\n",
    "\n",
    "new_train_set = multiplicate_rows(train_set)\n",
    "new_val_set = multiplicate_rows(val_set)\n",
    "new_test_set = multiplicate_rows(test_set)\n",
    "\n",
    "X_train = new_train_set['Neutralized SMILES']\n",
    "y_train = new_train_set['ATC Codes']\n",
    "X_test = new_test_set['Neutralized SMILES']\n",
    "X_test2 = test_set['Neutralized SMILES']\n",
    "y_test = new_test_set['ATC Codes']\n",
    "\n",
    "atc_nivel1 = []\n",
    "for y in y_train:\n",
    "    atc_nivel1.append(y[0])\n",
    "y_train_nivel1 = pd.DataFrame(atc_nivel1)\n",
    "y_train_nivel1 = y_train_nivel1.reset_index(drop=True)\n",
    "\n",
    "atc_nivel2 = []\n",
    "for y in y_train:\n",
    "    atc_nivel2.append(y[1:3])\n",
    "y_train_nivel2 = pd.DataFrame(atc_nivel2)\n",
    "y_train_nivel2 = y_train_nivel2.reset_index(drop=True)\n",
    "\n",
    "\n",
    "atc_nivel3 = []\n",
    "for y in y_train:\n",
    "    atc_nivel3.append(y[3:4])\n",
    "y_train_nivel3 = pd.DataFrame(atc_nivel3)\n",
    "y_train_nivel3 = y_train_nivel3.reset_index(drop=True)\n",
    "\n",
    "atc_nivel4 = []\n",
    "for y in y_train:\n",
    "    atc_nivel4.append(y[4:5])\n",
    "y_train_nivel4 = pd.DataFrame(atc_nivel4)\n",
    "y_train_nivel4 = y_train_nivel4.reset_index(drop=True)\n",
    "\n",
    "# Contar la frecuencia de cada elemento\n",
    "conteo1 = Counter(atc_nivel1)\n",
    "# Calcular la probabilidad de cada elemento\n",
    "total_elementos1 = len(atc_nivel1)\n",
    "probabilidades1 = {elemento: frecuencia / total_elementos1 for elemento, frecuencia in conteo1.items()}\n",
    "nivel1 = np.random.choice(list(probabilidades1.keys()), size=(len(X_test2),20), p=list(probabilidades1.values()))\n",
    "\n",
    "# Contar la frecuencia de cada elemento\n",
    "conteo2 = Counter(atc_nivel2)\n",
    "\n",
    "# Calcular la probabilidad de cada elemento\n",
    "total_elementos2 = len(atc_nivel2)\n",
    "probabilidades2 = {elemento: frecuencia / total_elementos2 for elemento, frecuencia in conteo2.items()}\n",
    "nivel2 = np.random.choice(list(probabilidades2.keys()), size=(len(X_test2),20), p=list(probabilidades2.values()))\n",
    "    \n",
    "# Contar la frecuencia de cada elemento\n",
    "conteo3 = Counter(atc_nivel3)\n",
    "\n",
    "# Calcular la probabilidad de cada elemento\n",
    "total_elementos3 = len(atc_nivel3)\n",
    "probabilidades3 = {elemento: frecuencia / total_elementos3 for elemento, frecuencia in conteo3.items()}\n",
    "nivel3 = np.random.choice(list(probabilidades3.keys()), size=(len(X_test2),20), p=list(probabilidades3.values()))\n",
    "\n",
    "# Contar la frecuencia de cada elemento\n",
    "conteo4 = Counter(atc_nivel4)\n",
    "\n",
    "# Calcular la probabilidad de cada elemento\n",
    "total_elementos4 = len(atc_nivel4)\n",
    "probabilidades4 = {elemento: frecuencia / total_elementos4 for elemento, frecuencia in conteo4.items()}\n",
    "nivel4 = np.random.choice(list(probabilidades4.keys()), size=(len(X_test2),20), p=list(probabilidades4.values()))\n",
    "\n",
    "predictions = []\n",
    "for i, atc1 in enumerate(nivel1):\n",
    "    codes = []\n",
    "    for j, code1 in enumerate(atc1):\n",
    "        codes.append(code1 + nivel2[i][j] + nivel3[i][j] + nivel4[i][j])\n",
    "    predictions.append(codes)\n",
    "    \n",
    "predictions_clean = []\n",
    "for preds in predictions:\n",
    "    interm = []\n",
    "    for pred in preds:\n",
    "        clean_pred = pred.replace('<START>', '').replace('<END>', '')\n",
    "        if len(clean_pred) == 5:\n",
    "            interm.append(clean_pred)\n",
    "    if len(interm) >= 10:\n",
    "        predictions_clean.append(interm[0:10])\n",
    "    else:\n",
    "        predictions_clean.append(interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf16194-89cc-4932-94aa-bd28c6132fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions1, recalls1, f1s1 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 1)\n",
    "precisions2, recalls2, f1s2 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 2)\n",
    "precisions3, recalls3, f1s3 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 3)\n",
    "precisions4, recalls4, f1s4 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 4)\n",
    "precisions5, recalls5, f1s5 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 5)\n",
    "precisions6, recalls6, f1s6 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 6)\n",
    "precisions7, recalls7, f1s7 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 7)\n",
    "precisions8, recalls8, f1s8 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 8)\n",
    "precisions9, recalls9, f1s9 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 9)\n",
    "precisions10, recalls10, f1s10 = defined_metrics.complete_metrics(predictions_clean, f'test_set.csv', 'ATC Codes', 10)\n",
    "\n",
    "precisions_average1 = sum(precisions1)/len(precisions1)\n",
    "recalls_average1 = sum(recalls1)/len(recalls1)\n",
    "f1s_average1 = sum(f1s1)/len(f1s1)\n",
    "\n",
    "precisions_average2 = sum(precisions2)/len(precisions2)\n",
    "recalls_average2 = sum(recalls2)/len(recalls2)\n",
    "f1s_average2 = sum(f1s2)/len(f1s2)\n",
    "\n",
    "precisions_average3 = sum(precisions3)/len(precisions3)\n",
    "recalls_average3 = sum(recalls3)/len(recalls3)\n",
    "f1s_average3 = sum(f1s3)/len(f1s3)\n",
    "\n",
    "precisions_average4 = sum(precisions4)/len(precisions4)\n",
    "recalls_average4 = sum(recalls4)/len(recalls4)\n",
    "f1s_average4 = sum(f1s4)/len(f1s4)\n",
    "\n",
    "precisions_average5 = sum(precisions5)/len(precisions5)\n",
    "recalls_average5 = sum(recalls5)/len(recalls5)\n",
    "f1s_average5 = sum(f1s5)/len(f1s5)\n",
    "\n",
    "precisions_average6 = sum(precisions6)/len(precisions6)\n",
    "recalls_average6 = sum(recalls6)/len(recalls6)\n",
    "f1s_average6 = sum(f1s6)/len(f1s6)\n",
    "\n",
    "precisions_average7 = sum(precisions7)/len(precisions7)\n",
    "recalls_average7 = sum(recalls7)/len(recalls7)\n",
    "f1s_average7 = sum(f1s7)/len(f1s7)\n",
    "\n",
    "precisions_average8 = sum(precisions8)/len(precisions8)\n",
    "recalls_average8 = sum(recalls8)/len(recalls8)\n",
    "f1s_average8 = sum(f1s8)/len(f1s8)\n",
    "\n",
    "precisions_average9 = sum(precisions9)/len(precisions9)\n",
    "recalls_average9 = sum(recalls9)/len(recalls9)\n",
    "f1s_average9 = sum(f1s9)/len(f1s9)\n",
    "\n",
    "precisions_average10 = sum(precisions10)/len(precisions10)\n",
    "recalls_average10 = sum(recalls10)/len(recalls10)\n",
    "f1s_average10 = sum(f1s10)/len(f1s10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c42e04-9171-4d53-86fd-4926abdc71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions_average_k = []\n",
    "precisions_average_k.append(precisions_average1)\n",
    "precisions_average_k.append(precisions_average2)\n",
    "precisions_average_k.append(precisions_average3)\n",
    "precisions_average_k.append(precisions_average4)\n",
    "precisions_average_k.append(precisions_average5)\n",
    "precisions_average_k.append(precisions_average6)\n",
    "precisions_average_k.append(precisions_average7)\n",
    "precisions_average_k.append(precisions_average8)\n",
    "precisions_average_k.append(precisions_average9)\n",
    "precisions_average_k.append(precisions_average10)\n",
    "recalls_average_k = []\n",
    "recalls_average_k.append(recalls_average1)\n",
    "recalls_average_k.append(recalls_average2)\n",
    "recalls_average_k.append(recalls_average3)\n",
    "recalls_average_k.append(recalls_average4)\n",
    "recalls_average_k.append(recalls_average5)\n",
    "recalls_average_k.append(recalls_average6)\n",
    "recalls_average_k.append(recalls_average7)\n",
    "recalls_average_k.append(recalls_average8)\n",
    "recalls_average_k.append(recalls_average9)\n",
    "recalls_average_k.append(recalls_average10)\n",
    "f1s_average_k = []\n",
    "f1s_average_k.append(f1s_average1)\n",
    "f1s_average_k.append(f1s_average2)\n",
    "f1s_average_k.append(f1s_average3)\n",
    "f1s_average_k.append(f1s_average4)\n",
    "f1s_average_k.append(f1s_average5)\n",
    "f1s_average_k.append(f1s_average6)\n",
    "f1s_average_k.append(f1s_average7)\n",
    "f1s_average_k.append(f1s_average8)\n",
    "f1s_average_k.append(f1s_average9)\n",
    "f1s_average_k.append(f1s_average10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0099cad9-b433-4b0d-8cc4-f3113de12473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(\"df_metrics.csv\")\n",
    "new_rows = pd.DataFrame(columns=[\"model\", \"precision\", \"recall\", \"f1\"])\n",
    "new_rows[\"precision\"] = precisions_average_k\n",
    "new_rows[\"recall\"] = recalls_average_k\n",
    "new_rows[\"f1\"] = f1s_average_k\n",
    "new_rows[\"model\"] = \"Random Classifier\"\n",
    "df_results = pd.concat([df_results , new_rows], ignore_index=True)\n",
    "df_results.to_csv(\"df_metrics.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
